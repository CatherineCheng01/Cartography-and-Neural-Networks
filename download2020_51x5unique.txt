
PT J
AU Estevez, PG
   Ferrari, SR
   Santamaria, TC
AF Garcia Estevez, Pablo
   Roji Ferrari, Salvador
   Corzo Santamaria, Teresa
TI Mapping of stock exchanges: contagion from a new perspective
SO SPANISH JOURNAL OF FINANCE AND ACCOUNTING-REVISTA ESPANOLA DE FINANCIACION Y CONTABILIDA
LA English
DT Article
DE Clusters; international financial markets; self-organizing neural networks; financial contagion
ID self-organizing maps; neural-networks; model
AB This paper addresses the contagion problem between stock exchanges and uses self-organizing maps (SOMs) to develop a two-dimensional map based on five market variables from 48 stock exchanges around the world for the 2000-2012 period. The study addresses markets worldwide that have different levels of economic development. Using five market variables, we group stock exchanges into distinctive clusters and analyze their similarities, differences, and dynamics. The technique applied, artificial neural networks (ANNs), is a non-parametric visualization tool to study the dynamics of the markets worldwide following a non-traditional perspective based on the specific formation of groups and their evolution. Each group is defined by the Euclidean distances between markets. There are certain common features, both economic and geographic, within the migrant and static exchanges, which offer new insights. By applying the standard contagion methodology to the resulting groups, we study the spread of the subprime crisis and find evidence of contagion, as well as a high interdependence between markets for the entire period under consideration.
C1 [Garcia Estevez, Pablo] CUNEF, Dept Finance, Madrid, Spain.
   [Roji Ferrari, Salvador] Univ Complutense, Madrid, Spain.
   [Corzo Santamaria, Teresa] Univ Pontificia Comillas, Finance Dept, ICADE, Madrid, Spain.
C3 CUNEF Universidad; Complutense University of Madrid; Comillas Pontifical University
RP Estevez, PG (corresponding author), Colegio Univ Estudios Financieros CUNEF, C Leonardo Prieto Castro 2, Madrid 28040, Spain.
EM pgestevez@cunef.edu
CR ALEXANDER GJ, 1988, J FINANC QUANT ANAL, V23, P135, DOI 10.2307/2330877
   Ao SI, 2003, IASTED: PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON MODELLING AND SIMULATION, V0, P353
   AO SI, 2003, P INT C COMP INT MOD, V0, P0
   Azcarraga A., 2008, SOFT COMPUTING KNOWL, V0, PP45, DOI 10.1007/978-0-387-69935-63
   Baker M, 2007, J ECON PERSPECT, V21, P129, DOI 10.1257/jep.21.2.129
   Barr D. S., 1994, AI EXPERT, V9, P16
   Barrera D, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS10), V0, PP73, DOI 10.1145/1866307.1866317
   Basu J.K., 2010, INT J SOFTW ENG ITS, V4, P0
   Bloom JZ, 2005, ANN TOURISM RES, V32, P93, DOI 10.1016/j.annals.2004.05.001
   Cao Q, 2005, COMPUT OPER RES, V32, P2499, DOI 10.1016/j.cor.2004.03.015
   Cottrell M., 1996, P NEURAL NETWORKS CA, V0, P0
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   de la Torre A, 2007, J BANK FINANC, V31, P1731, DOI 10.1016/j.jbankfin.2006.11.008
   Ding L, 2010, J INT FINANC MARK I, V20, P323, DOI 10.1016/j.intfin.2010.04.002
   Donaldson RG, 1996, J FORECASTING, V15, P49
   Ferstl O.K., 1998, HDB ARCHITECTURES IN, V0, PP347, DOI 10.1007/3-540-26661-5
   Forbes KJ, 2002, J FINANC, V57, P2223, DOI 10.1111/0022-1082.00494
   Frankel J, 2012, J INT ECON, V87, P216, DOI 10.1016/j.jinteco.2011.12.009
   Estevez PG, 2015, CUAD ECON-SPAIN, V38, P181, DOI 10.1016/j.cesjef.2015.07.003
   GRUDNITSKI G, 1993, J FUTURES MARKETS, V13, P631, DOI 10.1002/fut.3990130605
   Hagan MT, 2002, INT J ROBUST NONLIN, V12, P959, DOI 10.1002/rnc.727
   Hertz J., 1991, LECT NOTES SANTA FE, VI, P0
   Hewitson BC, 2002, CLIMATE RES, V22, P13, DOI 10.3354/cr022013
   HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088
   JAIN AK, 1988, ALGORITHMS CLUSTERIN, V0, P96
   Jasic T., 2004, APPL FINANCIAL EC, V14, P285
   Jegede O., 2007, COMP SCI IT ED C 200, V0, P0
   Kalteh AM, 2008, ENVIRON MODELL SOFTW, V23, P835, DOI 10.1016/j.envsoft.2007.10.001
   Kim T, 2006, I S INTELL SIG PROC, V0, P437
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kohonen T., 1997, INTRO SOM TOOLBOX, V0, P0
   KOHONEN T, 1989, SELF ORG ASS MEMORY, V0, P0
   Kolarun J., 2009, ADV DATA ANAL DATA H, V0, P461
   Kourtit K, 2012, INNOVATION-ABINGDON, V25, P93, DOI 10.1080/13511610.2012.660331
   Kryzanowski L., 1993, FINANCIAL ANALYSTS JOURNAL, V49, P21, DOI 10.2469/faj.v49.n4.21
   Lawrence RD, 1999, DATA MIN KNOWL DISC, V3, P171, DOI 10.1023/A:1009817804059
   Levine R., 2006, REVIEW OF FINANCE, V10, P153, DOI 10.1007/s10679-006-6981-7
   Mantegna RN, 1999, EUR PHYS J B, V11, P193, DOI 10.1007/s100510050929
   Martin B., 1994, NEURAL NETWORKS CAPI, V0, P341
   Martin B., 1997, REDES NEURONALES SIS, V0, P0
   McConnell J. M., 1996, SURVEY EVIDENCE DOME, V0, P0
   Minsky M., 2017, PERCEPTRONS INTRO CO, V0, P0
   Pagano M, 2001, EUR ECON REV, V45, P770, DOI 10.1016/S0014-2921(01)00132-5
   Quinn DP, 2008, AM ECON REV, V98, P535, DOI 10.1257/aer.98.2.535
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Sarlin P, 2013, J INT FINANC MARK I, V26, P46, DOI 10.1016/j.intfin.2013.05.002
   SAUDAGARAN SM, 1995, J INT BUS STUD, V26, P319, DOI 10.1057/palgrave.jibs.8490176
   SerranoCinca C, 1996, DECIS SUPPORT SYST, V17, P227, DOI 10.1016/0167-9236(95)00033-X
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   Vesanto J., 1999, INTELLIGENT DATA ANALYSIS, V3, P111, DOI 10.1016/S1088-467X(99)00013-X
   Vesanto J., 2000, TECHNICAL REPORT, V216, P216
   WILLSHAW DJ, 1976, PROC R SOC SER B-BIO, V194, P431, DOI 10.1098/rspb.1976.0087
NR 53
TC 0
Z9 0
U1 0
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0210-2412
EI 2332-0753
J9 SPAN J FINANC ACCOUN
JI Span. J. Financ. Account.
PD JAN 2
PY 2020
VL 49
IS 1
BP 1
EP 27
DI 10.1080/02102412.2018.1540120
PG 27
WC Business, Finance
SC Business & Economics
GA KD4PX
UT WOS:000507849500001
DA 2023-04-26
ER

PT J
AU Cho, BH
   Lee, Y
   Park, KA
   Oh, SY
   Moon, JH
   Lee, GI
   Noh, H
   Chung, JK
   Kang, MC
   Chung, MJ
AF Cho, Baek Hwan
   Lee, Young
   Park, Kyung-Ah
   Oh, Sei Yeul
   Moon, Jong Hak
   Lee, Ga-In
   Noh, Hoon
   Chung, Joon Kyo
   Kang, Min Chae
   Chung, Myung Jin
TI Computer-aided recognition of myopic tilted optic disc using deep learning algorithms in fundus photography
SO BMC OPHTHALMOLOGY
LA English
DT Article
DE Fundus photographs; Myopic tilted optic disc; Deep learning algorithm; Automated computer-aided recognition
ID nerve-fiber layer; diabetic-retinopathy; neural-networks; eyes; prevalence; validation; thickness; glaucoma; dataset; images
AB BackgroundIt is necessary to consider myopic optic disc tilt as it seriously impacts normal ocular parameters. However, ophthalmologic measurements are within inter-observer variability and time-consuming to get. This study aimed to develop and evaluate deep learning models that automatically recognize a myopic tilted optic disc in fundus photography.MethodsThis study used 937 fundus photographs of patients with normal or myopic tilted disc, collected from Samsung Medical Center between April 2016 and December 2018. We developed an automated computer-aided recognition system for optic disc tilt on color fundus photographs via a deep learning algorithm. We preprocessed all images with two image resizing techniques. GoogleNet Inception-v3 architecture was implemented. The performances of the models were compared with the human examiner's results. Activation map visualization was qualitatively analyzed using the generalized visualization technique based on gradient-weighted class activation mapping (Grad-CAM++).ResultsNine hundred thirty-seven fundus images were collected and annotated from 509 subjects. In total, 397 images from eyes with tilted optic discs and 540 images from eyes with non-tilted optic discs were analyzed. We included both eye data of most included patients and analyzed them separately in this study. For comparison, we conducted training using two aspect ratios: the simple resized dataset and the original aspect ratio (AR) preserving dataset, and the impacts of the augmentations for both datasets were evaluated. The constructed deep learning models for myopic optic disc tilt achieved the best results when simple image-resizing and augmentation were used. The results were associated with an area under the receiver operating characteristic curve (AUC) of 0.9780.008, an accuracy of 0.960 +/- 0.010, sensitivity of 0.937 +/- 0.023, and specificity of 0.963 +/- 0.015. The heatmaps revealed that the model could effectively identify the locations of the optic discs, the superior retinal vascular arcades, and the retinal maculae.Conclusions We developed an automated deep learning-based system to detect optic disc tilt. The model demonstrated excellent agreement with the previous clinical criteria, and the results are promising for developing future programs to adjust and identify the effect of optic disc tilt on ophthalmic measurements.
C1 [Cho, Baek Hwan; Lee, Young; Moon, Jong Hak; Chung, Myung Jin] Samsung Med Ctr, Med AI Res Ctr, Inst Smart Healthcare, Seoul, South Korea.
   [Cho, Baek Hwan; Moon, Jong Hak] Sungkyunkwan Univ, Dept Med Device Management & Res, SAIHST, Seoul, South Korea.
   [Lee, Young] Sungkyunkwan Univ, Dept Digital Hlth, SAIHST, Seoul, South Korea.
   [Park, Kyung-Ah; Oh, Sei Yeul; Lee, Ga-In; Noh, Hoon; Chung, Joon Kyo; Kang, Min Chae] Sungkyunkwan Univ, Samsung Med Ctr, Dept Ophthalmol, Sch Med, 81 Irwon Ro, Seoul 06351, South Korea.
   [Chung, Myung Jin] Sungkyunkwan Univ, Samsung Med Ctr, Dept Radiol, Sch Med, Seoul, South Korea.
C3 Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); Samsung Medical Center
RP Park, KA; Oh, SY (corresponding author), Sungkyunkwan Univ, Samsung Med Ctr, Dept Ophthalmol, Sch Med, 81 Irwon Ro, Seoul 06351, South Korea.
EM kparkoph@skku.edu; syoh@skku.edu
FU Biological & Medical Technology Development Program of the National Research Foundation of Korea (NRF) - Korean government, MSIT [NRF-2017M3A9E1064784]; Basic Science Research Program through the NRF - Ministry of Science and ICT [NRF-2019R1F1A1048920, NRF-2020R1F1A1049248]
CR Abramoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22
   Aizawa N, 2014, BMC OPHTHALMOL, V14, P0, DOI 10.1186/1471-2415-14-113
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8030292
   [Anonymous], 2010, P 13 INT C ARTIFICIA, V0, P0
   APPLE DJ, 1982, SURV OPHTHALMOL, V27, P3, DOI 10.1016/0039-6257(82)90111-4
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   BRAZITIKOS PD, 1990, ARCH OPHTHALMOL-CHIC, V108, P1698, DOI 10.1001/archopht.1990.01070140052027
   Bro R, 2003, J CHEMOMETR, V17, P16, DOI 10.1002/cem.773
   Burlina PM, 2017, JAMA OPHTHALMOL, V135, P1170, DOI 10.1001/jamaophthalmol.2017.3782
   Chattopadhay A, 2018, IEEE WINT CONF APPL, V0, PP839, DOI 10.1109/WACV.2018.00097
   Chen W. Y., 2019, ARXIV190404232, V0, P0
   Christopher M, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-35044-9
   Esmaeili Seyed A, 2017, P IEEE C COMP VIS PA, V0, P4622
   Geifman Y., 2019, ARXIV190109192, V0, P0
   GROSSNIKLAUS HE, 1992, RETINA-J RET VIT DIS, V12, P127, DOI 10.1097/00006982-199212020-00009
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hajian-Tilaki K, 2013, CASP J INTERN MED, V4, P627
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Holden BA, 2016, OPHTHALMOLOGY, V123, P1036, DOI 10.1016/j.ophtha.2016.01.006
   How ACS, 2009, ARCH OPHTHALMOL-CHIC, V127, P894, DOI 10.1001/archophthalmol.2009.134
   Hwang YH, 2012, J GLAUCOMA, V21, P394, DOI 10.1097/IJG.0b013e3182182567
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jonas JB, 1997, GRAEF ARCH CLIN EXP, V235, P627, DOI 10.1007/BF00946938
   Jonas JB, 1997, OPHTHALMOLOGY, V104, P1934, DOI 10.1016/S0161-6420(97)30004-9
   JONAS JB, 1988, GRAEF ARCH CLIN EXP, V226, P587, DOI 10.1007/BF02169209
   Kim YC, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-19242-z
   Kim YC, 2017, SCI REP-UK, V7, P0, DOI 10.1038/s41598-017-06072-8
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kohavi R., 1995, IJCAI 95 P 14 INT JO, V0, P0
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Law SK, 2010, ARCH OPHTHALMOL-CHIC, V128, P141, DOI 10.1001/archophthalmol.2009.340
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Nakazawa M, 2008, ACTA OPHTHALMOL, V86, P626, DOI 10.1111/j.1600-0420.2007.01139.x
   Pan CW, 2015, OPTOMETRY VISION SCI, V92, P258, DOI 10.1097/OPX.0000000000000516
   Park HYL, 2015, INVEST OPHTH VIS SCI, V56, P4927, DOI 10.1167/iovs.14-15819
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samarawickrama C, 2011, OPHTHALMOLOGY, V118, P2050, DOI 10.1016/j.ophtha.2011.02.040
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shoeibi N, 2017, CLIN EXP OPTOM, V100, P690, DOI 10.1111/cxo.12511
   Sola J, 1997, IEEE T NUCL SCI, V44, P1464, DOI 10.1109/23.589532
   Son J, 2020, OPHTHALMOLOGY, V127, P85, DOI 10.1016/j.ophtha.2019.05.029
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sung MS, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0187160
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan NYQ, 2019, CURR OPIN OPHTHALMOL, V30, P89, DOI 10.1097/ICU.0000000000000548
   Theodorou-Kanakari A, 2018, ADV THER, V35, P1510, DOI 10.1007/s12325-018-0776-z
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Vuori ML, 2008, ACTA OPHTHALMOL, V86, P622, DOI 10.1111/j.1600-0420.2007.01117.x
   Yasuzumi K, 2003, BRIT J OPHTHALMOL, V87, P1088, DOI 10.1136/bjo.87.9.1088
   You QS, 2008, EYE, V22, P728, DOI 10.1038/eye.2008.87
   Zheng L., 2016, ARXIV160400133, V0, P0
NR 55
TC 6
Z9 6
U1 0
U2 2
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 
EI 1471-2415
J9 BMC OPHTHALMOL
JI BMC Ophthalmol.
PD OCT 9
PY 2020
VL 20
IS 1
BP 
EP 
DI 10.1186/s12886-020-01657-w
PG 9
WC Ophthalmology
SC Ophthalmology
GA OB6TP
UT WOS:000578602000003
PM 33036582
DA 2023-04-26
ER

PT J
AU Punn, NS
   Agarwal, S
AF Punn, Narinder Singh
   Agarwal, Sonali
TI Inception U-Net Architecture for Semantic Segmentation to Identify Nuclei in Microscopy Cell Images
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Convolution neural networks; healthcare; medical image analysis; semantic segmentation
AB With the increasing applications of deep learning in biomedical image analysis, in this article we introduce an inception U-Net architecture for automating nuclei detection in microscopy cell images of varying size and modality to help unlock faster cures, inspired from Kaggle Data Science Bowl Challenge 2018 (KDSB18). This study follows from the fact that most of the analysis requires nuclei detection as the starting phase for getting an insight into the underlying biological process and further diagnosis. The proposed architecture consists of a switch normalization layer, convolution layers, and inception layers (concatenated 1x1, 3x3, and 5x5 convolution and the hybrid of a max and Hartley spectral pooling layer) connected in the U-Net fashion for generating the image masks. This article also illustrates the model perception of image masks using activation maximization and filter map visualization techniques. A novel objective function segmentation loss is proposed based on the binary cross entropy, dice coefficient, and intersection over union loss functions. The intersection over union score, loss value, and pixel accuracy metrics evaluate the model over the KDSB18 dataset. The proposed inception U-Net architecture exhibits quite significant results as compared to the original U-Net and recent U-Net++ architecture.
C1 [Punn, Narinder Singh; Agarwal, Sonali] Indian Inst Informat Technol Allahabad, Prayagraj, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Punn, NS (corresponding author), Indian Inst Informat Technol Allahabad, Prayagraj, Uttar Pradesh, India.
EM pse2017002@iiita.ac.in; sonali@iiit.ac.in
CR Akhtar N, 2020, NEURAL COMPUT APPL, V32, P879, DOI 10.1007/s00521-019-04296-5
   [Anonymous], 2016, OVERVIEW GRADIENT DE, V0, P0
   Anwar SM, 2018, J MED SYST, V42, P0, DOI 10.1007/s10916-018-1088-1
   Ba JL, 2016, LAYER NORMALIZATION, V0, P0
   Bell S, 2016, PROC CVPR IEEE, V0, PP2874, DOI 10.1109/CVPR.2016.314
   Bhardwaj R, 2017, P INT COMP SOFTW APP, V0, PP236, DOI 10.1109/COMPSAC.2017.164
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   GitHub, 2018, UNETPLUSPLUS, V0, P0
   Graham Simon, 2018, ARXIV181206499, V0, P0
   Gu Z, 2019, FRONT IMMUNOL, V10, P0, DOI 10.3389/fimmu.2019.02288
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Jiang Hongda, 2018, BIORXIV, V0, P0, DOI DOI 10.1101/382549v1.
   Kaggle, 2018, KDSB CHALLENGERANK 4, V0, P0
   Kaggle, 2018, KDSB CHALLENGE RANK, V0, P0
   Kaggle, 2018, KAGGLE DATA SCI BOWL, V0, P0
   Kaggle, 2018, KDSB ANOTHER IOU MET, V0, P0
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Lin T., 2017, P IEEE INT C COMPUTE, V0, P0
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Milletari F, 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, P0, DOI 10.1109/TPAMI.2015.2481406
   Ren J., 2018, ARXIV180610779, V0, P0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Simonyan K, 2014, WORKSH INT C LEARN R, V0, P0, DOI DOI 10.48550/ARXIV.1312.6034
   Solovei I, 2013, CELL, V152, P584, DOI 10.1016/j.cell.2013.01.009
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Ulyanov Dmitry, 2016, ABS160708022 CORR, V0, P0
   Weiskopf NG, 2013, J AM MED INFORM ASSN, V20, P144, DOI 10.1136/amiajnl-2011-000681
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zhang Hao, 2018, ARXIV181004028, V0, P0
   Zhou Zongwei, 2018, DEEP LEARN MED IMAGE ANAL MULTIMODAL LEARN CLIN DECIS SUPPORT (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zwerger M, 2011, ANNU REV BIOMED ENG, V13, P397, DOI 10.1146/annurev-bioeng-071910-124736
NR 39
TC 29
Z9 29
U1 2
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR 15
PY 2020
VL 16
IS 1
BP 
EP 
DI 10.1145/3376922
PG 15
WC Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods
SC Computer Science
GA OJ1FD
UT WOS:000583712100011
DA 2023-04-26
ER

PT J
AU Teganya, Y
   Romero, D
AF Teganya, Yves
   Romero, Daniel
TI Data-Driven Spectrum Cartography via Deep Completion Autoencoders
SO ICC 2020 - 2020 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC)
LA English
DT Proceedings Paper
DE Spectrum cartography; deep learning; cognitive radio; completion autoencoders
AB Spectrum maps, which provide RF spectrum metrics such as power spectral density for every location in a geographic area, find numerous applications in wireless communications such as interference control, spectrum management, resource allocation, and network planning to name a few. Spectrum cartography techniques construct these maps from a collection of measurements collected by spatially distributed sensors. Due to the nature of the propagation of electromagnetic waves, spectrum maps are complicated functions of the spatial coordinates. For this reason, model-free approaches have been preferred. However, all existing schemes rely on some interpolation algorithm unable to learn from data. This paper proposes a novel approach to spectrum cartography where propagation phenomena are learned from data. The resulting algorithms can therefore construct a spectrum map from a significantly smaller number of measurements than existing schemes since the spatial structure of shadowing and other phenomena is previously learned from maps in other environments. Besides the aforementioned new paradigm, this is also the first work to perform spectrum cartography with deep neural networks. To exploit the manifold structure of spectrum maps, a deep network architecture is proposed based on completion autoencoders.
C1 [Teganya, Yves; Romero, Daniel] Univ Agder, Dept Informat & Commun Technol, Kristiansand, Norway.
   [Teganya, Yves] Intelligent Signal Proc & Wireless Networks Lab W, Grimstad, Norway.
C3 University of Agder
RP Teganya, Y (corresponding author), Univ Agder, Dept Informat & Commun Technol, Kristiansand, Norway.; Teganya, Y (corresponding author), Intelligent Signal Proc & Wireless Networks Lab W, Grimstad, Norway.
EM yves.teganya@uia.no; daniel.romero@uia.no
FU Research Council of Norway through the FRIPRO TOPPFORSK grant [250910/F20]; INDNOR program under the LUCAT project
CR Alaya-Feki A.B.H., 2008, PROC IEEE INT S PERS, V0, P1
   Bazerque JA, 2013, IEEE SIGNAL PROC MAG, V30, P112, DOI 10.1109/MSP.2013.2253354
   Bazerque JA, 2011, IEEE T SIGNAL PROCES, V59, P4648, DOI 10.1109/TSP.2011.2160858
   Bazerque JA, 2010, IEEE T SIGNAL PROCES, V58, P1847, DOI 10.1109/TSP.2009.2038417
   Boccolini G, 2012, 2012 IEEE 23RD INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), V0, PP1565, DOI 10.1109/PIMRC.2012.6362597
   Cherkassky V., 2007, LEARN DATA CONCEPTS, V0, P0, DOI DOI 10.1002/9780470140529.CH4.[38]L
   DallAnese E, 2011, IEEE T WIREL COMMUN, V10, P3541, DOI 10.1109/TWC.2011.081711.110323
   Ding GR, 2016, IEEE J SEL AREA COMM, V34, P107, DOI 10.1109/JSAC.2015.2452532
   Dumoulin V, 2018, ARXIV, V0, P0
   Fan JC, 2017, NEUROCOMPUTING, V266, P540, DOI 10.1016/j.neucom.2017.05.074
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Grimoud S, 2010, IEEE GLOBE WORK, V0, PP819, DOI 10.1109/GLOCOMW.2010.5700438
   GUDMUNDSON M, 1991, ELECTRON LETT, V27, P2145, DOI 10.1049/el:19911328
   Hamid M, 2017, INT CONF ACOUST SPEE, V0, PP3599, DOI 10.1109/ICASSP.2017.7952827
   Hamilton BR, 2014, IEEE J-STSP, V8, P55, DOI 10.1109/JSTSP.2013.2287471
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Huang DH, 2015, IEEE T VEH TECHNOL, V64, P2318, DOI 10.1109/TVT.2014.2345738
   Iizuka S, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3072959.3073659
   Jayawickrama BA, 2013, IEEE ICC, V0, PP5657, DOI 10.1109/ICC.2013.6655495
   Jeruchim M.C., 2006, SIMULATION COMMUNICA, V0, P0
   Kim SJ, 2013, IEEE GLOB COMM CONF, V0, PP3206, DOI 10.1109/GLOCOM.2013.6831565
   Kim SJ, 2011, CONF REC ASILOMAR C, V0, PP1415, DOI 10.1109/ACSSC.2011.6190250
   Kim SJ, 2011, IEEE J-STSP, V5, P24, DOI 10.1109/JSTSP.2010.2053016
   Lee D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P3554
   Mandic D., 2001, ADAPT LEARN SYST SIG, V0, P0, DOI DOI 10.1002/047084535X
   Patwari N, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, V0, P82, DOI 10.1109/IPSN.2008.7
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Romero D, 2018, IEEE T SIGNAL PROCES, V66, P2055, DOI 10.1109/TSP.2018.2799169
   Romero D, 2017, IEEE T SIGNAL PROCES, V65, P2547, DOI 10.1109/TSP.2017.2666775
   Stoica P., 2005, SPECTRAL ANAL SIGNAL, V0, P0
   Teganya Y, 2019, IEEE T SIGNAL PROCES, V67, P4013, DOI 10.1109/TSP.2019.2923151
NR 31
TC 9
Z9 9
U1 1
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1550-3607
EI 
J9 IEEE ICC
PD JUN 15
PY 2020
VL 0
IS 
BP 
EP 
DI 
PG 7
WC Engineering, Electrical & Electronic; Telecommunications
SC Engineering; Telecommunications
GA BQ5PR
UT WOS:000606970304155
DA 2023-04-26
ER

PT J
AU Xiao, X
   Fang, CY
   Lin, H
AF Xiao, Xin
   Fang, Chaoyang
   Lin, Hui
TI Characterizing Tourism Destination Image Using Photos' Visual Content
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE tourism destination image; visual content analysis; social network services; big data; spatiotemporal analysis
ID learning-model; perceptions
AB "A picture is worth a thousand words". Analysis of the visual content of tourist photos is an effective way to explore the image of tourist destinations. With the development of computer deep learning and big data mining technology, identifying the content of massive numbers of tourist photos by convolutional neural network (CNN) approaches breaks through the limitations of manual approaches of identifying photos' visual information, e.g., small sample size, complex identification process, and results deviation. In this study, 531,629 travel photos of Jiangxi were identified as 365 scenes through deep learning technology. Through the latent Dirichlet allocation (LDA) model, five major tourism topics are found and visualized by map. Then, we explored the spatial and temporal distribution characteristics of different tourism scenes based on hot spot analysis technology and the seasonal evaluation index. Our research shows that the visual content mining on travel photos makes it possible to understand the tourism destination image and to reveal the temporal and spatial heterogeneity of the image, thereby providing an important reference for tourism marketing.
C1 [Xiao, Xin; Fang, Chaoyang; Lin, Hui] Jiangxi Normal Univ, Sch Geog & Environm, Nanchang 330022, Jiangxi, Peoples R China.
   [Fang, Chaoyang; Lin, Hui] Jiangxi Normal Univ, Key Lab Poyang Lake Wetland & Watershed Res, Minist Educ, Nanchang 330022, Jiangxi, Peoples R China.
C3 Jiangxi Normal University; Jiangxi Normal University
RP Fang, CY (corresponding author), Jiangxi Normal Univ, Sch Geog & Environm, Nanchang 330022, Jiangxi, Peoples R China.; Fang, CY (corresponding author), Jiangxi Normal Univ, Key Lab Poyang Lake Wetland & Watershed Res, Minist Educ, Nanchang 330022, Jiangxi, Peoples R China.
EM gisxx@jxnu.edu.cn; fcy@jxnu.edu.cn; huilin@cuhk.edu.hk
FU National Natural Science Foundation of China [41671378]
CR Bae SH, 2017, TOUR PLAN DEV, V14, P167, DOI 10.1080/21568316.2016.1204356
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang J., 2009, NEURAL INF PROCESS S, V22, P288
   Chen MX, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040264
   Chen W, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8120556
   Crompton J. L., 1979, JOURNAL OF TRAVEL RESEARCH, V17, P18, DOI 10.1177/004728757901700404
   Deng N, 2019, TOUR MANAG PERSPECT, V30, P182, DOI 10.1016/j.tmp.2019.02.016
   Deng N, 2018, TOURISM MANAGE, V65, P267, DOI 10.1016/j.tourman.2017.09.010
   Fung CKW, 2015, APPL GEOGR, V62, P301, DOI 10.1016/j.apgeog.2015.05.014
   Garrod B, 2009, J TRAVEL RES, V47, P346, DOI 10.1177/0047287508322785
   Garrod B, 2012, TOUR ANAL, V17, P167, DOI 10.3727/108354212X13388995267823
   GETIS A, 1992, GEOGR ANAL, V24, P189, DOI 10.1111/j.1538-4632.1992.tb00261.x
   Giglio S, 2020, CURR ISSUES TOUR, V23, P1646, DOI 10.1080/13683500.2019.1637827
   Gu ZH, 2016, ISPRS INT J GEO-INF, V5, P0, DOI 10.3390/ijgi5110210
   Guo Y, 2017, TOURISM MANAGE, V59, P467, DOI 10.1016/j.tourman.2016.09.009
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Hunt J.D., 2016, J TRAVEL RES, V13, P1, DOI 10.1177/004728757501300301
   Hunter WC, 2013, TOURISM MANAGE, V34, P101, DOI 10.1016/j.tourman.2012.03.017
   Jin C, 2018, J TRAVEL RES, V57, P779, DOI 10.1177/0047287517714906
   Kim D, 2020, SPAT INF RES, V28, P241, DOI 10.1007/s41324-019-00285-x
   Kim H, 2015, TOURISM MANAGE, V49, P29, DOI 10.1016/j.tourman.2015.02.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JJ, 2018, TOURISM MANAGE, V68, P301, DOI 10.1016/j.tourman.2018.03.009
   Liu L, 2016, GEOJOURNAL, V81, P817, DOI 10.1007/s10708-016-9739-6
   Mak AHN, 2017, TOURISM MANAGE, V60, P280, DOI 10.1016/j.tourman.2016.12.012
   Milman A., 2012, JOURNAL OF VACATION MARKETING, V18, P157, DOI 10.1177/1356766711435975
   Milman A, 2011, INT J HOSP TOUR ADM, V12, P144, DOI 10.1080/15256480.2011.564495
   Pan S, 2011, J TRAVEL RES, V50, P171, DOI 10.1177/0047287509355325
   Peng X, 2020, IEEE ACCESS, V8, P93868, DOI 10.1109/ACCESS.2020.2995066
   Popescu A., 2009, P 18 INT C WORLD WID, V0, P1183
   Sheng FQ, 2020, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-020-02344-w
   Sievert Carson, 2014, P WORKSH INT LANG LE, V0, PP63, DOI 10.13140/2.1.1394.3043
   Spyrou E, 2016, NEUROCOMPUTING, V172, P114, DOI 10.1016/j.neucom.2014.12.104
   Stepchenkova S, 2013, TOURISM MANAGE, V36, P590, DOI 10.1016/j.tourman.2012.08.006
   Taecharungroj V, 2020, CITIES, V102, P0, DOI 10.1016/j.cities.2020.102741
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Zhang F, 2020, COMPUT ENVIRON URBAN, V81, P0, DOI 10.1016/j.compenvurbsys.2020.101478
   Zhang F, 2018, LANDSCAPE URBAN PLAN, V180, P148, DOI 10.1016/j.landurbplan.2018.08.020
   Zhang K, 2019, TOURISM MANAGE, V75, P595, DOI 10.1016/j.tourman.2019.07.002
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou B, 2016, PROC CVPR IEEE, V0, PP2921, DOI 10.1109/CVPR.2016.319
NR 42
TC 17
Z9 19
U1 19
U2 67
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD DEC 15
PY 2020
VL 9
IS 12
BP 
EP 
DI 10.3390/ijgi9120730
PG 18
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA PK0HL
UT WOS:000602136500001
DA 2023-04-26
ER
