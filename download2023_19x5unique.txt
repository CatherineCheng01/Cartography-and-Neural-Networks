
PT J
AU Cai, Z
   Wang, T
   Mi, Q
   Su, X
   Guo, LM
   Ding, ZM
AF Cai, Zhi
   Wang, Tao
   Mi, Qing
   Su, Xing
   Guo, Limin
   Ding, Zhiming
TI Dynamic Weighted Road Network Based Multi-Vehicles Navigation and Evacuation
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE weighted road network; multi-vehicle evacuation; route diversity
ID neural-network; algorithm; map
AB Many events such as large-scale activities and traffic accidents could cause an increase in vehicle density in an area, which makes the evacuation of vehicles important. However, the existing evacuation methods are not efficient limit to multi-vehicles sequences or destinations. In this paper, we introduce a novel dynamic weighted road network model for route planning. Based on the model, the route planning algorithm can obtain higher search efficiency while avoiding congested roads. For multi-vehicles evacuation, we propose a spatial diversity theory to evaluate the overlaps of routes between vehicles to be evacuated and those already evacuated. To verify the efficiency and effectiveness of our model, we conducted experiments on real road network. The results showed that our methods and algorithms can provide more reasonable paths and manage the process more efficiently.
C1 [Cai, Zhi; Wang, Tao; Mi, Qing; Su, Xing; Guo, Limin; Ding, Zhiming] Beijing Univ Technol, Coll Comp Sci, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Mi, Q (corresponding author), Beijing Univ Technol, Coll Comp Sci, Beijing 100124, Peoples R China.
EM miqing@bjut.edu.cn
FU National Natural Science of Foundation of China [62072016, 62276011]; Beijing Natural Science Foundation [4212016]
CR Ahmed F, 2013, SOFT COMPUT, V17, P1283, DOI 10.1007/s00500-012-0964-8
   Bell MGH, 2009, TRANSPORT RES B-METH, V43, P97, DOI 10.1016/j.trb.2008.05.010
   Cai Z, 2020, IEEE ACCESS, V8, P9046, DOI 10.1109/ACCESS.2019.2962392
   Cai Z, 2018, GEOINFORMATICA, V22, P435, DOI 10.1007/s10707-018-0320-y
   Chen TY, 2018, C IND ELECT APPL, V0, P1510
   Chen YM, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P1376, DOI 10.1109/ICAL.2008.4636368
   Chen Yueming, 2009, JOURNAL OF TSINGHUA UNIVERSITY (SCIENCE AND TECHNOLOGY), V49, P1102
   Dai Lei-lei, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON SYSTEM SCIENCE AND ENGINEERING (ICSSE), V0, PP432, DOI 10.1109/ICSSE.2012.6257222
   Ding N, 2021, PHYSICA A, V561, P0, DOI 10.1016/j.physa.2020.125168
   Faizian P, 2016, INT PARALL DISTRIB P, V0, PP103, DOI 10.1109/IPDPS.2016.44
   Figueiredo L, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, V0, PP1206, DOI 10.1109/ITSC.2001.948835
   Guo C, 2018, IEEE T VEH TECHNOL, V67, P5635, DOI 10.1109/TVT.2018.2806979
   Guo J, 2017, IET INTELL TRANSP SY, V11, P685, DOI 10.1049/iet-its.2016.0288
   Huang BS, 2022, ELECTRONICS-SWITZ, V11, P0, DOI 10.3390/electronics11203267
   Huang FR, 2021, IEEE T INTELL TRANSP, V22, P3907, DOI 10.1109/TITS.2020.2987645
   Jeong MG, 2019, OCEAN ENG, V172, P72, DOI 10.1016/j.oceaneng.2018.11.050
   Khosroshahi A. H., 2011, 2011 IEEE 2ND INTERNATIONAL CONFERENCE ON COMPUTING, V0, P9, DOI 10.1109/CCIENG.2011.6007944
   Kinateder M, 2018, SAFETY SCI, V106, P170, DOI 10.1016/j.ssci.2018.03.015
   Konstantinidou MA, 2015, TRANSPORT RES REC, V0, PP107, DOI 10.3141/2532-13
   Lam CT, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), V0, P1548
   Li S., 2021, P 2021 IEEE 2 INT C, VVolume 2, P203, DOI 10.1109/ICIBA52610.2021.9688227
   Li ZJ, 2017, IEEE T CYBERNETICS, V47, P3879, DOI 10.1109/TCYB.2016.2587673
   Lin Jing, 2023, SAFETY SCIENCE, V160, P0, DOI 10.1016/j.ssci.2023.106063
   Liu JY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P1902, DOI 10.1109/ICAL.2007.4338884
   Liu M, 2016, ADV ENG INFORM, V30, P259, DOI 10.1016/j.aei.2016.04.005
   Liu Z.Q., 2012, J GUANGXI U TECHNOL, V23, P41
   Luo CM, 2008, IEEE T NEURAL NETWOR, V19, P1279, DOI 10.1109/TNN.2008.2000394
   Luo CM, 2014, IEEE INT CONF ROBOT, V0, PP4094, DOI 10.1109/ICRA.2014.6907454
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P2182, DOI 10.1109/TITS.2015.2399852
   Mo F, 2001, ICCAD 2001: IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, V0, P404, DOI 10.1109/ICCAD.2001.968658
   Nannicini G, 2008, LECT NOTES COMPUT SC, V5038, P334, DOI 10.1007/978-3-540-68552-4_25
   Ok SH, 2011, J CHIN INST ENG, V34, P181, DOI 10.1080/02533839.2011.565574
   Rao AR, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, V0, P0
   Rasekhipour Y, 2017, IEEE T INTELL TRANSP, V18, P1255, DOI 10.1109/TITS.2016.2604240
   Saini K, 2022, FUTURE GENER COMP SY, V131, P106, DOI 10.1016/j.future.2022.01.015
   Shlyakhtin A.E., 2016, J EC EC ED RES, V17, P157
   Shuzhi Zhao, 2011, PROCEEDINGS OF THE 2011 INTERNATIONAL CONFERENCE ON TRANSPORTATION AND MECHANICAL & ELECTRICAL ENGINEERING (TMEE), V0, PP8, DOI 10.1109/TMEE.2011.6199135
   Song R, 2019, APPL OCEAN RES, V83, P9, DOI 10.1016/j.apor.2018.12.001
   Song ZC, 2015, CHIN AUTOM CONGR, V0, PP1940, DOI 10.1109/CAC.2015.7382822
   Votion J, 2019, IEEE T IND ELECTRON, V66, P6117, DOI 10.1109/TIE.2018.2874587
   Wang C, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON ROBOT, VISION AND SIGNAL PROCESSING (RVSP), P47, DOI 10.1109/RVSP.2015.20
   Wang JH, 2016, PROCEDIA ENGINEER, V135, P128, DOI 10.1016/j.proeng.2016.01.091
   Wu CJ, 2020, IEEE ACCESS, V8, P180773, DOI 10.1109/ACCESS.2020.3028467
   Wu Q, 2020, SAFETY SCI, V130, P0, DOI 10.1016/j.ssci.2020.104836
   Xu JM, 2022, TRANSPORT RES REC, V2676, P528, DOI 10.1177/03611981221090511
   Xu JX, 2021, 2021 6TH INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA 2021), V0, PP612, DOI 10.1109/ICSGEA53208.2021.00143
   Xun FF, 2018, 2018 18TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), V0, PP495, DOI 10.1109/ISCIT.2018.8587925
   Yang ZS, 2017, J TRANSP GEOGR, V58, P127, DOI 10.1016/j.jtrangeo.2016.11.015
   Yazdani M, 2021, INT J DISAST RISK RE, V66, P0, DOI 10.1016/j.ijdrr.2021.102627
   Zhang X, 2017, ENG SCI TECHNOL, V20, P1203, DOI 10.1016/j.jestch.2017.04.007
   Zhang YL, 2018, IEEE T INTELL TRANSP, V19, P1080, DOI 10.1109/TITS.2017.2709798
   Zheng H, 2010, TRANSPORT RES REC, V0, PP65, DOI 10.3141/2196-07
   Zheng XC, 2018, ISPRS J PHOTOGRAMM, V146, P483, DOI 10.1016/j.isprsjprs.2018.11.004
   Zong XL, 2016, INT CONF COMP SCI ED, V0, PP568, DOI 10.1109/ICCSE.2016.7581643
NR 54
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD MAR 15
PY 2023
VL 12
IS 3
BP 
EP 
DI 10.3390/ijgi12030127
PG 20
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA A5TH7
UT WOS:000955738400001
DA 2023-04-26
ER

PT J
AU Wang, P
   Zhang, YQ
   Wang, LG
   Zhang, L
   Leung, H
AF Wang, Peng
   Zhang, Yanqin
   Wang, Liguo
   Zhang, Lei
   Leung, Henry
TI Sub-Pixel Mapping of Spectral Imagery Based on Deviation Information Measurement
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Predictive models; Spatiotemporal phenomena; Mathematical models; Resource management; Weight measurement; Training; Spatial resolution; Deviation information measurement (DIM); geographically weighted regression (GWR) model; mixed pixels; spatial attraction model; spectral imagery; sub-pixel mapping (SPM)
ID hopfield neural-network; superresolution; dependence; regression
AB Sub-pixel mapping (SPM) technology can analyze mixed pixels in spectral image and realize the transformation from abundance images to a fine sub-pixel classification image. Since the SPM belongs to an ill-posed issue, deviation information (DI) inevitably is in optimal abundance images. Due to simple structure and good robustness, most SPM approaches are according to the spatial dependence assumption; namely, the closer the spatial distance is, the more likely the subpixels belong to the same class. However, the existing SPM methods based on spatial dependence assumption cannot accurately measure the DI, which affects the accuracy of the final mapping result. To address this problem, the SPM based on DI measurement (DIM) is proposed in this work. The DIM uses a dual-scale spatial attraction model (DSAM) to process the coarse abundance images to obtain predicted abundance images. The fine prior images captured at different times from the same field of view are used to measure the deviation abundance images with the DI using a geographically weighted regression (GWR) model. The predicted abundance images and deviation abundance images are fused to derive optimal abundance images. Based on the proportion information on sub-pixels being classes in the optimal abundance images, the class labels are assigned to sub-pixels by label allocation method, yielding the final mapping result. The proposed DIM method is tested on National Land-cover Dataset, Rome Dataset, and Bastrop Fires dataset. The experimental results verify that the proposed DIM achieves the best performance with the overall accuracy of 97.26%, 88.15%, and 99.80% in the three experimental results.
C1 [Wang, Peng; Zhang, Yanqin] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 210016, Peoples R China.
   [Wang, Peng] Minist Nat Resources, Jiangsu Prov Surveying & Mapping Engn Inst, Key Lab Land Satellite Remote Sensing Applicat, Nanjing 210013, Peoples R China.
   [Wang, Peng] Chuzhou Univ, Anhui Prov Key Lab Phys Geog Environm, Chuzhou 23900, Peoples R China.
   [Wang, Peng] Chinese Univ Hong Kong, Inst Space & Earth Informat Sci, Hong Kong, Peoples R China.
   [Wang, Liguo] Dalian Minzu Univ, Coll Informat & Commun Engn, Dalian 116600, Liaoning, Peoples R China.
   [Zhang, Lei] Tongji Univ, Shanghai Autonomous Intelligent Unmanned Syst Sci, Shanghai 200082, Peoples R China.
   [Leung, Henry] Univ Calgary, Dept Elect & Comp Engn, Calgary, AB T2N 1N4, Canada.
C3 Nanjing University of Aeronautics & Astronautics; Ministry of Natural Resources of the People's Republic of China; Chuzhou University; Chinese University of Hong Kong; Dalian Minzu University; Tongji University; University of Calgary
RP Wang, P (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 210016, Peoples R China.; Wang, P (corresponding author), Minist Nat Resources, Jiangsu Prov Surveying & Mapping Engn Inst, Key Lab Land Satellite Remote Sensing Applicat, Nanjing 210013, Peoples R China.; Wang, P (corresponding author), Chuzhou Univ, Anhui Prov Key Lab Phys Geog Environm, Chuzhou 23900, Peoples R China.; Wang, P (corresponding author), Chinese Univ Hong Kong, Inst Space & Earth Informat Sci, Hong Kong, Peoples R China.
EM Pengwang-B614080003@hotmail.com; zyq010227@163.com; wangliguo@hrbeu.edu.cn; reizhg@tongji.edu.cn; leungh@ucalgary.ca
FU Natural Science Foundation of Jiangsu Province [BK20221478]; Hong Kong Scholars Program [XJ2022043]; National Natural Science Foundation of China [61801211]; Key Laboratory of Land Satellite Remote Sensing Application, Ministry of Natural Resources of China [KLSMNR-G202201]; Foundation of Anhui Province Key Laboratory of Physical Geographic Environment, China [2022PGE010]; Program of Remote Sensing Intelligent Monitoring and Emergency Services for Regional Security Elements; Nanjing University of Aeronautics and Astronautics through the Graduate Education and Teaching Reform Research Project [2021YJXGG11]; Nanjing University of Aeronautics and Astronautics [SYJS202203Y]
CR Atkinson P. M., 1997, INNOVATIONS GIS, V4, P166
   Atkinson PM, 2005, PHOTOGRAMM ENG REM S, V71, P839, DOI 10.14358/PERS.71.7.839
   Foody GM, 2003, REMOTE SENS ENVIRON, V88, P283, DOI 10.1016/j.rse.2003.08.004
   Foody GM, 2003, REMOTE SENS ENVIRON, V85, P463, DOI 10.1016/S0034-4257(03)00039-7
   Fotheringham AS, 1998, ENVIRON PLANN A, V30, P1905, DOI 10.1068/a301905
   Hao QB, 2021, IEEE T INSTRUM MEAS, V70, P0, DOI 10.1109/TIM.2021.3117634
   Hao SY, 2021, IEEE T GEOSCI REMOTE, V59, P2448, DOI 10.1109/TGRS.2020.3005623
   Hao SY, 2018, IEEE T GEOSCI REMOTE, V56, P4650, DOI 10.1109/TGRS.2018.2832228
   He D, 2021, IEEE T GEOSCI REMOTE, V59, P9518, DOI 10.1109/TGRS.2020.3032475
   He D, 2021, IEEE T GEOSCI REMOTE, V59, P10628, DOI 10.1109/TGRS.2021.3050824
   He D, 2020, IEEE T GEOSCI REMOTE, V58, P1696, DOI 10.1109/TGRS.2019.2947708
   He D, 2019, IEEE T GEOSCI REMOTE, V57, P2198, DOI 10.1109/TGRS.2018.2872081
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Jin HR, 2012, INT J REMOTE SENS, V33, P7747, DOI 10.1080/01431161.2012.702234
   Li XD, 2014, IEEE GEOSCI REMOTE S, V11, P1265, DOI 10.1109/LGRS.2013.2291778
   Ling F, 2019, REMOTE SENS LETT, V10, P598, DOI 10.1080/2150704X.2019.1587196
   Ling F, 2014, IEEE J-STARS, V7, P1816, DOI 10.1109/JSTARS.2014.2320256
   Ling F, 2013, INT J REMOTE SENS, V34, P341, DOI 10.1080/01431161.2012.705441
   Pena FL, 2010, IEEE T INSTRUM MEAS, V59, P1834, DOI 10.1109/TIM.2009.2030918
   Lu LZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040360
   Mei SH, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3058321
   Mei SH, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3102034
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Nguyen MQ, 2005, IEEE GEOSCI REMOTE S, V2, P366, DOI 10.1109/LGRS.2005.851551
   Nguyen QM, 2011, INT J REMOTE SENS, V32, P6149, DOI 10.1080/01431161.2010.507797
   Song M, 2020, IEEE T GEOSCI REMOTE, V58, P8176, DOI 10.1109/TGRS.2020.2987910
   Sun WW, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3146296
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   Wang LG, 2013, IEEE GEOSCI REMOTE S, V10, P1592, DOI 10.1109/LGRS.2013.2262371
   Wang P., 2022, IEEE GEOSCI REMOTE S, V19, P0
   Wang P, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3131477
   Wang P, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3072943
   Wang P, 2021, IEEE T GEOSCI REMOTE, V59, P2256, DOI 10.1109/TGRS.2020.3004353
   Wang P, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222695
   Wang P, 2019, IEEE GEOSCI REMOTE S, V16, P1284, DOI 10.1109/LGRS.2019.2895629
   Wang P, 2019, IEEE J-STARS, V12, P1835, DOI 10.1109/JSTARS.2019.2910539
   Wang P, 2019, IEEE GEOSCI REMOTE S, V16, P771, DOI 10.1109/LGRS.2018.2882516
   Wang P, 2019, IEEE J-STARS, V12, P334, DOI 10.1109/JSTARS.2018.2885793
   Wang P, 2016, IEEE GEOSCI REMOTE S, V13, P1851, DOI 10.1109/LGRS.2016.2614810
   Wang QM, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112054
   Wang QM, 2020, REMOTE SENS ENVIRON, V244, P0, DOI 10.1016/j.rse.2020.111817
   Wang QM, 2020, IEEE T GEOSCI REMOTE, V58, P45, DOI 10.1109/TGRS.2019.2930764
   Wang QM, 2016, IEEE T GEOSCI REMOTE, V54, P5397, DOI 10.1109/TGRS.2016.2562178
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P309, DOI 10.1109/TGRS.2014.2321834
   Wang QM, 2014, ISPRS J PHOTOGRAMM, V92, P1, DOI 10.1016/j.isprsjprs.2014.02.012
   Wang QM, 2014, IEEE T GEOSCI REMOTE, V52, P2940, DOI 10.1109/TGRS.2013.2267802
   Zhang YH, 2017, IEEE T GEOSCI REMOTE, V55, P600, DOI 10.1109/TGRS.2016.2613140
   Zhang YQ, 2021, IEEE T INSTRUM MEAS, V70, P0, DOI 10.1109/TIM.2020.3011777
NR 49
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PD JUN 15
PY 2023
VL 72
IS 
BP 
EP 
DI 10.1109/TIM.2023.3236318
PG 16
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Engineering; Instruments & Instrumentation
GA 8K1RE
UT WOS:000922884900009
DA 2023-04-26
ER

PT J
AU Keskin, M
   Kettunen, P
AF Keskin, Merve
   Kettunen, Pyry
TI Potential of eye-tracking for interactive geovisual exploration aided by machine learning
SO INTERNATIONAL JOURNAL OF CARTOGRAPHY
LA English
DT Article; Early Access
DE Geovisualization; geoexploration; eye tracking; machine learning; interaction
ID convolutional neural-network; individual-differences; visual analytics; classification; visualization; efficiency; maps
AB ABSTRAITECet article de synthese recueille des connaissances sur l'utilisation de methodes de suivi oculaire et d'apprentissage automatique appliquees a des systemes de geovisualisation automatises et interactifs. Nous nous concentrons sur la lecture exploratoire de geovisualisation (abrege en geoexploration) et sur les outils d'apprentissage automatique pour l'exploration de donnees geospatiales vectorielles. Nous examinons particulierement les donnees geospatiales non etiquetees, sujettes a confusion ou inconnues de l'utilisateur. La contribution de cet article est dans 1) la definition de principes et de besoins pour permettre l'interaction de l'utilisateur avec les outils de geovisualisation qui apprennent de l'utilisateur et s'adaptent a son comportement 2) l'analyse de l'utilisation de methodes de suivi oculaire et d'apprentissage pour la conception de systemes de cartes interactives sensibles au regard (GAIMS). Dans ce contexte, nous examinons la litterature sur 1) la conception des interfaces homme-machine (HCI) pour l'exploration de donnees geospatiales 2) l'utilisation du suivi oculaire pour des experiences cartographiques, et 3) l'apprentissage applique aux donnees geospatiales vectorielles. L'etat de l'art montre que la combinaison du suivi oculaire et de l'apprentissage est prometteuse pour assister la geoexploration. Il manque cependant des recherches sur le suivi oculaire pour les interactions et la personnalisation des interfaces cartographiques ainsi que sur l'apprentissage automatique pour la detection de geometries vectorielles.
C1 [Keskin, Merve; Kettunen, Pyry] NLS, Finnish Geospatial Res Inst FGI, Espoo, Finland.
RP Keskin, M (corresponding author), NLS, Finnish Geospatial Res Inst FGI, Espoo, Finland.
EM merve.keskin@nls.fi
FU Finnish Scientific Advisory Board for Defence (MATINE) through the TUGEVA project
CR AGARWAL P, 2008, SELF ORG MAPS APPL G, V0, P0
   Allen G. L, 2020, APPL SPATIAL COGNITI, V0, P0
   Andrienko GL, 1999, INT J GEOGR INF SCI, V13, P355, DOI 10.1080/136588199241247
   Andrienko N, 2022, IEEE COMPUT GRAPH, V42, P123, DOI 10.1109/MCG.2021.3130314
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Basole RC, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2937475
   Bertin J., 1967, SEMIOLOGY GRAPHICS, V0, P0
   Bloom B. S., 1956, HDB 1 COGNITIVE DOMA, V0, P0
   Bruna J, 2014, ARXIV, V0, P0
   Choi D, 2016, UBICOMP16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, V0, PP1170, DOI 10.1145/2971648.2971694
   Coltekin A, 2010, INT J GEOGR INF SCI, V24, P1559, DOI 10.1080/13658816.2010.511718
   Coltekin A., 2017, INT J CARTOGRAPHY, V3, P115, DOI 10.1080/23729333.2017.1302910
   Coltekin A., 2018, GEOGRAPHIC INFORM SC, V0, P0, DOI DOI 10.22224/gistbok/2018.2.6
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Duchowski A. T., 2017, EYE TRACKING METHODO, V3rd, P0
   Eidelman S., 2009, SOCIAL PSYCHOL BASES, V0, PP85, DOI 10.1093/ACPROF:OSO/9780195320916.001.0001
   Fabrikant SI, 2010, ANN ASSOC AM GEOGR, V100, P13, DOI 10.1080/00045600903362378
   Feiyu Xu, 2019, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 8TH CCF INTERNATIONAL CONFERENCE, V0, P0
   Flink H.-M., 2011, LECT NOTES GEOINFORM, V1, P239
   Fuchs R, 2009, IEEE T VIS COMPUT GR, V15, P1327, DOI 10.1109/TVCG.2009.199
   Gao S., 2021, GEOSPATIAL ARTIFICIA, V0, P0
   Garlandini S, 2009, LECT NOTES COMPUT SC, V5756, P195, DOI 10.1007/978-3-642-03832-7_12
   Gobel F., 2021, THESIS ETH ZURICH, V0, P0, DOI DOI 10.3929/ethz-b-000513243
   Gobel F, 2019, GEOINFORMATICA, V23, P663, DOI 10.1007/s10707-019-00344-3
   Gobel F, 2020, ETRA20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, V0, P0, DOI DOI 10.1145/3379155.3391323
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Han J, 2012, MOR KAUF D, V0, P1
   Haunert JH, 2008, GEOINFORMATICA, V12, P169, DOI 10.1007/s10707-007-0028-x
   He ST, 2020, AAAI CONF ARTIF INTE, V34, P10965
   Hegarty M, 2006, INTELLIGENCE, V34, P151, DOI 10.1016/j.intell.2005.09.005
   Heinzle F., 2007, GEN GEOGRAPHIC INFOR, V0, PP233, DOI 10.1016/B978-008045374-3/50014-4
   Heinzle F., 2007, JOINT WORKSH VIS EXP, V0, P0
   Henaff M, 2015, ARXIV, V0, P0
   Hewitson B. C., 2008, SELF ORG MAPS APPL G, V0, P137
   Holmqvist K., 2011, EYE TRACKING COMPREH, V0, P0
   Hu S, 2021, COMPUT ENVIRON URBAN, V87, P0, DOI 10.1016/j.compenvurbsys.2021.101619
   Idreos S, 2015, SIGMOD15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, V0, PP277, DOI 10.1145/2723372.2731084
   Jacob R. J. K., 1990, SIGCHI BULLETIN, V0, P11
   Jakel F, 2016, VISION RES, V126, P3, DOI 10.1016/j.visres.2016.06.004
   Janowicz K, 2020, INT J GEOGR INF SCI, V34, P625, DOI 10.1080/13658816.2019.1684500
   Jokinen Jussi., 2021, P 2021 CHI C HUM FAC, V0, PP1, DOI 10.1145/3411764.3445483
   KAHNEMAN D, 1991, J ECON PERSPECT, V5, P193, DOI 10.1257/jep.5.1.193
   Keskin M., 2021, ABSTRACTS ICA, V3, P1, DOI https://doi.org/10.5194/ica-abs-3-148-2021
   Keskin M, 2018, J EYE MOVEMENT RES, V11, P0, DOI 10.16910/jemr.11.3.4
   Kettunen P, 2014, ANALYSING LANDMARKS, V0, P0
   Kettunen P, 2019, CARTOGR GEOGR INF SC, V46, P489, DOI 10.1080/15230406.2018.1553113
   Kiefer P, 2017, SPAT COGN COMPUT, V17, P1, DOI 10.1080/13875868.2016.1254634
   Knapp L., 1995, COGNITIVE ASPECTS HU, V0, PP355, DOI 10.1007/978-94-011-0103-5_25
   Koua Etien L, 2004, INT J HEALTH GEOGR, V3, P12, DOI 10.1186/1476-072X-3-12
   Kulhavy RW, 1996, ANN ASSOC AM GEOGR, V86, P123, DOI 10.1111/j.1467-8306.1996.tb01748.x
   Kumar B, 2019, ISPRS J PHOTOGRAMM, V147, P80, DOI 10.1016/j.isprsjprs.2018.11.006
   Kwok TCK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290605.3300721
   LeCun, 1989, ADV NEURAL INFORM PR, V2, P0, DOI 10.5555/2969830.2969879
   Leonard TC, 2008, CONST POLITICAL ECON, V19, P356, DOI 10.1007/s10602-008-9056-2
   Ma LF, 2021, IEEE T INTELL TRANSP, V22, P821, DOI 10.1109/TITS.2019.2961060
   MacEachren A.M., 1992, CARTOGRAPHIC PERSPEC, V13, P10, DOI 10.14714/CP13.1000
   Maceachren AM, 1997, COMPUT GEOSCI, V23, P335, DOI 10.1016/S0098-3004(97)00018-6
   Meng L., 2005, MAP BASED MOBILE SER, V0, PP1, DOI 10.1007/3-540-26982-7_1
   Meng L., 2005, MAP BASED MOBILE SER, V0, P87
   Miura K., 2016, J ARCHITECTURE PLANN, V81, P959, DOI https://doi.org/10.3130/aija.81.959
   Montello DR, 2005, RESEARCH AGENDA FOR GEOGRAPHIC INFORMATION SCIENCE, V0, P61
   MORRISON J. L., 1974, INT YB CARTOGRAPHY, V14, P115
   Kipf TN, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1609.02907
   Nivala AM, 2008, CARTOGR J, V45, P129, DOI 10.1179/174327708X305120
   Norman D. A, 1986, AM J PSYCHOL, V0, P0
   OShea K, 2015, ARXIV, V0, P0
   Ooms K., 2012, DISSERTATION, V0, P0
   Ooms K, 2015, CARTOGR J, V52, P3, DOI 10.1179/1743277413Y.0000000068
   Palka G., 2018, INT J CARTOGRAPHY, V4, P25, DOI https://doi.org/10.1080/23729333.2018.1434603
   Pope PE, 2019, PROC CVPR IEEE, V0, PP10764, DOI 10.1109/CVPR.2019.01103
   Putto K, 2014, CARTOGR J, V51, P225, DOI 10.1179/1743277414Y.0000000087
   Raubal M, 2009, GEOGR COMPASS, V3, P1087, DOI 10.1111/j.1749-8198.2009.00224.x
   Richter K.-F., 2015, ARE WE THERE YET SPA, V0, P0, DOI DOI 10.5167/UZH-118002
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Roth R. E., 2017, INT ENCY GEOGRAPHY P, V0, PP1, DOI 10.1002/9781118786352.WBIEG0761
   Rudi D, 2020, J MULTIMODAL USER IN, V14, P25, DOI 10.1007/s12193-019-00309-8
   Samuelson W., 1988, J RISK UNCERTAINTY, V1, P7, DOI 10.1007/BF00055564
   Sen A, 2014, CARTOGR GEOGR INF SC, V41, P151, DOI 10.1080/15230406.2013.877231
   Sester M., 2008, SELF ORG MAPS APPL G, V0, P107
   Shneiderman B., 2002, INFORMATION VISUALIZATION, V1, P5, DOI 10.1057/palgrave/ivs/9500006
   Skupin A., 2008, SELF ORG MAPS APPL G, V0, PP1, DOI 10.1002/9780470021699.CH1
   Slocum T. A., 2001, CARTOGR GEOGR INF SC, V28, P61, DOI 10.1559/152304001782173998
   THORNDYKE PW, 1980, COGNITIVE PSYCHOL, V12, P137, DOI 10.1016/0010-0285(80)90006-7
   van Otterlo M, 2012, ADAPT LEARN OPTIM, V12, P3
   van t Veer R, 2019, ARXIV, V0, P0
   Vidal M, 2013, UBICOMP13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, V0, PP439, DOI 10.1145/2493432.2493477
   Wardlaw J., 2010, INTERACTING GEOSPATI, V0, PP179, DOI 10.1002/9780470689813.CH9
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Yan J., 2008, SELF ORG MAPS, V0, P67
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Zhang XD, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3072627
NR 93
TC 0
Z9 0
U1 1
U2 1
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2372-9333
EI 2372-9341
J9 INT J CARTOGRAPHY
JI Int. J. Cartogr.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1080/23729333.2022.2150379
PG 23
WC Computer Science, Information Systems; Geography; Geography, Physical; Remote Sensing
SC Computer Science; Geography; Physical Geography; Remote Sensing
GA 7U2LI
UT WOS:000911965800001
DA 2023-04-26
ER

PT J
AU Sundarasekar, R
   Appathurai, A
AF Sundarasekar, Revathi
   Appathurai, Ahilan
TI FMTM-feature-map-based transform model for brain image segmentation in tumor detection
SO NETWORK-COMPUTATION IN NEURAL SYSTEMS
LA English
DT Article
DE Feature map; image segmentation; transform model; unsupervised learning
ID neural-network; hybrid
AB The segmentation of brain images is a leading quantitative measure for detecting physiological changes and for analysing structural functions. Based on trends and dimensions of brain, the images indicate heterogeneity. Accurate brain tumour segmentation remains a critical challenge despite the persistent efforts of researchers were owing to a variety of obstacles. This impacts the outcome of tumour detection, causing errors. For addressing this issue, a Feature-Map based Transform Model (FMTM) is introduced to focus on heterogeneous features of input picture to map differences and intensity based on transition Fourier. Unchecked machine learning is used for reliable characteristic map recognition in this mapping process. For the determination of severity and variability, the method of identification depends on symmetry and texture. Learning instances are taught to improve precision using predefined data sets, regardless of loss of labels. The process is recurring until the maximum precision of tumour detection is achieved in low convergence. In this research, FMTM has been applied to brain tumour segmentation to automatically extract feature representations and produce accurate and steady performance because of promising performance made by powerful transition Fourier methods. The suggested model's performance is shown by the metrics processing time, precision, accuracy, and F1-Score.
C1 [Sundarasekar, Revathi; Appathurai, Ahilan] PSN Coll Engn & Technol, Tirunelveli, India.
   [Sundarasekar, Revathi] Anna Univ, Informat & Commun Engn, Chennai, India.
C3 Anna University; Anna University Chennai
RP Sundarasekar, R (corresponding author), Anna Univ, Informat & Commun Engn, Chennai, India.
EM revathisundarasekar@ieee.org
CR Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Bennai MT, 2020, ARTIF INTELL MED, V110, P0, DOI 10.1016/j.artmed.2020.101980
   Carvalho LE, 2018, J DIGIT IMAGING, V31, P799, DOI 10.1007/s10278-018-0101-z
   Chao Z, 2020, J SIGNAL PROCESS SYS, V92, P289, DOI 10.1007/s11265-019-01497-y
   Daimary D, 2020, PROCEDIA COMPUT SCI, V167, P2419, DOI 10.1016/j.procs.2020.03.295
   Deng W, 2020, IEEE ACCESS, V8, P26665, DOI 10.1109/ACCESS.2020.2966879
   Ding Y, 2019, IEEE ACCESS, V7, P104011, DOI 10.1109/ACCESS.2019.2926448
   Dolz J, 2020, COMPUT MED IMAG GRAP, V79, P0, DOI 10.1016/j.compmedimag.2019.101660
   Ghosal P, 2021, COMPUT METH PROG BIO, V200, P0, DOI 10.1016/j.cmpb.2020.105841
   Gonzalez-Villa S, 2020, NEUROIMAGE-CLIN, V27, P0, DOI 10.1016/j.nicl.2020.102306
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Huang H, 2019, IEEE ACCESS, V7, P12386, DOI 10.1109/ACCESS.2019.2893063
   Khorram B, 2019, J DIGIT IMAGING, V32, P162, DOI 10.1007/s10278-018-0111-x
   Lei XL, 2021, EXPERT SYST APPL, V168, P0, DOI 10.1016/j.eswa.2020.114262
   Li HC, 2019, COMPUT BIOL MED, V108, P150, DOI 10.1016/j.compbiomed.2019.03.014
   Liu D, 2019, IEEE ACCESS, V7, P14736, DOI 10.1109/ACCESS.2019.2893275
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Nie D, 2019, IEEE T CYBERNETICS, V49, P1123, DOI 10.1109/TCYB.2018.2797905
   Qamar S, 2020, FUTURE GENER COMP SY, V108, P613, DOI 10.1016/j.future.2019.11.021
   Sangawi AWK, 2021, B MALAYS MATH SCI SO, V44, P171, DOI 10.1007/s40840-020-00942-7
   Sert E, 2019, MED HYPOTHESES, V133, P0, DOI 10.1016/j.mehy.2019.109413
   Sun JW, 2019, J MED SYST, V43, P0, DOI 10.1007/s10916-019-1358-6
   Sun L, 2020, IEEE T MED IMAGING, V39, P2000, DOI 10.1109/TMI.2019.2962792
   Sun LY, 2020, IEEE T MED IMAGING, V39, P898, DOI 10.1109/TMI.2019.2937271
   Pham TX, 2019, MAGN RESON IMAGING, V61, P41, DOI 10.1016/j.mri.2019.05.009
   Tong JJ, 2018, FRONT INFORM TECH EL, V19, P471, DOI 10.1631/FITEE.1620342
   Ural B, 2018, J MED BIOL ENG, V38, P867, DOI 10.1007/s40846-017-0353-y
   Wang LS, 2019, IEEE ACCESS, V7, P39670, DOI 10.1109/ACCESS.2019.2906890
   Xu XF, 2020, NEUROINFORMATICS, V18, P181, DOI 10.1007/s12021-019-09432-z
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 30
TC 0
Z9 0
U1 1
U2 1
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0954-898X
EI 1361-6536
J9 NETWORK-COMP NEURAL
JI Netw.-Comput. Neural Syst.
PD APR 3
PY 2023
VL 34
IS 1-2
BP 1
EP 25
DI 10.1080/0954898X.2022.2110620
EA DEC 2022
PG 25
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Neurosciences
SC Computer Science; Engineering; Neurosciences & Neurology
GA 9Y1NU
UT WOS:000897201600001
PM 36514820
DA 2023-04-26
ER

PT J
AU Yu, SM
   Xu, HD
   Wu, C
   Jiang, X
   Sun, RC
   Sun, LN
AF Yu, Shumei
   Xu, Haidong
   Wu, Chong
   Jiang, Xin
   Sun, Rongchuan
   Sun, Lining
TI Bionic Path Planning Fusing Episodic Memory Based on RatSLAM
SO BIOMIMETICS
LA English
DT Article
DE bionic path planning; RatSLAM; episodic cognitive map; connectivity networks
AB Inspired by rodents' ability to navigate freely in a given space, bionavigation systems provide alternatives to traditional probabilistic solutions. This paper proposed a bionic path planning method based on RatSLAM to provide a novel viewpoint for robots to make a more flexible and intelligent navigation scheme. A neural network fusing historic episodic memory was proposed to improve the connectivity of the episodic cognitive map. It is biomimetically important to generate an episodic cognitive map and establish a one-to-one correspondence between the events generated by episodic memory and the visual template of RatSLAM. The episodic cognitive map can be improved by imitating the rodents' behavior of memory fusion to produce better path planning results. The experimental results of different scenarios illustrate that the proposed method identified the connectivity between way points, optimized the result of path planning, and improved the flexibility of the system.
C1 [Yu, Shumei; Xu, Haidong; Wu, Chong; Sun, Rongchuan; Sun, Lining] Soochow Univ, Sch Mech & Elect Engn, Suzhou 215137, Peoples R China.
   [Jiang, Xin] Harbin Inst Technol Shenzhen, Sch Mech Engn & Automat, Shenzhen 518055, Peoples R China.
C3 Soochow University - China; Harbin Institute of Technology
RP Sun, RC (corresponding author), Soochow Univ, Sch Mech & Elect Engn, Suzhou 215137, Peoples R China.; Jiang, X (corresponding author), Harbin Inst Technol Shenzhen, Sch Mech Engn & Automat, Shenzhen 518055, Peoples R China.
EM x.jiang@ieee.org; sunrongchuan@suda.edu.cn
FU National Natural Science Foundation of China [61673288, U1813202]; Joint Fund of Science & Technology Department of Liaoning Province; State Key Laboratory of Robotics of China [2020-KF-22-13]
CR Akyol E, 2016, IEEE T COMMUN, V64, P1220, DOI 10.1109/TCOMM.2016.2523516
   Arbib MA, 2020, BIOL CYBERN, V114, P139, DOI 10.1007/s00422-020-00829-7
   Bangyal WH, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11167591
   Bangyal WH, 2020, INT J BIO-INSPIR COM, V15, P1
   Cakir E, 2021, IFAC PAPERSONLINE, V54, P348, DOI 10.1016/j.ifacol.2021.06.048
   Chen J., 2017, ACTA TECH CSAV, V62, P219
   Dubey A.D., 2013, INT J ADV ENG TECHNO, V6, P780
   Ferguson D, 2006, J FIELD ROBOT, V23, P79, DOI 10.1002/rob.20109
   Healy MJ, 2019, NEURAL NETWORKS, V120, P40, DOI 10.1016/j.neunet.2019.09.021
   Ji C., 2014, P 2014 IEEE INT C IN, V0, P0
   Kala R, 2010, ARTIF INTELL REV, V33, P307, DOI 10.1007/s10462-010-9157-y
   Khan AT, 2022, BIOMIMETICS-BASEL, V7, P0, DOI 10.3390/biomimetics7030124
   Krause JB, 2000, NEURAL NETWORKS, V13, P847, DOI 10.1016/S0893-6080(00)00068-X
   Liu D, 2017, INT J ADV ROBOT SYST, V14, P0, DOI 10.1177/1729881417705922
   Luo X, 2012, J BIONIC ENG, V9, P143, DOI 10.1016/S1672-6529(11)60110-8
   Martins OO, 2021, GAZI U J SCI, V34, P765, DOI 10.35378/gujs.792682
   Milford M.J., 2004, P EEE INT C ROB AUT, V0, P0
   Milford MJ, 2008, IEEE T ROBOT, V24, P1038, DOI 10.1109/TRO.2008.2004520
   Min HS, 2015, ADV MECH ENG, V7, P0, DOI 10.1177/1687814015619276
   Mohan V, 2014, NEURAL COMPUT, V26, P2692, DOI 10.1162/NECO_a_00664
   Moll M, 1997, NEURAL NETWORKS, V10, P1017, DOI 10.1016/S0893-6080(97)00016-6
   Nasir J, 2019, AUTON ROBOT, V43, P2163, DOI 10.1007/s10514-019-09868-x
   Nemoto I, 2002, NEURAL NETWORKS, V15, P833, DOI 10.1016/S0893-6080(02)00066-7
   OKeefe J., 1979, SCIENCE, V204, P762
   Pshikhopov V, 2017, PATH PLANNING FOR VEHICLES OPERATING IN UNCERTAIN 2D ENVIRONMENTS, V0, P1
   Qi GP, 2008, J BIONIC ENG, V5, P197, DOI 10.1016/S1672-6529(08)60025-6
   Reverberi S, 2020, NEUROPSYCHOLOGIA, V143, P0, DOI 10.1016/j.neuropsychologia.2020.107491
   Shi YT, 2017, LECT NOTES ARTIF INT, V10363, P274, DOI 10.1007/978-3-319-63315-2_24
   Tang HJ, 2017, NEURAL NETWORKS, V87, P27, DOI 10.1016/j.neunet.2016.08.015
   TULVING E, 1973, PSYCHOL REV, V80, P352, DOI 10.1037/h0020071
   Tulving E, 2002, ANNU REV PSYCHOL, V53, P1, DOI 10.1146/annurev.psych.53.100901.135114
   TULVING E, 1974, J EXP PSYCHOL, V102, P778, DOI 10.1037/h0036383
   Tulving E., 1972, ORG MEMORY, V0, P381
   Vu N., 2019, INT CONF MACH LEARN, V8, P12, DOI 10.18178/ijmerr.8.1.12-17
   Wang YF, 2020, BIOMIMETICS-BASEL, V5, P0, DOI 10.3390/biomimetics5020026
   Wilson RC, 2014, NEURON, V81, P267, DOI 10.1016/j.neuron.2013.11.005
   Wu J., 2021, P 2021 36 YOUTH AC A, V0, P0
   [于乃功 Yu Naigong], 2018, 自动化学报 ACTA AUTOMATICA SINICA, V44, P52
   [邹强 Zou Qiang], 2018, 机器人 ROBOT, V40, P894
NR 39
TC 0
Z9 0
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2313-7673
J9 BIOMIMETICS-BASEL
JI Biomimetics
PD MAR 15
PY 2023
VL 8
IS 1
BP 
EP 
DI 10.3390/biomimetics8010059
PG 18
WC Engineering, Multidisciplinary; Materials Science, Biomaterials
SC Engineering; Materials Science
GA A3LQ2
UT WOS:000954184700001
PM 36810390
DA 2023-04-26
ER
