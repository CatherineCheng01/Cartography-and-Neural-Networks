
PT J
AU Kim, GB
   Son, YC
   Hwang, CI
AF Kim, Gyoo-Bum
   Son, Young-Chul
   Hwang, Chan-Ik
TI Determination of new national groundwater monitoring sites using artificial neural network model in South Korea
SO GEOSCIENCES JOURNAL
LA English
DT Article
DE groundwater monitoring; linear trend analysis; artificial neural network; geographic information systems
AB South Koreas National Groundwater Monitoring Network (NGMN) was installed during the early 1990s to detect the trends in groundwater levels; however, a revised NGMN plan is required in consideration of climate change and human activities. Linear trend analyses of the groundwater levels, Cl concentration, and NO3-N concentration of 521 monitoring wells were conducted to define the downward and upward trends. The attributes of 14 items relating to topography, stream proximity, land use, soil, hydrogeology, and well density were extracted from thematic maps for each monitoring site. An artificial neural network (ANN) model for groundwater level trends was developed using these 14 input variables to predict the downward (output variable: 1) and non-downward (output variable: 0) trends at any grid point in a standard watershed. Candidate sites for new groundwater monitoring wells were suggested based on the probability of the existence of two trends for groundwater levels. Candidate sites were excluded if they showed upward trends of Cl and NO3-N because the primary objective of the NGMN was not to observe changes in water quality but to observe the background conditions of water quality. It was proposed to install a total of 1475 groundwater monitoring wells (existing plus new wells) by 2045, and the percentage contributions of non-downward and downward trends of groundwater levels to the total number of trends (i.e., wells) were projected to be 61.5% and 38.5%, respectively. The NGMN will play an important role in recognizing climate change, observing groundwater level declines caused by human activities, and assessing the relationship between surface water and groundwater in standard watersheds.
C1 [Kim, Gyoo-Bum] Daejeon Univ, Dept Construct Safety & Disaster Prevent, Daejeon 34520, South Korea.
   [Son, Young-Chul] K Water, Daejeon 34045, South Korea.
   [Hwang, Chan-Ik] Daejeon Univ, Ind Acad Cooperat Fdn, Daejeon 34520, South Korea.
C3 Daejeon University; Daejeon University
RP Kim, GB (corresponding author), Daejeon Univ, Dept Construct Safety & Disaster Prevent, Daejeon 34520, South Korea.
EM geowater@dju.kr
FU National Research Foundation of Korea; Ministry of Science and ICT [NRF-2019R1A2C1088085]
CR Asefa T, 2004, WATER RESOUR RES, V40, P0, DOI 10.1029/2004WR003304
   Barthel R, 2016, WATER RESOUR MANAG, V30, P1, DOI 10.1007/s11269-015-1163-z
   Bhat S, 2015, ENVIRON MONIT ASSESS, V187, P0, DOI 10.1007/s10661-014-4183-x
   Condon LE, 2015, WATER RESOUR RES, V51, P6602, DOI 10.1002/2014WR016774
   Heath R. C., 1983, BASIC GROUND WATER H, V0, P0, DOI DOI 10.3133/wsp2220
   Hosseini M, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-6129-6
   IGRAC, 2020, NAT GROUNDW MON PROG, V0, P0
   Jousma G., 2004, 20041 IGRAC GP, V0, P0
   Kavusi M, 2020, WATER RESOUR MANAG, V34, P2503, DOI 10.1007/s11269-020-02568-7
   Kim G, 2010, WATER RESOUR MANAG, V24, P4009, DOI 10.1007/s11269-010-9644-6
   Kim SG, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11040753
   Lee JY, 2007, HYDROL PROCESS, V21, P907, DOI 10.1002/hyp.6282
   Lee JY, 2016, WATER-SUI, V8, P0, DOI 10.3390/w8040168
   Marklund L., 2009, TOPOGRAPHICAL CONTRO, V0, P0
   Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118
   MOE, 2020, KOR CLIM CHANG ASS R, V0, P0
   MOE, 2020, ANN REP GROUNDW KOR, V0, P0
   Peck M.F., 2003, P 2003 GEORG WAT RES, V0, P871
   Saltelli A., 2004, SENSITIVITY ANAL PRA, V0, P0
   The Subcommittee on Ground Water of the Advisory Committee on Water Information, 2013, NAT FRAM GROUND WAT, V0, P0
   US EPA, 2015, PROUCL VERS 5 1 002, V0, P0
NR 21
TC 2
Z9 2
U1 2
U2 4
PU GEOLOGICAL SOCIETY KOREA
PI SEOUL
PA NEW BLD RM 813, 22, TEHERAN-RO 7-GIL, SEOUL, 06130, SOUTH KOREA
SN 1226-4806
EI 1598-7477
J9 GEOSCI J
JI Geosci. J.
PD AUG 15
PY 2022
VL 26
IS 4
BP 513
EP 528
DI 10.1007/s12303-021-0044-0
EA MAR 2022
PG 16
WC Geosciences, Multidisciplinary
SC Geology
GA 2R3NB
UT WOS:000771336700001
DA 2023-04-26
ER

PT J
AU Aljaloud, S
   Alshudukhi, J
   Alhamazani, KT
   Belay, A
AF Aljaloud, Saud
   Alshudukhi, Jalawi
   Alhamazani, Khalid Twarish
   Belay, Assaye
TI Comparative Study of Artificial Intelligence Techniques for the Diagnosis of Chronic Nerve Diseases
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
AB Farming is essential to the long-term viability of any economy. It differs in each country, but it is essential for long-term economic success. Only a few of the agricultural industry's issues include a lack of suitable irrigation systems, weeds, and plant monitoring concerns as a consequence of efficient management in distinct open and closed zones for crop and plant treatment. The objective of this work is to carry out a study on the use of artificial intelligence and computer vision methods for diagnosis of diseases in agro sectors in the context of agribusiness, demonstrating the feasibility of using these techniques as tools to support automation and obtain productivity gains in this sector. During the literary analysis, it was determined that technology could improve efficiency, hence decreasing these types of concerns. Given the consequences of a wrong diagnosis, diagnosis is work that requires a high level of precision. Fuzzy cognitive maps were shown to be the most efficient method of utilizing bibliographically reviewed preferences, which led to the consideration of neural networks as a second option because this technique is the most robust in terms of the qualifying criteria of the data stored in databases.
C1 [Aljaloud, Saud; Alshudukhi, Jalawi; Alhamazani, Khalid Twarish] Univ Hail, Dept Comp Sci, Coll Comp Sci & Engn, Hail, Saudi Arabia.
   [Belay, Assaye] Mizan Tepi Univ, Dept Stat, Tepi, Ethiopia.
C3 University Ha'il
RP Belay, A (corresponding author), Mizan Tepi Univ, Dept Stat, Tepi, Ethiopia.
EM s.aljaloud@uoh.edu.sa; j.alshudukhi@uoh.edu.sa; k.alhamazani@uoh.edu.sa; assaye@mtu.edu.et
CR Akinyokun O.C., 2014, ARTIFICIAL INTELLIGE, V4, P12, DOI 10.5430/air.v4n1p12
   Al-Rahawe BA, 2021, APPL BIONICS BIOMECH, V2021, P0, DOI 10.1155/2021/1526931
   Alazzam MB, 2021, MATH PROBL ENG, V2021, P0, DOI 10.1155/2021/6842071
   Alsaffar M, 2021, MOB INF SYST, V2021, P0, DOI 10.1155/2021/7424836
   Alsaffar M, 2021, COMPUT MATH METHOD M, V2021, P0, DOI 10.1155/2021/9102095
   Alshammari G, 2021, WIREL COMMUN MOB COM, V2021, P0, DOI 10.1155/2021/4672688
   Barbedo JGA, 2016, IEEE LAT AM T, V14, P1910, DOI 10.1109/TLA.2016.7483534
   BhargavRam K, 2019, JMM-INT J MEDIA MANA, V8, P1264
   Bhavsar KA, 2021, CMC-COMPUT MATER CON, V67, P107, DOI 10.32604/cmc.2021.014604
   Bourgani E, 2014, LECT NOTES ARTIF INT, V8445, P544, DOI 10.1007/978-3-319-07064-3_47
   Fatima M., 2017, J INTELL LEARN SYST, V9, P1, DOI 10.4236/JILSA.2017.91001
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Groumpos P.P., 2017, ROBOT AUTOM ENG J, V1, P1, DOI /10.19080/RAEJ.2017.01.555563
   Hamad AA, 2021, ADV MATER SCI ENG, V2021, P0, DOI 10.1155/2021/8148772
   Jha S, 2022, J APPL SCI ENG, V25, P285, DOI 10.6180/jase.202204_25(2).0014
   Khadidos A, 2021, APPL BIONICS BIOMECH, V2021, P0, DOI 10.1155/2021/4520450
   Sidhu K. S., 2021, ENVIRONMENT CONSERVATION JOURNAL, V22, P55, DOI 10.36953/ECJ.2021.SE.2206
   Sikchi S. S., 2013, FUZZY EXPERT SYSTEMS, V63, P7
   Stylios CD, 2000, J INTELL FUZZY SYST, V8, P83
   Tetila EC, 2020, IEEE GEOSCI REMOTE S, V17, P903, DOI 10.1109/LGRS.2019.2932385
   Wang LJ, 2022, J INTERCONNECT NETW, V22, P0, DOI 10.1142/S0219265921430052
   Win T.T., 2018, THESIS KOBE I COMPUT, V5, P20
NR 22
TC 0
Z9 0
U1 0
U2 1
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PD JAN 13
PY 2022
VL 2022
IS 
BP 
EP 
DI 10.1155/2022/3522510
PG 6
WC Mathematical & Computational Biology
SC Mathematical & Computational Biology
GA ZY9KP
UT WOS:000772898400010
PM 35069781
DA 2023-04-26
ER

PT J
AU Zhang, N
   Nex, F
   Kerle, N
   Vosselman, G
AF Zhang, Ning
   Nex, Francesco
   Kerle, Norman
   Vosselman, George
TI LISU: Low-light indoor scene understanding with joint learning of reflectance restoration
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Semantic segmentation; Deep learning; Intrinsic image decomposition; Low-light
ID inspection
AB Semantic segmentation using convolutional neural networks (CNNs) achieves higher accuracy than traditional methods, but it fails to yield satisfactory results under illumination variants when the training set is limited. In this paper we present a new data set containing both real and rendered images and a novel cascade network to study semantic segmentation in low-light indoor environments. Specifically, the network decomposes a low-light image into illumination and reflectance components, and then a multi-tasking learning scheme is built. One branch learns to reduce noise and restore information on the reflectance (reflectance restoration branch). Another branch learns to segment the reflectance map (semantic segmentation branch). The CNN features from two tasks are concatenated together so as to improve the segmentation accuracy by embedding the illumination invariant features. We compare our approach with other CNN-based segmentation frameworks, including the state-of-the-art DeepLab v3+, on the proposed real data set, and our approach achieves the highest mIoU (47.6%). The experimental results also show that the semantic information supports the restoration of a sharper reflectance map, thus further improving the segmentation. Besides, we pre-train a model with the proposed large-scale rendered images and then fine-tune it on the real images. The pre-training results in an improvement of mIoU by 7.2%. Our models and data set are publicly available for research. This research is part of the EU project INGENIOUS(1). Our data sets and models are available on our website(2).
C1 [Zhang, Ning; Nex, Francesco; Kerle, Norman; Vosselman, George] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
C3 University of Twente
RP Zhang, N (corresponding author), Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
EM n.zhang@utwente.nl; f.nex@utwente.nl; n.kerle@utwente.nl; george.vosselman@utwente.nl
FU European Unions Horizon 2020 Research and Innovation Programme; Korean Gov-ernment [833435]
CR Adachi Miho, 2019, 2019 15TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), V0, PP15, DOI 10.1109/SITIS.2019.00015
   Alshammari N, 2018, IEEE INT VEH SYM, V0, P1027
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baslamisli AS, 2018, LECT NOTES COMPUT SC, V11210, P289, DOI 10.1007/978-3-030-01231-1_18
   Chang A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P53
   Chen C, 2018, PROC CVPR IEEE, V0, PP3291, DOI 10.1109/CVPR.2018.00347
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng JC, 2017, IEEE I CONF COMP VIS, V0, PP686, DOI 10.1109/ICCV.2017.81
   Cheng YH, 2017, PROC CVPR IEEE, V0, PP1475, DOI 10.1109/CVPR.2017.161
   Cho SW, 2020, IEEE ACCESS, V8, P93561, DOI 10.1109/ACCESS.2020.2994969
   Couprie C., 2013, 1 INT C LEARNING REP, V0, P1
   Dai DX, 2018, IEEE INT C INTELL TR, V0, PP3819, DOI 10.1109/ITSC.2018.8569387
   Dai JF, 2016, PROC CVPR IEEE, V0, PP3150, DOI 10.1109/CVPR.2016.343
   Fan QN, 2018, PROC CVPR IEEE, V0, PP8944, DOI 10.1109/CVPR.2018.00932
   García Herrera Arístides Lázaro, 2017, REV.MED.ELECTRÓN., V0, P1
   Giernacki W, 2017, 2017 22ND INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), V0, PP37, DOI 10.1109/MMAR.2017.8046794
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Gupta S, 2020, COMPUT NETW, V178, P0, DOI 10.1016/j.comnet.2020.107374
   Handa A, 2016, PROC CVPR IEEE, V0, PP4077, DOI 10.1109/CVPR.2016.442
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Janner M, 2017, ADV NEUR IN, V30, P0
   Jiao JB, 2019, PROC CVPR IEEE, V0, PP2864, DOI 10.1109/CVPR.2019.00298
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kwon YS, 2008, IEEE INT CONF ROBOT, V0, PP3998, DOI 10.1109/ROBOT.2008.4543825
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lau HYK, 2007, LECT NOTES COMPUT SC, V4628, P191
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li FY, 2018, AUTOMAT CONSTR, V95, P275, DOI 10.1016/j.autcon.2018.07.025
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Liu YF, 2020, PROC CVPR IEEE, V0, PP3245, DOI 10.1109/CVPR42600.2020.00331
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu YC, 2018, GEO-SPAT INF SCI, V21, P21, DOI 10.1080/10095020.2017.1420509
   Maddern W., 2014, ICRA, V0, P0
   McCormac J, 2017, IEEE I CONF COMP VIS, V0, PP2697, DOI 10.1109/ICCV.2017.292
   Narihira T, 2015, IEEE I CONF COMP VIS, V0, PP2992, DOI 10.1109/ICCV.2015.342
   Neuhold G, 2017, IEEE I CONF COMP VIS, V0, PP5000, DOI 10.1109/ICCV.2017.534
   Ozaslan T, 2015, SPRINGER TRAC ADV RO, V105, P123, DOI 10.1007/978-3-319-07488-7_9
   Park SJ, 2017, IEEE I CONF COMP VIS, V0, PP4990, DOI 10.1109/ICCV.2017.533
   Pedersen S.A., 2013, THESIS I DATATEKNIKK, V0, P0
   Rematas K, 2016, PROC CVPR IEEE, V0, PP4508, DOI 10.1109/CVPR.2016.488
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother Carsten, 2011, NEURIPS, V0, P0
   Sakaridis C., 2019, ICCV, V0, P0
   Shen L, 2008, PROC CVPR IEEE, V0, P2479
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, V0, PP567, DOI 10.1109/CVPR.2015.7298655
   Sun L, 2019, PROC SPIE, V11169, P0, DOI 10.1117/12.2532477
   Tappen MF, 2005, IEEE T PATTERN ANAL, V27, P1459, DOI 10.1109/TPAMI.2005.185
   Upcroft B, 2014, IEEE INT CONF ROBOT, V0, PP1712, DOI 10.1109/ICRA.2014.6907082
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C., 2018, BRIT MACH VIS C, V0, P0
   Wu BC, 2018, IEEE INT CONF ROBOT, V0, P1887
   Xu C., 2019, SECURITY DEFENCE, V0, P0
   Zeng Y, 2019, IEEE I CONF COMP VIS, V0, PP7222, DOI 10.1109/ICCV.2019.00732
   Zhang Y., 2021, SURVEY MULTITASK LEA, V0, P0
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1632, DOI 10.1145/3343031.3350926
   Zhu A., 2020, ICME, V0, P0
   Zuo Y., 2017, C ROB LEARN, V78, P27
NR 60
TC 4
Z9 4
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN 15
PY 2022
VL 183
IS 
BP 470
EP 481
DI 10.1016/j.isprsjprs.2021.11.010
PG 12
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA 0M9BI
UT WOS:000782441900002
DA 2023-04-26
ER

PT J
AU Jafarzadeh, H
   Mahdianpari, M
   Gill, EW
AF Jafarzadeh, Hamid
   Mahdianpari, Masoud
   Gill, Eric W.
TI Wet-GC: A Novel Multimodel Graph Convolutional Approach for Wetland Classification Using Sentinel-1 and 2 Imagery With Limited Training Samples
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Wetlands; Optical sensors; Convolutional neural networks; Synthetic aperture radar; Satellites; Optical imaging; Adaptive optics; Canada; classification; convolutional neural network (CNN); deep learning (DL); graph convolutional network (GCN); remote sensing (RS); sentinel; wetlands
ID remote-sensing images; land-cover; spatial-resolution; scene classification; neural-networks; sar; vegetation; cnn
AB Wetland is one of the most productive resources on earth, and it provides vital habitats for several unique species of flora and fauna. Over the last decade, mapping and monitoring wetlands by utilizing deep learning (DL) models and remote sensing data gained popularity due to the importance of wetland preservation. In general, DL-based methods have shown astonishing achievement in wetland classification, but some practical issues, such as limited training samples, still need to be addressed. Moreover, the performance of most of the DL approaches is decreased when moderate-resolution images with few features are used as input data. One solution to breaking the performance bottleneck of a single model is to fuse two or more of them. To this end, we strive to investigate and develop a multimodel DL algorithm for wetland classification based on the combination of a graph convolutional network (GCN) and a shallow convolutional neural network (CNN), which is called the Wet-GC algorithm hereinafter. In doing this, moderate-resolution Sentinel-1 (S1) synthetic aperture radar (SAR) and Sentinel-2 (S2) multispectral optical imagery are fed into the GCN and CNN models, respectively. As we know from the literature, the synergistic use of S1 SAR and S2 optical imagery can be used to extract different types of wetland features and increase the class discrimination possibility. Hence, wetland mapping by jointly using GCN and CNN has the ability to boost the wetland classification task. Findings indicate that the efficiency of Wet-GC with an overall accuracy (OA) of 88.68% outperforms the results obtained from random forest (OA = 84.88%), support vector machine (OA = 82.86%), extreme gradient boosting (OA = 86.55%), and ResNet50 (OA = 86.93%). The outcomes reveal that the Wet-GC architecture proposed in this article has an excellent capability to be applied over large areas with minimal need for training samples and can perform acceptably in supporting regional wetland mapping.
C1 [Jafarzadeh, Hamid; Mahdianpari, Masoud; Gill, Eric W.] Mem Univ Newfoundland, Dept Elect & Comp Engn, St John, NF A1B 3X5, Canada.
   [Mahdianpari, Masoud] C CORE, St John, NF A1B 3X5, Canada.
C3 Memorial University Newfoundland
RP Mahdianpari, M (corresponding author), Mem Univ Newfoundland, Dept Elect & Comp Engn, St John, NF A1B 3X5, Canada.
EM hjafarzadeh@mun.ca; m.mahdianpari@mun.ca; ewgill@mun.ca
FU Natural Sciences and Engineering Research Council (NSERC) [RGPIN-202204766]; NSERC Discovery [RGPIN-2020-05003]
CR Amani M, 2018, ISPRS J PHOTOGRAMM, V144, P119, DOI 10.1016/j.isprsjprs.2018.07.005
   Amarsaikhan D, 2010, INT J IMAGE DATA FUS, V1, P83, DOI 10.1080/19479830903562041
   [Anonymous], 2016, WETLAND INDICATORS G, V0, P0
   Chaoyang Fang, 2016, ANNALS OF GIS, V22, P259, DOI 10.1080/19475683.2016.1231719
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Costanza R, 2008, AMBIO, V37, P241, DOI 10.1579/0044-7447(2008)37[241:TVOCWF]2.0.CO;2
   DeLancey ER, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010002
   Gallant AL, 2015, REMOTE SENS-BASEL, V7, P10938, DOI 10.3390/rs70810938
   Gallant AL, 2014, WATER-SUI, V6, P694, DOI 10.3390/w6030694
   Gao Y, 2021, EUR J REMOTE SENS, V54, P141, DOI 10.1080/22797254.2020.1868273
   Gardner Royal C., 2015, STATE WORLDS WETLAND, V0, P0, DOI DOI 10.2139/SSRN.2589447
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Gori M, 2005, IEEE IJCNN, V0, P729
   Guo M, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17040777
   He K., 2015, PROC CVPR IEEE, V5, P6
   Henderson FM, 2008, INT J REMOTE SENS, V29, P5809, DOI 10.1080/01431160801958405
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V147, P193, DOI 10.1016/j.isprsjprs.2018.10.006
   Hosseiny B, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1080/09603123.2021.1964447
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Jafarzadeh H, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13214405
   Jafarzadeh H, 2019, IEEE J-STARS, V12, P4888, DOI 10.1109/JSTARS.2019.2939133
   Jamali A, 2022, REMOTE SENS-BASEL, V14, P0, DOI 10.3390/rs14020359
   Jamali A, 2021, GISCI REMOTE SENS, V58, P1072, DOI 10.1080/15481603.2021.1965399
   Kaplan G, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7100411
   Kasischke ES, 2003, REMOTE SENS ENVIRON, V88, P423, DOI 10.1016/j.rse.2003.08.016
   Landmann T, 2010, REMOTE SENS-BASEL, V2, P1751, DOI 10.3390/rs2071751
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li MY, 2021, IEEE J-STARS, V14, P3120, DOI 10.1109/JSTARS.2021.3060769
   Liu B, 2020, J APPL REMOTE SENS, V14, P0, DOI 10.1117/1.JRS.14.026516
   Liu HX, 2022, WATER-SUI, V14, P0, DOI 10.3390/w14010082
   Liu XN, 2019, IEEE GEOSCI REMOTE S, V16, P1200, DOI 10.1109/LGRS.2019.2894399
   LYNNE GD, 1981, J ENVIRON ECON MANAG, V8, P175, DOI 10.1016/0095-0696(81)90006-1
   Mabwoga SO, 2014, SPRINGERPLUS, V3, P0, DOI 10.1186/2193-1801-3-576
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Mahdavi S, 2018, GISCI REMOTE SENS, V55, P623, DOI 10.1080/15481603.2017.1419602
   Mahdianpari M., 2021, 2021 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM IGARSS, V0, PP88, DOI 10.1109/IGARSS47720.2021.9553053
   Mahdianpari M, 2020, GISCI REMOTE SENS, V57, P1102, DOI 10.1080/15481603.2020.1846948
   Mahdianpari M, 2020, CAN J REMOTE SENS, V46, P360, DOI 10.1080/07038992.2020.1802584
   Mahdianpari M, 2020, CAN J REMOTE SENS, V46, P15, DOI 10.1080/07038992.2019.1711366
   Mahdianpari M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010043
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   Mandianpari M, 2017, ISPRS J PHOTOGRAMM, V130, P13, DOI 10.1016/j.isprsjprs.2017.05.010
   Marshall CH, 2004, MON WEATHER REV, V132, P2243, DOI 10.1175/1520-0493(2004)132<2243:HTCONW>2.0.CO;2
   Mazzia V, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10010238
   McCarthy MJ, 2015, INT J APPL EARTH OBS, V40, P11, DOI 10.1016/j.jag.2015.03.011
   McGillem CD., 1991, CONTINUOUS DISCRETE, V0, P0
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P8246, DOI 10.1109/TGRS.2020.2973363
   ONeil GL, 2020, ENVIRON MODELL SOFTW, V126, P0, DOI 10.1016/j.envsoft.2020.104665
   RAPHAEL CN, 1979, COAST ZONE MANAGE J, V5, P181, DOI 10.1080/08920757909361805
   Rezaee M, 2018, IEEE J-STARS, V11, P3030, DOI 10.1109/JSTARS.2018.2846178
   Schmidt KS, 2003, REMOTE SENS ENVIRON, V85, P92, DOI 10.1016/S0034-4257(02)00196-7
   Sha AS, 2021, IEEE GEOSCI REMOTE S, V18, P157, DOI 10.1109/LGRS.2020.2966239
   Shen RP, 2019, INT J APPL EARTH OBS, V79, P48, DOI 10.1016/j.jag.2019.03.006
   Slagter B, 2020, INT J APPL EARTH OBS, V86, P0, DOI 10.1016/j.jag.2019.102009
   van Beijma S, 2014, REMOTE SENS ENVIRON, V149, P118, DOI 10.1016/j.rse.2014.04.010
   Van Tricht K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101642
   Wan S, 2021, IEEE T GEOSCI REMOTE, V59, P597, DOI 10.1109/TGRS.2020.2994205
   Wan S, 2020, IEEE T GEOSCI REMOTE, V58, P3162, DOI 10.1109/TGRS.2019.2949180
   Wang GL, 2017, IEEE J-STARS, V10, P4104, DOI 10.1109/JSTARS.2017.2705419
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Were D, 2019, EARTH SYST ENVIRON, V3, P327, DOI 10.1007/s41748-019-00094-0
   Xie J, 2019, IEEE T GEOSCI REMOTE, V57, P6916, DOI 10.1109/TGRS.2019.2909695
   Yu B, 2018, IEEE J-STARS, V11, P3252, DOI 10.1109/JSTARS.2018.2860989
   Zhang JX, 2010, INT J IMAGE DATA FUS, V1, P5, DOI 10.1080/19479830903561035
   Zhang W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050494
   ZOLTAI SC, 1995, VEGETATIO, V118, P131, DOI 10.1007/BF00045195
NR 67
TC 2
Z9 2
U1 15
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 22
PY 2022
VL 15
IS 
BP 5303
EP 5316
DI 10.1109/JSTARS.2022.3177579
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 2Y5XC
UT WOS:000825968600001
DA 2023-04-26
ER

PT J
AU Stock, A
   Subramaniam, A
AF Stock, Andy
   Subramaniam, Ajit
TI Iterative spatial leave-one-out cross-validation and gap-filling based data augmentation for supervised learning applications in marine remote sensing
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Ocean color; phytoplankton; Gulf of Mexico; accuracy; autocorrelation; gap-filling
ID gulf-of-mexico; phytoplankton pigment distribution; empirical orthogonal functions; chlorophyll-a; community structure; continental-margin; neural-network; sea; variability; model
AB In marine remote sensing, supervised learning can link variables measured in-situ near the ocean surface to variables that can be measured from space. However, the in-situ data used for training and validating such empirical satellite algorithms are often spatially auto-correlated and clustered, giving rise to various statistical challenges such as overfitting to spatial structures. Furthermore, co-located in-situ and satellite measurements are rare in the oceans because of the cost of data collection from research vessels and frequent cloud cover. We propose two methods to mitigate these challenges. The first method builds on spatial leave-one-out cross-validation (SLOOCV), an approach designed to provide sound error estimates when data are spatially auto-correlated by enforcing a minimum separation distance between training and test observations. However, estimating this distance may be impossible with sparse and spatially clustered data. We hence propose to iterate and integrate error estimates over a range of separation distances (iSLOOCV). To address the often-small size of labeled data sets based on marine in-situ data, we tested if increasing the number of observations for algorithm training by means of cloud-filling algorithms for marine satellite data improved predictions. The potential of these two methods is demonstrated by developing empirical algorithms for mapping the proportions of seven diagnostic pigments (DPs) that serve as proxies for phytoplankton community composition in the northern Gulf of Mexico. We estimated the prediction accuracy of 13 algorithms with iSLOOCV, using various sets of satellite data products as input, and found adequate algorithms for 4 of the 7 DPs. Random forests combining ocean color and environmental variables as input had the lowest prediction errors overall. Correlations between predictions and observations estimated by iSLOOCV ranged from 0.69 to 0.85 and mean absolute errors from 0.02 to 0.13. Daily maps and longer-term composites of these DPs were broadly consistent with previously published results. Overall, errors increased when extrapolating over larger distances, highlighting how iSLOOCV can illuminate changes in algorithm performance based on sub-regional data coverage. Generating larger training sets by prior gap-filling substantially improved all error measures for 3 of the 7 DPs, with mixed results for the others. Therefore, data augmentation by gap-filling of satellite data should not be used as a default approach but can be a useful tool when supervised learning applications are suspected to be limited by the size of the training set.
C1 [Stock, Andy; Subramaniam, Ajit] Columbia Univ, Lamont Doherty Earth Observ, Earth Inst, Palisades, NY 10027 USA.
   [Stock, Andy] Univ British Columbia, Inst Resources Environm & Sustainabil, Vancouver, BC, Canada.
C3 Columbia University; University of British Columbia
RP Stock, A (corresponding author), Columbia Univ, Lamont Doherty Earth Observ, Earth Inst, Palisades, NY 10027 USA.; Stock, A (corresponding author), Univ British Columbia, Inst Resources Environm & Sustainabil, Vancouver, BC, Canada.
EM andy.stock@ubc.ca
FU Gulf of Mexico Research Initiative's "Ecosystem Impacts of Oil and Gas Inputs to the Gulf" (ECOGIG) program; NASA OBB grant [NNX16AAJ08G]; Earth Institute Postdoctoral Fellowship at Columbia University; Liber Ero Postdoctoral Fellowship; MEOPAR Postdoctoral Award at the University of British Columbia; NSF [OCE 1737128]
CR Agumya A, 2002, INT J GEOGR INF SCI, V16, P405, DOI 10.1080/13658810210137031
   Alvera-Azcarate A, 2005, OCEAN MODEL, V9, P325, DOI 10.1016/j.ocemod.2004.08.001
   Alvera-Azcarate A, 2007, J GEOPHYS RES-OCEANS, V112, P0, DOI 10.1029/2006JC003660
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Bailey SW, 2006, REMOTE SENS ENVIRON, V102, P12, DOI 10.1016/j.rse.2006.01.015
   Barth A, 2020, GEOSCI MODEL DEV, V13, P1609, DOI 10.5194/gmd-13-1609-2020
   Beckers JM, 2003, J ATMOS OCEAN TECH, V20, P1839, DOI 10.1175/1520-0426(2003)020<1839:ECADFF>2.0.CO;2
   Bel L, 2009, COMPUT STAT DATA AN, V53, P3082, DOI 10.1016/j.csda.2008.09.012
   Ruescas AB, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050786
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Beyer J, 2016, MAR POLLUT BULL, V110, P28, DOI 10.1016/j.marpolbul.2016.06.027
   Biasutti M, 2012, CLIMATIC CHANGE, V112, P819, DOI 10.1007/s10584-011-0254-y
   Bracher A, 2015, OCEAN SCI, V11, P139, DOI 10.5194/os-11-139-2015
   Bracher A., 2014, NASATM2015217528, V0, P0
   Bracher A., 2015, PHYTOPLANKTON COMPOS, V0, P0
   Bracher A, 2017, FRONT MAR SCI, V4, P0, DOI 10.3389/fmars.2017.00055
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Brewin RJW, 2016, REMOTE SENS ENVIRON, V183, P82, DOI 10.1016/j.rse.2016.05.005
   Chakraborty S, 2017, J GEOPHYS RES-OCEANS, V122, P4922, DOI 10.1002/2016JC012092
   Chakraborty S, 2015, MAR ECOL PROG SER, V521, P31, DOI 10.3354/meps11107
   Chase AP, 2020, LIMNOL OCEANOGR-METH, V18, P570, DOI 10.1002/lom3.10385
   Chen SL, 2019, REMOTE SENS ENVIRON, V228, P203, DOI 10.1016/j.rse.2019.04.019
   Dierssen H, 2020, OCEANOGRAPHY, V33, P74, DOI 10.5670/oceanog.2020.111
   Doerffer R, 2007, INT J REMOTE SENS, V28, P517, DOI 10.1080/01431160600821127
   Dormann CF, 2013, ECOGRAPHY, V36, P27, DOI 10.1111/j.1600-0587.2012.07348.x
   E.U. Copernicus Marine Service, 2019, GLOB OC GRIDD L4 SEA, V0, P0
   El Hourany R, 2019, J GEOPHYS RES-OCEANS, V124, P1357, DOI 10.1029/2018JC014450
   Elith J, 2008, J ANIM ECOL, V77, P802, DOI 10.1111/j.1365-2656.2008.01390.x
   Fanton dAndon O., 2009, P 2009 IEEE INT GEOS, V0, P0, DOI DOI 10.1029/2006JC004007
   GHER, 2016, DINEOF, V0, P0
   Gittings JA, 2019, REMOTE SENS ENVIRON, V234, P0, DOI 10.1016/j.rse.2019.111387
   Vilas LG, 2011, REMOTE SENS ENVIRON, V115, P524, DOI 10.1016/j.rse.2010.09.021
   Graler B., 2016, R J, V8, P204, DOI 10.1007/978-3-319-17885-1
   Greenwell B., 2020, GBM DEV GBM GEN BOOS, V0, P0
   Gregr EJ, 2019, ECOGRAPHY, V42, P428, DOI 10.1111/ecog.03470
   Groom S, 2019, FRONT MAR SCI, V6, P0, DOI 10.3389/fmars.2019.00485
   Hieronymi M, 2017, FRONT MAR SCI, V4, P0, DOI 10.3389/fmars.2017.00140
   Hilborn A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091449
   Hirata T, 2011, BIOGEOSCIENCES, V8, P311, DOI 10.5194/bg-8-311-2011
   Hu SB, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030191
   Ifremer C.E.R.S.A.T., 2019, ASCAT METOP A LEVEL, V0, P0
   Ifremer C.E.R.S.A.T., 2019, SEAWINDS QUIKSCAT LE, V0, P0
   JPL MUR MEaSUREs Project, 2015, GHRSST LEV 4 MUR GLO, V0, P0, DOI DOI 10.5067/GHGMR-4FJ04
   Keiner LE, 1999, INT J REMOTE SENS, V20, P189, DOI 10.1080/014311699213695
   Kerr JT, 2003, TRENDS ECOL EVOL, V18, P299, DOI 10.1016/S0169-5347(03)00071-5
   Kramer SJ, 2020, FRONT MAR SCI, V7, P0, DOI 10.3389/fmars.2020.00215
   Kramer SJ, 2019, J GEOPHYS RES-OCEANS, V124, P7557, DOI 10.1029/2019JC015604
   Lambert CD, 1999, CONT SHELF RES, V19, P1, DOI 10.1016/S0278-4343(98)00075-2
   Lammers Bart, 2020, CRAN, V0, P0
   Le CF, 2014, J GEOPHYS RES-OCEANS, V119, P7449, DOI 10.1002/2014JC010084
   Le Quere C, 2005, GLOBAL CHANGE BIOL, V11, P2016, DOI 10.1111/j.1365-2468.2005.01004.x
   Le Rest K, 2014, GLOBAL ECOL BIOGEOGR, V23, P811, DOI 10.1111/geb.12161
   Le Rest K, 2013, ECOL INFORM, V14, P17, DOI 10.1016/j.ecoinf.2012.11.008
   Liu HZ, 2021, REMOTE SENS ENVIRON, V256, P0, DOI 10.1016/j.rse.2021.112316
   Liu HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010029
   Liu XM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020178
   Lyons MB, 2018, REMOTE SENS ENVIRON, V208, P145, DOI 10.1016/j.rse.2018.02.026
   Maritorena S, 2002, APPL OPTICS, V41, P2705, DOI 10.1364/AO.41.002705
   Maritorena S, 2010, REMOTE SENS ENVIRON, V114, P1791, DOI 10.1016/j.rse.2010.04.002
   Martinez-Lopez B, 2009, J MARINE SYST, V77, P1, DOI 10.1016/j.jmarsys.2008.10.002
   McClain CR, 2009, ANNU REV MAR SCI, V1, P19, DOI 10.1146/annurev.marine.010908.163650
   Moisan TA, 2017, FRONT MAR SCI, V4, P0, DOI 10.3389/fmars.2017.00189
   Mouw CB, 2019, GLOBAL BIOGEOCHEM CY, V33, P540, DOI 10.1029/2018GB006118
   Mouw CB, 2017, FRONT MAR SCI, V4, P0, DOI 10.3389/fmars.2017.00041
   MULLERKARGER FE, 1991, J GEOPHYS RES-OCEANS, V96, P12645, DOI 10.1029/91JC00787
   Nababan B, 2011, INT J REMOTE SENS, V32, P8373, DOI 10.1080/01431161.2010.542192
   Nair A, 2008, REMOTE SENS ENVIRON, V112, P3366, DOI 10.1016/j.rse.2008.01.021
   OReilly JE, 1998, J GEOPHYS RES-OCEANS, V103, P24937, DOI 10.1029/98JC02160
   Opsomer J, 2001, STAT SCI, V16, P134
   Otis DB, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060723
   Ozhan K, 2014, BIOSCIENCE, V64, P829, DOI 10.1093/biosci/biu117
   Pahlevan N, 2020, REMOTE SENS ENVIRON, V240, P0, DOI 10.1016/j.rse.2019.111604
   Pan XJ, 2013, REMOTE SENS ENVIRON, V128, P162, DOI 10.1016/j.rse.2012.10.014
   Pan XJ, 2010, REMOTE SENS ENVIRON, V114, P2403, DOI 10.1016/j.rse.2010.05.015
   Pebesma E, 2012, J STAT SOFTW, V51, P1
   Pebesma EJ, 2004, COMPUT GEOSCI-UK, V30, P683, DOI 10.1016/j.cageo.2004.03.012
   Pohjankukka J, 2017, INT J GEOGR INF SCI, V31, P2001, DOI 10.1080/13658816.2017.1346255
   Qian YR, 2003, CONT SHELF RES, V23, P1, DOI 10.1016/S0278-4343(02)00173-5
   Rabalais NN, 2002, ANNU REV ECOL SYST, V33, P235, DOI 10.1146/annurev.ecolsys.33.010802.150513
   Raitsos DE, 2008, LIMNOL OCEANOGR, V53, P605, DOI 10.4319/lo.2008.53.2.0605
   Roberts DR, 2017, ECOGRAPHY, V40, P913, DOI 10.1111/ecog.02881
   Ruddick KG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151742
   Sathyendranath, 2014, REPORTS INT OCEAN CO, V0, P0
   Saulquin B, 2019, J OPER OCEANOGR, V12, P47, DOI 10.1080/1755876X.2018.1552358
   Soja-Wozniak M, 2020, J MARINE SYST, V211, P0, DOI 10.1016/j.jmarsys.2020.103400
   Stock A, 2018, ECOL INFORM, V48, P37, DOI 10.1016/j.ecoinf.2018.07.007
   Stock A, 2022, ISPRS J PHOTOGRAMM, V187, P46, DOI 10.1016/j.isprsjprs.2022.02.023
   Stock A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203313
   Stock A, 2020, FRONT MAR SCI, V7, P0, DOI 10.3389/fmars.2020.00599
   Stock A, 2018, CONSERV BIOL, V32, P1368, DOI 10.1111/cobi.13141
   Stock A, 2015, INT J APPL EARTH OBS, V40, P55, DOI 10.1016/j.jag.2015.04.002
   Sun XR, 2019, J GEOPHYS RES-OCEANS, V124, P8887, DOI 10.1029/2019JC015552
   Uitz J, 2006, J GEOPHYS RES-OCEANS, V111, P0, DOI 10.1029/2005JC003207
   Valavi R, 2019, METHODS ECOL EVOL, V10, P225, DOI 10.1111/2041-210X.13107
   Vidussi F, 2001, J GEOPHYS RES-OCEANS, V106, P19939, DOI 10.1029/1999JC000308
   Werdell P.J., 2002, SEAWIFS BIOOPTICAL A, V0, P0
   Werdell P.J., 2003, UNIQUE DATA REPOSITO, V84, P377
   Wessel P, 1996, J GEOPHYS RES-SOL EA, V101, P8741, DOI 10.1029/96JB00104
   Wojtasiewicz B, 2018, REMOTE SENS ENVIRON, V209, P275, DOI 10.1016/j.rse.2018.02.057
   Xi HY, 2021, J GEOPHYS RES-OCEANS, V126, P0, DOI 10.1029/2020JC017127
   Xi HY, 2020, REMOTE SENS ENVIRON, V240, P0, DOI 10.1016/j.rse.2020.111704
   Xue Z, 2013, BIOGEOSCIENCES, V10, P7219, DOI 10.5194/bg-10-7219-2013
NR 103
TC 1
Z9 1
U1 2
U2 2
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD DEC 31
PY 2022
VL 59
IS 1
BP 1281
EP 1300
DI 10.1080/15481603.2022.2107113
PG 20
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA 5V8OI
UT WOS:000877483200001
DA 2023-04-26
ER
