PT J
AU Srivastava, S
   Volpi, M
   Tuia, D
AF Srivastava, Shivangi
   Volpi, Michele
   Tuia, Devis
TI JOINT HEIGHT ESTIMATION AND SEMANTIC LABELING OF MONOCULAR AERIAL IMAGES WITH CNNS
SO 2017 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (IGARSS)
LA English
DT Proceedings Paper
DE Convolutional neural networks; Multitask learning; Digital Surface Model; Semantic labeling
AB We aim to jointly estimate height and semantically label monocular aerial images. These two tasks are traditionally addressed separately in remote sensing, despite their strong correlation. Therefore, a model learning both height and classes jointly seems advantageous and so, we propose a multitask Convolutional Neural Network (CNN) architecture with two losses: one performing semantic labeling, and another predicting normalized Digital Surface Model (nDSM) from the pixel values. Since the nDSM/height information is used only in the second loss, there is no need to have a nDSM map at test time, and the model can estimate height automatically on new images. We test our proposed method on a set of sub-decimeter resolution images and show that our model equals the performances of two separate models, but at the cost of a single one.
C1 [Srivastava, Shivangi; Volpi, Michele; Tuia, Devis] Univ Zurich, Dept Geog, MultiModal Remote Sensing, Zurich, Switzerland.
C3 University of Zurich
RP Srivastava, S (corresponding author), Univ Zurich, Dept Geog, MultiModal Remote Sensing, Zurich, Switzerland.
EM shivangi.srivastava@geo.uzh.ch; michele.volpi@geo.uzh.ch; devis.tuia@geo.uzh.ch
FU Swiss National Science Foundation [PP00P2-150593]
CR Baatz G., 2012, EUR CONFEREECCVNCE C, V0, P0
   Eigen D., 2014, ARXIV14114734, V0, P0
   Eigen D., 2014, NIPS, V0, P0
   Ferretti A., 2007, TM19 ESA, V0, P0
   Gerke M., 2015, TECH REP, V0, P0
   Hoff W., 1989, IEEE T PATTERN ANAL, V0, P0
   Kokkinos I., 2016, ARXIV160902132, V0, P0
   Noh H., 2015, ICCV, V0, P0
   Produit T., 2014, ISPRS ANN PHOTOGRAMM, VII, P127
   Raggam H., 2006, PHOTO ENG REMOTE SEN, V0, P0
   Raggam J., 1989, ISPRS J INT SOC PHOT, V0, P0
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Scharstein D., 2003, CVPR, V0, P0
   Sherrah J., 2016, ARXIV160602585, V0, P0
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang P., 2015, CVPR, V0, P0
   Zisserman A., 2015, ICLR, V0, P0
NR 17
TC 37
Z9 37
U1 1
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2153-6996
EI 
J9 INT GEOSCI REMOTE SE
PD JUN 15
PY 2017
VL 0
IS 
BP 5173
EP 5176
DI 
PG 4
WC Geosciences, Multidisciplinary; Remote Sensing
SC Geology; Remote Sensing
GA BJ6TY
UT WOS:000426954605042
DA 2023-04-26
ER

PT J
AU Wu, K
   Liu, J
   Chi, YX
AF Wu, Kai
   Liu, Jing
   Chi, Yaxiong
TI Wavelet fuzzy cognitive maps
SO NEUROCOMPUTING
LA English
DT Article
DE Fuzzy cognitive maps; Wavelet; Pattern classification
ID neural-networks; classification; prediction
AB Fuzzy cognitive maps (FCMs) are fuzzy influence graphs which consist of concepts and weighted edges. Various transfer functions have been applied in modelling and simulating the dynamic system of FCMs. In FCMs, transfer function is used to bound the expression level of nodes to a certain range. Therefore, in this paper, we first use wavelet transfer function, and then combine it with FCMs to form wavelet FCMs (WFCM). The wavelet function is a kind of local functions that has limited duration and an average value of zero. Then, we conduct comprehensive analyses over existing transfer functions using synthetic data, real data and pattern classification problems. Finally, according to analysis, a new method involving the selection of transfer functions in the optimization process for pattern classification problems is proposed. The experimental results demonstrate the effectiveness of the proposed method. Still, findings show how the existing functions offer different capacities to deal with both problems.
C1 [Wu, Kai; Liu, Jing; Chi, Yaxiong] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
C3 Xidian University
RP Liu, J (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
EM neouma@163.com
FU Outstanding Young Scholar Program of National Natural Science Foundation of China (NSFC) [61522311]; General Program of NSFC [61271301]; Overseas, Hong Kong & Macao Scholars Collaborated Research Program of NSFC [61528205]; Research Fund for the Doctoral Program of Higher Education of China [20130203110010]; Fundamental Research Funds for the Central Universities [K5051202052]
CR Andreou AS, 2005, SOFT COMPUT, V9, P194, DOI 10.1007/s00500-004-0344-0
   Bueno S, 2009, EXPERT SYST APPL, V36, P5221, DOI 10.1016/j.eswa.2008.06.072
   Chen Y, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, V0, PP9, DOI 10.1145/2330163.2330166
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Froelich W, 2009, C HUM SYST INTERACT, V0, P13
   Glykas M, 2013, EXPERT SYST APPL, V40, P1, DOI 10.1016/j.eswa.2012.01.078
   Gonzalez JL, 2009, INT J INTELL SYST, V24, P1134, DOI 10.1002/int.20379
   Kannappan A, 2011, EXPERT SYST APPL, V38, P1282, DOI 10.1016/j.eswa.2010.06.069
   Knight CJK, 2014, APPL SOFT COMPUT, V15, P193, DOI 10.1016/j.asoc.2013.10.030
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   KUGARAJAH T, 1995, IEEE T NEURAL NETWOR, V6, P1552, DOI 10.1109/72.471353
   Lee KC, 2012, EXPERT SYST APPL, V39, P8626, DOI 10.1016/j.eswa.2012.01.191
   Lichman M, 2013, UCIMACHINE LEARNING, V0, P0
   LIU GZ, 1992, WAVELET ANAL APPL, V0, P0
   Marbach D, 2009, J COMPUT BIOL, V16, P229, DOI 10.1089/cmb.2008.09TT
   Papageorgiou EI, 2012, APPL SOFT COMPUT, V12, P3798, DOI 10.1016/j.asoc.2012.03.064
   Papageorgiou EI, 2012, NEUROCOMPUTING, V92, P28, DOI 10.1016/j.neucom.2011.08.034
   Papageorgiou EI, 2012, IEEE T SYST MAN CY C, V42, P150, DOI 10.1109/TSMCC.2011.2138694
   Papageorgiou EI, 2012, IEEE T INF TECHNOL B, V16, P143, DOI 10.1109/TITB.2011.2175937
   Papageorgiou EI, 2011, APPL SOFT COMPUT, V11, P500, DOI 10.1016/j.asoc.2009.12.010
   Papakostas GA, 2012, EXPERT SYST APPL, V39, P10620, DOI 10.1016/j.eswa.2012.02.148
   Papakostas GA, 2010, STUD FUZZ SOFT COMP, V247, P291
   Papakostas GA, 2008, INT J PATTERN RECOGN, V22, P1461, DOI 10.1142/S0218001408006910
   Papakostas G. A., 2015, 2015 IEEE INT C FUZZ, V0, P1
   Peng Z, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 1, PROCEEDINGS
   Prieto A., 2016, NEUROCOMPUTING, V0, P0
   Song HJ, 2010, IEEE T FUZZY SYST, V18, P233, DOI 10.1109/TFUZZ.2009.2038371
   Song HJJ, 2011, IEEE T FUZZY SYST, V19, P116, DOI 10.1109/TFUZZ.2010.2087383
   Stach W, 2005, FUZZY SET SYST, V153, P371, DOI 10.1016/j.fss.2005.01.009
   Stach W, 2008, IEEE T FUZZY SYST, V16, P61, DOI 10.1109/TFUZZ.2007.902020
   Stolovitzky G, 2007, ANN NY ACAD SCI, V1115, P1, DOI 10.1196/annals.1407.021
   Szu H, 1996, NEURAL NETWORKS, V9, P695, DOI 10.1016/0893-6080(95)00051-8
   Tsadiras AK, 1999, NEUROCOMPUTING, V24, P95, DOI 10.1016/S0925-2312(98)00094-0
   Tsadiras AK, 2008, INFORM SCIENCES, V178, P3880, DOI 10.1016/j.ins.2008.05.015
   ZHANG J, 1995, IEEE T SIGNAL PROCES, V43, P1485, DOI 10.1109/78.388860
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
NR 37
TC 12
Z9 12
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD APR 5
PY 2017
VL 232
IS 
BP 94
EP 103
DI 10.1016/j.neucom.2016.10.071
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA EJ9FU
UT WOS:000393532800009
DA 2023-04-26
ER

PT J
AU Onojeghuo, AO
   Onojeghuo, AR
AF Onojeghuo, Alex Okiemute
   Onojeghuo, Ajoke Ruth
TI Object-based habitat mapping using very high spatial resolution multispectral and hyperspectral imagery with LiDAR data
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE QuickBird; Eagle hyperspectral; OBIA; LiDAR; CHM; Intensity; SVM; kNN; Regression forest; Habitat mapping
ID support vector machines; tree species classification; land-cover; neural-networks; airborne lidar; hyperion eo-1; vegetation; fusion; casi
AB This study investigated the combined use of multispectral/hyperspectral imagery and LiDAR data for habitat mapping across parts of south Cumbria, North West England. The methodology adopted in this study integrated spectral information contained in pansharp QuickBird multispectral/AISA Eagle hyperspectral imagery and LiDAR-derived measures with object-based machine learning classifiers and ensemble analysis techniques. Using the LiDAR point cloud data, elevation models (such as the Digital Surface Model and Digital Terrain Model raster) and intensity features were extracted directly. The LiDAR-derived measures exploited in this study included Canopy Height Model, intensity and topographic information (i.e. mean, maximum and standard deviation). These three LiDAR measures were combined with spectral information contained in the pansharp QuickBird and Eagle MNF transformed imagery for image classification experiments. A fusion of pansharp QuickBird multispectral and Eagle MNF hyperspectral imagery with all LiDAR-derived measures generated the best classification accuracies, 89.8 and 92.6% respectively. These results were generated with the Support Vector Machine and Random Forest machine learning algorithms respectively. The ensemble analysis of all three learning machine classifiers for the pansharp QuickBird and Eagle MNF fused data outputs did not significantly increase the overall classification accuracy. Results of the study demonstrate the potential of combining either very high spatial resolution multispectral or hyperspectral imagery with LiDAR data for habitat mapping. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Onojeghuo, Alex Okiemute; Onojeghuo, Ajoke Ruth] Nnamdi Azikiwe Univ, Dept Surveying & Geoinformat, Awka, Anambra State, Nigeria.
   [Onojeghuo, Ajoke Ruth] Univ Leicester, Ctr Landscape & Climate Res, Leicester LE1 7RH, Leics, England.
C3 University of Leicester
RP Onojeghuo, AO (corresponding author), Nnamdi Azikiwe Univ, Dept Surveying & Geoinformat, Awka, Anambra State, Nigeria.
EM lexisgis@yahoo.com
FU NERC-ARSF [GB09/05]
CR Adam E, 2010, WETL ECOL MANAG, V18, P281, DOI 10.1007/s11273-009-9169-z
   Anderson JE, 2008, REMOTE SENS ENVIRON, V112, P1856, DOI 10.1016/j.rse.2007.09.009
   [Anonymous], 2018, INTRO CATEGORICAL DA, V0, P0
   ASPRS, 2011, LAS SPEC VERS 1 4 R6, V0, P0
   Azimuth-Systems, 2005, AZGCORR US MAN, V0, P0
   Bannari A., 1995, REMOTE SENS REV, V13, P27, DOI 10.1080/02757259509532295
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Bork EW, 2007, REMOTE SENS ENVIRON, V111, P11, DOI 10.1016/j.rse.2007.03.011
   Bradley JV., 1968, DISTRIBUTION FREE ST, V1, P0
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Buddenbaum H, 2005, INT J REMOTE SENS, V26, P5453, DOI 10.1080/01431160500285076
   CBP, 2001, CUMBR BIOD ACT PLAN, V0, P0
   Christian B, 2009, CURR SCI INDIA, V96, P1601
   Cumbria Wildlife Trust, 2009, CUMBR BAP SPEC LIST, V0, P0
   Dalponte M, 2012, REMOTE SENS ENVIRON, V123, P258, DOI 10.1016/j.rse.2012.03.013
   Digital Globe, 2006, QUICKBIRD IM PROD PR, V0, P0
   Dixon B, 2008, INT J REMOTE SENS, V29, P1185, DOI 10.1080/01431160701294661
   Du PJ, 2012, SENSORS-BASEL, V12, P4764, DOI 10.3390/s120404764
   Foody GM, 2007, INT J REMOTE SENS, V28, P1733, DOI 10.1080/01431160600962566
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Geerling GW, 2007, INT J REMOTE SENS, V28, P4263, DOI 10.1080/01431160701241720
   Ghimire B, 2012, GISCI REMOTE SENS, V49, P623, DOI 10.2747/1548-1603.49.5.623
   Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2
   Hill RA, 2005, INT J REMOTE SENS, V26, P3763, DOI 10.1080/01431160500114706
   Holmgren J, 2008, INT J REMOTE SENS, V29, P1537, DOI 10.1080/01431160701736471
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Immitzer M, 2012, REMOTE SENS-BASEL, V4, P2661, DOI 10.3390/rs4092661
   JNCC, 2010, HDB PHAS 1 HAB SURV, V0, P0
   Johnson B., 2011, ISPRS J PHOTOGRAMM R, V66, P0
   Jolliffe IT, 2002, PRINCIPAL COMPONENT, V0, P0, DOI DOI 10.1007/b98835
   Jones TG, 2010, REMOTE SENS ENVIRON, V114, P2841, DOI 10.1016/j.rse.2010.07.002
   Karpouzli E, 2003, INT J REMOTE SENS, V24, P1143, DOI 10.1080/0143116021000026779
   Ke YH, 2010, REMOTE SENS ENVIRON, V114, P1141, DOI 10.1016/j.rse.2010.01.002
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Moreno-Seco F, 2006, LECT NOTES COMPUT SC, V4109, P705
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Mucher CA, 2015, INT J APPL EARTH OBS, V37, P48, DOI 10.1016/j.jag.2014.09.001
   Onojeghuo AO, 2013, IEEE J-STARS, V6, P935, DOI 10.1109/JSTARS.2012.2212235
   Onojeghuo AO, 2011, REMOTE SENS ENVIRON, V115, P2025, DOI 10.1016/j.rse.2011.04.004
   Pal M, 2005, INT J REMOTE SENS, V26, P1007, DOI 10.1080/01431160512331314083
   Peerbhay KY, 2013, ISPRS J PHOTOGRAMM, V79, P19, DOI 10.1016/j.isprsjprs.2013.01.013
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Pu R, 2008, ENVIRON MONIT ASSESS, V140, P15, DOI 10.1007/s10661-007-9843-7
   Rapinel S, 2015, INT J APPL EARTH OBS, V37, P56, DOI 10.1016/j.jag.2014.09.002
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Solberg A.H.S., 2006, SIGNAL IMAGE PROCESS, V0, PP515, DOI 10.1201/9781420003130.CH23
   Song J.H., 2002, INT ARCH PHOTOGRAM 3, V34, P259
   Trimble, 2014, ECOGNITION DEV 9 0 U, V0, P0
   Trimble, 2014, ECOGNITION DEV 9 0 R, V0, P0
   Vapnik Vladimir, 1998, STAT LEARNING THEORY, V0, PP1, DOI 10.1007/978-1-4419-1428-6_5864
   Vepakomma U, 2008, REMOTE SENS ENVIRON, V112, P2326, DOI 10.1016/j.rse.2007.10.001
   Vyas D, 2011, INT J APPL EARTH OBS, V13, P228, DOI 10.1016/j.jag.2010.11.007
   Zhang CY, 2015, ISPRS J PHOTOGRAMM, V104, P213, DOI 10.1016/j.isprsjprs.2014.06.005
   Zhang CY, 2014, PHOTOGRAMM ENG REM S, V80, P733, DOI 10.14358/PERS.80.8.733
   Zhang CY, 2014, GEOCARTO INT, V29, P228, DOI 10.1080/10106049.2012.756940
   Zhang CY, 2012, PHOTOGRAMM ENG REM S, V78, P1079, DOI 10.14358/PERS.78.10.1079
   Zhang XY, 2005, INT GEOSCI REMOTE SE, V0, P1475
NR 58
TC 23
Z9 23
U1 1
U2 39
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD JUL 15
PY 2017
VL 59
IS 
BP 79
EP 91
DI 10.1016/j.jag.2017.03.007
PG 13
WC Remote Sensing
SC Remote Sensing
GA EW0ZS
UT WOS:000402220300008
DA 2023-04-26
ER

PT J
AU Pawluszek, K
   Borkowski, A
   Tarolli, P
AF Pawluszek, K.
   Borkowski, A.
   Tarolli, P.
TI TOWARDS THE OPTIMAL PIXEL SIZE OF DEM FOR AUTOMATIC MAPPING OF LANDSLIDE AREAS
SO ISPRS HANNOVER WORKSHOP: HRIGI 17 - CMRT 17 - ISA 17 - EUROCOW 17
LA English
DT Proceedings Paper
DE landslide; landslide mapping; DEM resolution; Neural Net classification; Maximum Likelihood classification
ID roznow lake; resolution; identification; susceptibility
AB Determining appropriate spatial resolution of digital elevation model (DEM) is a key step for effective landslide analysis based on remote sensing data. Several studies demonstrated that choosing the finest DEM resolution is not always the best solution. Various DEM resolutions can be applicable for diverse landslide applications. Thus, this study aims to assess the influence of special resolution on automatic landslide mapping. Pixel-based approach using parametric and non-parametric classification methods, namely feed forward neural network (FFNN) and maximum likelihood classification (ML), were applied in this study. Additionally, this allowed to determine the impact of used classification method for selection of DEM resolution. Landslide affected areas were mapped based on four DEMs generated at 1m, 2m, 5m and 10m spatial resolution from airborne laser scanning (ALS) data. The performance of the landslide mapping was then evaluated by applying landslide inventory map and computation of confusion matrix. The results of this study suggests that the finest scale of DEM is not always the best fit, however working at 1m DEM resolution on micro-topography scale, can show different results. The best performance was found at 5m DEM-resolution for FFNN and 1m DEM resolution for results. The best performance was found to be using 5m DEM-resolution for FFNN and 1m DEM resolution for ML classification.
C1 [Pawluszek, K.; Borkowski, A.] Wroclaw Univ Environm & Life Sci, Inst Geodesy & Geoinformat, Wroclaw, Poland.
   [Tarolli, P.] Univ Padua, Dept Land Environm Agr & Forestry, Padua, Italy.
C3 Institute of Geodesy & Cartography; Wroclaw University of Environmental & Life Sciences; University of Padua
RP Pawluszek, K (corresponding author), Wroclaw Univ Environm & Life Sci, Inst Geodesy & Geoinformat, Wroclaw, Poland.
EM kamila.pawluszek@igig.up.wroc.pl; andrzej.borkowski@igig.up.wroc.pl; paolo.tarolli@unipd.it
CR Ahmad A., 2012, APPL MATH SCI, V6, P6425
   [Anonymous], 2015, INTRO DIGITAL IMAGE, V0, P0
   Ardizzone F, 2007, NAT HAZARD EARTH SYS, V7, P637, DOI 10.5194/nhess-7-637-2007
   Booth AM, 2009, GEOMORPHOLOGY, V109, P132, DOI 10.1016/j.geomorph.2009.02.027
   Borkowski A, 2003, J GEODESY, V77, P543, DOI 10.1007/s00190-003-0354-1
   Borkowski A., 2008, SILK ROAD INFORM IMA, VXXXVII, P179
   Borkowski A, 2011, ACTA GEODYN GEOMATER, V8, P325
   Cheng KS, 2004, ADV SPACE RES-SERIES, V33, P296, DOI 10.1016/S0273-1177(03)00471-X
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Cruden D., 1991, B INT ASS ENG GEOL, V43, P27, DOI 10.1007/BF02590167
   Del Ventisette C, 2014, INT J APPL EARTH OBS, V30, P238, DOI 10.1016/j.jag.2014.02.008
   Duro DC, 2012, INT J REMOTE SENS, V33, P4502, DOI 10.1080/01431161.2011.649864
   Evans J. S., 2014, ARCGIS TOOLBOX SURFA, V0, P0
   Hengl T, 2006, COMPUT GEOSCI-UK, V32, P1283, DOI 10.1016/j.cageo.2005.11.008
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Leshchinsky BA, 2015, COMPUT GEOSCI-UK, V74, P27, DOI 10.1016/j.cageo.2014.10.007
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Moosavi V, 2014, GEOMORPHOLOGY, V204, P646, DOI 10.1016/j.geomorph.2013.09.012
   Mora OE, 2014, INT ARCH PHOTOGRAMM, V40-1, P293, DOI 10.5194/isprsarchives-XL-1-293-2014
   Ndehedehe C, 2013, NY SCI J, V6, P26, DOI 10.7537/MARSNYS060813.05
   Paudel U., 2016, INTERNATIONAL JOURNAL OF GEOSCIENCES, V7, P726, DOI 10.4236/ijg.2016.75056
   Pawluszek K, 2016, INT ARCH PHOTOGRAMM, V41, P145, DOI 10.5194/isprsarchives-XLI-B8-145-2016
   Pawluszek K, 2017, NAT HAZARDS, V86, P919, DOI 10.1007/s11069-016-2725-y
   Penna D, 2014, HYDROL EARTH SYST SC, V18, P2127, DOI 10.5194/hess-18-2127-2014
   Platt RV, 2008, PROF GEOGR, V60, P87, DOI 10.1080/00330120701724152
   Stumpf A, 2013, THESIS, V0, P0
   Tarolli P, 2006, HYDROL EARTH SYST SC, V10, P663, DOI 10.5194/hess-10-663-2006
   Tarolli P, 2014, GEOMORPHOLOGY, V216, P295, DOI 10.1016/j.geomorph.2014.03.008
   Tarolli P, 2012, NAT HAZARDS, V61, P65, DOI 10.1007/s11069-010-9695-2
   Twardosz R, 2014, PRACE GEOGRAFICZNE, V138, P7, DOI 10.4467/20833113PG.14.015.2697
   Van Den Eeckhaut M, 2005, GEOMORPHOLOGY, V67, P351, DOI 10.1016/j.geomorph.2004.11.001
   Wojciechowski T., 2012, PRZ GEOL, V60, P95
   Zhao CY, 2012, REMOTE SENS ENVIRON, V124, P348, DOI 10.1016/j.rse.2012.05.025
NR 33
TC 11
Z9 11
U1 1
U2 7
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 2194-9034
EI 
J9 INT ARCH PHOTOGRAMM
PD JUN 15
PY 2017
VL 42-1
IS W1
BP 83
EP 90
DI 10.5194/isprs-archives-XLII-1-W1-83-2017
PG 8
WC Remote Sensing; Optics; Imaging Science & Photographic Technology
SC Remote Sensing; Optics; Imaging Science & Photographic Technology
GA BK0CE
UT WOS:000430221300013
DA 2023-04-26
ER

PT J
AU Amit, SNKB
   Saito, S
   Aoki, Y
   Kiyoki, Y
AF Amit, Siti Nor Khuzaimah Binti
   Saito, Shunta
   Aoki, Yoshimitsu
   Kiyoki, Yasushi
TI Building Change Detection via Semantic Segmentation and Difference Extraction Method
SO INFORMATION MODELLING AND KNOWLEDGE BASES XXVIII
LA English
DT Proceedings Paper
DE aerial imagery; semantic segmentation; convolutional neural network; difference extraction; building change detection
AB Google Earth with high-resolution imagery basically takes months to process new images before online updates. It is considered as a time consuming and slow process especially for post-disaster application. In this study, we aim to develop a fast and accurate method of updating maps by detecting local differences occurred over different time series; where only region with differences will be updated. In our system, aerial imageries from Massachusetts's building open datasets are used as training datasets; meanwhile Saitama district datasets are used as input images. Semantic segmentation is then applied to input images to get predicted map patches of building. Semantic segmentation is a pixel-wise classification of images by implementing convolutional neural network technique. Convolutional neural network technique is implemented due to being not only efficient in learning highly discriminative image features such as buildings, but also partially robust to incomplete and poorly registered target maps. Next, in order to understand overall changes occurred in an area, both semantic segmented images from the same scene are undergone change detection method. Lastly, difference extraction method is implemented to specify the category of building changes. The results reveal that our proposed method is able to overcome current time-consuming map updating problem. Hence map updating will be cheaper, faster and more effective especially post-disaster application, by leaving unchanged region and only updating changed region.
C1 [Amit, Siti Nor Khuzaimah Binti; Saito, Shunta; Aoki, Yoshimitsu] Keio Univ, Grad Sch Sci & Technol, Kohoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa 2238522, Japan.
   [Kiyoki, Yasushi] Keio Univ, Grad Sch Media & Governance, 5322 Endo, Fujisawa, Kanagawa 2520882, Japan.
C3 Keio University; Keio University
RP Amit, SNKB (corresponding author), Keio Univ, Grad Sch Sci & Technol, Kohoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa 2238522, Japan.
CR Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Femiani J, 2015, IEEE J-STARS, V8, P2063, DOI 10.1109/JSTARS.2014.2369475
   Fkagawa R., 2008, P S JIB NO KANK KEIS, V0, P21
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Koizumi Keigo, 2012, SICE JOURNAL OF CONTROL, V0, P0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Miura H, 2006, EARTHQ SPECTRA, V22, P151, DOI 10.1193/1.2162940
   Nakamura Satoshi, 2013, J JAPAN ASS IMAGE EL, V42, P25
   Nichol J, 2005, INT J REMOTE SENS, V26, P1913, DOI 10.1080/01431160512331314047
   Saito Takayoshi Yamachita Shunta, 1900, V60, V0, P0
   Uetake M., 2010, STUDY PREDICTION SLO, V77, P49
   Urabe K, 2009, J JAPAN ASS EARTHQUA, V9, P0
NR 14
TC 1
Z9 1
U1 0
U2 7
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
EI 1879-8314
J9 FRONT ARTIF INTEL AP
PD JUN 15
PY 2017
VL 292
IS 
BP 249
EP 257
DI 10.3233/978-1-61499-720-7-249
PG 9
WC Computer Science, Artificial Intelligence
SC Computer Science
GA BH7BZ
UT WOS:000402391600018
DA 2023-04-26
ER
