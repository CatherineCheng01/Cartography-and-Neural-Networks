
PT J
AU Ponciano, JJ
   Roetner, M
   Reiterer, A
   Boochs, F
AF Ponciano, Jean-Jacques
   Roetner, Moritz
   Reiterer, Alexander
   Boochs, Frank
TI Object Semantic Segmentation in Point Clouds-Comparison of a Deep Learning and a Knowledge-Based Method
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE point cloud; deep learning; knowledge-based; SPARQL; segmentation; 3D; semantic segmentation; classification
ID automatic detection; system
AB Through the power of new sensing technologies, we are increasingly digitizing the real world. However, instruments produce unstructured data, mainly in the form of point clouds for 3D data and images for 2D data. Nevertheless, many applications (such as navigation, survey, infrastructure analysis) need structured data containing objects and their geometry. Various computer vision approaches have thus been developed to structure the data and identify objects therein. They can be separated into model-driven, data-driven, and knowledge-based approaches. Model-driven approaches mainly use the information on the objects contained in the data and are thus limited to objects and context. Among data-driven approaches, we increasingly find deep learning strategies because of their autonomy in detecting objects. They identify reliable patterns in the data and connect these to the object of interest. Deep learning approaches have to learn these patterns in a training stage. Knowledge-based approaches use characteristic knowledge from different domains allowing the detection and classification of objects. The knowledge must be formalized and substitutes the training for deep learning. Semantic web technologies allow the management of such human knowledge. Deep learning and knowledge-based approaches have already shown good results for semantic segmentation in various examples. The common goal but the different strategies of the two approaches engaged our interest in doing a comparison to get an idea of their strengths and weaknesses. To fill this knowledge gap, we applied two implementations of such approaches to a mobile mapping point cloud. The detected object categories are car, bush, tree, ground, streetlight and building. The deep learning approach uses a convolutional neural network, whereas the knowledge-based approach uses standard semantic web technologies such as SPARQL and OWL2to guide the data processing and the subsequent classification as well. The LiDAR point cloud used was acquired by a mobile mapping system in an urban environment and presents various complex scenes, allowing us to show the advantages and disadvantages of these two types of approaches. The deep learning and knowledge-based approaches produce a semantic segmentation with an average F1 score of 0.66 and 0.78, respectively. Further details are given by analyzing individual object categories allowing us to characterize specific properties of both types of approaches.
C1 [Ponciano, Jean-Jacques; Boochs, Frank] Mainz Univ Appl Sci, Inst Spatial Informat & Surveying Technol, i3mainz, D-55128 Mainz, Germany.
   [Roetner, Moritz; Reiterer, Alexander] Fraunhofer Inst Phys Measurement Tech IPM, D-79110 Freiburg, Germany.
   [Reiterer, Alexander] Univ Freiburg, Dept Sustainable Syst Engn INATECH, D-79110 Freiburg, Germany.
C3 Fraunhofer Gesellschaft; University of Freiburg
RP Ponciano, JJ (corresponding author), Mainz Univ Appl Sci, Inst Spatial Informat & Surveying Technol, i3mainz, D-55128 Mainz, Germany.
EM jean-jacques.ponciano@hs-mainz.de; moritz.roetner@ipm.fraunhofer.de; alexander.reiterer@ipm.fraunhofer.de; frank.boochs@hs-mainz.de
CR Anagnostopoulos I, 2016, CONSTRUCTION RESEARCH CONGRESS 2016: OLD AND NEW CONSTRUCTION TECHNOLOGIES CONVERGE IN HISTORIC SAN JUAN, V0, P2302
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, V0, P225, DOI 10.1109/RAM.2013.6758588
   Belgiu M, 2014, REMOTE SENS-BASEL, V6, P1347, DOI 10.3390/rs6021347
   Ben Hmida H, 2011, KEOD 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON KNOWLEDGE ENGINEERING AND ONTOLOGY DEVELOPMENT, V0, P255
   Diaz-Vilarino L, 2015, REMOTE SENS-BASEL, V7, P15651, DOI 10.3390/rs71115651
   Dietenbeck T, 2017, STUD COMPUT INTELL, V665, P181, DOI 10.1007/978-3-319-45763-5_10
   Drost B, 2010, PROC CVPR IEEE, V0, PP998, DOI 10.1109/CVPR.2010.5540108
   Durand N, 2007, PROC INT C TOOLS ART, V0, PP472, DOI 10.1109/ICTAI.2007.111
   Engelmann F, 2020, IEEE INT CONF ROBOT, V0, PP9463, DOI 10.1109/ICRA40945.2020.9197503
   Florkova Z, 2018, MATEC WEB CONF, V196, P0, DOI 10.1051/matecconf/201819604082
   Grau BC, 2008, J WEB SEMANT, V6, P309, DOI 10.1016/j.websem.2008.05.001
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hackel T., 2017, P ISPRS ANN PHOT REM, VIV-1/W1, P91, DOI 10.5194/ISPRS-ANNALS-IV-1-W1-91-2017
   Hu P, 2018, ISPRS ARCH, VXLII-2, P449, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-449-2018
   Jia Y., 2014, CORR, V0, P0
   Karmacharya A, 2015, PROC SPIE, V9528, P0, DOI 10.1117/12.2184801
   Lari Z, 2012, INT ARCH PHOTOGRAMM, V39-B3, P127
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Liu JX, 2019, IEEE I CONF COMP VIS, V0, PP7545, DOI 10.1109/ICCV.2019.00764
   Maillot N, 2004, PROC INT C TOOLS ART, V0, P620
   Milioto A, 2019, IEEE INT C INT ROBOT, V0, PP4213, DOI 10.1109/IROS40897.2019.8967762
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Ponciano J.J., 2020, PHOTOGRAMMETRIE LASE, V0, P1
   Ponciano J.J., 2019, OLDENBURGER 3D TAGE, V0, P98
   Ponciano J.J., 2019, THESIS U LYON LYON, V0, P0
   Ponciano J.J., 2019, STRUCTURAL ANAL HIST, V0, P297
   Ponciano J.J., 2017, GIS SCI Z GEOINFORM, V3, P97
   Ponciano JJ, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8100442
   Poux F., 2020, INT ARCH PHOTOGRAMME, V43, P309, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2020-309-2020
   Prud Hommeaux E., 2008, SPARQL QUERY LANGUAG, V0, P0
   Qi CR, 2017, ADV NEUR IN, V30, P0
   Qi CR, 2017, PROC CVPR IEEE, V0, PP77, DOI 10.1109/CVPR.2017.16
   Reiterer A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162530
   Rethage D., 2018, FULLY CONVOLUTIONAL, V0, P0
   Rosu R.A., 2019, LATTICENET FAST POIN, V0, P0
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Steder B, 2011, IEEE INT CONF ROBOT, V0, PP2601, DOI 10.1109/ICRA.2011.5980187
   Streiffer C, 2017, MIDDLEWARE17: PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (INDUSTRIAL TRACK), V0, PP22, DOI 10.1145/3154448.3154452
   Tatarchenko M, 2018, PROC CVPR IEEE, V0, PP3887, DOI 10.1109/CVPR.2018.00409
   Tombari F, 2011, IEEE IMAGE PROC, V0, PP809, DOI 10.1109/ICIP.2011.6116679
   Tonietto L, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-51545-7
   Tsarkov D, 2006, LECT NOTES ARTIF INT, V4130, P292
   Wang JL, 2019, AAAI CONF ARTIF INTE, V0, P8949
   Xu B, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010005
   Zhang X., 2008, PROC ASIAGRAPH, V8, P23
NR 46
TC 8
Z9 8
U1 3
U2 19
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD APR 15
PY 2021
VL 10
IS 4
BP 
EP 
DI 10.3390/ijgi10040256
PG 21
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RR4UM
UT WOS:000643095200001
DA 2023-04-26
ER

PT J
AU Yan, YL
   Ryu, Y
AF Yan, Yulin
   Ryu, Youngryel
TI Exploring Google Street View with deep learning for crop type mapping
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Crop type mapping; Deep learning; Google Earth Engine; Google Street View; Ground referencing
ID urban land-use; training data; sample-size; ndvi data; classification; information; imagery
AB Ground reference data are an essential prerequisite for supervised crop mapping. The lack of a low-cost and efficient ground referencing method results in pervasively limited reference data and hinders crop classification. In this study, we apply a convolutional neural network (CNN) model to explore the efficacy of automatic ground truthing via Google Street View (GSV) images in two distinct farming regions: Illinois and the Central Valley in California. We demonstrate the feasibility and reliability of our new ground referencing technique by performing pixel-based crop mapping at the state level using the cloud-based Google Earth Engine platform. The mapping results are evaluated using the United States Department of Agriculture (USDA) crop data layer (CDL) products. From similar to 130,000 GSV images, the CNN model identified similar to 9,400 target crop images. These images are well classified into crop types, including alfalfa, almond, corn, cotton, grape, rice, soybean, and pistachio. The overall GSV image classification accuracy is 92% for the Central Valley and 97% for Illinois. Subsequently, we shifted the image geographical coordinates 2-3 times in a certain direction to produce 31,829 crop reference points: 17,358 in Illinois, and 14,471 in the Central Valley. Evaluation of the mapping results with CDL products revealed satisfactory coherence. GSV-derived mapping results capture the general pattern of crop type distributions for 2011-2019. The overall agreement between CDL products and our mapping results is indicated by R-2 values of 0.44-0.99 for the Central Valley and 0.81-0.98 for Illinois. To show the applicational value of the proposed method in other countries, we further mapped rice paddy (2014-2018) in South Korea which yielded fairly well outcomes (R-2 = 0.91). These results indicate that GSV images used with a deep learning model offer an efficient and cost-effective alternative method for ground referencing, in many regions of the world.
C1 [Yan, Yulin; Ryu, Youngryel] Seoul Natl Univ, Interdisciplinary Program Agr & Forest Meteorol, Seoul, South Korea.
   [Ryu, Youngryel] Seoul Natl Univ, Dept Landscape Architecture & Rural Syst Engn, Seoul 151921, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Ryu, Y (corresponding author), Seoul Natl Univ, Dept Landscape Architecture & Rural Syst Engn, Seoul 151921, South Korea.
EM yryu@snu.ac.kr
FU "Cooperative Research Program for Agriculture Science & Technology Development", Rural Development Administration, Republic of Korea [PJ01475502]; China Scholarship Council; SNU Global Scholarship
CR [Anonymous], 2011, INTRO REMOTE SENSING, V0, P0
   Arvor D, 2011, INT J REMOTE SENS, V32, P7847, DOI 10.1080/01431161.2010.531783
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Cai YP, 2018, REMOTE SENS ENVIRON, V210, P35, DOI 10.1016/j.rse.2018.02.045
   Ciresan D. C, 2011, 22 INT JOINT C ART I, V0, P0
   Dodge S, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX), V0, P0
   Dong JW, 2016, REMOTE SENS ENVIRON, V185, P142, DOI 10.1016/j.rse.2016.02.016
   Foerster S, 2012, COMPUT ELECTRON AGR, V89, P30, DOI 10.1016/j.compag.2012.07.015
   Foga S, 2017, REMOTE SENS ENVIRON, V194, P379, DOI 10.1016/j.rse.2017.03.026
   Foody GM, 2016, ISPRS INT J GEO-INF, V5, P0, DOI 10.3390/ijgi5110199
   Foody GM, 2004, REMOTE SENS ENVIRON, V93, P107, DOI 10.1016/j.rse.2004.06.017
   Fowler J, 2020, INT J APPL EARTH OBS, V91, P0, DOI 10.1016/j.jag.2020.102114
   Frias-Martinez V, 2014, ENG APPL ARTIF INTEL, V35, P237, DOI 10.1016/j.engappai.2014.06.019
   Friedl MA, 2010, REMOTE SENS ENVIRON, V114, P168, DOI 10.1016/j.rse.2009.08.016
   Fritz S, 2019, COPERNICUS GLOBAL LA, V0, P0
   Fritz S, 2015, GLOBAL CHANGE BIOL, V21, P1980, DOI 10.1111/gcb.12838
   Fritz S, 2009, REMOTE SENS-BASEL, V1, P345, DOI 10.3390/rs1030345
   Gebru T, 2017, P NATL ACAD SCI USA, V114, P13108, DOI 10.1073/pnas.1700035114
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Graesser J, 2017, REMOTE SENS ENVIRON, V201, P165, DOI 10.1016/j.rse.2017.08.027
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Heydari SS, 2018, REMOTE SENS ENVIRON, V204, P648, DOI 10.1016/j.rse.2017.09.035
   Howard DM, 2014, PHOTOGRAMM ENG REM S, V80, P537, DOI 10.14358/PERS.80.6.537-549
   Kavzoglu T, 2009, ENVIRON MODELL SOFTW, V24, P850, DOI 10.1016/j.envsoft.2008.11.012
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   King L, 2017, REMOTE SENS ENVIRON, V195, P13, DOI 10.1016/j.rse.2017.03.047
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kun J., 2013, J APPL REMOTE SENS, V7, P1
   Li XJ, 2017, GISCI REMOTE SENS, V54, P819, DOI 10.1080/15481603.2017.1338389
   Liang Y, 2017, ICCAD-IEEE ACM INT, V0, P9
   Lillesand T., 2015, REMOTE SENSING IMAGE, V0, P0
   Liu XP, 2017, INT J GEOGR INF SCI, V31, P1675, DOI 10.1080/13658816.2017.1324976
   Long Y, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0171110
   Luo JQ, 2020, J COASTAL RES, V0, PP12, DOI 10.2112/JCR-SI108-003.1
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Massey R, 2017, REMOTE SENS ENVIRON, V198, P490, DOI 10.1016/j.rse.2017.06.033
   Munoz J.E.V., 2020, IEEE GEOSCI REMOTE S, V0, P0
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Phalke AR, 2018, REMOTE SENS ENVIRON, V219, P180, DOI 10.1016/j.rse.2018.09.025
   Rakower L.H., 2011, J INT L, V0, P317
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Ringland J, 2019, COMPUT ELECTRON AGR, V158, P36, DOI 10.1016/j.compag.2019.01.014
   Skakun S, 2017, REMOTE SENS ENVIRON, V195, P244, DOI 10.1016/j.rse.2017.04.026
   Srivastava S, 2020, INT J GEOGR INF SCI, V34, P1117, DOI 10.1080/13658816.2018.1542698
   Srivastava S, 2019, REMOTE SENS ENVIRON, V228, P129, DOI 10.1016/j.rse.2019.04.014
   Torbick N., 2018, REMOTE SENS, V10, P0
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Van Niel TG, 2005, REMOTE SENS ENVIRON, V98, P468, DOI 10.1016/j.rse.2005.08.011
   Waldner F, 2019, INT J APPL EARTH OBS, V80, P82, DOI 10.1016/j.jag.2019.01.002
   Wang S, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-00646-4
   Wang S, 2019, REMOTE SENS ENVIRON, V222, P303, DOI 10.1016/j.rse.2018.12.026
   Wardlow BD, 2008, REMOTE SENS ENVIRON, V112, P1096, DOI 10.1016/j.rse.2007.07.019
   Wardlow BD, 2007, REMOTE SENS ENVIRON, V108, P290, DOI 10.1016/j.rse.2006.11.021
   Wood SA, 2013, SCI REP-UK, V3, P0, DOI 10.1038/srep02976
   Xiao X., 2011, EOS T AM GEOPHYS UN, V92, P453, DOI 10.1029/2011EO490002
   You LZ, 2014, AGR SYST, V127, P53, DOI 10.1016/j.agsy.2014.01.002
   Zhang F, 2019, ISPRS J PHOTOGRAMM, V153, P48, DOI 10.1016/j.isprsjprs.2019.04.017
   Zhang WX, 2017, COMPUT ENVIRON URBAN, V64, P215, DOI 10.1016/j.compenvurbsys.2017.03.001
   Zhong LH, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111411
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhong LH, 2016, ISPRS J PHOTOGRAMM, V119, P151, DOI 10.1016/j.isprsjprs.2016.05.014
NR 62
TC 24
Z9 25
U1 11
U2 62
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN 15
PY 2021
VL 171
IS 
BP 278
EP 296
DI 10.1016/j.isprsjprs.2020.11.022
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PN3UD
UT WOS:000604406500019
DA 2023-04-26
ER

PT J
AU Ahmadlou, M
   Al-Fugara, A
   Al-Shabeeb, AR
   Arora, A
   Al-Adamat, R
   Pham, QB
   Al-Ansari, N
   Linh, NTT
   Sajedi, H
AF Ahmadlou, Mohammad
   Al-Fugara, A'kif
   Al-Shabeeb, Abdel Rahman
   Arora, Aman
   Al-Adamat, Rida
   Quoc Bao Pham
   Al-Ansari, Nadhir
   Nguyen Thi Thuy Linh
   Sajedi, Hedieh
TI Flood susceptibility mapping and assessment using a novel deep learning model combining multilayer perceptron and autoencoder neural networks
SO JOURNAL OF FLOOD RISK MANAGEMENT
LA English
DT Article
DE deep learning; flood susceptibility; GIS; mapping; multilayer perceptron
ID multicriteria decision-making; spatial prediction; artificial-intelligence; statistical-models; frequency ratio; river catchment; bivariate; area; regression; city
AB Floods are one of the most destructive natural disasters causing financial damages and casualties every year worldwide. Recently, the combination of data-driven techniques with remote sensing (RS) and geographical information systems (GIS) has been widely used by researchers for flood susceptibility mapping. This study presents a novel hybrid model combining the multilayer perceptron (MLP) and autoencoder models to produce the susceptibility maps for two study areas located in Iran and India. For two cases, nine, and twelve factors were considered as the predictor variables for flood susceptibility mapping, respectively. The prediction capability of the proposed hybrid model was compared with that of the traditional MLP model through the area under the receiver operating characteristic (AUROC) criterion. The AUROC curve for the MLP and autoencoder-MLP models were, respectively, 75 and 90, 74 and 93% in the training phase and 60 and 91, 81 and 97% in the testing phase, for Iran and India cases, respectively. The results suggested that the hybrid autoencoder-MLP model outperformed the MLP model and, therefore, can be used as a powerful model in other studies for flood susceptibility mapping.
C1 [Ahmadlou, Mohammad] KN Toosi Univ Technol, Geodesy & Geomat Fac, GIS Dept, Tehran, Iran.
   [Al-Fugara, A'kif] Al al Bayt Univ, Fac Engn, Dept Surveying Engn, Mafraq, Jordan.
   [Al-Shabeeb, Abdel Rahman; Al-Adamat, Rida] Al al Bayt Univ, Inst Earth & Environm Sci, Dept GIS & Remote Sensing, Mafraq, Jordan.
   [Arora, Aman] Fac Nat Sci, Dept Geog, New Delhi, India.
   [Quoc Bao Pham] Ton Duc Thang Univ, Environm Qual Atmospher Sci & Climate Change Res, Ho Chi Minh City, Vietnam.
   [Quoc Bao Pham] Ton Duc Thang Univ, Fac Environm & Labour Safety, Ho Chi Minh City, Vietnam.
   [Al-Ansari, Nadhir] Lulea Univ Technol, Dept Civil Environm & Nat Resources Engn, S-97187 Lulea, Sweden.
   [Nguyen Thi Thuy Linh] Duy Tan Univ, Inst Res & Dev, Danang 550000, Vietnam.
   [Nguyen Thi Thuy Linh] Duy Tan Univ, Fac Environm & Chem Engn, Danang 550000, Vietnam.
   [Sajedi, Hedieh] Univ Tehran, Coll Sci, Sch Math, Dept Comp Sci, Tehran, Iran.
C3 K. N. Toosi University of Technology; Al al-Bayt University; Al al-Bayt University; Ton Duc Thang University; Ton Duc Thang University; Lulea University of Technology; Duy Tan University; Duy Tan University; University of Tehran
RP Pham, QB (corresponding author), Ton Duc Thang Univ, Environm Qual Atmospher Sci & Climate Change Res, Ho Chi Minh City, Vietnam.
EM phambaoquoc@tdtu.edu.vn
CR Abbas A, 2015, NAT HAZARDS, V75, P2119, DOI 10.1007/s11069-014-1415-x
   Ahmadlou M, 2019, GEOCARTO INT, V34, P1252, DOI 10.1080/10106049.2018.1474276
   Ali SA, 2020, ECOL INDIC, V117, P0, DOI 10.1016/j.ecolind.2020.106620
   [Anonymous], 1998, FLOODS PHYS PROCESSE, V0, P0
   [Anonymous], 2010, J SPAT HYDROL, V0, P0
   Arabameri A, 2019, SCI TOTAL ENVIRON, V660, P443, DOI 10.1016/j.scitotenv.2019.01.021
   Arora A, 2021, GEOCARTO INT, V36, P2085, DOI 10.1080/10106049.2019.1687594
   Baz I, 2009, ADV ENG SOFTW, V40, P128, DOI 10.1016/j.advengsoft.2008.03.016
   Bhatt CM, 2016, GEOMAT NAT HAZ RISK, V7, P747, DOI 10.1080/19475705.2014.949877
   Bracken LJ, 2008, HYDROL PROCESS, V22, P683, DOI 10.1002/hyp.6641
   Cao B, 2020, IEEE T FUZZY SYST, V28, P939, DOI 10.1109/TFUZZ.2020.2972207
   Chao LJ, 2018, J HYDROL, V558, P275, DOI 10.1016/j.jhydrol.2018.01.042
   Chapi K, 2017, ENVIRON MODELL SOFTW, V95, P229, DOI 10.1016/j.envsoft.2017.06.012
   Chen M, 2017, IEEE TRANS BIG DATA, VPP, P1, DOI 10.1109/tbdata.2017.2717439
   Chicco D., 2014, P 5 ACM C BIOINF COM, V0, PP533, DOI 10.1145/2649387
   Costache R, 2020, J HYDROL, V585, P0, DOI 10.1016/j.jhydrol.2020.124808
   Costache R, 2020, J ENVIRON MANAGE, V265, P0, DOI 10.1016/j.jenvman.2020.110485
   Costache R, 2020, SCI TOTAL ENVIRON, V712, P0, DOI 10.1016/j.scitotenv.2019.136492
   Costache R, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.134514
   Costache R, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104179
   Costache R, 2019, SCI TOTAL ENVIRON, V691, P1098, DOI 10.1016/j.scitotenv.2019.07.197
   Costache R, 2019, SCI TOTAL ENVIRON, V659, P1115, DOI 10.1016/j.scitotenv.2018.12.397
   Dassanayake DR, 2015, COAST ENG J, V57, P0, DOI 10.1142/S0578563415400070
   Diaz JH, 2006, J TRAVEL MED, V13, P361, DOI 10.1111/j.1708-8305.2006.00072.x
   Bui DT, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134413
   Bui DT, 2016, J HYDROL, V540, P317, DOI 10.1016/j.jhydrol.2016.06.027
   Elnazer AA, 2017, NAT HAZARDS, V89, P1389, DOI 10.1007/s11069-017-3030-0
   Fernandez DS, 2010, ENG GEOL, V111, P90, DOI 10.1016/j.enggeo.2009.12.006
   GAILLARD J., 2007, DISASTER PREVENTION, V16, P522, DOI 10.1108/09653560710817011
   Gajbhiye S, 2014, APPL WATER SCI, V4, P51, DOI 10.1007/s13201-013-0129-7
   Garmdareh ES, 2018, HYDROLOG SCI J, V63, P426, DOI 10.1080/02626667.2018.1432056
   Hernandez E, 2016, LECT NOTES ARTIF INT, V9648, P151, DOI 10.1007/978-3-319-32034-2_13
   Hong HY, 2018, SCI TOTAL ENVIRON, V625, P575, DOI 10.1016/j.scitotenv.2017.12.256
   Hong HY, 2018, SCI TOTAL ENVIRON, V621, P1124, DOI 10.1016/j.scitotenv.2017.10.114
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Janizadeh S, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11195426
   JUDI DR, 2018, WATER SUI, V10, P0
   Kadam P., 2012, J HYDRAULIC ENG, V18, P129, DOI 10.1080/09715010.2012.695449
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Khosravi K, 2016, NAT HAZARDS, V83, P947, DOI 10.1007/s11069-016-2357-2
   Kia MB, 2012, ENVIRON EARTH SCI, V67, P251, DOI 10.1007/s12665-011-1504-z
   Kourgialas NN, 2017, SCI TOTAL ENVIRON, V601, P441, DOI 10.1016/j.scitotenv.2017.05.197
   Kousky C, 2018, RISK MANAG INSUR REV, V21, P11, DOI 10.1111/RMIR.12090
   Lee S, 2006, ENVIRON GEOL, V50, P847, DOI 10.1007/s00254-006-0256-7
   Lee S, 2017, GEOMAT NAT HAZ RISK, V8, P1185, DOI 10.1080/19475705.2017.1308971
   Li KZ, 2012, NAT HAZARDS, V63, P737, DOI 10.1007/s11069-012-0180-y
   Lv ZH, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106300
   Nair V, 2010, ICML, V27, P807
   Oh HJ, 2011, J HYDROL, V399, P158, DOI 10.1016/j.jhydrol.2010.12.027
   Pachauri R.K., 2014, CLIMATE CHANGE 2014, V0, P0
   Pourghasemi H., 2012, TERRIGENOUS MASS MOV, V0, P0, DOI DOI 10.1007/978-3-642-25495-6_2
   Prado Oliveira Tiago, 2014, NETWORK AND PARALLEL COMPUTING. 11TH IFIP WG 10.3 INTERNATIONAL CONFERENCE, V0, P61, DOI 10.1007/978-3-662-44917-2_6
   Quan Q, 2022, NEURAL COMPUT APPL, V34, P8501, DOI 10.1007/s00521-020-04836-4
   Rahmati O, 2016, GEOCARTO INT, V31, P42, DOI 10.1080/10106049.2015.1041559
   SCHUMM SA, 1965, AM J SCI, V263, P110, DOI 10.2475/ajs.263.2.110
   Shafizadeh-Moghadam H, 2018, J ENVIRON MANAGE, V217, P1, DOI 10.1016/j.jenvman.2018.03.089
   Shafizadeh-Moghadam H, 2017, GISCI REMOTE SENS, V54, P639, DOI 10.1080/15481603.2017.1309125
   Shaluf I.M., 2007, DISASTER PREV MANAG, V16, P704, DOI 10.1108/09653560710837019
   Shi KB, 2020, FUZZY SET SYST, V381, P1, DOI 10.1016/j.fss.2018.11.017
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Souissi D, 2020, GEOCARTO INT, V35, P991, DOI 10.1080/10106049.2019.1566405
   Sun WJ, 2016, MEASUREMENT, V89, P171, DOI 10.1016/j.measurement.2016.04.007
   Talukdar S, 2020, STOCH ENV RES RISK A, V34, P2277, DOI 10.1007/s00477-020-01862-5
   Tang ZQ, 2018, STOCH ENV RES RISK A, V32, P701, DOI 10.1007/s00477-017-1431-y
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Tehrany MS, 2014, ENVIRON EARTH SCI, V72, P4001, DOI 10.1007/s12665-014-3289-3
   Tehrany MS, 2013, J HYDROL, V504, P69, DOI 10.1016/j.jhydrol.2013.09.034
   Teng WH, 2006, NAT HAZARDS, V37, P191, DOI 10.1007/s11069-005-4667-7
   Termeh SVR, 2018, SCI TOTAL ENVIRON, V615, P438, DOI 10.1016/j.scitotenv.2017.09.262
   Testa G, 2007, J HYDRAUL RES, V45, P37, DOI 10.1080/00221686.2007.9521831
   van Alphen J, 2006, FLOODS, V0, P0
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang S, 2020, ENVIRON MODELL SOFTW, V124, P0, DOI 10.1016/j.envsoft.2019.104607
   Wang ZL, 2015, J HYDROL, V527, P1130, DOI 10.1016/j.jhydrol.2015.06.008
   Yang L, 2019, NEURAL COMPUT APPL, V31, P4463, DOI 10.1007/s00521-018-3525-y
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yariyan P, 2020, WATER RESOUR MANAG, V34, P3037, DOI 10.1007/s11269-020-02603-7
   Youssef AM, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4830-8
   Zeiler MD, 2013, INT CONF ACOUST SPEE, V0, PP3517, DOI 10.1109/ICASSP.2013.6638312
   Zurada, 1992, INTRO ARTIFICIAL NEU, V0, P0
NR 81
TC 39
Z9 39
U1 3
U2 35
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1753-318X
EI 
J9 J FLOOD RISK MANAG
JI J. Flood Risk Manag.
PD MAR 15
PY 2021
VL 14
IS 1
BP 
EP 
DI 10.1111/jfr3.12683
EA DEC 2020
PG 22
WC Environmental Sciences; Water Resources
SC Environmental Sciences & Ecology; Water Resources
GA QK9MU
UT WOS:000599620700001
DA 2023-04-26
ER

PT J
AU Yu, DW
   Ji, SP
   Liu, J
   Wei, SQ
AF Yu, Dawen
   Ji, Shunping
   Liu, Jin
   Wei, Shiqing
TI Automatic 3D building reconstruction from multi-view aerial images with deep learning
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE 3D building reconstruction; Multi-view aerial images; Convolutional neural network; Earth surface reconstruction; Building segmentation; Building footprint regularization
ID semantic segmentation; dsm; models; extraction; networks
AB The study presented in this paper introduced a new fully automatic three-dimensional building reconstruction method that can generate first level of detail (LoD 1) building models from multi-view aerial images without any assistance from other data. The accuracy and completeness of our reconstructed models have approached that of manually delineated models to a large extent. The presented method consists of three parts: (1) efficient dense matching and Earth surface reconstruction, (2) reliable building footprint extraction and polygon regularization, and (3) highly accurate height inference of building roofs and bases. First, our novel deep learning-based multi-view matching method, composed of a convolutional neural network, gated recurrent convolutions, and a multi-scale pyramid matching structure, is used to reconstruct the digital surface model (DSM) and digital orthophoto map (DOM) efficiently without generating epipolarly rectified images. Second, our three-stage 2D building extraction method is introduced to deliver reliable and accurate building contours. Deep-learning based segmentation, assisted with DSM, is used to segment buildings from backgrounds; and the generated building maps are fused with a terrain classification algorithm to reach better segmentation results. A polygon regularization algorithm and a level set algorithm are thereafter employed to transfer the binary segmentation maps to structured vector-form building polygons. Third, a novel method is introduced to infer the height of building roofs and bases using adaptive local terrain filtering and neighborhood buffer analysis. We tested our method on a large experimental area that covered 2284 aerial images and 782 various types of buildings. Our results as far as correctness and completeness exceeded the results of other similar methods in a between-method comparison by at least 15% for individual 3D building models with many of them comparable to manual delineation results.
C1 [Yu, Dawen; Ji, Shunping; Liu, Jin; Wei, Shiqing] Wuhan Univ, Sch Remote Sensing Informat & Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Ji, SP (corresponding author), Wuhan Univ, Sch Remote Sensing Informat & Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
EM yudawen@whu.edu.cn; jishunping@whu.edu.cn; wei_sq@whu.edu.cn
FU National Key Research and Development Program of China [2018YFB0505003]; Huawei Company [YBN2018095106]
CR Aanaes H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9
   Alidoost F, 2015, INT ARCH PHOTOGRAMM, V41, P43, DOI 10.5194/isprsarchives-XL-1-W5-43-2015
   Alidoost F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192219
   Anders, 1996, INT ARCH PHOTOGRAM R, V31, P285
   [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   [Anonymous], 2012, ISPRS ANN PHOTOGRAM, V0, P0
   Arefi H, 2013, REMOTE SENS-BASEL, V5, P1681, DOI 10.3390/rs5041681
   Bethmann F, 2017, PFG-J PHOTOGRAMM REM, V85, P349, DOI 10.1007/s41064-017-0034-z
   Bittner K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121926
   Bittner K, 2018, IEEE J-STARS, V11, P2615, DOI 10.1109/JSTARS.2018.2849363
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, V0, P0, DOI DOI 10.5244/C.25.14
   Bulatov D, 2014, ISPRS J PHOTOGRAMM, V93, P157, DOI 10.1016/j.isprsjprs.2014.02.016
   Cao ZY, 2019, IEEE GEOSCI REMOTE S, V16, P1766, DOI 10.1109/LGRS.2019.2907009
   Cavegn S., 2015, EXTRACTING 3D URBAN, V0, P1
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang JR, 2018, PROC CVPR IEEE, V0, PP5410, DOI 10.1109/CVPR.2018.00567
   Chen D., 2020, ARXIV200309934, V0, P0
   Collins RT, 1996, PROC CVPR IEEE, V0, PP358, DOI 10.1109/CVPR.1996.517097
   Douglas D. H., 1973, CARTOGRAPHICA INT J, V10, P112, DOI 10.3138/FM57-6770-U75U-7727
   Geiger A., 2012, C COMP VIS PATT REC, V0, P0
   Groger G, 2012, ISPRS J PHOTOGRAMM, V71, P12, DOI 10.1016/j.isprsjprs.2012.04.004
   Groger G., 2007, OPENGIS CITY GEOGRAP, V0, P0
   Gu XD, 2020, PROC CVPR IEEE, V0, PP2492, DOI 10.1109/CVPR42600.2020.00257
   Haala N, 2010, ISPRS J PHOTOGRAMM, V65, P570, DOI 10.1016/j.isprsjprs.2010.09.006
   Hammoudi K, 2011, SENSORS-BASEL, V11, P228, DOI 10.3390/s110100228
   Hansen, 2005, INT ARCH PHOTOGRAM 3, V36, P0
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jayaraj P., 2018, INT ARCH PHOTOGRAMM, V5, P175, DOI 10.5194/isprs-archives-XLII-5-175-2018
   Ji SP, 2019, INT J REMOTE SENS, V40, P3308, DOI 10.1080/01431161.2018.1528024
   Jia B, 2012, IEEE IMAGE PROC, V0, PP1781, DOI 10.1109/ICIP.2012.6467226
   Kendall A, 2017, IEEE I CONF COMP VIS, V0, PP66, DOI 10.1109/ICCV.2017.17
   Li ML, 2016, COMPUT GRAPH-UK, V54, P84, DOI 10.1016/j.cag.2015.07.004
   Liu J, 2020, PROC CVPR IEEE, V0, PP6049, DOI 10.1109/CVPR42600.2020.00609
   Lorensen W.E., 1987, P 14 ANN C COMPUTER, V0, PP163, DOI 10.1145/37402.37422
   Moreira JMM, 2013, INT ARCH PHOTOGRAMM, V40-1, P213
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   MALIHI S, 2016, ISPRS INT ARCH PHO B, V3, P71
   Maltezos E, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042620
   Mayer H., 2019, ISPRS ANN PHOTOGRAM, V4, P0
   Mayer N, 2016, PROC CVPR IEEE, V0, PP4040, DOI 10.1109/CVPR.2016.438
   McClune AP, 2016, INT ARCH PHOTOGRAMM, V41, P641, DOI 10.5194/isprsarchives-XLI-B3-641-2016
   Mousa YA, 2019, PHOTOGRAMM REC, V34, P85, DOI 10.1111/phor.12275
   Nan LL, 2017, IEEE I CONF COMP VIS, V0, PP2372, DOI 10.1109/ICCV.2017.258
   Neumann U., 2010, COMP VIS ECCV 2010 3, V0, P0
   Perko R, 2015, ISPRS ANN PHOTO REM, V2-3, P165, DOI 10.5194/isprsannals-II-3-W4-165-2015
   Pohl Melanie, 2016, VISIGRAPP 2016. 11TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, V0, P59
   Pohl M, 2017, LECT NOTES COMPUT SC, V10270, P3, DOI 10.1007/978-3-319-59129-2_1
   Qin Z., 2018, INT ARCH PHOTOGRAMME, V42, P0
   Rothermel M., 2012, P P LC3D WORKSH BERL, V8, P0
   Rottensteiner F, 2014, ISPRS J PHOTOGRAMM, V93, P256, DOI 10.1016/j.isprsjprs.2013.10.004
   Rutzinger M, 2009, IEEE J-STARS, V2, P11, DOI 10.1109/JSTARS.2009.2012488
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Schonberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Shamos M.I., 1985, COMPUTATIONAL GEOMET, V0, P0
   Stucker C., 2020, P IEEE CVF C COMP VI, V0, P184
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tack F, 2012, ISPRS J PHOTOGRAMM, V67, P52, DOI 10.1016/j.isprsjprs.2011.10.003
   Wei SQ, 2020, IEEE T GEOSCI REMOTE, V58, P2178, DOI 10.1109/TGRS.2019.2954461
   Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131
   Wu ZY, 2019, IEEE I CONF COMP VIS, V0, PP7483, DOI 10.1109/ICCV.2019.00758
   Xiong B, 2015, ISPRS J PHOTOGRAMM, V101, P275, DOI 10.1016/j.isprsjprs.2015.01.002
   Xu HF, 2020, PROC CVPR IEEE, V0, PP1956, DOI 10.1109/CVPR42600.2020.00203
   Yan YM, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17020222
   Yang, 2019, IEEE ACCESS, V7, P0
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yao Y, 2019, PROC CVPR IEEE, V0, PP5520, DOI 10.1109/CVPR.2019.00567
   Yu D., 2020, ISPRS INT ARCH PHOTO, V43, P541, DOI 10.5194/isprs-archives-XLIII-B2-2020-541-2020
   Zbontar J, 2016, J MACH LEARN RES, V17, P0
   Zeng CQ, 2014, INT J REMOTE SENS, V35, P7614, DOI 10.1080/01431161.2014.975375
   Zhang FH, 2019, PROC CVPR IEEE, V0, PP185, DOI 10.1109/CVPR.2019.00027
NR 72
TC 39
Z9 42
U1 39
U2 114
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN 15
PY 2021
VL 171
IS 
BP 155
EP 170
DI 10.1016/j.isprsjprs.2020.11.011
PG 16
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PN3UD
UT WOS:000604406500011
DA 2023-04-26
ER

PT J
AU Vemulapalli, SC
   Mesapam, S
AF Vemulapalli, Sai Charitha
   Mesapam, Shashi
TI Slope Stability Analysis for Mine Hazard Assessment Using UAV
SO JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING
LA English
DT Article
DE Artificial neural networks; Mines; Slope stability; Unmanned air vehicles (UAV)
AB Slopes in open-pit mines are excavated to the steepest feasible angle for maximum profits, which involves a great risk of failure. Unmanned Air Vehicles (UAV) are emerging as new technology to provide information at a high spatial resolution which leads to fast and accurate qualitative results that can be used for stability analysis. The acquired images from the UAV flight plan are processed to produce Digital Elevation Model (DEM). Parameters of slope instability derived from DEM, namely slope, aspect along with inventory maps are fed as an input to Artificial Neural Network (ANN) models. ANNs have the ability to learn and generalize the knowledge on unseen data. Opencast mines in different areas are selected as training sites using random sampling. A feedforward back-propagation algorithm is implemented to analyze slope susceptibility, and the area is classified into four hazard-prone zones. Four input parameters, namely slope, aspect, drainage density and geological structures, are trained using the algorithm. The factors are rated based on the role played by each of them in causing slope failure. 20% of the training sites are selected for testing and 20% for validation purpose. Hazard-prone zones provide useful information regarding possible future which helps in drawing up measures for mitigation.
C1 [Vemulapalli, Sai Charitha; Mesapam, Shashi] NIT Warangal, Dept Civil Engn, Warangal 506004, Andhra Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Warangal
RP Mesapam, S (corresponding author), NIT Warangal, Dept Civil Engn, Warangal 506004, Andhra Pradesh, India.
EM vemulapallisai@student.nitw.ac.in; mshashi@nitw.ac.in
FU Terra drone Pvt Ltd
CR Aleotti P., 1999, B ENG GEOL ENVIRON, V58, P21, DOI 10.1007/s100640050066
   Arora MK, 2004, INT J REMOTE SENS, V25, P559, DOI 10.1080/0143116031000156819
   Chauhan S, 2010, INT J APPL EARTH OBS, V12, P340, DOI 10.1016/j.jag.2010.04.006
   Koeva M, 2018, SURV REV, V50, P312, DOI 10.1080/00396265.2016.1268756
   Liu S., 2016, ELECTRON J GEOTECH E, V21, P7613
   Oguz, 2018, GEOD LIST, V0, P0, DOI DOI 10.5194/nhess-2018-13
   Rahul, 2015, GEOMECH GEOPHYS GEO-, V1, P69, DOI 10.1007/s40948-015-0009-8
   Riping, 2007, APPL REMOTE SENSING, V0, P55
   Sengupta S, 2018, J EARTH SYST SCI, V127, P0, DOI 10.1007/s12040-018-0982-8
   Tsangaratos P., 2013, B GEOL SOC GREECE, V47, P1901, DOI 10.12681/BGSG.10945
   Uysal M, 2015, MEASUREMENT, V73, P539, DOI 10.1016/j.measurement.2015.06.010
NR 11
TC 2
Z9 2
U1 3
U2 25
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0255-660X
EI 0974-3006
J9 J INDIAN SOC REMOTE
JI J. Indian Soc. Remote Sens.
PD JUL 15
PY 2021
VL 49
IS 7
BP 1483
EP 1491
DI 10.1007/s12524-020-01239-9
EA FEB 2021
PG 9
WC Environmental Sciences; Remote Sensing
SC Environmental Sciences & Ecology; Remote Sensing
GA TL2DR
UT WOS:000619753900002
DA 2023-04-26
ER
