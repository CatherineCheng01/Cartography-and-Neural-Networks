
PT J
AU Zeng, PY
   Song, X
   Yang, H
   Wei, N
   Du, LP
AF Zeng, Pengyuan
   Song, Xuan
   Yang, Huan
   Wei, Ning
   Du, Liping
TI Digital Soil Mapping of Soil Organic Matter with Deep Learning Algorithms
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE digital soil mapping (DSM); soil organic matter (SOM); deep learning (DL); resnet; remote sensing
ID geographically weighted regression; artificial neural-network; spatial-distribution; regional-scale; total nitrogen; carbon stocks; baneh region; river-basin; prediction; vegetation
AB Digital soil mapping has emerged as a new method to describe the spatial distribution of soils economically and efficiently. In this study, a lightweight soil organic matter (SOM) mapping method based on a deep residual network, which we call LSM-ResNet, is proposed to make accurate predictions with background covariates. ResNet not only integrates spatial background information around the observed environmental covariates, but also reduces problems such as information loss, which undermines the integrity of information and reduces prediction uncertainty. To train the model, rectified linear units, mean squared error, and adaptive momentum estimation were used as the activation function, loss/cost function, and optimizer, respectively. The method was tested with Landsat5, the meteorological data from WorldClim, and the 1602 sampling points set from Xinxiang, China. The performance of the proposed LSM-ResNet was compared to a traditional machine learning algorithm, the random forest (RF) algorithm, and a training set (80%) and a test set (20%) were created to test both models. The results showed that the LSM-ResNet (RMSE = 6.40, R-2 = 0.51) model outperformed the RF model in both the roots mean square error (RMSE) and coefficient of determination (R-2), and the training accuracy was significantly improved compared to RF (RMSE = 6.81, R-2 = 0.46). The trained LSM-ResNet model was used for SOM prediction in Xinxiang, a district of plain terrain in China. The prediction maps can be deemed an accurate reflection of the spatial variability of the SOM distribution.
C1 [Zeng, Pengyuan; Song, Xuan] Zhengzhou Univ, Sch Cyber Sci & Engn, Zhengzhou 450001, Peoples R China.
   [Yang, Huan; Wei, Ning] Zhengzhou Univ, Sch Water Conservancy Sci & Engn, Zhengzhou 450001, Peoples R China.
   [Du, Liping] Zhengzhou Univ, Sch Civil Engn, Zhengzhou 450001, Peoples R China.
C3 Zhengzhou University; Zhengzhou University; Zhengzhou University
RP Song, X (corresponding author), Zhengzhou Univ, Sch Cyber Sci & Engn, Zhengzhou 450001, Peoples R China.
EM pengyuanzeng@163.com; songxuan@zzu.edu.cn; huanyang_zzu@163.com; 13283883207@163.com; dulp@zzu.edu.cn
FU National Key Research and Development Program of China [2017YFD0800605]
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   [Anonymous], 1967, RUSSIAN CHERNOZEM SE, V0, P0
   [Anonymous], 2017, ARXIV, V0, P0
   [Anonymous], 2018, GUIDE CONVOLUTION AR, V0, P0
   Arrouays D, 2014, ADV AGRON, V125, P93, DOI 10.1016/B978-0-12-800137-0.00003-0
   Behrens T, 2018, GEODERMA, V310, P128, DOI 10.1016/j.geoderma.2017.09.015
   Behrens T, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-33516-6
   Behrens T, 2010, GEODERMA, V155, P175, DOI 10.1016/j.geoderma.2009.07.010
   Beven K., 1979, HYDROLOG SCI J, V24, P43, DOI 10.1080/02626667909491834
   Bot A., 2005, FOOD AGR ORG, V0, P0
   Chen D, 2019, SCI TOTAL ENVIRON, V669, P844, DOI 10.1016/j.scitotenv.2019.03.151
   Ciresan D, 2012, PROC CVPR IEEE, V0, PP3642, DOI 10.1109/CVPR.2012.6248110
   Cressie N, 2008, J R STAT SOC B, V70, P209, DOI 10.1111/j.1467-9868.2007.00633.x
   CRGCST (Cooperative Research Group on Chinese Soil Taxonomy), 2001, KEYS CHIN SOIL TAX, V0, P0
   Fick SE, 2017, INT J CLIMATOL, V37, P4302, DOI 10.1002/joc.5086
   Garajeh MK, 2021, SCI TOTAL ENVIRON, V778, P0, DOI 10.1016/j.scitotenv.2021.146253
   Guo PT, 2013, NUTR CYCL AGROECOSYS, V95, P333, DOI 10.1007/s10705-013-9566-9
   He K., 2016, PROC IEEE C COMPUT V, V0, P770
   Hengl T., 2004, INT J APPL EARTH OBS, V5, P97, DOI 10.1016/J.JAG.2004.01.006
   Hengl T, 2007, COMPUT GEOSCI-UK, V33, P1301, DOI 10.1016/j.cageo.2007.05.001
   Hengl T, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0169748
   Heung B, 2016, GEODERMA, V265, P62, DOI 10.1016/j.geoderma.2015.11.014
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2
   Jenny H., 1941, FACTORS SOIL FORMATI, V0, P0, DOI DOI 10.1097/00010694-194111000-00009
   Kane DA, 2021, ENVIRON RES LETT, V16, P0, DOI 10.1088/1748-9326/abe492
   Ketkar Nikhil, 2017, DEEP LEARNING PYTHON, V0, P97
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2011, J ENVIRON MONITOR, V13, P3128, DOI 10.1039/c1em10520e
   Kumhalova J, 2011, PRECIS AGRIC, V12, P813, DOI 10.1007/s11119-011-9221-x
   Lee H., 2009, P 26 ANN INT C MACH, V0, PP609, DOI 10.1145/1553374.1553453
   Li QQ, 2013, CATENA, V104, P210, DOI 10.1016/j.catena.2012.11.012
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   Lin M., 2014, ARXIV, V0, P0
   Long J., 2015, P IEEE C COMPUTER VI, V0, PP3431, DOI 10.48550/ARXIV.1411.4038
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   McLauchlan K, 2006, ECOSYSTEMS, V9, P1364, DOI 10.1007/s10021-005-0135-1
   Meersmans J, 2008, GEODERMA, V143, P1, DOI 10.1016/j.geoderma.2007.08.025
   Mondal A, 2017, EGYPT J REMOTE SENS, V20, P61, DOI 10.1016/j.ejrs.2016.06.004
   Padarian J, 2019, SOIL-GERMANY, V5, P79, DOI 10.5194/soil-5-79-2019
   RICHARDSON AJ, 1977, PHOTOGRAMM ENG REM S, V43, P1541
   Rouse J.W., 1974, NASA SPECIAL PUBLICA, V0, P309
   Snoek J, 2012, 25 INT C NEURAL INFO, V25, P0
   Song W, 2018, INT CONF DAT MIN WOR, V0, PP795, DOI 10.1109/ICDMW.2018.00119
   Song XD, 2016, GEODERMA, V261, P11, DOI 10.1016/j.geoderma.2015.06.024
   Sun Y, 2013, PROC CVPR IEEE, V0, PP3476, DOI 10.1109/CVPR.2013.446
   Szegedy C., 1900, P1, V0, P0
   Taghizadeh-Mehrjardi R, 2020, GEODERMA, V376, P0, DOI 10.1016/j.geoderma.2020.114552
   Taghizadeh-Mehrjardi R, 2016, GEODERMA, V266, P98, DOI 10.1016/j.geoderma.2015.12.003
   Taghizadeh-Mehrjardi R, 2015, GEODERMA, V253, P67, DOI 10.1016/j.geoderma.2015.04.008
   Taghizadeh-Mehrjardi R, 2020, EUR J SOIL SCI, V71, P352, DOI 10.1111/ejss.12893
   Tsakiridis NL, 2020, GEODERMA, V367, P0, DOI 10.1016/j.geoderma.2020.114208
   Veres M, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, V0, PP8, DOI 10.1109/CRV.2015.15
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wadoux AMJC, 2020, EARTH-SCI REV, V210, P0, DOI 10.1016/j.earscirev.2020.103359
   Wadoux AMJC, 2019, SOIL-GERMANY, V5, P107, DOI 10.5194/soil-5-107-2019
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang K, 2013, APPL GEOGR, V42, P73, DOI 10.1016/j.apgeog.2013.04.002
   Wang S, 2017, GEODERMA, V305, P250, DOI 10.1016/j.geoderma.2017.05.048
   Wei JB, 2006, ENVIRON MONIT ASSESS, V121, P597, DOI 10.1007/s10661-005-9158-5
   Were K, 2015, ECOL INDIC, V52, P394, DOI 10.1016/j.ecolind.2014.12.028
   Wiesmeier M, 2011, PLANT SOIL, V340, P7, DOI 10.1007/s11104-010-0425-z
   Wu TJ, 2019, IEEE J-STARS, V12, P1091, DOI 10.1109/JSTARS.2019.2902375
   Wu W, 2018, COMPUT ELECTRON AGR, V144, P86, DOI 10.1016/j.compag.2017.11.037
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Yang L, 2016, SOIL SCI SOC AM J, V80, P637, DOI 10.2136/sssaj2015.08.0285
   YEOMANS JC, 1988, COMMUN SOIL SCI PLAN, V19, P1467, DOI 10.1080/00103628809368027
   Zeng CY, 2016, GEODERMA, V281, P69, DOI 10.1016/j.geoderma.2016.06.033
   Zhang CY, 2019, ISPRS J PHOTOGRAMM, V148, P221, DOI 10.1016/j.isprsjprs.2019.01.006
   Zhang F, 2006, BIOGEOSCIENCES, V3, P451, DOI 10.5194/bg-3-451-2006
   Zhang JH, 2014, GEOMORPHOLOGY, V216, P114, DOI 10.1016/j.geomorph.2014.03.030
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang TY, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13081452
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 74
TC 1
Z9 1
U1 15
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD MAY 15
PY 2022
VL 11
IS 5
BP 
EP 
DI 10.3390/ijgi11050299
PG 19
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA 1P1HG
UT WOS:000801768200001
DA 2023-04-26
ER

PT J
AU Rana, K
   Malik, N
   Ozturk, U
AF Rana, Kamal
   Malik, Nishant
   Ozturk, Ugur
TI Landsifier v1.0: a Python library to estimate likely triggers of mapped landslides
SO NATURAL HAZARDS AND EARTH SYSTEM SCIENCES
LA English
DT Article
ID earthquake
AB Landslide hazard models aim at mitigating landslide impact by providing probabilistic forecasting, and the accuracy of these models hinges on landslide databases for model training and testing. Landslide databases at times lack information on the underlying triggering mechanism, making these inventories almost unusable in hazard models. We developed a Python-based unique library, Landsifier, that contains three different machine-Learning frameworks for assessing the likely triggering mechanisms of individual landslides or entire inventories based on landslide geometry. Two of these methods only use the 2D landslide planforms, and the third utilizes the 3D shape of landslides relying on an underlying digital elevation model (DEM). The base method extracts geometric properties of landslide polygons as a feature space for the shallow learner - random forest (RF). An alternative method relies on landslide planform images as an input for the deep learning algorithm - convolutional neural network (CNN). The last framework extracts topological properties of 3D landslides through topological data analysis (TDA) and then feeds these properties as a feature space to the random forest classifier. We tested all three interchangeable methods on several inventories with known triggers spread over the Japanese archipelago. To demonstrate the effectiveness of developed methods, we used two testing configurations. The first configuration merges all the available data for the k-fold cross-validation, whereas the second configuration excludes one inventory during the training phase to use as the sole testing inventory. Our geometric-feature-based method performs satisfactorily, with classification accuracies varying between 67 % and 92 %. We have introduced a more straightforward but data-intensive CNN alternative, as it inputs only landslide images without manual feature selection. CNN eases the scripting process without losing classification accuracy. Using topological features from 3D landslides (extracted through TDA) in the RF classifier improves classification accuracy by 12 % on average. TDA also requires less training data. However, the landscape autocorrelation could easily bias TDA-based classification. Finally, we implemented the three methods on an inventory without any triggering information to showcase a real-world application.
C1 [Rana, Kamal; Ozturk, Ugur] GFZ German Res Ctr Geosci, Helmholtz Ctr Potsdam, Potsdam, Germany.
   [Rana, Kamal] Rochester Inst Technol, Chester F Carlson Ctr Imaging Sci, Rochester, NY 14623 USA.
   [Rana, Kamal; Ozturk, Ugur] Univ Potsdam, Inst Environm Sci & Geog, Potsdam, Germany.
   [Malik, Nishant] Rochester Inst Technol, Sch Math Sci, Rochester, NY USA.
C3 Helmholtz Association; Helmholtz-Center Potsdam GFZ German Research Center for Geosciences; Rochester Institute of Technology; University of Potsdam; Rochester Institute of Technology
RP Rana, K (corresponding author), GFZ German Res Ctr Geosci, Helmholtz Ctr Potsdam, Potsdam, Germany.; Rana, K (corresponding author), Rochester Inst Technol, Chester F Carlson Ctr Imaging Sci, Rochester, NY 14623 USA.; Rana, K (corresponding author), Univ Potsdam, Inst Environm Sci & Geog, Potsdam, Germany.
EM kr7843@rit.edu
FU German Academic Exchange Service; Co-PREPARE [57553291]; German Academic Exchange Service~(DAAD); Rochester Institute of Technology's (RIT) Steven~M.~Wear Endowed Graduate Fellowship; RIT's FEAD; Earth and Environmental Systems of the University of Potsdam
CR Adams H, 2017, J MACH LEARN RES, V18, P0
   Albawi S, 2017, I C ENG TECHNOL, V0, P0
   Amato G, 2021, INT J APPL EARTH OBS, V104, P0, DOI 10.1016/j.jag.2021.102549
   Aurisano A, 2016, J INSTRUM, V11, P0, DOI 10.1088/1748-0221/11/09/P09001
   Behling R, 2016, REMOTE SENS ENVIRON, V186, P88, DOI 10.1016/j.rse.2016.07.017
   Behling R, 2014, REMOTE SENS-BASEL, V6, P2572, DOI 10.3390/rs6032572
   Bhattacharya B, 2006, NEURAL NETWORKS, V19, P186, DOI 10.1016/j.neunet.2006.01.005
   Bil M, 2021, NAT HAZARD EARTH SYS, V21, P2581, DOI 10.5194/nhess-21-2581-2021
   Bubenik P, 2017, J SYMB COMPUT, V78, P91, DOI 10.1016/j.jsc.2016.03.009
   Carlsson G, 2009, B AM MATH SOC, V46, P255, DOI 10.1090/S0273-0979-09-01249-X
   Cruden D.M., 1996, LANDSLIDES INVESTIGA, V0, P36
   Depicker A, 2021, NAT SUSTAIN, V4, P965, DOI 10.1038/s41893-021-00757-9
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Fan XM, 2012, GEOMORPHOLOGY, V171, P58, DOI 10.1016/j.geomorph.2012.05.003
   Garin Adelie, 2019, 2019 18TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP1551, DOI 10.1109/ICMLA.2019.00256
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Gillies S., 2013, SHAPELY USER MANUAL, V0, P0
   Gorum T, 2014, QUATERNARY SCI REV, V95, P80, DOI 10.1016/j.quascirev.2014.04.032
   Guo TM, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), V0, PP721, DOI 10.1109/ICBDA.2017.8078730
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Hensel F, 2021, FRONT ARTIF INTELL, V4, P0, DOI 10.3389/frai.2021.681108
   Jones JN, 2021, J GEOPHYS RES-EARTH, V126, P0, DOI 10.1029/2021JF006067
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Li Q, 2014, I C CONT AUTOMAT ROB, V0, PP844, DOI 10.1109/ICARCV.2014.7064414
   Loche M, 2022, EARTH-SCI REV, V232, P0, DOI 10.1016/j.earscirev.2022.104125
   Lombardo L, 2021, ENG GEOL, V293, P0, DOI 10.1016/j.enggeo.2021.106288
   Lombardo L, 2022, STOCH ENV RES RISK A, V36, P2229, DOI 10.1007/s00477-021-02020-1
   Lombardo L, 2020, EARTH-SCI REV, V209, P0, DOI 10.1016/j.earscirev.2020.103318
   Lombardo L, 2019, J GEOPHYS RES-EARTH, V124, P1958, DOI 10.1029/2019JF005056
   Malamud BD, 2004, EARTH SURF PROC LAND, V29, P687, DOI 10.1002/esp.1064
   Marin RJ, 2020, ENG GEOL, V278, P0, DOI 10.1016/j.enggeo.2020.105855
   Martha TR, 2021, LANDSLIDES, V18, P2125, DOI 10.1007/s10346-021-01645-1
   Moreno M., 2022, ARXIV, V0, P0, DOI DOI 10.31223/x5vd1p
   Munch E., 2017, J LEARN ANAL, V4, P47, DOI 10.18608/jla.2017.42.6
   Oksanen J, 2005, COMPUT GEOSCI-UK, V31, P1015, DOI 10.1016/j.cageo.2005.02.014
   Ozturk U, 2021, LANDSLIDES, V18, P3119, DOI 10.1007/s10346-021-01689-3
   Ozturk U, 2021, LANDSLIDES, V18, P681, DOI 10.1007/s10346-020-01485-5
   Rana K., 2022, KAMALRANA 7843 SIFIE, V0, P0, DOI DOI 10.5281/zenodo.7332187
   Rana K, 2021, GEOPHYS RES LETT, V48, P0, DOI 10.1029/2020GL090848
   Reininghaus J, 2015, PROC CVPR IEEE, V0, PP4741, DOI 10.1109/CVPR.2015.7299106
   RODRIGUEZ E, 2005, D31639 JPL, V0, P0
   Saito H, 2018, PROG EARTH PLANET SC, V5, P0, DOI 10.1186/s40645-018-0169-6
   Samia J, 2017, LANDSLIDES, V14, P547, DOI 10.1007/s10346-016-0739-x
   Schuster R.J., 1978, 176 TRB NAT RES COUN, V0, P11
   Stumpf A, 2011, REMOTE SENS ENVIRON, V115, P2564, DOI 10.1016/j.rse.2011.05.013
   Tanyas H, 2022, NAT HAZARDS, V112, P639, DOI 10.1007/s11069-021-05199-2
   Tauzin G, 2021, J MACH LEARN RES, V22, P0
   Taylor FE, 2018, EARTH SURF PROC LAND, V43, P3164, DOI 10.1002/esp.4479
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zhu J, 2017, OPEN REPOSITORY EART, V0, P0, DOI DOI 10.3133/DS1064
NR 50
TC 1
Z9 1
U1 6
U2 6
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1561-8633
EI 1684-9981
J9 NAT HAZARD EARTH SYS
JI Nat. Hazards Earth Syst. Sci.
PD NOV 22
PY 2022
VL 22
IS 11
BP 3751
EP 3764
DI 10.5194/nhess-22-3751-2022
PG 14
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources
SC Geology; Meteorology & Atmospheric Sciences; Water Resources
GA 6P4WI
UT WOS:000890930400001
DA 2023-04-26
ER

PT J
AU Peng, Y
   Bin C
   Yin, HJ
   Zhang, YH
   Du, PJ
AF Peng, Yao
   Bin Cui
   Yin, Hujun
   Zhang, Yonghong
   Du, Peijun
TI Automatic SAR Change Detection Based on Visual Saliency and Multi-Hierarchical Fuzzy Clustering
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Visualization; Feature extraction; Radar polarimetry; Clustering algorithms; Synthetic aperture radar; Change detection algorithms; Adaptive systems; Change detection; classed-balanced adaptive focal loss; fuzzy clustering; synthetic aperture radar (SAR); visual saliency difference map
ID unsupervised change detection; log-ratio image; difference; fusion
AB Change detection based on multi-temporal synthetic aperture radar (SAR) images plays a significant role in environmental and earth observations. With the advancement in deep neural networks, existing work in the literature mainly concentrates on developing self-supervised methods to generate pseudo-labeled samples to guide the subsequent deep learning based detection. However, this way of selecting sample inevitably introduces erroneous labels and imbalance between unchanged and changed classes, thus causing deterioration in change detection performance. To mitigate these issues, we have proposed a SAR change detection network based on visual saliency and multi-hierarchical fuzzy clustering. Specifically, with multi-dimensional difference feature representations, a visual saliency based difference map is constructed for accurate difference feature extraction. By integrating neighborhood information and hierarchical clustering, the multi-hierarchical fuzzy local information C-means clustering algorithm has been developed to identify potential changed regions for sample selection. A class-balanced adaptive focal loss has further been incorporated into the network training to obtain accurate predictions. Extensive experiments and comparisons on five datasets have been performed. The proposed method has achieved averaged accuracy of 99.07% and Kappa coefficient of 79.87%, outperforming other state-of-the-art algorithms both visually and quantitatively.
C1 [Peng, Yao; Bin Cui] Nanjing Univ Posts & Telecommun, Sch Geog & Biol Informat, Nanjing 210023, Peoples R China.
   [Bin Cui; Du, Peijun] Nanjing Univ, Sch Geog & Ocean Sci, Nanjing 210023, Peoples R China.
   [Yin, Hujun] Univ Manchester, Dept Elect & Elect Engn, Manchester M13 9PL, Lancs, England.
   [Zhang, Yonghong] Chinese Acad Surveying & Mapping, Beijing 100830, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University; University of Manchester; Chinese Academy of Surveying & Mapping
RP Bin C (corresponding author), Nanjing Univ, Sch Geog & Ocean Sci, Nanjing 210023, Peoples R China.
EM pengyao0130@njupt.edu.cn; bincui@njupt.edu.cn; hujun.yin@manchester.ac.uk; yhzhang@casm.ac.cn; peijun@nju.edu.cn
FU National Natural Science Foundation of China [41874014, 41631176]; China Postdoctoral Science Foundation [2022M711546]; State Key Laboratory of Geo-Information Engineering and Key Laboratory of Surveying and Mapping Science and Geospatial Information Technology of MNR, CASM [2021-03-12]; NUPTSF [NY221034, NY220168]
CR [Anonymous], 2006, P P 14 ACM INT C MUL, V0, P0, DOI DOI 10.1145/1180639.1180824
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Cui B, 2019, REMOTE SENS LETT, V10, P488, DOI 10.1080/2150704X.2018.1562256
   [高丛珊 Gao Congshan], 2010, 遥感学报 JOURNAL OF REMOTE SENSING, V14, P710
   Gao F, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2021, IEEE J-STARS, V14, P10748, DOI 10.1109/JSTARS.2021.3120381
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Gokon H, 2015, IEEE GEOSCI REMOTE S, V12, P1277, DOI 10.1109/LGRS.2015.2392792
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li HC, 2020, ISPRS J PHOTOGRAMM, V160, P167, DOI 10.1016/j.isprsjprs.2019.12.002
   Li L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091091
   Li YQ, 2018, IMMS 2019: 2019 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND MANAGEMENT SCIENCES, V0, PP123, DOI 10.1145/3357292.3357320
   Liang YH, 2022, DIGIT SIGNAL PROCESS, V123, P0, DOI 10.1016/j.dsp.2022.103446
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Moreira A, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2248301
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Reigber A, 2013, P IEEE, V101, P759, DOI 10.1109/JPROC.2012.2220511
   Roy M, 2014, IEEE J-STARS, V7, P1200, DOI 10.1109/JSTARS.2013.2293175
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Wang J, 2020, ISPRS J PHOTOGRAMM, V164, P61, DOI 10.1016/j.isprsjprs.2020.04.007
   Wieland M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100792
   Xiaofan Qu, 2022, IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, V19, P0, DOI 10.1109/LGRS.2021.3073900
   Zagoruyko S, 2015, PROC CVPR IEEE, V0, PP4353, DOI 10.1109/CVPR.2015.7299064
   Zanotta DC, 2012, PATTERN RECOGN, V45, P2927, DOI 10.1016/j.patcog.2012.02.004
   Zhang XZ, 2021, ISPRS J PHOTOGRAMM, V173, P79, DOI 10.1016/j.isprsjprs.2021.01.004
   Zhao XL, 2022, MECH SYST SIGNAL PR, V170, P0, DOI 10.1016/j.ymssp.2022.108826
   Zhao YY, 2021, IET IMAGE PROCESS, V15, P1345, DOI 10.1049/ipr2.12109
   Zheng YG, 2017, PATTERN RECOGN, V61, P309, DOI 10.1016/j.patcog.2016.07.040
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
NR 46
TC 0
Z9 0
U1 9
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2022
VL 15
IS 
BP 7755
EP 7769
DI 10.1109/JSTARS.2022.3199017
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 4T8VU
UT WOS:000858388100003
DA 2023-04-26
ER

PT J
AU Matsumoto, Y
   Natsuaki, R
   Hirose, A
AF Matsumoto, Yuya
   Natsuaki, Ryo
   Hirose, Akira
TI Full-Learning Rotational Quaternion Convolutional Neural Networks and Confluence of Differently Represented Data for PolSAR Land Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Quaternions; Convolution; Convolutional neural networks; Kernel; Scattering; Optical sensors; Optical imaging; Convolutional neural network (CNN); polarimetric synthetic aperture radar (PolSAR); quaternion neural network (QNN)
ID image classification; scattering model; sar; decomposition
AB Quaternion convolutional neural networks (QCNNs) expand the range of their applications in processing optical and polarimetric synthetic aperture radar (PolSAR) images. Conventional real-valued convolutional neural networks (RVCNNs) compress a three-channel input image into a single-channel feature map and ignore the relationship among the channels. In contrast, QCNNs deal with the input image as a single quaternion matrix and perform quaternion operation without the reduction of the channels. They can learn the interrelationship among the channel components. Though there exist two types of QCNNs, they have problems, respectively. One type conducts physically unclear quaternion convolution by using simple quaternionic multiplications. The other employs quaternion rotations with fixed axes, resulting in impairment of expression ability. In this article, we propose full-learning rotational QCNNs, which perform quaternion rotation in convolution, and update all the four parameters of a quaternion weight by backpropagation. They realize quaternion rotational convolution with high expression ability. We also propose using two different kinds of features, namely PolSAR pseudocolor features and Stokes vectors normalized by their total power. These two features allow neural networks to learn totally different characteristics of land surface. We train two networks with these features independently. Then, we merge their two classification results to obtain final decision to compensate for the shortcomings of the respective features. Experiments demonstrate that our proposed QCNNs show better classification performance than that of RVCNNs and the two existing QCNNs. We also find that the combination of the two features improves final classification results measured by F-scores.
C1 [Matsumoto, Yuya; Natsuaki, Ryo; Hirose, Akira] Univ Tokyo, Dept Elect Engn & Informat Syst, Bunkyo Ku, Tokyo 1138656, Japan.
C3 University of Tokyo
RP Matsumoto, Y (corresponding author), Univ Tokyo, Dept Elect Engn & Informat Syst, Bunkyo Ku, Tokyo 1138656, Japan.
EM matsumoto@eis.t.u-tokyo.ac.jp; natsuaki@eis.t.u-tokyo.ac.jp; ahirose@ee.t.u-tokyo.ac.jp
FU Japan Society for the Promotion of Science KAKENHI [18H04105]; Cooperative Research Project Program of the Research Institute of Electrical Communication (RIEC), Tohoku University
CR Chen SW, 2018, IEEE GEOSCI REMOTE S, V15, P627, DOI 10.1109/LGRS.2018.2799877
   Cloude SR, 1997, IEEE T GEOSCI REMOTE, V35, P68, DOI 10.1109/36.551935
   Cloude SR, 1996, IEEE T GEOSCI REMOTE, V34, P498, DOI 10.1109/36.485127
   De S, 2018, IEEE J-STARS, V11, P154, DOI 10.1109/JSTARS.2017.2752282
   Du PJ, 2015, ISPRS J PHOTOGRAMM, V105, P38, DOI 10.1016/j.isprsjprs.2015.03.002
   Freeman A, 1998, IEEE T GEOSCI REMOTE, V36, P963, DOI 10.1109/36.673687
   Gao F, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7050447
   Gaudet CJ, 2018, IEEE IJCNN, V0, P0
   Kim H, 2018, IEEE T GEOSCI REMOTE, V56, P1839, DOI 10.1109/tgrs.2017.2768619
   Kinugawa K, 2018, IEEE GEOSCI REMOTE S, V15, P1234, DOI 10.1109/LGRS.2018.2831215
   Lardeux C, 2009, IEEE T GEOSCI REMOTE, V47, P4143, DOI 10.1109/TGRS.2009.2023908
   Lee JS, 1999, IEEE T GEOSCI REMOTE, V37, P2249, DOI 10.1109/36.789621
   Lee JS, 2001, IEEE T GEOSCI REMOTE, V39, P2343, DOI 10.1109/36.964970
   LEE JS, 1994, INT J REMOTE SENS, V15, P2299, DOI 10.1080/01431169408954244
   Loosvelt L, 2012, IEEE T GEOSCI REMOTE, V50, P4185, DOI 10.1109/TGRS.2012.2189012
   Matsui N, 2004, J INTELL FUZZY SYST, V15, P149
   Niu X, 2013, INT J REMOTE SENS, V34, P1, DOI 10.1080/01431161.2012.700133
   Parcollet T., 2018, ARXIV180607789, V0, P0
   Parcollet T, 2019, INT CONF ACOUST SPEE, V0, PP8514, DOI 10.1109/ICASSP.2019.8682495
   Parikh H, 2020, INT J IMAGE DATA FUS, V11, P1, DOI 10.1080/19479832.2019.1655489
   Shang F, 2014, IEEE T GEOSCI REMOTE, V52, P5693, DOI 10.1109/TGRS.2013.2291940
   Yamaguchi Y, 2005, IEEE T GEOSCI REMOTE, V43, P1699, DOI 10.1109/TGRS.2005.852084
   Yamaguchi Y, 2011, IEEE T GEOSCI REMOTE, V49, P2251, DOI 10.1109/TGRS.2010.2099124
   Yin QL, 2019, IEEE ACCESS, V7, P20293, DOI 10.1109/ACCESS.2019.2897000
   Zhang XZ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151831
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zhu XY, 2018, LECT NOTES COMPUT SC, V11212, P645, DOI 10.1007/978-3-030-01237-3_39
NR 28
TC 0
Z9 0
U1 1
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2022
VL 15
IS 
BP 2914
EP 2928
DI 10.1109/JSTARS.2022.3164431
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 1E0FH
UT WOS:000794172000001
DA 2023-04-26
ER

PT J
AU Santhiya, P
   Chitrakala, S
AF Santhiya, P.
   Chitrakala, S.
TI PTCERE: personality-trait mapping using cognitive-based emotion recognition from electroencephalogram signals
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Cognitive computing; Cognitive personality trait; Emotion recognition; Electroencephalogram (EEG); Human emotion; Machine learning
ID feature-extraction; user identification; neural-networks; eeg; classification; framework; features
AB Human emotion recognition is a technique for identifying human emotions with respect to various aspects of human life, such as in decision-making, detecting lies, assessing social behaviour, measuring brain-related activity and identifying the personality of a person. In general, this paper aims to propose an efficient EEG-based cognitive personality trait detection based on the human emotion recognition system. Two different algorithms were proposed for this system, namely the normalised window-short time Fourier transform (NW-STFT) algorithm and the cognitive mapping-based Hebbian learning (CM-HL) algorithm. The NW-STFT algorithm dynamically fixes the window size for feature extraction using EEG-based emotion recognition, and the CM-HL algorithm is proposed for mapping the top five big personality traits with the help of recognised primary emotions. The pre-processing method reduces the contaminated artefacts from the benchmark dataset, as well as the brain signal's band power frequency range analysis time. The proposed emotion recognition method has shown a significant improvement in accuracy, leading to greater enhancement in personality-trait mapping. The outcome shows that the proposed two algorithms are effective in finding emotional and personality trait mapping. query Please check the edit made in the article title.
C1 [Santhiya, P.; Chitrakala, S.] Anna Univ, Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Santhiya, P (corresponding author), Anna Univ, Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM santhiyasasitha16@gmail.com; chitrakala.au@gmail.com
CR Bajaj V, 2018, HEALTH INF SCI SYST, V6, P0, DOI 10.1007/s13755-018-0048-y
   Bhatti AM, 2016, COMPUT HUM BEHAV, V65, P267, DOI 10.1016/j.chb.2016.08.029
   Carella T, 2018, IEEE ENG MED BIO, V0, PP223, DOI 10.1109/EMBC.2018.8512228
   Chettupuzhakkaran P., 2018, 2018 INT C EM TRENDS, V0, P15
   Cui H, 2020, KNOWL-BASED SYST, V205, P0, DOI 10.1016/j.knosys.2020.106243
   Dar MN, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20164551
   Degirmenci M, 2018, 2018 MEDICAL TECHNOLOGIES NATIONAL CONGRESS (TIPTEKNO), V0, P0
   Gonzalez HA, 2019, IEEE ENG MED BIO, V0, PP694, DOI 10.1109/EMBC.2019.8857248
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Kaur B, 2017, MULTIMED TOOLS APPL, V76, P25581, DOI 10.1007/s11042-016-4232-2
   Khurana V, 2018, COGN SYST RES, V49, P33, DOI 10.1016/j.cogsys.2017.11.003
   Krishna AH, 2019, IET SCI MEAS TECHNOL, V13, P375, DOI 10.1049/iet-smt.2018.5237
   Krishna NM, 2019, IEEE ACCESS, V7, P77905, DOI 10.1109/ACCESS.2019.2922047
   Kumar P, 2017, IEEE REGION 10 SYMP, V0, P0
   Kumar P, 2017, J NETW COMPUT APPL, V89, P62, DOI 10.1016/j.jnca.2017.02.011
   Lan ZR, 2019, IEEE T COGN DEV SYST, V11, P85, DOI 10.1109/TCDS.2018.2826840
   Lan ZR, 2016, VISUAL COMPUT, V32, P347, DOI 10.1007/s00371-015-1183-y
   Li JP, 2018, COGN COMPUT, V10, P368, DOI 10.1007/s12559-017-9533-x
   Liu W, 2016, LECT NOTES COMPUT SC, V9948, P521, DOI 10.1007/978-3-319-46672-9_58
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu Y, 2020, COMPUT BIOL MED, V123, P0, DOI 10.1016/j.compbiomed.2020.103927
   Matilda S, 2015, INT J ADV RES COMPUT, V3, P14
   Mehmood RM, 2016, COMPUT ELECTR ENG, V53, P444, DOI 10.1016/j.compeleceng.2016.04.009
   Menezes MLR, 2017, PERS UBIQUIT COMPUT, V21, P1003, DOI 10.1007/s00779-017-1072-7
   Mert A, 2018, PATTERN ANAL APPL, V21, P81, DOI 10.1007/s10044-016-0567-6
   Pane ES, 2019, COGN PROCESS, V20, P405, DOI 10.1007/s10339-019-00924-z
   Rahman MA, 2020, EGYPT INFORM J, V21, P23, DOI 10.1016/j.eij.2019.10.002
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saini R, 2018, INFORM SCIENCES, V430, P163, DOI 10.1016/j.ins.2017.11.045
   Santhiya P., 2019, 2019 INT C VIS EM TR, V0, P16
   Siddharth, 2022, IEEE T AFFECT COMPUT, V13, P96, DOI 10.1109/TAFFC.2019.2916015
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Soundarya S., 2019, J EMERG TECHNOL INNO, V5, P744
   Vergini E.S., 2016, 2016 7 INT C INF INT, V0, P16
   Wang F, 2018, LECT NOTES COMPUT SC, V10705, P82, DOI 10.1007/978-3-319-73600-6_8
   Wang SF, 2015, IEEE T AUTON MENT DE, V7, P189, DOI 10.1109/TAMD.2015.2463113
   Widrow B, 2015, IEEE COMPUT INTELL M, V10, P37, DOI 10.1109/MCI.2015.2471216
   Yadava M, 2017, MULTIMED TOOLS APPL, V76, P19087, DOI 10.1007/s11042-017-4580-6
   Yang YM, 2018, IEEE T COGN DEV SYST, V10, P408, DOI 10.1109/TCDS.2017.2685338
   Yu D, 2020, INFORMATION, V11, P0, DOI 10.3390/info11040212
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P26697, DOI 10.1007/s11042-018-5885-9
   Zhang Y, 2016, NEUROSCI LETT, V633, P152, DOI 10.1016/j.neulet.2016.09.037
   Zhao GZ, 2018, IEEE T AFFECT COMPUT, V9, P362, DOI 10.1109/TAFFC.2017.2786207
   Zheng W.-L., 2017, IEEE T AFFECTIVE COM, V0, P0, DOI DOI 10.1109/TAFFC.2017.2712143
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
NR 48
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1007/s00371-022-02502-5
PG 15
WC Computer Science, Software Engineering
SC Computer Science
GA 1B6GN
UT WOS:000792533800001
DA 2023-04-26
ER
