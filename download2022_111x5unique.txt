
PT J
AU Knani, M
   Echchakoui, S
   Ladhari, R
AF Knani, Mouna
   Echchakoui, Said
   Ladhari, Riadh
TI Artificial intelligence in tourism and hospitality: Bibliometric analysis and research agenda
SO INTERNATIONAL JOURNAL OF HOSPITALITY MANAGEMENT
LA English
DT Article
DE Artificial intelligence; Bibliometric approach; Artificial neural network; Robotics; Automation; Big data; Research agenda
ID big data; analytics; systems; demand; image; user; web
AB Artificial intelligence (AI) has received a great deal of attention in tourism and hospitality (T&H) literature and practices. The authors of this study propose a bibliometric approach aiming to examine current state-of-the-art AI research in T&H. In total, 1035 manuscripts published between 1984 and 2021 were retrieved form Scopus and Web of Science. This study highlights the evolving volume of studies, authors, affiliated institutions and countries, authorship networks, keyword co-occurrences, and keyword networks and also includes a thematic map that highlights four types of research: motor themes (i.e., artificial neural networks and data mining); basic and transversal themes (i.e., text mining and sentiment analysis, Internet of things and big data, COVID and AI); emerging themes (experience with service robots); and specialized and peripheral themes (e.g., forecasting tourism models, augmented reality and virtual reality, and biometrics). The paper concludes with future perspectives and research avenues in this field.
C1 [Knani, Mouna] HEC Montreal, Montreal, PQ H3T 2A7, Canada.
   [Echchakoui, Said] Univ Quebec Rimouski, Management Dept, Levis, PQ G6V 0A6, Canada.
   [Ladhari, Riadh] Laval Univ, Fac Business Adm, Quebec City, PQ G1V 0A6, Canada.
C3 Universite de Montreal; HEC Montreal; University of Quebec; Universite du Quebec a Rimouski; Laval University
RP Ladhari, R (corresponding author), Laval Univ, Fac Business Adm, Quebec City, PQ G1V 0A6, Canada.
EM riadh.ladhari@fsa.ulaval.ca
CR Bastidas-Manzano AB, 2021, J HOSP TOUR RES, V45, P529, DOI 10.1177/1096348020967062
   Belanche D, 2020, J SERV MANAGE, V31, P267, DOI 10.1108/JOSM-05-2019-0156
   Buhalis D., 2015, INFORM COMMUNICATION, V0, PP377, DOI 10.1007/978-3-319-14343-9_28
   Buhalis D, 2019, J SERV MANAGE, V30, P484, DOI 10.1108/JOSM-12-2018-0398
   Bulchand-Gidumal J., 2020, HDB E TOUR, V0, PP1, DOI 10.1007/978-3-030-05324-6_110-1
   Chen KY, 2007, TOURISM MANAGE, V28, P215, DOI 10.1016/j.tourman.2005.12.018
   Choi S, 2007, TOURISM MANAGE, V28, P118, DOI 10.1016/j.tourman.2006.03.002
   Cobo MJ, 2011, J AM SOC INF SCI TEC, V62, P1382, DOI 10.1002/asi.21525
   Loureiro SMC, 2020, TOURISM MANAGE, V77, P0, DOI 10.1016/j.tourman.2019.104028
   de la Hoz-Correa A, 2018, TOURISM MANAGE, V65, P200, DOI 10.1016/j.tourman.2017.10.001
   Doborjeh Z, 2022, INT J CONTEMP HOSP M, V34, P1154, DOI 10.1108/IJCHM-06-2021-0767
   Dwivedi YK, 2021, INT J INFORM MANAGE, V57, P0, DOI 10.1016/j.ijinfomgt.2019.08.002
   Echchakoui S, 2020, J MARK ANAL, V8, P165, DOI 10.1057/s41270-020-00081-9
   Ghose A, 2012, MARKET SCI, V31, P493, DOI 10.1287/mksc.1110.0700
   Gretzel U, 2015, ELECTRON MARK, V25, P179, DOI 10.1007/s12525-015-0196-8
   Grundner L, 2021, J DESTIN MARK MANAGE, V19, P0, DOI 10.1016/j.jdmm.2020.100511
   Guo Y, 2017, TOURISM MANAGE, V59, P467, DOI 10.1016/j.tourman.2016.09.009
   Huang A, 2022, J HOSP TOUR INSIGHTS, V5, P1080, DOI 10.1108/JHTI-01-2021-0021
   Ioannou A, 2020, INT J INFORM MANAGE, V54, P0, DOI 10.1016/j.ijinfomgt.2020.102122
   Ivanov S, 2019, J HOSP TOUR TECHNOL, V10, P489, DOI 10.1108/JHTT-08-2018-0087
   Liang LJ, 2021, TOUR HOSP RES, V21, P15, DOI 10.1177/1467358420941913
   Johnson AG, 2019, J HOSP TOUR TECHNOL, V10, P600, DOI 10.1108/JHTT-07-2018-0065
   Law R, 2019, ANN TOURISM RES, V75, P410, DOI 10.1016/j.annals.2019.01.014
   Leung XY, 2017, INT J HOSP MANAG, V66, P35, DOI 10.1016/j.ijhm.2017.06.012
   Li JJ, 2018, TOURISM MANAGE, V68, P301, DOI 10.1016/j.tourman.2018.03.009
   Li J, 2019, TOURISM MANAGE, V73, P172, DOI 10.1016/j.tourman.2019.02.006
   Li X, 2020, TOUR MANAG PERSPECT, V33, P0, DOI 10.1016/j.tmp.2019.100608
   Li X, 2017, TOURISM MANAGE, V59, P57, DOI 10.1016/j.tourman.2016.07.005
   Liu SQ, 2017, INT J HOSP MANAG, V60, P33, DOI 10.1016/j.ijhm.2016.09.012
   Lu Y, 2018, TECHNOL FORECAST SOC, V136, P285, DOI 10.1016/j.techfore.2018.01.022
   Maia SC, 2019, SCIENTOMETRICS, V120, P929, DOI 10.1007/s11192-019-03165-1
   Marasco A, 2018, J DESTIN MARK MANAGE, V9, P138, DOI 10.1016/j.jdmm.2017.12.002
   Mariani M, 2018, INT J CONTEMP HOSP M, V30, P3514, DOI 10.1108/IJCHM-07-2017-0461
   Mehraliyev F, 2019, J HOSP TOUR TECHNOL, V10, P522, DOI 10.1108/JHTT-08-2018-0076
   Miah SJ, 2017, INFORM MANAGE-AMSTER, V54, P771, DOI 10.1016/j.im.2016.11.011
   Mirzaalian F, 2019, J HOSP TOUR TECHNOL, V10, P764, DOI 10.1108/JHTT-08-2018-0078
   Morosan C, 2020, J ELECTRON COMMER RE, V21, P21
   Mustak M, 2021, J BUS RES, V124, P389, DOI 10.1016/j.jbusres.2020.10.044
   Nadkarni S, 2019, J HOSP TOUR TECHNOL, V11, P93, DOI 10.1108/JHTT-12-2018-0120
   Nowacki M, 2020, SCAND J HOSP TOUR, V20, P503, DOI 10.1080/15022250.2020.1833362
   Pereira V, 2023, HUM RESOUR MANAGE R, V33, P0, DOI 10.1016/j.hrmr.2021.100857
   Samara D, 2020, J HOSP TOUR TECHNOL, V11, P343, DOI 10.1108/JHTT-12-2018-0118
   Shankar V, 2018, J RETAILING, V94, PVI, DOI 10.1016/S0022-4359(18)30076-9
   Shin H, 2022, INT J CONTEMP HOSP M, V34, P2337, DOI 10.1108/IJCHM-09-2021-1171
   Tuomi A, 2020, ANN TOURISM RES, V81, P0, DOI 10.1016/j.annals.2019.06.003
   Tussyadiah I, 2020, ANN TOURISM RES, V81, P0, DOI 10.1016/j.annals.2020.102883
   Tussyadiah IP, 2020, ANN TOURISM RES, V81, P0, DOI 10.1016/j.annals.2020.102886
   Vargas-Sanchez A, 2019, WORLDW HOSP TOUR THE, V11, P748, DOI 10.1108/WHATT-09-2019-0057
   Vuong H.Q., 2021, CEUR WORKSHOP PROC, V3026, P0
   Wang G, 2022, J HOSP TOUR INSIGHTS, V0, P0, DOI DOI 10.1108/JHTI-09-2021-0260
   Wei W, 2019, J HOSP TOUR TECHNOL, V10, P539, DOI 10.1108/JHTT-04-2018-0030
   Wirtz J, 2018, J SERV MANAGE, V29, P907, DOI 10.1108/JOSM-04-2018-0119
   Xiang Z, 2021, ANN TOURISM RES, V86, P0, DOI 10.1016/j.annals.2021.103154
   Xiang Z, 2015, INT J HOSP MANAG, V44, P120, DOI 10.1016/j.ijhm.2014.10.013
   Xu FF, 2020, J SUSTAIN TOUR, V28, P144, DOI 10.1080/09669582.2019.1631318
   Zhang XY, 2022, INT J CONTEMP HOSP M, V34, P2004, DOI 10.1108/IJCHM-10-2021-1262
   Zupic I, 2015, ORGAN RES METHODS, V18, P429, DOI 10.1177/1094428114562629
NR 57
TC 1
Z9 1
U1 22
U2 22
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0278-4319
EI 1873-4693
J9 INT J HOSP MANAG
JI Int. J. Hosp. Manag.
PD OCT 15
PY 2022
VL 107
IS 
BP 
EP 
DI 10.1016/j.ijhm.2022.103317
PG 15
WC Hospitality, Leisure, Sport & Tourism
SC Social Sciences - Other Topics
GA 8R2HG
UT WOS:000927717000001
DA 2023-04-26
ER

PT J
AU Song, XY
   Hua, Z
   Li, JJ
AF Song, Xinyang
   Hua, Zhen
   Li, Jinjiang
TI PSTNet: Progressive Sampling Transformer Network for Remote Sensing Image Change Detection
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Context modeling; Semantics; Remote sensing; Data mining; Current transformers; Task analysis; Attention mechanisms; change detection (CD); deep convolutional network; dual-time satellite remote sensing images; progressive sampling (PS); transformers
AB Remote sensing change detection (CD) is to use multitemporal remote sensing data to extract change information by using a variety of image processing and pattern recognition methods, and quantitatively analyze and determine the characteristics and processes of surface changes. In recent research on CD, how to more accurately segment objects and how to extract and effectively link spatiotemporal information are important parts. To achieve this, we propose a progressive sampling (PS) transformer network for remote sensing image CD, which continuously extracts and optimizes feature information in an iterative manner, so that pixels can establish better connections in the spatial domain to model the context. Our intuition is that, through this iterative sampling method, the parts of interest in the image can be gradually extracted. This allows subsequent processing to be more focused on useful areas, which in turn reduces interference from uninteresting parts, and the information after PS will be generalize into several tokens containing rich semantic information. Using the excellent modeling ability of the transformer, the optimized tokens are mapped back to the original image features to achieve the purpose of segmenting accurate difference images. We conducted extensive experiments on three CD datasets, LEVIR-CD, DSIFN-CD, and WHU-CD, and achieved evaluation scores of 90.73/84.11, 80.10/68.93, and 91.67/85.15 on F1-score and IoU metrics, respectively. Notably, the convolutional neural network (CNN) backbone of our network uses only a simplified ResNet model, without using structurally complex frameworks, such as FPN and Unet, but our model uses PS module and transformer to achieve better performance than the recent advanced CD models.
C1 [Song, Xinyang; Li, Jinjiang] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Song, Xinyang; Li, Jinjiang] Inst Network Technol, Yantai 264000, Peoples R China.
   [Hua, Zhen] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology & Business University
RP Hua, Z (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
EM 1041824895@qq.com; huazhen@sdtbu.edu.cn; lijinjiang@gmail.com
FU National Natural Science Foundation of China [61772319, 62002200, 61972235, 12001327, 62176140]; Shandong Natural Science Foundation of China [ZR2020QF012, ZR2021MF068]; Yantai Science and Technology Innovation Development Plan [2022JCYJ031]
CR Ba JMY, 2015, ARXIV, V0, P0
   Bao TF, 2020, IEEE GEOSCI REMOTE S, V17, P1797, DOI 10.1109/LGRS.2019.2955309
   Bazi Y, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030516
   Carion Nicolas, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12346), V0, PP213, DOI 10.1007/978-3-030-58452-8_13
   Chen HT, 2021, PROC CVPR IEEE, V0, PP12294, DOI 10.1109/CVPR46437.2021.01212
   Chen H, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3066802
   Chen H, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3095166
   Chen H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Dai JF, 2017, IEEE I CONF COMP VIS, V0, PP764, DOI 10.1109/ICCV.2017.89
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, V0, P2115
   de Bem PP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060901
   Devlin J, 2019, ARXIV, V0, P0
   Diakogiannis FI, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13183707
   Dong Zhang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12373), V0, PP323, DOI 10.1007/978-3-030-58604-1_20
   Dosovitskiy A, 2020, ARXIV, V0, P0
   Elsayed G., 2019, PROC INT C NEURAL IN, V0, P0
   Fang B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111292
   Fang S, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1145/3510858.3510863
   Gedara Chaminda Bandara W., 2022, ARXIV, V0, P0
   He J, 2020, IEEE T GEOSCI REMOTE, V58, P165, DOI 10.1109/TGRS.2019.2934760
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Ji SP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030484
   Khan Salman, 2021, ARXIV210101169, V0, P0
   Lebedev M., 2018, INT ARCH PHOTOGRAM R, V42, P565, DOI 10.5194/isprs-archives-XLII-2-565-2018
   Li XH, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3098774
   Li ZT, 2020, IEEE J-STARS, V13, P847, DOI 10.1109/JSTARS.2020.2971763
   Liu RY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232844
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP9992, DOI 10.1109/ICCV48922.2021.00986
   Lv PY, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3157671
   Ma JJ, 2022, IEEE J-STARS, V15, P2223, DOI 10.1109/JSTARS.2022.3155665
   Mnih V, 2014, ADV NEUR IN, V27, P0
   Nemoto K, 2017, PROC SPIE, V10431, P0, DOI 10.1117/12.2277912
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Peng XL, 2021, IEEE T GEOSCI REMOTE, V59, P7296, DOI 10.1109/TGRS.2020.3033009
   Rahman F, 2018, IEEE GLOB CONF SIG, V0, PP958, DOI 10.1109/GlobalSIP.2018.8646512
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Sun L, 2022, IEEE J-STARS, V15, P4045, DOI 10.1109/JSTARS.2022.3175191
   Sun L, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3144158
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang MY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020205
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P10532, DOI 10.1109/TGRS.2020.3044054
   Wu BC, 2020, ARXIV, V0, P0
   Xie E., 2021, ARXIV210515203, V34, P1, DOI 10.48550/ARXIV.2105.15203
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue DH, 2021, IEEE J-STARS, V14, P1796, DOI 10.1109/JSTARS.2020.3046838
   Yang FZ, 2020, PROC CVPR IEEE, V0, PP5790, DOI 10.1109/CVPR42600.2020.00583
   Yue XY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP377, DOI 10.1109/ICCV48922.2021.00044
   Xu JZ, 2019, ARXIV, V0, P0
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhao WZ, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3035780
   Zhao WZ, 2020, IEEE T GEOSCI REMOTE, V58, P2720, DOI 10.1109/TGRS.2019.2953879
   Zheng SX, 2021, PROC CVPR IEEE, V0, PP6877, DOI 10.1109/CVPR46437.2021.00681
   Zhu XZ, 2021, ARXIV, V0, P0
   Zhu XZ, 2019, PROC CVPR IEEE, V0, PP9300, DOI 10.1109/CVPR.2019.00953
NR 64
TC 0
Z9 0
U1 13
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2022
VL 15
IS 
BP 8442
EP 8455
DI 10.1109/JSTARS.2022.3204191
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 5F7ZK
UT WOS:000866530700004
DA 2023-04-26
ER

PT J
AU Kukreja, V
   Sakshi
AF Kukreja, Vinay
   Sakshi
TI Machine learning models for mathematical symbol recognition: A stem to stern literature analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Handwritten mathematical symbol recognition; Machine learning; Mathematical symbol recognition; Optical character recognition; Support vector machine; Segmentation
ID handwritten; online; math; system
AB Given the ubiquity of handwriting and mathematical content in human transactions, machine recognition of handwritten mathematical text and symbols has become a domain of great practical scope and significance. Recognition of mathematical expression (ME) has remained a challenging and emerging research domain, with mathematical symbol recognition (MSR) as a requisite step in the entire recognition process. Many variations in writing styles and existing dissimilarities among the wide range of symbols and recurring characters make the recognition tasks strenuous even for Optical Character Recognition. The past decade has witnessed the emergence of recognition techniques and the peaking interest of several researchers in this evolving domain. In light of the current research status associated with recognizing handwritten math symbols, a systematic review of the literature seems timely. This article seeks to provide a complete systematic analysis of recognition techniques, models, datasets, sub-stages, accuracy metrics, and accuracy details in an extracted form as described in the literature. A systematic literature review conducted in this study includes pragmatic studies until the year 2021, and the analysis reveals Support Vector Machine (SVM) to be the most dominating recognition technique and symbol recognition rate to be most frequently deployed accuracy measure and other interesting results in terms of segmentation, feature extraction and datasets involved are vividly represented. The statistics of mathematical symbols-related papers are shown, and open problems are identified for more advanced research. Our study focused on the key points of earlier research, present work, and the future direction of MSR.
C1 [Kukreja, Vinay; Sakshi] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Sakshi (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
EM onlyvinaykukreja@gmail.com; asakshi541@gmail.com
CR Ali I, 2018, INT ARAB J INF TECHN, V15, P565
   Alvaro F, 2010, INT C PATTERN RECOGN, V0, P0, DOI DOI 10.1109/ICPR.2010.481
   Alvaro F, 2014, INT C PATT RECOG, V0, PP2944, DOI 10.1109/ICPR.2014.507
   Alvaro F, 2013, PROC INT CONF DOC, V0, PP1012, DOI 10.1109/ICDAR.2013.203
   Baker JB, 2010, P INT WORKSH DOC AN, V0, PP485, DOI 10.1145/1815330.1815393
   Bouvett E, 2012, IEEE MEDITERR ELECT, V0, PP653, DOI 10.1109/MELCON.2012.6196516
   Cao XY, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM DESIGN AND ENGINEERING APPLICATIONS (ISDEA), V0, PP803, DOI 10.1109/ISDEA.2012.191
   Chajri Y, 2016, I C COMP GRAPH IM VI, V0, PP448, DOI 10.1109/CGiV.2016.92
   Chan KF, 2001, PROC INT CONF DOC, V0, PP774, DOI 10.1109/ICDAR.2001.953893
   Chan KF, 2001, PATTERN RECOGN, V34, P1671, DOI 10.1016/S0031-3203(00)00102-3
   Char BW, 2007, PROC INT CONF DOC, V0, P1198
   Chen Y, 2001, INT J PATTERN RECOGN, V15, P967, DOI 10.1142/S021800140100126X
   Clark R, 2013, 2013 IEEE EUROCON, V0, PP2029, DOI 10.1109/EUROCON.2013.6625259
   Davila K, 2018, INT CONF FRONT HAND, V0, PP50, DOI 10.1109/ICFHR-2018.2018.00018
   Davila K, 2014, INT CONF FRONT HAND, V0, PP323, DOI 10.1109/ICFHR.2014.61
   DIMITRIADIS YA, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P944, DOI 10.1109/ICNN.1993.298684
   Drsouza L., 2018, 2018 INT C INF COMM, V0, P0, DOI DOI 10.1109/ICICET.2018.8533789
   Fang DB, 2020, IEEE ACCESS, V8, P48101, DOI 10.1109/ACCESS.2020.2979346
   Fang DB, 2019, IEEE INT CONF ELECTR, V0, PP226, DOI 10.1109/ICEIEC.2019.8784656
   Farulla GA, 2016, LECT NOTES COMPUT SC, V9758, P7, DOI 10.1007/978-3-319-41264-1_1
   Firdaus S. A., 2020, ADV DECISION SCI IMA, V0, PP658, DOI 10.1007/978-3- 030-24318-0_75
   Garain U, 2004, INT C PATT RECOG, V0, PP380, DOI 10.1109/ICPR.2004.1334131
   Tran GS, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL, V0, P15, DOI 10.1109/CRC.2018.00012
   Golubitsky O, 2010, INT J DOC ANAL RECOG, V13, P133, DOI 10.1007/s10032-009-0107-7
   Golubitsky O, 2009, LECT NOTES COMPUT SC, V5625, P460, DOI 10.1007/978-3-642-02614-0_36
   Green BN, 2001, J SPORT CHIROPR REH, V15, P5, DOI 10.1016/S0899-3467(07)60142-6
   Nguyen HD, 2016, IEICE T INF SYST, VE99D, P3110, DOI 10.1587/transinf.2016EDP7102
   Hu L, 2012, INT C PATT RECOG, V0, P326
   Hu L, 2011, PROC INT CONF DOC, V0, PP457, DOI 10.1109/ICDAR.2011.98
   Hu R, 2014, INT SYMP SYMB NUMERI, V0, PP61, DOI 10.1109/SYNASC.2013.15
   Jakjoud W, 2011, INT C MULTIMEDIA COM, V0, PP1, DOI 10.1109/ICMCS.2011.5945634
   Jakjoud W, 2009, INT CONF RES CHAL, V0, PP427, DOI 10.1109/RCIS.2009.5089307
   Jimenez ND, 2013, RECOGNITION HANDWRIT, V0, P0
   Julca-Aguilar F, 2014, INT CONF FRONT HAND, V0, PP500, DOI 10.1109/ICFHR.2014.90
   Kacem A., 2001, INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION, V4, P97, DOI 10.1007/s100320100064
   Kam-Fai Chan, 2000, INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION, V3, P3, DOI 10.1007/PL00013549
   Kanahori T, 2000, LECT NOTES COMPUT SC, V1948, P394
   Keshari B, 2008, P MATH US INT WORK, V0, P0
   Keshari B, 2007, PROC INT CONF DOC, V0, P859
   Kitchenham, 2004, PROCEDURES PERFORMIN, V2004, P1
   KURTZBERG JM, 1987, IBM J RES DEV, V31, P91, DOI 10.1147/rd.311.0091
   LEE HJ, 1994, PATTERN RECOGN, V27, P447, DOI 10.1016/0031-3203(94)90121-X
   Li LH, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 3, PROCEEDINGS
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   Luo ZX, 2008, INT CONF ACOUST SPEE, V0, P1953
   MacLean S, 2015, PATTERN RECOGN, V48, P2433, DOI 10.1016/j.patcog.2015.02.017
   MacLean S, 2013, INT J DOC ANAL RECOG, V16, P139, DOI 10.1007/s10032-012-0184-x
   Mahdavi Mahshad, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP647, DOI 10.1109/ICDAR.2019.00109
   Malon C, 2008, PATTERN RECOGN LETT, V29, P1326, DOI 10.1016/j.patrec.2008.02.005
   Malon C, 2006, LECT NOTES COMPUT SC, V4109, P136
   Marinai S, 2011, PROC INT CONF DOC, V0, PP1309, DOI 10.1109/ICDAR.2011.263
   Medjkoune S, 2011, PROC INT CONF DOC, V0, PP379, DOI 10.1109/ICDAR.2011.84
   Mohamed Shaffril H.A., 2020, QUAL QUANT, V55, P1319, DOI 10.1007/s11135-020-01059-6
   Nazemi A., 2019, ARXIV191007395, V0, P0
   Nguyen HD, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, V0, PP121, DOI 10.1109/ACPR.2015.7486478
   Okamoto M., 2001, PROCEEDINGS OF SIXTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, V0, PP121, DOI 10.1109/ICDAR.2001.953767
   Page MJ, 2021, BMJ-BRIT MED J, V372, P0, DOI 10.1136/bmj.n71
   Pathak A, 2019, 2019 2 INT C ADV COM, V0, PP1, DOI 10.1109/ICACCP.2019.8882887
   Pillay A, 2014, INTELLIGENT COMBINAT, V0, P0
   Prusa D, 2007, PROC INT CONF DOC, V0, P849
   Ramadhan I, 2016, 2016 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT), V0, P0
   Ramirez-Pina C, 2018, IB C PATT REC, V1, P893, DOI 10.1007/978-3-030-13469-3
   Sabeghi Saroui B, 2015, PROC INT CONF DOC, V0, PP1051, DOI 10.1109/ICDAR.2015.7333922
   Sakshi, 2021, ENG APPL ARTIF INTEL, V103, P0, DOI 10.1016/j.engappai.2021.104292
   Sui Kun Guan, 2019, 2019 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), V0, PP185, DOI 10.1109/HPCS48598.2019.9188180
   Takiguchi Y, 2005, PROC INT CONF DOC, V0, PP745, DOI 10.1109/ICDAR.2005.10
   Tapia E, 2003, PROC INT CONF DOC, V0, P980
   Tian XD, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1678
   Tian XD, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, V0, P0
   Toyozumi K, 2004, P 17 INT C PATTERN R, V2, P2
   Wang CC, 2016, INT CONF FRONT HAND, V0, PP252, DOI 10.1109/ICFHR.2016.0056
   Wang HY, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), V0, PP461, DOI 10.1109/ISCIT.2016.7751674
   Wang J, 2020, PATTERN RECOGN, V119, P1, DOI 10.48550/ARXIV.2002.08670
   Watt SM, 2005, PROC INT CONF DOC, V0, PP740, DOI 10.1109/ICDAR.2005.195
   Watt SM, 2005, PROTOTYPE PRUNING FE, V0, P0
   Shi Y, 2007, PROC INT CONF DOC, V0, P854
   Zanibbi R, 2001, PROC INT CONF DOC, V0, PP768, DOI 10.1109/ICDAR.2001.953892
   Zanibbi R, 2002, IEEE T PATTERN ANAL, V24, P1455, DOI 10.1109/TPAMI.2002.1046157
   Zanibbi R, 2012, INT J DOC ANAL RECOG, V15, P331, DOI 10.1007/s10032-011-0174-4
   Zhang DY, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P251, DOI 10.1109/ICACC.2010.5486679
   Zhao W, 2021, HANDWRITTEN MATH EXP, V0, P0
   Zhao XJ, 1997, PROC INT CONF DOC, V0, PP645, DOI 10.1109/ICDAR.1997.620585
   Zhu BL, 2011, PROC INT CONF DOC, V0, PP603, DOI 10.1109/ICDAR.2011.127
NR 83
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG 15
PY 2022
VL 81
IS 20
BP 28651
EP 28687
DI 10.1007/s11042-022-12644-2
EA MAR 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900003
DA 2023-04-26
ER

PT J
AU Colomer, S
   Cuperlier, N
   Bresson, G
   Pechberti, S
   Romain, O
AF Colomer, Sylvain
   Cuperlier, Nicolas
   Bresson, Guillaume
   Pechberti, Steve
   Romain, Olivier
TI Sparse and Topological Coding for Visual Localization of Autonomous Vehicles
SO FROM ANIMALS TO ANIMATS 16
LA English
DT Proceedings Paper
DE Visual place recognition; Sparse coding; Autonomous vehicle; Visual cortex; Bio-inspired robotics
ID recognition
AB Efficient encoding of visual information is essential to the success of vision-based navigation tasks in large-scale environments. To do so, we propose in this article the Sparse Max-Pi neural network (SMP), a novel compute-efficient model of visual localization based on sparse and topological encoding of visual information. Inspired by the spatial cognition of mammals, the model uses a "topologic sparse dictionary" to efficiently compress the visual information of a landmark, allowing rich visual information to be represented with very small codes. This descriptor, inspired by the neurons in the primary visual cortex (V1), are learned using sparse coding, homeostasis and self-organising map mechanisms. Evaluated in cross-validation on the Oxford-car dataset, our experimental results show that the SMP model is competitive with the state of the art. It thus provides comparable or better performance than CoHog and NetVlad, two state-of-the-art VPR models.
C1 [Colomer, Sylvain; Cuperlier, Nicolas; Romain, Olivier] Univ Paris Seine, Lab ETIS UMR8051, ENSEA, CNRS, Paris, France.
   [Colomer, Sylvain; Bresson, Guillaume; Pechberti, Steve] Inst VEDECOM, 23 Bis Allee Marronniers, F-78000 Versailles, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Colomer, S (corresponding author), Univ Paris Seine, Lab ETIS UMR8051, ENSEA, CNRS, Paris, France.; Colomer, S (corresponding author), Inst VEDECOM, 23 Bis Allee Marronniers, F-78000 Versailles, France.
EM sylvain.colomer@ensea.fr
CR Arandjelovic R, 2016, ARXIV, V0, P0
   Colomer S, 2021, IEEE INT C INTELL TR, V0, PP3002, DOI 10.1109/ITSC48978.2021.9564608
   Colomer S, 2022, FRONT ROBOT AI, V8, P0, DOI 10.3389/frobt.2021.703811
   Geva-Sagiv M, 2015, NAT REV NEUROSCI, V16, P94, DOI 10.1038/nrn3888
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007
   Perrinet L.U, 2019, VISION, V3, P47, DOI 10.3390/VSIION3030047
   Rolls ET, 2018, PROG NEUROBIOL, V171, P90, DOI 10.1016/j.pneurobio.2018.09.004
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Willmore B, 2001, NETWORK-COMP NEURAL, V12, P255, DOI 10.1088/0954-898X/12/3/302
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zaffar M, 2020, IEEE ROBOT AUTOM LET, V5, P1835, DOI 10.1109/LRA.2020.2969917
NR 12
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
J9 LECT NOTES ARTIF INT
PD JUN 15
PY 2022
VL 13499
IS 
BP 153
EP 164
DI 10.1007/978-3-031-16770-6_13
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA BU0HY
UT WOS:000869588400013
DA 2023-04-26
ER

PT J
AU Peng, T
   Tang, CY
   Wang, J
AF Peng, Tao
   Tang, Caiyin
   Wang, Jing
TI Prostate Segmentation of Ultrasound Images Based on Interpretable-Guided Mathematical Model
SO MULTIMEDIA MODELING (MMM 2022), PT I
LA English
DT Proceedings Paper
DE Ultrasound prostate segmentation; Principal curve and neural network; Interpretable-guided mathematical model
ID features
AB Ultrasound prostate segmentation is challenging due to the low contrast of transrectal ultrasound (TRUS) images and the presence of imaging artifacts such as speckle and shadow regions. In this work, we propose an improved principal curve-based & differential evolution-based ultrasound prostate segmentation method (H-SegMod) based on an interpretable-guided mathematical model. Comparing with existing related studies, H-SegMod has three main merits and contributions: (1) The characteristic of the principal curve on automatically approaching the center of the dataset is utilized by our proposed H-SegMod. (2) When acquiring the data sequences, we use the principal curve-based constraint closed polygonal segment model, which uses different initialization, normalization, and vertex filtering methods. (3) We propose a mathematical map model (realized by differential evolution-based neural network) to describe the smooth prostate contour represented by the output of neural network (i.e., optimized vertices) so that it can match the ground truth contour. Compared with the traditional differential evolution method, we add different mutation steps and loop constraint conditions. Both quantitative and qualitative evaluation studies on a clinical prostate dataset show that our method achieves better segmentation than many state-of-the-art methods.
C1 [Peng, Tao; Wang, Jing] UT Southwestern Med Ctr, 2280 Inwood Rd, Dallas, TX 75235 USA.
   [Tang, Caiyin] Taizhou Peoples Hosp, Taizhou, Jiangsu, Peoples R China.
C3 University of Texas System; University of Texas Southwestern Medical Center Dallas
RP Peng, T; Wang, J (corresponding author), UT Southwestern Med Ctr, 2280 Inwood Rd, Dallas, TX 75235 USA.
EM Tao.Peng@UTSouthwestern.edu; Jing.Wang@UTSouthwestern.edu
FU National Institute of Health [R01 EB027898]
CR Alickovic E, 2016, J MED SYST, V40, P0, DOI 10.1007/s10916-016-0467-8
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Chen PY, 2019, EXPERT SYST APPL, V136, P33, DOI 10.1016/j.eswa.2019.06.035
   Dai BS, 2017, PATTERN RECOGN, V64, P226, DOI 10.1016/j.patcog.2016.11.017
   Kabir W, 2015, MIDWEST SYMP CIRCUIT, V0, P0
   Kegl B, 2002, IEEE T PATTERN ANAL, V24, P59, DOI 10.1109/34.982884
   Kim DW, 2020, IEEE ACCESS, V8, P98018, DOI 10.1109/ACCESS.2020.2997010
   Li XP, 2018, J SIGNAL PROCESS SYS, V90, P449, DOI 10.1007/s11265-017-1257-3
   Li ZX, 2017, BIOMED SIGNAL PROCES, V36, P221, DOI 10.1016/j.bspc.2017.04.002
   Peng T., 2020, COMPUT J, V0, P0
   Peng T, 2019, IEEE ACCESS, V7, P137794, DOI 10.1109/ACCESS.2019.2941511
   Peng T, 2020, IEEE ACCESS, V8, P73293, DOI 10.1109/ACCESS.2020.2987925
   Peng T, 2018, J DIGIT IMAGING, V31, P520, DOI 10.1007/s10278-018-0058-y
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Shahedi M, 2018, MED PHYS, V45, P2527, DOI 10.1002/mp.12898
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Wang Y, 2019, IEEE T MED IMAGING, V38, P2768, DOI 10.1109/TMI.2019.2913184
   Yan K, 2019, COMPUT METH PROG BIO, V170, P11, DOI 10.1016/j.cmpb.2018.12.031
   Zeng YR, 2017, ENERGY, V127, P381, DOI 10.1016/j.energy.2017.03.094
   Zhang JP, 2008, IEEE T INTELL TRANSP, V9, P666, DOI 10.1109/TITS.2008.2006780
   Zhu Y, 2019, J MAGN RESON IMAGING, V49, P1149, DOI 10.1002/jmri.26337
NR 22
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
J9 LECT NOTES COMPUT SC
PD JUN 15
PY 2022
VL 13141
IS 
BP 166
EP 177
DI 10.1007/978-3-030-98358-1_14
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods
SC Computer Science
GA BT0JX
UT WOS:000788273400014
DA 2023-04-26
ER
