
PT J
AU Salama, A
   Hampshire, C
   Lee, J
   Sabour, A
   Yao, JW
   Al-Masri, E
   Ali, M
   Govind, H
   Tan, M
   Agrawal, V
   Maresov, E
   Prakash, R
AF Salama, Abdulrahman
   Hampshire, Cordel
   Lee, Josh
   Sabour, Adel
   Yao, Jiawei
   Al-Masri, Eyhab
   Ali, Mohamed
   Govind, Harsh
   Tan, Ming
   Agrawal, Vashutosh
   Maresov, Egor
   Prakash, Ravi
TI RDQS: A Geospatial Data Analysis System for Improving Roads Directionality Quality
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE computer vision; roads; geospatial analysis; geospatial data; smart city; IoT; convolutional neural networks; arrow detection; arrow directionality; Detectron2; rcnn; faster-rcnn
ID accuracy
AB With the increasing availability of smart devices, billions of users are currently relying on map services for many fundamental daily tasks such as obtaining directions and getting routes. It is becoming more and more important to verify the quality and consistency of route data presented by different map providers. However, verifying this consistency manually is a very time-consuming task. To address this problem, in this paper we introduce a novel geospatial data analysis system that is based on road directionality. We investigate our Road Directionality Quality System (RDQS) using multiple map providers, including: Bing Maps, Google Maps, and OpenStreetMap. Results from the experiments conducted show that our detection neural network is able to detect an arrow's position and direction in map images with >90% F1-Score across each of the different providers. We then utilize this model to analyze map images in six different regions. Our findings show that our approach can reliably assess map quality and discover discrepancies in road directionality across the different providers. We report the percentage of discrepancies found between map providers using this approach in a proposed study area. These results can help determine areas needs to be revised and prioritized to improve the overall quality of the data within maps.
C1 [Salama, Abdulrahman; Hampshire, Cordel; Lee, Josh; Sabour, Adel; Yao, Jiawei; Al-Masri, Eyhab; Ali, Mohamed] Univ Washington, Sch Engn & Technol, Tacoma, WA 98402 USA.
   [Govind, Harsh; Tan, Ming; Agrawal, Vashutosh; Maresov, Egor; Prakash, Ravi] Microsoft Corp, Redmond, WA 98052 USA.
C3 University of Washington; University of Washington Tacoma; Microsoft
RP Al-Masri, E (corresponding author), Univ Washington, Sch Engn & Technol, Tacoma, WA 98402 USA.
EM ealmasri@uw.edu
CR Alghanim A, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10070436
   Bandil Ayush, 2020, SIGSPATIAL 20: PROCEEDINGS OF THE 28TH INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS, V0, PP425, DOI 10.1145/3397536.3422348
   Bandil A, 2021, PROC INT CONF DATA, V0, PP2535, DOI 10.1109/ICDE51399.2021.00285
   Basiri A, 2016, GEO-SPAT INF SCI, V19, P56, DOI 10.1080/10095020.2016.1151213
   Brovelli MA, 2016, INT ARCH PHOTOGRAMM, V41, P919, DOI 10.5194/isprsarchives-XLI-B7-919-2016
   Brovelli MA, 2017, T GIS, V21, P191, DOI 10.1111/tgis.12182
   CIPELUCH B., 2010, P 9 INT S SPAT ACC A, V1, P337
   Dosovitskiy A., 2020, IMAGE IS WORTH 16X16, V0, P0
   Girshick R., 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Jackson SP, 2013, ISPRS INT GEO-INF, V2, P507, DOI 10.3390/ijgi2020507
   John V, 2016, 2016 ASIA-PACIFIC CONFERENCE ON INTELLIGENT ROBOT SYSTEMS (ACIRS 2016), V0, PP204, DOI 10.1109/ACIRS.2016.7556213
   Koukoletsos T., 2011, P GEOCOMPUTATION LON, V0, P0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu Z., 2022, PROC IEEECVF C COMPU, V0, P11976
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP9992, DOI 10.1109/ICCV48922.2021.00986
   Ludwig I, 2011, LECT NOTES GEOINF CA, V1, P65, DOI 10.1007/978-3-642-19789-5_4
   Ma JZ, 2022, ISPRS INT J GEO-INF, V11, P0, DOI 10.3390/ijgi11060331
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Santosh KC, 2016, IEEE INTELL SYST, V31, P66, DOI 10.1109/MIS.2016.24
   Schafer B, 2021, INT J DOC ANAL RECOG, V24, P3, DOI 10.1007/s10032-020-00361-1
   Unsalan C, 2012, IEEE T GEOSCI REMOTE, V50, P4441, DOI 10.1109/TGRS.2012.2190078
   Vokhidov H, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16122160
   Wu Y., 2019, DETECTRON 2, V0, P0
   Yu TF, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10110761
   Zielstra D, 2012, TRANSPORT RES REC, V0, PP41, DOI 10.3141/2299-05
NR 30
TC 0
Z9 0
U1 1
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD AUG 15
PY 2022
VL 11
IS 8
BP 
EP 
DI 10.3390/ijgi11080448
PG 20
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA 4C8JR
UT WOS:000846692800001
DA 2023-04-26
ER

PT J
AU Zhou, LM
   Rao, XH
   Li, YH
   Zuo, XY
   Qiao, BJ
   Lin, YH
AF Zhou, Liming
   Rao, Xiaohan
   Li, Yahui
   Zuo, Xianyu
   Qiao, Baojun
   Lin, Yinghao
TI A Lightweight Object Detection Method in Aerial Images Based on Dense Feature Fusion Path Aggregation Network
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE feature reuse module; residual dense block; dense feature fusion; remote sensing
AB In recent years, significant progress has been obtained in object detection using Convolutional Neural Networks (CNNs). However, owing to the particularity of Remote Sensing Images (RSIs), common object detection methods are not well suited for RSIs. Aiming at the difficulties in RSIs, this paper proposes an object detection method based on the Dense Feature Fusion Path Aggregation Network (DFF-PANet). Firstly, for better improving the detection performance of small and medium-sized instances, we propose Feature Reuse Module (FRM), which can integrate semantic and location information contained in feature maps; this module can reuse feature maps in the backbone to enhance the detection capability of small and medium-sized instances. After that, we design the DFF-PANet, which can help feature information extracted from the backbone to be fused more efficiently, and thus cope with the problem of external interference factors. We performed experiments on the Dataset of Object deTection in Aerial images (DOTA) dataset and the HRSC2016 dataset; the accuracy reached 71.5% mAP, which exceeds most object detectors of one-stage and two-stages at present. Meanwhile, the size of our model is only 9.2 M, which satisfies the requirement of being lightweight. The experimental results demonstrate that our method not only has better detection accuracy but also maintains high efficiency in RSIs.
C1 [Zhou, Liming; Rao, Xiaohan; Li, Yahui; Zuo, Xianyu; Qiao, Baojun; Lin, Yinghao] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475000, Peoples R China.
   [Zhou, Liming; Rao, Xiaohan; Li, Yahui; Zuo, Xianyu; Qiao, Baojun; Lin, Yinghao] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475000, Peoples R China.
C3 Henan University; Henan University
RP Zuo, XY (corresponding author), Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475000, Peoples R China.; Zuo, XY (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng 475000, Peoples R China.
EM lmzhou@henu.edu.cn; rshenhaibb@henu.edu.cn; liyahui@henu.edu.cn; xianyu_zuo@henu.edu.cn; qbj@henu.edu.cn; linyh@henu.edu.cn
FU National Basic Research Program of China [2019YFE0126600]; Major Project of Science and Technology of Henan Province [201400210300]; Key Scientific and Technological Project of Henan Province [212102210496]; Key Research and Promotion Projects of Henan Province [212102210393, 202102110121, 222102320163]; Kaifeng science and technology development plan [2002001]
CR [Anonymous], 2015, P INT C MACH LEARN, V0, P0
   Azimi SM, 2019, LECT NOTES COMPUT SC, V11363, P150, DOI 10.1007/978-3-030-20893-6_10
   Bochkovskiy A, 2020, PREPRINT, V0, P0
   Cao CQ, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20174696
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Ding J., 2018, ARXIV PREPRINT ARXIV, V0, P0
   Ding J, 2022, IEEE T PATTERN ANAL, V44, P7778, DOI 10.1109/TPAMI.2021.3117983
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu G, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050498
   Girshick R., 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Girshick R., 2014, P IEEE COMP SOC COL, V0, P0
   Glorot X., 2011, P 14 INT C ART INT S, V0, P315
   Huang W, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13050847
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li X, 2013, ACM T INTEL SYST TEC, V4, P0, DOI 10.1145/2508037.2508039
   Liao MH, 2018, PROC CVPR IEEE, V0, PP5909, DOI 10.1109/CVPR.2018.00619
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Liu ZK, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, V0, PP324, DOI 10.5220/0006120603240331
   Luo R, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13152940
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Ming Q, 2021, AAAI CONF ARTIF INTE, V35, P2355
   Qian W., 2019, ARXIV191108299, V0, P0
   Qing YH, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13112171
   Qu ZF, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13193908
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sun W., 2020, P IGARSS 2020 2020 I, V0, P0
   Sun ZZ, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13214209
   Tian Z, 2019, IEEE I CONF COMP VIS, V0, PP9626, DOI 10.1109/ICCV.2019.00972
   Wei LX, 2021, VISUAL COMPUT, V37, P133, DOI 10.1007/s00371-019-01787-3
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xiao ZF, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010073
   Yan J., 2019, R3DET REFINED SINGLE, V0, P0
   Yang X, 2021, PROC CVPR IEEE, V0, PP15814, DOI 10.1109/CVPR46437.2021.01556
   Yang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010132
   Yuan ZC, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13050862
   Zhang H, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19235284
   Zhang JM, 2020, MULTIMED TOOLS APPL, V79, P15095, DOI 10.1007/s11042-018-6562-8
   Zhang T., 2020, TELECOMMUN SCI, V36, P92
   Zhang YJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071196
   Zhang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P1745, DOI 10.1109/LGRS.2018.2856921
   Zheng T, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), V0, P0, DOI DOI 10.1145/3207677.3278092
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou K, 2016, DESTECH TRANS COMP, V0, P0
   Zhu HM, 2019, REMOTE SENS LETT, V10, P959, DOI 10.1080/2150704X.2019.1633486
   Zhu J, 2018, IEEE GEOSCI REMOTE S, V15, P1254, DOI 10.1109/LGRS.2018.2830403
NR 52
TC 4
Z9 5
U1 6
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD MAR 15
PY 2022
VL 11
IS 3
BP 
EP 
DI 10.3390/ijgi11030189
PG 24
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA 0C5MH
UT WOS:000775356600001
DA 2023-04-26
ER

PT J
AU Cai, XB
   Yuan, WX
   Liu, XH
   Wang, XH
   Chen, YP
   Deng, XJ
   Wu, Q
   Han, K
   Cao, ZY
   Wu, WD
   Wang, BJ
AF Cai, Xiaobo
   Yuan, Wenxia
   Liu, Xiaohui
   Wang, Xinghua
   Chen, Yaping
   Deng, Xiujuan
   Wu, Qi
   Han, Ke
   Cao, Zhiyong
   Wu, Wendou
   Wang, Baijuan
TI Deep Learning Model for Soil Environment Quality Classification of Pu-erh Tea
SO FORESTS
LA English
DT Article
DE soil environment; deep learning; grade classification; Pu-erh tea
AB Pu-erh tea, Camellia sinensis is a traditional Chinese tea, one of the black teas, originally produced in China's Yunnan Province, named after its origin and distribution center in Pu-erh, Yunnan. Yunnan Pu-erh tea is protected by geographical Indication and has unique quality characteristics. It is made from Yunnan large-leaf sun-green tea with specific processing techniques. The quality formation of Pu-erh tea is closely related to the soil's environmental conditions. In this paper, time-by-time data of the soil environment of tea plantations during the autumn tea harvesting period in Menghai County, Xishuangbanna, Yunnan Province, China, in 2021 were analyzed. Spearman's correlation analysis was conducted between the inner components of Pu'er tea and the soil environmental factor. The analysis showed that three soil environmental indicators, soil temperature, soil moisture, and soil pH, were highly significantly correlated. The soil environmental quality evaluation method was proposed based on the selected soil environmental characteristics. Meanwhile, a deep learning model of Long Short Term Memory (LSTM) Network for the soil environmental quality of tea plantation was established according to the proposed method, and the soil environmental quality of tea was classified into four classes. In addition, the paper also compares the constructed models based on BP neural network and random forest to evaluate the coefficient of determination (R-2), mean absolute error (MAE), mean square error (MSE), mean absolute percentage error (MAPE) and root mean square error (RMSE) of the indicators for comparative analysis. This paper innovatively proposes to introduce the main inclusions of Pu'er tea into the classification and discrimination model of the soil environment in tea plantations, while using machine learning-related algorithms to classify and predict the categories of soil environmental quality, instead of relying solely on statistical data for analysis. This research work makes it possible to quickly and accurately determines the physiological status of tea leaves based on the establishment of a soil environment quality prediction model, which provides effective data for the intelligent management of tea plantations and has the advantage of rapid and low-cost assessment compared with the need to measure the intrinsic quality of Pu-erh tea after harvesting is completed.
C1 [Cai, Xiaobo; Yuan, Wenxia; Liu, Xiaohui; Wang, Xinghua; Chen, Yaping; Deng, Xiujuan; Wu, Qi; Cao, Zhiyong; Wu, Wendou; Wang, Baijuan] Yunnan Agr Univ, Yunnan Organ Tea Ind Intelligent Engn Res Ctr, Key Lab Intelligent Organ Tea Garden Construct, Kunming 650201, Peoples R China.
   [Han, Ke] Kunming Met Coll, Coll Elect & Mech, Kunming 650033, Peoples R China.
C3 Yunnan Agricultural University
RP Wang, BJ (corresponding author), Yunnan Agr Univ, Yunnan Organ Tea Ind Intelligent Engn Res Ctr, Key Lab Intelligent Organ Tea Garden Construct, Kunming 650201, Peoples R China.
EM wangbaijuan123@126.com
FU Yunnan Science and Technology Major Project [202002AE 09001004]; National Natural Science Foundation of China [32060702]; Yunnan Provincial Basic Research Project [202101AT070267]; scientific research fund project of Kunming Metallurgy College [2020XJZK01]; Scientific research fund project of Yunnan Provincial Education Department [2021J0943]; Yunnan Province "Ten Thousand People Plan" Industrial Technology Leading Talents Project [YNWR-CYJS-2018-009]; Yunnan Province Technology Innovation Talent Project [2019BH089]
CR Cai LL, 2019, INT CONF SIM SEMI PR, V0, P1
   Cao HB, 2010, SCI TOTAL ENVIRON, V408, P2777, DOI 10.1016/j.scitotenv.2010.03.019
   Chan EW C., 2021, J CHIN PHARM SCI, V30, P11
   Chen J., 2020, ADV FOREST MANAGEMEN, V0, P0, DOI DOI 10.5772/intechopen.87525
   Chen J, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11030343
   Cheng E.S., 2021, P 2021 IEEE INT C CO, V0, P1
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, PI, DOI 10.1561/2000000039
   Gayathri S., 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS AND SUSTAINABLE COMMUNICATION SYSTEMS (ICESC). PROCEEDINGS, V0, PP398, DOI 10.1109/ICESC48915.2020.9155850
   Ge YH, 2021, FOOD CHEM, V358, P0, DOI 10.1016/j.foodchem.2021.129602
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He HF, 2020, AGRICULTURE-BASEL, V10, P0, DOI 10.3390/agriculture10020047
   Hong ZQ, 2021, INFRARED PHYS TECHN, V114, P0, DOI 10.1016/j.infrared.2021.103666
   Hu GS, 2022, SUSTAIN COMPUT-INFOR, V35, P0, DOI 10.1016/j.suscom.2022.100696
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Jun Tian, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1952, P0, DOI 10.1088/1742-6596/1952/2/022063
   Kamrul M.H., 2020, P INT C COMPUTING AD, V0, P1
   Karak T, 2017, J HAZARD MATER, V338, P250, DOI 10.1016/j.jhazmat.2017.05.036
   Khanali M, 2017, ENVIRON SCI POLLUT R, V24, P26324, DOI 10.1007/s11356-017-0234-5
   Kimutai G, 2020, DATA, V5, P0, DOI 10.3390/data5020044
   Latha RS, 2021, INT CONF COMP COMMUN, V0, P0, DOI DOI 10.1109/ICCCI50826.2021.9402225
   Lee LK, 2013, FOOD RES INT, V53, P619, DOI 10.1016/j.foodres.2013.02.036
   Li Y., 2022, INT J AGR BIOL ENG, V15, P0
   Liu JY, 2021, FOOD CHEM, V353, P0, DOI 10.1016/j.foodchem.2021.129439
   Liu YJ, 2007, ENVIRON POLLUT, V145, P387, DOI 10.1016/j.envpol.2006.05.010
   Liu YX, 2021, FIELD CROP RES, V264, P0, DOI 10.1016/j.fcr.2021.108098
   Meng Y, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, V0, P1281, DOI 10.1109/ICECC.2011.6066400
   Paranavithana I.R., 2021, IAENG INT J COMPUT S, V48, P599
   Paul A, 2021, J SPAT SCI, V0, P0, DOI DOI 10.1080/14498596.2021.2013966
   Phan P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111814
   Plawiak P, 2014, SENSOR ACTUAT B-CHEM, V192, P117, DOI 10.1016/j.snb.2013.10.065
   Qi C, 2022, EXPERT SYST APPL, V193, P0, DOI 10.1016/j.eswa.2021.116473
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sitienei BJ, 2017, CLIMATE, V5, P0, DOI 10.3390/cli5030054
   Tang ZX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182935
   Tao Gong, 2021, 2021 3RD INTERNATIONAL SYMPOSIUM ON ROBOTICS & INTELLIGENT MANUFACTURING TECHNOLOGY (ISRIMT), V0, PP264, DOI 10.1109/ISRIMT53730.2021.9596977
   Tresch S, 2018, FRONT ENV SCI-SWITZ, V6, P0, DOI 10.3389/fenvs.2018.00136
   Wang X.V., 2021, PROCEDIA CIRP, V104, P906, DOI 10.1016/j.procir.2021.11.152
   Xiaoxiao Sun, 2018, 2018 INTERNATIONAL CONFERENCE ON SECURITY, V0, P0
   Xu WK, 2022, COMPUT ELECTRON AGR, V192, P0, DOI 10.1016/j.compag.2021.106547
   Yang HL, 2019, IEEE ACCESS, V7, P180998, DOI 10.1109/ACCESS.2019.2958614
   Yang HL, 2021, COMPUT ELECTRON AGR, V181, P0, DOI 10.1016/j.compag.2020.105946
   Yang ZW, 2021, COMPUT ELECTRON AGR, V187, P0, DOI 10.1016/j.compag.2021.106297
   Zhang J, 2018, INT J ENV RES PUB HE, V15, P0, DOI 10.3390/ijerph15010133
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang ZF, 2021, FOOD SCI NUTR, V9, P4883, DOI 10.1002/fsn3.2437
NR 45
TC 0
Z9 0
U1 8
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1999-4907
J9 FORESTS
JI Forests
PD NOV 15
PY 2022
VL 13
IS 11
BP 
EP 
DI 10.3390/f13111778
PG 19
WC Forestry
SC Forestry
GA 6B2QB
UT WOS:000881183000001
DA 2023-04-26
ER

PT J
AU Tejeswari, B
   Sharma, SK
   Kumar, M
   Gupta, K
AF Tejeswari, Banda
   Sharma, Surendra Kumar
   Kumar, Minakshi
   Gupta, Kshama
TI BUILDING FOOTPRINT EXTRACTION FROM SPACE- BORNE IMAGERY USING DEEP NEURAL NETWORKS
SO XXIV ISPRS CONGRESS IMAGING TODAY, FORESEEING TOMORROW, COMMISSION II
LA English
DT Proceedings Paper
DE Deep Learning; Building foot-pint extraction; Mask RCNN; Open Source training data; Open Street Map; Remote Sensing; Satellite imagery
AB One of the important and high-level detailing contained within basemaps is the 'building feature'. Though pre-trained Deep Learning (DL) models are available for Building Feature Extraction (BFE), they are not efficient in predicting the buildings in other locations. This study explores the need and the major issue of implementing DL models for BFE from Very High Resolution Remote Sensing (VHRS) satellite data for any given area. Though advanced DL models are invented, in order to implement them, huge amount of potential training data is demanded for feed in. the building typologies are highly subjected to the context of study area including soil characteristics, culture/lifestyle/economy, architectural style and the building byelaws. The study believes that availability of enough training data of contextual buildings as one of the concern for effective model training. The study aims to extract the buildings present in the study area from Pleiades 1A (2019) RGB VHRS data using simple Mask R-CNN instance segmentation model which is training on the native contextual buildings. Here, an automated method of generating the location-specific training data for a given area is followed using Google Maps API (2021). The generated training data when trained on a deep learning architecture and predicted by the input data yielded promising results. The prediction accuracy of about 98.41% specificity, 96.20% predictive accuracy and 0.89 F1 score are achieved. The methods adopted assist the planning/governing bodies to accelerate the qualitative urban map preparation.
C1 [Tejeswari, Banda; Sharma, Surendra Kumar; Gupta, Kshama] Indian Inst Remote Sensing, URSD, Dehra Dun, Uttarakhand, India.
   [Kumar, Minakshi] Indian Inst Remote Sensing, PRSD, Dehra Dun, Uttarakhand, India.
C3 Department of Space (DoS), Government of India; Indian Space Research Organisation (ISRO); Indian Institute of Remote Sensing (IIRS); Department of Space (DoS), Government of India; Indian Space Research Organisation (ISRO); Indian Institute of Remote Sensing (IIRS)
RP Sharma, SK (corresponding author), Indian Inst Remote Sensing, URSD, Dehra Dun, Uttarakhand, India.
EM bandatejaswari@gmail.com; ssharma3@ce.iitr.ac.in; minakshikumar900@gmail.com; gupta.kshama@gmail.com
CR Aung HT, 2022, GEOCARTO INT, V37, P792, DOI 10.1080/10106049.2020.1740949
   Gavankar NL, 2018, EUR J REMOTE SENS, V51, P182, DOI 10.1080/22797254.2017.1416676
   Li WJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040403
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), V0, P0, DOI DOI 10.1145/3173574.3173703
   Roscher R., 2020, ISPRS ANN PHOTOGRAMM, V5, P109
   Wang C, 2014, OPTIK, V125, P5588, DOI 10.1016/j.ijleo.2014.07.002
   Wen Q, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19020333
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
NR 8
TC 0
Z9 0
U1 1
U2 1
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 1682-1750
EI 2194-9034
J9 INT ARCH PHOTOGRAMM
PD JUN 15
PY 2022
VL 43-B2
IS 
BP 641
EP 647
DI 10.5194/isprs-archives-XLIII-B2-2022-641-2022
PG 7
WC Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA BT8VT
UT WOS:000855635300088
DA 2023-04-26
ER

PT J
AU Jonnalagadda, J
   Hashemi, M
AF Jonnalagadda, Jahnavi
   Hashemi, Mahdi
TI Feature Selection and Spatial-Temporal Forecast of Oceanic Nino Index Using Deep Learning
SO INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING
LA English
DT Article
DE Spatial-temporal forecast; feature selection; ENSO events; climate anomalies
ID tropical pacific; el-nino; long; model
AB El Nino-Southern Oscillation (ENSO) is a climate phenomenon caused due to irregular periodic oscillation in easterly winds and sea surface temperature (SST) over the tropical Pacific Ocean. ENSO is one of the main drivers of Earth's inter-annual climate variability, which causes climate anomalies in the form of tropical cyclones, severe storms, heavy rainfalls and droughts. Due to the impact of ENSO on global climate, forecasting ENSO is of great importance. However, forecast accuracy of ENSO for a lead time of one year is low. ENSO events are forecasted through Oceanic Nino Index (ONI), which is the three-month running mean of SST anomalies over the Nino 3.4 region (5 degrees N-5 degrees S, 120 degrees W-170 degrees W). Features, such as SST, sea level pressure, zonal wind speed and meridional wind speed that contribute in determining ONI are mapped on spatial or geographical grids, where each spatial or geographical grid represents the values of one feature at a snapshot. Juxtaposing the spatial grids of all features creates a layered map at a snapshot. The layered spatial feature map is constructed at different snapshots, and they all are fed to the CLSTM to forecast ONI at lead times of 1, 3, 6, 9 and 12 months. This study employs backward stepwise feature selection based on generalization accuracy to find the most effective features. SST showed to be the best feature for forecasting ONI. Experiments showed that the CLSTM outperforms Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM) and Standard Neural Network (SNN) in terms of coefficient of determination (R2), Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). More specifically, an improvement in R2 values by 27.6%, 20.9%, 25% and 15.2% over CNN is observed for lead times of 3, 6, 9 and 12 months, respectively.
C1 [Jonnalagadda, Jahnavi; Hashemi, Mahdi] George Mason Univ, Dept Informat Sci & Technol, 4400 Univ Dr, Fairfax, VA 22030 USA.
C3 George Mason University
RP Jonnalagadda, J (corresponding author), George Mason Univ, Dept Informat Sci & Technol, 4400 Univ Dr, Fairfax, VA 22030 USA.
EM jjonnala@gmu.edu; mhashem2@gmu.edu
CR Aguilar-Martinez S., 2009, INT J OCEANOGRAPHY, V2009, P1, DOI 10.1155/2009/167239
   [Anonymous], 1997, NEURAL COMPUT, V0, P0
   Baawain MS, 2005, J ENVIRON ENG SCI, V4, P113, DOI 10.1139/S04-047
   Dijkstra HA, 2019, FRONT PHYS-LAUSANNE, V7, P0, DOI 10.3389/fphy.2019.00153
   Ha S, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-90964-3
   Ham YG, 2019, NATURE, V573, P568, DOI 10.1038/s41586-019-1559-7
   Hashemi M, 2021, IEEE J-STARS, V14, P3438, DOI 10.1109/JSTARS.2021.3065585
   Hashemi M, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0263-7
   Hashemi M, 2020, IEEE J-STARS, V13, P3066, DOI 10.1109/JSTARS.2020.2995834
   Hashemi M, 2020, MULTIMED TOOLS APPL, V79, P11921, DOI 10.1007/s11042-019-08373-8
   Hashemi M, 2016, L N INST COMP SCI SO, V166, P468, DOI 10.1007/978-3-319-33681-7_39
   Hashemi M, 2017, EARTHQ ENG ENG VIB, V16, P33, DOI 10.1007/s11803-017-0366-0
   Hashemi M, 2011, LECT NOTES GEOINF CA, V1, P3, DOI 10.1007/978-3-642-19789-5_1
   Hashemi M, 2019, IMAGE VISION COMPUT, V89, P95, DOI 10.1016/j.imavis.2019.06.001
   Hashemi M, 2013, COMPUT GEOSCI-UK, V58, P8, DOI 10.1016/j.cageo.2013.04.005
   He YX, 1996, J CLIMATE, V9, P2020, DOI 10.1175/1520-0442(1996)009<2020:LLFOSP>2.0.CO;2
   Jonnalagadda J., 2021, 33 INT C SOFTW ENG K, V0, P309
   Jonnalagadda J, 2020, 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2020), V0, PP209, DOI 10.1109/IRI49571.2020.00037
   Lakshminarayanan B., 2017, ADV NEURAL INFORM PR, V4, P0, DOI 10.5555/3295222.3295387
   McDermott PL, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21020184
   Mu B, 2019, IEEE IJCNN, V0, P0
   Nooteboom PD, 2018, EARTH SYST DYNAM, V9, P969, DOI 10.5194/esd-9-969-2018
   Petersik PJ, 2020, GEOPHYS RES LETT, V47, P0, DOI 10.1029/2019GL086423
   Philander S.G.H., 1990, NINO NINA SO OSCILLA, V0, P0
   Saha S, 2014, J CLIMATE, V27, P2185, DOI 10.1175/JCLI-D-12-00823.1
   Shi XJ, 2015, ADV NEUR IN, V28, P0
   Tangang FT, 1998, J GEOPHYS RES-OCEANS, V103, P7511, DOI 10.1029/97JC03414
   VANDENDOOL HM, 1994, TELLUS A, V46, P314, DOI 10.1034/j.1600-0870.1994.t01-2-00006.x
   Xue Y, 2000, GEOPHYS RES LETT, V27, P2701, DOI 10.1029/1999GL011107
   Zhang HP, 2019, CLIM DYNAM, V53, P3373, DOI 10.1007/s00382-019-04710-7
NR 31
TC 2
Z9 2
U1 4
U2 13
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-1940
EI 1793-6403
J9 INT J SOFTW ENG KNOW
JI Int. J. Softw. Eng. Knowl. Eng.
PD JAN 15
PY 2022
VL 32
IS 01
BP 91
EP 107
DI 10.1142/S0218194022500048
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA ZG4ZX
UT WOS:000760269000004
DA 2023-04-26
ER
