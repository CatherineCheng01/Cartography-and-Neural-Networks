
PT J
AU Mohammadifar, A
   Gholami, H
   Golzari, S
AF Mohammadifar, Aliakbar
   Gholami, Hamid
   Golzari, Shahram
TI Assessment of the uncertainty and interpretability of deep learning models for mapping soil salinity using DeepQuantreg and game theory
SO SCIENTIFIC REPORTS
LA English
DT Article
AB This research introduces a new combined modelling approach for mapping soil salinity in the Minab plain in southern Iran. This study assessed the uncertainty (with 95% confidence limits) and interpretability of two deep learning (DL) models (deep boltzmann machine-DBM) and a one dimensional convolutional neural networks (1DCNN)-long short-term memory (LSTM) hybrid model (1DCNN-LSTM) for mapping soil salinity by applying DeepQuantreg and game theory (Shapely Additive exPlanations (SHAP) and permutation feature importance measure (PFIM)), respectively. Based on stepwise forward regression (SFR)-a technique for controlling factor selection, 18 of 47 potential controls were selected as effective factors. Inventory maps of soil salinity were generated based on 476 surface soil samples collected for measuring electrical conductivity (ECe). Based on Taylor diagrams, both DL models performed well (RMSE < 20%), but the 1DCNN-LSTM hybrid model performed slightly better than the DBM model. The uncertainty range associated with the ECe values predicted by both models estimated using DeepQuantilreg were similar (0-25 dS/m for the 1DCNN-LSTM hybrid model and 2-27 dS/m for DBM model). Based on the SFR and PFIM (permutation feature importance measure)-a measure in game theory, four controls (evaporation, sand content, precipitation and vertical distance to channel) were selected as the most important factors for soil salinity in the study area. The results of SHAP (Shapely Additive exPlanations)-the second measure used in game theory-suggested that five factors (evaporation, vertical distance to channel, sand content, cation exchange capacity (CEC) and digital elevation model (DEM)) have the strongest impact on model outputs. Overall, the methodology used in this study is recommend for applications in other regions for mapping environmental problems.
C1 [Mohammadifar, Aliakbar; Gholami, Hamid] Univ Hormozgan, Dept Nat Resources Engn, Bandar Abbas, Hormozgan, Iran.
   [Golzari, Shahram] Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Hormozgan, Iran.
   [Golzari, Shahram] Univ Hormozgan, Deep Learning Res Grp, Bandar Abbas, Hormozgan, Iran.
C3 University of Hormozgan; University of Hormozgan; University of Hormozgan
RP Gholami, H (corresponding author), Univ Hormozgan, Dept Nat Resources Engn, Bandar Abbas, Hormozgan, Iran.
EM hgholami@hormozgan.ac.ir
FU Faculty of Agriculture and Natural Resources, University of Hormozgan, Iran
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Aly HHH, 2020, OCEAN ENG, V218, P0, DOI 10.1016/j.oceaneng.2020.108254
   [Anonymous], 2015, STATUS WORLDS SOIL R, V0, P0
   Boettinger JL, 2008, DIGITAL SOIL MAPPING WITH LIMITED DATA, V0, PP193, DOI 10.1007/978-1-4020-8592-5_16
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Butcher K, 2016, AGRON J, V108, P2189, DOI 10.2134/agronj2016.06.0368
   Chen W, 2017, CATENA, V151, P147, DOI 10.1016/j.catena.2016.11.032
   Bui DT, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104426
   Efroymson M., 1960, MATH METHODS DIGITAL, V0, P0
   Fan ST, 2020, OCEAN ENG, V205, P0, DOI 10.1016/j.oceaneng.2020.107298
   Gholami H, 2021, AEOLIAN RES, V50, P0, DOI 10.1016/j.aeolia.2021.100682
   Gibert K, 2018, ENVIRON MODELL SOFTW, V110, P3, DOI 10.1016/j.envsoft.2018.09.021
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   He W, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/8071810
   HOCKING RR, 1976, BIOMETRICS, V32, P1, DOI 10.2307/2529336
   Huang SZ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19092018
   Jia Y., 2020, DEEP LEARNING QUANTI, V0, P0
   Kakeh J, 2020, SCI TOTAL ENVIRON, V732, P0, DOI 10.1016/j.scitotenv.2020.139168
   Khan M., 2021, J SUPERCOMPUT, V77, P1
   Khan NM, 2005, AGR WATER MANAGE, V77, P96, DOI 10.1016/j.agwat.2004.09.038
   KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Mohammadifar A, 2021, ENVIRON SCI POLLUT R, V28, P39432, DOI 10.1007/s11356-021-13503-7
   Navamani TM, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, V0, PP123, DOI 10.1016/B978-0-12-816718-2.00014-2
   Panahi M, 2021, GEOSCI FRONT, V12, P0, DOI 10.1016/j.gsf.2020.09.007
   Ragab MG, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su122310090
   Rahmanian MR, 2011, LAKE RESERV MANAGE, V27, P245, DOI 10.1080/07438141.2011.602510
   Saggi MK, 2019, COMPUT ELECTRON AGR, V156, P387, DOI 10.1016/j.compag.2018.11.031
   Salakhutdinov R, 2009, ARTIFICIAL INTELLIGE, V0, P0
   Salakhutdinov R., 2010, P AISTATS, V0, P0
   Sidike P, 2019, REMOTE SENS ENVIRON, V221, P756, DOI 10.1016/j.rse.2018.11.031
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Nhu VH, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2020.104458
   Wang H, 2020, IEEE T IND INFORM, V16, P5735, DOI 10.1109/TII.2019.2955540
   Wang JZ, 2020, SCI TOTAL ENVIRON, V707, P0, DOI 10.1016/j.scitotenv.2019.136092
   Witten IH, 2017, DATA MINING: PRACTICAL MACHINE LEARNING TOOLS AND TECHNIQUES, V0, P0
   Wuyan Li, 2021, INFORMATION PROCESSING IN AGRICULTURE, V8, P185, DOI 10.1016/j.inpa.2020.02.002
   Xiaobin Zhang, 2018, PROCEDIA COMPUTER SCIENCE, V131, P911, DOI 10.1016/j.procs.2018.04.221
   Xu Y, 2021, MEASUREMENT, V169, P0, DOI 10.1016/j.measurement.2020.108502
   Yu XQ, 2020, FRONT BIOENG BIOTECH, V8, P0, DOI 10.3389/fbioe.2020.00063
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zhang B., 2016, 2016 IEEEACIS 15 INT, V0, P1
NR 43
TC 2
Z9 2
U1 11
U2 11
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
EI 
J9 SCI REP-UK
JI Sci Rep
PD SEP 7
PY 2022
VL 12
IS 1
BP 
EP 
DI 10.1038/s41598-022-19357-4
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA 4L4WQ
UT WOS:000852630800050
PM 36071137
DA 2023-04-26
ER

PT J
AU Qazi, AS
   Farooq, MS
   Rustam, F
   Villar, MG
   Rodriguez, CL
   Ashraf, I
AF Qazi, Awais Salman
   Farooq, Muhammad Shoaib
   Rustam, Furqan
   Gracia Villar, Monica
   Lili Rodriguez, Carmen
   Ashraf, Imran
TI Emotion Detection Using Facial Expression Involving Occlusions and Tilt
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE facial expression recognition; convolutional neural network; machine learning; support vector machines
ID recognition
AB Facial emotion recognition (FER) is an important and developing topic of research in the field of pattern recognition. The effective application of facial emotion analysis is gaining popularity in surveillance footage, expression analysis, activity recognition, home automation, computer games, stress treatment, patient observation, depression, psychoanalysis, and robotics. Robot interfaces, emotion-aware smart agent systems, and efficient human-computer interaction all benefit greatly from facial expression recognition. This has garnered attention as a key prospect in recent years. However, due to shortcomings in the presence of occlusions, fluctuations in lighting, and changes in physical appearance, research on emotion recognition has to be improved. This paper proposes a new architecture design of a convolutional neural network (CNN) for the FER system and contains five convolution layers, one fully connected layer with rectified linear unit activation function, and a SoftMax layer. Additionally, the feature map enhancement is applied to accomplish a higher detection rate and higher precision. Lastly, an application is developed that mitigates the effects of the aforementioned problems and can identify the basic expressions of human emotions, such as joy, grief, surprise, fear, contempt, anger, etc. Results indicate that the proposed CNN achieves 92.66% accuracy with mixed datasets, while the accuracy for the cross dataset is 94.94%.
C1 [Qazi, Awais Salman; Farooq, Muhammad Shoaib] Univ Management & Technol, Dept Comp Sci, Lahore 54000, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin D04 V1W8, Ireland.
   [Gracia Villar, Monica; Lili Rodriguez, Carmen] Univ Europea Atlantico, Fac Social Sci & Humanities, Isabel Torres 21, Santander 39011, Spain.
   [Gracia Villar, Monica] Univ Int Iberoamer, Dept Project Management, Arecibo, PR 00613 USA.
   [Gracia Villar, Monica] Univ Int Cuanza, Dept Extens, EN250, Cuito, Bie, Angola.
   [Lili Rodriguez, Carmen] Univ Int Iberoamer, Dept Project Management, Campeche 24560, Campeche, Mexico.
   [Lili Rodriguez, Carmen] Fdn Univ Int Colombia, Bogota 111311, Colombia.
   [Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 University of Management & Technology (UMT); University College Dublin; Yeungnam University
RP Villar, MG (corresponding author), Univ Europea Atlantico, Fac Social Sci & Humanities, Isabel Torres 21, Santander 39011, Spain.; Villar, MG (corresponding author), Univ Int Iberoamer, Dept Project Management, Arecibo, PR 00613 USA.; Villar, MG (corresponding author), Univ Int Cuanza, Dept Extens, EN250, Cuito, Bie, Angola.; Ashraf, I (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM monica.gracia@uneatlantico.es; imranashraf@ynu.ac.kr
FU European University of the Atlantic
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Akhand MAH, 2021, ELECTRONICS-SWITZ, V10, P0, DOI 10.3390/electronics10091036
   Al-Tuwaijari Jamal M., 2020, 2020 6TH INTERNATIONAL ENGINEERING CONFERENCE, V0, P211, DOI 10.1109/IEC49899.2020.9122927
   Anil J., 2016, 2016 INT C CIRCUIT P, V0, PP1, DOI 10.1109/ICCPCT.2016.7530173
   Ashwin TS, 2015, IEEE CONF TECHNOL ED, V0, PP23, DOI 10.1109/T4E.2015.21
   Berbar MA, 2006, P GEOM MOD IM NEW TR, V0, PP209, DOI 10.1109/GMAI.2006.18
   Boser B. E., 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP144, DOI 10.1145/130385.130401
   Bost R, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), V0, P0, DOI DOI 10.14722/ndss.2015.23241
   Chu CC, 2015, INT CONF MACH LEARN, V0, PP586, DOI 10.1109/ICMLC.2015.7340620
   Dalgleish T, 1999, HDB COGNITION EMOTIO, V0, P0
   Ekman P., 1977, FACIAL ACTION CODING, V0, P0
   Ekman Paul, 2013, EMOTION HUMAN FACE G, V11, P0
   Fnaiech A, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), V0, PP172, DOI 10.1109/ATSIP.2016.7523090
   Gavrilescu M, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19173693
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Haykin S., 2009, NEURAL NETWORKS LEAR, V0, P0
   Ijjina EP, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP392, DOI 10.1109/ICMLA.2014.70
   Jaiswal S, 2020, NEURAL COMPUT APPL, V32, P11253, DOI 10.1007/s00521-019-04564-4
   Jeni L. A., 2013, PROC 10 IEEE INT C W, V0, P1
   Kiran T, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, V0, P0
   Li SC, 2016, DES AUT CON, V0, P0, DOI DOI 10.1145/2897937.2898064
   Mehendale N., 2021, FACIAL EMOTION RECOG, V2, P1
   Mostafa A, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), V0, PP417, DOI 10.1109/ICCES.2018.8639182
   Muttu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), V0, PP102, DOI 10.1109/INFOP.2015.7489359
   Paul T., 2018, INT J BIOMED SOFT CO, V23, P27, DOI 10.24466/IJBSCHS
   Pauly L, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, V0, P0
   Radlak K., 2016, 2016 18 MED EL C MEL, V0, P1
   Roshanzamir M, 2021, ARXIV, V0, P0
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Rusia MK, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), V0, PP612, DOI 10.1109/ICIIP47207.2019.8985867
   Salmam FZ, 2016, I C COMP GRAPH IM VI, V0, PP125, DOI 10.1109/CGiV.2016.33
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Tivatansakul S, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN HEALTHCARE AND E-HEALTH (CICARE), V0, PP40, DOI 10.1109/CICARE.2014.7007832
   Xiao HF, 2022, APPL SCI-BASEL, V12, P0, DOI 10.3390/app12020807
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yao L, 2021, MULTIMED TOOLS APPL, V80, P24287, DOI 10.1007/s11042-021-10836-w
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
NR 38
TC 0
Z9 0
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD NOV 15
PY 2022
VL 12
IS 22
BP 
EP 
DI 10.3390/app122211797
PG 24
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA 6J9WS
UT WOS:000887166800001
DA 2023-04-26
ER

PT J
AU Jang, SS
   Kim, CJ
   Hwang, SY
   Lee, MJ
   Ha, YG
AF Jang, Sung-su
   Kim, Cheol-jin
   Hwang, Seong-yeon
   Lee, Myung-jae
   Ha, Young-guk
TI L-GAN: landmark-based generative adversarial network for efficient face de-identification
SO JOURNAL OF SUPERCOMPUTING
LA English
DT Article; Early Access
DE Facial landmark; GAN; Face de-identification; Face generation
ID privacy
AB A large amount of high-quality data are collected through autonomous vehicles, CCTVs, guidance service robots, and web map services (Google Street View). However, the data collected through them include personal information such as peoples' faces and vehicle license plates. Currently, personal information contained in data is de-identified using methods such as face blur, pixelation, and masking. Consequently, it loses value as data for artificial intelligence (AI) learning. Therefore, in this study, we propose a model to generate a fake face that maintains the basic structure of the human face. There are several methods for generating faces. One is to generate them using a generative adversarial network (GAN) model. The GAN is an AI algorithm used for unsupervised learning and is implemented by a system in which two neural networks compete. However, because GAN operates as an input of a random noise vector, it is difficult to obtain results for the desired face angle and shape. Therefore, pre- and post-processing is required to generate a fake face that maintains the basic structure and angles; however, the calculation is complicated, and it is difficult to generate a natural image. To solve this problem, we propose a method for generating a fake face that maintains the basic structure and angle of the real face by applying a facial landmark. Using the proposed method, it was possible to generate a fake face with a different impression while maintaining the basic structure and angle of the face.
C1 [Jang, Sung-su; Kim, Cheol-jin; Hwang, Seong-yeon; Lee, Myung-jae; Ha, Young-guk] Konkuk Univ, Dept Comp Sci & Engn, Seoul 143701, South Korea.
C3 Konkuk University
RP Ha, YG (corresponding author), Konkuk Univ, Dept Comp Sci & Engn, Seoul 143701, South Korea.
EM pik1100@naver.com; cjfwls1070@naver.com; wiw100@naver.com; dualespresso@naver.com; ygha@konkuk.ac.kr
FU Konkuk University Researcher Fund
CR Berthelot D, 2017, ARXIV, V0, P0
   Chen JW, 2018, IEEE COMPUT SOC CONF, V0, PP1651, DOI 10.1109/CVPRW.2018.00207
   Cho D, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10031120
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Culjak I., 2012, 2012 35TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, V0, P1725
   Demir U, 2018, ARXIV, V0, P0
   Du L, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014), V0, P0
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Goodfellow IJ, 2014, 28 C NEURAL INFORM P, V27, P2672, DOI 10.48550/ARXIV.1406.2661
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Gross Ralph, 2006, 2006 C COMPUTER VISI, V0, P161
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Hukkelas H, 2020, LECT NOTES COMPUT SC, V11844, P565, DOI 10.1007/978-3-030-33720-9_44
   Ide H, 2017, IEEE IJCNN, V0, PP2684, DOI 10.1109/IJCNN.2017.7966185
   Isola P, 2017, PROC CVPR IEEE, V0, PP5967, DOI 10.1109/CVPR.2017.632
   Jourabloo A, 2015, INT CONF BIOMETR, V0, PP278, DOI 10.1109/ICB.2015.7139096
   Karras T, 2019, PROC CVPR IEEE, V0, PP4396, DOI 10.1109/CVPR.2019.00453
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li J, 2019, PROC CVPR IEEE, V0, PP5055, DOI 10.1109/CVPR.2019.00520
   Li T, 2019, IEEE COMPUT SOC CONF, V0, PP56, DOI 10.1109/CVPRW.2019.00013
   Li YX, 2021, IEEE SIGNAL PROC LET, V28, P1345, DOI 10.1109/LSP.2021.3067517
   Liu YJ, 2017, IEEE INT CONF COMP V, V0, PP1619, DOI 10.1109/ICCVW.2017.190
   Liu Z., 2018, LARGE SCALE CELEBFAC, V15, P2018
   Mao XD, 2017, IEEE I CONF COMP VIS, V0, PP2813, DOI 10.1109/ICCV.2017.304
   McPherson R, 2016, ARXIV, V0, P0
   Meden B, 2021, IEEE T INF FOREN SEC, V16, P4147, DOI 10.1109/TIFS.2021.3096024
   Mirza M, 2014, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.1411.1784
   Murez Z, 2018, PROC CVPR IEEE, V0, PP4500, DOI 10.1109/CVPR.2018.00473
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Nguyen TT, 2019, ARXIV, V0, P0
   Oh SJ, 2016, LECT NOTES COMPUT SC, V9907, P19, DOI 10.1007/978-3-319-46487-9_2
   Radford A, 2016, ARXIV, V0, P0
   Ren ZZ, 2018, LECT NOTES COMPUT SC, V11205, P639, DOI 10.1007/978-3-030-01246-5_38
   Ribaric S, 2016, SIGNAL PROCESS-IMAGE, V47, P131, DOI 10.1016/j.image.2016.05.020
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shu Chang, 2011, TSINGHUA SCIENCE AND TECHNOLOGY, V16, P216, DOI 10.1016/S1007-0214(11)70032-3
   Sun QR, 2018, PROC CVPR IEEE, V0, PP5050, DOI 10.1109/CVPR.2018.00530
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/7068349
   Wang HP, 2021, IEEE COMPUT SOC CONF, V0, PP3275, DOI 10.1109/CVPRW53098.2021.00366
   Wen YQ, 2021, ARXIV, V0, P0
   Zhan FN, 2019, PROC CVPR IEEE, V0, PP3648, DOI 10.1109/CVPR.2019.00377
   Zhang X, 2022, PATTERN RECOGN, V124, P0, DOI 10.1016/j.patcog.2021.108415
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhenzhong Kuang, 2021, MM 21: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP3182, DOI 10.1145/3474085.3475464
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 49
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-8542
EI 1573-0484
J9 J SUPERCOMPUT
JI J. Supercomput.
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1007/s11227-022-04954-x
PG 28
WC Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 6J5ZC
UT WOS:000886899600002
DA 2023-04-26
ER

PT J
AU Wang, PH
   Qiao, JZ
   Liu, NN
AF Wang, Pinhe
   Qiao, Jianzhong
   Liu, Nannan
TI An Improved Convolutional Neural Network-Based Scene Image Recognition Method
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
LA English
DT Article
AB To solve the problems existing in the research of scene recognition, this paper studies a new convolutional neural network target detection model to achieve a better balance between the accuracy and speed of high-speed scene image recognition. First, aiming at the problem that the image is easy to be disturbed by impurities and poor quality in fine-grained image recognition, a preprocessing method based on the Canny edge detection is designed and the Canny operator is introduced to process the gray image. Second, the L2 regularization algorithm is used to optimize the basic network framework of the convolutional neural network, enhance the stability of the model in a complex environment, improve the generalization ability of the model, and improve the recognition accuracy of the algorithm to a certain extent. Finally, by collecting the campus environment datasets under different environmental conditions, the location recognition experiment and heat map visualization experiment are carried out. Experiments show that compared with the basic convolution neural network algorithm, the algorithm has better recognition performance and good generalization ability. The research of this study realizes the effective combination of multiframe convolution neural network and batch normalization algorithm and has a good practical effect on scene image recognition.
C1 [Wang, Pinhe; Qiao, Jianzhong] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110169, Peoples R China.
   [Liu, Nannan] China Coal Technol Intelligent Storage & Loading T, Beijing 100013, Peoples R China.
C3 Northeastern University - China
RP Wang, PH (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110169, Peoples R China.
EM 1710575@stu.neu.edu.cn; qiaojianzhong@mail.neu.edu.cn; liunn121@163.com
CR Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Guo ZW, 2022, IEEE T FUZZY SYST, V30, P4543, DOI 10.1109/TFUZZ.2021.3130311
   Guo ZW, 2021, SIMUL MODEL PRACT TH, V107, P0, DOI 10.1016/j.simpat.2020.102215
   Kang XD, 2019, IEEE GEOSCI REMOTE S, V16, P447, DOI 10.1109/LGRS.2018.2873476
   Khan, 2018, SYNTHESIS LECT COMPU, V8, P1, DOI 10.2200/S00822ED1V01Y201712COV015
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Manoharan S, 2019, J INNOVATIVE IMAGE P, V1, P61, DOI 10.36548/JIIP.2019.2.001
   Meng D, 2021, COMPUT COMMUN, V179, P231, DOI 10.1016/j.comcom.2021.08.014
   Parul Sharma, 2020, INFORMATION PROCESSING IN AGRICULTURE, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Peng YH, 2022, IEEE T IND INFORM, V18, P5670, DOI 10.1109/TII.2021.3139357
   Renuka B., 2018, ASIAN J APPL SCI TEC, V2, P495
   Soffer S, 2019, RADIOLOGY, V290, P590, DOI 10.1148/radiol.2018180547
   Tan L, 2022, IEEE T INTELL TRANSP, V23, P2830, DOI 10.1109/TITS.2021.3119921
   Versaci M, 2021, INT J FUZZY SYST, V23, P918, DOI 10.1007/s40815-020-01030-5
   Yadav SS, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0276-2
   Yang L, 2022, IEEE T IND INFORM, V18, P8864, DOI 10.1109/TII.2021.3128954
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yu KP, 2021, IEEE COMMUN MAG, V59, P76, DOI 10.1109/MCOM.101.2001126
   Zhao L, 2022, IEEE T RELIAB, V71, P951, DOI 10.1109/TR.2022.3159664
   Zhou DX, 2020, APPL COMPUT HARMON A, V48, P787, DOI 10.1016/j.acha.2019.06.004
NR 21
TC 0
Z9 0
U1 3
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-5265
EI 1687-5273
J9 COMPUT INTEL NEUROSC
JI Comput. Intell. Neurosci.
PD JUN 29
PY 2022
VL 2022
IS 
BP 
EP 
DI 10.1155/2022/3464984
PG 10
WC Mathematical & Computational Biology; Neurosciences
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA 5A1PJ
UT WOS:000862665900024
PM 35814559
DA 2023-04-26
ER

PT J
AU Drakonakis, GI
   Tsagkatakis, G
   Fotiadou, K
   Tsakalides, P
AF Drakonakis, Georgios, I
   Tsagkatakis, Grigorios
   Fotiadou, Konstantina
   Tsakalides, Panagiotis
TI OmbriaNet-Supervised Flood Mapping via Convolutional Neural Networks Using Multitemporal Sentinel-1 and Sentinel-2 Data Fusion
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Image segmentation; Remote sensing; Deep learning; Satellites; Synthetic aperture radar; Machine learning; Emergency services; Convolutional neural network (CNN); deep learning; flood mapping; remote sensing; Sentinel-1; Sentinel-2
ID support vector machines; difference water index; remote-sensing data; surface-water; semantic segmentation; sar; images; extraction; ndwi
AB Regions around the world experience adverse climate-change-induced conditions that pose severe risks to the normal and sustainable operations of modern societies. Extreme weather events, such as floods, rising sea levels, and storms, stand as characteristic examples that impair the core services of the global ecosystem. Especially floods have a severe impact on human activities, hence, early and accurate delineation of the disaster is of top priority since it provides environmental, economic, and societal benefits and eases relief efforts. In this article, we introduce OmbriaNet, a deep neural network architecture, based on convolutional neural networks, that detects changes between permanent and flooded water areas by exploiting the temporal differences among flood events extracted by different sensors. To demonstrate the potential of the proposed approach, we generated OMBRIA, a bitemporal and multimodal satellite imagery dataset for image segmentation through supervised binary classification. It consists of a total number of 3.376 images, synthetic aperture radar imagery from Sentinel-1, and multispectral imagery from Sentinel-2, accompanied with ground-truth binary images produced from data derived by experts and provided from the Emergency Management Service of the European Space Agency Copernicus Program. The dataset covers 23 flood events around the globe, from 2017 to 2021. We collected, co-registrated and preprocessed the data in Google Earth Engine. To validate the performance of our method, we performed different benchmarking experiments on the OMBRIA dataset and we compared with several competitive state-of-the-art techniques. The experimental analysis demonstrated that the proposed formulation is able to produce high-quality flood maps, achieving a superior performance over the state-of-the-art. We provide OMBRIA dataset, as well as OmbriaNet code at: https://github.com/geodrak/OMBRIA.
C1 [Drakonakis, Georgios, I; Fotiadou, Konstantina; Tsakalides, Panagiotis] Univ Crete, Dept Comp Sci, Iraklion 70013, Greece.
   [Drakonakis, Georgios, I; Tsagkatakis, Grigorios; Fotiadou, Konstantina; Tsakalides, Panagiotis] Univ Crete, Inst Comp Sci, Iraklion 70013, Greece.
   [Drakonakis, Georgios, I; Tsagkatakis, Grigorios; Fotiadou, Konstantina; Tsakalides, Panagiotis] Univ Crete, Fdn Res & Technol Hellas, Iraklion 70013, Greece.
C3 University of Crete; University of Crete; Foundation for Research & Technology - Hellas (FORTH); University of Crete
RP Drakonakis, GI (corresponding author), Univ Crete, Dept Comp Sci, Iraklion 70013, Greece.
EM drakonakis@ics.forth.gr; greg@ics.forth.gr; kfot@ics.forth.gr; tsakalid@ics.forth.gr
FU Marie Sklodowska-Curie project CALCHAS project within the H2020 Framework Program of the European Commission [842560]
CR Ahmad M, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, V0, P0
   Ahmad S, 2010, ADV WATER RESOUR, V33, P69, DOI 10.1016/j.advwatres.2009.10.008
   Ahmadlou M, 2021, J FLOOD RISK MANAG, V14, P0, DOI 10.1111/jfr3.12683
   Akiva P, 2021, IEEE WINT CONF APPL, V0, PP111, DOI 10.1109/WACV48630.2021.00016
   Amitrano D, 2018, IEEE T GEOSCI REMOTE, V56, P3290, DOI 10.1109/TGRS.2018.2797536
   Berger M, 2012, REMOTE SENS ENVIRON, V120, P84, DOI 10.1016/j.rse.2011.07.023
   Bonafilia D, 2020, IEEE COMPUT SOC CONF, V0, PP835, DOI 10.1109/CVPRW50498.2020.00113
   Boser B. E., 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP144, DOI 10.1145/130385.130401
   Brakenridge R, 2006, NATO SCI S SS IV EAR, V72, P1
   Brivio PA, 2002, INT J REMOTE SENS, V23, P429, DOI 10.1080/01431160010014729
   Caballero I, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11122499
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cian F, 2018, NAT HAZARD EARTH SYS, V18, P3063, DOI 10.5194/nhess-18-3063-2018
   Cui BE, 2020, IEEE ACCESS, V8, P116744, DOI 10.1109/ACCESS.2020.3003914
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003
   Du Y, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8040354
   Fotiadou K., 2017, J ELECTRON IMAGING, V2017, P185, DOI 10.2352/ISSN.2470-1173.2017.17.COIMG-445
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   García Herrera Arístides Lázaro, 2017, REV.MED.ELECTRÓN., V0, P1
   Gascon F, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060584
   Goffi A, 2020, INT J APPL EARTH OBS, V84, P0, DOI 10.1016/j.jag.2019.101951
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Hansen MC, 2012, REMOTE SENS ENVIRON, V122, P66, DOI 10.1016/j.rse.2011.08.024
   Hirabayashi Y, 2013, NAT CLIM CHANGE, V3, P816, DOI 10.1038/nclimate1911
   Hollstein A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080666
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   Isikdogan F, 2017, IEEE J-STARS, V10, P4909, DOI 10.1109/JSTARS.2017.2735443
   Karakizi C, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081214
   Karantzalos K, 2015, IEEE J-STARS, V8, P4665, DOI 10.1109/JSTARS.2015.2461556
   Kemker R, 2017, IEEE T GEOSCI REMOTE, V55, P2693, DOI 10.1109/TGRS.2017.2651639
   King DB, 2015, ACS SYM SER, V1214, P1
   KUMAR M, 1988, MAR GEOD, V12, P117, DOI 10.1080/15210608809379580
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li Y, 2019, ISPRS J PHOTOGRAMM, V152, P178, DOI 10.1016/j.isprsjprs.2019.04.014
   Long S, 2014, ENVIRON RES LETT, V9, P0, DOI 10.1088/1748-9326/9/3/035002
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Maas Andrew L, 2013, PROC INT C MACH LEAR, V30, P3
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   Masser I, 2001, HABITAT INT, V25, P503, DOI 10.1016/S0197-3975(01)00021-2
   Mughees A, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, V0, P59
   MunuchRE,, 2019, RISKS FLOODS STORM S, V0, P0
   Pal M, 2005, INT J REMOTE SENS, V26, P1007, DOI 10.1080/01431160512331314083
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Pulvirenti L, 2011, NAT HAZARD EARTH SYS, V11, P529, DOI 10.5194/nhess-11-529-2011
   Rahnemoonfar M, 2021, IEEE ACCESS, V9, P89644, DOI 10.1109/ACCESS.2021.3090981
   RANGO A, 1974, WATER RESOUR RES, V10, P473, DOI 10.1029/WR010i003p00473
   Refice A, 2014, IEEE J-STARS, V7, P2711, DOI 10.1109/JSTARS.2014.2305165
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schlaffer S, 2015, INT J APPL EARTH OBS, V38, P15, DOI 10.1016/j.jag.2014.12.001
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Simonyan K, 2015, ARXIV, V0, P0
   Snyder J.P., 1987, MAP PROJECTIONS A WO, V1395, P0
   Stivaktakis R, 2019, IEEE GEOSCI REMOTE S, V16, P1031, DOI 10.1109/LGRS.2019.2893306
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   Tin Kam Ho, 1995, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, V0, PP278, DOI 10.1109/ICDAR.1995.598994
   Tsagkatakis G, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19183929
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, V0, PP1873, DOI 10.1109/IGARSS.2015.7326158
   Van Ackere S, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11112275
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Wang XB, 2018, INT J APPL EARTH OBS, V68, P73, DOI 10.1016/j.jag.2018.01.018
   Wang Y, 2002, INT J REMOTE SENS, V23, P3681, DOI 10.1080/01431160110114484
   Wieland M, 2020, INT J REMOTE SENS, V41, P4740, DOI 10.1080/01431161.2020.1723817
   Xie FY, 2017, IEEE J-STARS, V10, P3631, DOI 10.1109/JSTARS.2017.2686488
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/832093
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   [徐涵秋 Xu Hanqiu], 2005, 遥感学报 JOURNAL OF REMOTE SENSING, V9, P589
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 69
TC 3
Z9 3
U1 9
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2022
VL 15
IS 
BP 2341
EP 2356
DI 10.1109/JSTARS.2022.3155559
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA ZZ4TB
UT WOS:000773262200005
DA 2023-04-26
ER
