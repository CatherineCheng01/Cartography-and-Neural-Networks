
PT J
AU Chen, L
   Wang, YQ
   Ren, CY
   Zhang, B
   Wang, ZM
AF Chen, Lin
   Wang, Yeqiao
   Ren, Chunying
   Zhang, Bai
   Wang, Zongming
TI Optimal Combination of Predictors and Algorithms for Forest Above-Ground Biomass Mapping from Sentinel and SRTM Data
SO REMOTE SENSING
LA English
DT Article
DE optimal predictors; algorithm comparison; Sentinel-1 SAR; Sentinel-2 MSI; SRTM DEM; forest AGB mapping
ID growing stock volume; african tropical forest; boreal forest; ground biomass; mangrove forests; canopy height; carbon stocks; lidar; parameters; resolution
AB Accurate forest above-ground biomass (AGB) mapping is crucial for sustaining forest management and carbon cycle tracking. The Shuttle Radar Topographic Mission (SRTM) and Sentinel satellite series offer opportunities for forest AGB monitoring. In this study, predictors filtered from 121 variables from Sentinel-1 synthetic aperture radar (SAR), Sentinal-2 multispectral instrument (MSI) and SRTM digital elevation model (DEM) data were composed into four groups and evaluated for their effectiveness in prediction of AGB. Five evaluated algorithms include linear regression such as stepwise regression (SWR) and geographically weighted regression (GWR); machine learning (ML) such as artificial neural network (ANN), support vector machine for regression (SVR), and random forest (RF). The results showed that the RF model used predictors from both the Sentinel series and SRTM DEM performed the best, based on the independent validation set. The RF model achieved accuracy with the mean error, mean absolute error, root mean square error, and correlation coefficient in 1.39, 25.48, 61.11 Mgha(-1) and 0.9769, respectively. Texture characteristics, reflectance, vegetation indices, elevation, stream power index, topographic wetness index and surface roughness were recommended predictors for AGB prediction. Predictor variables were more important than algorithms for improving the accuracy of AGB estimates. The study demonstrated encouraging results in the optimal combination of predictors and algorithms for forest AGB mapping, using openly accessible and fine-resolution data based on RF algorithms.
C1 [Chen, Lin; Ren, Chunying; Zhang, Bai; Wang, Zongming] Chinese Acad Sci, Northeast Inst Geog & Agroecol, Key Lab Wetland Ecol & Environm, Changchun 130102, Jilin, Peoples R China.
   [Chen, Lin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Chen, Lin; Wang, Yeqiao] Univ Rhode Isl, Dept Nat Resources Sci, 1 Greenhouse Rd, Kingston, RI 02881 USA.
C3 Chinese Academy of Sciences; Northeast Institute of Geography & Agroecology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; University of Rhode Island
RP Ren, CY (corresponding author), Chinese Acad Sci, Northeast Inst Geog & Agroecol, Key Lab Wetland Ecol & Environm, Changchun 130102, Jilin, Peoples R China.
EM chenlin@iga.ac.cn; yqwang@uri.edu; renchy@iga.ac.cn; zhangbai@iga.ac.cn; zongmingwang@iga.ac.cn
FU National Key Research and Development Project of China [2016YFC0500300]; Jilin Scientific and Technological Development Program [20170301001NY]
CR [Anonymous], 1979, HYDROL SCI B, V0, P0
   [Anonymous], 1989, APPL GEOSTATISTICS, V0, P0
   Attarchi S, 2014, REMOTE SENS-BASEL, V6, P3693, DOI 10.3390/rs6053693
   Atzberger C, 2004, REMOTE SENS ENVIRON, V93, P53, DOI 10.1016/j.rse.2004.06.016
   Avitabile V, 2012, REMOTE SENS ENVIRON, V117, P366, DOI 10.1016/j.rse.2011.10.012
   Baccini A, 2012, NAT CLIM CHANGE, V2, P182, DOI 10.1038/nclimate1354
   Battude M, 2016, REMOTE SENS ENVIRON, V184, P668, DOI 10.1016/j.rse.2016.07.030
   Bendix J, 1999, J VEG SCI, V10, P243, DOI 10.2307/3237145
   Berninger A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060831
   Bloom AA, 2016, P NATL ACAD SCI USA, V113, P1285, DOI 10.1073/pnas.1515160113
   Bourgoin C, 2018, FORESTS, V9, P0, DOI 10.3390/f9060303
   Brown S, 1997, FOREST ECOL MANAG, V96, P37, DOI 10.1016/S0378-1127(97)00044-3
   Byrd KB, 2018, ISPRS J PHOTOGRAMM, V139, P255, DOI 10.1016/j.isprsjprs.2018.03.019
   Byrd KB, 2014, REMOTE SENS ENVIRON, V149, P166, DOI 10.1016/j.rse.2014.04.003
   Castillo JAA, 2017, ISPRS J PHOTOGRAMM, V134, P70, DOI 10.1016/j.isprsjprs.2017.10.016
   Chen L, 2018, FORESTS, V9, P0, DOI 10.3390/f9100582
   Chen Q, 2015, REMOTE SENS ENVIRON, V160, P134, DOI 10.1016/j.rse.2015.01.009
   Chrysafis I, 2017, REMOTE SENS LETT, V8, P508, DOI 10.1080/2150704X.2017.1295479
   Dhanda P, 2017, PROG PHYS GEOG, V41, P247, DOI 10.1177/0309133317693443
   Minh DHT, 2018, REMOTE SENS ENVIRON, V213, P206, DOI 10.1016/j.rse.2018.04.056
   Dong L., 2015, THESIS, V0, P0
   Ene LT, 2013, REMOTE SENS ENVIRON, V133, P210, DOI 10.1016/j.rse.2013.02.002
   Erb KH, 2018, NATURE, V553, P73, DOI 10.1038/nature25138
   Fassnacht FE, 2014, REMOTE SENS ENVIRON, V154, P102, DOI 10.1016/j.rse.2014.07.028
   Fotis AT, 2018, J ECOL, V106, P561, DOI 10.1111/1365-2745.12847
   Franklin SE, 1996, COMPUT GEOSCI-UK, V22, P665, DOI 10.1016/0098-3004(96)00009-X
   Gao YK, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040627
   Ghosh SM, 2018, APPL GEOGR, V96, P29, DOI 10.1016/j.apgeog.2018.05.011
   Gonzalez P, 2010, REMOTE SENS ENVIRON, V114, P1561, DOI 10.1016/j.rse.2010.02.011
   Hall M., 2009, ACM SIGKDD EXPLOR NE, V11, P10, DOI 10.1145/1656274.1656278
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hou Zhao-Jiang, 2014, CHINESE JOURNAL OF PLANT ECOLOGY, V38, P281, DOI 10.3724/SP.J.1258.2014.00025
   Huang HB, 2019, REMOTE SENS ENVIRON, V221, P225, DOI 10.1016/j.rse.2018.11.017
   IBM Corp, 2012, IBM SPSS STAT 21 COR, V0, P0
   Jacquemoud S, 2009, REMOTE SENS ENVIRON, V113, PS56, DOI 10.1016/j.rse.2008.01.026
   Joshi NP, 2015, REMOTE SENS-BASEL, V7, P4442, DOI 10.3390/rs70404442
   Kumar P, 2018, GEOCARTO INT, V33, P942, DOI 10.1080/10106049.2017.1316781
   Laurin GV, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.016008
   Laurin GV, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010018
   Laurin GV, 2016, REMOTE SENS ENVIRON, V176, P163, DOI 10.1016/j.rse.2016.01.017
   Laurin GV, 2014, ISPRS J PHOTOGRAMM, V89, P49, DOI 10.1016/j.isprsjprs.2014.01.001
   Liu KL, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040341
   Lopez-Serrano PM, 2016, CAN J REMOTE SENS, V42, P690, DOI 10.1080/07038992.2016.1217485
   Ma J, 2017, FOREST ECOL MANAG, V389, P199, DOI 10.1016/j.foreco.2016.12.020
   Majasalmi T, 2016, REMOTE SENS LETT, V7, P427, DOI 10.1080/2150704X.2016.1149251
   Malenovsky Z, 2012, REMOTE SENS ENVIRON, V120, P91, DOI 10.1016/j.rse.2011.09.026
   Montesano PM, 2015, REMOTE SENS ENVIRON, V158, P95, DOI 10.1016/j.rse.2014.10.029
   Motlagh MG, 2018, ENVIRON MONIT ASSESS, V190, P0, DOI 10.1007/s10661-018-6725-0
   Mura M, 2018, INT J APPL EARTH OBS, V66, P126, DOI 10.1016/j.jag.2017.11.013
   Murdock JN, 2007, J PHYCOL, V43, P449, DOI 10.1111/j.1529-8817.2007.00357.x
   Muukkonen P, 2007, REMOTE SENS ENVIRON, V107, P617, DOI 10.1016/j.rse.2006.10.011
   Nakaya T, 2014, GWR4 USER MANUAL WIN, V0, P1
   OBrien RM, 2007, QUAL QUANT, V41, P673, DOI 10.1007/s11135-006-9018-6
   Rivera JP, 2014, REMOTE SENS-BASEL, V6, P4927, DOI 10.3390/rs6064927
   Pan YD, 2011, SCIENCE, V333, P988, DOI 10.1126/science.1201609
   Pandit S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040601
   Peddle DR, 1999, REMOTE SENS ENVIRON, V67, P288, DOI 10.1016/S0034-4257(98)00090-X
   Propastin P, 2012, INT J APPL EARTH OBS, V18, P82, DOI 10.1016/j.jag.2011.12.013
   Puliti S, 2018, REMOTE SENS ENVIRON, V204, P485, DOI 10.1016/j.rse.2017.10.007
   Rodriguez E, 2006, PHOTOGRAMM ENG REM S, V72, P249, DOI 10.14358/PERS.72.3.249
   Saatchi SS, 2011, P NATL ACAD SCI USA, V108, P9899, DOI 10.1073/pnas.1019576108
   Sadeghi Y, 2018, INT J APPL EARTH OBS, V68, P202, DOI 10.1016/j.jag.2017.12.004
   Santi E, 2017, REMOTE SENS ENVIRON, V200, P63, DOI 10.1016/j.rse.2017.07.038
   Santi E, 2015, EUR J REMOTE SENS, V48, P673, DOI 10.5721/EuJRS20154837
   Sarker LR, 2011, REMOTE SENS ENVIRON, V115, P968, DOI 10.1016/j.rse.2010.11.010
   Searle EB, 2017, FOREST ECOL MANAG, V400, P468, DOI 10.1016/j.foreco.2017.06.042
   SEDJO RA, 1993, WATER AIR SOIL POLL, V70, P295, DOI 10.1007/BF01105003
   Sentinel 1_Team, 2013, SENT 1 US HDB, V0, P0
   Sentinel 2_Team, 2015, SENT 2 US HDB, V0, P0
   Shao ZF, 2017, IEEE J-STARS, V10, P5569, DOI 10.1109/JSTARS.2017.2748341
   Sharifi A, 2016, PHOTOGRAMM ENG REM S, V82, P41, DOI 10.14358/PERS.83.1.41
   Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050
   Shin J, 2016, CAN J REMOTE SENS, V42, P739, DOI 10.1080/07038992.2016.1252908
   Sibanda M, 2015, ISPRS J PHOTOGRAMM, V110, P55, DOI 10.1016/j.isprsjprs.2015.10.005
   Simard M, 2006, PHOTOGRAMM ENG REM S, V72, P299, DOI 10.14358/PERS.72.3.299
   SNAP, 2016, SENT APPL PLATF SOFT, V0, P0
   Su YJ, 2016, REMOTE SENS ENVIRON, V173, P187, DOI 10.1016/j.rse.2015.12.002
   Sun GQ, 2011, REMOTE SENS ENVIRON, V115, P2906, DOI 10.1016/j.rse.2011.03.021
   Tang GA., 2013, ARCGIS EXPT COURSE S, V0, P0
   Thurner M, 2014, GLOBAL ECOL BIOGEOGR, V23, P297, DOI 10.1111/geb.12125
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   VECI L., 2015, SENTINEL 1 TOOLBOX S, V0, P0
   Vincini M, 2014, IEEE T GEOSCI REMOTE, V52, P3220, DOI 10.1109/TGRS.2013.2271813
   Wang CK, 2006, FOREST ECOL MANAG, V222, P9, DOI 10.1016/j.foreco.2005.10.074
   Weiss M., 2016, SENTINEL2 TOOLBOX LE, V0, P0
   Wu CF, 2018, J FORESTRY RES, V29, P151, DOI 10.1007/s11676-017-0404-9
   Xu YZ, 2015, FOREST ECOL MANAG, V357, P95, DOI 10.1016/j.foreco.2015.08.010
   Yue JB, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010066
   Zhang G, 2014, REMOTE SENS ENVIRON, V151, P44, DOI 10.1016/j.rse.2014.01.025
   Zhao KG, 2018, REMOTE SENS ENVIRON, V204, P883, DOI 10.1016/j.rse.2017.09.007
   Zhao PP, 2016, INT J APPL EARTH OBS, V53, P1, DOI 10.1016/j.jag.2016.08.007
   Zhao PP, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060469
   Zheng DL, 2004, REMOTE SENS ENVIRON, V93, P402, DOI 10.1016/j.rse.2004.08.008
   Zhu BA, 2010, J PLANT RES, V123, P439, DOI 10.1007/s10265-009-0301-1
NR 94
TC 46
Z9 46
U1 13
U2 44
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 2
PY 2019
VL 11
IS 4
BP 
EP 
DI 10.3390/rs11040414
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA HO2SL
UT WOS:000460766100044
DA 2023-04-26
ER

PT J
AU Ren, YB
   Cheng, T
   Zhang, Y
AF Ren, Yibin
   Cheng, Tao
   Zhang, Yang
TI Deep spatio-temporal residual neural networks for road-network-based data modeling
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Spatio-temporal modeling; road network; deep learning; residual neural network
ID passenger demand; mobile; flow
AB Recently, researchers have introduced deep learning methods such as convolutional neural networks (CNN) to model spatio-temporal data and achieved better results than those with conventional methods. However, these CNN-based models employ a grid map to represent spatial data, which is unsuitable for road-network-based data. To address this problem, we propose a deep spatio-temporal residual neural network for road-network-based data modeling (DSTR-RNet). The proposed model constructs locally-connected neural network layers (LCNR) to model road network topology and integrates residual learning to model the spatio-temporal dependency. We test the DSTR-RNet by predicting the traffic flow of Didi cab service, in an 8-km(2) region with 2,616 road segments in Chengdu, China. The results demonstrate that the DSTR-RNet maintains the spatial precision and topology of the road network as well as improves the prediction accuracy. We discuss the prediction errors and compare the prediction results to those of grid-based CNN models. We also explore the sensitivity of the model to its parameters; this will aid the application of this model to network-based data modeling.
C1 [Ren, Yibin; Cheng, Tao; Zhang, Yang] UCL, Dept Civil Environm & Geomat Engn, SpaceTimeLab, London, England.
   [Ren, Yibin] Ocean Univ China, Coll Informat Sci & Engn, Qingdao Collaborat Innovat Ctr Marine Sci & Techn, Qingdao, Shandong, Peoples R China.
   [Ren, Yibin] Qingdao Natl Lab Marine Sci & Technol, Lab Reg Oceanog & Numer Modeling, Qingdao, Shandong, Peoples R China.
C3 University of London; University College London; Ocean University of China; Laoshan Laboratory
RP Cheng, T (corresponding author), UCL, Dept Civil Environm & Geomat Engn, SpaceTimeLab, London, England.
EM tao.cheng@ucl.ac.uk
FU Economic and Social Research Council [ES/L011840/1]; Science and Technology Project of Qingdao [16-6-2-61-NSH]; China Scholarship Council (CSC); EPSRC [EP/J004197/1, EP/G023212/1, EP/M023583/1] Funding Source: UKRI; ESRC [ES/L011840/1] Funding Source: UKRI; Economic and Social Research Council [ES/L011840/1] Funding Source: researchfish; Engineering and Physical Sciences Research Council [EP/M023583/1] Funding Source: researchfish
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Boeing G, 2017, COMPUT ENVIRON URBAN, V65, P126, DOI 10.1016/j.compenvurbsys.2017.05.004
   Box G.E.P., 1970, TIME SERIES ANAL FOR, V0, P0
   Caruana R, 2001, ADV NEUR IN, V13, P402
   Chen J, 2018, INT J GEOGR INF SCI, V32, P1770, DOI 10.1080/13658816.2018.1460753
   Cheng T., 2011, J GEOGRAPHICAL SYSTE, V14, P389
   Cheng Tao, 2008, TRANSACTIONS IN GIS, V12, P591, DOI 10.1111/j.1467-9671.2008.01117.x
   Cheng T, 2014, GEOGR ANAL, V46, P75, DOI 10.1111/gean.12026
   Cheng T, 2009, COMPUT ENVIRON URBAN, V33, P409, DOI 10.1016/j.compenvurbsys.2009.08.004
   Chollet F., 2015, DATA SCI CENT, V7, P0
   Haworth J, 2014, TRANSPORT RES C-EMER, V46, P151, DOI 10.1016/j.trc.2014.05.015
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HOANG M, 2016, AREA, V0, PP1, DOI 10.1145/2996913.2996934
   Huang W, 2015, INT J GEOGR INF SCI, V29, P1569, DOI 10.1080/13658816.2015.1033421
   Jiang B, 2009, INT J GEOGR INF SCI, V23, P1119, DOI 10.1080/13658810701690448
   Jiang B, 2009, INT J GEOGR INF SCI, V23, P823, DOI 10.1080/13658810802022822
   Ke JT, 2017, TRANSPORT RES C-EMER, V85, P591, DOI 10.1016/j.trc.2017.10.016
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li X, 2016, IEEE T INTELL TRANSP, V17, P2344, DOI 10.1109/TITS.2016.2518685
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Ma XL, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17040818
   Ma ZL, 2014, TRANSPORT RES C-EMER, V39, P148, DOI 10.1016/j.trc.2013.12.008
   Newson P., 2009, P 17 ACM SIGSPATIAL, V0, PP336, DOI 10.1145/1653771.1653818
   Rosser G., 2016, J QUANTITATIVE CRIMI, V33, P569
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shaw SL, 2016, INT J GEOGR INF SCI, V30, P1687, DOI 10.1080/13658816.2016.1164317
   Shi X., 2015, ADV NEURAL INFORM PR, V28, P802, DOI 10.5555/2969239.2969329
   Stockwell D, 1999, INT J GEOGR INF SCI, V13, P143, DOI 10.1080/136588199241391
   Wang J., 2010, P 5 IMA C MATH TRANS, V0, P0
   Wang JQ, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS
   Wang JQ, 2016, ENG APPL ARTIF INTEL, V52, P145, DOI 10.1016/j.engappai.2016.02.012
   Yu HY, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17071501
   Zhang J, 2017, ARXIV170102543CS, V0, P0
   Zhang J, 2017, PROCEEDINGS OF THE ASME 11TH INTERNATIONAL CONFERENCE ON ENERGY SUSTAINABILITY, V0, P0
   Zhang JB, 2018, ARTIF INTELL, V259, P147, DOI 10.1016/j.artint.2018.03.002
   Zhang JB, 2016, 24TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2016), V0, P0, DOI DOI 10.1145/2996913.2997016
   Zhang Y, 2020, IEEE T INTELL TRANSP, V21, P617, DOI 10.1109/TITS.2019.2896460
   Zhu X, 2014, T GIS, V18, P421, DOI 10.1111/tgis.12100
NR 42
TC 19
Z9 23
U1 4
U2 35
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD SEP 2
PY 2019
VL 33
IS 9
BP 1894
EP 1912
DI 10.1080/13658816.2019.1599895
EA APR 2019
PG 19
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA IW5VZ
UT WOS:000467143800001
DA 2023-04-26
ER

PT J
AU Li, GY
   Liu, Z
   Shi, R
   Wei, WJ
AF Li, Gongyang
   Liu, Zhi
   Shi, Ran
   Wei, Weijie
TI Constrained fixation point based segmentation via deep neural network
SO NEUROCOMPUTING
LA English
DT Article
DE Human visual system; Object segmentation; Interactive image segmentation; Fixation point; Deep neural network
ID saliency detection; visual-attention; video
AB It is an explicit mode to use the clicking points by the mouse in the interactive image segmentation, while an implicit interaction mode is to use the fixation points from the eye-tracking device. Both modes can provide a series of points. Inspired by the similarity between these two interaction modes, we propose a novel human visual system (HVS) based neural network for transferring the constrained fixation point based segmentation to the clicking point based interactive segmentation. Briefly speaking, the sequence of information transmission and processing in our model is RGB image, VGG-16 backbone, LGN-like module (LGNL) and ConvLSTM block, which correspond to the pathway of stimulus transmission and processing, i.e. stimulus, retina, lateral geniculate nucleus (LGN) and visual cortex in the HVS. First, the RGB image is fed to the VGG-16 backbone to obtain the multiple-layer feature maps. Then the LGNL is adopted to effectively incorporate edge-aware features and semantic features from different layers of the VGG-16 backbone in multiple resolutions, so as to produce rich contextual features. Finally, with the guidance of the fixation density map transformed from the fixation points, the output feature maps of LGNL are utilized to generate the segmentation map via a stack of ConvLSTM blocks in a coarse-to-fine manner. Comprehensive experiments demonstrate that the proposed HVS based neural network achieves a higher segmentation performance and outperforms seven state-of-the-art methods, and prove that the transfer from constrained fixation points to clicking points is reasonable and valid. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Li, Gongyang; Liu, Zhi; Wei, Weijie] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Li, Gongyang; Liu, Zhi; Wei, Weijie] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Shi, Ran] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Shanghai University; Shanghai University; Nanjing University of Science & Technology
RP Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
FU National Natural Science Foundation of China [61771301, 61801219]
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bell A.H., 2012, FUNDAM NEUROSCI, V0, P947
   Bottou L, 2010, COMPSTAT2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, V0, PP177, DOI 10.1007/978-3-7908-2604-3_16
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS
   Caelles S, 2017, PROC CVPR IEEE, V0, PP5320, DOI 10.1109/CVPR.2017.565
   Fan DP, 2019, PROC CVPR IEEE, V0, PP8546, DOI 10.1109/CVPR.2019.00875
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P4684, DOI 10.1109/TIP.2017.2721112
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Glorot X., 2010, P 13 INT C ART INT S, V0, P249
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Gulshan V, 2010, PROC CVPR IEEE, V0, PP3129, DOI 10.1109/CVPR.2010.5540073
   Gygli M, 2013, IEEE I CONF COMP VIS, V0, PP1633, DOI 10.1109/ICCV.2013.205
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   HOFFMAN JE, 1995, PERCEPT PSYCHOPHYS, V57, P787, DOI 10.3758/BF03206794
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Li SQ, 2017, NEUROCOMPUTING, V230, P173, DOI 10.1016/j.neucom.2016.12.026
   Li Y, 2014, PROC CVPR IEEE, V0, PP280, DOI 10.1109/CVPR.2014.43
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Mishra A, 2009, IEEE I CONF COMP VIS, V0, PP468, DOI 10.1109/ICCV.2009.5459254
   Quan R, 2018, IEEE T MULTIMEDIA, V20, P1101, DOI 10.1109/TMM.2017.2763780
   Rayner K, 2009, Q J EXP PSYCHOL, V62, P1457, DOI 10.1080/17470210902816461
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi R, 2017, IEEE SIGNAL PROC LET, V24, P1493, DOI 10.1109/LSP.2017.2739200
   Shi XS, 2015, 2015 IEEE ADVANCED INFORMATION TECHNOLOGY, V0, P802, DOI 10.1109/IAEAC.2015.7428667
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Tang H, 2018, MULTIMED TOOLS APPL, V77, P165, DOI 10.1007/s11042-016-4248-7
   Theis L, 2018, ARXIV180105787V2, V0, P0
   Tian XL, 2015, IEEE IMAGE PROC, V0, PP2125, DOI 10.1109/ICIP.2015.7351176
   Wang H, 2016, AER ADV ENG RES, V101, P285
   Wang WG, 2018, PROC CVPR IEEE, V0, PP1711, DOI 10.1109/CVPR.2018.00184
   Xie SN, 2015, IEEE I CONF COMP VIS, V0, PP1395, DOI 10.1109/ICCV.2015.164
   XU J, 2018, J VIS, V14, P1, DOI 10.1109/ICSICT.2018.8565687)
   Xu YY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3887
   Yu F., 2016, INT C LEARN REPR ICL, V0, P1
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
NR 39
TC 25
Z9 25
U1 5
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD NOV 27
PY 2019
VL 368
IS 
BP 180
EP 187
DI 10.1016/j.neucom.2019.08.051
PG 8
WC Computer Science, Artificial Intelligence
SC Computer Science
GA JD3VN
UT WOS:000489905200016
DA 2023-04-26
ER

PT J
AU Zajzon, B
   Mahmoudian, S
   Morrison, A
   Duarte, R
AF Zajzon, Barna
   Mahmoudian, Sepehr
   Morrison, Abigail
   Duarte, Renato
TI Passing the Message: Representation Transfer in Modular Balanced Networks
SO FRONTIERS IN COMPUTATIONAL NEUROSCIENCE
LA English
DT Article
DE modularity; information transfer; reservoir computing; spiking neural networks; topographic maps
ID signal propagation; feedback projections; synchronous spiking; mixed selectivity; topographic maps; visual-cortex; firing rates; connectivity; computation; dynamics
AB Neurobiological systems rely on hierarchical and modular architectures to carry out intricate computations using minimal resources. A prerequisite for such systems to operate adequately is the capability to reliably and efficiently transfer information across multiple modules. Here, we study the features enabling a robust transfer of stimulus representations in modular networks of spiking neurons, tuned to operate in a balanced regime. To capitalize on the complex, transient dynamics that such networks exhibit during active processing, we apply reservoir computing principles and probe the systems' computational efficacy with specific tasks. Focusing on the comparison of random feed-forward connectivity and biologically inspired topographic maps, we find that, in a sequential set-up, structured projections between the modules are strictly necessary for information to propagate accurately to deeper modules. Such mappings not only improve computational performance and efficiency, they also reduce response variability, increase robustness against interference effects, and boost memory capacity. We further investigate how information from two separate input streams is integrated and demonstrate that it is more advantageous to perform non-linear computations on the input locally, within a given module, and subsequently transfer the result downstream, rather than transferring intermediate information and performing the computation downstream. Depending on how information is integrated early on in the system, the networks achieve similar task-performance using different strategies, indicating that the dimensionality of the neural responses does not necessarily correlate with nonlinear integration, as predicted by previous studies. These findings highlight a key role of topographic maps in supporting fast, robust, and accurate neural communication over longer distances. Given the prevalence of such structural feature, particularly in the sensory systems, elucidating their functional purpose remains an important challenge toward which this work provides relevant, new insights. At the same time, these results shed new light on important requirements for designing functional hierarchical spiking networks.
C1 [Zajzon, Barna; Morrison, Abigail; Duarte, Renato] Inst Adv Simulat IAS 6, Inst Neurosci & Med INM 6, Julich Res Ctr, Julich, Germany.
   [Zajzon, Barna; Morrison, Abigail; Duarte, Renato] JARA Inst Brain Struct Funct Relationships JBI 1, Julich, Germany.
   [Zajzon, Barna] Rhein Westfal TH Aachen, Dept Psychiat Psychotherapy & Psychosomat, Aachen, Germany.
   [Mahmoudian, Sepehr] Georg August Univ Gottingen, Dept Data Driven Anal Biol Networks, Campus Inst Dynam Biol Networks, Gottingen, Germany.
   [Mahmoudian, Sepehr] Goethe Univ, Brain Imaging Ctr, MEG Unit, Frankfurt, Germany.
   [Morrison, Abigail] Ruhr Univ Bochum, Fac Psychol, Inst Cognit Neurosci, Bochum, Germany.
C3 Helmholtz Association; Research Center Julich; RWTH Aachen University; University of Gottingen; Goethe University Frankfurt; Ruhr University Bochum
RP Zajzon, B (corresponding author), Inst Adv Simulat IAS 6, Inst Neurosci & Med INM 6, Julich Res Ctr, Julich, Germany.; Zajzon, B (corresponding author), JARA Inst Brain Struct Funct Relationships JBI 1, Julich, Germany.; Zajzon, B (corresponding author), Rhein Westfal TH Aachen, Dept Psychiat Psychotherapy & Psychosomat, Aachen, Germany.
EM b.zajzon@fz-juelich.de
FU Erasmus Mundus Joint Doctoral Program EuroSPIN; German Ministry for Education and Research 1041 (Bundesministerium fur Bildung und Forschung) BMBF Grant [01GQ0420]; Initiative and Networking Fund of the Helmholtz Association; Helmholtz Portfolio theme Supercomputing and Modeling for the Human Brain; funding initiative Niedersachsisches Vorab
CR Abbott L. F., 2011, ARXIV09123832, V0, PP1, DOI 10.1093/ACPROF:OSO/9780195393798.003.0004
   Adams DL, 2003, J NEUROSCI, V23, P3771
   Barak O, 2013, J NEUROSCI, V33, P3844, DOI 10.1523/JNEUROSCI.2753-12.2013
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038
   Bednar JA, 2016, NEUROSCIENTIST, V22, P604, DOI 10.1177/1073858415597645
   Brunel N, 2000, J PHYSIOLOGY-PARIS, V94, P445, DOI 10.1016/S0928-4257(00)01084-6
   Clavagnier S, 2004, COGN AFFECT BEHAV NE, V4, P117, DOI 10.3758/CABN.4.2.117
   Diesmann M, 1999, NATURE, V402, P529, DOI 10.1038/990101
   Duarte FJ, 2018, IOP EXPAND PHYS, V0, PP1, DOI 10.1088/978-0-7503-1572-2
   Duarte R, 2017, CURR OPIN NEUROBIOL, V43, P156, DOI 10.1016/j.conb.2017.02.007
   Duarte R, 2015, J NEUROSCI, V35, P7315, DOI 10.1523/JNEUROSCI.0874-15.2015
   Duarte RCF, 2014, FRONT COMPUT NEUROSC, V8, P0, DOI 10.3389/fncom.2014.00124
   Ecker AS, 2010, SCIENCE, V327, P584, DOI 10.1126/science.1179867
   Emin Orhan A., 2017, ARXIV170109175, V0, P0
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300
   Gewaltig M.-O., 2007, SCHOLARPEDIA, V2, P1430, DOI 10.4249/SCH0LARPEDIA.1430
   Girman SV, 1999, J NEUROPHYSIOL, V82, P301, DOI 10.1152/jn.1999.82.1.301
   Haeusler S, 2007, CEREB CORTEX, V17, P149, DOI 10.1093/cercor/bhj132
   Hagler DJ, 2006, NEUROIMAGE, V29, P567, DOI 10.1016/j.neuroimage.2005.08.058
   Harris KD, 2015, NAT NEUROSCI, V18, P170, DOI 10.1038/nn.3917
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   HUBEL DH, 1988, EYE BRAIN VISION, V22, P0
   Joglekar MR, 2018, NEURON, V98, P222, DOI 10.1016/j.neuron.2018.02.031
   Kaas JH, 1997, BRAIN RES BULL, V44, P107, DOI 10.1016/S0361-9230(97)00094-4
   Keller GB, 2012, NEURON, V74, P809, DOI 10.1016/j.neuron.2012.03.040
   Klampfl S, 2013, J NEUROSCI, V33, P11515, DOI 10.1523/JNEUROSCI.5044-12.2013
   Knosche TR, 2011, FRONT SYST NEUROSCI, V5, P0, DOI 10.3389/fnsys.2011.00058
   Kremkow J, 2010, J NEUROSCI, V30, P15760, DOI 10.1523/JNEUROSCI.3874-10.2010
   Kumar A, 2008, J NEUROSCI, V28, P5268, DOI 10.1523/JNEUROSCI.2542-07.2008
   Kumar A, 2010, NAT REV NEUROSCI, V11, P615, DOI 10.1038/nrn2886
   Kunkel S., 2017, NEST 2 12 10, V0, P0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955
   Maass W, 2004, J PHYSIOL-PARIS, V98, P315, DOI 10.1016/j.jphysparis.2005.09.020
   Macaluso E, 2000, SCIENCE, V289, P1206, DOI 10.1126/science.289.5482.1206
   Mante V, 2013, NATURE, V503, P78, DOI 10.1038/nature12742
   Markopoulos F, 2012, NEURON, V76, P1175, DOI 10.1016/j.neuron.2012.10.028
   Markov NT, 2014, J COMP NEUROL, V522, P225, DOI 10.1002/cne.23458
   Markov NT, 2013, CURR OPIN NEUROBIOL, V23, P187, DOI 10.1016/j.conb.2012.12.008
   Mazzucato L, 2016, FRONT SYST NEUROSCI, V10, P0, DOI 10.3389/fnsys.2016.00011
   Miller KD, 2016, CURR OPIN NEUROBIOL, V37, P75, DOI 10.1016/j.conb.2016.01.008
   Mountcastle V., 1978, ORG PRINCIPLE CEREBR, V0, P0
   Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701
   Murray JD, 2014, NAT NEUROSCI, V17, P1661, DOI 10.1038/nn.3862
   Nikolic D, 2009, PLOS BIOL, V7, P0, DOI 10.1371/journal.pbio.1000260
   Park HJ, 2013, SCIENCE, V342, P579, DOI 10.1126/science.1238411
   Pauli R, 2018, FRONT NEUROINFORM, V12, P0, DOI 10.3389/fninf.2018.00046
   Revina Y., 2018, NEUROIMAGE, V180, P280, DOI 10.1016/j.neuroimage.2017.09.047
   Rigotti M., 2016, ARXIV160503952, V0, P0
   Rigotti M, 2013, NATURE, V497, P585, DOI 10.1038/nature12160
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Schomers MR, 2017, J NEUROSCI, V37, P3045, DOI 10.1523/JNEUROSCI.2693-16.2017
   Shadlen MN, 1998, J NEUROSCI, V18, P3870
   Shinomoto S, 2009, PLOS COMPUT BIOL, V5, P0, DOI 10.1371/journal.pcbi.1000433
   Shuler MG, 2006, SCIENCE, V311, P1606, DOI 10.1126/science.1123513
   Silver MA, 2005, J NEUROPHYSIOL, V94, P1358, DOI 10.1152/jn.01316.2004
   Sussillo D, 2014, CURR OPIN NEUROBIOL, V25, P156, DOI 10.1016/j.conb.2014.01.008
   Tetzlaff T, 2003, NEUROCOMPUTING, V52-4, P949, DOI 10.1016/S0925-2312(02)00854-8
   Thivierge JP, 2007, TRENDS NEUROSCI, V30, P251, DOI 10.1016/j.tins.2007.04.004
   VAADIA E, 1995, NATURE, V373, P515, DOI 10.1038/373515a0
   van den Broek D., 2017, C COGN COMP NEUR NEW, V0, P0
   van Rossum MCW, 2002, J NEUROSCI, V22, P1956, DOI 10.1523/JNEUROSCI.22-05-01956.2002
   Vogels TP, 2009, NAT NEUROSCI, V12, P483, DOI 10.1038/nn.2276
   Vogels TP, 2005, J NEUROSCI, V25, P10786, DOI 10.1523/JNEUROSCI.3508-05.2005
   Warden MR, 2010, J NEUROSCI, V30, P15801, DOI 10.1523/JNEUROSCI.1569-10.2010
   Yang GR, 2019, NAT NEUROSCI, V22, P297, DOI 10.1038/s41593-018-0310-2
   Zajzon B., 2018, 2018 INT JOINT C NEU, V0, P1
   Zajzon B., 2019, BIORXIV, V0, PP1, DOI 10.1101/716118
NR 70
TC 4
Z9 4
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 1662-5188
J9 FRONT COMPUT NEUROSC
JI Front. Comput. Neurosci.
PD DEC 5
PY 2019
VL 13
IS 
BP 
EP 
DI 10.3389/fncom.2019.00079
PG 18
WC Mathematical & Computational Biology; Neurosciences
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA JX1HU
UT WOS:000503494900001
PM 31920605
DA 2023-04-26
ER

PT J
AU Mzurikwao, D
   Samuel, OW
   Asogbon, MG
   Li, XX
   Li, G
   Yeo, WH
   Efstratiou, C
   Ang, CS
AF Mzurikwao, Deogratias
   Samuel, Oluwarotimi Williams
   Asogbon, Mojisola Grace
   Li, Xiangxin
   Li, Guanglin
   Yeo, Woon-Hong
   Efstratiou, Christos
   Ang, Chee Siang
TI A Channel Selection Approach Based on Convolutional Neural Network for Multi-Channel EEG Motor Imagery Decoding
SO 2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE)
LA English
DT Proceedings Paper
DE BCI; CNN; EEG; Feature maps; Motor imagery; Topographic maps
ID bci
AB For many disabled people, brain computer interface ( BCI) may be the only way to communicate with others and to control things around them. Using motor imagery paradigm, one can decode an individual's intention by using their brainwaves to help them interact with their environment without having to make any physical movement. For decades, machine learning models, trained on features extracted from acquired electroencephalogram (EEG) signals have been used to decode motor imagery activities. This method has several limitations and constraints especially during feature extraction. Large number of channels on the current EEG devices make them hard to use in real-life as they are bulky, uncomfortable to wear, and takes lot of time in preparation. In this paper, we introduce a technique to perform channel selection using convolutional neural network (CNN) and to decode multiple classes of motor imagery intentions from four participants who are amputees. A CNN model trained on EEG data of 64 channels achieved a mean classification accuracy of 99.7% with five classes. Channel selection based on weights extracted from the trained model has been performed with subsequent models trained on eight selected channels achieved a reasonable accuracy of 91.5%. Training the model in time domain and frequency domain was also compared, different window sizes were experimented to test the possibilities of realtime application. Our method of channel selection was then evaluated on a publicly available motor imagery EEG dataset.
C1 [Mzurikwao, Deogratias; Efstratiou, Christos; Ang, Chee Siang] Univ Kent, Sch Engn & Digital Arts, Canterbury, Kent, England.
   [Samuel, Oluwarotimi Williams; Asogbon, Mojisola Grace; Li, Xiangxin; Li, Guanglin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Guangdong, Peoples R China.
   [Yeo, Woon-Hong] Georgia Inst Adv Technol, Inst Elect & Nano Flexible Hybrid Elect, Atlanta, GA USA.
C3 University of Kent; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS
RP Mzurikwao, D (corresponding author), Univ Kent, Sch Engn & Digital Arts, Canterbury, Kent, England.
EM dm521@kent.ac.uk; samuel@siat.ac.cn; grace@siat.ac.cn; lixx@siat.ac.cn; gl.li@siat.ac.cn; whyeo@gatech.edu; c.efstratiou@kent.ac.uk; c.s.ang@kent.ac.uk
FU National Natural Science Foundation of China [U1613222, 81850410557, 61803361]; Shenzhen Governmental Basic Research Grant [JCYJ20160331185848286]; Outstanding Youth Innovation Research Fund of Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences [Y7G016]
CR Abdulkader SN, 2015, EGYPT INFORM J, V16, P213, DOI 10.1016/j.eij.2015.06.002
   Ameri SK, 2016, INT EL DEVICES MEET, V0, P0
   Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125
   Chen GY, 2014, EXPERT SYST APPL, V41, P2391, DOI 10.1016/j.eswa.2013.09.037
   Frey J., 2017, P 2017 CHI C HUM FAC, V0, P1253
   Goldberger AL, 2000, CIRCULATION, V101, PE215, DOI 10.1161/01.CIR.101.23.e215
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hosseini MP, 2017, IEEE T BIG DATA, V3, P392, DOI 10.1109/TBDATA.2017.2769670
   Kikkert S, 2017, CORTEX, V95, P29, DOI 10.1016/j.cortex.2017.07.015
   Kosmyna N, 2015, ACM T COMPUT-HUM INT, V22, P0, DOI 10.1145/2808228
   Kostov A, 2000, IEEE T REHABIL ENG, V8, P203, DOI 10.1109/86.847816
   Kwak NS, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0172578
   Li XX, 2017, J NEUROENG REHABIL, V14, P0, DOI 10.1186/s12984-016-0212-z
   Liu JW, 2015, CHIN CONTR CONF, V0, PP3518, DOI 10.1109/ChiCC.2015.7260182
   Mao ZJ, 2017, I IEEE EMBS C NEUR E, V0, PP609, DOI 10.1109/NER.2017.8008425
   Marchesi M., 2012, P 2012 VIRT REAL INT, V0, P28
   Morabito F. C., 2016, 2016 IEEE 2 INT FORU, V0, PP1, DOI 10.1109/RTSI.2016.7740576
   Park HJ, 2017, IEEE ENG MED BIO, V0, PP2863, DOI 10.1109/EMBC.2017.8037454
   Samuel O.W., 1900, P161, V0, P0
   Samuel OW, 2017, J MED SYST, V41, P0, DOI 10.1007/s10916-017-0843-z
   Samuel OW, 2017, IEEE ENG MED BIO, V0, PP2976, DOI 10.1109/EMBC.2017.8037482
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   SCHIFF SJ, 1994, ELECTROEN CLIN NEURO, V91, P442, DOI 10.1016/0013-4694(94)90165-1
   Sun H., 1900, P118, V0, P0
   Thodoroff P., 2016, PROC MACH LEARN HEAL, V0, P0
   Wang F, 2013, CHIN CONT DECIS CONF, V0, P5140
   Wang KJ, 2017, INT C REHAB ROBOT, V0, PP1073, DOI 10.1109/ICORR.2017.8009392
   Zhang X, 2018, SHOCK VIB, V2018, P1
   Zhou SM, 2008, INFORM SCIENCES, V178, P1629, DOI 10.1016/j.ins.2007.11.012
NR 29
TC 6
Z9 6
U1 0
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 
EI 
J9 
PD JUN 15
PY 2019
VL 0
IS 
BP 195
EP 202
DI 10.1109/AIKE.2019.00042
PG 8
WC Computer Science, Artificial Intelligence
SC Computer Science
GA BO1TQ
UT WOS:000502534100034
DA 2023-04-26
ER
