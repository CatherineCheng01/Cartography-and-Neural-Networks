FN Thomson Reuters Web of Science™
VR 1.0
PT J
AU Costa, H
   Foody, Giles M
   Boyd, Doreen S
TI Using mixed objects in the training of object-based image classifications
SO REMOTE SENSING OF ENVIRONMENT
DE obia; mixed pixels; under-segmentation; over-segmentation; scale parameter
AB Image classification for thematic mapping is a very common application in remote sensing, which is sometimes realized through object-based image analysis. In these analyses, it is common for some of the objects to be mixed in their class composition and thus violate the commonly made assumption of object purity that is implicit in a conventional object-based image analysis. Mixed objects can be a problem throughout a classification analysis, but are particularly challenging in the training stage as they can result in degraded training statistics and act to reduce mapping accuracy. In this paper the potential of using mixed objects in training object-based image classifications is evaluated. Remotely sensed data were submitted to a series of segmentation analyses from which a range of under- to over-segmented outputs were intentionally produced. Training objects were then selected from the segmentation outputs, resulting in training data sets that varied in terms of size (i.e. number of objects) and proportion of mixed objects. These training data sets were then used with an artificial neural network and a generalized linear model, which can accommodate objects of mixed composition, to produce a series of land cover maps. The use of training statistics estimated based on both pure and mixed objects often increased classification accuracy by around 25% when compared with accuracies obtained from the use of only pure objects in training. So rather than the mixed objects being a problem, they can be an asset in classification and facilitate land cover mapping from remote sensing. It is, therefore, desirable to recognize the nature of the objects and possibly accommodate mixed objects directly in training. The results obtained here may also have implications for the common practice of seeking an optimal segmentation output, and also act to challenge the widespread view that object-based classification is superior to pixel-based classification. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Costa, Hugo; Foody, Giles M.; Boyd, Doreen S.] Univ Nottingham, Sch Geog, Nottingham NG7 2RD, England.
RP Costa, H (corresponding author), Univ Nottingham, Sch Geog, Nottingham NG7 2RD, England.
FU "Fundacao para a Ciencia e a Tecnologia" (FCT) - "Programa Operacional Potential Humano" (POPH) [SFRH/BD/77031/2011]; European Social Fund; Fundação para a Ciência e a Tecnologia [SFRH/BD/77031/2011] Funding Source: FCT
CR Addink EA, 2012, INT J APPL EARTH OBS, V15, P1, DOI 10.1016/j.jag.2011.12.001
   Archer E, 2016, RFPERMUTE ESTIMATE P, V0, P0
   Belgiu M, 2014, ISPRS J PHOTOGRAMM, V96, P67, DOI 10.1016/j.isprsjprs.2014.07.002
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Boyden J, 2013, J SPAT SCI, V58, P53, DOI 10.1080/14498596.2012.759086
   Cai SS, 2013, REMOTE SENS LETT, V4, P998, DOI 10.1080/2150704X.2013.828180
   Canovas-Garcia F, 2015, GEOCARTO INT, V30, P937, DOI 10.1080/10106049.2015.1004131
   Castilla G, 2014, INT J REMOTE SENS, V35, P1029, DOI 10.1080/01431161.2013.875630
   Costa H, 2015, PHOTOGRAMM ENG REM S, V81, P451, DOI 10.14358/PERS.81.6.451
   Dronova I, 2012, REMOTE SENS ENVIRON, V127, P357, DOI 10.1016/j.rse.2012.09.018
   Estoque RC, 2015, GEOCARTO INT, V30, P1113, DOI 10.1080/10106049.2015.1027291
   Fritz S, 2013, EOS T AM GEOPHYS UN, V94, P31, DOI 10.1002/2013EO030006
   Gardi C, 2015, J ENVIRON PLANN MAN, V58, P898, DOI 10.1080/09640568.2014.899490
   Goodin DG, 2015, INT J REMOTE SENS, V36, P4702, DOI 10.1080/01431161.2015.1088674
   Guttler FN, 2016, REMOTE SENS LETT, V7, P358, DOI 10.1080/2150704X.2016.1142678
   Hansen MC, 2012, REMOTE SENSING LAND, V0, PP127, DOI 10.1201/B11964-12
   Korting TS, 2013, COMPUT GEOSCI-UK, V57, P133, DOI 10.1016/j.cageo.2013.02.007
   Li MC, 2016, INT J APPL EARTH OBS, V49, P87, DOI 10.1016/j.jag.2016.01.011
   Luo H, 2015, REMOTE SENS LETT, V6, P59, DOI 10.1080/2150704X.2014.1001079
   Luyssaert S, 2014, NAT CLIM CHANGE, V4, P389, DOI 10.1038/NCLIMATE2196
   Ma L, 2015, ISPRS J PHOTOGRAMM, V102, P14, DOI 10.1016/j.isprsjprs.2014.12.026
   Mahmood R, 2014, INT J CLIMATOL, V34, P929, DOI 10.1002/joc.3736
   Martin Y, 2013, GLOBAL ECOL BIOGEOGR, V22, P1204, DOI 10.1111/geb.12087
   Memarian H, 2013, J APPL REMOTE SENS, V7, P0, DOI 10.1117/1.JRS.7.073512
   Millard K, 2015, REMOTE SENS-BASEL, V7, P8489, DOI 10.3390/rs70708489
   Mishra NB, 2014, INT J REMOTE SENS, V35, P1175, DOI 10.1080/01431161.2013.876120
   Moller M, 2013, INT J REMOTE SENS, V34, P8685, DOI 10.1080/01431161.2013.845319
   Momeni R, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020088
   Mui A, 2015, ISPRS J PHOTOGRAMM, V109, P30, DOI 10.1016/j.isprsjprs.2015.08.005
   Pal M, 2012, IEEE J-STARS, V5, P1344, DOI 10.1109/JSTARS.2012.2215310
   Rasanen A, 2013, INT J REMOTE SENS, V34, P8603, DOI 10.1080/01431161.2013.845318
   Richards JA, 2014, IEEE T GEOSCI REMOTE, V52, P2715, DOI 10.1109/TGRS.2013.2264831
   Samat A, 2016, PATTERN RECOGN, V51, P43, DOI 10.1016/j.patcog.2015.08.019
   Shimabukuro YE, 2015, IEEE J-STARS, V8, P4502, DOI 10.1109/JSTARS.2015.2464097
   Tuanmu MN, 2014, GLOBAL ECOL BIOGEOGR, V23, P1031, DOI 10.1111/geb.12182
   Uddin K, 2015, J ENVIRON MANAGE, V148, P82, DOI 10.1016/j.jenvman.2014.07.047
   Verbeeck K, 2012, INT J APPL EARTH OBS, V18, P428, DOI 10.1016/j.jag.2012.03.015
   Whiteside TG, 2014, INT J APPL EARTH OBS, V28, P117, DOI 10.1016/j.jag.2013.11.009
   Yang J, 2015, ISPRS J PHOTOGRAMM, V101, P186, DOI 10.1016/j.isprsjprs.2014.12.015
   Zhu ZC, 2013, REMOTE SENS-BASEL, V5, P927, DOI 10.3390/rs5020927
NR 40
TC 39
Z9 0
U1 1
U2 38.0
J9 REMOTE SENSING OF ENVIRONMENT
PD MAR
PY 2017
VL 190
BP 188
EP 197
DI 10.1016/j.rse.2016.12.017
PG 10
SC ENVIRONMENTAL SCIENCES & ECOLOGY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000394399300015
PM 
ER

PT J
AU Santana, TMHC
   Nogueira, Keiller
   Machado, Alexei M C
   dos santos, Jefersson A
TI DEEP CONTEXTUAL DESCRIPTION OF SUPERPIXELS FOR AERIAL URBAN SCENES CLASSIFICATION
SO 2017 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (IGARSS)
DE convolutional neural networks; contextual description; land-cover thematic maps
AB This paper proposes a new approach for contextual feature extraction from superpixels in aerial urban scenes. Our method extracts features with many levels of context from superpixels by exploiting different layers of a pre-trained convolutional neural network. Experimental results show the effectiveness of the proposed approach, which outperforms traditional methods based on handcrafted feature extraction algorithms.
C1 [Santana, Tiago M. H. C.; Nogueira, Keiller; dos Santos, Jefersson A.] Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.   
[Machado, Alexei M. C.] Pontificia Univ Catolica Minas Gerais, Elect Engn Dept, Belo Horizonte, MG, Brazil.
RP Santana, TMHC (corresponding author), Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.
FU CNPq [449638/2014-6]; CAPES; Fapemig [APQ-00768-14]; Microsoft Azure
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Hu TY, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020151
   Mostajahi M, 2015, PROC CVPR IEEE, V0, PP3376, DOI 10.1109/CVPR.2015.7298959
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Parikh D, 2012, IEEE T PATTERN ANAL, V34, P1978, DOI 10.1109/TPAMI.2011.276
   Santana TMHC, 2016, CIARP, V0, P0
   Vargas JE, 2015, IGARSS, V0, P0
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   dos Santos JA, 2012, INT C PATT RECOG, V0, P3090
NR 10
TC 3
Z9 0
U1 0
U2 1.0
J9 2017 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (IGARSS)
PD JUN
PY 2017
VL 0
BP 3027
EP 3030
PG 4
SC GEOLOGY; REMOTE SENSING
UT WOS:000426954603031
PM 
ER

PT J
AU Chen, Y
   Ge, Yong
   Jia, Yuanxin
TI Integrating Object Boundary in Super-Resolution Land-Cover Mapping
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
DE land cover; object boundary; remotely sensed imagery; super-resolution mapping (srm)
AB This paper proposes a novel class allocation strategy in units of object (UOO) for soft-then-hard super-resolution mapping (STHSRM). STHSRM involves two processes: 1) subpixel sharpening and 2) class allocation. The UOO is implemented in the second process by integrating the object boundaries as an additional structural constraint. First, UOO obtains the object boundaries from remote-sensing images by image segmentation. The number of subpixels within an object is then calculated for each class to meet the coherence constraint of fractional images imposed by soft classification. Finally, a linear optimization model is built for each object to obtain the optimal hard class labels of subpixels. A synthetic image and two real remote-sensing images are used to evaluate the effectiveness of UOO. The results are compared visually and quantitatively with two existing class allocation methods: 1) the highest attribute values first (HAVF) and 2) units of class (UOC). The experimental results show that UOO performs better than these twomethods. UOO can better reduce the salt and pepper effect in resultant maps than both HAVF and UOC when dealing with real remote-sensing images. Moreover, UOO can better maintain the structure of land-cover patches, with smoother boundaries as compared with the two methods.
C1 [Chen, Yuehong; Ge, Yong; Jia, Yuanxin] Univ Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.   
[Ge, Yong] Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Jiangsu, Peoples R China.
RP Chen, YH (corresponding author), Univ Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.
FU National Natural Science Foundation of China [41471296]; Key Technologies Research and Development Program of China [2012BAH33B01]
CR Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Chen YH, 2014, REMOTE SENS LETT, V5, P902, DOI 10.1080/2150704X.2014.973079
   Chen YH, 2015, IEEE GEOSCI REMOTE S, V12, P2516, DOI 10.1109/LGRS.2015.2489683
   Chen YH, 2015, IEEE J-STARS, V8, P2040, DOI 10.1109/JSTARS.2015.2417191
   Ge Y, 2013, INT J APPL EARTH OBS, V22, P115, DOI 10.1016/j.jag.2012.04.013
   Ge Y, 2014, INT J REMOTE SENS, V35, P1756, DOI 10.1080/01431161.2014.882034
   Hu JL, 2015, IEEE J-STARS, V8, P2031, DOI 10.1109/JSTARS.2015.2399509
   Li XD, 2014, IEEE GEOSCI REMOTE S, V11, P1265, DOI 10.1109/LGRS.2013.2291778
   Li XD, 2014, IEEE T GEOSCI REMOTE, V52, P2810, DOI 10.1109/TGRS.2013.2266345
   Ling F, 2012, INT J APPL EARTH OBS, V18, P283, DOI 10.1016/j.jag.2012.02.008
   Ling F, 2013, REMOTE SENS LETT, V4, P629, DOI 10.1080/2150704X.2013.781284
   Ling F, 2014, IEEE T GEOSCI REMOTE, V52, P4424, DOI 10.1109/TGRS.2013.2281992
   Ling F, 2014, IEEE T GEOSCI REMOTE, V52, P5677, DOI 10.1109/TGRS.2013.2291902
   Su YF, 2012, IEEE J-STARS, V5, P1403, DOI 10.1109/JSTARS.2012.2191537
   Wang QM, 2014, IEEE J-STARS, V7, P327, DOI 10.1109/JSTARS.2013.2262927
   Wang QM, 2014, IEEE T GEOSCI REMOTE, V52, P2940, DOI 10.1109/TGRS.2013.2267802
   Wang QM, 2014, ISPRS J PHOTOGRAMM, V92, P1, DOI 10.1016/j.isprsjprs.2014.02.012
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P309, DOI 10.1109/TGRS.2014.2321834
   Xu X, 2013, IEEE J-STARS, V6, P580, DOI 10.1109/JSTARS.2012.2227246
   Zhang YH, 2015, INT J REMOTE SENS, V36, P2831, DOI 10.1080/01431161.2015.1047048
   Zhong YF, 2012, IEEE T SYST MAN CY B, V42, P1306, DOI 10.1109/TSMCB.2012.2189561
   Zhong YF, 2014, ISPRS J PHOTOGRAMM, V96, P134, DOI 10.1016/j.isprsjprs.2014.06.019
   Zhong YF, 2015, IEEE T GEOSCI REMOTE, V53, P1411, DOI 10.1109/TGRS.2014.2340734
NR 23
TC 16
Z9 0
U1 1
U2 46.0
J9 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
PD JAN
PY 2017
VL 10
BP 219
EP 230
DI 10.1109/JSTARS.2016.2533571
PG 12
SC ENGINEERING; PHYSICAL GEOGRAPHY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000391719900020
PM 
ER

PT J
AU Li, M
   de beurs, Kirsten M
   Stein, Alfred
   Bijker, Wietske
TI Incorporating Open Source Data for Bayesian Classification of Urban Land Use From VHR Stereo Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
DE bayesian methods; convolutional neural networks (cnn); fuzzy decision trees; open source data; urban land use; very high resolution (vhr) stereo images
AB This study investigates the incorporation of open source data into a Bayesian classification of urban land use from very high resolution (VHR) stereo satellite images. The adopted classification framework starts from urban land cover classification, proceeds to building-type characterization, and results in urban land use. For urban land cover classification, a preliminary classification distinguishes trees, grass, and shadow objects using a random forest at a fine segmentation level. Fuzzy decision trees derived from hierarchical Bayesian models separate buildings from other man-made objects at a coarse segmentation level, where an open street map provides prior building information. A Bayesian network classifier combining commonly used land use indicators and spatial arrangement is used for the urban land use classification. The experiments were conducted on GeoEye stereo images over Oklahoma City, USA. Experimental results showed that the urban land use classification using VHR stereo images performed better than that using a monoscopic VHR image, and the integration of open source data improved the final urban land use classification. Our results also show a way of transferring the adopted urban land use classification framework, developed for a specific urban area in China, to other urban areas. The study concludes that incorporating open source data by Bayesian analysis improves urban land use classification. Moreover, a pretrained convolutional neural network fine tuned on the UC Merced land use dataset offers a useful tool to extract additional information for urban land use classification.
C1 [Li, Mengmeng; Stein, Alfred; Bijker, Wietske] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, NL-7514 AE Enschede, Netherlands.   
[de Beurs, Kirsten M.] Univ Oklahoma, Dept Geog & Environm Sustainabil, Norman, OK 73019 USA.
RP Li, MM (corresponding author), Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, NL-7514 AE Enschede, Netherlands.
FU China Scholarship Council (CSC); ITC Research Fund; NASA IDS Project [NNX12AM89G]
CR Aguilar MA, 2014, IEEE T GEOSCI REMOTE, V52, P1259, DOI 10.1109/TGRS.2013.2249521
   Alahmadi M, 2015, INT J REMOTE SENS, V36, P4315, DOI 10.1080/01431161.2015.1079666
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Chen SZ, 2015, IEEE T GEOSCI REMOTE, V53, P1947, DOI 10.1109/TGRS.2014.2351395
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Comber AJ, 2012, INT J APPL EARTH OBS, V18, P274, DOI 10.1016/j.jag.2012.01.020
   Geiss C, 2017, NAT HAZARDS, V86, P81, DOI 10.1007/s11069-016-2663-8
   Gelman A, 2013, BAYESIAN DATA ANAL, V0th, P0
   Guo Z, 2016, IEEE J-STARS, V9, P1854, DOI 10.1109/JSTARS.2016.2539362
   Hu SG, 2013, INT J REMOTE SENS, V34, P790, DOI 10.1080/01431161.2012.714510
   Hu TY, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020151
   Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Letourneau A, 2012, ENVIRON MODELL SOFTW, V33, P61, DOI 10.1016/j.envsoft.2012.01.007
   Li MM, 2015, ISPRS J PHOTOGRAMM, V102, P48, DOI 10.1016/j.isprsjprs.2014.12.023
   Li MM, 2016, INT J APPL EARTH OBS, V44, P217, DOI 10.1016/j.jag.2015.09.005
   Li MM, 2016, ISPRS J PHOTOGRAMM, V122, P192, DOI 10.1016/j.isprsjprs.2016.10.007
   Li XC, 2016, REMOTE SENS ENVIRON, V186, P286, DOI 10.1016/j.rse.2016.08.029
   Longbotham N, 2012, IEEE T GEOSCI REMOTE, V50, P1155, DOI 10.1109/TGRS.2011.2165548
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Muller D, 2014, J LAND USE SCI, V9, P133, DOI 10.1080/1747423X.2014.883731
   Pesaresi M, 2013, IEEE J-STARS, V6, P2102, DOI 10.1109/JSTARS.2013.2271445
   Qin RJ, 2015, IEEE J-STARS, V8, P2125, DOI 10.1109/JSTARS.2015.2424275
   Shean DE, 2016, ISPRS J PHOTOGRAMM, V116, P101, DOI 10.1016/j.isprsjprs.2016.03.012
   UNHABITAT, 2016, URB DEV EM FUT, V0, P0, DOI DOI 10.1016/S0264-2751(03)00010-6
   Vedaldi A, 2015, ARXIV14124564CSCV, V0, P1
   Verdoliva L, 2015, ARXIV PREPRINT ARXIV, V28, P627
   Voltersen M, 2014, REMOTE SENS ENVIRON, V154, P192, DOI 10.1016/j.rse.2014.08.024
   Walde I, 2014, INT J GEOGR INF SCI, V28, P584, DOI 10.1080/13658816.2013.865189
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang Q, 2015, REMOTE SENS-BASEL, V7, P16422, DOI 10.3390/rs71215840
   Zhang XY, 2015, IEEE J-STARS, V8, P2005, DOI 10.1109/JSTARS.2015.2414178
NR 35
TC 13
Z9 0
U1 3
U2 33.0
J9 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
PD NOV
PY 2017
VL 10
BP 4930
EP 4943
DI 10.1109/JSTARS.2017.2737702
PG 14
SC ENGINEERING; PHYSICAL GEOGRAPHY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000415719000022
PM 
ER

