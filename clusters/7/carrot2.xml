<?xml version="1.0" encoding="UTF-8"?>
<searchresult>
<query>Global</query>
<document id="1">
<title>Mapping stone walls in Northeastern USA using deep learning and LiDAR data</title>
<url>http://dx.doi.org/10.1080/15481603.2023.2196117</url>
<snippet>Stone walls are widespread and iconic landforms found throughout forested terrain in the Northeastern USA that were built during the 17th to early 20th centuries to delineate property boundaries and the edges of agricultural fields and pastures. As linear, or broadly curved, features that are typically &gt; 0.5 m high, 1-2 m wide, and &gt; 4-8 m long, stone walls are highly visible in LiDAR data, and mapping them is of broad interest to the cultural heritage sector as well as to researchers specifically focused on historic landscape reconstruction. However, existing mapping attempts have commonly relied on field surveys and manual digitization, which is time-consuming, especially when trying to complete mapping at broader scales. In response to this limitation, this study: (1) presents a novel framework to automate stone wall mapping using Deep Convolutional Neural Networks (DCNN) models (U-Net and ResUnet) and high-resolution airborne LiDAR, (2) evaluates model performance in two test sites against field verified stone walls, (3) investigates the factors that can influence model performance in terms of the quality of LiDAR data (e.g. ground point spacing), and (4) suggests post-processing for town-level mapping of stone walls (similar to 120 km(2)). Both models performed well with respect to the Matthews Correlation Coefficient (MCC) score. U-Net scenario 3 achieved an MCC score of 0.87 at test site 1, while ResUnet scenario 3 (S3) had an MCC score of 0.80 at test site 2. In town-level test site 3, ResUnet S3 achieved the best F-1 score of 82&#37; after post-processing. This study demonstrates the potential of automated mapping of anthropogenic features using our models.
WOS:000963378900001
</snippet>
</document>

<document id="2">
<title>Convolutional Embedded Networks for Population Scale Clustering and Bio-Ancestry Inferencing</title>
<url>http://dx.doi.org/10.1109/TCBB.2020.2994649</url>
<snippet>The study of genetic variants (GVs) can help find correlating population groups and to identify cohorts that are predisposed to common diseases and explain differences in disease susceptibility and how patients react to drugs. Machine learning techniques are increasingly being applied to identify interacting GVs to understand their complex phenotypic traits. Since the performance of a learning algorithm not only depends on the size and nature of the data but also on the quality of underlying representation, deep neural networks (DNNs) can learn non-linear mappings that allow transforming GVs data into more clustering and classification friendly representations than manual feature selection. In this paper, we propose convolutional embedded networks (CEN) in which we combine two DNN architectures called convolutional embedded clustering (CEC) and convolutional autoencoder (CAE) classifier for clustering individuals and predicting geographic ethnicity based on GVs, respectively. We employed CAE-based representation learning to 95 million GVs from the 1000 genomes (covering 2,504 individuals from 26 ethnic origins) and Simons genome diversity (covering 279 individuals from 130 ethnic origins) projects. Quantitative and qualitative analyses with a focus on accuracy and scalability show that our approach outperforms state-of-the-art approaches such as VariantSpark and ADMIXTURE. In particular, CEC can cluster targeted population groups in 22 hours with an adjusted rand index (ARI) of 0.915, the normalized mutual information (NMI) of 0.92, and the clustering accuracy (ACC) of 89 percent. Contrarily, the CAE classifier can predict the geographic ethnicity of unknown samples with an F1 and Mathews correlation coefficient (MCC) score of 0.9004 and 0.8245, respectively. Further, to provide interpretations of the predictions, we identify significant biomarkers using gradient boosted trees (GBT) and SHapley Additive exPlanations (SHAP). Overall, our approach is transparent and faster than the baseline methods, and scalable for 5 to 100 percent of the full human genome.
WOS:000752015800038
</snippet>
</document>

<document id="3">
<title>A stacking ensemble algorithm for improving the biases of forest aboveground biomass estimations from multiple remotely sensed datasets</title>
<url>http://dx.doi.org/10.1080/15481603.2021.2023842</url>
<snippet>Accurately quantifying the aboveground biomass (AGB) of forests is crucial for understanding global change-related issues such as the carbon cycle and climate change. Many studies have estimated AGB from multiple remotely sensed datasets using various algorithms, but substantial uncertainties remain in AGB predictions. In this study, we aim to explore whether diverse algorithms stacked together are able to improve the accuracy of AGB estimates. To build the stacking framework, five base learners were first selected from a series of algorithms, including multivariate adaptive regression splines (MARS), support vector regression (SVR), multilayer perceptron (MLP) model, random forests (RF), extremely randomized trees (ERT), stochastic gradient boosting (SGB), gradient-boosted regression tree (GBRT) algorithm, and categorical boosting (CatBoost), based on diversity and accuracy metrics. Ridge and RF were utilized as the meta learner to combine the outputs of base learners. In addition, six important features were selected according to the feature importance values provided by the CatBoost, ERT, GBRT, SGB, MARS and RF algorithms as inputs of the meta learner in the stacking process. We then used stacking models with 3-5 selected base learners and ridge or RF to estimate AGB. The AGB data compiled from plot-level forest AGB, high-resolution AGB data derived from field and lidar data and the corresponding predictor variables extracted from the satellite-derived leaf area index, net primary production, forest canopy height, tree cover data, and Global Multiresolution Terrain Elevation Data 2010, as well as climate data, were randomly split into groups of 80&#37; for training the model and 20&#37; for model evaluation. The evaluation results showed that stacking generally outweighed the optimal base learner and provided improved AGB estimations, mainly by decreasing the bias. All stacking models had relative improvement (RI) values in bias of at least 22.12&#37;, even reaching more than 90&#37; under some scenarios, except for deciduous broadleaf forests, where an optimal algorithm could provide low biased estimations. In contrast, the improvements of stacking in R-2 and RMSE were not significant. The stacking of MARS, MLP, and SVR provided improved results compared with the optimal base learner, and the average RI in R-2 was 3.54&#37; when we used all data without separating forest types. Finally, the optimal stacking model was used to generate global forest AGB maps.
WOS:000737615200001
</snippet>
</document>

<document id="4">
<title>Mapping spatial distribution and geographic shifts of East African highland banana (Musa spp.) in Uganda</title>
<url>http://dx.doi.org/10.1371/journal.pone.0263439</url>
<snippet>East African highland banana (Musa acuminata genome group AAA-EA; hereafter referred to as banana) is critical for Ugandas food supply, hence our aim to map current distribution and to understand changes in banana production areas over the past five decades. We collected banana presence/absence data through an online survey based on high-resolution satellite images and coupled this data with independent covariates as inputs for ensemble machine learning prediction of current banana distribution. We assessed geographic shifts of production areas using spatially explicit differences between the 1958 and 2016 banana distribution maps. The biophysical factors associated with banana spatial distribution and geographic shift were determined using a logistic regression model and classification and regression tree, respectively. Ensemble models were superior (AUC = 0.895; 0.907) compared to their constituent algorithms trained with 12 and 17 covariates, respectively: random forests (AUC = 0.883; 0.901), gradient boosting machines (AUC = 0.878; 0.903), and neural networks (AUC = 0.870; 0.890). The logistic regression model (AUC = 0.879) performance was similar to that for the ensemble model and its constituent algorithms. In 2016, banana cultivation was concentrated in the western (44&#37;) and central (36&#37;) regions, while only a small proportion was in the eastern (18&#37;) and northern (2&#37;) regions. About 60&#37; of increased cultivation since 1958 was in the western region; 50&#37; of decreased cultivation in the eastern region; and 44&#37; of continued cultivation in the central region. Soil organic carbon, soil pH, annual precipitation, slope gradient, bulk density and blue reflectance were associated with increased banana cultivation while precipitation seasonality and mean annual temperature were associated with decreased banana cultivation over the past 50 years. The maps of spatial distribution and geographic shift of banana can support targeting of context-specific intensification options and policy advocacy to avert agriculture driven environmental degradation.
WOS:000777505200020
</snippet>
</document>

<document id="5">
<title>Assessment of the uncertainty and interpretability of deep learning models for mapping soil salinity using DeepQuantreg and game theory</title>
<url>http://dx.doi.org/10.1038/s41598-022-19357-4</url>
<snippet>This research introduces a new combined modelling approach for mapping soil salinity in the Minab plain in southern Iran. This study assessed the uncertainty (with 95&#37; confidence limits) and interpretability of two deep learning (DL) models (deep boltzmann machine-DBM) and a one dimensional convolutional neural networks (1DCNN)-long short-term memory (LSTM) hybrid model (1DCNN-LSTM) for mapping soil salinity by applying DeepQuantreg and game theory (Shapely Additive exPlanations (SHAP) and permutation feature importance measure (PFIM)), respectively. Based on stepwise forward regression (SFR)-a technique for controlling factor selection, 18 of 47 potential controls were selected as effective factors. Inventory maps of soil salinity were generated based on 476 surface soil samples collected for measuring electrical conductivity (ECe). Based on Taylor diagrams, both DL models performed well (RMSE &lt; 20&#37;), but the 1DCNN-LSTM hybrid model performed slightly better than the DBM model. The uncertainty range associated with the ECe values predicted by both models estimated using DeepQuantilreg were similar (0-25 dS/m for the 1DCNN-LSTM hybrid model and 2-27 dS/m for DBM model). Based on the SFR and PFIM (permutation feature importance measure)-a measure in game theory, four controls (evaporation, sand content, precipitation and vertical distance to channel) were selected as the most important factors for soil salinity in the study area. The results of SHAP (Shapely Additive exPlanations)-the second measure used in game theory-suggested that five factors (evaporation, vertical distance to channel, sand content, cation exchange capacity (CEC) and digital elevation model (DEM)) have the strongest impact on model outputs. Overall, the methodology used in this study is recommend for applications in other regions for mapping environmental problems.
WOS:000852630800050
</snippet>
</document>

<document id="6">
<title>Performance of deep learning in mapping water quality of Lake Simcoe with long-term Landsat archive</title>
<url>http://dx.doi.org/10.1016/j.isprsjprs.2021.11.023</url>
<snippet>Remote sensing provides full-coverage and dynamic water quality monitoring with high efficiency and low consumption. Deep learning (DL) has been progressively used in water quality retrieval because it efficiently captures the potential relationship between target variables and imagery. In this study, the multimodal deep learning (MDL) models were developed and rigorously validated using atmospherically corrected Landsat remote sensing reflectance data and synchronous water quality measurements for estimating long-term Chlorophyll-a (Chl-a), total phosphorus (TP), and total nitrogen (TN) in Lake Simcoe, Canada. Since TP and TN are non optically active, their retrievals were based on the fact that they are closely related to the optically active constituents (OACs) such as Chl-a. We trained the MDL models with one in-situ measured data set (for Chl-a, N = 315, for TP and TN, N = 303), validated the models with two independent data sets (N = 147), and compared the model performances with several DL, machine learning, and empirical algorithms. The results indicated that the MDL models adequately estimated Chl-a (mean absolute error (MAE) = 32.57&#37;, Bias = 10.61&#37;), TP (MAE = 42.58&#37;, Bias =-2.82&#37;), and TN (MAE = 35.05&#37;, Bias = 13.66&#37;), and outperformed several other candidate algorithms, namely the progressively decreasing deep neural network (DNN), a DNN with trainable parameters similar to MDL but without splitting input features, the eXtreme Gradient Boosting, the support vector regression, the NASA Ocean Color two-band and three-band ratio algorithms, and another empirical algorithm of Landsat data in clear lakes. Using the MDL models, we reconstructed the historical spatiotemporal patterns of Chl-a, TP, and TN in Lake Simcoe since 1984, and investigated the effects of two water quality improvement programs. In addition, the physical mechanism and interpretability of the MDL models were explored by quantifying the contribution of each feature to the model outputs. The framework proposed in this study provides a practical method for long-term Chl-a, TP, and TN estimation at the regional scale.
WOS:000782441900001
</snippet>
</document>

<document id="7">
<title>Characterising social-ecological drivers of landuse/cover change in a complex transboundary basin using singular or ensemble machine learning</title>
<url>http://dx.doi.org/10.1016/j.rsase.2022.100773</url>
<snippet>Studies have focused on understanding land use/cover (LULC) change through regression techniques. However, machine learning (ML) techniques and their ensembles may provide more accurate results. Accurate determination of drivers of LULC can guide reliable land use planning and effective natural resource management. In this study, we tested the utility of ML techniques and ensemble modelling to explain the social-ecological drivers of LULC in the Okavango basin. The Deep Neural Network (DNN) coupled with climate-based regionalization of the study area were used for LULC classification of the years 2002, 2013 and 2020. Centroids of 22 LULC transitions of the same period were used to separately calibrate five (5) machine algorithms (namely Random Forests (RF), Gradient Boost Models (GBM) and Maximum Entropy (MaxEnt), Classification Tree Analysis (CTA) and their ensemble. Model performance was evaluated using the Receiver Operating Characteristic (ROC) and the True skill statistic (TSS). Variable importance was used to assess the contribution of social-ecological variables to each LULC transition. Variables that were determined to be driving LULC were then used to predict future LULC using the Artificial Neural Network and Cellular Automata (ANN-CA). Analysis results show that average LULC classification accuracy for the study period (2002, 2013 and 2020) was (Bsh Koppen zone; OA = 95.03, Kappa = 0.94), (Cwa Koppen zone; OA = 95.29, Kappa = 0.94), Cwb Koppen zone; OA = 96.04, Kappa = 0.95). The ML ensemble performed better (ROC &gt; 95, TSS &gt; 87) than singular ML models based on two separate model evaluation metrics. The Random Forest classifier outperformed other singular ML (ROC = 90.41, TSS = 84.2). Based on the top-performing ensemble model, distance from rivers, population density, annual average temperature, drought severity, fire frequency and distance from towns influence the conversion of natural to anthropogenic LULC classes (importance &gt; 0.5). On the other hand, distance from rivers, soil organic carbon, precipitation, GDP, elevation, population density and annual average temperature importantly influenced conversion from one natural LULC class to another natural LULC class. The study revealed that natural classes (wetland, shrubland, water and woodlands) will gradually decrease at the expense of anthropogenic classes (built-up and cultivated) in future (2040). Despite proposing the necessity of a basin-wide land-use plan to minimise pressure on resources and ensure sustainable use, findings in this study illustrate the benefit of ensemble modelling in understanding LULC dynamics in trans-boundary basins.
WOS:000805661800004
</snippet>
</document>

<document id="8">
<title>Generating annual high resolution land cover products for 28 metropolises in China based on a deep super-resolution mapping network using Landsat imagery</title>
<url>http://dx.doi.org/10.1080/15481603.2022.2142727</url>
<snippet>High resolution of global land cover dynamic is indicative for understanding the influence of anthropogenic activity on environmental change. However, most of the land cover products are based on Landsat image that only has 30 m resolution, which is insufficient to distinguish the heterogenous urban structure; while very high spatial resolution image usually has low temporal resolution, which is difficult to monitor the urban dynamic. Deep-learning-driven super-resolution mapping is a prevailing way of achieving very-high-resolution land cover dynamic products in aspect of alleviating the mixed pixel problem of Landsat image. However, two limitations are obvious: 1) the fixed grid of kernel during the upsampling process favors spatial homogeneity and suppresses the learning of spatial heterogeneity of urban composition and 2) geometric or radiation variation over large spatial and long temporal extent in remote sensing images makes the super-resolution mapping approach difficult to transfer for application. Here, we attempt to solve these two limitations: 1) a progressive edge-guided super-resolution architecture is designed to allow nonuniformed kernel specific at the low-confidence edge region and intensify the learning of heterogenous compositions patterns and 2) an alternating optimization strategy is designed to minimize the resultant entropy and modulate the classification hyperplane to accommodate to the manifold of the discrepant region. Validation experiments are investigated based on a fine-grained and large-extent super-resolution (FLAS) dataset constructed in this study, and it is found that our approach remarkably enhances rich detailed patterns of heterogenous region and outperforms other state-of-the-art algorithms. Besides, we applied DETNet to the large spatial extent of 28 metropolises in China (&gt;40,000 km(2)) and the large temporal extent of continuous 21-year (2000-2020) in Wuhan city to examine transferability. From the land cover areas variation, we find that the expansion rate of cropland is faster than the urban expansion over the past 10 years, which are gradually becoming the principal source for the encroachment of forest and lakes. From detailed urban dynamic reflected by the 21-year products, we find that urban-villages between the old city zone and the outer high-tech development zone are gradually disappeared. The captured dynamic is consistence with the urban-village renovation policy during this period, which is meant to redistribute the spatial configuration of the city for a more sustainable urban structure. We believe that the proposed method can facilitate a seamless and fine-grained observation system that can fill the weakness of the existing land cover activities and provide a brand-new insight into the urban dynamic and its underlying mechanism.
WOS:000884630400001
</snippet>
</document>

<document id="9">
<title>Correspondence between Site Amplification and Topographical, Geological Parameters: Collation of Data from Swiss and Japanese Stations, and Neural Networks-Based Prediction of Local Response</title>
<url>http://dx.doi.org/10.1785/0120210225</url>
<snippet>We address the relation between seismic local amplification and topographical and geological indicators describing the site morphology. We focus on parameters that can be derived from layers of diffuse information (e.g., digital elevation models, geological maps) and do not require in situ surveys; we term these parameters as "indirect" proxies, as opposed to "direct" indicators (e.g., f(0), V-S30) derived from field measurements. We first compiled an extensive database of indirect parameters covering 142 and 637 instrumented sites in Switzerland and Japan, respectively; we collected topographical indicators at various spatial extents and focused on shared features in the geological descriptions of the two countries. We paired this proxy database with a companion dataset of site amplification factors at 10 frequencies within 0.5-20 Hz, empirically measured at the same Swiss and Japanese stations. We then assessed the robustness of the correlation between individual site-condition indicators and local response by means of statistical analyses; we also compared the proxy-site amplification relations at Swiss versus Japanese sites. Finally, we tested the prediction of site amplification by feeding ensembles of indirect parameters to a neural network (NN) structure. The main results are: (1) indirect indicators show higher correlation with site amplification in the low-frequency range (0.5-3.33 Hz); (2) topographical parameters primarily relate to local response not because of topographical amplification effects but because topographical features correspond to the properties of the subsurface, hence to stratigraphic amplification; (3) large-scale topographical indicators relate to low-frequency response, smaller-scale to higher-frequency response; (4) site amplification versus indirect proxy relations show a more marked regional variability when compared with direct indicators; and (5) the NN-based prediction of site response is the best achieved in the 1.67-5 Hz band, with both geological and topographical proxies provided as input; topographical indicators alone perform better than geological parameters.
WOS:000778523200003
</snippet>
</document>

<document id="10">
<title>Replay in minds and machines</title>
<url>http://dx.doi.org/10.1016/j.neubiorev.2021.08.002</url>
<snippet>Experience-related brain activity patterns reactivate during sleep, wakeful rest, and brief pauses from active behavior. In parallel, machine learning research has found that experience replay can lead to substantial performance improvements in artificial agents. Together, these lines of research suggest that replay has a variety of computational benefits for decision-making and learning. Here, we provide an overview of putative computational functions of replay as suggested by machine learning and neuroscientific research. We show that replay can lead to faster learning, less forgetting, reorganization or augmentation of experiences, and support planning and generalization. In addition, we highlight the benefits of reactivating abstracted internal representations rather than veridical memories, and discuss how replay could provide a mechanism to build internal representations that improve learning and decision-making.
WOS:000692239200009
</snippet>
</document>

<document id="11">
<title>A deep learning ensemble model for wildfire susceptibility mapping</title>
<url>http://dx.doi.org/10.1016/j.ecoinf.2021.101397</url>
<snippet>Devastating wildfires have increased in frequency and intensity over the last few years, worsened by climate change and prolonged droughts. Wildfire susceptibility mapping with machine learning has been proven useful for fire-prevention plans, turning into an indispensable tool in wildfire prevention. However, applications of deep learning models in wildfire susceptibility prediction to date are scarce. This study proposes a new Ensemble model based on two deep learning networks previously presented in literature that achieved remarkable results for forest fire susceptibility and other environmental risks. We compare our model with each of its sub-models, two more deep learning networks, and other machine learning benchmark, namely, XGBoost and SVM. Furthermore, we analyze the effects that different sample patch sizes have on the predictive performance of the algorithms. As case study we selected the fire occurrences in two regions in Chile, from 2013 to 2019. Satellite imagery data for fifteen fire influencing factors in the study area were retrieved to build a dataset to extract the samples to train the models. These factors include elevation, aspect, surface roughness, slope, minimum and maximum temperature, wind speed, precipitation, actual evapotranspiration, climatic water deficit, NDVI, land cover type, distance to rivers, distance to roads and distance to urban areas. During training, the best sample patch size was found to be 25 x 25 pixels. As a result, the highest area under the curve (AUC) was 0.953 achieved by the Ensemble model, followed by CNN-1 with AUC = 0.902. The Ensemble model also achieved the best accuracy, sensitivity, specificity, negative predictive value and F1 score. Finally, the predicted susceptibility maps suggest that static variables can be considered as predisposing factors, while dynamic variables affect the intensity of the predicted probabilities, with an important role of the anthropogenic variables. These resulting maps may be useful to prioritize wildfire surveillance and monitoring in extensive high risk areas.
WOS:000703766700001
</snippet>
</document>

<document id="12">
<title>Comparison of high-resolution NAIP and unmanned aerial vehicle (UAV) imagery for natural vegetation communities classification using machine learning approaches</title>
<url>http://dx.doi.org/10.1080/15481603.2023.2177448</url>
<snippet>To map and manage forest vegetation including wetland communities, remote sensing technology has been shown to be a valid and widely employed technology. In this paper, two ecologically different study areas were evaluated using free and widely available high-resolution multispectral National Agriculture Imagery Program (NAIP) and ultra-high-resolution multispectral unmanned aerial vehicle (UAV) imagery located in the Upper Great Lakes Laurentian Mixed Forest. Three different machine learning algorithms, random forest (RF), support vector machine (SVM), and averaged neural network (avNNet), were evaluated to classify complex natural habitat communities as defined by the Michigan Natural Features Inventory. Accurate training sets were developed using both spectral enhancement and transformation techniques, field collected data, soil data, texture, spectral indices, and expert knowledge. The utility of the various ancillary datasets significantly improved classification results. Using the RF classifier, overall accuracies (OA) between 83.8&#37; and 87.7&#37; with kappa (k) values between 0.79 and 0.85 for the NAIP imagery and between 87.3&#37; and 93.7&#37; OA with k values between 0.83 and 0.92 for the UAV dataset were achieved. Based on the results, we concluded RF to be a robust choice for classifying complex forest vegetation including surrounding wetland communities.
WOS:000934536200001
</snippet>
</document>

<document id="13">
<title>Landslide susceptibility maps of Italy: Lesson learnt from dealing with multiple landslide types and the uneven spatial distribution of the national inventory</title>
<url>http://dx.doi.org/10.1016/j.earscirev.2022.104125</url>
<snippet>Landslide susceptibility corresponds to the probability of landslide occurrence across a given geographic space. This probability is usually estimated by using a binary classifier which is informed of landslide presence/absence data and associated landscape characteristics. Here, we consider the Italian national landslide inventory to prepare slope-unit based landslide susceptibility maps. These maps are prepared for the eight types of mass movements existing in the inventory, (Complex, Deep Seated Gravitational Slope Deformation, Diffused Fall, Fall, Rapid Flow, Shallow, Slow Flow, Translational) and we build one susceptibility map for each type. The analysis - carried out by using a Bayesian version of a Generalized Additive Model with a multiple intercept for each Italian region - revealed that the inventory may have been compiled with different levels of detail. This would be consistent with the dataset being assembled from twenty sub-inventories, each prepared by different administrations of the Italian regions. As a result, this spatial heterogeneity may lead to biased national-scale susceptibility maps. On the basis of these considerations, we further analyzed the national database to confirm or reject the varying quality hypothesis on the basis of the model equipped with multiple regional intercepts. For each landslide type, we then tried to build unbiased susceptibility models by removing regions with a poor landslide inventory from the calibration stage, and used them only as a prediction target of a simulation routine. We analyzed the resulting eight maps finding out a congruent dominant pattern in the Alpine and Apennine sectors.The whole procedure is implemented in R-INLA. This allowed to examine fixed (linear) and random (nonlinear) effects from an interpretative standpoint and produced a full prediction equipped with an estimated uncertainty.We propose this overall modeling pipeline for any landslide datasets where a significant mapping bias may influence the susceptibility pattern over space.
WOS:000842980100002
</snippet>
</document>

<document id="14">
<title>Detection of Banana Plants Using Multi-Temporal Multispectral UAV Imagery</title>
<url>http://dx.doi.org/10.3390/rs13112123</url>
<snippet>Unoccupied aerial vehicles (UAVs) have become increasingly commonplace in aiding planning and management decisions in agricultural and horticultural crop production. The ability of UAV-based sensing technologies to provide high spatial (&lt;1 m) and temporal (on-demand) resolution data facilitates monitoring of individual plants over time and can provide essential information about health, yield, and growth in a timely and quantifiable manner. Such applications would be beneficial for cropped banana plants due to their distinctive growth characteristics. Limited studies have employed UAV data for mapping banana crops and to our knowledge only one other investigation features multi-temporal detection of banana crowns. The purpose of this study was to determine the suitability of multiple-date UAV-captured multi-spectral data for the automated detection of individual plants using convolutional neural network (CNN), template matching (TM), and local maximum filter (LMF) methods in a geographic object-based image analysis (GEOBIA) software framework coupled with basic classification refinement. The results indicate that CNN returns the highest plant detection accuracies, with the developed rule set and model providing greater transferability between dates (F-score ranging between 0.93 and 0.85) than TM (0.86-0.74) and LMF (0.86-0.73) approaches. The findings provide a foundation for UAV-based individual banana plant counting and crop monitoring, which may be used for precision agricultural applications to monitor health, estimate yield, and to inform on fertilizer, pesticide, and other input requirements for optimized farm management.
WOS:000660595800001
</snippet>
</document>

<document id="15">
<title>Estimating Alpha, Beta, and Gamma Diversity Through Deep Learning</title>
<url>http://dx.doi.org/10.3389/fpls.2022.839407</url>
<snippet>The reliable mapping of species richness is a crucial step for the identification of areas of high conservation priority, alongside other value and threat considerations. This is commonly done by overlapping range maps of individual species, which requires dense availability of occurrence data or relies on assumptions about the presence of species in unsampled areas deemed suitable by environmental niche models. Here, we present a deep learning approach that directly estimates species richness, skipping the step of estimating individual species ranges. We train a neural network model based on species lists from inventory plots, which provide ground truth data for supervised machine learning. The model learns to predict species richness based on spatially associated variables, including climatic and geographic predictors, as well as counts of available species records from online databases. We assess the empirical utility of our approach by producing independently verifiable maps of alpha, beta, and gamma plant diversity at high spatial resolutions for Australia, a continent with highly heterogeneous diversity patterns. Our deep learning framework provides a powerful and flexible new approach for estimating biodiversity patterns, constituting a step forward toward automated biodiversity assessments.
WOS:000809752600001
</snippet>
</document>

<document id="16">
<title>In-season and dynamic crop mapping using 3D convolution neural networks and sentinel-2 time series</title>
<url>http://dx.doi.org/10.1016/j.isprsjprs.2022.12.005</url>
<snippet>An accurate, frequently updated, automatic and reproducible mapping procedure to identify seasonal cultivated crops is a prerequisite for many crop monitoring activities. Deep learning was demonstrated to be an effective mapping approach already successfully applied to decametric resolution satellite images (like Sentinel-2 data) to produce yearly crop maps. In this framework, algorithm training is performed with ground truth typically consisting of spatially explicit information available after the end of the season (e.g. yearly crop maps and/or farmer declaration for subsidies at parcel level); however, such data (i) does not allow performing in-season prediction, and (ii) does not provide temporal details fundamental to describe a dynamic crop succession and/or to understand crop management (i.e. planting and harvesting). In this paper we present a Deep Neural Network-based approach capable of generating (i) a crop map of the current season at a specific point in time ("In season mapping"conventionally at the end of the current year), along with (ii) all intermediate maps during the season able to describe in near real-time the evolution of crop presence ("Dynamic-mapping"at the temporal granularity of satellite imagery revisiting, e.g., 5 days for Sentinel-2 data). This approach adopts a smart training procedure of a Deep Neural model by exploiting historical satellite data and ground truth. We introduce a method to automatically generate "short-term"ground truth maps (i.e. 5 days reference) starting from the "long-term"ones (i.e. available yearly static reference) and characterizing temporally the different crop presence by performing a phenological analysis of historical time series. The model was trained and validated in Lombardy (North of Italy) exploiting multi-annual authoritative crop maps from 2016 to 2019. Validation was performed both in time (same areas used for training in a different year) and space (different location) for the year 2019. The quantitative error metrics calculation and Spatio-temporal analysis clearly demonstrate that the model can predict in-season crop presence with a generalization capacity over the long-term (yearly maps: OA &gt; 70&#37; and Kappa &gt; 0.64&#37;) and that the short-term predictions (5 days maps) are coherent with the reference information from expert knowledge (local crop calendars). The model can produce dynamically along the season short-term maps with a medium-high crop-specific User Accuracy at the maximum green-up phase (UA &gt; 53&#37; up to 95&#37;). These products are of extreme interest for final users providing information at the peak of plant development that dynamically changes according to the considered crop, the specific location and the investigated season. These results demonstrate that it is possible to produce a crop map early in the season and extract useful additional information such as crop intensity (e.g. double crops presence) and crop dynamics related to different sowing dates.
WOS:000913152800001
</snippet>
</document>

<document id="17">
<title>Mapping land-use intensity of grasslands in Germany with machine learning and Sentinel-2 time series</title>
<url>http://dx.doi.org/10.1016/j.rse.2022.112888</url>
<snippet>Information on grassland land-use intensity (LUI) is crucial for understanding trends and dynamics in biodi-versity, ecosystem functioning, earth system science and environmental monitoring. LUI is a major driver for numerous environmental processes and indicators, such as primary production, nitrogen deposition and resil-ience to climate extremes. However, large extent, high resolution data on grassland LUI is rare. New satellite generations, such as Copernicus Sentinel-2, enable a spatially comprehensive detection of the mainly subtle changes induced by land-use intensification by their fine spatial and temporal resolution. We developed a methodology quantifying key parameters of grassland LUI such as grazing intensity, mowing frequency and fertiliser application across Germany using Convolutional Neural Networks (CNN) on Sentinel-2 satellite data with 20 m x 20 m spatial resolution. Subsequently, these land-use components were used to calculate a continuous LUI index. Predictions of LUI and its components were validated using comprehensive in situ grassland management data. A feature contribution analysis using Shapley values substantiates the applicability of the methodology by revealing a high relevance of springtime satellite observations and spectral bands related to vegetation health and structure. We achieved an overall classification accuracy of up to 66&#37; for grazing in-tensity, 68&#37; for mowing, 85&#37; for fertilisation and an r2 of 0.82 for subsequently depicting LUI. We evaluated the methodologys robustness with a spatial 3-fold cross-validation by training and predicting on geographically distinctly separated regions. Spatial transferability was assessed by delineating the models area of applicability. The presented methodology enables a high resolution, large extent mapping of land-use intensity of grasslands.
WOS:000804945700003
</snippet>
</document>

<document id="18">
<title>Exploring Google Street View with deep learning for crop type mapping</title>
<url>http://dx.doi.org/10.1016/j.isprsjprs.2020.11.022</url>
<snippet>Ground reference data are an essential prerequisite for supervised crop mapping. The lack of a low-cost and efficient ground referencing method results in pervasively limited reference data and hinders crop classification. In this study, we apply a convolutional neural network (CNN) model to explore the efficacy of automatic ground truthing via Google Street View (GSV) images in two distinct farming regions: Illinois and the Central Valley in California. We demonstrate the feasibility and reliability of our new ground referencing technique by performing pixel-based crop mapping at the state level using the cloud-based Google Earth Engine platform. The mapping results are evaluated using the United States Department of Agriculture (USDA) crop data layer (CDL) products. From similar to 130,000 GSV images, the CNN model identified similar to 9,400 target crop images. These images are well classified into crop types, including alfalfa, almond, corn, cotton, grape, rice, soybean, and pistachio. The overall GSV image classification accuracy is 92&#37; for the Central Valley and 97&#37; for Illinois. Subsequently, we shifted the image geographical coordinates 2-3 times in a certain direction to produce 31,829 crop reference points: 17,358 in Illinois, and 14,471 in the Central Valley. Evaluation of the mapping results with CDL products revealed satisfactory coherence. GSV-derived mapping results capture the general pattern of crop type distributions for 2011-2019. The overall agreement between CDL products and our mapping results is indicated by R-2 values of 0.44-0.99 for the Central Valley and 0.81-0.98 for Illinois. To show the applicational value of the proposed method in other countries, we further mapped rice paddy (2014-2018) in South Korea which yielded fairly well outcomes (R-2 = 0.91). These results indicate that GSV images used with a deep learning model offer an efficient and cost-effective alternative method for ground referencing, in many regions of the world.
WOS:000604406500019
</snippet>
</document>

<document id="19">
<title>Geo-Object-Based Vegetation Mapping via Machine Learning Methods with an Intelligent Sample Collection Scheme: A Case Study of Taibai Mountain, China</title>
<url>http://dx.doi.org/10.3390/rs13020249</url>
<snippet>Precise vegetation maps of mountainous areas are of great significance to grasp the situation of an ecological environment and forest resources. In this paper, while multi-source geospatial data can generally be quickly obtained at present, to realize effective vegetation mapping in mountainous areas when samples are difficult to collect due to their perilous terrain and inaccessible deep forest, we propose a novel and intelligent method of sample collection for machine-learning (ML)-based vegetation mapping. First, we employ geo-objects (i.e., polygons) from topographic partitioning and constrained segmentation as basic mapping units and formalize the problem as a supervised classification process using ML algorithms. Second, a previously available vegetation map with rough-scale label information is overlaid on the geo-object-level polygons, and candidate geo-object-based samples can be identified when all the grids labels of vegetation types within the geo-objects are the same. Third, various kinds of geo-object-level features are extracted according to high-spatial-resolution remote sensing (HSR-RS) images and multi-source geospatial data. Some unreliable geo-object-based samples are rejected in the candidate set by comparing their features and the rules based on local expert knowledge. Finally, based on these automatically collected samples, we train the model using a random forest (RF)-based algorithm and classify all the geo-objects with labels of vegetation types. A case experiment of Taibai Mountain in China shows that the methodology has the ability to achieve good vegetation mapping results with the rapid and convenient sample collection scheme. The map with a finer geographic distribution pattern of vegetation could clearly promote the vegetation resources investigation and monitoring of the study area; thus, the methodological framework is worth popularizing in the mapping areas such as mountainous regions where the field survey sampling is difficult to implement.
WOS:000611956400001
</snippet>
</document>

<document id="20">
<title>Accuracy Assessment in Convolutional Neural Network-Based Deep Learning Remote Sensing Studies-Part 1: Literature Review</title>
<url>http://dx.doi.org/10.3390/rs13132450</url>
<snippet>Convolutional neural network (CNN)-based deep learning (DL) is a powerful, recently developed image classification approach. With origins in the computer vision and image processing communities, the accuracy assessment methods developed for CNN-based DL use a wide range of metrics that may be unfamiliar to the remote sensing (RS) community. To explore the differences between traditional RS and DL RS methods, we surveyed a random selection of 100 papers from the RS DL literature. The results show that RS DL studies have largely abandoned traditional RS accuracy assessment terminology, though some of the accuracy measures typically used in DL papers, most notably precision and recall, have direct equivalents in traditional RS terminology. Some of the DL accuracy terms have multiple names, or are equivalent to another measure. In our sample, DL studies only rarely reported a complete confusion matrix, and when they did so, it was even more rare that the confusion matrix estimated population properties. On the other hand, some DL studies are increasingly paying attention to the role of class prevalence in designing accuracy assessment approaches. DL studies that evaluate the decision boundary threshold over a range of values tend to use the precision-recall (P-R) curve, the associated area under the curve (AUC) measures of average precision (AP) and mean average precision (mAP), rather than the traditional receiver operating characteristic (ROC) curve and its AUC. DL studies are also notable for testing the generalization of their models on entirely new datasets, including data from new areas, new acquisition times, or even new sensors.
WOS:000671055800001
</snippet>
</document>

<document id="21">
<title>Hybrid deep learning models for mapping surface NO2 across China: One complicated model, many simple models, or many complicated models? br</title>
<url>http://dx.doi.org/10.1016/j.atmosres.2022.106339</url>
<snippet>While deep learning is an emerging trend in modeling spatiotemporal dynamics of air pollution, designing a high-performance architecture with various neural network components is difficult. This study aims to identify a suitable deep learning architecture for deriving spatiotemporal distributions of surface NO2 across China. Based on satellite retrievals and geographic variables, we compared the performance of a series of deep learning models and a benchmark model (i.e., random forest) in predicting daily NO2 during 2016-2017 on a 0.1 degrees grid. The deep learning models tested were hybrids of full connection layers (FC), autoencoders (AE), residual networks (RES), and convolution layers (CNN). Their ensemble forms were also comparatively evaluated. The integrated results of the sample-, cell-, and date-based holdout tests show that the ensemble FC-AE-RES-CNN model (R2 = 0.71; RMSE = 9.9 mu g/m3) outperformed the random forest (R2 = 0.67; RMSE = 10.8 mu g/m3), but none of the singleform networks did (R2 ranged from 0.56 to 0.61, and RMSE ranged from 11.6 to 12.2 mu g/m3). The superior performance of the ensemble FC-AE-RES-CNN model could be attributed to its lower bias and lower variance, which benefited from the sophisticated model structure and the ensemble strategy. Consequently, the ensemble FC-AE-RES-CNN model predictions demonstrated a spatiotemporal distribution of surface NO2 with higher fidelity. In light of the comprehensive comparisons, we expect that ensemble deep learning models will be substituting for traditional machine learning models in environmental spatiotemporal mapping applications.
WOS:000865420700002
</snippet>
</document>

<document id="22">
<title>Remote Sensing Scene Graph and Knowledge Graph Matching with Parallel Walking Algorithm</title>
<url>http://dx.doi.org/10.3390/rs14194872</url>
<snippet>In deep neural network model training and prediction, due to the limitation of GPU memory and computing resources, massive image data must be cropped into limited-sized samples. Moreover, in order to improve the generalization ability of the model, the samples need to be randomly distributed in the experimental area. Thus, the background information is often incomplete or even missing. On this condition, a knowledge graph must be applied to the semantic segmentation of remote sensing. However, although a single sample contains only a limited number of geographic categories, the combinations of geographic objects are diverse and complex in different samples. Additionally, the involved categories of geographic objects often span different classification system branches. Therefore, existing studies often directly regard all the categories involved in the knowledge graph as candidates for specific sample segmentation, which leads to high computation cost and low efficiency. To address the above problems, a parallel walking algorithm based on cross modality information is proposed for the scene graph-knowledge graph matching (PWGM). The algorithm uses a graph neural network to map the visual features of the scene graph into the semantic space of the knowledge graph through anchors and designs a parallel walking algorithm of the knowledge graph that takes into account the visual features of complex scenes. Based on the algorithm, we propose a semantic segmentation model for remote sensing. The experiments demonstrate that our model improves the overall accuracy by 3.7&#37; compared with KGGAT (which is a semantic segmentation model using a knowledge graph and graph attention network (GAT)), by 5.1&#37; compared with GAT and by 13.3&#37; compared with U-Net. Our study not only effectively improves the recognition accuracy and efficiency of remote sensing objects, but also offers useful exploration for the development of deep learning from a data-driven to a data-knowledge dual drive.
WOS:000867172500001
</snippet>
</document>

<document id="23">
<title>Very High Resolution Species Distribution Modeling Based on Remote Sensing Imagery: How to Capture Fine-Grained and Large-Scale Vegetation Ecology With Convolutional Neural Networks?</title>
<url>http://dx.doi.org/10.3389/fpls.2022.839279</url>
<snippet>Species Distribution Models (SDMs) are fundamental tools in ecology for predicting the geographic distribution of species based on environmental data. They are also very useful from an application point of view, whether for the implementation of conservation plans for threatened species or for monitoring invasive species. The generalizability and spatial accuracy of an SDM depend very strongly on the type of model used and the environmental data used as explanatory variables. In this article, we study a country-wide species distribution model based on very high resolution (VHR) (1 m) remote sensing images processed by a convolutional neural network. We demonstrate that this model can capture landscape and habitat information at very fine spatial scales while providing overall better predictive performance than conventional models. Moreover, to demonstrate the ecological significance of the model, we propose an original analysis based on the t-distributed Stochastic Neighbor Embedding (t-SNE) dimension reduction technique. It allows visualizing the relation between input data and species traits or environment learned by the model as well as conducting some statistical tests verifying them. We also analyze the spatial mapping of the t-SNE dimensions at both national and local levels, showing the model benefit of automatically learning environmental variation at multiple scales.
WOS:000802108900001
</snippet>
</document>

<document id="24">
<title>Spatial modelling of soil salinity: deep or shallow learning models?</title>
<url>http://dx.doi.org/10.1007/s11356-021-13503-7</url>
<snippet>Understanding the spatial distribution of soil salinity is required to conserve land against degradation and desertification. Against this background, this study is the first attempt to predict soil salinity in the Jaghin basin, in southern Iran, by applying and comparing the performance of four deep learning (DL) models (deep convolutional neural networks-DCNNs, dense connected deep neural networks-DenseDNNs, recurrent neural networks-long short-term memory-RNN-LSTM and recurrent neural networks-gated recurrent unit-RNN-GRU) and six shallow machine learning (ML) models (bagged classification and regression tree-BCART, cforest, cubist, quantile regression with LASSO penalty-QR-LASSO, ridge regression-RR and support vectore machine-SVM). To do this, 49 environmental landsat8-derived variables including digital elevation model (DEM)-extracted covariates, soil-salinity indices, and other variables (e.g., soil order, lithology, land use) were mapped spatially. For assessing the relationships between soil salinity (EC) and factors controlling EC, we collected 319 surficial (0-5 cm depth) soil samples for measuring soil salinity on the basis of electrical conductivity (EC). We then selected the most important features (covariates) controlling soil salinity by applying a MARS model. The performance of the DL and shallow ML models for generating soil salinity spatial maps (SSSMs) was assessed using a Taylor diagram and the Nash Sutcliff coefficient (NSE). Among all 10 predictive models, DL models with NSE &gt;= 0.9 (DCNNs was the most accurate model with NSE = 0.96) were selected as the four best models, and performed better than the six shallow ML models with NSE &lt;= 0.83 (QR-LASSO was the weakest predictive model with NSE = 0.50). Based on DCNNs-, the values of the EC ranged between 0.67 and 14.73 dS/m, whereas for QR-LASSO the corresponding EC values were 0.37 to 19.6 dS/m. Overall, DL models performed better than shallow ML models for production of the SSSMs and therefore we recommend applying DL models for prediction purposes in environmental sciences.
WOS:000631811800004
</snippet>
</document>

<document id="25">
<title>Live fuel moisture content estimation from MODIS: A deep learning approach</title>
<url>http://dx.doi.org/10.1016/j.isprsjprs.2021.07.010</url>
<snippet>Live fuel moisture content (LFMC) is an essential variable to model fire danger and behaviour. This paper presents the first application of deep learning to LFMC estimation based on the historical LFMC ground samples of the Globe-LFMC database, as a step towards operational daily LFMC mapping in the Contiguous United States (CONUS). One-year MODerate resolution Imaging Spectroradiometer (MODIS) time series preceding each LFMC sample were extracted as the primary data source for training. The proposed temporal convolutional neural network for LFMC (TempCNN-LFMC) comprises three 1-D convolutional layers that learn the multi-scale temporal dynamics (features) of one-year MODIS time series specific to LFMC estimation. The learned features, together with a few auxiliary variables (e.g., digital elevation model), are then passed to three fully connected layers to extract the non-linear relationships with LFMC. In the primary training and validation scenario, the neural network was trained using samples from 2002 to 2013 and then adopted to estimating the LFMC from 2014 to 2018, achieving an overall root mean square error (RMSE) of 25.57&#37; and a correlation coefficient (R) of 0.74. Good consistency on spatial patterns and temporal trends of accuracy was observed. The trained model achieved a similar RMSE of 25.98&#37;, 25.20&#37; and 25.93&#37; for forest, shrubland, and grassland, respectively, without requiring prior information on the vegetation type.
WOS:000686386900006
</snippet>
</document>

<document id="26">
<title>Long Short-Term Memory Neural Network for Ionospheric Total Electron Content Forecasting Over China</title>
<url>http://dx.doi.org/10.1029/2020SW002706</url>
<snippet>An increasing number of terrestrial- and space-based radio-communication systems are influenced by the ionospheric space weather, making the ionospheric state increasingly important to forecast. In this study, a novel extended encoder-decoder long short-term memory extended (ED-LSTME) neural network, which can predict ionospheric total electron content (TEC) is proposed. Useful inherent features were automatically extracted from the historical TEC by LSTM layers, and the performance of the proposed model was enhanced by considering solar flux and geomagnetic activity data. The proposed ED-LSTME model was validated using 15-min TEC values from GPS measurements over one solar cycle (from January 2006 to July 2018) collected at 15 GPS stations in China. Different assessment experiments were conducted in different geographical locations and seasons as well as under varying geomagnetic activities, to comprehensively evaluate the models performance. These comparative experiments were conducted using an ED-LSTM, a traditional LSTM, a deep neural network, autoregressive integrated moving average, and the 2016 International Reference Ionosphere models. The results indicated that the ED-LSTME model is superior to the other statistical models, with R-2 and root mean square error values of 0.89 and 12.09 TECU, respectively. In addition, TEC was adequately predicted under different ionospheric conditions, and satisfactory results were obtained even under geomagnetically disturbed conditions. These results suggest that the prediction performance could be significantly improved by utilizing auxiliary data. These observations confirm that the proposed model outperforms several state-of-the-art models in making predictions at different times and under diverse conditions.
WOS:000644602700010
</snippet>
</document>

<document id="27">
<title>Estimating fractional snow cover from passive microwave brightness temperature data using MODIS snow cover product over North America</title>
<url>http://dx.doi.org/10.5194/tc-15-835-2021</url>
<snippet>The dynamic characteristics of seasonal snow cover are critical for hydrology management, the climate system, and the ecosystem functions. Optical satellite remote sensing has proven to be an effective tool for monitoring global and regional variations in snow cover. However, accurately capturing the characteristics of snow dynamics at a finer spatiotemporal resolution continues to be problematic as observations from optical satellite sensors are greatly impacted by clouds and solar illumination. Traditional methods of mapping snow cover from passive microwave data only provide binary information at a spatial resolution of 25 km. This innovative study applies the random forest regression technique to enhanced-resolution passive microwave brightness temperature data (6.25 km) to estimate fractional snow cover over North America in winter months (January and February). Many influential factors, including land cover, topography, and location information, were incorporated into the retrieval models. Moderate Resolution Imaging Spectro-radiometer (MODIS) snow cover products between 2008 and 2017 were used to create the reference fractional snow cover data as the "true" observations in this study. Although over-estimating and underestimating around two extreme values of fractional snow cover, the proposed retrieval algorithm outperformed the other three approaches (linear regression, artificial neural networks, and multivariate adaptive regression splines) using independent test data for all land cover classes with higher accuracy and no out-of-range estimated values. The method enabled the evaluation of the estimated fractional snow cover using independent datasets, in which the root mean square error of evaluation results ranged from 0.189 to 0.221. The snow cover detection capability of the proposed algorithm was validated using meteorological station observations with more than 310 000 records. We found that binary snow cover obtained from the estimated fractional snow cover was in good agreement with ground measurements (kappa: 0.67). There was significant improvement in the accuracy of snow cover identification using our algorithm; the overall accuracy increased by 18&#37; (from 0.71 to 0.84), and the omission error was reduced by 71&#37; (from 0.48 to 0.14) when the threshold of fractional snow cover was 0.3. The experimental results show that passive microwave brightness temperature data may potentially be used to estimate fractional snow cover directly in that this retrieval strategy offers a competitive advantage in snow cover detection.
WOS:000621382900001
</snippet>
</document>

<document id="28">
<title>Large-scale crop type and crop area mapping across Brazil using synthetic aperture radar and optical imagery</title>
<url>http://dx.doi.org/10.1016/j.jag.2020.102294</url>
<snippet>Improved data on crop type and crop area from satellite imagery are invaluable for agronomy managers and are crucial for balancing agricultural expansion and forest degradation. However, large-scale maps of crop type and crop area using satellite imagery are not easily available in some regions, especially Brazil. Reasons for this include limited ground truth data, inadequate spatial and temporal satellite data availability, computational challenges, lack of cropland data and field boundaries. In this paper, we attempted to overcome some of these obstacles by using an ensemble of approaches to generate crop classification maps for Brazil. In order to compensate for the lack of abundant ground truth data in Brazil, we combined extensive field data and satellite input features from the United States with available field data and satellite input features from Brazil to train crop classification model for Brazil. Before applying the crop classification model for Brazil, we classified cropland areas using harmonic functions and delineated field boundaries using a supervised deep learning approach. Cropland masking and field boundary delineation allowed field-level mapping of crop type and crop area. Applying the crop classification model for Brazil in the states of Mato Grosso and Goias gave a true positive accuracy of 88&#37; in the 2017/2018 summer growing season for soybean classification, 95&#37; in the 2018 safrinha growing season for corn classification, and 86&#37; in the 2018/2019 summer growing season for soybean classification. Our crop area estimates also showed a good agreement (correlation of 0.95 and mean absolute error of 0.64) with state-scale statistical data provided by the Companhia Nacional de Abastecimento (CONAB) in both summer and safrinha growing seasons adding further confidence to the results. These results suggest that extensive data from one geography can be used to train machine learning models in conjunction with limited field data from another geography. Accuracy assessments support the portability of crop classification model for Brazil with reasonable accuracy spatially, as tested in the state of Parana, and temporally, to the following year. The approaches and datasets presented in this paper provide building blocks for large-scale crop monitoring benefitting both public and private sectors.
WOS:000616288400001
</snippet>
</document>

<document id="29">
<title>RegNet: a neural network model for predicting regional desirability with VGI data</title>
<url>http://dx.doi.org/10.1080/13658816.2020.1768261</url>
<snippet>Volunteered geographic information can be used to predict regional desirability. A common challenge regarding previous works is that intuitive empirical models, which are inaccurate and bring in perceptual bias, are traditionally used to predict regional desirability. This results from the fact that the hidden interactions between user online check-ins and regional desirability have not been revealed and clearly modelled yet. To solve the problem, a novel neural network model RegNet is proposed. The user check-in history is input into a neural network encoder structure firstly for redundancy reduction and feature learning. The encoded representation is then fed into a hidden-layer structure and the regional desirability is predicted. The proposed RegNet is data-driven and can adaptively model the unknown mappings from input to output, without presumed bias and prior knowledge. We conduct experiments with real-world datasets and demonstrate RegNet outperforms state-of-the-art methods in terms of ranking quality and prediction accuracy of rating. Additionally, we also examine how the structure of encoder affects RegNet performance and suggest on choosing proper sizes of encoded representation. This work demonstrates the effectiveness of data-driven methods in modelling the hidden unknown relationships and achieving a better performance over traditional empirical methods.
WOS:000535110000001
</snippet>
</document>

<document id="30">
<title>A comparison of the integrated fuzzy object-based deep learning approach and three machine learning techniques for land use/cover change monitoring and environmental impacts assessment</title>
<url>http://dx.doi.org/10.1080/15481603.2021.2000350</url>
<snippet>Recent improvements in the spatial, temporal, and spectral resolution of satellite images necessitate (semi-)automated classification and information extraction approaches. Therefore, we developed an integrated fuzzy object-based image analysis and deep learning (FOBIA-DL) approach for monitoring the land use/cover (LULC) and respective changes and compared it to three machine learning (ML) algorithms, namely the support vector machine (SVM), random forest (RF), and classification and regression tree (CART). We investigated LULC impacts on drought by analyzing Landsat satellite images from 1990 to 2020 for the Urmia Lake area in northern Iran. In the FOBIA-DL approach, following the initial segmentation steps, object features were identified for each LULC class. We then derived their respective attributes using fuzzy membership functions and deep convolutional neural networks (DCNNs), a deep learning method. The Fuzzy Synthetic Evaluation and Dempster-Shafer Theory (FSE-DST) also applied to validate and carryout the spatial uncertainties. Our results indicate that the FOBIA-DL, with an accuracy of 90.1&#37; to 96.4&#37; and a spatial certainty of 0.93 to 0.97, outperformed the other approaches, closely followed by the SVM. Our results also showed that the integration of Fuzzy-OBIA and DCNNs could improve the strength and robustness of the OBIAs decision rules, while the FSE-DST approach notably improved the spatial accuracy of the object-based classification maps. While object-based image analysis (OBIA) is already considered a paradigm shift in GIScience, the integration of OBIA with fuzzy and deep learning creates more flexibility and robust OBIA decision rules for image analysis and classification. This research integrated popular data-driven approaches and developed a novel methodology for image classification and spatial accuracy assessment. From the environmental perspective, the results of this research support lake restoration initiatives by decision-makers and authorities in applications such as drought mitigation, land use management and precision agriculture programs.
WOS:000724069000001
</snippet>
</document>

<document id="31">
<title>Forest Conservation with Deep Learning: A Deeper Understanding of Human Geography around the Betampona Nature Reserve, Madagascar</title>
<url>http://dx.doi.org/10.3390/rs13173495</url>
<snippet>Documenting the impacts of climate change and human activities on tropical rainforests is imperative for protecting tropical biodiversity and for better implementation of REDD+ and UN Sustainable Development Goals. Recent advances in very high-resolution satellite sensor systems (i.e., WorldView-3), computing power, and machine learning (ML) have provided improved mapping of fine-scale changes in the tropics. However, approaches so far focused on feature extraction or the extensive tuning of ML parameters, hindering the potential of ML in forest conservation mapping by not using textural information, which is found to be powerful for many applications. Additionally, the contribution of shortwave infrared (SWIR) bands in forest cover mapping is unknown. The objectives were to develop end-to-end mapping of the tropical forest using fully convolution neural networks (FCNNs) with WorldView-3 (WV-3) imagery and to evaluate human impact on the environment using the Betampona Nature Reserve (BNR) in Madagascar as the test site. FCNN (U-Net) using spatial/textural information was implemented and compared with feature-fed pixel-based methods including Support Vector Machine (SVM), Random Forest (RF), and Deep Neural Network (DNN). Results show that the FCNN model outperformed other models with an accuracy of 90.9&#37;, while SVM, RF, and DNN provided accuracies of 88.6&#37;, 84.8&#37;, and 86.6&#37;, respectively. When SWIR bands were excluded from the input data, FCNN provided superior performance over other methods with a 1.87&#37; decrease in accuracy, while the accuracies of other models-SVM, RF, and DNN-decreased by 5.42&#37;, 3.18&#37;, and 8.55&#37;, respectively. Spatial-temporal analysis showed a 0.7&#37; increase in Evergreen Forest within the BNR and a 32&#37; increase in tree cover within residential areas likely due to forest regeneration and conservation efforts. Other effects of conservation efforts are also discussed.
WOS:000694540300001
</snippet>
</document>

<document id="32">
<title>Multitemporal Relearning With Convolutional LSTM Models for Land Use Classification</title>
<url>http://dx.doi.org/10.1109/JSTARS.2021.3055784</url>
<snippet>In this article, we present a novel hybrid framework, which integrates spatial-temporal semantic segmentation with postclassification relearning, for multitemporal land use and land cover (LULC) classification based on very high resolution (VHR) satellite imagery. To efficiently obtain optimal multitemporal LULC classification maps, the hybrid framework utilizes a spatial-temporal semantic segmentation model to harness temporal dependency for extracting high-level spatial-temporal features. In addition, the principle of postclassification relearning is adopted to efficiently optimize model output. Thereby, the initial outcome of a semantic segmentation model is provided to a subsequent model via an extended input space to guide the learning of discriminative feature representations in an end-to-end fashion. Last, object-based voting is coupled with postclassification relearning for coping with the high intraclass and low interclass variances. The framework was tested with two different postclassification relearning strategies (i.e., pixel-based relearning and object-based relearning) and three convolutional neural network models, i.e., UNet, a simple Convolutional LSTM, and a UNet Convolutional-LSTM. The experiments were conducted on two datasets with LULC labels that contain rich semantic information and variant building morphologic features (e.g., informal settlements). Each dataset contains four time steps from WorldView-2 and Quickbird imagery. The experimental results unambiguously underline that the proposed framework is efficient in terms of classifying complex LULC maps with multitemporal VHR images.
WOS:000637186500003
</snippet>
</document>

<document id="33">
<title>Thin Cloud Removal Fusing Full Spectral and Spatial Features for Sentinel-2 Imagery</title>
<url>http://dx.doi.org/10.1109/JSTARS.2022.3211857</url>
<snippet>Multispectral remote sensing images are widely used for monitoring the globe. Although thin clouds can affect all optical bands, the influences of thin clouds differ with band wavelength. When processing multispectral bands at different resolutions, many methods only remove thin clouds in visible/near-infrared bands or rescale multiresolution bands to the same resolution and then process them together. The former cannot make full use of multispectral information, and in the latter, the rescaling process will introduce noise. In this article, a deep-learning-based thin cloud removal method that fuses full spectral and spatial features in original Sentinel-2 bands is proposed, named CR4S2. A multi-input and output architecture is designed for better fusing information in all bands and reconstructing the background at original resolutions. In addition, two parallel downsampling residual blocks are designed to transfer features extracted from different depths to the bottom of the network. Experiments were conducted on a new globally distributed Sentinel-2 thin cloud removal dataset called WHUS2-CRv. The results show that the best averaged peak signal-to-noise ratio, structural similarity index measurement, normalized root-mean-square error, and spectral angle mapper of the proposed method over 12 bands in all 20 testing images were 39.55, 0.9443, 0.0245, and 2.5676 degrees, respectively. Compared with baseline methods, the proposed CR4S2 method can better restore not only the spatial features but also spectral features. This indicates that the proposed method is very promising for removing thin clouds in multispectral remote sensing images at different resolutions.
WOS:000871047900003
</snippet>
</document>

<document id="34">
<title>Machine Learning Techniques for Estimating Hydraulic Properties of the Topsoil across the Zambezi River Basin</title>
<url>http://dx.doi.org/10.3390/land11040591</url>
<snippet>It is critical to produce more crop per drop in an environment where water availability is decreasing and competition for water is increasing. In order to build such agricultural production systems, well parameterized crop growth models are essential. While in most crop growth modeling research, focus is on gathering model inputs such as climate data, less emphasis is paid to collecting the critical soil hydraulic properties (SHPs) data needed to operate crop growth models. Collection of SHPs data for the Zambezi River Basin (ZRB) is extremely labor-intensive and expensive, thus alternate technologies such as digital soil mapping (DSM) must be explored. We evaluated five types of DSM models to establish the best spatially explicit estimates of the soil water content at pF0.0 (saturation), pF2.0 (field capacity), and pF4.2 (wilting point), and of the saturated hydraulic conductivity (Ksat) across the ZRB by using estimates of locally calibrated pedotransfer functions of 1481 locations for training and testing the DSM models, as well as a reference dataset of measurements from 174 locations for validating the DSM models. We produced coverages of environmental covariates from various source datasets, including climate variables, soil and land use maps, parent materials and lithologic units, derivatives of a digital elevation model (DEM), and Landsat imagery with a spatial resolution of 90 m. The five types of models included multiple linear regression and four machine learning techniques: artificial neural network, gradient boosted regression trees, random forest, and support vector machine. Where the residuals of the initial DSM models were spatially autocorrelated, the models were extended/complemented with residual kriging (RK). Spatial autocorrelation in the model residuals was observed for all five models of each of the three water contents, but not for Ksat. On average for the water content, the R 2 ranged from 0.40 to 0.80 in training and test datasets before adding kriged model residuals and ranged from 0.80 to 0.95 after adding model residuals. Overall, the best prediction method consisted of random forest as the deterministic model, complemented with RK, whereby soil texture followed by climate and topographic elevation variables were the most important covariates. The resulting maps are a ready-to-use resource for hydrologists and crop modelers to aliment and calibrate their hydrological and crop growth models.
WOS:000786341100001
</snippet>
</document>

<document id="35">
<title>Exploitation of Time Series Sentinel-2 Data and Different Machine Learning Algorithms for Detailed Tree Species Classification</title>
<url>http://dx.doi.org/10.1109/JSTARS.2021.3098817</url>
<snippet>The classification of tree species through remote sensing data is of great significance to monitoring forest disturbances, biodiversity assessment, and carbon estimation. The dense time series and a wide swath of Sentinel-2 data provided the opportunity to map tree species accurately and in a timely manner over a large area. Many current studies have applied machine learning (ML) algorithms combined with Sentinel-2 images to classify tree species, but it is still unclear, which algorithm is more effective in the automotive extraction of tree species. In this study, five ML algorithms were compared to identify the composition of tree species with multitemporal Sentinel-2 images in the JianShe forest farm, Northeast China. Three major types of deep neural networks [Conv1D, AlexNet, and long short-term memory (LSTM)] were tested to classify Sentinel-2 time series, which represent three disparate but effective strategies to apply sequential data. The other two models are support vector machine (SVM) and random forest (RF), which are renowned for extensive adoption and high performance for various remote sensing applications. The results show that the overall accuracy of neural network models is better than that of SVM and RF. The Conv1D model had the highest classification accuracy (84.19&#37;), followed by the LSTM model (81.52&#37;), and the AlexNet model (76.02&#37;). For non-neural network models, RFs classification accuracy (79.04&#37;) is higher than that of SVM (72.79&#37;), but lower than that of Conv1D and LSTM. Therefore, the deep neural networks combined with multitemporal Sentinel-2 images can efficiently improve the accuracy of tree species classification.
WOS:000684698600004
</snippet>
</document>

<document id="36">
<title>Spatial prediction of groundwater potential and driving factor analysis based on deep learning and geographical detector in an arid endorheic basin</title>
<url>http://dx.doi.org/10.1016/j.ecolind.2022.109256</url>
<snippet>Substantial mineral resources are enriched in the arid endorheic basins; however, due to environmental constraints, these areas face water shortages as well as its extremely uneven spatiotemporal distribution, which restricts the development of local industry and agriculture. Identifying these areas of the high groundwater potential are useful for groundwater supply and its sustainable planning. In this study, the Qaidam Basin in Northwest China was taken as an example. We collected 17 conditioning factors (i.e., precipitation, evaporation, geology, soil, Topographic Wetness Index, Fractional Vegetation Cover, distance to rivers, river density, distance to roads, road density, distance to faults, fault density, slope, curvature, residential density, landcover, and geomorphology) affecting groundwater resources in arid areas. We also collected 139 groundwater samples and used random forest (RF), deep neural network (DNN) and convolutional neural network (CNN) (associated with one-hot encoding) to predict the groundwater potential in this area. The Qaidam Basin was discretized into 420,000 sample points calculated in turn by the above three models. Receiver operating characteristic (ROC) and area under the curve (AUC) were used to test the accuracy of the three methods. Results indicated that the prediction scores for the three methods were 0.742, 0.790, and 0.817, and the AUC was 0.783, 0.811, and 0.846, respectively. The result provided by CNN was more precise than the results provided by RF and DNN. Additionally, this study aims to investigate the effects of the aforementioned factors on groundwater potential. A total of 17 factors were combined with the Geodetector model to quantify their impacts and interactions on the groundwater potential of the Qaidam Basin. Results revealed that the critical factors affecting groundwater potential in the Qaidam Basin were geomorphology (0.183) and evaporation (0.144), and their combined contribution was 0.457. The influence of arbitrary two-factors on groundwater potential is larger than that of themselves, demonstrating linear or nonlinear enhancement between them and confirming that the factor selections were sensible. The method based on CNN-Geodetector provides a novel approach for calculating groundwater potential, selecting appropriate evaluation indicators and quantifying the driving factors in the arid endorheic basins.
WOS:000872003000001
</snippet>
</document>

<document id="37">
<title>Coupling Dual Graph Convolution Network and Residual Network for Local Climate Zone Mapping</title>
<url>http://dx.doi.org/10.1109/JSTARS.2021.3132394</url>
<snippet>Local climate zone (LCZ) has become a new standard classification scheme in urban landscapes and showed great potential in urban climate research. Traditional classifiers and ordinary neural networks only consider the spectral or local spatial features of the pixel, ignoring the effect of nonlocal information on the LCZ classification. The graph convolutional network (GCN) has been used to exploit the relationship between adjacent and global land covers owing to the ability to conduct flexible convolution over graphs. In this work, we integrated a convolutional neural network and two GCNs into an end-to-end hybrid framework and generated LCZs directly from the original images. Local-, regional-, and global-level features were extracted and grouped complementarily to foster better performance. Experiments were conducted in six cities around the world to verify the effectiveness of our method. Results showed that the average classification accuracy of the six cities reached 0.956 and performed better than any other comparable model. Ablation experiments also demonstrated the mutual promotion of the different modules. Finally, the small sample experiment provided a practical reference for the LCZ classification in the absence of samples in future.
WOS:000748370600003
</snippet>
</document>

<document id="38">
<title>Water-energy, climate, and habitat heterogeneity mutually drives spatial pattern of tree species richness in the Indian Western Himalaya</title>
<url>http://dx.doi.org/10.3389/ffgc.2022.1022082</url>
<snippet>Analyzing plant species richness across a broad geographic gradient is critical for understanding the patterns and processes of biodiversity. In view of this, a species richness map was developed by stacking the ranges of 51 tree species along an elevational gradient in the Western Himalaya using stacked species distribution models (SSDMs). Among modeling algorithms available in SSDMs, random forest and artificial neural networks exhibited the best performance (r = 0.81, p &lt; 0.001). The predicted tree species richness distribution pattern revealed a mid-elevation peak at around 2,000 m asl, which is in concordance with the observed richness pattern (R-2 = 0.94, p &lt; 0.001). Additionally, structural equation models (SEMs) were used to confirm the key factors that influence tree richness. The results based on SEMs confirm that the elevational pattern of predicted tree species richness is explained by mutual effects of water-energy availability, climate, and habitat heterogeneity. This study also validates that the impact of moisture on tree species richness coincides geographically with climate factors. The results have revealed that water-energy-related variables are likely to impact the species richness directly at higher elevations, whereas the effect is more likely to be tied to moisture at lower elevations. SSDMs provide a good tool to predict a species richness pattern and could help in the conservation and management of high biodiverse areas at different spatial scales. However, more investigation is needed to validate the SSDMs in other parts of the Himalayan region to provide a comprehensive synoptic perspective of Himalayan biodiversity at a larger scale.
WOS:000889972900001
</snippet>
</document>

<document id="39">
<title>GETNext: Trajectory Flow Map Enhanced Transformer for Next POI Recommendation</title>
<url>http://dx.doi.org/10.1145/3477495.3531983</url>
<snippet>Next POI recommendation intends to forecast users' immediate future movements given their current status and historical information, yielding great values for both users and service providers. However, this problem is perceptibly complex because various data trends need to be considered together. This includes the spatial locations, temporal contexts, user's preferences, etc. Most existing studies view the next POI recommendation as a sequence prediction problem while omitting the collaborative signals from other users. Instead, we propose a user-agnostic global trajectory flow map and a novel Graph Enhanced Transformer model (GETNext) to better exploit the extensive collaborative signals for a more accurate next POI prediction, and alleviate the cold start problem in the meantime. GETNext incorporates the global transition patterns, user's general preference, spatio-temporal context, and time-aware category embeddings together into a transformer model to make the prediction of user's future moves. With this design, our model outperforms the state-of-the-art methods with a large margin and also sheds light on the cold start challenges within the spatio-temporal involved recommendation problems.
WOS:000852715901021
</snippet>
</document>

<document id="40">
<title>Mapping Gridded Gross Domestic Product Distribution of China Using Deep Learning With Multiple Geospatial Big Data</title>
<url>http://dx.doi.org/10.1109/JSTARS.2022.3148448</url>
<snippet>Timely griddedgross domestic product (GDP) data is a fundamental indicator in many applications. It is critical to characterize the complex relationship between GDP and its auxiliary information for accurately estimating gridded GDP. However, few knowledge is available about the performance of deep learning approaches for learning this complex relationship. This article develops a novel convolutional neural network based GDP downscaling approach (GDPnet) to transform the statistical GDP data into GDP grids by integrating various geospatial big data. An existing autoencoder-based downscaling approach (Resautonet) is employed to compare with GDPnet. The latest county-level GDP data of China and the multiple geospatial big data are adopted to generate the 1-km gridded GDP data in 2019. Due to the different related auxiliary data of each GDP sector, the two downscaling approaches are first separately built for each GDP sector and then the results are merged to the gridded total GDP data. Experimental results show that the two deep learning approaches had good predictive power with R-2 over 0.8, 0.9, and 0.92 for the three sectors tested by county-level GDP data. Meanwhile, the proposed GDPnet outperformed the existing Resautonet. The average R-2 of GDPnet was 0.034 higher than that of Resautonet in terms of county-level GDP test data. Furthermore, GDPnet had higher accuracy (R-2 = 0.739) than Resautonet (R-2 = 0.704) assessed by town-level GDP data. In addition, the proposed GDPnet is faster (about 78&#37; running time) than the Resautonet. Hence, the proposed approach provides a valuable option for generating gridded GDP data.
WOS:000761219000002
</snippet>
</document>

<document id="41">
<title>A CNN approach to simultaneously count plants and detect plantation-rows from UAV imagery</title>
<url>http://dx.doi.org/10.1016/j.isprsjprs.2021.01.024</url>
<snippet>Accurately mapping croplands is an important prerequisite for precision farming since it assists in field management, yield-prediction, and environmental management. Crops are sensitive to planting patterns and some have a limited capacity to compensate for gaps within a row. Optical imaging with sensors mounted on Unmanned Aerial Vehicles (UAV) is a cost-effective option for capturing images covering croplands nowadays. However, visual inspection of such images can be a challenging and biased task, specifically for detecting plants and rows on a one-step basis. Thus, developing an architecture capable of simultaneously extracting plant individually and plantation-rows from UAV-images is yet an important demand to support the management of agricultural systems. In this paper, we propose a novel deep learning method based on a Convolutional Neural Network (CNN) that simultaneously detects and geolocates plantation-rows while counting its plants considering highly-dense plantation configurations. The experimental setup was evaluated in (a) a cornfield (Zea mays L.) with different growth stages (i.e. recently planted and mature plants) and in a (b) Citrus orchard (Citrus Sinensis Pera). Both datasets characterize different plant density scenarios, in different locations, with different types of crops, and from different sensors and dates. This scheme was used to prove the robustness of the proposed approach, allowing a broader discussion of the method. A two-branch architecture was implemented in our CNN method, where the information obtained within the plantation-row is updated into the plant detection branch and retro-feed to the row branch; which are then refined by a Multi-Stage Refinement method. In the corn plantation datasets (with both growth phases - young and mature), our approach returned a mean absolute error (MAE) of 6.224 plants per image patch, a mean relative error (MRE) of 0.1038, precision and recall values of 0.856, and 0.905, respectively, and an F-measure equal to 0.876. These results were superior to the results from other deep networks (HRNet, Faster R-CNN, and RetinaNet) evaluated with the same task and dataset. For the plantation-row detection, our approach returned precision, recall, and F-measure scores of 0.913, 0.941, and 0.925, respectively. To test the robustness of our model with a different type of agriculture, we performed the same task in the citrus orchard dataset. It returned an MAE equal to 1.409 citrus-trees per patch, MRE of 0.0615, precision of 0.922, recall of 0.911, and F-measure of 0.965. For the citrus plantation-row detection, our approach resulted in precision, recall, and F-measure scores equal to 0.965, 0.970, and 0.964, respectively. The proposed method achieved state-of-the-art performance for counting and geolocating plants and plant-rows in UAV images from different types of crops. The method proposed here may be applied to future decision-making models and could contribute to the sustainable management of agricultural systems.
WOS:000640987800001
</snippet>
</document>

<document id="42">
<title>Digital mapping of soil texture classes using Random Forest classification algorithm</title>
<url>http://dx.doi.org/10.1111/sum.12668</url>
<snippet>Soil texture is the most important soil physical property that determines water holding capacity, nutrient availability and crop growth. Spatial distribution of soil texture at a higher spatial resolution at regional and national level is essential for crop planning and management. In the present study, we mapped the soil textural classes over 16.2 M ha area of Andhra Pradesh state, India, at 250 m spatial resolution up to 2 m depth using the digital soil mapping approach. A total of 2,272 profile observations were used for the prediction of soil textural classes using the Random Forest (RF) classification algorithm. To estimate textural classes at six standard soil depth intervals (0-5, 5-15, 15-30, 30-60, 60-100 and 100-200 cm), we used continuous depth function of texture distribution using average sand, silt and clay content of different textural classes. Depth-wise spline outputs were then transformed into textural classes as per USDA textural classification. Sixteen environmental variables including Landsat-8 data, digital elevation model attributes and climatic variables were used for modelling. For model building, 75&#37; of data was used and 25&#37; of data was used for validation. Overall classification accuracy index and kappa index were calculated for validation data sets using 100 RF models. We recorded overall accuracy of 50&#37;-65&#37; and kappa index of 35&#37;-47&#37; for various depths. We found that equal-area quadratic splines of average sand, silt and clay are useful for soil profile depth harmonization of soil textural classes and random forest classification algorithm is a promising tool for spatial prediction of texture classes at the regional level. The present high-resolution (250 m) maps of soil texture classes are useful for different hydrological studies and preparation of proper land-use plans.
WOS:000585937200001
</snippet>
</document>

<document id="43">
<title>Mapping Potential Plant Species Richness over Large Areas with Deep Learning, MODIS, and Species Distribution Models</title>
<url>http://dx.doi.org/10.3390/rs13132490</url>
<snippet>The spatial patterns of species richness can be used as indicators for conservation and restoration, but data problems, including the lack of species surveys and geographical data gaps, are obstacles to mapping species richness across large areas. Lack of species data can be overcome with remote sensing because it covers extended geographic areas and generates recurring data. We developed a Deep Learning (DL) framework using Moderate Resolution Imaging Spectroradiometer (MODIS) products and modeled potential species richness by stacking species distribution models (S-SDMs) to ask, "What are the spatial patterns of potential plant species richness across the Korean Peninsula, including inaccessible North Korea, where survey data are limited?" First, we estimated plant species richness in South Korea by combining the probability-based SDM results of 1574 species and used independent plant surveys to validate our potential species richness maps. Next, DL-based species richness models were fitted to the species richness results in South Korea, and a time-series of the normalized difference vegetation index (NDVI) and leaf area index (LAI) from MODIS. The individually developed models from South Korea were statistically tested using datasets that were not used in model training and obtained high accuracy outcomes (0.98, Pearson correlation). Finally, the proposed models were combined to estimate the richness patterns across the Korean Peninsula at a higher spatial resolution than the species survey data. From the statistical feature importance tests overall, growing season NDVI-related features were more important than LAI features for quantifying biodiversity from remote sensing time-series data.
WOS:000671056500001
</snippet>
</document>

<document id="44">
<title>Deep-learning-based single-image height reconstruction from very-high-resolution SAR intensity data</title>
<url>http://dx.doi.org/10.1016/j.isprsjprs.2021.11.012</url>
<snippet>Originally developed in fields such as robotics and autonomous driving with image-based navigation in mind, deep learning-based single-image depth estimation (SIDE) has found great interest in the wider image analysis community. Remote sensing is no exception, as the possibility to estimate height maps from single aerial or satellite imagery bears great potential in the context of topographic reconstruction. A few pioneering investigations have demonstrated the general feasibility of single image height prediction from optical remote sensing images and motivate further studies in that direction. With this paper, we present the first-ever demonstration of deep learning-based single image height prediction for the other important sensor modality in remote sensing: synthetic aperture radar (SAR) data. Besides the adaptation of a convolutional neural network (CNN) architecture for SAR intensity images, we present a workflow for the generation of training data, and extensive experimental results for different SAR imaging modes and test sites. Since we put a particular emphasis on transferability, we are able to confirm that deep learning-based single-image height estimation is not only possible, but also transfers quite well to unseen data, even if acquired by different imaging modes and imaging parameters.
WOS:000782587600002
</snippet>
</document>

<document id="45">
<title>Digital Soil Mapping of Soil Organic Matter with Deep Learning Algorithms</title>
<url>http://dx.doi.org/10.3390/ijgi11050299</url>
<snippet>Digital soil mapping has emerged as a new method to describe the spatial distribution of soils economically and efficiently. In this study, a lightweight soil organic matter (SOM) mapping method based on a deep residual network, which we call LSM-ResNet, is proposed to make accurate predictions with background covariates. ResNet not only integrates spatial background information around the observed environmental covariates, but also reduces problems such as information loss, which undermines the integrity of information and reduces prediction uncertainty. To train the model, rectified linear units, mean squared error, and adaptive momentum estimation were used as the activation function, loss/cost function, and optimizer, respectively. The method was tested with Landsat5, the meteorological data from WorldClim, and the 1602 sampling points set from Xinxiang, China. The performance of the proposed LSM-ResNet was compared to a traditional machine learning algorithm, the random forest (RF) algorithm, and a training set (80&#37;) and a test set (20&#37;) were created to test both models. The results showed that the LSM-ResNet (RMSE = 6.40, R-2 = 0.51) model outperformed the RF model in both the roots mean square error (RMSE) and coefficient of determination (R-2), and the training accuracy was significantly improved compared to RF (RMSE = 6.81, R-2 = 0.46). The trained LSM-ResNet model was used for SOM prediction in Xinxiang, a district of plain terrain in China. The prediction maps can be deemed an accurate reflection of the spatial variability of the SOM distribution.
WOS:000801768200001
</snippet>
</document>

<document id="46">
<title>Characterizing Forest Cover and Landscape Pattern Using Multi-Source Remote Sensing Data with Ensemble Learning</title>
<url>http://dx.doi.org/10.3390/rs14215470</url>
<snippet>Accurate information on forest distribution is an essential basis for the protection of forest resources. Recent advances in remote sensing and machine learning have contributed to the monitoring of forest-cover distribution cost-effectively, but reliable methods for rapid forest-cover mapping over mountainous areas are still lacking. In addition, the forest landscape pattern has proven to be closely related to the functioning of forest ecosystems, yet few studies have explicitly measured the forest landscape pattern or revealed its driving forces in mountainous areas. To address these challenges, we developed a framework for forest-cover mapping with multi-source remote sensing data (Sentinel-1, Sentinel-2) and an automated ensemble learning method. We also designed a scheme for forest landscape pattern evaluation and driver attribution based on landscape metrics and random forest regression. Results in the Qilian Mountains showed that the proposed framework and scheme could accurately depict the distribution and pattern of forest cover. The overall accuracy of the obtained level-1 and level-2 forest-cover maps reached 95.49&#37; and 78.05&#37;, respectively. The multi-classifier comparison revealed that for forest classification, the ensemble learning method outperformed base classifiers such as LightGBM, random forests, CatBoost, XGBoost, and neural networks. Integrating multi-dimensional features, including spectral, phenological, topographic, and geographic information, helped distinguish forest cover. Compared with other land-cover products, our mapping results demonstrated high quality and rich spatial details. Furthermore, we found that forest patches in the Qilian Mountains were concentrated in the eastern regions with low-to-medium elevations and shady aspects. We also identified that climate was the critical environmental determent of the forest landscape pattern in the Qilian Mountains. Overall, the proposed framework and scheme have strong application potential for characterizing forest cover and landscape patterns. The mapping and evaluation results can further support forest resource management, ecological assessment, and regional sustainable development.
WOS:000882805300001
</snippet>
</document>

<document id="47">
<title>A recognition method for drainage patterns using a graph convolutional network</title>
<url>http://dx.doi.org/10.1016/j.jag.2022.102696</url>
<snippet>Drainage pattern recognition (DPR) is a classic and challenging problem in hydrographic system analysis, topographical knowledge mining, and map generalization. An outstanding issue for traditional DPR methods is that the rules used to extract patterns based on certain geometric measures are limited, not accessing the effects of manual recognition. In this study, a graph convolutional network (GCN) was introduced for DPR. First, a dual graph of drainage was built based on the channel connection and hierarchical structure after constructing typical sample data. Second, its features were extracted as inputs of the GCN from three scales, namely, global unity at a macroscale, hierarchical connectivity at a mesoscale, and local equilibrium at a microscale. Finally, the model architecture based on the GCN was designed for DPR. Typical pattern samples (i.e. dendritic, distributary, parallel, skeleton, and rectangular drainage) from OpenStreetMap and USGS were used to implement the training and testing of the model, respectively. The results show that our approach outperforms other machine learning methods, including convolutional neural network, with an accuracy of 85.0&#37;. In summary, the GCN has considerable potential for DPR and a wide scope for further improvement.
WOS:000765058700002
</snippet>
</document>

<document id="48">
<title>An Improved Segmentation Method for Automatic Mapping of Cone Karst from Remote Sensing Data Based on DeepLab V3+Model</title>
<url>http://dx.doi.org/10.3390/rs13030441</url>
<snippet>The South China Karst, a United Nations Educational, Scientific and Cultural Organization (UNESCO) natural heritage site, is one of the worlds most spectacular examples of humid tropical to subtropical karst landscapes. The Libo cone karst in the southern Guizhou Province is considered as the world reference site for these types of karst, forming a distinctive and beautiful landscape. Geomorphic information and spatial distribution of cone karst is essential for conservation and management for Libo heritage site. In this study, a deep learning (DL) method based on DeepLab V3+ network was proposed to document the cone karst landscape in Libo by multi-source data, including optical remote sensing images and digital elevation model (DEM) data. The training samples were generated by using Landsat remote sensing images and their combination with satellite derived DEM data. Each group of training dataset contains 898 samples. The input module of DeepLab V3+ network was improved to accept four-channel input data, i.e., combination of Landsat RGB images and DEM data. Our results suggest that the mean intersection over union (MIoU) using the four-channel data as training samples by a new DL-based pixel-level image segmentation approach is the highest, which can reach 95.5&#37;. The proposed method can accomplish automatic extraction of cone karst landscape by self-learning of deep neural network, and therefore it can also provide a powerful and automatic tool for documenting other type of geological landscapes worldwide.
WOS:000615468100001
</snippet>
</document>

<document id="49">
<title>Marine aquaculture mapping using GF-1 WFV satellite images and full resolution cascade convolutional neural network</title>
<url>http://dx.doi.org/10.1080/17538947.2022.2133184</url>
<snippet>Growing demand for seafood and reduced fishery harvests have raised intensive farming of marine aquaculture in coastal regions, which may cause severe coastal water problems without adequate environmental management. Effective mapping of mariculture areas is essential for the protection of coastal environments. However, due to the limited spatial coverage and complex structures, it is still challenging for traditional methods to accurately extract mariculture areas from medium spatial resolution (MSR) images. To solve this problem, we propose to use the full resolution cascade convolutional neural network (FRCNet), which maintains effective features over the whole training process, to identify mariculture areas from MSR images. Specifically, the FRCNet uses a sequential full resolution neural network as the first-level subnetwork, and gradually aggregates higher-level subnetworks in a cascade way. Meanwhile, we perform a repeated fusion strategy so that features can receive information from different subnetworks simultaneously, leading to rich and representative features. As a result, FRCNet can effectively recognize different kinds of mariculture areas from MSR images. Results show that FRCNet obtained better performance than other classical and recently proposed methods. Our developed methods can provide valuable datasets for large-scale and intelligent modeling of the marine aquaculture management and coastal zone planning.
WOS:000891824900001
</snippet>
</document>

<document id="50">
<title>Application of a two-step sampling strategy based on deep neural network for landslide susceptibility mapping</title>
<url>http://dx.doi.org/10.1007/s10064-022-02615-0</url>
<snippet>The selection of nonlandslide samples is a key issue in landslide susceptibility modeling (LSM). In view of the potential subjectivity and randomness in random sampling, this paper considers LSM as a positive-unlabeled (PU) learning problem and proposes a two-step deep neural network framework (T-DNN). Through the Spy technique and iteratively training binary classifiers, negative samples with high confidence were identified from the random subsamples with unlabeled sets. Based on the framework and traditional random sampling, we used logistic regression (LR), support vector machine (SVM), and deep neural network (DNN) models for testing and validation. Taking the Changbai Mountain Area in Jilin Province, China, as an example, according to the regional landslide list and the metrological, geographical, and human factors of frequent disasters, landslide susceptibility was evaluated. Results show that the proposed T-DNN method can enhance the selection of negative samples and make the results of landslide susceptibility assessment more reliable and accurate; the area under the receiver operating characteristic curve (AUC) reaches 0.953. In addition, compared with traditional random negative sample sampling, the optimized sample set shows more stable and superior prediction performance in different classifiers.
WOS:000768826600003
</snippet>
</document>

<document id="51">
<title>Interband Retrieval and Classification Using the Multilabeled Sentinel-2 BigEarthNet Archive</title>
<url>http://dx.doi.org/10.1109/JSTARS.2021.3112209</url>
<snippet>Conventional remote sensing data analysistechniques have a significant bottleneck of operating on a selectively chosen small-scale dataset. Availability of an enormous volume of data demands handling large-scale, diverse data, which have been made possible with neural network-based architectures. This article exploits the contextual information capturing ability of deep neural networks, particularly investigating multispectral band properties from Sentinel-2 image patches. Besides, an increase in the spatial resolution often leads to nonlinear mixing of land-cover types within a target resolution cell. We recognize this fact and group the bands according to their spatial resolutions, and propose a classification and retrieval framework. We design a representation learning framework for classifying the multispectral data by first utilizing all the bands and then using the grouped bands according to their spatial resolutions. We also propose a novel triplet-loss function for multilabeled images and use it to design an interband group retrieval framework. We demonstrate its effectiveness over the conventional triplet-loss function. Finally, we present a comprehensive discussion of the obtained results. We thoroughly analyze the performance of the band groups on various land-cover and land-use areas from agro-forestry regions, water bodies, and human-made structures. Experimental results for the classification and retrieval framework on the benchmarked BigEarthNet dataset exhibit marked improvements over existing studies.
WOS:000709074200001
</snippet>
</document>

<document id="52">
<title>Graph Neural Network based Short-term Solar Irradiance Forcasting Model Considering Surrounding Meteorological Factors</title>
<url>http://dx.doi.org/10.1109/ICPS54075.2022.9773879</url>
<snippet>Accurate short-term solar irradiance forecasting can achieve precise solar photovoltaic (PV) power forecasting and ensure the safe and stable operation of power grid. However, the existing solar irradiance forecasting methods only based on the historical power data and meteorological information of the local PV power station itself, which is difficult to obtain sufficiently accurate forecasting results. In this paper, we propose a short-term irradiance forecasting model based on Graph Neural Network (GNN) considering surrounding meteorological factors to further improve the accuracy. Firstly, the spatio-temporal correlation stations are constructed according to geographical location and meteorological information, and simulate the spatio-temporal correlation data around the target station by utilizing the satellite image-irradiance mapping model. Secondly, based on the complex network theory, a new index is proposed to evaluate the connectivity of the graph structure, which improves the predictive ability of the GNN model. Finally, the spatio-temporal correlation around the target site is mined through GNN model to achieve the short-term irradiance forecasting. The results show that the proposed method further improves the forecasting accuracy compared with models that don't consider surrounding meteorological factors. The reliability of the graph connectivity is directly proportional to the forecasting accuracy, which verifies the effectiveness of the proposed index.
WOS:000838714500028
</snippet>
</document>

<document id="53">
<title>Landslide Detection Using Densely Connected Convolutional Networks and Environmental Conditions</title>
<url>http://dx.doi.org/10.1109/JSTARS.2021.3079196</url>
<snippet>A complete and accurate landslide map is necessary for landslide susceptibility and risk assessment. Currently, deep learning faces the dilemma of insufficient application, scarce samples, and poor efficiency in landslide recognition. This article utilizes the advantages of dense convolutional networks (DenseNets) and their modified technique to solve the three proposed problems. For this purpose, we created a new landslide sample library. On the original remote sensing image, 12 geological, topographic, hydrological and land cover factors that can directly or indirectly reflect the landslide are superimposed. Then, landslide detection was carried out in the three Gorges reservoir area in China to test the performance of the improved method. The quantitative evaluation of the landslide detection map shows that the combination of environmental factors and DenseNet can improve the accuracy of the detection model. Compared with the optical image, kappa and F1 increased by 9.7&#37; and 9.1&#37; respectively. Compared with other traditional neural networks and machine learning algorithms, DenseNet has the highest kappa and F1 values. Based on the base Densenet, through data augmentation and fine-tuning optimization technology, the kappa and F1 values reach the highest values of 0.9474 and 0.9505, respectively. The proposed method has promising applicability in large area landslide identification scenarios.
WOS:000658340600008
</snippet>
</document>

<document id="54">
<title>A CNN-LSTM Model for Soil Organic Carbon Content Prediction with Long Time Series of MODIS-Based Phenological Variables</title>
<url>http://dx.doi.org/10.3390/rs14184441</url>
<snippet>The spatial distribution of soil organic carbon (SOC) serves as critical geographic information for assessing ecosystem services, climate change mitigation, and optimal agriculture management. Digital mapping of SOC is challenging due to the complex relationships between the soil and its environment. Except for the well-known terrain and climate environmental covariates, vegetation that interacts with soils influences SOC significantly over long periods. Although several remote-sensing-based vegetation indices have been widely adopted in digital soil mapping, variables indicating long term vegetation growth have been less used. Vegetation phenology, an indicator of vegetation growth characteristics, can be used as a potential time series environmental covariate for SOC prediction. A CNN-LSTM model was developed for SOC prediction with inputs of static and dynamic environmental variables in Xuancheng City, China. The spatially contextual features in static variables (e.g., topographic variables) were extracted by the convolutional neural network (CNN), while the temporal features in dynamic variables (e.g., vegetation phenology over a long period of time) were extracted by a long short-term memory (LSTM) network. The ten-year phenological variables derived from moderate-resolution imaging spectroradiometer (MODIS) observations were adopted as predictors with historical temporal changes in vegetation in addition to the commonly used static variables. The random forest (RF) model was used as a reference model for comparison. Our results indicate that adding phenological variables can produce a more accurate map, as tested by the five-fold cross-validation, and demonstrate that CNN-LSTM is a potentially effective model for predicting SOC at a regional spatial scale with long-term historical vegetation phenology information as an extra input. We highlight the great potential of hybrid deep learning models, which can simultaneously extract spatial and temporal features from different types of environmental variables, for future applications in digital soil mapping.
WOS:000856760700001
</snippet>
</document>

<document id="55">
<title>Global distribution and drivers of forest biome foliar nitrogen to phosphorus ratios (N:P)</title>
<url>http://dx.doi.org/10.1111/geb.13457</url>
<snippet>Aim The aim was to create global maps of foliar nitrogen-to-phosphorus (N:P) ratios across ecosystems, based on modelled climate, soil, and N and P deposition data, to identify global drivers of woody vegetation N:P ratios and to explore the role of genetic legacy (phylogenetics) in foliar N:P ratios of woody plants. Location Woody cover globally. Time period Present; data collected from 1990 to 2016. Major taxa studied Woody plants. Methods We compiled a database of 20,851 foliar N:P records and assigned them into boreal, temperate coniferous, temperate broadleaved and tropical groups. We applied neural networks to predict N:P global distribution maps, generalized linear models to assess environmental drivers and generalized linear mixed models to disentangle the effect of genetic legacy. Results and main conclusions Foliar N:P ratios are negatively associated with latitude, with higher N:P ratios occurring in tropical forests and lower N:P ratios in boreal forests. Globally, N:P ratios indicate greater levels of P limitation than N limitation. The influence of environmental factors varied among the four forest biomes, probably owing to contrasting combined environmental conditions; this finding would have been obscured had we conducted a single "forest biome" analysis. Genetic legacy explained significant variation in woody plant foliar N:P ratios, and we suggest its inclusion in future studies to improve N:P ratio predictions.
WOS:000768382400001
</snippet>
</document>

<document id="56">
<title>A new attention-based CNN approach for crop mapping using time series Sentinel-2 images</title>
<url>http://dx.doi.org/10.1016/j.compag.2021.106090</url>
<snippet>Accurate crop mapping is of great importance for agricultural applications, and deep learning methods have been applied on multi-temporal remotely sensed images to classify crops. However, due to the geographic heterogeneity, the spectral profiles of the same crop can vary spatially, and thus using the spectral features alone can limit the model performance in mapping crops in large scales. Moreover, it is a challenge for traditional deep learning models to accurately capture the important information from a large number of features. To address these issues, in this study, we developed a novel attention-based convolutional neural network (CNN) approach (Geo-CBAM-CNN) for crop classification using time series Sentinel-2 images. Specifically, geographic information of crops was first integrated into an advanced attention module, Convolutional Block Attention Module (CBAM) to form a Geo-CBAM module which can help mitigate the impacts of geographic heterogeneity and restrain unnecessary information. Then, the developed Geo-CBAM module was embedded into a CNN model to boost the model?s attention both spectrally and spatially. The proposed Geo-CBAM-CNN model was validated on four main crops over six counties with different geographic environments in the U.S. Also, it was compared to three other state-of-the-art machine learning approaches, including CBAM-CNN, CNN and Random Forest (RF). The results showed that the proposed model achieved the best performance, reaching 97.82&#37; overall accuracy, 96.82&#37; Kappa coefficient and 96.96&#37; Macro-average F1 score. Moreover, the developed Geo-CBAM-CNN model showed strong spatial adaptability, indicating its superior performance in large scale applications. Furthermore, by visualizing the structure of the Geo-CBAM-CNN, we found that the model automatically allocated different weights to the features, and generally, the red-edge features in the middle of the year obtained more attention.
WOS:000641351000001
</snippet>
</document>

<document id="57">
<title>Deep Learning Based Land Cover and Crop Type Classification: A Comparative Study</title>
<url>http://dx.doi.org/10.1109/ICoDT252288.2021.9441483</url>
<snippet>Remote sensing data is available free of cost with an ever-increase in the number of satellites. This satellite imagery can be used as raw input from which cultivated/non-cultivated and crop fields can be mapped. Previous trends included the use of traditional ML techniques and standard CNN, RNN for such mappings. In this paper, we investigate the segmentation models for the task of Landcover and Crop type Classification. We investigate the UNet, SegNet, and DeepLabv3+ in the data-rich states of Nebraska, Mid-West, United States. We acquire dataset from Cropland data Layer provided by USDA National Agricultural Statistics Service. Our Experimental results show that cultivated and non-cultivated landcover is classified with an accuracy of 90&#37; and crop types are classified around 70&#37; ensuring the models trained on one geographical area can be used for accurate classification in other geographical areas, which makes it more reliable for real-time application in agricultural business. [GitHub]
WOS:000760235700011
</snippet>
</document>

<document id="58">
<title>Instance GNN: A Learning Framework for Joint Symbol Segmentation and Recognition in Online Handwritten Diagrams</title>
<url>http://dx.doi.org/10.1109/TMM.2021.3087000</url>
<snippet>Online handwritten diagram recognition (OHDR) has attracted considerable attention for its potential applications in many areas, but it is a challenging task due to the complex 2D structure, writing style variation, and lack of annotated data. Existing OHDR methods often have limitations in modeling and learning complex contextual relationships. To overcome these challenges, we propose an OHDR method based on graph neural networks (GNNs) in this paper. In particular, we formulate symbol segmentation and symbol recognition as node clustering and node classification problems on stroke graphs and solve the problems jointly under a unified learning framework with a GNN model. This GNN model is denoted as Instance GNN since it gives the symbol instance label as well as the semantic label. Extensive experiments on two flowchart datasets and a finite automata dataset show that our method consistently outperforms previous methods with large margins and achieves state-of-the-art performance. In addition, we release a large-scale annotated online handwritten flowchart dataset, CASIA-OHFC, and provide initial experimental results as a baseline.
WOS:000793839600026
</snippet>
</document>

<document id="59">
<title>Interpretation of Convolutional Neural Networks for Acid Sulfate Soil Classification</title>
<url>http://dx.doi.org/10.3389/fenvs.2021.809995</url>
<snippet>Convolutional neural networks (CNNs) have been originally used for computer vision tasks, such as image classification. While several digital soil mapping studies have been assessing these deep learning algorithms for the prediction of soil properties, their potential for soil classification has not been explored yet. Moreover, the use of deep learning and neural networks in general has often raised concerns because of their presumed low interpretability (i.e., the black box pitfall). However, a recent and fast-developing sub-field of Artificial Intelligence (AI) called explainable AI (XAI) aims to clarify complex models such as CNNs in a systematic and interpretable manner. For example, it is possible to apply model-agnostic interpretation methods to extract interpretations from any machine learning model. In particular, SHAP (SHapley Additive exPlanations) is a method to explain individual predictions: SHAP values represent the contribution of a covariate to the final model predictions. The present study aimed at, first, evaluating the use of CNNs for the classification of potential acid sulfate soils located in the wetland areas of Jutland, Denmark (c. 6,500 km(2)), and second and most importantly, applying a model-agnostic interpretation method on the resulting CNN model. About 5,900 soil observations and 14 environmental covariates, including a digital elevation model and derived terrain attributes, were utilized as input data. The selected CNN model yielded slightly higher prediction accuracy than the random forest models which were using original or scaled covariates. These results can be explained by the use of a common variable selection method, namely recursive feature elimination, which was based on random forest and thus optimized the selection for this method. Notably, the SHAP method results enabled to clarify the CNN model predictions, in particular through the spatial interpretation of the most important covariates, which constitutes a crucial development for digital soil mapping.
WOS:000749777000001
</snippet>
</document>

<document id="60">
<title>A New Method to Evaluate Gold Mineralisation-Potential Mapping Using Deep Learning and an Explainable Artificial Intelligence (XAI) Model</title>
<url>http://dx.doi.org/10.3390/rs14184486</url>
<snippet>Geoscientists have extensively used machine learning for geological mapping and exploring the mineral prospect of a province. However, the interpretation of results becomes challenging due to the complexity of machine learning models. This study uses a convolutional neural network (CNN) and Shapley additive explanation (SHAP) to estimate potential locations for gold mineralisation in Rengali Province, a tectonised mosaic of volcano-sedimentary sequences juxtaposed at the interface of the Archaean cratonic segment in the north and the Proterozoic granulite provinces of the Eastern Ghats Belt in Eastern India. The objective is to integrate multi-thematic data involving geological, geophysical, mineralogical and geochemical surveys on a 1:50 K scale with the aim of prognosticating gold mineralisation. The available data utilised during the integration include aero-geophysical (aeromagnetic and aerospectrometric), geochemical (national geochemical mapping), ground geophysical (gravity), satellite gravity, remote sensing (multispectral) and National Geomorphology and Lineament Project structural lineament maps obtained from the Geological Survey of India Database. The CNN model has an overall accuracy of 90&#37;. The SHAP values demonstrate that the major contributing factors are, in sequential order, antimony, clay, lead, arsenic content and a magnetic anomaly in CNN modelling. Geochemical pathfinders, including geophysical factors, have high importance, followed by the shear zones in mineralisation mapping. According to the results, the central parts of the study area, including the river valley, have higher gold prospects than the surrounding areas. Gold mineralisation is possibly associated with intermediate metavolcanics along the shear zone, which is later intruded by quartz veins in the northern part of the Rengali Province. This work intends to model known occurrences with respect to multiple themes so that the results can be replicated in surrounding areas.
WOS:000859069000001
</snippet>
</document>

<document id="61">
<title>Towards Scalable Within-Season Crop Mapping With Phenology Normalization and Deep Learning</title>
<url>http://dx.doi.org/10.1109/JSTARS.2023.3237500</url>
<snippet>Crop-type mapping using time-series remote sensing data is crucial for a wide range of agricultural applications. Crop mapping during the growing season is particularly critical in timely monitoring of the agricultural system. Most existing studies focusing on within-season crop mapping leverage historical remote sensing and crop type reference data for model building, due to the difficulty in obtaining timely crop type samples for the current growing season. Yet the crop type samples from previous years may not be used directly considering the diverse patterns of crop phenology across years and locations, which hampers the scalability and transferability of the model to the current season for timely crop mapping. This article proposes an innovative within-season emergence (WISE) phenology normalized deep learning model towards scalable within-season crop mapping. The crop time-series remote sensing data are first normalized by the WISE crop emergence dates before being fed into an attention-based one-dimensional convolutional neural network classifier. Compared to conventional calendar-based approaches, the WISE-phenology normalization approach substantially helps the deep learning crop mapping model accommodate the spatiotemporal variations in crop phenological dynamics. Results in Illinois from 2017 to 2020 indicate that the proposed model outperforms calendar-based approaches and yields over 90&#37; overall accuracy for classifying corn and soybeans at the end of season. During the growing season, the proposed model can give satisfactory performance (85&#37; overall accuracy) one to four weeks earlier than calendar-based approaches. With WISE-phenology normalization, the proposed model exhibits more stable performance across Illinois and can be transferred to different years with enhanced scalability and robustness.
WOS:000923811200005
</snippet>
</document>

<document id="62">
<title>Deep Learning in Forest Structural Parameter Estimation Using Airborne LiDAR Data</title>
<url>http://dx.doi.org/10.1109/JSTARS.2020.3046053</url>
<snippet>Accurately estimating and mapping forest structural parameters are essential for monitoring forest resources and understanding ecological processes. The novel deep learning algorithm has the potential to be a promising approach to improve the estimation accuracy while combining with advanced remote sensing technology. Airborne light detection and ranging (LiDAR) has the preferable capability to characterize 3-D canopy structure and estimate forest structural parameters. In this study, we developed a deep learning-based algorithm (Deep-RBN) that combined the fully connected network (FCN) deep learning algorithm with the optimized radial basis neural network (RBN) algorithm for forest structural parameter estimation using airborne LiDAR data. The multiple iterations were used to constantly update the internal weights to achieve the optimized accuracy of model fitting, and the optimized RBN algorithm was developed for the limited training sets. We assessed the efficiency and capability of the Deep-RBN in the estimation of forest structural parameters in a subtropical planted forest of southern China, by comparing the traditional FCN algorithm and multiple linear regression. We found that Deep-RBN had the strongest capability in estimates of forest structural parameters (R-2 = 0.67-0.86, rRMSE = 6.95&#37;-20.34&#37;). The sensitivity analysis of the key hyperparameters of Deep-RBN algorithm showed that the learning rate is one of the most important parameters that influence the performance of predictive models, and while its value equal is to 0.001, the predictive models had the highest accuracy (mean DBH: RMSE = 1.01, mean height: RMSE = 1.45, volume: RMSE = 26.49, stem density: RMSE = 121.06). With the increase of training samples added in Deep-RBN model, the predictive models performed better; however, no significant improvements of accuracy were observed while the number of training set is larger than 80. This study demonstrates the benefits of jointly using the Deep-RBN algorithm and airborne LiDAR data to improve the accuracy of forest structural parameter estimation and mapping, which provides a promising methodology for sustainable forest resources monitoring.
WOS:000607810600013
</snippet>
</document>

<document id="63">
<title>Modelling soil organic carbon stock distribution across different land-uses in South Africa: A remote sensing and deep learning approach</title>
<url>http://dx.doi.org/10.1016/j.isprsjprs.2022.04.026</url>
<snippet>Soil organic carbon (SOC) is a critical measure for ecosystem health and offers opportunities to understand carbon fluxes and associated implications. However, SOC can be significantly influenced by anthropogenic land use change, with intensive and extensive disturbances resulting in considerable SOC loss. Consequently, understanding the spatial distribution of SOC across different land uses, particularly at national level characterised by different biomes, is vital for integrated land-use planning and climate change mitigation. Remote sensing and deep learning (DL) offer a reliable largescale mapping of SOC by leveraging on their big data provision and powerful analytical prowess, respectively. This study modelled SOC stocks across South Africas major land uses using Deep Neural Networks (DNN) and Sentinel-3 satellite data. Based on 1936 soil samples and 31 spectral predictors, results show a relatively high accuracy with an R-2 and RMSE value of 0.685 and 10.15 t/h (26&#37; of the mean), respectively. From the seven land uses evaluated, grasslands (31.36&#37;) contributed the most to the overall SOC stocks while urban vegetation (0.04&#37;) contributed the least. Moreover, although SOC stock was found to be relatively proportional to land coverage, commercial (46.06 t/h) and natural (44.34 t/h) forests showed a higher carbon sequestration capacity. These findings provide an important guideline to managing SOC stocks in South Africa, useful in climate change mitigation through sustainable land-use practices. Whereas landscape restoration, and other relevant interventions are encouraged to improve SOC storage, care must be taken within land use decision making to maintain an appropriate balance between carbon sequestration, biodiversity, and general ecosystem functions.
WOS:000799679800001
</snippet>
</document>

<document id="64">
<title>A Mountain Summit Recognition Method Based on Improved Faster R-CNN</title>
<url>http://dx.doi.org/10.1155/2021/8235108</url>
<snippet>Mountain summits are vital topographic feature points, which are essential for understanding landform processes and their impacts on the environment and ecosystem. Traditional summit detection methods operate on handcrafted features extracted from digital elevation model (DEM) data and apply parametric detection algorithms to locate mountain summits. However, these methods may no longer be effective to achieve desirable recognition results in small summits and suffer from the objective criterion lacking problem. Thus, to address these problems, we propose an improved Faster region-convolutional neural network (R-CNN) to accurately detect the mountain summits from DEM data. Based on Faster R-CNN, the improved network adopts a residual convolution block to replace the traditional part and adds a feature pyramid network (FPN) to fuse the features with adjacent layers to better address the mountain summit detection task. The residual convolution is employed to capture the deep correlation between visual and physical morphological features. The FPN is utilized to integrate the location and semantic information in the extracted feature maps to effectively represent the mountain summit area. The experimental results demonstrate that the proposed network could achieve the highest recall and precision without manually designed summit features and accurately identify small summits.
WOS:000687467200002
</snippet>
</document>

<document id="65">
<title>Digital Mapping of Soil Organic Carbon Based on Machine Learning and Regression Kriging</title>
<url>http://dx.doi.org/10.3390/s22228997</url>
<snippet>In the last two decades, machine learning (ML) methods have been widely used in digital soil mapping (DSM), but the regression kriging (RK) model which combines the advantages of the ML and kriging methods has rarely been used in DSM. In addition, due to the limitation of a single-model structure, many ML methods have poor prediction accuracy in undulating terrain areas. In this study, we collected the SOC content of 115 soil samples in a hilly farming area with continuous undulating terrain. According to the theory of soil-forming factors in pedogenesis, we selected 10 topographic indices, 7 vegetation indices, and 2 soil indices as environmental covariates, and according to the law of geographical similarity, we used ML and RK methods to mine the relationship between SOC and environmental covariates to predict the SOC content. Four ensemble models-random forest (RF), Cubist, stochastic gradient boosting (SGB), and Bayesian regularized neural networks (BRNNs)-were used to fit the trend of SOC content, and the simple kriging (SK) method was used to interpolate the residuals of the ensemble models, and then the SOC and residual were superimposed to obtain the RK prediction result. Moreover, the 115 samples were divided into calibration and validation sets at a ratio of 80&#37;, and the tenfold cross-validation method was used to fit the optimal parameters of the model. From the results of four ensemble models: RF performed best in the calibration set (R-c(2) = 0.834) but poorly in the validation set (R-v(2) = 0.362); Cubist had good accuracy and stability in both the calibration and validation sets (R-c(2) = 0.693 and R-v(2) = 0.445); SGB performed poorly (R-c(2) = 0.430 and R-v(2) = 0.336); and BRNN had the lowest accuracy (R-c(2) = 0.323 and R-v(2) = 0.282). The results showed that the R-2 of the four RK models in the validation set were 0.718, 0.674, 0.724, and 0.625, respectively. Compared with the ensemble models without superimposed residuals, the prediction accuracy was improved by 0.356, 0.229, 0.388, and 0.343, respectively. In conclusion, Cubist has high prediction accuracy and generalization ability in areas with complex topography, and the RK model can make full use of trends and spatial structural factors that are not easy to mine by ML models, which can effectively improve the prediction accuracy. This provides a reference for soil survey and digital mapping in complex terrain areas.
WOS:000887802800001
</snippet>
</document>

<document id="66">
<title>Deep Learning-Based Soil Moisture Retrieval in CONUS Using CYGNSS Delay-Doppler Maps</title>
<url>http://dx.doi.org/10.1109/JSTARS.2022.3196658</url>
<snippet>National Aeronautics and Space Administrations Cyclone Global Navigation Satellite System (CYGNSS) mission has gained significant attention within the land remote sensing community for estimating soil moisture (SM) by using the Global Navigation System Reflectometry (GNSS-R) technique. CYGNSS constellation generates Delay-Doppler Maps (DDMs), containing important Earth surface information from GNSS reflection measurements. Previous studies considered only designed features from CYGNSS DDM, whereas the whole DDM image is affected by SM, inundation, and vegetation. This paper presents a deep learning (DL) based framework for estimating SM in the Continental United States by leveraging spaceborne GNSS-R DDM observations provided by the CYGNSS constellation along with remotely sensed geophysical data. A data-driven approach utilizing convolutional neural networks (CNNs) is developed to determine complex relationships between the reflected measurements and surface parameters which can provide improved SM estimation. The model is trained jointly with three types of processed DDM images of analog power, effective scattering area, and bistatic radar cross-section with other auxiliary geophysical information such as elevation, soil properties, and vegetation water content (VWC). The model is trained and evaluated using the Soil Moisture Active Passive (SMAP) missions enhanced SM products at a 9 km resolution with VWC less than 5 kg/m(2). The mean unbiased root-mean-square difference between concurrent CYGNSS and SMAP SM retrievals from 2017 to 2020 is 0.0366 m(3)/m(3) with a correlation coefficient of 0.93 over fivefold cross-validation and 0.0333 m(3)/m(3) with a correlation coefficient of 0.94 over year-based cross-validation at spatial resolution of 9 km and temporal resolution similar to CYGNSS mission.
WOS:000848245900004
</snippet>
</document>

<document id="67">
<title>Review on remote sensing methods for landslide detection using machine and deep learning</title>
<url>http://dx.doi.org/10.1002/ett.3998</url>
<snippet>Landslide, one of the most critical natural hazards, is caused due to specific compositional slope movement. In the past decades, due to inflation of urbanized area and climate change, a compelling expansion in landslide prevalence took place which is also termed as mass/slope movement and mass wasting, causing extensive collapse around the world. The principal reason for its pursuance is a reduction in the internal resistance of soil and rocks, classified as a slide, topple, fall, and flow. Slopes can be differentiated based on earth material and the nature of its movements. The downward flow of landslides occurs due to excessive rainfall, snowmelt, earthquake, volcanic eruption, and so on. This review article revisits the conventional approaches for identification of landslides, predicting future risk, associated with slope failures, followed by emphasizing the advantages of modern geospatial techniques such as aerial photogrammetry, satellite remote sensing images (ie, panchromatic, multispectral, radar images), Terrestrial laser scanning, and High-Resolution Digital Elevation Model (HR-DEM) in updating landslide inventory maps. Machine learning techniques like Support Vector Machine, Artificial neural network, deep learning has been extensively used with geographical data producing effective results for assessment of natural hazard/resources and environmental research. Based on recent studies, deep learning is a reliable tool addressing remote sensing challenges such as trade-off in imaging system producing poor quality investigation, in addition, to expedite consequent task such as image recognition, object detection, classification, and so on. Conventional methods, like pixel and object-based machine learning methods, have been broadly explored. Advanced development in deep learning technique like CNN (Convolutional neural network) has been extensively successful in information extraction from an image and has exceeded other traditional approaches. Over the past few years, minor attempts have been made for landslide susceptibility mapping using CNN. In addition, small sample sizes for training purpose will be major drawback and notably remarkable while using deep learning techniques. Also, assessment of the models performance with diverse training and testing proportion other than commonly utilized ratio, that is, 70/30 needs to be explored further. The review article briefly highlights the remote sensing methods for landslide detection using machine learning and deep learning.
WOS:000542033600001
</snippet>
</document>

<document id="68">
<title>Extensibility of U-Net Neural Network Model for Hydrographic Feature Extraction and Implications for Hydrologic Modeling</title>
<url>http://dx.doi.org/10.3390/rs13122368</url>
<snippet>Accurate maps of regional surface water features are integral for advancing ecologic, atmospheric and land development studies. The only comprehensive surface water feature map of Alaska is the National Hydrography Dataset (NHD). NHD features are often digitized representations of historic topographic map blue lines and may be outdated. Here we test deep learning methods to automatically extract surface water features from airborne interferometric synthetic aperture radar (IfSAR) data to update and validate Alaska hydrographic databases. U-net artificial neural networks (ANN) and high-performance computing (HPC) are used for supervised hydrographic feature extraction within a study area comprised of 50 contiguous watersheds in Alaska. Surface water features derived from elevation through automated flow-routing and manual editing are used as training data. Model extensibility is tested with a series of 16 U-net models trained with increasing percentages of the study area, from about 3 to 35 percent. Hydrography is predicted by each of the models for all watersheds not used in training. Input raster layers are derived from digital terrain models, digital surface models, and intensity images from the IfSAR data. Results indicate about 15 percent of the study area is required to optimally train the ANN to extract hydrography when F1-scores for tested watersheds average between 66 and 68. Little benefit is gained by training beyond 15 percent of the study area. Fully connected hydrographic networks are generated for the U-net predictions using a novel approach that constrains a D-8 flow-routing approach to follow U-net predictions. This work demonstrates the ability of deep learning to derive surface water feature maps from complex terrain over a broad area.
WOS:000666342600001
</snippet>
</document>

<document id="69">
<title>Vegetation Coverage in the Desert Area of the Junggar Basin of Xinjiang, China, Based on Unmanned Aerial Vehicle Technology and Multisource Data</title>
<url>http://dx.doi.org/10.3390/rs14205146</url>
<snippet>Vegetation coverage information is an important indicator of desert ecological environments. Accurately grasping vegetation coverage changes in desert areas can help in assessing the quality of ecosystems and maintaining their functions. Improving remote sensing methods to detect the vegetation coverage in areas of low vegetation coverage is an important challenge for the remote sensing of vegetation in deserts. In this study, based on the fusion of MOD09GA and MOD09GQ data, 2019-2021 low-altitude unmanned aerial vehicle (UAV) remote sensing data, and other factors (such as geographical, topographic, and meteorological factors), three types of inversion models for vegetation coverage were constructed: a multivariate parametric regression model, a support vector machine (SVM) regression model, and a back-propagation neural network (BPNN) regression model. The optimal model was then used to map the spatial distribution of vegetation coverage and its dynamic change in the Junggar Basin of Xinjiang, China, over 22 years (from 2000 to 2021). The results show that: (1) The correlation between enhanced vegetation index (EVI) obtained from image fusion and vegetation coverage in desert areas is the highest (r = 0.72). (2) Among the geographical and topographic factors, only longitude and latitude were significantly correlated with vegetation coverage (p &lt; 0.05). The average monthly temperature and precipitation from the previous six months were correlated with the vegetation coverage (p &lt; 0.05), but the vegetation coverage of the current month had the highest correlation with the average temperature (r = -0.27) and precipitation (r = 0.33) of the previous month. (3) Among the multivariate parametric models established by selecting the five aforementioned factors, the multiple linear regression model performed the best (R-2 = 0.64). (4) The SVM regression model was superior to the other regression models (R-2 = 0.80, mean squared error = 8.35&#37;). (5) The average vegetation coverage in the desert area of the Junggar Basin was 7.36&#37;, and from 2000-2021, the vegetation coverage in 54.59&#37; of the desert area increased.
WOS:000873554200001
</snippet>
</document>

<document id="70">
<title>Predicting spatial distribution of soil organic carbon and total nitrogen in a typical human impacted area</title>
<url>http://dx.doi.org/10.1080/10106049.2021.1886344</url>
<snippet>The relationship between soil properties and environmental covariates is mostly nonlinear for human impacted areas. Herein, we proposed a nonlinear model for mapping soil organic carbon (SOC) and total nitrogen (TN) in a typical human impacted area (a small watershed of Poyang Lake, China), namely radial basis function neural network combined with agricultural land use (RBFNN_ALU). The results showed that the RBFNN_ALU performs better than the ordinary kriging (OK), the OK combined with agricultural land use (OK_ALU), the geographically weighted regression (GWR), the multiple linear regression (MLR), the MLR combined with agricultural land use (MLR_ALU) and the RBFNN. In addition, RBFNN_ALU provided a more detailed and accurate description of the spatial SOC and TN patterns. The results indicate that when predicting spatial distribution of SOC and TN for human impacted areas, non-linear models are critical for predicting the spatial distribution of soil properties.
WOS:000627736800001
</snippet>
</document>

<document id="71">
<title>A Scale Sequence Object-based Convolutional Neural Network (SS-OCNN) for crop classification from fine spatial resolution remotely sensed imagery</title>
<url>http://dx.doi.org/10.1080/17538947.2021.1950853</url>
<snippet>The highly dynamic nature of agro-ecosystems in space and time usually leads to high intra-class variance and low inter-class separability in the fine spatial resolution (FSR) remotely sensed imagery. This makes traditional classifiers essentially relying on spectral information for crop mapping from FSR imagery an extremely challenging task. To mine effectively the rich spectral and spatial information in FSR imagery, this paper proposed a Scale Sequence Object-based Convolutional Neural Network (SS-OCNN) that classifies images at the object level by taking segmented objects (crop parcels) as basic units of analysis, thus, ensuring that the boundaries between crop parcels are delineated precisely. These segmented objects were subsequently classified using a CNN model integrated with an automatically generated scale sequence of input patch sizes. This scale sequence can fuse effectively the features learned at different scales by transforming progressively the information extracted at small scales to larger scales. The effectiveness of the SS-OCNN was investigated using two heterogeneous agricultural areas with FSR SAR and optical imagery, respectively. Experimental results revealed that the SS-OCNN consistently achieved the most accurate classification results. The SS-OCNN, thus, provides a new paradigm for crop classification over heterogeneous areas using FSR imagery, and has a wide application prospect.
WOS:000670807600001
</snippet>
</document>

<document id="72">
<title>A graph deep learning approach for urban building grouping</title>
<url>http://dx.doi.org/10.1080/10106049.2020.1856195</url>
<snippet>Identifying the spatial configurations of buildings and grouping them reasonably is an important task in cartography. This study developed a grouping approach using graph deep learning by integrating multiple cognitive features and manual cartographic experiences. Taking building center points as nodes, adjacent buildings were organized as a graph in which cognitive variables including size, orientation, and shape were defined for each node. Then, a learning model combining the graph convolution and neural network was designed to analyse the adjacent buildings modelled by the graph. The center points of groups were used as labels to train the positions of graph nodes and finally, a k-means algorithm was employed to obtain the grouping results based on the predicted node positions. Experiments confirmed that our approach can extract the inherent features describing the grouping relationship between buildings and performed better than two existing approaches referring to the ARI index (from 0.647 to 0.749).
WOS:000603852500001
</snippet>
</document>

<document id="73">
<title>Spatial distribution and computational modeling for mapping of tuberculosis in Pakistan</title>
<url>http://dx.doi.org/10.1093/pubmed/fdac125</url>
<snippet>Background Tuberculosis (TB) like many other infectious diseases has a strong relationship with climatic parameters. Methods The present study has been carried out on the newly diagnosed sputum smear-positive pulmonary TB cases reported to National TB Control Program across Pakistan from 2007 to 2020. In this study, spatial and temporal distribution of the disease was observed through detailed district wise mapping and clustered regions were also identified. Potential risk factors associated with this disease depending upon population and climatic variables, i.e. temperature and precipitation were also identified. Results Nationwide, the incidence rate of TB was observed to be rising from 7.03&#37; to 11.91&#37; in the years 2007-2018, which then started to decline. However, a declining trend was observed after 2018-2020. The most populous provinces, Punjab and Sindh, have reported maximum number of cases and showed a temporal association as the climatic temperature of these two provinces is higher with comparison to other provinces. Machine learning algorithms Maxent, Support Vector Machine (SVM), Environmental Distance (ED) and Climate Space Model (CSM) predict high risk of the disease with14.02&#37;, 24.75&#37;, 34.81&#37; and 43.89&#37; area, respectively. Conclusion SVM has a higher significant probability of prediction in the diseased area with a 1.86 partial receiver-operating characteristics (ROC) value as compared with other models.
WOS:000891993900001
</snippet>
</document>

</searchresult>
