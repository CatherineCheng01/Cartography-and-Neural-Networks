FN Thomson Reuters Web of Scienceâ„¢
VR 1.0
PT J
AU Gomez, C
   White, Joanne C
   Wulder, Michael A
TI Optical remotely sensed time series data for land cover classification: A review
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
DE remote sensing; landsat; sentinel 2; monitoring; composite; change detection; mapping; large area
AB Accurate land cover information is required for science, monitoring, and reporting. Land cover changes naturally over time, as well as a result of anthropogenic activities. Monitoring and mapping of land cover and land cover change in a consistent and robust manner over large areas is made possible with Earth Observation (EO) data. Land cover products satisfying a range of science and policy information needs are currently produced periodically at different spatial and temporal scales. The increased availability of EO data-particularly from the Landsat archive (and soon to be augmented with Sentinel-2 data)-coupled with improved computing and storage capacity with novel image compositing approaches, have resulted in the availability of annual, large-area, gap-free, surface reflectance data products. In turn, these data products support the development of annual land cover products that can be both informed and constrained by change detection outputs. The inclusion of time series change in the land cover mapping process provides information on class stability and informs on logical class transitions (both temporally and categorically). In this review, we present the issues and opportunities associated with generating and validating time-series informed annual, large-area, land cover products, and identify methods suited to incorporating time series information and other novel inputs for land cover characterization. Crown Copyright (C) 2016 Published by Elsevier B.V.
C1 [Gomez, Cristina] INIA, Forest Res Ctr, Dept Silviculture & Forest Management, Crta La Coruna Km 7,5, Madrid 28040, Spain.   
[Gomez, Cristina] Univ Aberdeen, Sch Geosci, Dept Geog & Environm, Aberdeen AB24 3UE, Scotland.   
[White, Joanne C.; Wulder, Michael A.] Nat Resources Canada, Canadian Forest Serv, Pacific Forestry Ctr, Victoria, BC V8Z 1M5, Canada.
RP White, JC (corresponding author), Nat Resources Canada, Canadian Forest Serv, Pacific Forestry Ctr, Victoria, BC V8Z 1M5, Canada.
FU Canadian Space Agency (CSA) Government Related Initiatives Program (GRIP); Canadian Forest Service (CFS) of Natural Resources Canada
CR Amoros-Lopez J, 2013, INT J APPL EARTH OBS, V23, P132, DOI 10.1016/j.jag.2012.12.004
   Andrew ME, 2014, PROG PHYS GEOG, V38, P328, DOI 10.1177/0309133314528942
   Bai Y, 2014, REMOTE SENS-BASEL, V6, P8739, DOI 10.3390/rs6098739
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Belward AS, 2015, ISPRS J PHOTOGRAMM, V103, P115, DOI 10.1016/j.isprsjprs.2014.03.009
   Bontemps S, 2011, GLOBCOVER 2009 PRODU, V0, P53
   Bontemps S, 2012, REMOTE SENSING LAND, V0, P243
   Broich M, 2011, INT J APPL EARTH OBS, V13, P277, DOI 10.1016/j.jag.2010.11.004
   Bruzzone L, 2014, REMOTE SENS DIGIT IM, V18, P127, DOI 10.1007/978-94-007-7969-3, 9
   Buttner G, 2014, LAND USE LAND COVER, V0, P31
   Cai SS, 2014, REMOTE SENS ENVIRON, V147, P243, DOI 10.1016/j.rse.2014.03.012
   Chen J, 2014, ISPRS J PHOTOGRAMM R, V0, P0
   Chen XH, 2015, REMOTE SENS LETT, V6, P29, DOI 10.1080/2150704X.2014.998793
   Chen YL, 2013, ISPRS J PHOTOGRAMM, V83, P64, DOI 10.1016/j.isprsjprs.2013.06.003
   Clark ML, 2012, REMOTE SENS ENVIRON, V126, P84, DOI 10.1016/j.rse.2012.08.013
   Colditz RR, 2011, REMOTE SENS ENVIRON, V115, P3264, DOI 10.1016/j.rse.2011.07.010
   DeVries B, 2015, REMOTE SENS ENVIRON, V161, P107, DOI 10.1016/j.rse.2015.02.012
   Elghazel H, 2015, MACH LEARN, V98, P157, DOI 10.1007/s10994-013-5337-8
   Franklin SE, 2015, CAN J REMOTE SENS, V41, P293, DOI 10.1080/07038992.2015.1089401
   Gebhardt S, 2014, REMOTE SENS-BASEL, V6, P3923, DOI 10.3390/rs6053923
   Gevaert CM, 2015, REMOTE SENS ENVIRON, V156, P34, DOI 10.1016/j.rse.2014.09.012
   Ghimire B, 2012, GISCI REMOTE SENS, V49, P623, DOI 10.2747/1548-1603.49.5.623
   Glanz H, 2014, ISPRS J PHOTOGRAMM, V97, P219, DOI 10.1016/j.isprsjprs.2014.09.004
   Gomez C, 2011, REMOTE SENS ENVIRON, V115, P1665, DOI 10.1016/j.rse.2011.02.025
   Gomez C, 2012, INT J REMOTE SENS, V33, P5546, DOI 10.1080/01431161.2012.663115
   Gomez C, 2014, ISPRS J PHOTOGRAMM, V93, P14, DOI 10.1016/j.isprsjprs.2014.03.008
   Gomez C, 2015, CAN J REMOTE SENS, V41, P271, DOI 10.1080/07038992.2015.1089162
   Gomez-Chova L, 2011, AUGMENT VIS REAL, V3, P171, DOI 10.1007/978-3-642-14212-3, 10
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Gorecki T, 2014, PATTERN RECOGN LETT, V45, P99, DOI 10.1016/j.patrec.2014.03.009
   Gray J, 2013, REMOTE SENS ENVIRON, V134, P333, DOI 10.1016/j.rse.2013.03.022
   Griffiths P, 2013, IEEE J-STARS, V6, P2088, DOI 10.1109/JSTARS.2012.2228167
   Griffiths P, 2014, REMOTE SENS ENVIRON, V151, P72, DOI 10.1016/j.rse.2013.04.022
   Guardia NB, 2014, REMOTE SENS DIGIT IM, V18, P31, DOI 10.1007/978-94-007-7969-3, 3
   Gutierrez-Velez VH, 2013, REMOTE SENS ENVIRON, V129, P154, DOI 10.1016/j.rse.2012.10.033
   Hansen MC, 2011, REMOTE SENS LETT, V2, P279, DOI 10.1080/01431161.2010.519002
   Hansen MC, 2012, REMOTE SENS ENVIRON, V122, P66, DOI 10.1016/j.rse.2011.08.024
   Hansen MC, 2012, REMOTE SENSING LAND, V0, PP127, DOI 10.1201/B11964-12
   Hansen MC, 2013, SCIENCE, V342, P850, DOI 10.1126/science.1244693
   Hansen MC, 2014, REMOTE SENS ENVIRON, V140, P466, DOI 10.1016/j.rse.2013.08.014
   Hermosilla T, 2015, REMOTE SENS ENVIRON, V158, P220, DOI 10.1016/j.rse.2014.11.005
   Hermosilla T, 2015, REMOTE SENS ENVIRON, V170, P121, DOI 10.1016/j.rse.2015.09.004
   Houghton RA, 2012, BIOGEOSCIENCES, V9, P5125, DOI 10.5194/bg-9-5125-2012
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Irons JR, 2012, REMOTE SENS ENVIRON, V122, P11, DOI 10.1016/j.rse.2011.08.026
   Jamali S, 2015, REMOTE SENS ENVIRON, V156, P182, DOI 10.1016/j.rse.2014.09.010
   Jia K, 2014, ISPRS J PHOTOGRAMM, V93, P49, DOI 10.1016/j.isprsjprs.2014.04.004
   Jia K, 2014, REMOTE SENS LETT, V5, P148, DOI 10.1080/2150704X.2014.889862
   Jia K, 2014, REMOTE SENS-BASEL, V6, P11518, DOI 10.3390/rs61111518
   Jun G, 2013, IEEE T GEOSCI REMOTE, V51, P273, DOI 10.1109/TGRS.2012.2198654
   Kennedy RE, 2012, REMOTE SENS ENVIRON, V122, P117, DOI 10.1016/j.rse.2011.09.024
   Kennedy RE, 2014, FRONT ECOL ENVIRON, V12, P339, DOI 10.1890/130066
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Lehmann EA, 2013, INT J APPL EARTH OBS, V21, P453, DOI 10.1016/j.jag.2012.06.005
   Li M, 2014, EUR J REMOTE SENS, V47, P389, DOI 10.5721/EuJRS20144723
   Liu DS, 2012, ANN ASSOC AM GEOGR, V102, P1329, DOI 10.1080/00045608.2011.596357
   Mahmood R, 2014, INT J CLIMATOL, V34, P929, DOI 10.1002/joc.3736
   Main-Knorn M, 2013, REMOTE SENS ENVIRON, V139, P277, DOI 10.1016/j.rse.2013.08.010
   Melaas EK, 2013, REMOTE SENS ENVIRON, V132, P176, DOI 10.1016/j.rse.2013.01.011
   Muller E, 2015, MACH LEARN, V98, P1, DOI 10.1007/s10994-014-5445-0
   Muller H, 2014, REMOTE SENS ENVIRON, V156, P490
   Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Olthof I, 2014, REMOTE SENS-BASEL, V6, P11558, DOI 10.3390/rs61111558
   Parmentier B, 2014, INT J REMOTE SENS, V35, P671, DOI 10.1080/01431161.2013.871595
   Pengra B, 2015, REMOTE SENS ENVIRON, V165, P234, DOI 10.1016/j.rse.2015.01.018
   Perez-Hoyos A, 2012, ISPRS J PHOTOGRAMM, V74, P185, DOI 10.1016/j.isprsjprs.2012.09.006
   Peterson B, 2014, REMOTE SENS-BASEL, V6, P12409, DOI 10.3390/rs61212409
   Petitjean F, 2012, IEEE T GEOSCI REMOTE, V50, P3081, DOI 10.1109/TGRS.2011.2179050
   Pflugmacher D, 2011, REMOTE SENS ENVIRON, V115, P3539, DOI 10.1016/j.rse.2011.08.016
   Pflugmacher D, 2014, REMOTE SENS ENVIRON, V151, P124, DOI 10.1016/j.rse.2013.05.033
   Potapov P, 2011, REMOTE SENS ENVIRON, V115, P548, DOI 10.1016/j.rse.2010.10.001
   Pouliot D, 2013, MULTITEMP 2013: 7TH INTERNATIONAL WORKSHOP ON THE ANALYSIS OF MULTI-TEMPORAL REMOTE SENSING IMAGES, V0, P0
   Pouliot D, 2014, REMOTE SENS ENVIRON, V140, P731, DOI 10.1016/j.rse.2013.10.004
   Radoux J, 2014, REMOTE SENS-BASEL, V6, P3965, DOI 10.3390/rs6053965
   Rodriguez-Galiano VF, 2012, REMOTE SENS ENVIRON, V121, P93, DOI 10.1016/j.rse.2011.12.003
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Schroeder TA, 2011, REMOTE SENS ENVIRON, V115, P1421, DOI 10.1016/j.rse.2011.01.022
   Schroeder TA, 2014, REMOTE SENS ENVIRON, V154, P61, DOI 10.1016/j.rse.2014.08.005
   Senf C, 2015, REMOTE SENS ENVIRON, V156, P527, DOI 10.1016/j.rse.2014.10.018
   Sexton JO, 2013, REMOTE SENS ENVIRON, V128, P246, DOI 10.1016/j.rse.2012.10.010
   Sexton JO, 2013, REMOTE SENS ENVIRON, V129, P42, DOI 10.1016/j.rse.2012.10.025
   Shao Y, 2012, ISPRS J PHOTOGRAMM, V70, P78, DOI 10.1016/j.isprsjprs.2012.04.001
   Shao Y, 2016, REMOTE SENS ENVIRON, V174, P258, DOI 10.1016/j.rse.2015.12.023
   Shenthilnath J, 2011, IEEE J-STARS, V5, P762
   Shimabukuro YE, 2014, REMOTE SENS LETT, V5, P773, DOI 10.1080/2150704X.2014.967880
   Sulla-Menashe D, 2011, REMOTE SENS ENVIRON, V115, P392, DOI 10.1016/j.rse.2010.09.010
   Tateishi R, 2011, INT J DIGIT EARTH, V4, P22, DOI 10.1080/17538941003777521
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Thompson SD, 2015, CAN J REMOTE SENS, V41, P203, DOI 10.1080/07038992.2015.1065708
   Tsutsumida N, 2015, INT J APPL EARTH OBS, V41, P46, DOI 10.1016/j.jag.2015.04.018
   Tuia D, 2011, REMOTE SENS ENVIRON, V115, P2232, DOI 10.1016/j.rse.2011.04.022
   Tulbure MG, 2013, ISPRS J PHOTOGRAMM, V79, P44, DOI 10.1016/j.isprsjprs.2013.01.010
   Verbesselt J, 2012, REMOTE SENS ENVIRON, V123, P98, DOI 10.1016/j.rse.2012.02.022
   Wang J, 2015, ISPRS J PHOTOGRAMM, V103, P38, DOI 10.1016/j.isprsjprs.2014.03.007
   Wehmann A, 2015, ISPRS J PHOTOGRAMM, V107, P77, DOI 10.1016/j.isprsjprs.2015.04.009
   Weiss DJ, 2014, ISPRS J PHOTOGRAMM, V98, P106, DOI 10.1016/j.isprsjprs.2014.10.001
   White JC, 2014, CAN J REMOTE SENS, V40, P192, DOI 10.1080/07038992.2014.945827
   Wulder MA, 2012, REMOTE SENS ENVIRON, V122, P2, DOI 10.1016/j.rse.2012.01.010
   Wulder MA, 2015, REMOTE SENS ENVIRON, V170, P62, DOI 10.1016/j.rse.2015.09.001
   Wulder MA, 2016, REMOTE SENS ENV, V0, P0
   Xue ZH, 2014, IEEE J-STARS, V7, P1142, DOI 10.1109/JSTARS.2013.2294956
   Yan L, 2014, REMOTE SENS ENVIRON, V144, P42, DOI 10.1016/j.rse.2014.01.006
   Yan L, 2015, REMOTE SENS ENVIRON, V158, P478, DOI 10.1016/j.rse.2014.11.024
   Yin H, 2014, IEEE J-STARS, V7, P3421, DOI 10.1109/JSTARS.2014.2348411
   Zald HSJ, 2016, REMOTE SENS ENVIRON, V176, P188, DOI 10.1016/j.rse.2016.01.015
   Zhang XH, 2011, EXPERT SYST APPL, V38, P11891, DOI 10.1016/j.eswa.2011.03.081
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
   Zhu Z, 2014, REMOTE SENS ENVIRON, V152, P217, DOI 10.1016/j.rse.2014.06.012
   Zhu Z, 2015, REMOTE SENS ENVIRON, V159, P269, DOI 10.1016/j.rse.2014.12.014
   Zhu Z, 2015, REMOTE SENS ENVIRON, V162, P67, DOI 10.1016/j.rse.2015.02.009
NR 113
TC 619
Z9 0
U1 42
U2 519.0
J9 ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
PD JUN
PY 2016
VL 116
BP 55
EP 72
DI 10.1016/j.isprsjprs.2016.03.008
PG 18
SC PHYSICAL GEOGRAPHY; GEOLOGY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000374624600005
PM 
ER

PT J
AU Debats, SR
   Luo, Dee
   Estes, Lyndon D
   Fuchs, Thomas J
   Caylor, Kelly K
TI A generalized computer vision approach to mapping crop fields in heterogeneous agricultural landscapes
SO REMOTE SENSING OF ENVIRONMENT
DE land cover; agriculture; sub-saharan africa; computer vision; machine learning
AB Smallholder farms dominate in many parts of the world, particularly Sub-Saharan Africa. These systems are characterized by small, heterogeneous, and often indistinct field patterns, requiring a specialized methodology to map agricultural land cover. Using a variety of sites in South Africa, we present a new approach to mapping agricultural fields, based on efficient extraction of a vast set of simple, highly correlated, and interdependent features, followed by a random forest classifier. We achieved similar high performance across agricultural types, including the spectrally indistinct smallholder fields as well as the more easily distinguishable commercial fields, and demonstrated the ability to generalize performance across large geographic areas. In sensitivity analyses, we determined multi-temporal information provided greater gains in performance than the addition of multi-spectral bands available in DigitalGlobe Worldview-2 imagery. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Debats, Stephanie R.; Estes, Lyndon D.; Caylor, Kelly K.] Princeton Univ, Dept Civil & Environm Engn, Princeton, NJ 08544 USA.   
[Luo, Dee] Princeton Univ, Dept Operat Res & Financial Engn, Princeton, NJ 08544 USA.   
[Fuchs, Thomas J.] NASA, Jet Prop Lab, Pasadena, CA 91109 USA.
RP Debats, SR (corresponding author), Princeton Univ, Dept Civil & Environm Engn, Princeton, NJ 08544 USA.
FU Princeton Environmental Institute through the Walbridge Fund; Mary and Randall Hack 69 Research Fund; Program in Science, Technology, and Environmental Policy (PEI-STEP) Fellowship; NASA Jet Propulsion Laboratory Strategic University Partnerships (JPL SURP) [1524338]; National Science Foundation [SES-1360463, BCS-1026776]; NASA New Investigator Program [NNX15AC64G]; NASA [809418, NNX15AC64G] Funding Source: Federal RePORTER; Direct For Social, Behav & Economic Scie; Divn Of Social and Economic Sciences [1830752] Funding Source: National Science Foundation; Divn Of Social and Economic Sciences; Direct For Social, Behav & Economic Scie [1534544, 1360463] Funding Source: National Science Foundation
CR AFDB OECD UNDP, 2014, AFR EC OUTL 2014 GLO, V0, P0
   AGRA, 2013, AFR AGR STAT REP FOC, V0, P0
   Adam E, 2014, INT J REMOTE SENS, V35, P693, DOI 10.1080/01431161.2013.870676
   Baccini A, 2012, NAT CLIM CHANGE, V2, P182, DOI 10.1038/nclimate1354
   Bekker DL, 2014, ASTROBIOLOGY, V14, P486, DOI 10.1089/ast.2014.1172
   Crawford MM, 2013, P IEEE, V101, P593, DOI 10.1109/JPROC.2012.2231951
   Davis KF, 2014, POPUL ENVIRON, V36, P180, DOI 10.1007/s11111-014-0215-2
   Egorov AV, 2015, REMOTE SENS ENVIRON, V165, P135, DOI 10.1016/j.rse.2015.04.022
   Estes LD, 2013, GLOBAL CHANGE BIOL, V19, P3762, DOI 10.1111/gcb.12325
   Estes LD, 2014, ENVIRON RES LETT, V9, P0, DOI 10.1088/1748-9326/9/7/075005
   Estes LD, 2016, ENVIRON MODELL SOFTW, V80, P41, DOI 10.1016/j.envsoft.2016.01.011
   Evans JS, 2011, PREDICTIVE SPECIES AND HABITAT MODELING IN LANDSCAPE ECOLOOGY: CONCEPTS AND APPLICATIONS, V0, PP139, DOI 10.1007/978-1-4419-7390-0, 8
   Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Fritz S, 2011, GEOPHYS RES LETT, V38, P0, DOI 10.1029/2010GL046213
   Fritz S, 2015, GLOBAL CHANGE BIOL, V21, P1980, DOI 10.1111/gcb.12838
   Glassman A, 2014, DELIVERING DATA REVO, V0, P0
   Gollin D, 2014, SMALLHOLDER AGR AFRI, V0, P0
   Hardy M, 2011, RAINFED FARMING SYST, V0, P0, DOI DOI 10.1007/978-1-4020-9132-2
   Haub C, 2013, 2013 WORLD POPULATIO, V0, P0
   Hayes MM, 2014, REMOTE SENS LETT, V5, P112, DOI 10.1080/2150704X.2014.882526
   IFAD (International Fund for Agricultural Development) and UNEP (United Nations Environment Programme), 2013, SMALLH FOOD SEC ENV, V0, P0
   Jain M, 2013, REMOTE SENS ENVIRON, V134, P210, DOI 10.1016/j.rse.2013.02.029
   Jayne TS, 2014, FOOD POLICY, V48, P1, DOI 10.1016/j.foodpol.2014.05.014
   Lobell DB, 2013, FIELD CROP RES, V143, P56, DOI 10.1016/j.fcr.2012.08.008
   Low F, 2015, ISPRS J PHOTOGRAMM, V105, P91, DOI 10.1016/j.isprsjprs.2015.03.004
   Lowder SK, 2014, DO WE REALLY KNOW NU, V0, P0
   Mascaro J, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0085993
   Masters WA, 2013, GLOB FOOD SECUR-AGR, V2, P156, DOI 10.1016/j.gfs.2013.07.002
   Mayes MT, 2015, REMOTE SENS ENVIRON, V165, P203, DOI 10.1016/j.rse.2015.05.006
   Mukashema A, 2014, INT J APPL EARTH OBS, V33, P331, DOI 10.1016/j.jag.2014.05.005
   Nogales G, 2014, AGRIBUSINESS FOOD IN, V4, P0
   Ozdarici-Ok A, 2015, REMOTE SENS-BASEL, V7, P5611, DOI 10.3390/rs70505611
   Pienaar PL, 2013, THESIS STELLENBOSCH, V0, P0
   QGIS Development Team, 2015, QGIS GEOGR INF SYST, V0, P0
   Rodriguez-Galiano V, 2012, APPL GEOGR, V35, P208, DOI 10.1016/j.apgeog.2012.06.014
   Rodriguez-Galiano VF, 2011, PROCEDIA ENVIRON SCI, V3, P44, DOI 10.1016/j.proenv.2011.02.009
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Rodriguez-Galiano VF, 2012, REMOTE SENS ENVIRON, V121, P93, DOI 10.1016/j.rse.2011.12.003
   Rojas O, 2011, REMOTE SENS ENVIRON, V115, P343, DOI 10.1016/j.rse.2010.09.006
   Rulli MC, 2013, P NATL ACAD SCI USA, V110, P892, DOI 10.1073/pnas.1213163110
   Rulli MC, 2014, ENVIRON RES LETT, V9, P0, DOI 10.1088/1748-9326/9/6/064030
   See LD, 2015, GLOB FOOD SECUR-AGR, V4, P37, DOI 10.1016/j.gfs.2014.10.004
   Shao Y, 2012, ISPRS J PHOTOGRAMM, V70, P78, DOI 10.1016/j.isprsjprs.2012.04.001
   Szeliski R, 2011, TEXTS COMPUT SCI, V0, PP1, DOI 10.1007/978-1-84882-935-0
   Thornton PK, 2011, PHILOS T R SOC A, V369, P117, DOI 10.1098/rsta.2010.0246
   Tokarczyk P, 2013, ISPRS ANN PHOTO REM, VII-3/W1, P35, DOI 10.5194/isprsannals-II-3-W1-35-2013
   Tokarczyk P, 2015, IEEE T GEOSCI REMOTE, V53, P280, DOI 10.1109/TGRS.2014.2321423
   Touw WG, 2013, BRIEF BIOINFORM, V14, P315, DOI 10.1093/bib/bbs034
   Vintrou E, 2012, PHOTOGRAMM ENG REM S, V78, P839, DOI 10.14358/PERS.78.8.839
   Wagstaff KL, 2013, GEOPHYS RES LETT, V40, P4188, DOI 10.1002/grl.50817
   World Bank, 2013, UNLOCKING AFRICAS AG, V0, P0
   Yan L, 2014, REMOTE SENS ENVIRON, V144, P42, DOI 10.1016/j.rse.2014.01.006
   [Anonymous], 2013, P WORLD BANK WORK PA, V0, P0
NR 53
TC 55
Z9 0
U1 5
U2 75.0
J9 REMOTE SENSING OF ENVIRONMENT
PD JUN
PY 2016
VL 179
BP 210
EP 221
DI 10.1016/j.rse.2016.03.010
PG 12
SC ENVIRONMENTAL SCIENCES & ECOLOGY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000375506100017
PM 
ER

PT J
AU Zhu, Z
   Gallant, Alisa L
   Woodcock, Curtis E
   Pengra, Bruce
   Olofsson, Pontus
   Loveland, Thomas R
   Jin, Suming
   Dahal, Devendra
   Yang, Limin
   Auch, Roger F
TI Optimizing selection of training and auxiliary data for operational land cover classification for the LCMAP initiative
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
DE continuous change detection and classification (ccdc); training strategy; auxiliary data; land cover classification; landsat
AB The U.S. Geological Surveys Land Change Monitoring, Assessment, and Projection (LCMAP) initiative is a new end-to-end capability to continuously track and characterize changes in land cover, use, and condition to better support research and applications relevant to resource management and environmental change. Among the LCMAP product suite are annual land cover maps that will be available to the public. This paper describes an approach to optimize the selection of training and auxiliary data for deriving the thematic land cover maps based on all available clear observations from Landsats 4-8. Training data were selected from map products of the U.S. Geological Surveys Land Cover Trends project. The Random Forest classifier was applied for different classification scenarios based on the Continuous Change Detection and Classification (CCDC) algorithm. We found that extracting training data proportionally to the occurrence of land cover classes was superior to an equal distribution of training data per class, and suggest using a total of 20,000 training pixels to classify an area about the size of a Landsat scene. The problem of unbalanced training data was alleviated by extracting a minimum of 600 training pixels and a maximum of 8000 training pixels per class. We additionally explored removing outliers contained within the training data based on their spectral and spatial criteria, but observed no significant improvement in classification results. We also tested the importance of different types of auxiliary data that were available for the conterminous United States, including: (a) five variables used by the National Land Cover Database, (b) three variables from the cloud screening "Function of mask" (Fmask) statistics, and 
C1 [Zhu, Zhe] Texas Tech Univ, Dept Geosci, MS 1053,Sci Bldg 125, Lubbock, TX 79409 USA.   
[Gallant, Alisa L.; Loveland, Thomas R.; Auch, Roger F.] US Geol Survey, Earth Resources Observat & Sci EROS Ctr, 47914 252nd St, Sioux Falls, SD 57198 USA.   
[Woodcock, Curtis E.; Olofsson, Pontus] Boston Univ, Dept Earth & Environm, 685 Commonwealth Ave, Boston, MA 02215 USA.   
[Pengra, Bruce; Dahal, Devendra; Yang, Limin] US Geol Survey, SGT, Earth Resources Observat & Sci EROS Ctr, 47914 252nd St, Sioux Falls, SD 57198 USA.   
[Zhu, Zhe; Jin, Suming] US Geol Survey, ASRC InuTeq, Earth Resources Observat & Sci EROS Ctr, 47914 252nd St, Sioux Falls, SD 57198 USA.
RP Zhu, Z (corresponding author), Texas Tech Univ, Dept Geosci, MS 1053,Sci Bldg 125, Lubbock, TX 79409 USA.
FU USGS [G13PC00028, G15PC00012]
CR Auch RF, 2012, REMOTE SENSING LAND, V0, P351
   Auch RF, 2015, US GEOLOGICAL SURV C, V0, P190
   Calzia PJ, 2012, 1794A30 US GEOL SURV, V0, P303
   Chen J, 2015, ISPRS J PHOTOGRAMM, V103, P7, DOI 10.1016/j.isprsjprs.2014.09.002
   Corcoran JM, 2013, REMOTE SENS-BASEL, V5, P3212, DOI 10.3390/rs5073212
   Cracknell MJ, 2014, COMPUT GEOSCI-UK, V63, P22, DOI 10.1016/j.cageo.2013.10.008
   Freeman EA, 2012, ECOL MODEL, V233, P1, DOI 10.1016/j.ecolmodel.2012.03.007
   Fry JA, 2011, PHOTOGRAMM ENG REM S, V77, P859
   Gallant AL, 2015, REMOTE SENS-BASEL, V7, P10938, DOI 10.3390/rs70810938
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Homer C, 2015, PHOTOGRAMM ENG REM S, V81, P345, DOI 10.14358/PERS.81.5.345
   Jin HR, 2014, INT J REMOTE SENS, V35, P2067, DOI 10.1080/01431161.2014.885152
   Mellor A, 2015, ISPRS J PHOTOGRAMM, V105, P155, DOI 10.1016/j.isprsjprs.2015.03.014
   Millard K, 2015, REMOTE SENS-BASEL, V7, P8489, DOI 10.3390/rs70708489
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Radoux J, 2014, REMOTE SENS-BASEL, V6, P3965, DOI 10.3390/rs6053965
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Rodriguez-Galiano VF, 2012, REMOTE SENS ENVIRON, V121, P93, DOI 10.1016/j.rse.2011.12.003
   Schmidt Gail L, 2013, LANDSAT ECOSYSTEM DI, V0, P0
   Soulard CE, 2014, US GEOLOGICAL SURVEY, V844, P10, DOI 10.3133/DS844
   Taylor JL, 2015, STATUS TRENDS LAND C, V1794, P0, DOI 10.3133/pp1794B
   USGeological Survey, 2016, LANDS 8 PROD GUID VE, V0, P0
   Verikas A, 2011, PATTERN RECOGN, V44, P330, DOI 10.1016/j.patcog.2010.08.011
   Wulder MA, 2016, REMOTE SENS ENVIRON, V185, P271, DOI 10.1016/j.rse.2015.11.032
   Yan L, 2015, REMOTE SENS ENVIRON, V158, P478, DOI 10.1016/j.rse.2014.11.024
   Zhen Z, 2013, INT J REMOTE SENS, V34, P6914, DOI 10.1080/01431161.2013.810822
   Zhu Z, 2012, REMOTE SENS ENVIRON, V117, P72, DOI 10.1016/j.rse.2011.07.020
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
   Zhu Z, 2014, REMOTE SENS ENVIRON, V152, P217, DOI 10.1016/j.rse.2014.06.012
   Zhu Z, 2015, REMOTE SENS ENVIRON, V159, P269, DOI 10.1016/j.rse.2014.12.014
   Zhu Z, 2015, REMOTE SENS ENVIRON, V162, P67, DOI 10.1016/j.rse.2015.02.009
NR 32
TC 103
Z9 0
U1 6
U2 62.0
J9 ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
PD DEC
PY 2016
VL 122
BP 206
EP 221
DI 10.1016/j.isprsjprs.2016.11.004
PG 16
SC PHYSICAL GEOGRAPHY; GEOLOGY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000390719600015
PM 
ER

PT J
AU Skakun, S
   Kussul, Nataliia
   Shelestov, Andrii Yu
   Lavreniuk, Mykola
   Kussul, Olga
TI Efficiency Assessment of Multitemporal C-Band Radarsat-2 Intensity and Landsat-8 Surface Reflectance Satellite Imagery for Crop Classification in Ukraine
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
DE crop classification; ensemble; joint experiment for crop assessment and monitoring (jecam); landsat-8; neural networks (nns); radarsat-2; ukraine
AB Ukraine is one of the most developed agricultural countries in the world. For many applications, it is extremely important to provide reliable crop maps taking into account diversity of cropping systems used in Ukraine. The use of optical imagery only is limited due to cloud cover, and previous studies showed particular difficulties in discriminating summer crops in Ukraine such as maize, soybeans, sunflower, and sugar beet. This paper focuses on exploring feasibility and assessing efficiency of using multitemporal satellite synthetic-aperture radar (SAR) acquired in C-band and optical images for crop classification in Ukraine. Both optical (Landsat-8/OLI) and SAR (Radarsat-2) images are used to assess the impact of adding backscattering intensity from SAR images for classification purposes. SAR intensity information is very important due to availability of Sentinel-1 imagery over Ukraine starting March 2015. Different combinations of optical and SAR images, as well as SAR modes and polarizations, are assessed for better discrimination of crops. A committee of neural networks, in particular multilayer perceptrons (MLPs), is used to improve classification accuracy compared to several standard classifiers. It is found that using backscatter coefficients from SAR images alone provides the same performance for winter crops (wheat and rapeseed) as surface reflectance from optical images. Considering the summer crops, the major impact of adding backscatter intensity information from SAR images is in better separation of sunflower, soybeans, and maize.
C1 [Skakun, Sergii; Kussul, Nataliia] NAS Ukraine, Dept Space Informat Technol & Syst, Space Res Inst, UA-03680 Kiev, Ukraine.   
[Skakun, Sergii; Kussul, Nataliia] SSA Ukraine, UA-03680 Kiev, Ukraine.   
[Shelestov, Andrii Yu.] Natl Univ Life & Environm Sci Ukraine, Dept Comp Sci, UA-03041 Kiev, Ukraine.   
[Lavreniuk, Mykola] Taras Shevchenko Natl Univ Kyiv, UA-01601 Kiev, Ukraine.   
[Kussul, Olga] Natl Tech Univ Ukraine Kyiv Polytech Inst, Dept Informat Secur, UA-03056 Kiev, Ukraine.
RP Skakun, S (corresponding author), NAS Ukraine, Dept Space Informat Technol & Syst, Space Res Inst, UA-03680 Kiev, Ukraine.; Skakun, S (corresponding author), SSA Ukraine, UA-03680 Kiev, Ukraine.
FU EC [603719]; Canadian Space Agency (CSA) within the SOAR-JECAM [5102]
CR Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Du PJ, 2012, SENSORS-BASEL, V12, P4764, DOI 10.3390/s120404764
   European Space Agency, 2014, NEXT ESA SAR TOOLB N, V0, P0
   Forkuor G, 2014, REMOTE SENS-BASEL, V6, P6472, DOI 10.3390/rs6076472
   Gallego FJ, 2014, INT J APPL EARTH OBS, V29, P22, DOI 10.1016/j.jag.2013.12.013
   Gallego J, 2012, J AUTOMAT INFORM SCI, V44, P67, DOI 10.1615/JAutomatInfScien.v44.i5.70
   Hoekman DH, 2011, IEEE J-STARS, V4, P402, DOI 10.1109/JSTARS.2010.2042280
   Jiao XF, 2014, ISPRS J PHOTOGRAMM, V96, P38, DOI 10.1016/j.isprsjprs.2014.06.014
   McNairn H, 2014, INT J APPL EARTH OBS, V28, P252, DOI 10.1016/j.jag.2013.12.015
   Meier U, 2011, PROC INT CONF DOC, V0, PP1250, DOI 10.1109/ICDAR.2011.252
   Moran MS, 2012, IEEE T GEOSCI REMOTE, V50, P1057, DOI 10.1109/TGRS.2011.2166080
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Shao Y, 2012, ISPRS J PHOTOGRAMM, V70, P78, DOI 10.1016/j.isprsjprs.2012.04.001
   Shelestov AY, 2013, CYBERN SYST ANAL+, V49, P124, DOI 10.1007/s10559-013-9492-5
   Skakun S, 2015, J AUTOMAT INFORM SCI, V46, P19
   Skriver H, 2011, IEEE J-STARS, V4, P423, DOI 10.1109/JSTARS.2011.2106198
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   [ ESA] European Space Agency, 2013, SENT 1 US HDB, V0, P0
NR 18
TC 106
Z9 0
U1 2
U2 15.0
J9 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
PD AUG
PY 2016
VL 9
BP 3712
EP 3719
DI 10.1109/JSTARS.2015.2454297
PG 8
SC ENGINEERING; PHYSICAL GEOGRAPHY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000384907200034
PM 
ER

PT J
AU Foody, GM
   Pal, Mahesh
   Rocchini, Duccio
   Garzon-lopez, Carol X
   Bastin, Lucy
TI The Sensitivity of Mapping Methods to Reference Data Quality: Training Supervised Image Classifications with Imperfect Reference Data
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
DE classification; training; error; accuracy; remote sensing; land cover
AB The accuracy of a map is dependent on the reference dataset used in its construction. Classification analyses used in thematic mapping can, for example, be sensitive to a range of sampling and data quality concerns. With particular focus on the latter, the effects of reference data quality on land cover classifications from airborne thematic mapper data are explored. Variations in sampling intensity and effort are highlighted in a dataset that is widely used in mapping and modelling studies; these may need accounting for in analyses. The quality of the labelling in the reference dataset was also a key variable influencing mapping accuracy. Accuracy varied with the amount and nature of mislabelled training cases with the nature of the effects varying between classifiers. The largest impacts on accuracy occurred when mislabelling involved confusion between similar classes. Accuracy was also typically negatively related to the magnitude of mislabelled cases and the support vector machine (SVM), which has been claimed to be relatively insensitive to training data error, was the most sensitive of the set of classifiers investigated, with overall classification accuracy declining by 8% (significant at 95% level of confidence) with the use of a training set containing 20% mislabelled cases.
C1 [Foody, Giles M.] Univ Nottingham, Sch Geog, Nottingham NG7 2RD, England.   
[Pal, Mahesh] Natl Inst Technol, Dept Civil Engn, Kurukshetra 136119, Haryana, India.   
[Rocchini, Duccio] Fdn Edmund Mach, Res & Innovat Ctr, Dept Biodivers & Mol Ecol, Via E Mach 1, I-38010 San Michele All Adige, TN, Italy.   
[Garzon-Lopez, Carol X.] Univ Picardy Jules Verne, FRE CNRS 3498, Ecol & Dynam Human Influenced Syst Res Unit EDYSA, 1 Rue Louvels, FR-80037 Amiens 1, France.   
[Bastin, Lucy] Aston Univ, Sch Engn & Appl Sci, Birmingham B4 7ET, W Midlands, England.
RP Foody, GM (corresponding author), Univ Nottingham, Sch Geog, Nottingham NG7 2RD, England.
FU EU COST Action [TD1202]
CR An WJ, 2013, NEUROCOMPUTING, V110, P101, DOI 10.1016/j.neucom.2012.11.023
   Anderson RP, 2016, CASE GLOBAL BIODIVER, V0, P0
   Costa H, 2015, ISPRS INT J GEO-INF, V4, P2496, DOI 10.3390/ijgi4042496
   Costa H, 2015, PHOTOGRAMM ENG REM S, V81, P451, DOI 10.14358/PERS.81.6.451
   Dong M, 2015, ECOSYST SERV, V15, P63, DOI 10.1016/j.ecoser.2015.07.006
   Fleiss JL, 2013, STAT METHODS RATES P, V0, P0
   Foody GM, 2013, REMOTE SENS LETT, V4, P783, DOI 10.1080/2150704X.2013.798708
   Foody GM, 2013, T GIS, V17, P847, DOI 10.1111/tgis.12033
   Foody GM, 2015, ECOL ECON, V111, P23, DOI 10.1016/j.ecolecon.2015.01.003
   Foody GM, 2015, P IEEE INT GEOSC REM, V0, P0
   Graves SJ, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020161
   Mather PM, 2011, COMPUTER PROCESSING, Vfourth, P0, DOI 10.1002/9780470666517
   Mianji FA, 2011, IEEE T GEOSCI REMOTE, V49, P2100, DOI 10.1109/TGRS.2010.2103381
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Pal M, 2012, IEEE J-STARS, V5, P1344, DOI 10.1109/JSTARS.2012.2215310
   Radoux J, 2014, REMOTE SENS-BASEL, V6, P3965, DOI 10.3390/rs6053965
   Townshend JR, 2012, INT J DIGIT EARTH, V5, P373, DOI 10.1080/17538947.2012.713190
   Vapnik V, 2013, NATURE STAT LEARNING, V0, P0
NR 18
TC 46
Z9 0
U1 0
U2 18.0
J9 ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
PD NOV
PY 2016
VL 5
BP 
EP 
DI 10.3390/ijgi5110199
PG 20
SC COMPUTER SCIENCE; PHYSICAL GEOGRAPHY; REMOTE SENSING
UT WOS:000390104200006
PM 
ER

PT J
AU Kussul, N
   Lemoine, Guido
   Gallego, Francisco Javier
   Skakun, Sergii V
   Lavreniuk, Mykola
   Shelestov, Andrii Yu
TI Parcel-Based Crop Classification in Ukraine Using Landsat-8 Data and Sentinel-1A Data
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
DE agriculture; crop classification; landsat-8; joint experiment of crop assessment and monitoring (jecam); neural networks; parcel-based; remote sensing; sentinel-1; ukraine
AB For many applied problems in agricultural monitoring and food security, it is important to provide reliable crop classification maps. Satellite imagery is extremely valuable source of data to provide crop maps in a timely way at moderate and high spatial resolution. Information on parcel boundaries that takes into account the spatial context may improve the quality of maps compared to pixel-based classification approaches. In general, parcels may contain several plots with different crops and such situations should be taken into account when using parcel boundaries. In this paper, we aim to compare pixel-based and parcel-based approaches to crop classification from multitemporal optical (Landsat-8) and synthetic-aperture radar (SAR) Sentinel-1 imagery. For this, we propose a parcel-based approach that involves a pixel-based classification map and specifically designed rules to account for several plots within parcel. The study is carried out for the Joint Experiment of Crop Assessment and Monitoring test site in Ukraine covering the Kyiv oblast (North of Ukraine) in 2013-2015, and the Odessa oblast (South of Ukraine) in 2014-2015. We found that pixel-based overall classification accuracy can be increased from 85.32% to 89.40% when using parcel boundaries. Among tested parcel-based approaches, the one that relied on pixel-based classification map and a procedure to select multiple plots within the parcel yielded the best performance.
C1 [Kussul, Nataliia] Natl Acad Sci Ukraine, Dept Space Informat Technol & Syst, Space Res Inst, UA-03680 Kiev, Ukraine.   
[Kussul, Nataliia] SSA Ukraine, UA-03680 Kiev, Ukraine.   
[Lemoine, Guido; Gallego, Francisco Javier] European Commiss Joint Res Ctr, Inst Environm & Sustainabil, Monitoring Agr Resources Unit, I-21027 Ispra, Italy.   
[Skakun, Sergii V.] Univ Maryland, Dept Geog Sci, College Pk, MD 20742 USA.   
[Lavreniuk, Mykola] Taras Shevchenko Natl Univ Kyiv, UA-01601 Kiev, Ukraine.   
[Shelestov, Andrii Yu.] Natl Tech Univ Ukraine, Dept Informat Secur, Kyiv Polytech Inst, UA-03056 Kiev, Ukraine.
RP Kussul, N (corresponding author), Natl Acad Sci Ukraine, Dept Space Informat Technol & Syst, Space Res Inst, UA-03680 Kiev, Ukraine.; Kussul, N (corresponding author), SSA Ukraine, UA-03680 Kiev, Ukraine.
CR Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Cover TM, 2012, ELEMENTS INFORM THEO, V0, P0, DOI DOI 10.1002/047174882X
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   European Space Agency, 2015, SENTINEL 1 TOOLB S1T, V0, P0
   Food and Agriculture Organization of the United Nations, 2015, WORLD PROGR IN PRESS, V1, P0
   Fritz S, 2013, EOS T AM GEOPHYS UN, V94, P31, DOI 10.1002/2013EO030006
   Gallego FJ, 2014, INT J APPL EARTH OBS, V29, P22, DOI 10.1016/j.jag.2013.12.013
   Gallego J, 2012, J AUTOMAT INFORM SCI, V44, P67, DOI 10.1615/JAutomatInfScien.v44.i5.70
   Kogan F, 2013, INT J APPL EARTH OBS, V23, P192, DOI 10.1016/j.jag.2013.01.002
   Kogan F, 2013, J AUTOMAT INFORM SCI, V45, P68, DOI 10.1615/JAutomatInfScien.v45.i6.70
   Kolotii A, 2015, INT ARCH PHOTOGRAMM, V47, P39, DOI 10.5194/isprsarchives-XL-7-W3-39-2015
   Kussul N, 2014, INT GEOSCI REMOTE SE, V0, PP1497, DOI 10.1109/IGARSS.2014.6946721
   Kussul N, 2015, INT ARCH PHOTOGRAMM, V47, P45, DOI 10.5194/isprsarchives-XL-7-W3-45-2015
   Liu C, 2013, IEEE T GEOSCI REMOTE, V51, P2227, DOI 10.1109/TGRS.2012.2208649
   Mahmoud A, 2011, ADV SPACE RES, V48, P799, DOI 10.1016/j.asr.2011.04.005
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Shelestov AY, 2013, CYBERN SYST ANAL+, V49, P124, DOI 10.1007/s10559-013-9492-5
   Skakun S, 2015, GEOMAT NAT HAZ RISK, V7, P901, DOI 10.1080/19475705.2015.1016555
   Skakun S, 2015, J AUTOMAT INFORM SCI, V46, P19
   Skakun S, 2016, IEEE J-STARS, V9, P3712, DOI 10.1109/JSTARS.2015.2454297
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   Yan L, 2014, REMOTE SENS ENVIRON, V144, P42, DOI 10.1016/j.rse.2014.01.006
NR 22
TC 113
Z9 0
U1 5
U2 84.0
J9 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
PD JUN
PY 2016
VL 9
BP 2500
EP 2508
DI 10.1109/JSTARS.2016.2560141
PG 9
SC ENGINEERING; PHYSICAL GEOGRAPHY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000379935100034
PM 
ER

PT J
AU Zhang, P
   Gong, Maoguo
   Su, Linzhi
   Liu, Jia
   Li, Zhizhou
TI Change detection based on deep feature representation and mapping transformation for multi-spatial-resolution remote sensing images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
DE change detection; spatial-resolution; denoising autoencoder; stacked denoising autoencoder; deep neural networks; feature transformation
AB Multi-spatial-resolution change detection is a newly proposed issue and it is of great significance in remote sensing, environmental and land use monitoring, etc. Though multi-spatial-resolution image pair are two kinds of representations of the same reality, they are often incommensurable superficially due to their different modalities and properties. In this paper, we present a novel multi-spatial resolution change detection framework, which incorporates deep-architecture-based unsupervised feature learning and mapping-based feature change analysis. Firstly, we transform multi-resolution image-pair into the same pixel-resolution through co-registration, followed by details recovery, which is designed to remedy the spatial details lost in the registration. Secondly, the denoising autoencoder is stacked to learn local and high-level representation/feature from the local neighborhood of the given pixel, in an unsupervised fashion. Thirdly, motivated by the fact that multi-resolution image-pair share the same reality in the unchanged regions, we try to explore the inner relationships between them by building a mapping neural network. And it can be used to learn a mapping function based on the most-unlikely-changed feature-pairs, which are selected from all the feature-pairs via a coarse initial change map generated in advance. The learned mapping function can bridge the different representations and highlight changes. Finally, we can build a robust and contractive change map through feature similarity analysis, and the change detection result is obtained through the segmentation of the final change map. Experiments are carried out on four real datasets, and the results confirmed the effectiveness and superiority of the proposed method. (C) 2016 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.
C1 [Zhang, Puzhao; Gong, Maoguo; Su, Linzhi; Liu, Jia; Li, Zhizhou] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Int Res Ctr Intelligent Percept & Computat, Xian 710071, Shaanxi Provinc, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Int Res Ctr Intelligent Percept & Computat, Xian 710071, Shaanxi Provinc, Peoples R China.
FU National Natural Science Foundation of China [61273317, 61422209]; National Program for Support of Top-notch Young Professionals of China; Specialized Research Fund for the Doctoral Program of Higher Education [20130203110011]
CR Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Carotenuto V, 2015, IEEE T GEOSCI REMOTE, V53, P3294, DOI 10.1109/TGRS.2014.2372900
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen J, 2013, ISPRS J PHOTOGRAMM, V85, P1, DOI 10.1016/j.isprsjprs.2013.07.009
   Coates A, 2011, AISTATS, V0, P0
   Colditz RR, 2012, INT J REMOTE SENS, V33, P6426, DOI 10.1080/01431161.2012.688148
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2, 13
   Doxani G, 2012, INT J APPL EARTH OBS, V15, P38, DOI 10.1016/j.jag.2011.07.002
   Gao F, 2012, INT J REMOTE SENS, V33, P7609, DOI 10.1080/01431161.2012.700424
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Hebel M, 2013, ISPRS J PHOTOGRAMM, V86, P52, DOI 10.1016/j.isprsjprs.2013.09.005
   Hecheltjen A, 2014, REMOTE SENS DIGIT IM, V18, P145, DOI 10.1007/978-94-007-7969-3, 10
   Hulley G, 2014, REMOTE SENS ENVIRON, V140, P755, DOI 10.1016/j.rse.2013.10.014
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Kit O, 2013, ISPRS J PHOTOGRAMM, V83, P130, DOI 10.1016/j.isprsjprs.2013.06.009
   Klaric MN, 2013, IEEE T GEOSCI REMOTE, V51, P2067, DOI 10.1109/TGRS.2013.2243840
   Li XD, 2015, PHOTOGRAMM ENG REM S, V81, P59, DOI 10.14358/PERS.81.1.59
   Muller X, 2011, PROC 28 INT C MACH L, V0, P833
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Teo TA, 2013, INT J REMOTE SENS, V34, P968, DOI 10.1080/01431161.2012.714504
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Tian J, 2013, ISPRS J PHOTOGRAMM, V79, P226, DOI 10.1016/j.isprsjprs.2013.02.017
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P1692, DOI 10.1109/TGRS.2014.2346535
   Xu Y, 2013, 8 INT S MULT IM PROC, V0, P0
   Yousif O, 2013, IEEE T GEOSCI REMOTE, V51, P2032, DOI 10.1109/TGRS.2013.2245900
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
   Zou WY, 2011, WORKSH DEEP LEARN UN, V0, P0
NR 32
TC 194
Z9 0
U1 15
U2 311.0
J9 ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
PD JUN
PY 2016
VL 116
BP 24
EP 41
DI 10.1016/j.isprsjprs.2016.02.013
PG 18
SC PHYSICAL GEOGRAPHY; GEOLOGY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000374624600003
PM 
ER

PT J
AU Li, B
   Ti, Chaopu
   Zhao, Yongqiang
   Yan, Xiaoyuan
TI Estimating Soil Moisture with Landsat Data and Its Application in Extracting the Spatial Distribution of Winter Flooded Paddies
SO REMOTE SENSING
DE soil moisture; landsat; tasseled cap transformation; tvdi; neural network; winter flooded paddy
AB Dynamic monitoring of the spatial pattern of winter continuously flooded paddies (WFP) at regional scales is a challenging but highly necessary process in analyzing trace greenhouse gas emissions, water resource management, and food security. The present study was carried out to demonstrate the feasibility of extracting the spatial distribution of WFP through time series imagery of volumetric surface soil moisture content ((v)) at the field scale (30 m). A trade-off approach based on the synergistic use of tasseled cap transformation wetness and temperature vegetation dryness index was utilized to obtain paddy (v). The results showed that the modeled (v) was in good agreement with in situ measurements. The overall correlation coefficient (R) was 0.78, with root-mean-square ranging from 1.96% to 9.96% in terms of different vegetation cover and surface water status. The lowest error of (v) estimates was found to be restricted at the flooded paddy surface with moderate or high fractional vegetation cover. The flooded paddy was then successfully identified using the (v) image with saturated moisture content thresholding, with an overall accuracy of 83.33%. This indicated that the derived geospatial dataset of WFP could be reliably applied to fill gaps in census statistics.
C1 [Li, Bolun; Ti, Chaopu; Zhao, Yongqiang; Yan, Xiaoyuan] Chinese Acad Sci, Inst Soil Sci, State Key Lab Soil & Sustainable Agr, Nanjing 210008, Jiangsu, Peoples R China.   
[Li, Bolun] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.   
[Zhao, Yongqiang] Zhengzhou Normal Univ, Coll Geog & Tourism, Zhengzhou 450044, Peoples R China.
RP Yan, XY (corresponding author), Chinese Acad Sci, Inst Soil Sci, State Key Lab Soil & Sustainable Agr, Nanjing 210008, Jiangsu, Peoples R China.
FU "Strategic Priority Research Program e Climate Change: Carbon Budget and Relevant Issues" of the Chinese Academy of Sciences [XDA05020200]; Key Research Program of the Chinese Academy of Sciences [KZZD-EW-10-04-2]; Ministry of Science and Technology of China [2012DFG90290]; Ministry of Agriculture of China [201103039]
CR Baig MHA, 2014, REMOTE SENS LETT, V5, P423, DOI 10.1080/2150704X.2014.915434
   Hayashida S, 2013, REMOTE SENS ENVIRON, V139, P246, DOI 10.1016/j.rse.2013.08.008
   Hoan NT, 2012, INT GEOSCI REMOTE SE, V0, PP7161, DOI 10.1109/IGARSS.2012.6352011
   Holzman ME, 2014, INT J APPL EARTH OBS, V28, P181, DOI 10.1016/j.jag.2013.12.006
   Jia K, 2015, IEEE T GEOSCI REMOTE, V53, P4787, DOI 10.1109/TGRS.2015.2409563
   Jonai H, 2014, INT GEOSCI REMOTE SE, V0, PP2098, DOI 10.1109/IGARSS.2014.6946879
   Liu YY, 2012, REMOTE SENS ENVIRON, V123, P280, DOI 10.1016/j.rse.2012.03.014
   Panda BN, 2015, NEURAL COMPUT APPL, V26, P1129, DOI 10.1007/s00521-014-1788-5
   Pasolli L, 2014, EUR J SOIL SCI, V65, P852, DOI 10.1111/ejss.12189
   Peng Li, 2014, REMOTE SENSING, V6, P310, DOI 10.3390/rs6010310
   Prakash R, 2012, IEEE J-STARS, V5, P196, DOI 10.1109/JSTARS.2011.2169236
   Shafian S, 2015, REMOTE SENS-BASEL, V7, P2352, DOI 10.3390/rs70302352
   Xu Y, 2015, SCI TOTAL ENVIRON, V505, P1043, DOI 10.1016/j.scitotenv.2014.10.073
   Zhang DJ, 2014, REMOTE SENS-BASEL, V6, P3170, DOI 10.3390/rs6043170
   Zhu Z, 2015, REMOTE SENS ENVIRON, V159, P269, DOI 10.1016/j.rse.2014.12.014
NR 15
TC 27
Z9 0
U1 1
U2 58.0
J9 REMOTE SENSING
PD JAN
PY 2016
VL 8
BP 
EP 
DI 10.3390/rs8010038
PG 18
SC ENVIRONMENTAL SCIENCES & ECOLOGY; GEOLOGY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000369494500020
PM 
ER

PT J
AU Shao, Z
   Zhang, Yuan
   Zhang, Lei
   Song, Yang
   Peng, Minjun
TI COMBINING SPECTRAL AND TEXTURE FEATURES USING RANDOM FOREST ALGORITHM: EXTRACTING IMPERVIOUS SURFACE AREA IN WUHAN
SO XXIII ISPRS CONGRESS, COMMISSION VII
DE impervious surface area; random forest; texture features
AB Impervious surface area (ISA) is one of the most important indicators of urban environments. At present, based on multi-resolution remote sensing images, numerous approaches have been proposed to extract impervious surface, using statistical estimation, sub pixel classification and spectral mixture analysis method of sub-pixel analysis. Through these methods, impervious surfaces can be effectively applied to regional-scale planning and management. However, for the large scale region, high resolution remote sensing images can provide more details, and therefore they will be more conducive to analysis environmental monitoring and urban management. Since the purpose of this study is to map impervious surfaces more effectively, three classification algorithms (random forests, decision trees, and artificial neural networks) were tested for their ability to map impervious surface. Random forests outperformed the decision trees, and artificial neural networks in precision. Combining the spectral indices and texture, random forests is applied to impervious surface extraction with a producers accuracy of 0.98, a users accuracy of 0.97, and an overall accuracy of 0.98 and a kappa coefficient of 0.97.
C1 [Shao, Zhenfeng; Zhang, Yuan; Zhang, Lei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Peoples R China.   
[Shao, Zhenfeng] State Key Lab Informat Engn Surveying Mapping & R, Shenzhen Res & Dev Ctr, Shenzhen 518057, Peoples R China.   
[Song, Yang] Guangzhou Urban Planning Design & Survey Res Inst, 10 Jianshedamalu, Guangzhou 510060, Guangdong, Peoples R China.   
[Peng, Minjun] Wuhan City Land Resources & Planning Informat Ctr, 13 Sanyang Rd, Wuhan 430014, Peoples R China.
RP Zhang, Y (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
FU National Science & Technology Specific Projects [2012YQ16018505, 2013BAH42F03]; Shenzhen science and Technology Development Foundation [JCYJ20120618162928009]; Special Project on the Integration of Industry, Education and Research of Guangdong Province [2012B090500016]; Guangzhou Science and Technology Development Foundation [201504291602178]
CR Akar O, 2015, INT J REMOTE SENS, V36, P442, DOI 10.1080/01431161.2014.995276
   Dye M, 2012, J SPAT SCI, V57, P193, DOI 10.1080/14498596.2012.733620
   Fawagreh K, 2014, SYST SCI CONTROL ENG, V2, P602, DOI 10.1080/21642583.2014.956265
   Grinand C, 2013, REMOTE SENS ENVIRON, V139, P68, DOI 10.1016/j.rse.2013.07.008
   Hsieh YT, 2011, INT GEOSCI REMOTE SE, V0, PP3050, DOI 10.1109/IGARSS.2011.6049860
   Im J, 2012, REMOTE SENS ENVIRON, V117, P102, DOI 10.1016/j.rse.2011.06.024
   Kuhnlein M, 2014, REMOTE SENS ENVIRON, V141, P129, DOI 10.1016/j.rse.2013.10.026
   Lu DS, 2011, INT J REMOTE SENS, V32, P2519, DOI 10.1080/01431161003698393
   Mhangara P, 2011, AFRICAGEODOWNLOADS I, V0, P0
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Xu HQ, 2013, INT J REMOTE SENS, V34, P27, DOI 10.1080/01431161.2012.703343
   Zhang YZ, 2014, REMOTE SENS ENVIRON, V141, P155, DOI 10.1016/j.rse.2013.10.028
NR 12
TC 5
Z9 0
U1 2
U2 13.0
J9 XXIII ISPRS CONGRESS, COMMISSION VII
PD JUN
PY 2016
VL 41
BP 351
EP 358
DI 10.5194/isprsarchives-XLI-B7-351-2016
PG 8
SC PHYSICAL GEOGRAPHY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000393155900055
PM 
ER

