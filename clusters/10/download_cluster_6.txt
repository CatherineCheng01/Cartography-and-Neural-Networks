FN Thomson Reuters Web of Science™
VR 1.0
PT J
AU Suh, JW
   Ouimet, William
TI Mapping stone walls in Northeastern USA using deep learning and LiDAR data
SO GISCIENCE & REMOTE SENSING
DE automated anthropogenic feature mapping; stone walls; airborne lidar; deep convolutional neural networks; human impacts
AB Stone walls are widespread and iconic landforms found throughout forested terrain in the Northeastern USA that were built during the 17th to early 20th centuries to delineate property boundaries and the edges of agricultural fields and pastures. As linear, or broadly curved, features that are typically > 0.5 m high, 1-2 m wide, and > 4-8 m long, stone walls are highly visible in LiDAR data, and mapping them is of broad interest to the cultural heritage sector as well as to researchers specifically focused on historic landscape reconstruction. However, existing mapping attempts have commonly relied on field surveys and manual digitization, which is time-consuming, especially when trying to complete mapping at broader scales. In response to this limitation, this study: (1) presents a novel framework to automate stone wall mapping using Deep Convolutional Neural Networks (DCNN) models (U-Net and ResUnet) and high-resolution airborne LiDAR, (2) evaluates model performance in two test sites against field verified stone walls, (3) investigates the factors that can influence model performance in terms of the quality of LiDAR data (e.g. ground point spacing), and (4) suggests post-processing for town-level mapping of stone walls (similar to 120 km(2)). Both models performed well with respect to the Matthews Correlation Coefficient (MCC) score. U-Net scenario 3 achieved an MCC score of 0.87 at test site 1, while ResUnet scenario 3 (S3) had an MCC score of 0.80 at test site 2. In town-level test site 3, ResUnet S3 achieved the best F-1 score of 82% after post-processing. This study demonstrates the potential of automated mapping of anthropogenic features using our models.
C1 [Suh, Ji Won] Univ Connecticut, Dept Nat Resources & Environm, Storrs, CT 06269 USA.   
[Suh, Ji Won; Ouimet, William] Univ Connecticut, Dept Geog, Storrs, CT 06269 USA.   
[Ouimet, William] Univ Connecticut, Dept Earth Sci, Storrs, CT USA.
RP Suh, JW (corresponding author), Univ Connecticut, Dept Nat Resources & Environm, Storrs, CT 06269 USA.; Suh, JW (corresponding author), Univ Connecticut, Dept Geog, Storrs, CT 06269 USA.
CR Abdollahi A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091444
   Carbonneau PE, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112107
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172767
   Chen YL, 2022, REMOTE SENS-BASEL, V14, P0, DOI 10.3390/rs14225654
   Chicco D, 2020, BMC GENOMICS, V21, P0, DOI 10.1186/s12864-019-6413-7
   Connecticut Environmental Conditions Online (CT ECO), 2019, CONN ORTH 2019, V0, P0
   Davis DS, 2019, J ARCHAEOL SCI-REP, V23, P166, DOI 10.1016/j.jasrep.2018.10.035
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Gallwey J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171994
   Guyot A, 2021, J COMPUTER APPL ARCH, V4, P1, DOI 10.5334/jcaa.64
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Heidemann H, 2018, LIDAR BASE SPECIFICA, V0, P0
   Johnson KM, 2018, APPL GEOGR, V91, P32, DOI 10.1016/j.apgeog.2017.12.018
   Johnson KM, 2021, ANN AM ASSOC GEOGR, V111, P1656, DOI 10.1080/24694452.2020.1856640
   Johnson KM, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13214318
   Kim M, 2018, IEEE J-STARS, V11, P4604, DOI 10.1109/JSTARS.2018.2880783
   Kokalj Z, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070747
   Kugelman J, 2022, SCI REP-UK, V12, P0, DOI 10.1038/s41598-022-18646-2
   Leonard J, 2021, GEOLOGICAL SOC AM AB, V53, P0, DOI 10.1130/abs/2021NE-361715
   Li W, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111953
   Liu P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050894
   Mboga N, 2020, ISPRS J PHOTOGRAMM, V167, P385, DOI 10.1016/j.isprsjprs.2020.07.005
   Niculita M, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20041192
   Olteanu-Raimond AM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071186
   Orengo HA, 2020, P NATL ACAD SCI USA, V117, P18240, DOI 10.1073/pnas.2005583117
   Qi WW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152487
   Risbol O, 2018, ARCHAEOL PROSPECT, V25, P329, DOI 10.1002/arp.1712
   Rodriguez CG, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223836
   Srivastava S, 2019, REMOTE SENS ENVIRON, V228, P129, DOI 10.1016/j.rse.2019.04.014
   Stoian A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171986
   Suh JW, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13224630
   Sylvain JD, 2019, ISPRS J PHOTOGRAMM, V156, P14, DOI 10.1016/j.isprsjprs.2019.07.010
   Tan YH, 2018, IEEE J-STARS, V11, P3988, DOI 10.1109/JSTARS.2018.2871046
   Thorson RM, 2023, HIST ARCHAEOL, V0, P0
   Trier OD, 2021, INT J APPL EARTH OBS, V95, P0, DOI 10.1016/j.jag.2020.102241
   Verbovsek T, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242946
   Verschoof-van der Vaart W, 2019, J COMPUTER APPL ARCH, V2, P31, DOI 10.5334/JCAA.32
   Verschoof-van der Vaart W, 2022, ARCHAEOL PROSPECT, V0, P0, DOI DOI 10.1002/arp.1889
   Verschoof-van der Vaart WB, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9050293
   Verschoof-van der Vaart WB, 2021, J CULT HERIT, V47, P143, DOI 10.1016/j.culher.2020.10.009
   Waldner F, 2020, REMOTE SENS ENVIRON, V245, P0, DOI 10.1016/j.rse.2020.111741
   Wang YL, 2019, IEEE GEOSC REM SEN M, V7, P64, DOI 10.1109/MGRS.2019.2927260
   Witharana C, 2018, GISCI REMOTE SENS, V55, P183, DOI 10.1080/15481603.2018.1431356
   Wu RZ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12244020
   Yan S, 2021, INT J APPL EARTH OBS, V102, P0, DOI 10.1016/j.jag.2021.102445
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111593
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhou Zongwei, 2018, DEEP LEARN MED IMAGE ANAL MULTIMODAL LEARN CLIN DECIS SUPPORT (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5, 1
NR 51
TC 0
Z9 0
J9 GISCIENCE & REMOTE SENSING
PD DEC
PY 2023
VL 60
BP 
EP 
DI 10.1080/15481603.2023.2196117
PG 25
SC PHYSICAL GEOGRAPHY; REMOTE SENSING
UT WOS:000963378900001
PM 
ER

PT J
AU Keskin, M
   Kettunen, Pyry
TI Potential of eye-tracking for interactive geovisual exploration aided by machine learning
SO INTERNATIONAL JOURNAL OF CARTOGRAPHY
DE geovisualization; geoexploration; eye tracking; machine learning; interaction
AB ABSTRAITECet article de synthese recueille des connaissances sur lutilisation de methodes de suivi oculaire et dapprentissage automatique appliquees a des systemes de geovisualisation automatises et interactifs. Nous nous concentrons sur la lecture exploratoire de geovisualisation (abrege en geoexploration) et sur les outils dapprentissage automatique pour lexploration de donnees geospatiales vectorielles. Nous examinons particulierement les donnees geospatiales non etiquetees, sujettes a confusion ou inconnues de lutilisateur. La contribution de cet article est dans 1) la definition de principes et de besoins pour permettre linteraction de lutilisateur avec les outils de geovisualisation qui apprennent de lutilisateur et sadaptent a son comportement 2) lanalyse de lutilisation de methodes de suivi oculaire et dapprentissage pour la conception de systemes de cartes interactives sensibles au regard (GAIMS). Dans ce contexte, nous examinons la litterature sur 1) la conception des interfaces homme-machine (HCI) pour lexploration de donnees geospatiales 2) lutilisation du suivi oculaire pour des experiences cartographiques, et 3) lapprentissage applique aux donnees geospatiales vectorielles. Letat de lart montre que la combinaison du suivi oculaire et de lapprentissage est prometteuse pour assister la geoexploration. Il manque cependant des recherches sur le suivi oculaire pour les interactions et la personnalisation des interfaces cartographiques ainsi que sur lapprentissage automatique pour la detection de geometries vectorielles.
C1 [Keskin, Merve; Kettunen, Pyry] NLS, Finnish Geospatial Res Inst FGI, Espoo, Finland.
RP Keskin, M (corresponding author), NLS, Finnish Geospatial Res Inst FGI, Espoo, Finland.
FU Finnish Scientific Advisory Board for Defence (MATINE) through the TUGEVA project
CR Allen GL, 2020, APPL SPATIAL COGNITI, V0, P0
   Andrienko N, 2022, IEEE COMPUT GRAPH, V42, P123, DOI 10.1109/MCG.2021.3130314
   Basole RC, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2937475
   Coltekin A, 2018, GEOGRAPHIC INFORM SC, V0, P0, DOI DOI 10.22224/gistbok/2018.2.6
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Feiyu Xu, 2019, NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING. 8TH CCF INTERNATIONAL CONFERENCE, V0, P0
   Gao S, 2021, GEOSPATIAL ARTIFICIA, V0, P0
   Gobel F, 2019, GEOINFORMATICA, V23, P663, DOI 10.1007/s10707-019-00344-3
   Gobel F, 2020, ETRA20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, V0, P0, DOI DOI 10.1145/3379155.3391323
   Gobel F, 2021, THESIS ETH ZURICH, V0, P0, DOI DOI 10.3929/ethz-b-000513243
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He ST, 2020, AAAI CONF ARTIF INTE, V34, P10965
   Hu S, 2021, COMPUT ENVIRON URBAN, V87, P0, DOI 10.1016/j.compenvurbsys.2021.101619
   Janowicz K, 2020, INT J GEOGR INF SCI, V34, P625, DOI 10.1080/13658816.2019.1684500
   Jokinen Jussi, 2021, P 2021 CHI C HUM FAC, V0, PP1, DOI 10.1145/3411764.3445483
   Keskin M, 2018, J EYE MOVEMENT RES, V11, P0, DOI 10.16910/jemr.11.3.4
   Keskin M, 2021, ABSTRACTS ICA, V3, P1
   Kettunen P, 2019, CARTOGR GEOGR INF SC, V46, P489, DOI 10.1080/15230406.2018.1553113
   Kumar B, 2019, ISPRS J PHOTOGRAMM, V147, P80, DOI 10.1016/j.isprsjprs.2018.11.006
   Kwok TCK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290605.3300721
   Ma LF, 2021, IEEE T INTELL TRANSP, V22, P821, DOI 10.1109/TITS.2019.2961060
   Palka G, 2018, INT J CARTOGRAPHY, V4, P25
   Pope PE, 2019, PROC CVPR IEEE, V0, PP10764, DOI 10.1109/CVPR.2019.01103
   Rudi D, 2020, J MULTIMODAL USER IN, V14, P25, DOI 10.1007/s12193-019-00309-8
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Zhang XD, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3072627
   van t Veer R, 2019, ARXIV, V0, P0
NR 27
TC 0
Z9 0
U1 1
U2 1.0
J9 INTERNATIONAL JOURNAL OF CARTOGRAPHY
PD JUN
PY 2023
VL 0
BP 
EP 
DI 10.1080/23729333.2022.2150379
PG 23
SC COMPUTER SCIENCE; GEOGRAPHY; PHYSICAL GEOGRAPHY; REMOTE SENSING
UT WOS:000911965800001
PM 
ER

PT J
AU Xiao, T
   Ai, Tinghua
   Yu, Huafei
   Yang, Min
   Liu, Pengcheng
TI A point selection method in map generalization using graph convolutional network model
SO CARTOGRAPHY AND GEOGRAPHIC INFORMATION SCIENCE
DE map generalization; point cluster; data-driven; graph convolutional network; context
AB For point clusters, the conflict and crowding of map symbols is an inevitable problem during the transition from large to small scales. The cartographic generalization involved in this problem as a spatial decision-making process is usually related to the analysis of spatial context, the choice of abstraction operators, and the judgment of the resulting data quality. The rules summarized by traditional generalization methods usually require manual setting of conditions or thresholds and sometimes encounter special cases that make it difficult to directly match certain rules or integrate different rules together. An alternative method is using a data-driven strategy under AI technology background to simulate cartographer behaviors through typical sample training, such as deep learning. The integration of cartography domain knowledge and deep learning is a better choice to settle generalization decisions. This study uses a combination of domain knowledge and a data-driven approach to introduce graph neural networks into point cluster generalization. First, we construct a virtual graph structure of point clusters using Delaunay triangulation, secondly, we extract spatial features, contextual features, and attributes of each point separately, and then propose a generalization model based on the TAGCN network. Finally, this model is trained with the manually generalized sample to realize the automatic point cluster generalization. The results demonstrate that the proposed model is valid and efficient for point cluster generalization and that this algorithm can better maintain various characteristics of the point cluster in both the local area and the overall map compared to other methods.
C1 [Xiao, Tianyuan; Ai, Tinghua; Yu, Huafei; Yang, Min] Wuhan Univ, Sch Resource & Environm Sci, Wuhan, Peoples R China.   
[Liu, Pengcheng] Cent China Normal Univ, Coll Urban & Environm Sci, Wuhan, Peoples R China.
RP Ai, TH (corresponding author), Wuhan Univ, Sch Resource & Environm Sci, Wuhan, Peoples R China.
CR Ai TH, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0218877
   Bahari M, 2021, TRANSPORT RES C-EMER, V128, P0, DOI 10.1016/j.trc.2021.103010
   Du J, 2018, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1710.10370
   Du JW, 2022, CARTOGR GEOGR INF SC, V49, P313, DOI 10.1080/15230406.2021.2013944
   Du JW, 2022, GEOCARTO INT, V37, P4158, DOI 10.1080/10106049.2021.1878288
   Feng Y, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8060258
   Goodchild MF, 2018, ANN AM ASSOC GEOGR, V108, P1476, DOI 10.1080/24694452.2017.1416281
   Kang YH, 2019, INT J CARTOGRAPHY, V5, P115, DOI 10.1080/23729333.2019.1615729
   Karsznia I, 2018, CARTOGR GEOGR INF SC, V45, P111, DOI 10.1080/15230406.2016.1274237
   Karsznia I, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040230
   Lalitha V, 2022, MATER TODAY-PROC, V62, P4772, DOI 10.1016/j.matpr.2022.03.341
   Li CM, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0208101
   Liu Y, 2022, ACTA MATER, V238, P0, DOI 10.1016/j.actamat.2022.118195
   Lu XM, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8030105
   Lyu Z, 2022, ISPRS INT J GEO-INF, V11, P0, DOI 10.3390/ijgi11030159
   Qin YF, 2022, NEUROCOMPUTING, V510, P69, DOI 10.1016/j.neucom.2022.09.011
   Radil SM, 2019, INT J GEOGR INF SCI, V33, P1270, DOI 10.1080/13658816.2018.1563299
   Schuster D, 2022, COMPUT IND, V137, P0, DOI 10.1016/j.compind.2022.103612
   Sester M, 2018, ISPRS INT ARCH PHOTO, V42, P565
   Touya G, 2019, INT J CARTOGRAPHY, V5, P142, DOI 10.1080/23729333.2019.1613071
   Wan YY, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2022.102916
   Wang B, 2022, SCI REP-UK, V12, P0, DOI 10.1038/s41598-022-11150-7
   Wang Y, 2022, ISPRS INT J GEO-INF, V11, P0, DOI 10.3390/ijgi11020102
   Wang YQ, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3386252
   Xu XF, 2022, INFORM SCIENCES, V608, P375, DOI 10.1016/j.ins.2022.06.073
   Xu YY, 2022, INT J GEOGR INF SCI, V36, P2009, DOI 10.1080/13658816.2022.2048834
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Yang M, 2022, INT J APPL EARTH OBS, V108, P0, DOI 10.1016/j.jag.2022.102753
   Yang M, 2022, INT J GEOGR INF SCI, V36, P280, DOI 10.1080/13658816.2021.1873998
   Yang W, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18041261
   Yu HF, 2022, INT J APPL EARTH OBS, V107, P0, DOI 10.1016/j.jag.2022.102696
   Yu HF, 2023, EXPERT SYST APPL, V211, P0, DOI 10.1016/j.eswa.2022.118639
   Yu WH, 2022, T GIS, V26, P2302, DOI 10.1111/tgis.12965
   Zhang L, 2022, PATTERN RECOGN, V128, P0, DOI 10.1016/j.patcog.2022.108661
   Zhang Y, 2020, INT J GEOGR INF SCI, V34, P969, DOI 10.1080/13658816.2019.1697879
   Zhao R, 2020, CARTOGR GEOGR INF SC, V47, P400, DOI 10.1080/15230406.2020.1757512
   Zhu YH, 2022, INFORM FUSION, V77, P53, DOI 10.1016/j.inffus.2021.07.013
   [李思倩 Li Siqian], 2019, 地理与地理信息科学 GEOGRAPHY AND GEO-INFORMATION SCIENCE, V35, P1
   [王米琪 Wang Miqi], 2020, 武汉大学学报. 信息科学版 GEOMATICS AND INFORMATION SCIENCE OF WUHAN UNIVERSITY, V45, P1960
   [艾廷华 Al Tinghua], 2021, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V50, P1170
NR 40
TC 0
Z9 0
U1 1
U2 1.0
J9 CARTOGRAPHY AND GEOGRAPHIC INFORMATION SCIENCE
PD JUN
PY 2023
VL 0
BP 
EP 
DI 10.1080/15230406.2023.2187886
PG 21
SC GEOGRAPHY
UT WOS:000950985900001
PM 
ER

PT J
AU Li, P
   Yan, Haowen
   Lu, Xiaomin
TI A Siamese neural network for learning the similarity metrics of linear features
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
DE linear feature; similarity; metric learning; siamese network; linestringnet
AB Measuring similarity is essential for classifying, clustering, retrieving, and matching linear features in geospatial data. However, the complexity of linear features challenges the formalization of characteristics and determination of the weight of each characteristic in similarity measurements. Additionally, traditional methods have limited adaptability to the variety of linear features. To address these challenges, this study proposes a metric learning model that learns similarity metrics directly from linear features. The models ability to learn allows no pre-determined characteristics and supports adaptability to different levels of complex linear features. LineStringNet functions as a feature encoder that maps vector lines to embeddings without format conversion or feature engineering. With a Siamese architecture, the learning process minimizes the contrastive loss, which brings similar pairs closer and pushes dissimilar pairs away in the embedding space. Finally, the proposed model calculates the Euclidean distance to measure the similarity between learned embeddings. Experiments on common linear features and building shapes indicated that the learned similarity metrics effectively supported retrieving, matching, and classifying lines and polygons, with higher precision and accuracy than traditional measures. Furthermore, the model ensures desired metric properties, including rotation and starting point invariances, by adjusting labeling strategies or preprocessing input data.
C1 [Li, Pengbo; Yan, Haowen; Lu, Xiaomin] Lanzhou Jiaotong Univ, Fac Geomat, Lanzhou, Peoples R China.   
[Li, Pengbo; Yan, Haowen; Lu, Xiaomin] Natl Local Joint Engn Res Ctr Technol & Applicat, Lanzhou, Peoples R China.   
[Li, Pengbo; Yan, Haowen; Lu, Xiaomin] Gansu Prov Engn Lab Natl Geog State Monitoring, Lanzhou, Peoples R China.
RP Yan, HW (corresponding author), Lanzhou Jiaotong Univ, Fac Geomat, Lanzhou, Peoples R China.; Yan, HW (corresponding author), Natl Local Joint Engn Res Ctr Technol & Applicat, Lanzhou, Peoples R China.; Yan, HW (corresponding author), Gansu Prov Engn Lab Natl Geog State Monitoring, Lanzhou, Peoples R China.
FU National Natural Science Foundation of China [41930101, 42161066]; 2021 Central-Guided Local Science and Technology Development Fund of Gansu Province: Making and Applications of We-maps Oriented to Public Participation Mapping; LZJTU EP [201806]
CR Feng Y, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8060258
   He K, 2020, P IEEE CVF C COMP VI, V0, P9729
   Kaya M, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11091066
   Li ZX, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7070283
   Liu C, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10100687
   Xu L, 2019, J GEOMATICS SCI TECH, V36, P298
   Xu YY, 2021, INT J GEOGR INF SCI, V35, P847, DOI 10.1080/13658816.2020.1800016
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Yan XF, 2021, INT J GEOGR INF SCI, V35, P490, DOI 10.1080/13658816.2020.1768260
   Zhao R, 2020, CARTOGR GEOGR INF SC, V47, P400, DOI 10.1080/15230406.2020.1757512
   [何海威 He Haiwei], 2018, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V47, P385
   [何海威 He Haiwei], 2020, 武汉大学学报. 信息科学版 GEOMATICS AND INFORMATION SCIENCE OF WUHAN UNIVERSITY, V45, P344
   [程绵绵 Cheng Mianmian], 2019, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V48, P489
   [程绵绵 Cheng Mianmian], 2020, 测绘科学 SCIENCE OF SURVEYING AND MAPPING, V45, P170
NR 14
TC 0
Z9 0
U1 8
U2 8.0
J9 INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
PD MAR
PY 2023
VL 37
BP 684
EP 711
DI 10.1080/13658816.2022.2143505
PG 28
SC COMPUTER SCIENCE; GEOGRAPHY; PHYSICAL GEOGRAPHY; INFORMATION SCIENCE & LIBRARY SCIENCE
UT WOS:000881869600001
PM 
ER

PT J
AU Apostolopoulos, ID
   Groumpos, Peter P
TI Fuzzy Cognitive Maps: Their Role in Explainable Artificial Intelligence
SO APPLIED SCIENCES-BASEL
DE fuzzy cognitive maps; explainable artificial intelligence; interpretability
AB Currently, artificial intelligence is facing several problems with its practical implementation in various application domains. The explainability of advanced artificial intelligence algorithms is a topic of paramount importance, and many discussions have been held recently. Pioneering and classical machine learning and deep learning models behave as black boxes, constraining the logical interpretations that the end users desire. Artificial intelligence applications in industry, medicine, agriculture, and social sciences require the users trust in the systems. Users are always entitled to know why and how each method has made a decision and which factors play a critical role. Otherwise, they will always be wary of using new techniques. This paper discusses the nature of fuzzy cognitive maps (FCMs), a soft computational method to model human knowledge and provide decisions handling uncertainty. Though FCMs are not new to the field, they are evolving and incorporate recent advancements in artificial intelligence, such as learning algorithms and convolutional neural networks. The nature of FCMs reveals their supremacy in transparency, interpretability, transferability, and other aspects of explainable artificial intelligence (XAI) methods. The present study aims to reveal and defend the explainability properties of FCMs and to highlight their successful implementation in many domains. Subsequently, the present study discusses how FCMs cope with XAI directions and presents critical examples from the literature that demonstrate their superiority. The study results demonstrate that FCMs are both in accordance with the XAI directives and have many successful applications in domains such as medical decision-support systems, precision agriculture, energy savings, environmental monitoring, and policy-making for the public sector.
C1 [Apostolopoulos, Ioannis D.] Univ Patras, Sch Med, Dept Med Phys, Patras 26504, Greece.   
[Groumpos, Peter P.] Univ Patras, Dept Elect & Comp Technol Engn, Patras 26504, Greece.
RP Apostolopoulos, ID (corresponding author), Univ Patras, Sch Med, Dept Med Phys, Patras 26504, Greece.
CR Alipour M, 2019, RENEW SUST ENERG REV, V116, P0, DOI 10.1016/j.rser.2019.109410
   Apostolopoulos DJ, 2022, ALGORITHMS, V15, P0, DOI 10.3390/a15120455
   Apostolopoulos ID, 2020, COMPUT METHOD BIOMEC, V23, P879, DOI 10.1080/10255842.2020.1768534
   Apostolopoulos ID, 2021, BIOMED PHYS ENG EXPR, V7, P0, DOI 10.1088/2057-1976/abfd83
   Apostolopoulos ID, 2022, DIAGNOSTICS, V12, P0, DOI 10.3390/diagnostics12102333
   Apostolopoulos ID, 2022, DISEASES-BASEL, V10, P0, DOI 10.3390/diseases10030056
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Asan O, 2021, JMIR HUM FACTORS, V8, P0, DOI 10.2196/28236
   Bahri O, 2020, EURO-MEDITERR J ENVI, V5, P0, DOI 10.1007/s41207-020-0143-8
   Clement T, 2023, MACH LEARN KNOW EXTR, V5, P78, DOI 10.3390/make5010006
   Denton E, 2021, BIG DATA SOC, V8, P0, DOI 10.1177/20539517211035955
   Dwivedi R, 2023, ACM COMPUT SURV, V55, P0, DOI 10.1145/3561048
   Falcone PM, 2020, LAND USE POLICY, V96, P0, DOI 10.1016/j.landusepol.2020.104680
   Felix G, 2019, ARTIF INTELL REV, V52, P1707, DOI 10.1007/s10462-017-9575-1
   Groumpos PP, 2018, STUD INFORM CONTROL, V27, P247, DOI 10.24846/v27i3y201801
   Groumpos Peter P, 2021, RESEARCH ON BIOMEDICAL ENGINEERING, V0, PP749, DOI 10.1007/s42600-021-00182-z
   Haeri SAS, 2019, J CLEAN PROD, V221, P768, DOI 10.1016/j.jclepro.2019.02.193
   Irani Z, 2018, COMPUT OPER RES, V98, P367, DOI 10.1016/j.cor.2017.10.007
   Kokkinos K, 2018, FRONT ENERGY RES, V6, P0, DOI 10.3389/fenrg.2018.00112
   Kornblith S, 2019, PROC CVPR IEEE, V0, PP2656, DOI 10.1109/CVPR.2019.00277
   Langer M, 2021, ARTIF INTELL, V296, P0, DOI 10.1016/j.artint.2021.103473
   Linardatos P, 2021, ENTROPY-SWITZ, V23, P0, DOI 10.3390/e23010018
   Morone P, 2019, J CLEAN PROD, V208, P563, DOI 10.1016/j.jclepro.2018.10.075
   Mpelogianni V, 2018, AI SOC, V33, P175, DOI 10.1007/s00146-018-0813-0
   Napoles G, 2018, STUD FUZZ SOFT COMP, V360, P83, DOI 10.1007/978-3-319-64286-4, 5
   Olazabal M, 2018, SYST RES BEHAV SCI, V35, P791, DOI 10.1002/sres.2519
   Papageorgiou KI, 2019, ALGORITHMS, V12, P0, DOI 10.3390/a12110235
   Phillips PJ, 2020, 4 PRINCIPLES EXPLAIN, V0, P0
   Pisoni G, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11020870
   Speith Timo, 2022, FACCT 22: 2022 ACM CONFERENCE ON FAIRNESS, V0, P0
   Vilone G, 2021, INFORM FUSION, V76, P89, DOI 10.1016/j.inffus.2021.05.009
   Ziv G, 2018, APPL ENERG, V210, P487, DOI 10.1016/j.apenergy.2017.08.033
NR 32
TC 0
Z9 0
U1 2
U2 2.0
J9 APPLIED SCIENCES-BASEL
PD MAR
PY 2023
VL 13
BP 
EP 
DI 10.3390/app13063412
PG 16
SC CHEMISTRY; ENGINEERING; MATERIALS SCIENCE; PHYSICS
UT WOS:000953855200001
PM 
ER

PT J
AU Majstorovic, J
   Giffard-roisin, Sophie
   Poli, Piero
TI Interpreting convolutional neural network decision for earthquake detection with feature map visualization, backward optimization and layer-wise relevance propagation methods
SO GEOPHYSICAL JOURNAL INTERNATIONAL
DE neural networks; fuzzy logic; numerical modelling; time-series analysis; computational seismology
AB In the recent years, the seismological community has adopted deep learning (DL) models for many diverse tasks such as discrimination and classification of seismic events, identification of P- and S-phase wave arrivals or earthquake early warning systems. Numerous models recently developed are showing high accuracy values, and it has been attested for several tasks that DL models perform better than the classical seismological state-of-art models. However, their performances strongly depend on the DL architecture, the training hyperparameters, and the training data sets. Moreover, due to their complex nature, we are unable to understand how the model is learning and therefore how it is making a prediction. Thus, DL models are usually referred to as a black-box. In this study, we propose to apply three complementary techniques to address the interpretability of a convolutional neural network (CNN) model for the earthquake detection. The implemented techniques are: feature map visualization, backward optimization and layer-wise relevance propagation. Since our model reaches a good accuracy performance (97%), we can suppose that the CNN detector model extracts relevant characteristics from the data, however a question remains: can we identify these characteristics? The proposed techniques help to answer the following questions: How is an earthquake processed by a CNN model? What is the optimal earthquake signal according to a CNN? Which parts of the earthquake signal are more relevant for the model to correctly classify an earthquake sample? The answer to these questions help understand why the model works and where it might fail, and whether the model is designed well for the predefined task. The CNN used in this study had been trained for single-station detection, where an input sample is a 25 s three-component waveform. The model outputs a binary target: earthquake (positive) or noise (negative) class. The training database contains a balanced number of samples from both classes. Our results shows that the CNN model correctly learned to recognize where is the earthquake within the sample window, even though the position of the earthquake in the window is not explicitly given during the training. Moreover, we give insights on how a neural network builds its decision process: while some aspects can be linked to clear physical characteristics, such as the frequency content and the P and S waves, we also see how different a DL detection is compared to a visual expertise or an STA/LTA detection. On top of improving our model designs, we also think that understanding how such models work, how they perceive an earthquake, can be useful for the comprehension of events that are not fully understood yet such as tremors or low frequency earthquakes.
C1 [Majstorovic, Josipa; Giffard-Roisin, Sophie; Poli, Piero] Univ Grenoble Alpes, Inst Sci Terre, CNRS, UMR5275, F-38058 Grenoble, France.
RP Majstorovic, J (corresponding author), Univ Grenoble Alpes, Inst Sci Terre, CNRS, UMR5275, F-38058 Grenoble, France.
FU European Research Council (ERC) under the European Union [802777-MONIFAULTS]
CR Anders CJ, 2019, UNDERSTANDING PATCH, V0, P297
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bergen KJ, 2019, SCIENCE, V363, P1299, DOI 10.1126/science.aau0323
   Bohle M, 2019, FRONT AGING NEUROSCI, V11, P0, DOI 10.3389/fnagi.2019.00194
   Charles Z, 2018, PR MACH LEARN RES, V80, P0
   Jozinovic D, 2020, GEOPHYS J INT, V222, P1379, DOI 10.1093/gji/ggaa233
   Kong QK, 2019, SEISMOL RES LETT, V90, P3, DOI 10.1785/0220180259
   Kong QK, 2022, GEOPHYS RES LETT, V49, P0, DOI 10.1029/2022GL098645
   Linardatos P, 2021, ENTROPY-SWITZ, V23, P0, DOI 10.3390/e23010018
   Lomax A, 2019, SEISMOL RES LETT, V90, P517, DOI 10.1785/0220180311
   Magrini F, 2020, ARTIF INTELL, V1, P1, DOI 10.1016/J.AIIG.2020.04.001
   Majstorovic J, 2021, J GEOPHYS RES-SOL EA, V126, P0, DOI 10.1029/2020JB021566
   McGovern A, 2019, B AM METEOROL SOC, V100, P2175, DOI 10.1175/BAMS-D-18-0195.1
   Mignan A, 2020, SEISMOL RES LETT, V91, P2330, DOI 10.1785/0220200021
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Montavon G, 2019, EXPLAINABLE INTERPRE, V0, PP193, DOI 10.1007/978-3-030-28954-6, 10
   Mousavi SM, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-45748-1
   Mousavi SM, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17591-w
   Perol T, 2018, SCI ADV, V4, P0, DOI 10.1126/sciadv.1700578
   Ras G, 2022, J ARTIF INTELL RES, V73, P329
   Roscher R, 2020, IEEE ACCESS, V8, P42200, DOI 10.1109/ACCESS.2020.2976199
   Ross ZE, 2018, B SEISMOL SOC AM, V108, P2894, DOI 10.1785/0120180080
   Saad OM, 2021, J GEOPHYS RES-SOL EA, V126, P0, DOI 10.1029/2020JB021473
   Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483
   Toms BA, 2020, J ADV MODEL EARTH SY, V12, P0, DOI 10.1029/2019MS002002
   Woollam J, 2022, SEISMOL RES LETT, V93, P1695, DOI 10.1785/0220210324
   Wu Y, 2019, IEEE T GEOSCI REMOTE, V57, P62, DOI 10.1109/TGRS.2018.2852302
   Xiao ZW, 2021, J GEOPHYS RES-SOL EA, V126, P0, DOI 10.1029/2020JB021444
   Yang SB, 2021, SEISMOL RES LETT, V92, P246, DOI 10.1785/0220200137
   Zhu WQ, 2019, GEOPHYS J INT, V216, P261, DOI 10.1093/gji/ggy423
NR 30
TC 0
Z9 0
U1 16
U2 16.0
J9 GEOPHYSICAL JOURNAL INTERNATIONAL
PD OCT
PY 2023
VL 232
BP 923
EP 939
DI 10.1093/gji/ggac369
PG 17
SC GEOCHEMISTRY & GEOPHYSICS
UT WOS:000866173400007
PM 
ER

PT J
AU Mai, G
   Jiang, Chiyu
   Sun, Weiwei
   Zhu, Rui
   Xuan, Yao
   Cai, Ling
   Janowicz, Krzysztof
   Ermon, Stefano
   Lao, Ni
TI Towards general-purpose representation learning of polygonal geometries
SO GEOINFORMATICA
DE polygon encoding; non-uniform fourier transformation; shape classification; spatial relation prediction; spatially explicit artificial intelligence
AB Neural network representation learning for spatial data (e.g., points, polylines, polygons, and networks) is a common need for geographic artificial intelligence (GeoAI) problems. In recent years, many advancements have been made in representation learning for points, polylines, and networks, whereas little progress has been made for polygons, especially complex polygonal geometries. In this work, we focus on developing a general-purpose polygon encoding model, which can encode a polygonal geometry (with or without holes, single or multipolygons) into an embedding space. The result embeddings can be leveraged directly (or finetuned) for downstream tasks such as shape classification, spatial relation prediction, building pattern classification, cartographic building generalization, and so on. To achieve model generalizability guarantees, we identify a few desirable properties that the encoder should satisfy: loop origin invariance, trivial vertex invariance, part permutation invariance, and topology awareness. We explore two different designs for the encoder: one derives all representations in the spatial domain and can naturally capture local structures of polygons; the other leverages spectral domain representations and can easily capture global structures of polygons. For the spatial domain approach we propose ResNet1D, a 1D CNN-based polygon encoder, which uses circular padding to achieve loop origin invariance on simple polygons. For the spectral domain approach we develop NUFTspec based on Non-Uniform Fourier Transformation (NUFT), which naturally satisfies all the desired properties. We conduct experiments on two different tasks: 1) polygon shape classification based on the commonly used MNIST dataset; 2) polygon-based spatial relation prediction based on two new datasets (DBSR-46K and DBSR-cplx46K) constructed from OpenStreetMap and DBpedia. Our results show that NUFTspec and ResNet1D outperform multiple existing baselines with significant margins. While ResNet1D suffers from model performance degradation after shape-invariance geometry modifications, NUFTspec is very robust to these modifications due to the nature of the NUFT representation. NUFTspec is able to jointly consider all parts of a multipolygon and their spatial relations during prediction while ResNet1D can recognize the shape details which are sometimes important for classification. This result points to a promising research direction of combining spatial and spectral representations.
C1 [Mai, Gengchen] Univ Georgia, Dept Geog, Spatially Explicit Artificial Intelligence Lab, Athens, GA 30602 USA.   
[Mai, Gengchen; Ermon, Stefano] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.   
[Mai, Gengchen; Zhu, Rui; Cai, Ling; Janowicz, Krzysztof] Univ Calif Santa Barbara, STKO Lab, Santa Barbara, CA 93106 USA.   
[Mai, Gengchen; Zhu, Rui; Cai, Ling; Janowicz, Krzysztof] Univ Calif Santa Barbara, Ctr Spatial Studies, Santa Barbara, CA 93106 USA.   
[Jiang, Chiyu] Univ Calif Berkeley, Dept Mech Engn, Berkeley, CA 94720 USA.   
[Sun, Weiwei] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.   
[Zhu, Rui] Univ Bristol, Sch Geog Sci, Bristol BS8 1TH, Avon, England.   
[Xuan, Yao] Univ Calif Santa Barbara, Dept Math, Santa Barbara, CA 93106 USA.   
[Janowicz, Krzysztof] Univ Vienna, Dept Geog & Reg Res, A-1040 Vienna, Austria.   
[Ermon, Stefano] Chan Zuckerberg Biohub, San Francisco, CA 94158 USA.   
[Lao, Ni] Google, Mountain View, CA 94043 USA.
RP Mai, GC (corresponding author), Univ Georgia, Dept Geog, Spatially Explicit Artificial Intelligence Lab, Athens, GA 30602 USA.; Mai, GC (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.; Mai, GC (corresponding author), Univ Calif Santa Barbara, STKO Lab, Santa Barbara, CA 93106 USA.; Mai, GC (corresponding author), Univ Calif Santa Barbara, Ctr Spatial Studies, Santa Barbara, CA 93106 USA.
FU National Science Foundation [2033521 A1]; Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA) [2021-2011000004]; NSF [1651565]; AFOSR [FA95501910024]; ARO [W911NF-21-1-0125]; Sloan Fellowship; CZ Biohub
CR Appleby G, 2020, AAAI DIGITAL LIB C P, V0, P0
   Baker N, 2018, PLOS COMPUT BIOL, V14, P0, DOI 10.1371/journal.pcbi.1006613
   Bei WJ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19245518
   Cai L, 2019, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE (K-CAP 19), V0, PP131, DOI 10.1145/3360901.3364441
   Cai L, 2020, T GIS, V24, P736, DOI 10.1111/tgis.12644
   David Acuna, 2018, 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION. PROCEEDINGS, V0, PP859, DOI 10.1109/CVPR.2018.00096
   Deng C, 2021, P IEEECVF INT C COMP, V0, P12200
   Esteves C, 2018, LECT NOTES COMPUT SC, V11217, P54, DOI 10.1007/978-3-030-01261-8, 4
   Fan WQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP417, DOI 10.1145/3308558.3313488
   Feng Y, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8060258
   Ha David, 2018, INT C LEARN REPR, V0, P0
   He XJ, 2018, ISPRS J PHOTOGRAMM, V136, P26, DOI 10.1016/j.isprsjprs.2017.12.001
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Janowicz K, 2020, INT J GEOGR INF SCI, V34, P625, DOI 10.1080/13658816.2019.1684500
   Jiang CM, 2019, INT C LEARNING REPRE, V0, P0
   Jiang CY, 2019, IEEE I CONF COMP VIS, V0, PP8768, DOI 10.1109/ICCV.2019.00886
   Kurnianggoro L, 2018, NEUROCOMPUTING, V300, P1, DOI 10.1016/j.neucom.2018.02.093
   Li WW, 2021, ANN AM ASSOC GEOGR, V111, P1887, DOI 10.1080/24694452.2021.1877527
   Li Y, 2019, INT C LEARNING REPRE, V0, P0
   Li YY, 2018, ADV NEUR IN, V31, P0
   Liang Justin, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9128, DOI 10.1109/CVPR42600.2020.00915
   Lin YJ, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), V0, PP359, DOI 10.1145/3274895.3274907
   Liu Y, 2018, INT C LEARNING REPRE, V0, P1
   Mac Aodha O, 2019, IEEE I CONF COMP VIS, V0, PP9595, DOI 10.1109/ICCV.2019.00969
   Mai G, 2020, 8 INT C LEARN REPR, V0, P0
   Mai G, 2021, AGILE GISCIENCE SERI, V2, P1, DOI 10.5194/AGILE-GISS-2-8-2021
   Mai GC, 2020, LECT NOTES GEOINF CA, V0, PP21, DOI 10.1007/978-3-030-14745-7, 2
   Mai GC, 2020, T GIS, V24, P623, DOI 10.1111/tgis.12629
   Mai GC, 2022, INT J GEOGR INF SCI, V36, P639, DOI 10.1080/13658816.2021.2004602
   Mai GM, 2022, P 30 SIGSPATIAL INT, V0, P0, DOI DOI 10.1145/3557915.3561043
   Matthew Tancik, 2020, ARXIV200610739, V33, P7537, DOI 10.48550/ARXIV.2006.10739
   Mildenhall B, 2020, ECCV, V0, PP405, DOI 10.1007/978-3-030-58452-8, 24
   Punjani D, 2018, PROCEEDINGS OF THE 12TH WORKSHOP ON GEOGRAPHIC INFORMATION RETRIEVAL (GIR18), V0, P0, DOI DOI 10.1145/3281354.3281362
   Rao J, 2020, LEIBNIZ INT P INFORM, V0, P0
   Regalia B, 2019, T GIS, V23, P601, DOI 10.1111/tgis.12548
   Rv V, 2018, ARXIV, V0, P0
   Scheider S, 2021, INT J DIGIT EARTH, V14, P1, DOI 10.1080/17538947.2020.1738568
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4, 38
   Wu YK, 2021, AAAI CONF ARTIF INTE, V35, P4478
   Xu YY, 2018, PROC CVPR IEEE, V0, PP5275, DOI 10.1109/CVPR.2018.00553
   Yan B, 2019, T GIS, V23, P620, DOI 10.1111/tgis.12547
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Yan XF, 2021, INT J GEOGR INF SCI, V35, P490, DOI 10.1080/13658816.2020.1768260
   Yan XF, 2022, GEOCARTO INT, V37, P2944, DOI 10.1080/10106049.2020.1856195
   Yu F, 2018, PROC CVPR IEEE, V0, PP2403, DOI 10.1109/CVPR.2018.00255
   Zhang P, 2019, PROC CVPR IEEE, V0, P12085
NR 46
TC 1
Z9 0
U1 8
U2 8.0
J9 GEOINFORMATICA
PD APR
PY 2023
VL 27
BP 289
EP 340
DI 10.1007/s10707-022-00481-2
PG 52
SC COMPUTER SCIENCE; PHYSICAL GEOGRAPHY
UT WOS:000870986700001
PM 
ER

PT J
AU Lin, Z
   Wang, Qianyu
   Lai, Chang
TI Analysis of Airglow Image Classification Based on Feature Map Visualization
SO APPLIED SCIENCES-BASEL
DE airglow images; image classification; convolutional neural network; feature map visualization
AB All-sky airglow imagers (ASAIs) are used in the Meridian Project to observe the airglow in the middle and upper atmosphere to study the atmospheric perturbation. However, the ripples of airglow caused by the perturbation are only visible in the airglow images taken on a clear night. It is a problem to effectively select images suitable for scientific analysis from the enormous amount of airglow images captured under various environments due to the low efficiency and subjectivity of traditional manual classification. We trained a classification model based on convolutional neural network to distinguish between airglow images from clear nights and unclear nights. The data base contains 1688 images selected from the airglow images captured at Xinglong station (40.4 degrees N, 30.5 degrees E). The entire training process was tracked by feature maps which visualized every resulting classification model. The classification models with the clearest feature maps were saved for future use. We cropped the central part of the airglow images to avoid disturbance from the artificial lights at the edge of the vision field according to the feature maps of our first training. The accuracy of the saved model is 99%. The feature maps of five categories also indicate the reliability of the classification model.
C1 [Lin, Zhishuang; Lai, Chang] Chongqing Univ Posts & Telecommun, Sch Sci, Chongqing 400065, Peoples R China.   
[Wang, Qianyu] Univ Oxford, Merton Coll, Oxford OX1 4JD, England.   
[Lai, Chang] Natl Space Sci Ctr, State Key Lab Space Weather, Beijing 100190, Peoples R China.
RP Lai, C (corresponding author), Chongqing Univ Posts & Telecommun, Sch Sci, Chongqing 400065, Peoples R China.; Lai, C (corresponding author), Natl Space Sci Ctr, State Key Lab Space Weather, Beijing 100190, Peoples R China.
FU Science Foundation of Chongqing [cstc2020jcyj-msxmX0914]; Specialized Research Fund for State Key Laboratories
CR Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Dosovitskiy A, 2020, ARXIV, V0, P0
   Figueiredo CAOB, 2018, J GEOPHYS RES-SPACE, V123, P7843, DOI 10.1029/2018JA025438
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Lai C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131516
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Li QZ, 2018, J GEOPHYS RES-SPACE, V123, P2168, DOI 10.1002/2017JA025081
   Linardatos P, 2021, ENTROPY-SWITZ, V23, P0, DOI 10.3390/e23010018
   Mishra J, 2022, MULTIMED TOOLS APPL, V81, P18915, DOI 10.1007/s11042-022-12531-w
   Ramkumar TK, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-89694-3
   Rocha MMM, 2022, MULTIMED TOOLS APPL, V0, P0, DOI DOI 10.1007/s11042-022-14206-y
   Sau S, 2018, ADV SPACE RES, V62, P1762, DOI 10.1016/j.asr.2018.06.039
   Sedlak R, 2021, ATMOS MEAS TECH, V14, P6821, DOI 10.5194/amt-14-6821-2021
   Xu JY, 2021, UPPER ATMOSPHERE DYN, V0, P0
   Yu DH, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20071999
   Zhou C, 2018, J GEOPHYS RES-SPACE, V123, P5195, DOI 10.1029/2018JA025352
NR 17
TC 0
Z9 0
J9 APPLIED SCIENCES-BASEL
PD MAR
PY 2023
VL 13
BP 
EP 
DI 10.3390/app13063671
PG 13
SC CHEMISTRY; ENGINEERING; MATERIALS SCIENCE; PHYSICS
UT WOS:000957417400001
PM 
ER

PT J
AU Li, J
   Xiao, Ningchuan
TI Computational Cartographic Recognition: Identifying Maps, Geographic Regions, and Projections from Images Using Machine Learning
SO ANNALS OF THE AMERICAN ASSOCIATION OF GEOGRAPHERS
DE cartogram; computational cartographic recognition; convolutional neural network; machine learning; map
AB Map reading is a challenging task for computer programs. This article explores how artificial intelligence and machine learning methods can be used to understand maps, an area we broadly refer to as computational cartographic recognition. Specifically, we use machine learning methods to (1) identify whether an image is a map, (2) recognize the geographic region on the map, and (3) recognize the projection used on the map. Four machine learning models-support vector machine, multilayer perceptrons, convolutional neural networks (CNNs) developed from scratch using our own architecture (CNNS), and pretrained CNN models through transfer learning (CNNT)-are applied in these tasks. We use 2,200 online map images, 500 nonmap images, and 1,050 synthetic map images to train and evaluate the models. Results show that the CNNT models achieve the highest performance among all models, with an accuracy rate above 90 percent for the tasks. The CNNS models come in second. We also conduct a round of stress tests using 3,600 additional synthetic maps where the shape and layout are systematically distorted and test if the models can still identify the maps and recognize the region and projection on the maps. The results of the stress tests show that the models can reliably recognize some of the modified maps even when exhibiting performance inferior to even random models for other maps. This unpredictable nature of the methods when applied to maps that are not represented in the training data suggests both promises and limitations of the current machine learning approaches to cartographic recognition.
C1 [Li, Jialin; Xiao, Ningchuan] Ohio State Univ, Dept Geog, Columbus, OH 43210 USA.
RP Li, JL (corresponding author), Ohio State Univ, Dept Geog, Columbus, OH 43210 USA.
CR Ardanuy Mariona Coll, 2020, SIGSPATIAL 20: PROCEEDINGS OF THE 28TH INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS, V0, PP385, DOI 10.1145/3397536.3422236
   Brownlee Jason, 2019, DEEP LEARNING COMPUT, V0, P0
   Coeckelbergh M, 2020, ETHICS, V0, P0
   Dino Hivi Ismat, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED SCIENCE AND ENGINEERING (ICOASE), V0, PP70, DOI 10.1109/ICOASE.2019.8723728
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Firestone C, 2020, P NATL ACAD SCI USA, V117, P26562, DOI 10.1073/pnas.1905334117
   Geron A, 2019, HANDS ON MACHINE LEA, V0, P0
   Janowicz K, 2020, INT J GEOGR INF SCI, V34, P625, DOI 10.1080/13658816.2019.1684500
   Li J, 2019, GEOCOMPUTATION 2019, V0, P0
   Matheny M, 2019, ARTIF INTELL, V0, P0
   Nikolenko SI, 2021, SYNTHETIC DATA DEEP, V0, P0, DOI DOI 10.1007/978-3-030-75178-4, 11
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3234150
   Robinson AC, 2019, CARTOGR GEOGR INF SC, V46, P293, DOI 10.1080/15230406.2018.1484304
   Sang J, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18124272
   Vabalas A, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0224365
   Wang H, 2019, IEEE INTEL TRANSP SY, V11, P82, DOI 10.1109/MITS.2019.2903518
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wang W, 2019, OPT ENG, V58, P0, DOI 10.1117/1.OE.58.4.040901
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Zhang Y, 2018, NPJ COMPUT MATER, V4, P0, DOI 10.1038/s41524-018-0081-z
   Zhou X, 2018, AUTOCARTO 2018, V0, P147
NR 21
TC 0
Z9 0
J9 ANNALS OF THE AMERICAN ASSOCIATION OF GEOGRAPHERS
PD JUN
PY 2023
VL 0
BP 
EP 
DI 10.1080/24694452.2023.2166010
PG 25
SC GEOGRAPHY
UT WOS:000942715400001
PM 
ER

