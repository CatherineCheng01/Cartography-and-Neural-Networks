<?xml version="1.0" encoding="UTF-8"?>
<searchresult>
<query>Global</query>
<document id="1">
<title>TCIANet: Transformer-Based Context Information Aggregation Network for Remote Sensing Image Change Detection</title>
<url>http://dx.doi.org/10.1109/JSTARS.2023.3241157</url>
<snippet>Change detection based on remote sensing data is an important method to detect the earth surface changes. With the development of deep learning, convolutional neural networks have excelled in the field of change detection. However, the existing neural network models are susceptible to external factors in the change detection process, leading to pseudo change and missed detection in the detection results. In order to better achieve the change detection effect and improve the ability to discriminate pseudo change, this article proposes a new method, namely, transformer-based context information aggregation network for remote sensing image change detection. First, we use a filter-based visual tokenizer to segment each temporal feature map into multiple visual semantic tokens. Second, the addition of the progressive sampling vision transformer not only effectively excludes the interference of irrelevant changes, but also uses the transformer encoder to obtain compact spatiotemporal context information in the token set. Then, the tokens containing rich semantic information are fed into the pixel space, and the transformer decoder is used to acquire pixel-level features. In addition, we use the feature fusion module to fuse low-level semantic feature information to complete the extraction of coarse contour information of the changed region. Then, the semantic relationships between object regions and contours are captured by the contour-graph reasoning module to obtain feature maps with complete edge information. Finally, the prediction model is used to discriminate the change of feature information and generate the final change map. Numerous experimental results show that our method has more obvious advantages in visual effect and quantitative evaluation than other methods.
WOS:000940195200003
</snippet>
</document>

<document id="2">
<title>A Hierarchical Deformable Deep Neural Network and an Aerial Image Benchmark Dataset for Surface Multiview Stereo Reconstruction</title>
<url>http://dx.doi.org/10.1109/TGRS.2023.3234694</url>
<snippet>Multiview stereo (MVS) aerial image depth estimation is a research frontier in the remote sensing field. Recent deep learning-based advances in close-range object reconstruction have suggested the great potential of this approach. Meanwhile, the deformation problem and the scale variation issue are also worthy of attention. These characteristics of aerial images limit the applicability of the current methods for aerial image depth estimation. Moreover, there are few available benchmark datasets for aerial image depth estimation. In this regard, this article describes a new benchmark dataset called the LuoJia-MVS dataset (https://irsip.whu.edu.cn/resources/resources_en_v2.php), as well as a new deep neural network known as the hierarchical deformable cascade MVS network (HDC-MVSNet). The LuoJia-MVS dataset contains 7972 five-view images with a spatial resolution of 10 cm, pixel-wise depths, and precise camera parameters, and was generated from an accurate digital surface model (DSM) built from thousands of stereo aerial images. In the HDC-MVSNet network, a new full-scale feature pyramid extraction module, a hierarchical set of 3-D convolutional blocks, and "true 3-D " deformable 3-D convolutional layers are specifically designed by considering the aforementioned characteristics of aerial images. Overall and ablation experiments on the WHU and LuoJia-MVS datasets validated the superiority of HDC-MVSNet over the current state-of-the-art MVS depth estimation methods and confirmed that the newly built dataset can provide an effective benchmark.
WOS:000915822400016
</snippet>
</document>

<document id="3">
<title>Two-dimensional fast imaging of airborne EM data based on U-net</title>
<url>http://dx.doi.org/10.3389/feart.2022.1082876</url>
<snippet>As an efficient geophysical exploration tool, the airborne electromagnetic (AEM) method has been widely used in mineral exploration, geological mapping, environmental and engineering investigation, etc. Currently, the imaging and 1D inversions are the mainstream means for AEM interpretation as the amount of AEM data is huge and 2D and 3D inversions are not efficient. In this paper, we propose a 2D fast imaging method for frequency-domain AEM data based on U-net network. The U-net is a symmetric full-convolution neural network, in which the partial pooling operation between the convolution layers is replaced by the up-sampling operation, while the target location is achieved by skipping connection. This method does not need to consider the complex coupling between the EM responses and underground structures, but instead it establishes a mapping relationship between EM responses and the resistivity model and can quickly achieve accurate imaging of AEM data. We use this network to image both synthetic and field survey data and compare the results with the traditional inversion algorithms. The results show that the U-net imaging have high resolution at high speed that provides a new way for interpreting large amounts of AEM data.
WOS:000919396100001
</snippet>
</document>

<document id="4">
<title>HD2A-Net: A novel dual gated attention network using comprehensive hybrid dilated convolutions for medical image segmentation</title>
<url>http://dx.doi.org/10.1016/j.compbiomed.2022.106384</url>
<snippet>The convolutional neural networks (CNNs) have been widely proposed in the medical image analysis tasks, especially in the image segmentations. In recent years, the encoder-decoder structures, such as the U-Net, were rendered. However, the multi-scale information transmission and effective modeling for long-range feature dependencies in these structures were not sufficiently considered. To improve the performance of the existing methods, we propose a novel hybrid dual dilated attention network (HD2A-Net) to conduct the lesion region segmentations. In the proposed network, we innovatively present the comprehensive hybrid dilated convolution (CHDC) module, which facilitates the transmission of the multi-scale information. Based on the CHDC module and the attention mechanisms, we design a novel dual dilated gated attention (DDGA) block to enhance the saliency of related regions from the multi-scale aspect. Besides, a dilated dense (DD) block is designed to expand the receptive fields. The ablation studies were performed to verify our proposed blocks. Besides, the interpretability of the HD2A-Net was analyzed through the visualization of the attention weight maps from the key blocks. Compared to the state-of-the-art methods including CA-Net, DeepLabV3+, and Attention U-Net, the HD2A-Net outperforms significantly, with the metrics of Dice, Average Symmetric Surface Distance (ASSD), and mean Intersection-over-Union (mIoU) reaching 93.16&#37;, 93.63&#37;, and 94.72&#37;, 0.36 pix, 0.69 pix, and 0.52 pix, and 88.03&#37;, 88.67&#37;, and 90.33&#37; on three publicly available medical image datasets: MAEDE-MAFTOUNI (COVID-19 CT), ISIC-2018 (Melanoma Dermoscopy), and Kvasir-SEG (Gastrointestinal Disease Polyp), respectively.
WOS:000900280100004
</snippet>
</document>

<document id="5">
<title>MC-UNet: Martian Crater Segmentation at Semantic and Instance Levels Using U-Net-Based Convolutional Neural Network</title>
<url>http://dx.doi.org/10.3390/rs15010266</url>
<snippet>Crater recognition on Mars is of paramount importance for many space science applications, such as accurate planetary surface age dating and geological mapping. Such recognition is achieved by means of various image-processing techniques employing traditional CNNs (convolutional neural networks), which typically suffer from slow convergence and relatively low accuracy. In this paper, we propose a novel CNN, referred to as MC-UNet (Martian Crater U-Net), wherein classical U-Net is employed as the backbone for accurate identification of Martian craters at semantic and instance levels from thermal-emission-imaging-system (THEMIS) daytime infrared images. Compared with classical U-Net, the depth of the layers of MC-UNet is expanded to six, while the maximum number of channels is decreased to one-fourth, thereby making the proposed CNN-based architecture computationally efficient while maintaining a high recognition rate of impact craters on Mars. For enhancing the operation of MC-UNet, we adopt average pooling and embed channel attention into the skip-connection process between the encoder and decoder layers at the same network depth so that large-sized Martian craters can be more accurately recognized. The proposed MC-UNet is adequately trained using 2 &amp; SIM;32 km radii Martian craters from THEMIS daytime infrared annotated images. For the predicted Martian crater rim pixels, template matching is subsequently used to recognize Martian craters at the instance level. The experimental results indicate that MC-UNet has the potential to recognize Martian craters with a maximum radius of 31.28 km (136 pixels) with a recall of 0.7916 and F1-score of 0.8355. The promising performance shows that the proposed MC-UNet is on par with or even better than other classical CNN architectures, such as U-Net and Crater U-Net.
WOS:000909721200001
</snippet>
</document>

</searchresult>
