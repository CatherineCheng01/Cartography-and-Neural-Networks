FN Thomson Reuters Web of Scienceâ„¢
VR 1.0
PT J
AU Xu, X
   Li, Jinjiang
   Chen, Zheng
TI TCIANet: Transformer-Based Context Information Aggregation Network for Remote Sensing Image Change Detection
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
DE feature extraction; remote sensing; transformers; semantics; convolutional neural networks; deep learning; visualization; attention mechanism; bitemporal remote sensing images; change detection (cd); graph convolutional network (gcn); transformers
AB Change detection based on remote sensing data is an important method to detect the earth surface changes. With the development of deep learning, convolutional neural networks have excelled in the field of change detection. However, the existing neural network models are susceptible to external factors in the change detection process, leading to pseudo change and missed detection in the detection results. In order to better achieve the change detection effect and improve the ability to discriminate pseudo change, this article proposes a new method, namely, transformer-based context information aggregation network for remote sensing image change detection. First, we use a filter-based visual tokenizer to segment each temporal feature map into multiple visual semantic tokens. Second, the addition of the progressive sampling vision transformer not only effectively excludes the interference of irrelevant changes, but also uses the transformer encoder to obtain compact spatiotemporal context information in the token set. Then, the tokens containing rich semantic information are fed into the pixel space, and the transformer decoder is used to acquire pixel-level features. In addition, we use the feature fusion module to fuse low-level semantic feature information to complete the extraction of coarse contour information of the changed region. Then, the semantic relationships between object regions and contours are captured by the contour-graph reasoning module to obtain feature maps with complete edge information. Finally, the prediction model is used to discriminate the change of feature information and generate the final change map. Numerous experimental results show that our method has more obvious advantages in visual effect and quantitative evaluation than other methods.
C1 [Xu, Xintao] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.   
[Li, Jinjiang; Chen, Zheng] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
FU National Natural Science Foundation of China [62002200, 62202268, 62272281]; Shandong Provincial Science and Technology Support Program of Youth Innovation Team in Colleges [2021KJ069, 2019KJN042]; Shandong Natural Science Foundation of China [ZR2021MF107, ZR2022MA076]; Yantai Science and Technology Innovation Development Plan [2022JCYJ031]
CR Bandara Wele Gedara Chaminda, 2022, IGARSS 2022 - 2022 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, V0, PP207, DOI 10.1109/IGARSS46834.2022.9883686
   Bazi Y, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030516
   Brown TB, 2020, P 34 INT C NEUR INF, V33, P1877
   Carion Nicolas, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12346), V0, PP213, DOI 10.1007/978-3-030-58452-8, 13
   Chen H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101662
   Chen H, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3095166
   Chen HJ, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3227098
   Chen HT, 2021, PROC CVPR IEEE, V0, PP12294, DOI 10.1109/CVPR46437.2021.01212
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen YP, 2019, PROC CVPR IEEE, V0, PP433, DOI 10.1109/CVPR.2019.00052
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Diakogiannis FI, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13183707
   Dong Zhang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12373), V0, PP323, DOI 10.1007/978-3-030-58604-1, 20
   Dosovitskiy A, 2021, P INT C LEARN REPR I, V0, P0
   Fang S, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1145/3510858.3510863
   Feng WQ, 2018, INT J REMOTE SENS, V39, P7998, DOI 10.1080/01431161.2018.1479794
   Feng YC, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3168331
   He J, 2020, IEEE T GEOSCI REMOTE, V58, P165, DOI 10.1109/TGRS.2019.2934760
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030484
   Lebedev M, 2018, INT ARCH PHOTOGRAM R, V42, P565, DOI 10.5194/isprs-archives-XLII-2-565-2018
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li Y, 2018, ADV NEUR IN, V31, P0
   Liu M, 2021, IEEE T GEOSCI REMOTE, V60, P0
   Liu QC, 2021, IEEE T GEOSCI REMOTE, V59, P8657, DOI 10.1109/TGRS.2020.3037361
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Lu P, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111235
   Ma BF, 2022, IEEE SENS J, V22, P3745, DOI 10.1109/JSEN.2021.3139629
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Peng XL, 2021, IEEE T GEOSCI REMOTE, V59, P7296, DOI 10.1109/TGRS.2020.3033009
   Qu J, 2021, IEEE T GEOSCI REMOTE, V60, P0
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Sun L, 2022, IEEE J-STARS, V15, P4045, DOI 10.1109/JSTARS.2022.3175191
   Sun L, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3144158
   Tang X, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3169835
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Wang K, 2022, BIOMED SIGNAL PROCES, V75, P0, DOI 10.1016/j.bspc.2022.103621
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P10532, DOI 10.1109/TGRS.2020.3044054
   Wang YH, 2021, INT J APPL EARTH OBS, V104, P0, DOI 10.1016/j.jag.2021.102582
   Xu JL, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13153053
   Yang FZ, 2020, PROC CVPR IEEE, V0, PP5790, DOI 10.1109/CVPR42600.2020.00583
   Yue XY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), V0, PP377, DOI 10.1109/ICCV48922.2021.00044
   Zerrouki N, 2019, IEEE SENS J, V19, P5843, DOI 10.1109/JSEN.2019.2904137
   Zhang CS, 2018, IEEE J-STARS, V11, P2440, DOI 10.1109/JSTARS.2018.2817121
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang L, 2021, ISPRS J PHOTOGRAMM, V177, P147, DOI 10.1016/j.isprsjprs.2021.05.002
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang X, 2021, IEEE GEOSCI REMOTE S, V19, P0
   Zhang Y, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13081440
   Zhao LQ, 2022, IEEE SENS J, V22, P10890, DOI 10.1109/JSEN.2022.3172132
   Zheng SX, 2021, PROC CVPR IEEE, V0, PP6877, DOI 10.1109/CVPR46437.2021.00681
   Zheng Z, 2021, ISPRS J PHOTOGRAMM, V175, P247, DOI 10.1016/j.isprsjprs.2021.03.005
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5, 1
   de Bem PP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060901
NR 56
TC 0
Z9 0
U1 16
U2 16.0
J9 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
PD JUN
PY 2023
VL 16
BP 1951
EP 1971
DI 10.1109/JSTARS.2023.3241157
PG 21
SC ENGINEERING; PHYSICAL GEOGRAPHY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000940195200003
PM 
ER

PT J
AU Li, J
   Huang, Xin
   Feng, Yujin
   Ji, Zhen
   Zhang, Shulei
   Wen, Dawei
TI A Hierarchical Deformable Deep Neural Network and an Aerial Image Benchmark Dataset for Surface Multiview Stereo Reconstruction
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
DE deep learning; depth map-based stereo recon-struction; digital surface model (dsm); multiview stereo (mvs) reconstruction
AB Multiview stereo (MVS) aerial image depth estimation is a research frontier in the remote sensing field. Recent deep learning-based advances in close-range object reconstruction have suggested the great potential of this approach. Meanwhile, the deformation problem and the scale variation issue are also worthy of attention. These characteristics of aerial images limit the applicability of the current methods for aerial image depth estimation. Moreover, there are few available benchmark datasets for aerial image depth estimation. In this regard, this article describes a new benchmark dataset called the LuoJia-MVS dataset (https://irsip.whu.edu.cn/resources/resources_en_v2.php), as well as a new deep neural network known as the hierarchical deformable cascade MVS network (HDC-MVSNet). The LuoJia-MVS dataset contains 7972 five-view images with a spatial resolution of 10 cm, pixel-wise depths, and precise camera parameters, and was generated from an accurate digital surface model (DSM) built from thousands of stereo aerial images. In the HDC-MVSNet network, a new full-scale feature pyramid extraction module, a hierarchical set of 3-D convolutional blocks, and "true 3-D " deformable 3-D convolutional layers are specifically designed by considering the aforementioned characteristics of aerial images. Overall and ablation experiments on the WHU and LuoJia-MVS datasets validated the superiority of HDC-MVSNet over the current state-of-the-art MVS depth estimation methods and confirmed that the newly built dataset can provide an effective benchmark.
C1 [Li, Jiayi] Hubei Luojia Lab, Wuhan 430079, Peoples R China.   
[Li, Jiayi] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.   
[Huang, Xin] Wuhan Univ, Sch Remote Sensing & Informat Engi neering, Hubei Luojia Lab, Wuhan 430079, Peoples R China.   
[Huang, Xin] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & Re, Wuhan 430079, Peoples R China.   
[Feng, Yujin; Ji, Zhen; Zhang, Shulei] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.   
[Wen, Dawei] Wuhan Inst Technol, Sch Comp Sci & Engn, Wuhan 430070, Peoples R China.
RP Huang, X (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engi neering, Hubei Luojia Lab, Wuhan 430079, Peoples R China.
FU Special Fund of the Hubei Luojia Laboratory; National Natural Science Foundation of China [42071311, 41971295]; Foundation forInnovative Research Groups of the Natural Science Foundation of Hubei Province [2020CFA003]; Wuhan 2022 Dawning Project [2022010801020123]; Wuhan University Experiment Technology Project [WHU-2020-SYJS-0007]
CR Beyer RA, 2018, EARTH SPACE SCI, V5, P537, DOI 10.1029/2018EA000409
   Chen R, 2019, IEEE I CONF COMP VIS, V0, PP1538, DOI 10.1109/ICCV.2019.00162
   Gu XD, 2020, PROC CVPR IEEE, V0, PP2492, DOI 10.1109/CVPR42600.2020.00257
   Huang HM, 2020, INT CONF ACOUST SPEE, V0, PP1055, DOI 10.1109/ICASSP40776.2020.9053405
   Huang X, 2021, IEEE T GEOSCI REMOTE, V59, P10266, DOI 10.1109/TGRS.2020.3037211
   Jianfeng Yan, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12349), V0, PP674, DOI 10.1007/978-3-030-58548-8, 39
   Laga H, 2022, IEEE T PATTERN ANAL, V44, P1738, DOI 10.1109/TPAMI.2020.3032602
   Li JY, 2019, NATL SCI REV, V6, P1082, DOI 10.1093/nsr/nwz058
   Liu J, 2020, PROC CVPR IEEE, V0, PP6049, DOI 10.1109/CVPR42600.2020.00609
   Luo KY, 2019, IEEE I CONF COMP VIS, V0, PP10451, DOI 10.1109/ICCV.2019.01055
   Mahato M, 2019, IEEE T GEOSCI REMOTE, V57, P3341, DOI 10.1109/TGRS.2018.2883483
   Rao ZB, 2021, IEEE T GEOSCI REMOTE, V59, P6138, DOI 10.1109/TGRS.2020.3029527
   Sun K, 2019, PROC CVPR IEEE, V0, PP5686, DOI 10.1109/CVPR.2019.00584
   Wang FJ, 2021, PROC CVPR IEEE, V0, PP14189, DOI 10.1109/CVPR46437.2021.01397
   Wang Y, 2022, PROC CVPR IEEE, V0, P19809
   Weilharter R, 2021, IEEE ACCESS, V9, P11306, DOI 10.1109/ACCESS.2021.3050556
   Xu Y, 2022, GEOSPATIAL INFORM SC, V0, P1
   Yang JY, 2020, PROC CVPR IEEE, V0, PP4876, DOI 10.1109/CVPR42600.2020.00493
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3, 47
   Yao Y, 2019, PROC CVPR IEEE, V0, PP5520, DOI 10.1109/CVPR.2019.00567
   Yao Y, 2020, PROC CVPR IEEE, V0, PP1787, DOI 10.1109/CVPR42600.2020.00186
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P1500, DOI 10.1109/LSP.2020.3013518
   Yu DW, 2021, ISPRS J PHOTOGRAMM, V171, P155, DOI 10.1016/j.isprsjprs.2020.11.011
   Yu ZH, 2020, PROC CVPR IEEE, V0, PP1946, DOI 10.1109/CVPR42600.2020.00202
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5, 1
   Zhu QT, 2021, ARXIV, V0, P0
   Zhu XZ, 2019, PROC CVPR IEEE, V0, PP9300, DOI 10.1109/CVPR.2019.00953
NR 27
TC 0
Z9 0
U1 8
U2 8.0
J9 IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
PD JUN
PY 2023
VL 61
BP 
EP 
DI 10.1109/TGRS.2023.3234694
PG 12
SC GEOCHEMISTRY & GEOPHYSICS; ENGINEERING; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000915822400016
PM 
ER

PT J
AU Liu, Q
   Yin, Changchun
   Su, Yang
   Liu, Yunhe
   Wang, Luyuan
   Liang, Hao
   Wang, Han
TI Two-dimensional fast imaging of airborne EM data based on U-net
SO FRONTIERS IN EARTH SCIENCE
DE airborne em; frequency-domain; neural networks; u-net; full convolution
AB As an efficient geophysical exploration tool, the airborne electromagnetic (AEM) method has been widely used in mineral exploration, geological mapping, environmental and engineering investigation, etc. Currently, the imaging and 1D inversions are the mainstream means for AEM interpretation as the amount of AEM data is huge and 2D and 3D inversions are not efficient. In this paper, we propose a 2D fast imaging method for frequency-domain AEM data based on U-net network. The U-net is a symmetric full-convolution neural network, in which the partial pooling operation between the convolution layers is replaced by the up-sampling operation, while the target location is achieved by skipping connection. This method does not need to consider the complex coupling between the EM responses and underground structures, but instead it establishes a mapping relationship between EM responses and the resistivity model and can quickly achieve accurate imaging of AEM data. We use this network to image both synthetic and field survey data and compare the results with the traditional inversion algorithms. The results show that the U-net imaging have high resolution at high speed that provides a new way for interpreting large amounts of AEM data.
C1 [Liu, Qiang; Yin, Changchun; Su, Yang; Liu, Yunhe; Wang, Luyuan; Liang, Hao; Wang, Han] Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun, Peoples R China.
RP Yin, CC (corresponding author), Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun, Peoples R China.
FU National Natural Science Foundation of China [42030806]; National Key R&D Program of China [2021YFB3202104]
CR Gao ZH, 2018, APPL GEOPHYS, V15, P318, DOI 10.1007/s11770-018-0684-7
   Haber E, 2019, ASEG EXTENDED ABSTRA, V2019, P1, DOI 10.1080/22020586.2019.12072978
   Huang HM, 2020, INT CONF ACOUST SPEE, V0, PP1055, DOI 10.1109/ICASSP40776.2020.9053405
   Iturraran-Viveros U, 2021, PURE APPL GEOPHYS, V178, P423, DOI 10.1007/s00024-021-02655-9
   Li JF, 2020, GEOPHYSICS, V85, PE163, DOI 10.1190/GEO2019-0015.1
   Liu B, 2020, IEEE T GEOSCI REMOTE, V58, P5715, DOI 10.1109/TGRS.2020.2969040
   Liu YH, 2018, GEOPHYS J INT, V213, P1, DOI 10.1093/gji/ggx545
   Noh K, 2020, EXPLOR GEOPHYS, V51, P214, DOI 10.1080/08123985.2019.1668240
   Puzyrev V, 2019, GEOPHYS J INT, V218, P817, DOI 10.1093/gji/ggz204
   Ronning JS, 2020, NGU REPORT 2019031, V0, P0, DOI DOI 10.13140/RG.2.2.31573.17126
   Wang J, 2021, APPL GEOPHYS, V18, P199, DOI 10.1007/s11770-021-0894-2
   Yang FS, 2019, GEOPHYSICS, V84, PR585, DOI 10.1190/GEO2018-0249.1
   Yu SW, 2021, REV GEOPHYS, V59, P0, DOI 10.1029/2021RG000742
   Zhu WQ, 2019, GEOPHYS J INT, V216, P261, DOI 10.1093/gji/ggy423
NR 14
TC 0
Z9 0
U1 5
U2 5.0
J9 FRONTIERS IN EARTH SCIENCE
PD JAN
PY 2023
VL 10
BP 
EP 
DI 10.3389/feart.2022.1082876
PG 13
SC GEOLOGY
UT WOS:000919396100001
PM 
ER

PT J
AU Cui, R
   Yang, Runzhuo
   Liu, Feng
   Geng, Hua
TI HD2A-Net: A novel dual gated attention network using comprehensive hybrid dilated convolutions for medical image segmentation
SO COMPUTERS IN BIOLOGY AND MEDICINE
DE medical image segmentation; deep neural network; comprehensive hybrid dilated convolution; dual dilated gated attention; dilated dense block
AB The convolutional neural networks (CNNs) have been widely proposed in the medical image analysis tasks, especially in the image segmentations. In recent years, the encoder-decoder structures, such as the U-Net, were rendered. However, the multi-scale information transmission and effective modeling for long-range feature dependencies in these structures were not sufficiently considered. To improve the performance of the existing methods, we propose a novel hybrid dual dilated attention network (HD2A-Net) to conduct the lesion region segmentations. In the proposed network, we innovatively present the comprehensive hybrid dilated convolution (CHDC) module, which facilitates the transmission of the multi-scale information. Based on the CHDC module and the attention mechanisms, we design a novel dual dilated gated attention (DDGA) block to enhance the saliency of related regions from the multi-scale aspect. Besides, a dilated dense (DD) block is designed to expand the receptive fields. The ablation studies were performed to verify our proposed blocks. Besides, the interpretability of the HD2A-Net was analyzed through the visualization of the attention weight maps from the key blocks. Compared to the state-of-the-art methods including CA-Net, DeepLabV3+, and Attention U-Net, the HD2A-Net outperforms significantly, with the metrics of Dice, Average Symmetric Surface Distance (ASSD), and mean Intersection-over-Union (mIoU) reaching 93.16%, 93.63%, and 94.72%, 0.36 pix, 0.69 pix, and 0.52 pix, and 88.03%, 88.67%, and 90.33% on three publicly available medical image datasets: MAEDE-MAFTOUNI (COVID-19 CT), ISIC-2018 (Melanoma Dermoscopy), and Kvasir-SEG (Gastrointestinal Disease Polyp), respectively.
C1 [Cui, Rongsheng; Yang, Runzhuo; Liu, Feng] Nankai Univ, Coll Elect Informat & Opt Engn, Tianjin, Peoples R China.   
[Liu, Feng] Nankai Univ, Tianjin Key Lab Optoelect Sensor & Sensing Network, Tianjin, Peoples R China.   
[Geng, Hua] Tianjin Chest Hosp, Dept Pathol, Tianjin, Peoples R China.
RP Liu, F (corresponding author), Nankai Univ, Coll Elect Informat & Opt Engn, Tianjin, Peoples R China.
FU National Natural Science Foun-dation of China; Natural Science Foun-dation of Tianjin City of Peoples Republic of China;  [61901233];  [19JC-QNJC00900];  [21JCZDJC00340]
CR Ahmadianfar I, 2021, EXPERT SYST APPL, V181, P0, DOI 10.1016/j.eswa.2021.115079
   Alkassar S, 2020, 2 INT C ELECT COMMUN, V0, P188
   Bui TD, 2019, BIOMED SIGNAL PROCES, V54, P0, DOI 10.1016/j.bspc.2019.101613
   Chartsias A, 2021, IEEE T MED IMAGING, V40, P781, DOI 10.1109/TMI.2020.3036584
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2, 49
   Cui ZH, 2018, IEEE T IND INFORM, V14, P3187, DOI 10.1109/TII.2018.2822680
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Gegundez-Arias ME, 2021, COMPUT METH PROG BIO, V205, P0, DOI 10.1016/j.cmpb.2021.106081
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   He BJ, 2022, EXPERT SYST, V39, P0, DOI 10.1111/exsy.12822
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hu KL, 2022, COMPUT BIOL MED, V147, P0, DOI 10.1016/j.compbiomed.2022.105760
   Huang HM, 2020, INT CONF ACOUST SPEE, V0, PP1055, DOI 10.1109/ICASSP40776.2020.9053405
   Li KP, 2018, PROC CVPR IEEE, V0, PP9215, DOI 10.1109/CVPR.2018.00960
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Oktay O, 2018, ARXIV180403999, V0, P0
   Qi AL, 2022, COMPUT BIOL MED, V148, P0, DOI 10.1016/j.compbiomed.2022.105810
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1, 48
   Su H, 2022, COMPUT BIOL MED, V146, P0, DOI 10.1016/j.compbiomed.2022.105618
   Tajbakhsh N, 2020, MED IMAGE ANAL, V63, P0, DOI 10.1016/j.media.2020.101693
   Tanveer M, 2022, IEEE J BIOMED HEALTH, V26, P1453, DOI 10.1109/JBHI.2021.3083274
   Tu J, 2021, J BIONIC ENG, V18, P674, DOI 10.1007/s42235-021-0050-y
   Valanarasu JMJ, 2021, MEDICAL TRANSFORMER, V0, P0
   Wang GG, 2018, INT J BIO-INSPIR COM, V12, P1, DOI 10.1504/IJBIC.2015.10004283
   Wang GG, 2018, MEMET COMPUT, V10, P151, DOI 10.1007/s12293-016-0212-3
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wang GG, 2022, IEEE T IND INFORM, V18, P8519, DOI 10.1109/TII.2022.3165636
   Wang PQ, 2018, IEEE WINT CONF APPL, V0, PP1451, DOI 10.1109/WACV.2018.00163
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Wang WX, 2022, KSII T INTERNET INF, V16, P211, DOI 10.3837/tiis.2022.01.012
   Wang Y, 2022, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-022-03766-4
   Yang QH, 2022, BIOMED SIGNAL PROCES, V77, P0, DOI 10.1016/j.bspc.2022.103805
   Yang SD, 2021, BIOMED SIGNAL PROCES, V70, P0, DOI 10.1016/j.bspc.2021.103027
   Yang YT, 2021, EXPERT SYST APPL, V177, P0, DOI 10.1016/j.eswa.2021.114864
   Zhang CR, 2022, BIOMED SIGNAL PROCES, V73, P0, DOI 10.1016/j.bspc.2021.103423
   Zhou LC, 2018, IEEE COMPUT SOC CONF, V0, PP192, DOI 10.1109/CVPRW.2018.00034
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5, 1
   [Anonymous], 2021, PYTORCH 1 11 0 GPU P, V0, P0
   [Anonymous], 2022, COVID 19 CT LUNG INF, V0, P0
   [Anonymous], 2022, ISIC 2018 DATASET, V0, P0
   [Anonymous], 2022, KVASIR SEG DATASET, V0, P0
   van Sloun RJG, 2021, IEEE T MED IMAGING, V40, P829, DOI 10.1109/TMI.2020.3037790
NR 42
TC 0
Z9 0
U1 7
U2 7.0
J9 COMPUTERS IN BIOLOGY AND MEDICINE
PD JAN
PY 2023
VL 152
BP 
EP 
DI 10.1016/j.compbiomed.2022.106384
PG 12
SC LIFE SCIENCES & BIOMEDICINE - OTHER TOPICS; COMPUTER SCIENCE; ENGINEERING; MATHEMATICAL & COMPUTATIONAL BIOLOGY
UT WOS:000900280100004
PM 36493731
ER

PT J
AU Chen, D
   Hu, Fan
   Mathiopoulos, P Takis
   Zhang, Zhenxin
   Peethambaran, Jiju
TI MC-UNet: Martian Crater Segmentation at Semantic and Instance Levels Using U-Net-Based Convolutional Neural Network
SO REMOTE SENSING
DE martian craters; crater recognition; semantic segmentation; instance-level segmentation; u-net; template matching
AB Crater recognition on Mars is of paramount importance for many space science applications, such as accurate planetary surface age dating and geological mapping. Such recognition is achieved by means of various image-processing techniques employing traditional CNNs (convolutional neural networks), which typically suffer from slow convergence and relatively low accuracy. In this paper, we propose a novel CNN, referred to as MC-UNet (Martian Crater U-Net), wherein classical U-Net is employed as the backbone for accurate identification of Martian craters at semantic and instance levels from thermal-emission-imaging-system (THEMIS) daytime infrared images. Compared with classical U-Net, the depth of the layers of MC-UNet is expanded to six, while the maximum number of channels is decreased to one-fourth, thereby making the proposed CNN-based architecture computationally efficient while maintaining a high recognition rate of impact craters on Mars. For enhancing the operation of MC-UNet, we adopt average pooling and embed channel attention into the skip-connection process between the encoder and decoder layers at the same network depth so that large-sized Martian craters can be more accurately recognized. The proposed MC-UNet is adequately trained using 2 & SIM;32 km radii Martian craters from THEMIS daytime infrared annotated images. For the predicted Martian crater rim pixels, template matching is subsequently used to recognize Martian craters at the instance level. The experimental results indicate that MC-UNet has the potential to recognize Martian craters with a maximum radius of 31.28 km (136 pixels) with a recall of 0.7916 and F1-score of 0.8355. The promising performance shows that the proposed MC-UNet is on par with or even better than other classical CNN architectures, such as U-Net and Crater U-Net.
C1 [Chen, Dong; Hu, Fan] Nanjing Forestry Univ, Coll Civil Engn, Nanjing 210037, Peoples R China.   
[Mathiopoulos, P. Takis] Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece.   
[Zhang, Zhenxin] Capital Normal Univ, Coll Resource Environm & Tourism, Beijing 100048, Peoples R China.   
[Peethambaran, Jiju] St Marys Univ, Dept Math & Comp Sci, Halifax, NS B3P 2M6, Canada.
RP Zhang, ZX (corresponding author), Capital Normal Univ, Coll Resource Environm & Tourism, Beijing 100048, Peoples R China.
FU National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Qinglan Project of Jiangsu Province, China; Key Laboratory of Land Satellite Remote-Sensing Applications, Ministry of Natural Resources of the Peoples Republic of China;  [42271450];  [41971415];  [42071445];  [BK20201387];  [KLSMNR-G202209]
CR DeLatte DM, 2019, IEEE J-STARS, V12, P2944, DOI 10.1109/JSTARS.2019.2918302
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Heidler K, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3064606
   Hong ZH, 2022, SENSOR MATER, V34, P237, DOI 10.18494/SAM3564
   Jia YT, 2021, IEEE ACCESS, V9, P44107, DOI 10.1109/ACCESS.2021.3066445
   Lagain A, 2021, NAT COMMUN, V12, P0, DOI 10.1038/s41467-021-26648-3
   Oktay O, 2018, ARXIV180403999, V0, P0
   Pan L, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-12162-0
   Saeedizadeh Narges, 2021, COMPUT METHODS PROGRAMS BIOMED UPDATE, V1, P100007, DOI 10.1016/j.cmpbup.2021.100007
   Silburt A, 2019, ICARUS, V317, P27, DOI 10.1016/j.icarus.2018.06.022
   Smith DE, 2022, PLANET SCI J, V3, P0, DOI 10.3847/PSJ/ac8c39
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Udry A, 2020, J GEOPHYS RES-PLANET, V125, P0, DOI 10.1029/2020JE006523
   Wang RJ, 2018, ADV NEUR IN, V31, P0
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2, 1
   Yahyatabar M, 2020, IEEE ENG MED BIO, V0, PP1242, DOI 10.1109/EMBC44109.2020.9176033
   Yang XF, 2019, IEEE IJCNN, V0, P0
   Yu MY, 2022, SENSORS-BASEL, V22, P0, DOI 10.3390/s22082932
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5, 1
NR 19
TC 1
Z9 0
U1 6
U2 6.0
J9 REMOTE SENSING
PD JAN
PY 2023
VL 15
BP 
EP 
DI 10.3390/rs15010266
PG 26
SC ENVIRONMENTAL SCIENCES & ECOLOGY; GEOLOGY; REMOTE SENSING; IMAGING SCIENCE & PHOTOGRAPHIC TECHNOLOGY
UT WOS:000909721200001
PM 
ER

