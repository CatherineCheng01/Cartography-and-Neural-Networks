
PT J
AU Zeng, CY
   Zhang, F
   Luo, MZ
AF Zeng, Chunying
   Zhang, Fan
   Luo, Mingzhong
TI A deep neural network-based decision support system for intelligent geospatial data analysis in intelligent agriculture system
SO SOFT COMPUTING
LA English
DT Article
DE Agricultural informatization; Geographic spatial data; Neural network; Grey decision system; Prediction model
ID internet; things
AB Agriculture is an important field for most of the countries, as it is the primary source of food production, and has a great role in growing the economy of a country. The world's population is increasing with a faster speed, and as a result, the need for food is rapidly increasing. Farmers' traditional techniques are insufficient to meet the rising demand of food. The agriculture sector faces various challenges such as producing more and better products while enhancing the sustainability through the smart use of natural resources, minimizing environmental harm, and adapting to the climate change. Agricultural informatization is the inevitable trend of modern agricultural development. The purpose of introducing information technology into agriculture is to save production costs, improve production efficiency, and accelerate the development of productivity. Agricultural informatization is an intelligent, digital, and a networked-based system. Geographic information system technology is widely used in agriculture, such as precision agriculture, land resource management, crop yield estimation and monitoring, and soil and water conservation. The characteristic of expert decision-making system is the logical reasoning of knowledge, and the advantage of neural network is the acquisition of knowledge. Therefore, the study of the organic combination of neural network and expert decision-making system technology is of a great significance to the research of integrated system righteousness. In this paper, the agricultural data obtained from the expert database are displayed in the form of a tree list and are used in the process of system design. The geospatial data can be uploaded through the map loading function, find the map path, and easily uploaded by modifying the expert database. In order to realize the scalability of the platform, we transplanted the analysis objects to other provinces and cities. Further, the grey decision-making system and back-propagation neural network (BPNN) prediction models are used to predict the future indicators of agricultural data. Based on the historical data of agricultural economic indicators, the effect of predicting the future value of agricultural indicators by using grey decision-making system and neural network models is repeatedly tested. The experimental result shows that the BPNN model performed really well in terms of prediction accuracy and relative error rate as compared to the grey decision-making system.
C1 [Zeng, Chunying] Guangdong Acad Agr Sci, Inst Agr Econ & Informat, Key Lab Urban Agr South China, Guangzhou 510640, Peoples R China.
   [Zhang, Fan] Nanjing Univ Finance & Econ, Sch Management, Nanjing 210023, Peoples R China.
   [Zeng, Chunying; Luo, Mingzhong] South China Agr Univ, Guangzhou 510640, Peoples R China.
C3 Guangdong Academy of Agricultural Sciences; Nanjing University of Finance & Economics; South China Agricultural University
RP Luo, MZ (corresponding author), South China Agr Univ, Guangzhou 510640, Peoples R China.
EM dg1602037@smail.nju.edu.cn
FU Philosophy and Social Science project of Guangdong Province [GD20XGL35]; Innovation Fund project of Guangdong Academy of Agricultural Sciences [202213]
CR Arshad J, 2022, SUSTAINABILITY-BASEL, V14, P0, DOI 10.3390/su14020827
   Chaudhuri, 2009, AM EURASIAN J SUSTAI, V0, P0
   Chen TE, 2008, COMPUTER ENG DESIGN, V0, P0
   Chen XH, 2015, CHINESE J ANIMAL SCI, V0, P0
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Chu QQ, 2003, REV CHINA AGR SCI TE, V0, P0
   Fan XL, 2012, J AGR SCI TECH-IRAN, V0, P0
   FAO, 2009, GLOB AGR 2050 HIGH L, V0, P0
   Feng XD., 1998, SYST ENG THEORY PRAC, V1, P5
   Gao N, 2003, THESIS ANHUI AGR U, V0, P0
   Gore A, 1999, PHOTOGRAMM ENG REM S, V65, P528
   He Yong, 2005, TRANSACTIONS OF THE CHINESE SOCIETY OF AGRICULTURAL ENGINEERING, V21, P110
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Khan R, 2021, IEEE SENS J, V21, P17492, DOI 10.1109/JSEN.2020.3012511
   Lamb A, 2016, NAT CLIM CHANGE, V6, P488, DOI 10.1038/NCLIMATE2910
   Li, 2000, MINE SURVEYING, V0, P0
   Liakos KG, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18082674
   Liang Y., 2002, J GEOSPATIAL INF SCI, V5, P6
   Lu XY., 2004, T CHIN SOC AGR ENG, V7, P117
   Morota G, 2018, J ANIM SCI, V96, P1540, DOI 10.1093/jas/sky014
   Shen S, 2010, AGRIC AGRIC SCI PROC, V1, P42, DOI 10.1016/j.aaspro.2010.09.006
   Tzounis A, 2017, BIOSYST ENG, V164, P31, DOI 10.1016/j.biosystemseng.2017.09.007
   Xi L., 2012, DISTRIBUTED METADATA, V0, P0
   Xiang X., 2009, ZIGBEE WIRELESS SENS, V0, P0
   Yang GJ, 2020, IEEE ACCESS, V8, P124382, DOI 10.1109/ACCESS.2020.3006036
   Zhang NQ, 2002, COMPUT ELECTRON AGR, V36, P113, DOI 10.1016/S0168-1699(02)00096-0
   Zhang QW., 2003, PRELIMINARY DISCUSSI, V0, P0
   Zhao Q., 2011, I POLICY SUPPORT AGR, V0, P0, DOI DOI 10.1007/978-3-642-19128-2_9
   Zhu T, 2007, LECT NOTE COMPUT SCI, V0, P0
   Zhu Z, 2009, WRI WORLD C SOFTWARE, V0, P0
NR 30
TC 3
Z9 3
U1 4
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD OCT 15
PY 2022
VL 26
IS 20
BP 10813
EP 10826
DI 10.1007/s00500-022-07018-7
EA MAY 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA 4S0NH
UT WOS:000790265200002
DA 2023-04-26
ER

PT J
AU Bin, OK
   Hooi, YK
   Kadir, SJA
   Fujita, H
   Rosli, LH
AF Bin, Ong Kai
   Hooi, Yew Kwang
   Kadir, Said Jadid Abdul
   Fujita, Haruhiro
   Rosli, Luqman Hakim
TI Enhanced Symbol Recognition based on Advanced Data Augmentation for Engineering Diagrams
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Symbol recognition; symbol spotting; engineering drawing; convolution neural network (CNN); CycleGAN; piping and instrument diagram (P&ID)
ID complex
AB Symbol recognition has generated research interest for image analytics of engineering diagrams. Techniques including structural, syntactic, statistical, Convolution Neural Network (CNN) were studied to identify gaps of research. Despite popularity, CNN requires huge learning dataset, which often involves costly procurement. To address this, combination between CycleGAN and CNN is proposed. CycleGAN generates more learning dataset synthetically, thus yielding opportunity to improve accuracy of symbol recognition. In the domain of for engineering symbols, standard CNN model is developed and used in experimental testing. Different ratios of training dataset were tested in multiple experiments using Piping and Instrument Diagram (P&IDs) drawings. Result of highest accuracy for symbol recognition is up to 92.85% against baseline and other method. The results determined that gradual reduction of training samples, the effectiveness of recognition accuracy performance after using proposed method was remained substantially stable.
C1 [Bin, Ong Kai; Hooi, Yew Kwang; Kadir, Said Jadid Abdul; Rosli, Luqman Hakim] Univ Teknol PETRONAS, Dept Comp & Informat Sci, Seri Iskandar, Perak, Malaysia.
   [Fujita, Haruhiro] Niigata Univ Int & Informat Studies, Fac Managem & Informat Sci, Niigata, Japan.
C3 Universiti Teknologi Petronas; Niigata University
RP Bin, OK (corresponding author), Univ Teknol PETRONAS, Dept Comp & Informat Sci, Seri Iskandar, Perak, Malaysia.
FU Universiti Teknologi PETRONAS, under the Yayasan Universiti Teknologi PETRONAS (YUTP) Fundamental Research Grant Scheme [YUTP-FRG/015LC0-280]
CR [Anonymous], 2018, DOCUMENT IMAGE ANAL, V0, P0
   Delalandre M, 2004, LECT NOTES COMPUT SC, V3138, P425
   Elyan E, 2020, NEURAL NETWORKS, V129, P91, DOI 10.1016/j.neunet.2020.05.025
   Elyan E, 2018, IEEE IJCNN, V0, P0
   Fang W, 2018, CMC-COMPUT MATER CON, V57, P167, DOI 10.32604/cmc.2018.02356
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Han C., 2019, P 28 ACM INT C INF, V0, P0
   Kim H, 2021, EXPERT SYST APPL, V183, P0, DOI 10.1016/j.eswa.2021.115337
   Liu Jianfei, 2020, MED IMAGE COMPUT COMPUT ASSIST INTERV, V12262, P760, DOI 10.1007/978-3-030-59713-9_73
   Liu SH, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP2445, DOI 10.1145/3394171.3413526
   Moreno-Garcia CF, 2019, NEURAL COMPUT APPL, V31, P1695, DOI 10.1007/s00521-018-3583-1
   Nan SP, 2021, OPT MEMORY NEURAL, V30, P67, DOI 10.3103/S1060992X21010069
   Park M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223715
   Rezvanifar Alireza, 2019, IPSJ TRANSACTIONS ON COMPUTER VISION AND APPLICATIONS, V11, P0, DOI 10.1186/s41074-019-0055-1
   Santosh KC, 2017, COMM COM INF SC, V709, P3, DOI 10.1007/978-981-10-4859-3_1
   Santosh W. L., 2015, GRAPHICAL SYMBOL REC, V0, P0
   Shrivastava A, 2017, PROC CVPR IEEE, V0, PP2242, DOI 10.1109/CVPR.2017.241
   Yu E., 2019, FEATURES RECOGNITION, V0, P0
   Yun DY, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10114005
   Zhang XR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080930
   Zhang Y., 2019, CNN BASED SYMBOL REC, V0, P0
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 23
TC 0
Z9 0
U1 1
U2 1
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD MAY 15
PY 2022
VL 13
IS 5
BP 537
EP 546
DI 
PG 10
WC Computer Science, Theory & Methods
SC Computer Science
GA 3L9VM
UT WOS:000835107800001
DA 2023-04-26
ER

PT J
AU Zhang, H
   Dong, JB
   Liu, XX
   Liu, JF
   Zhang, XC
AF Zhang, Hua
   Dong, Jiangbo
   Liu, Xingxu
   Liu, Jianfei
   Zhang, Xincheng
TI An Artificial Intelligence Radio Propagation Model Based on Geographical Information
SO IEEE TRANSACTIONS ON ANTENNAS AND PROPAGATION
LA English
DT Article
DE Geographical information features; machine learning; multilayer perceptrons (MLPs); neural networks; radio propagation; reference signal received power (RSRP)
ID path-loss prediction; indoor
AB In this article, a new wireless network planning propagation model is proposed, the datasets are continuous wave data from different cities, and the model is constructed based on the artificial neural network in machine learning and uses geographical information to do feature engineering. Six geographical information features are used as the input feature vectors of the model. The terrain type near the receiving point is a corrective factor affecting the propagation field intensity. To make the physical implications more explicit, two multilayer perceptron networks were designed, and the one-hot encoding of terrain types of five grids near the receiving point on the line between the receiving and transmitting points is taken as one of the input features of the second network. Through the model training and validation, and tested in actual scene, the model on the datasets of different cities has achieved good results. Compared with the traditional propagation model, such as the standard propagation model (SPM), this artificial intelligence model is more suitable for correction of data containing random disturbance and has a better simulation accuracy; the random disturbance includes external random interference sources, global positioning system offsets, and inaccurate maps.
C1 [Zhang, Hua; Dong, Jiangbo; Liu, Xingxu; Liu, Jianfei; Zhang, Xincheng] China Mobile Grp Design Inst Co Ltd, Beijing 100080, Peoples R China.
C3 China Mobile
RP Liu, XX (corresponding author), China Mobile Grp Design Inst Co Ltd, Beijing 100080, Peoples R China.
EM zhanghua@cmdi.chinamobile.com; dongliangbo@cmdi.chinamobile.com; liuxingxu@cmdi.chinamobile.com; liujianfei@cmdi.chinamobile.com; zhangxincheng@cmdi.chinamobile.com
CR Amanaf M., 2020, PROC IOP C MAT SCI E, V0, P0
   Ayadi M, 2017, IEEE T ANTENN PROPAG, V65, P3675, DOI 10.1109/TAP.2017.2705112
   Fang Cheng, 2010, 2010 2ND INTERNATIONAL CONFERENCE ON EDUCATION TECHNOLOGY AND COMPUTER (ICETC 2010), V0, PP255, DOI 10.1109/ICETC.2010.5529392
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gorce JM, 2007, IEEE T ANTENN PROPAG, V55, P938, DOI 10.1109/TAP.2007.891811
   Hancock JT, 2020, J BIG DATA-GER, V7, P0, DOI 10.1186/s40537-020-00305-w
   HATA M, 1980, IEEE T VEH TECHNOL, V29, P317, DOI 10.1109/T-VT.1980.23859
   Hayashi T., 2020, PROC 14 EUR C ANTENN, V0, P0
   Huang C, 2022, IEEE T ANTENN PROPAG, V70, P3939, DOI 10.1109/TAP.2022.3149663
   Huang C, 2022, IEEE T ANTENN PROPAG, V70, P3955, DOI 10.1109/TAP.2022.3149665
   Inoue K, 2021, 2020 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP), V0, PP315, DOI 10.23919/ISAP47053.2021.9391150
   Lee JH, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), V0, PP560, DOI 10.1109/ICAIIC.2019.8669002
   Masood U, 2019, IEEE GLOB COMM CONF, V0, P0
   Mladenovic J., 2022, IEEE T PATTERN ANAL, V6, P18
   Morocho-Cayamcela ME, 2020, IEEE T WIREL COMMUN, V19, P5075, DOI 10.1109/TWC.2020.2986202
   NAGELKERKE NJD, 1991, BIOMETRIKA, V78, P691, DOI 10.1093/biomet/78.3.691
   Neskovic A., 2001, EUROCON2001. INTERNATIONAL CONFERENCE ON TRENDS IN COMMUNICATIONS. TECHNICAL PROGRAM, V0, P128, DOI 10.1109/EURCON.2001.937780
   OBrien WM, 2000, IEEE T VEH TECHNOL, V49, P622, DOI 10.1109/25.832994
   Ostlin E, 2010, IEEE T VEH TECHNOL, V59, P2735, DOI 10.1109/TVT.2010.2050502
   Popescu I, 2001, IEEE VTS VEH TECHNOL, V0, PP387, DOI 10.1109/VETECS.2001.944870
   Popescu I., 2006, P 2006 IEEE 17 INT S, V0, P1
   Popoola SI, 2019, IEEE ACCESS, V7, P150462, DOI 10.1109/ACCESS.2019.2947009
   Rappaport T. S, 1996, WIRELESS COMMUNICATI, V0, P0
   Rice P. L., 1965, 101 US DEP COMM NAT, V0, P0
   Rojas R., 1996, NEURAL NETWORKS SYST, V0, P0
   Sarkar TK, 2003, IEEE ANTENN PROPAG M, V45, P51, DOI 10.1109/MAP.2003.1232163
   Seretis A, 2022, IEEE T ANTENN PROPAG, V70, P3970, DOI 10.1109/TAP.2021.3098616
   Seretis A, 2020, IET MICROW ANTENNA P, V14, P1198, DOI 10.1049/iet-map.2019.0988
   Sotiroudis SP, 2020, ICT EXPRESS, V6, P160, DOI 10.1016/j.icte.2020.04.008
   Thrane J, 2020, IEEE GLOB COMM CONF, V0, P0, DOI DOI 10.1109/GLOBECOM42002.2020.9322089
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Wu LN, 2020, IEEE ACCESS, V8, P199523, DOI 10.1109/ACCESS.2020.3035209
NR 32
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-926X
EI 1558-2221
J9 IEEE T ANTENN PROPAG
JI IEEE Trans. Antennas Propag.
PD DEC 15
PY 2022
VL 70
IS 12
BP 12049
EP 12060
DI 10.1109/TAP.2022.3215818
PG 12
WC Engineering, Electrical & Electronic; Telecommunications
SC Engineering; Telecommunications
GA 8R8UH
UT WOS:000928163000090
DA 2023-04-26
ER

PT J
AU Date, K
   Allweil, Y
AF Date, Kartikeya
   Allweil, Yael
TI Towards a new image archive for the built environment
SO ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE
LA English
DT Article
DE Archives; built environment; neural networks; architectural history; methods
ID tel-aviv; city
AB The ever-growing online corpus of images of the built environment, on social media and mapping platforms, offers a new kind of archive of the built environment. Recent advances in computer vision, specifically convolutional neural networks, offer new ways of querying and analyzing large image corpuses. In this paper, we propose a new method by which historians of the built environment can use these vast image corpuses in their study, enabling new research questions. To demonstrate proof of need, we report on an ongoing case study in Tel Aviv that attempts to show the feasibility of our proposed method for enabling a Historic Urban Landscapes (HUL)-based approach to the study of the built environment. In so doing, we show how such image corpuses could potentially form a new type of archive for architectural and urban history.
C1 [Date, Kartikeya; Allweil, Yael] Israel Inst Technol, Technion, 503 Segoe, Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Allweil, Y (corresponding author), Israel Inst Technol, Technion, 503 Segoe, Haifa, Israel.
EM kartikeya@campus.technion.ac.il
FU Israel Science Foundation (ISF) [2029064]
CR Alexander C., 1977, PATTERN LANGUAGE TOW, V0, P0
   Allweil Y, 2016, PRACTICE FREEDOM ANA, V0, P43
   Allweil Y, 2019, URBAN PLAN, V4, P167, DOI 10.17645/up.v4i3.2182
   Allweil Yael, 2016, HOMELAND ZIONISM HOU, V0, P0
   ANDREWS J. H., 2001, NEW NATURE MAPS ESSA, V0, P1
   [Anonymous], 2002, NEW PARADIGM ARCHITE, V0, P0
   Araldi A, 2017, LECT NOTES COMPUT SC, V10407, P365, DOI 10.1007/978-3-319-62401-3_27
   Bandarin F., 2019, RESHAPING URBAN CONS, V0, PP3, DOI 10.1007/978-981-10-8887-2_1
   Behnisch M, 2019, ENVIRON PLAN B-URBAN, V46, P1203, DOI 10.1177/2399808319870016
   Benguigui L, 2006, ENVIRON PLANN B, V33, P269, DOI 10.1068/b31118
   Bernheimer R, 1961, NATURE REPRESENTATIO, V0, P0
   Bodenhamer B, 2015, DEEP MAPS SPATIAL NA, V0, P0
   Bodenhamer DJ, 2013, HIST GIS EPISTEMOLOG, V0, P1
   Boy JD, 2017, T I BRIT GEOGR, V42, P612, DOI 10.1111/tran.12185
   Bucciarelli L. L., 1900, P159, V0, P0, DOI DOI 10.1016/0142-694X(88)90045-2
   Carpo Mario, 2001, ARCHITECTURE AGE PRI, V0, P0
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Colaninno N., 2011, AUTOMATIC CLASSIFICA, V0, P0
   DAcci L., 2019, MATH URBAN MORPHOLOG, V0, P0
   DASTON L, 1992, REPRESENTATIONS, V0, P81
   Datta R, 2008, ACM COMPUT SURV, V40, P0, DOI 10.1145/1348246.1348248
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   DERRIDA J, 1995, DIACRITICS, V25, P9, DOI 10.2307/465144
   Doersch C, 2015, COMMUN ACM, V58, P103, DOI 10.1145/2830541
   Farge A., 2013, ALLURE ARCH, V0, P0
   Ferguson E. S., 1994, ENG MINDS EYE, V0, P0
   Fletcher B, 1931, HIST ARCHITECTURE CO, V0, P0
   Frampton K., 1981, MODERN ARCHITECTURE, V1st, P0
   Gane N., 2008, NEW MEDIA KEY CONCEP, V0, P0
   GERON A, 2019, HANDS MACHINE LEARNI, V0, P0
   Goel V., 1995, SKETCHES THOUGHT, V0, P0
   Goldschmidt G., 1991, CREATIVITY RES J, V4, P123, DOI https://doi.org/10.1080/10400419109534381
   GOLLEDGE RG, 1978, GEOGR ANAL, V10, P403
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Goodman N., 1968, LANGUAGES ART, V0, P0
   Gottesman R, 2019, RESHAPING URBAN CONS, V0, P473
   Habraken N.J., 2000, STRUCTURE ORDINARY F, V0, P0
   Haken H, 2003, J ENVIRON PSYCHOL, V23, P385, DOI 10.1016/S0272-4944(03)00003-3
   Harris K, 2014, JOHNS HOPKINS GUIDE TO DIGITAL MEDIA, V0, P16
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Heyman S., 2015, NEW YORK TIMES, V0, P0
   Hochman Nadav, 2013, FIRST MONDAY, V18, P32, DOI 10.5210/fm.v18i7.4711
   IBRAHIM MR, 2019, ENV PLANNING B, V0, P0
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Kalay YE., 2004, ARCHITECTURES NEW ME, V0, P0
   Kang J, 2018, ISPRS J PHOTOGRAMM, V145, P44, DOI 10.1016/j.isprsjprs.2018.02.006
   Kostof S., 2000, ARCHITECT, V0, P0
   Kostof S., 1985, HIST ARCHITECTURE SE, V0, P0
   Kovashka A, 2014, FOUND TRENDS COMPUT, V10, PI, DOI 10.1561/0600000071
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavee M, 2017, DEOT, V81, P40
   Lavee M, 2019, TIKKOUN SOFRIM COMBI, V0, P0
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leszczynski A, 2019, PROG HUM GEOG, V43, P1143, DOI 10.1177/0309132518787997
   Long J, 2015, ARXIV14114038CS, V0, P0
   Lynch K., 2008, IMAGE CITY, V33rd ed., P0
   LYNCH M., 1990, REPRESENTATION SCI P, V0, P0
   Manoff M, 2004, PORTAL-LIBR ACAD, V4, P9, DOI 10.1353/pla.2004.0015
   Metzger-Szmuck N, 2004, DWELLINGS DUNES, V0, P0
   MORRIS AEJ, 1979, HIST URBAN FORM IND, V0, P0
   Naik N, 2017, P NATL ACAD SCI USA, V114, P7571, DOI 10.1073/pnas.1619003114
   Naik N, 2014, IEEE COMPUT SOC CONF, V0, PP793, DOI 10.1109/CVPRW.2014.121
   Oliveira V., 2016, URBAN MORPHOLOGY, V0, P0
   Perez J, 2018, INT C SPAT AN MOD SA, V2018 September, P0
   Perez-Neira A, 2000, MULTIACCESS, V0, P1
   PEVSNER N., 1976, HIST BUILDING TYPES, V0, P0
   Pickles J., 1995, GROUND TRUTH SOCIAL, V0, P0
   Pont MB, 2019, ENVIRON PLAN B-URBAN, V46, P1226, DOI 10.1177/2399808319857450
   Prince S., 2012, COMPUTER VISION MODE, V0, P0
   Protzen J-P, 1980, DESIGN STUDIES, V1, P291
   Rabari C, 2015, CAMB J REG ECON SOC, V8, P27, DOI 10.1093/cjres/rsu021
   Roman A, 2004, IEEE VISUALIZATION 2004, V0, P537, DOI 10.1109/VISUAL.2004.50
   Rose G, 2019, ENVIRON PLANN D, V37, P411, DOI 10.1177/0263775818771080
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, ARXIV, V0, P0
   UNESCO, 2012, GEN C 36 SESS PAR 25, V1, P50
   Van Oers R., 2010, WORLD HERITAGE PAPER, V0, P7
   Veldpaus L, 2013, HIST ENVIRON POLICY, V4, P3, DOI 10.1179/1756750513Z.00000000022
   Wittkower Rudolf, 1952, ARCHITECTURAL PRINCI, VSecond, P0
   WOLLHEIM R, 1977, CRIT INQUIRY, V3, P709, DOI 10.1086/447913
   Yatour Bruno, 1986, KNOWLEDGE SOC STUDIE, V6, P1, DOI 10.1002/9780470979587.CH9
   Zhou BL, 2014, ADV NEUR IN, V27, P0
NR 84
TC 0
Z9 0
U1 0
U2 9
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 2399-8083
EI 2399-8091
J9 ENVIRON PLAN B-URBAN
JI Env. Plan. B-Urban Anal. City Sci.
PD FEB 15
PY 2022
VL 49
IS 2
BP 519
EP 534
DI 10.1177/23998083211011474
EA MAY 2021
PG 16
WC Environmental Studies; Geography; Regional & Urban Planning; Urban Studies
SC Environmental Sciences & Ecology; Geography; Public Administration; Urban Studies
GA YU3AA
UT WOS:000650021500001
DA 2023-04-26
ER

PT J
AU Tripodi, S
   Girard, N
   Fonteix, G
   Duan, L
   Mapurisa, W
   Leras, M
   Trastour, F
   Tarabalka, Y
   Laurore, L
AF Tripodi, S.
   Girard, N.
   Fonteix, G.
   Duan, L.
   Mapurisa, W.
   Leras, M.
   Trastour, F.
   Tarabalka, Y.
   Laurore, L.
TI BRIGHTEARTH: PIPELINE FOR ON-THE-FLY 3D RECONSTRUCTION OF URBAN AND RURAL SCENES FROM ONE SATELLITE IMAGE
SO XXIV ISPRS CONGRESS: IMAGING TODAY, FORESEEING TOMORROW, COMMISSION III
LA English
DT Proceedings Paper
DE Deep learning; optical satellite images; semantic segmentation; 3D reconstruction; digital terrain model
AB With the growth of the availability and quality of satellite images, automatic 3D reconstruction from optical satellite images remains a popular research topic. Numerous applications, such as telecommunications and defence, directly benefit from the use of 3D models of both urban and rural scenes. While most of the state-of-the-art methods use stereo pairs for 3D reconstruction, such pairs are not immediately available anywhere in the world. In this paper, we propose an automatic pipeline for very-large-scale 3D reconstruction of urban and rural scenes from one high-resolution satellite image. Convolutional neural networks are trained to extract key semantic information. The extracted information is then converted into GIS vector format, and enriched by both terrain and object height information. The final classification step is applied, yielding a 16-class 3D map. The presented pipeline is operational and available for commercial purposes under the BrightEarth trademark.
C1 [Tripodi, S.; Girard, N.; Fonteix, G.; Duan, L.; Leras, M.; Trastour, F.; Tarabalka, Y.; Laurore, L.] LuxCarta Technol, Mouans Sartoux, France.
   [Mapurisa, W.] LuxCarta South Africa, Cape Town, South Africa.
RP Tripodi, S (corresponding author), LuxCarta Technol, Mouans Sartoux, France.
EM stripodi@luxcarta.com
CR [Anonymous], 2013, NASA SHUTTL RAD TOP, V0, P0
   Bodansky E, 2002, LECT NOTES COMPUT SC, V2390, P256
   Budninskiy M, 2017, COMPUT GRAPH FORUM, V36, P117, DOI 10.1111/cgf.13250
   Duan LY, 2019, IEEE COMPUT SOC CONF, V0, PP1442, DOI 10.1109/CVPRW.2019.00185
   Fonteix G., 2021, ISPRS ANN PHOTOGRAMM, V3, P101
   He KM, 2015, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1512.03385
   Japan Aerospace Exploration Agency, 2021, ALOS WORLD 3D 30M, V0, P0, DOI DOI 10.5069/G94M92HB
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Mousa A. -k., 2017, INT ARCH PHOTOGRAMME, V42, P0
   Pepe M, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10100697
   Rahman Md Atiqur, 2016, ADVANCES IN VISUAL COMPUTING. 12TH INTERNATIONAL SYMPOSIUM, V0, P234, DOI 10.1007/978-3-319-50835-1_22
   Ronneberger O, 2015, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1505.04597
   Tasar O, 2019, IEEE J-STARS, V12, P3524, DOI 10.1109/JSTARS.2019.2925416
   Tripodi S., 2019, INT ARCH PHOTOGRAMME, V0, P0
   Zhang PB, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113717
   Zheng XW, 2016, INT ARCH PHOTOGRAMM, V41, P459, DOI 10.5194/isprsarchives-XLI-B2-459-2016
NR 16
TC 0
Z9 0
U1 0
U2 0
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 2194-9042
EI 2194-9050
J9 ISPRS ANN PHOTO REM
PD JUN 15
PY 2022
VL 5-3
IS 
BP 263
EP 270
DI 10.5194/isprs-annals-V-3-2022-263-2022
PG 8
WC Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA BT8SD
UT WOS:000855203200036
DA 2023-04-26
ER
