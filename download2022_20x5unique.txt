
PT J
AU Al-Azizi, JI
   Shafri, HZM
   Bin Hashim, SJ
   Mansor, SB
AF Al-Azizi, Jalal Ibrahim
   Shafri, Helmi Zulhaidi Mohd
   Bin Hashim, Shaiful Jahari
   Mansor, Shattri B.
TI DeepAutoMapping: low-cost and real-time geospatial map generation method using deep learning and video streams
SO EARTH SCIENCE INFORMATICS
LA English
DT Article
DE Computer vision for automation; Deep learning neural networks; Geographic information system (GIS); Geospatial data; Mapping and localization; Surveying methods
AB Field data collection and geospatial map generation are critical aspects in different fields such as road asset management, urban planning, and geospatial applications. However, one of the primary impediments to data collection is the availability of spatial and attribute data. This issue is aggravated by the high cost of conventional data collection and data processing methods and by the lack of geospatial data collection policies. This study proposes an inexpensive approach that enables real-time field data observation and geospatial data generation from video streams connected to a laptop and positioning sensors using deep learning technology. This proposed method was evaluated via an application called "DeepAutoMapping", which was built on top of Python, then underwent through two different evaluation scenarios. The results demonstrated that the proposed approach is quick, easy to use and that it provides a high detection accuracy and an acceptable positioning accuracy in the outdoor environment. The proposed solution may also be considered as a pipeline for efficient and economical method of geospatial data collection and auto-map generation in the future.
C1 [Al-Azizi, Jalal Ibrahim; Shafri, Helmi Zulhaidi Mohd; Mansor, Shattri B.] Univ Putra Malaysia UPM, Fac Engn, Dept Civil Engn, Serdang 43400, Malaysia.
   [Al-Azizi, Jalal Ibrahim; Shafri, Helmi Zulhaidi Mohd; Mansor, Shattri B.] Univ Putra Malaysia UPM, Fac Engn, Geospatial Informat Sci Res Ctr GISRC, Serdang 43400, Malaysia.
   [Bin Hashim, Shaiful Jahari] Univ Putra Malaysia UPM, Fac Engn, Dept Comp & Commun Syst Engn, Serdang 43400, Malaysia.
C3 Universiti Putra Malaysia; Universiti Putra Malaysia; Universiti Putra Malaysia
RP Shafri, HZM (corresponding author), Univ Putra Malaysia UPM, Fac Engn, Dept Civil Engn, Serdang 43400, Malaysia.; Shafri, HZM (corresponding author), Univ Putra Malaysia UPM, Fac Engn, Geospatial Informat Sci Res Ctr GISRC, Serdang 43400, Malaysia.
EM Jalal.alazizi@gmail.com; helmi@upm.edu.my; sjh@upm.edu.my; shattri@upm.edu.my
FU Universiti Putra Malaysia (UPM)
CR Al-Azizi Jalal Ibrahim, 2017, INTERNATIONAL JOURNAL OF NAVIGATION AND OBSERVATION, V2017, P0, DOI 10.1155/2017/6750346
   Alexey AB, 2019, WINDOWS LINUX VERSIO, V0, P0
   [Anonymous], 2014, PROC IEEE C COMPUT V, V0, P0
   Bradski G., 2008, LEARNING OPENCV COMP, V0, P0
   Cao YT, 2013, SOFTWARE ENG, V1, P376, DOI 10.7763/LNSE.2013.V1.80
   Chen CY, 2015, IEEE I CONF COMP VIS, V0, PP2722, DOI 10.1109/ICCV.2015.312
   Chen X, 2015, CORR, V1504, P325
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), V0, PP1796, DOI 10.1109/ICIT.2016.7475036
   Damodharan P, 2017, CONTROLLING INPUT DE, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Goodchild MF, 2009, PROCED EARTH PLAN SC, V1, P1037, DOI 10.1016/j.proeps.2009.09.160
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Guimaraes RG, 2017, IEEE ACCESS, V5, P10805, DOI 10.1109/ACCESS.2017.2706674
   Harrington Peter, 2012, MACHINE LEARNING ACT, V0, P0
   Holzmann C., 2012, PROCEEDINGS OF THE 2012 32ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS (ICDCS WORKSHOPS), V0, PP88, DOI 10.1109/ICDCSW.2012.22
   Huang J, 2017, IEEE INT C INT ROBOT, V0, P3296
   Kang M., 2017, 2017 INT WORKSHOP RE, V0, PP1, DOI 10.1109/RSIP.2017.7958815
   Kanjee R, 2013, 2013 6TH ROBOTICS AND MECHATRONICS CONFERENCE (ROBMECH), V0, PP93, DOI 10.1109/RoboMech.2013.6685498
   Korpilo S, 2017, LANDSCAPE URBAN PLAN, V157, P608, DOI 10.1016/j.landurbplan.2016.08.005
   Lin GT, 2017, ASIAPAC SIGN INFO PR, V0, P692
   Lu XG, 2013, INTERSPEECH, V0, P436
   Lwin KK., 2011, J GEOGRAPHIC INFORM, V3, P382, DOI 10.4236/JGIS.2011.34037
   Martinez A, 2017, INT ARCH PHOTOGRAMME, V42, P0, DOI 10.5194/isprs-archives-XLII-4-W3-65-2017
   Nahhas FH, 2018, J SENSORS, V2018, P0, DOI 10.1155/2018/7212307
   Norvig P., 2016, ARTIF INTELL, V0, P0
   Puente I, 2011, INT ARCH PHOTOGRAMM, V38, P0, DOI 10.5194/isprsarchives-XXXVIII-5-W12-163-2011
   Pulli K, 2012, COMMUN ACM, V55, P61, DOI 10.1145/2184319.2184337
   Radovic M, 2017, J IMAGING, V3, P0, DOI 10.3390/jimaging3020021
   Redmon J., 2016, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   REDMON J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Saipullah K, 2013, J THEORETICAL APPL I, V47, P0
   Silva J. F. C., 2000, INT ARCH PHOTOGRAMME, V33, P510
   Singh SP, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, V0, P162, DOI 10.1109/COMPTELIX.2017.8003957
   Sotelo M. A., 2004, 2004 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS) (IEEE CAT. NO.04CH37566), V0, P64
   Stein GP, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, V0, P120, DOI 10.1109/IVS.2003.1212895
   Sun Y, 2014, PROC CVPR IEEE, V0, PP1891, DOI 10.1109/CVPR.2014.244
   Tang S, 2015, INT C IEEE 2016, V0, P0
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, V0, PP1873, DOI 10.1109/IGARSS.2015.7326158
   Vasari P, 2019, OVERFITTING VS UNDER, V0, P0
   Wang B, 2019, J VIS COMMUN IMAGE R, V58, P102, DOI 10.1016/j.jvcir.2018.11.014
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Yang BS, 2013, ISPRS J PHOTOGRAMM, V79, P80, DOI 10.1016/j.isprsjprs.2013.01.016
NR 47
TC 3
Z9 3
U1 4
U2 11
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1865-0473
EI 1865-0481
J9 EARTH SCI INFORM
JI Earth Sci. Inform.
PD SEP 15
PY 2022
VL 15
IS 3
BP 1481
EP 1494
DI 10.1007/s12145-020-00529-7
EA OCT 2020
PG 14
WC Computer Science, Interdisciplinary Applications; Geosciences, Multidisciplinary
SC Computer Science; Geology
GA 3X7JM
UT WOS:000577987000001
DA 2023-04-26
ER

PT J
AU Li, JX
   Tang, HJ
   Yan, R
AF Li, Jiaxin
   Tang, Huajin
   Yan, Rui
TI A Hybrid Loop Closure Detection Method Based on Brain-Inspired Models
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Feature extraction; Simultaneous localization and mapping; Visualization; Liquid crystal displays; Brain modeling; Convolutional codes; Robot control; Brain-inspired simultaneous localization and mapping (SLAM); fly's locality-sensitive hashing algorithm (Fly-LSH); loop closure detection (LCD)
ID grid cells; map; hippocampus; navigation; space; codes
AB Various hippocampal-entorhinal-based models are used to construct brain-inspired simultaneous localization and mapping (SLAM) systems. Loop closure detection (LCD) is a critical process of SLAM systems for robots to relocalize themselves and correct accumulative errors. The existing LCD methods of brain-inspired SLAM systems cannot solve well with challenging or large-scale environments by hand-crafted features and brute force search strategy. In this article, we propose a hybrid LCD method, which is based on the convolutional neural network (CNN) features and the fly's locality-sensitive hashing algorithm (Fly-LSH). CNN features can improve the reliability of image matching results, and the Fly-LSH, a nearest neighbor search method derived from the fruit fly olfactory circuit, is used to accelerate the image processing. We use multiple hash tables to make a balance between the image matching time and the accuracy of loop closures. The proposed method provides a general approach for SLAM systems to process visual cues, and has application in a hippocampal-entorhinal-based SLAM system. The experimental results verify that the proposed method enables the system to build cognitive maps with better robustness and efficiency.
C1 [Li, Jiaxin] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Tang, Huajin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
   [Yan, Rui] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
C3 Sichuan University; Zhejiang University; Zhejiang University of Technology
RP Yan, R (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Peoples R China.
EM ryan@zjut.edu.cn
FU National Natural Science Foundation of China [61773271]; National Natural Science Foundation of China NSAF [U2030204]; Zhejiang Lab [2021KC0AC01]
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI 10.1109/CVPR.2016.572
   Ball D, 2013, AUTON ROBOT, V34, P149, DOI 10.1007/s10514-012-9317-9
   Banino A, 2018, NATURE, V557, P429, DOI 10.1038/s41586-018-0102-6
   Bellmund JLS, 2018, SCIENCE, V362, P0, DOI 10.1126/science.aat6766
   Bonin-Font F, 2014, 2014 IEEE EMERGING TECHNOLOGY AND FACTORY AUTOMATION (ETFA), V0, P0
   Burak Y, 2009, PLOS COMPUT BIOL, V5, P0, DOI 10.1371/journal.pcbi.1000291
   Bush D, 2014, TRENDS NEUROSCI, V37, P136, DOI 10.1016/j.tins.2013.12.003
   Cheng J, 2014, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2014.8
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Dasgupta S, 2017, SCIENCE, V358, P793, DOI 10.1126/science.aam9868
   Eade E. D., 2008, P BRIT MACH VIS C, V13, P136
   Eichenbaum H, 2017, J NEUROPHYSIOL, V117, P1785, DOI 10.1152/jn.00005.2017
   Friedman J. H., 1984, SLACPUB3477 NAT ACC, V0, P0
   Fuhs MC, 2006, J NEUROSCI, V26, P4266, DOI 10.1523/JNEUROSCI.4353-05.2006
   Giocomo LM, 2011, NEURON, V71, P589, DOI 10.1016/j.neuron.2011.07.023
   Gong YC, 2013, PROC CVPR IEEE, V0, PP484, DOI 10.1109/CVPR.2013.69
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, V0, PP2238, DOI 10.1109/ICInfA.2015.7279659
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Liu LY, 2017, LECT NOTES COMPUT SC, V10538, P110, DOI 10.1007/978-3-319-68155-9_9
   Liu S, 2015, IEEE IJCNN, V0, P0
   Liu W., 2014, ADV NEURAL INFORM PR, V2, P3419
   Mathis A, 2012, NEURAL COMPUT, V24, P2280, DOI 10.1162/NECO_a_00319
   Morris R, 2007, HIPPOCAMPUS BOOK, V0, P581
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   OKeefe J., 2014, SPATIAL CELLS HIPPOC, V0, P0
   Redish A D, 1999, COGNITIVE MAP PLACE, V0, P0
   Rolls ET, 2006, NETWORK-COMP NEURAL, V17, P447, DOI 10.1080/09548980601064846
   Savelli F, 2010, J NEUROPHYSIOL, V103, P3167, DOI 10.1152/jn.00932.2009
   Shahbazi H, 2011, IEEE INT C INT ROBOT, V0, PP1228, DOI 10.1109/IROS.2011.6048862
   Shamwell EJ, 2020, IEEE T PATTERN ANAL, V42, P2478, DOI 10.1109/TPAMI.2019.2909895
   Tang HJ, 2018, IEEE T COGN DEV SYST, V10, P751, DOI 10.1109/TCDS.2017.2776965
   Tian B, 2013, IEEE INT C INT ROBOT, V0, PP1562, DOI 10.1109/IROS.2013.6696557
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Yang SC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), V0, PP1222, DOI 10.1109/IROS.2016.7759204
   Yu FW, 2019, BIOL CYBERN, V113, P515, DOI 10.1007/s00422-019-00806-9
   Yuan ML, 2015, AAAI CONF ARTIF INTE, V0, P586
   Zeng TP, 2017, FRONT NEUROROBOTICS, V11, P0, DOI 10.3389/fnbot.2017.00061
   Zhou SC, 2017, INT J AUTOM COMPUT, V14, P564, DOI 10.1007/s11633-017-1090-y
NR 41
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC 15
PY 2022
VL 14
IS 4
BP 1532
EP 1543
DI 10.1109/TCDS.2022.3152910
PG 12
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA 8B3IW
UT WOS:000916821100019
DA 2023-04-26
ER

PT J
AU Alshehhi, R
   Gebhardt, C
AF Alshehhi, Rasha
   Gebhardt, Claus
TI Automated Geological Landmarks Detection on Mars Using Deep Domain Adaptation From Lunar High-Resolution Satellite Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Deep learning; domain adaptation (DA); lunar; Martian
ID crater detection; rockfalls
AB The diversity in geological characteristics on the planetary surface, such as distribution (density), size, shapes, floor structures, ages, and availability of various input data types such as optical, thermal images, and digital elevation maps pose numerous challenges for detecting geological landmarks (e.g., rockfalls, craters, etc.). Several automatic detection methods are proposed to identify geological landmarks. However, the insufficiency of the labeled dataset is a challenging problem. It requires exceedingly time-consuming and expensive manual annotation. In this article, we use the domain adaptation technique to transfer deep learning from the planetary surface to another (lunar surface into Martian surface). We test the feasibility of transfer learning of the convolutional neural networks in optical images and elevation maps to distinguish landmarks such as rockfalls and craters from the background. The experimental results demonstrate the effectiveness of the proposed method. It achieves high F1-scores compared to the state-of-the-art methods with 58.32 +/- 2.3 and 57.51 +/- 2.4 in detecting rockfall regions in optical lunar and Martian images. It also achieves 65.32 +/- 1.8, 67.39 +/- 2.4, 77.37 +/- 2.2, and 72.56 +/- 2.3 in detecting crater regions in optical images and digital elevation maps of Moon and Mars. This method can be a potential approach to identify landmarks for coming Mars missions.
C1 [Alshehhi, Rasha] New York Univ, Ctr Space Sci, Abu Dhabi 129188, U Arab Emirates.
   [Gebhardt, Claus] United Arab Emirates Univ, Natl Space Sci & Technol Ctr, Al Ain 15551, U Arab Emirates.
C3 United Arab Emirates University
RP Alshehhi, R (corresponding author), New York Univ, Ctr Space Sci, Abu Dhabi 129188, U Arab Emirates.
EM ra130@nyu.edu; claus.gebhardt@uaeu.ac.ae
FU New York University Abu Dhabi, Center for Space Science
CR Balme M, 2006, REV GEOPHYS, V44, P0, DOI 10.1029/2005RG000188
   Barlow NG, 2005, GEOL SOC AM SPEC PAP, V384, P433, DOI 10.1130/0-8137-2384-1.433
   Barlow NG, 2003, J GEOPHYS RES-PLANET, V108, P0, DOI 10.1029/2002JE002036
   Bickel V. T., 2021, FRONT REMOTE SENS, V2, P1
   Bickel VT, 2020, IEEE J-STARS, V13, P2831, DOI 10.1109/JSTARS.2020.2991588
   Bickel VT, 2019, IEEE T GEOSCI REMOTE, V57, P3501, DOI 10.1109/TGRS.2018.2885280
   Bridges NT, 2012, NATURE, V485, P339, DOI 10.1038/nature11022
   Brusnikin ES, 2016, ICARUS, V278, P52, DOI 10.1016/j.icarus.2016.06.005
   Chen H., 2020, ARXIV200609225, V0, P0
   de Haas T, 2015, J GEOPHYS RES-PLANET, V120, P2169, DOI 10.1002/2015JE004915
   Diaz-Zapata M, 2020, I C CONT AUTOMAT ROB, V0, P421
   Emami E., 2018, P LUNAR PLANET SCI C, V0, P1
   Finkelstein S. M., 2019, AUTOMATIC LUNAR CRAT, V0, P0
   Galloway MJ, 2014, IEEE IMAGE PROC, V0, PP1579, DOI 10.1109/ICIP.2014.7025316
   Galloway M. J., 2015, P WORKSH ISS CRAT ST, V0, P0
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Head JW, 2010, SCIENCE, V329, P1504, DOI 10.1126/science.1195050
   Hsu J., 2021, PROC INT C COMPUT VI, V0, P1
   Jiang He, 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP 2010), V0, PP302, DOI 10.1109/ICICIP.2010.5565284
   Kumar PS, 2019, EARTH PLANET SC LETT, V505, P51, DOI 10.1016/j.epsl.2018.10.008
   Lee C, 2019, PLANET SPACE SCI, V170, P16, DOI 10.1016/j.pss.2019.03.008
   Marghany M, 2017, P 38 AS C REM SENS, V1, P49
   Norman C.J., 2018, PLANETARY SCI INFORM, V2082, P6004
   Pasquon K, 2016, ICARUS, V274, P195, DOI 10.1016/j.icarus.2016.03.024
   Pedrosa MM, 2017, GEOMAT NAT HAZ RISK, V8, P1306, DOI 10.1080/19475705.2017.1327463
   Povilaitis RZ, 2018, PLANET SPACE SCI, V162, P41, DOI 10.1016/j.pss.2017.05.006
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Robbins SJ, 2013, PLANET SPACE SCI, V86, P57, DOI 10.1016/j.pss.2013.06.019
   Robinson MS, 2010, SPACE SCI REV, V150, P81, DOI 10.1007/s11214-010-9634-2
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Russell P, 2008, GEOPHYS RES LETT, V35, P0, DOI 10.1029/2008GL035790
   Salamuniccar G., 2010, 38 COSPAR SCI ASSEMB, V38, P3
   Silburt A, 2019, ICARUS, V317, P27, DOI 10.1016/j.icarus.2018.06.022
   Stillman DE, 2020, ICARUS, V335, P0, DOI 10.1016/j.icarus.2019.113420
   Tewari A., 2020, PLANET SPACE SCI, V0, P0, DOI DOI 10.1016/J.PSS.2022.105500
   Tuia Devis, 2021, ARXIV210407778, V0, P0
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang Y.-W., 2018, DETECTING CRATERS TR, V0, P13
   Yang C, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-14983-w
   Yin JH, 2015, IEEE J-STARS, V8, P23, DOI 10.1109/JSTARS.2014.2375066
   Zhang Z.-B., 2016, P LUNAR PLANET SCI C, V0, P0
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zurek RW, 2007, J GEOPHYS RES-PLANET, V112, P0, DOI 10.1029/2006JE002701
NR 44
TC 0
Z9 0
U1 9
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2022
VL 15
IS 
BP 2274
EP 2283
DI 10.1109/JSTARS.2022.3156371
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA ZZ4TB
UT WOS:000773262200001
DA 2023-04-26
ER

PT J
AU Scholz, F
   Gumbsch, C
   Otte, S
   Butz, MV
AF Scholz, Fedor
   Gumbsch, Christian
   Otte, Sebastian
   Butz, Martin V.
TI Inference of affordances and active motor control in simulated agents
SO FRONTIERS IN NEUROROBOTICS
LA English
DT Article
DE affordances; active inference; goal-directed control; simulation; free energy principle; model-predictive control; cognitive maps; event-predictive cognition
ID place-cell sequences; perception
AB Flexible, goal-directed behavior is a fundamental aspect of human life. Based on the free energy minimization principle, the theory of active inference formalizes the generation of such behavior from a computational neuroscience perspective. Based on the theory, we introduce an output-probabilistic, temporally predictive, modular artificial neural network architecture, which processes sensorimotor information, infers behavior-relevant aspects of its world, and invokes highly flexible, goal-directed behavior. We show that our architecture, which is trained end-to-end to minimize an approximation of free energy, develops latent states that can be interpreted as affordance maps. That is, the emerging latent states signal which actions lead to which effects dependent on the local context. In combination with active inference, we show that flexible, goal-directed behavior can be invoked, incorporating the emerging affordance maps. As a result, our simulated agent flexibly steers through continuous spaces, avoids collisions with obstacles, and prefers pathways that lead to the goal with high certainty. Additionally, we show that the learned agent is highly suitable for zero-shot generalization across environments: After training the agent in a handful of fixed environments with obstacles and other terrains affecting its behavior, it performs similarly well in procedurally generated environments containing different amounts of obstacles and terrains of various sizes at different locations.
C1 [Scholz, Fedor; Gumbsch, Christian; Otte, Sebastian; Butz, Martin V.] Eberhard Karls Univ Tubingen, Dept Comp Sci & Psychol, Neurocognit Modeling Grp, Tubingen, Germany.
   [Gumbsch, Christian] Max Planck Inst Intelligent Syst, Autonomous Learning Grp, Tubingen, Germany.
C3 Eberhard Karls University of Tubingen; Max Planck Society
RP Scholz, F (corresponding author), Eberhard Karls Univ Tubingen, Dept Comp Sci & Psychol, Neurocognit Modeling Grp, Tubingen, Germany.
EM fedor.scholz@uni-tuebingen.de
FU German Research Foundation (DFG) within Priority-Program SPP 2134 Project-Development; Functions and Interactions [BU 1335/11-1, EL 253/8-1]; Machine Learning Cluster of Excellence - Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy - EXC [BU 1335/12-1]; University of Tuebingen [390727645]
CR Bergstra J., 2013, INT C MACHINE LEARNI, V0, P0
   Bonner MF, 2017, P NATL ACAD SCI USA, V114, P4793, DOI 10.1073/pnas.1618228114
   Botvinick M, 2012, TRENDS COGN SCI, V16, P485, DOI 10.1016/j.tics.2012.08.006
   Brockman G, 2016, ARXIV, V0, P0
   Butz MV, 2021, TOP COGN SCI, V13, P10, DOI 10.1111/tops.12522
   Butz MV, 2019, NEURAL NETWORKS, V117, P135, DOI 10.1016/j.neunet.2019.05.001
   Butz MV, 2008, CONSTR FOUND, V4, P1
   Chua K, 2018, ADV NEUR IN, V31, P0
   Cisek P, 2007, PHILOS T R SOC B, V362, P1585, DOI 10.1098/rstb.2007.2054
   Cobbe K, 2019, PR MACH LEARN RES, V97, P0
   Diba K, 2007, NAT NEUROSCI, V10, P1241, DOI 10.1038/nn1961
   Eppe M, 2022, NAT MACH INTELL, V4, P11, DOI 10.1038/s42256-021-00433-9
   Friston K, 2015, COGN NEUROSCI-UK, V6, P187, DOI 10.1080/17588928.2015.1020053
   Friston K, 2013, J R SOC INTERFACE, V10, P0, DOI 10.1098/rsif.2013.0475
   Friston KJ, 2012, PLOS COMPUT BIOL, V8, P0, DOI 10.1371/journal.pcbi.1002327
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Gibson J.J.., 1979, ECOLOGICAL APPROACH, V0, P0
   Gumbsch Christian, 2021, ADV NEURAL INFORM PR, V34, P17518
   Ha D, 2018, ARXIV, V0, P0
   Hafner D, 2020, ARXIV, V0, P0
   Hafner D, 2019, PR MACH LEARN RES, V97, P0
   Lenz I, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI, V0, P0
   Levine S, 2020, ARXIV, V0, P0
   Liaw R, 2018, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.1807.05118
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   Otte S, 2017, LECT NOTES COMPUT SC, V10613, P227, DOI 10.1007/978-3-319-68600-4_27
   Pfeiffer BE, 2013, NATURE, V497, P74, DOI 10.1038/nature12112
   Pinneri Cristina, 2020, ARXIV, V0, P0
   Qi WL, 2020, ARXIV, V0, P0
   Rubinstein R., 1999, METHODOL COMPUT APPL, V1, P127, DOI 10.1023/A:1010091220143
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Tani J., 2017, IEEE CDS NEWSLETT, V14, P4
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Zacks JM, 2007, PSYCHOL BULL, V133, P273, DOI 10.1037/0033-2909.133.2.273
   Zacks JM, 2001, PSYCHOL BULL, V127, P3, DOI 10.1037//0033-2909.127.1.3
NR 38
TC 0
Z9 0
U1 5
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5218
EI 
J9 FRONT NEUROROBOTICS
JI Front. Neurorobotics
PD AUG 11
PY 2022
VL 16
IS 
BP 
EP 
DI 10.3389/fnbot.2022.881673
PG 18
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA 3Z4JL
UT WOS:000844381900001
PM 36035589
DA 2023-04-26
ER

PT J
AU Hoxha, G
   Chouaf, S
   Melgani, F
   Smara, Y
AF Hoxha, Genc
   Chouaf, Seloua
   Melgani, Farid
   Smara, Youcef
TI Change Captioning: A New Paradigm for Multitemporal Remote Sensing Image Analysis
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change captioning (CC); change detection (CD); convolutional neural networks (CNNs); image captioning (IC); recurrent neural networks (RNNs); support vector machines (SVMs)
ID unsupervised change-detection; classification change detection; model; area
AB Change detection (CD) is among the most important applications in remote sensing (RS) that allows identifying the changes that occurred in a given geographical area across different times. Even though CD systems have seen a lot of progress in RS, their output is either a binary map highlighting the changing area or a semantic change map that indicates the type of change for each pixel. The change maps are often difficult to interpret by end users, and they omit important information such as relationships and attributes of the changed areas. Motivated by the recent advancement of image captioning in the RS community, in this article, we propose to describe the changes over bitemporal images through change sentence descriptions. The aim of this article is to provide a user-friendly interpretation of the occurred changes. To this end, we propose two change captioning (CC) systems that take bitemporal images as input and generate coherent sentence descriptions of the occurred changes. Convolutional neural networks (CNNs) are used to extract discriminative features from the bitemporal images and recurrent neural networks (RNNs) or support vector machines (SVMs) are exploited to generate coherent change descriptions. Furthermore, in the absence of a CC dataset to test our systems, we propose two new datasets. One is based on very high-resolution RGB images, and the other one is based on multispectral RS images. The obtained experimental results show promising capabilities of the proposed systems to generate coherent change descriptions from the bitemporal images. The datasets are available at the following link: https://disi.unitn.it/similar to melgani/datasets.html.
C1 [Hoxha, Genc; Melgani, Farid] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
   [Chouaf, Seloua; Smara, Youcef] Univ Sci & Technol Houari Boumediene, LTIR Lab, Algiers 16111, Algeria.
C3 University of Trento; University Science & Technology Houari Boumediene
RP Melgani, F (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
EM genc.hoxha@unitn.it; chouaf.seloua@gmail.com; melgani@disi.unitn.it; yousmara@yahoo.com
CR Ahlqvist O, 2008, REMOTE SENS ENVIRON, V112, P1226, DOI 10.1016/j.rse.2007.08.012
   [Anonymous], 2018, **DATA OBJECT**, V0, P0, DOI DOI 10.5066/F7WH2P8G
   Bahdanau D, 2016, ARXIV, V0, P0
   Banerjee S, 2005, P ACL WORKSH INTR EX, V0, PP65, DOI 10.3115/1626355.1626389
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bejiga MB, 2021, IEEE GEOSCI REMOTE S, V18, P622, DOI 10.1109/LGRS.2020.2983851
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P820, DOI 10.1109/LGRS.2009.2026188
   Chen H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101662
   Cho K, 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/V1/D14-1179
   Chouaf S., 2021, PROC IEEE INT GEOSCI, V0, P2891
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Geng J., 2017, PROC INT WORKSHOP RE, V0, P1
   Ghoggali N, 2008, IEEE GEOSCI REMOTE S, V5, P212, DOI 10.1109/LGRS.2008.915600
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   Hedjam R, 2020, IEEE J-STARS, V13, P4178, DOI 10.1109/JSTARS.2020.3009116
   Hoxha G, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3105004
   Hoxha G, 2020, IEEE J-STARS, V13, P4462, DOI 10.1109/JSTARS.2020.3013818
   Hoxha G, 2020, 2020 MEDITERRANEAN AND MIDDLE-EAST GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (M2GARSS), V0, PP1, DOI 10.1109/M2GARSS47143.2020.9105191
   Huang W, 2021, IEEE GEOSCI REMOTE S, V18, P436, DOI 10.1109/LGRS.2020.2980933
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Li XL, 2021, IEEE T GEOSCI REMOTE, V59, P5246, DOI 10.1109/TGRS.2020.3010106
   Li ZM, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3159544
   Lin Chin -Yew, 2004, TEXT SUMMARIZATION B, V0, P74
   Liu J, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3071347
   Liu RC, 2019, IEEE ACCESS, V7, P156349, DOI 10.1109/ACCESS.2019.2947286
   Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P1985, DOI 10.1109/TGRS.2019.2951636
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mao JH, 2014, ARXIV, V0, P0
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Melgani F, 2003, IEEE T GEOSCI REMOTE, V41, P2478, DOI 10.1109/TGRS.2003.817269
   Melgani F, 2002, OPT ENG, V41, P3288, DOI 10.1117/1.1518995
   Melgani F, 2006, IEEE GEOSCI REMOTE S, V3, P457, DOI 10.1109/LGRS.2006.875773
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P311, DOI 10.3115/1073083.1073135
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Perronnin F, 2010, PROC CVPR IEEE, V0, PP3384, DOI 10.1109/CVPR.2010.5540009
   Qu B, 2016, INT CONF COMP INFO, V0, P124
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   Shao ZF, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110945
   Shi ZW, 2017, IEEE T GEOSCI REMOTE, V55, P3623, DOI 10.1109/TGRS.2017.2677464
   Simonyan K, 2015, ARXIV, V0, P0
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh P, 2014, INT C PATT RECOG, V0, PP924, DOI 10.1109/ICPR.2014.169
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS
   Sumbul G, 2021, IEEE T GEOSCI REMOTE, V59, P6922, DOI 10.1109/TGRS.2020.3031111
   Sutskever I, 2014, ADV NEUR IN, V27, P0
   Tanti M, 2018, NAT LANG ENG, V24, P467, DOI 10.1017/S1351324918000098
   Vapnik V, 1998, STAT LEARNING THEORY, V0, P156
   Vedantam R, 2015, PROC CVPR IEEE, V0, PP4566, DOI 10.1109/CVPR.2015.7299087
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang BQ, 2020, IEEE J-STARS, V13, P256, DOI 10.1109/JSTARS.2019.2959208
   Wang BQ, 2019, IEEE GEOSCI REMOTE S, V16, P1274, DOI 10.1109/LGRS.2019.2893772
   Wang ZX, 2021, NEUROCOMPUTING, V457, P155, DOI 10.1016/j.neucom.2021.06.059
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   You YN, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152460
   Yousif O, 2013, IEEE T GEOSCI REMOTE, V51, P2032, DOI 10.1109/TGRS.2013.2245900
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Yuan ZH, 2020, IEEE ACCESS, V8, P2608, DOI 10.1109/ACCESS.2019.2962195
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8040189
   Zhang XR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060612
   Zhong P, 2007, IEEE T GEOSCI REMOTE, V45, P3978, DOI 10.1109/TGRS.2007.907109
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 76
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JUN 15
PY 2022
VL 60
IS 
BP 
EP 
DI 10.1109/TGRS.2022.3195692
PG 14
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology
GA 3X8WG
UT WOS:000843314100015
DA 2023-04-26
ER
