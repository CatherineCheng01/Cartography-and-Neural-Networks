
PT J
AU Xu, TT
   Gao, J
   Coco, G
AF Xu, Tingting
   Gao, Jay
   Coco, Giovanni
TI Simulation of urban expansion via integrating artificial neural network with Markov chain - cellular automata
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Urban expansion; artificial neural network; cellular automata; Markov chain; kappa simulation; South Auckland
ID land-use change; cross-border region; logistic-regression; sensitivity-analysis; growth simulation; hierarchy process; model; gis; cover; ca
AB Accurate simulations and predictions of urban expansion are critical to manage urbanization and explicitly address the spatiotemporal trends and distributions of urban expansion. Cellular Automata integrated Markov Chain (CA-MC) is one of the most frequently used models for this purpose. However, the urban suitability index (USI) map produced from the conventional CA-MC is either affected by human bias or cannot accurately reflect the possible nonlinear relations between driving factors and urban expansion. To overcome these limitations, a machine learning model (Artificial Neural Network, ANN) was integrated with CA-MC instead of the commonly used Analytical Hierarchy Process (AHP) and Logistic Regression (LR) CA-MC models. The ANN was optimized to create the USI map and then integrated with CA-MC to spatially allocate urban expansion cells. The validated results of kappa and fuzzy kappa simulation indicate that ANN-CA-MC outperformed other variously coupled CA-MC modelling approaches. Based on the ANN-CA-MC model, the urban area in South Auckland is predicted to expand to 1340.55 ha in 2026 at the expense of non-urban areas, mostly grassland and open-bare land. Most of the future expansion will take place within the planned new urban growth zone.
C1 [Xu, Tingting; Gao, Jay; Coco, Giovanni] Univ Auckland, Sch Environm, Auckland, New Zealand.
C3 University of Auckland
RP Xu, TT (corresponding author), Univ Auckland, Sch Environm, Auckland, New Zealand.
EM txu648@aucklanduni.ac.nz
CR Aburas MM, 2017, INT J APPL EARTH OBS, V59, P65, DOI 10.1016/j.jag.2017.03.006
   Aburas MM, 2016, INT J APPL EARTH OBS, V52, P380, DOI 10.1016/j.jag.2016.07.007
   Angel S, 2011, PROG PLANN, V75, P53, DOI 10.1016/j.progress.2011.04.001
   [Anonymous], 1986, PARALLEL DISTRIBUTED, V0, P0
   Arsanjani JJ, 2013, CITIES, V32, P33, DOI 10.1016/j.cities.2013.01.005
   Arsanjani JJ, 2013, INT J APPL EARTH OBS, V21, P265, DOI 10.1016/j.jag.2011.12.014
   Auckland Regional Council, 2010, BRIEF HIST AUCKL URB, V0, P0
   Azari M, 2016, GISCI REMOTE SENS, V53, P183, DOI 10.1080/15481603.2015.1137111
   Basse RM, 2016, APPL GEOGR, V67, P94, DOI 10.1016/j.apgeog.2015.12.001
   Basse RM, 2014, APPL GEOGR, V53, P160, DOI 10.1016/j.apgeog.2014.06.016
   Batty M., 1999, COMPUTERS, V0, P0
   Batty M., 1994, ENVIRON PLANN B, V21, P31, DOI 10.1068/B21S031
   Berberoglu S, 2016, LANDSCAPE URBAN PLAN, V153, P11, DOI 10.1016/j.landurbplan.2016.04.017
   Bihamta N, 2015, J INDIAN SOC REMOTE, V43, P407, DOI 10.1007/s12524-014-0402-8
   Clarke KC, 1997, ENVIRON PLANN B, V24, P247, DOI 10.1068/b240247
   Dahiya B. S., 2016, SPATIAL DIVERSITY DY, V0, PP209, DOI 10.1007/978-94-017-9786-3_11
   Du GD, 2018, INT J GEOGR INF SCI, V32, P757, DOI 10.1080/13658816.2017.1410550
   Dymond JR, 2017, NEW ZEAL J ECOL, V41, P56, DOI 10.20417/nzjecol.41.5
   Feng Y., 2012, ADV SPATIAL DATA HAN, V0, P27
   Feng YJ, 2016, STOCH ENV RES RISK A, V30, P1387, DOI 10.1007/s00477-015-1128-z
   Feng YJ, 2011, LANDSCAPE URBAN PLAN, V102, P188, DOI 10.1016/j.landurbplan.2011.04.004
   Ferchichi A, 2018, KNOWL INF SYST, V55, P719, DOI 10.1007/s10115-017-1102-9
   Gao J., 2016, URBAN SPRAWL AUCKLAN, V0, P0
   Ghosh Pramit, 2017, REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT, V5, P64, DOI 10.1016/j.rsase.2017.01.005
   Grekousis G, 2013, CITIES, V30, P193, DOI 10.1016/j.cities.2012.03.006
   Hagan M.T., 1996, NEURAL NETWORK DESIG, V0, P0
   Hagenauer J, 2012, INT J GEOGR INF SCI, V26, P963, DOI 10.1080/13658816.2011.619501
   He CY, 2008, LANDSCAPE URBAN PLAN, V86, P79, DOI 10.1016/j.landurbplan.2007.12.010
   Hewitt R, 2017, COMPUT ENVIRON URBAN, V62, P113, DOI 10.1016/j.compenvurbsys.2016.10.011
   Hosseinali F., 2008, AM J APPL SCI, V5, P1187, DOI 10.3844/ajassp.2008.1187.1198
   Islam K, 2018, ECOL INDIC, V88, P439, DOI 10.1016/j.ecolind.2018.01.047
   Jat MK, 2017, EGYPT J REMOTE SENS, V20, P223, DOI 10.1016/j.ejrs.2017.02.002
   Jenerette GD, 2007, LANDSCAPE ECOL, V22, P353, DOI 10.1007/s10980-006-9032-z
   Kamusoko C, 2009, APPL GEOGR, V29, P435, DOI 10.1016/j.apgeog.2008.10.002
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laffan S.W., 1998, P 3 INT C GEOCOMPUTA, V0, P0
   Lagarias A, 2012, APPL GEOGR, V34, P146, DOI 10.1016/j.apgeog.2011.10.018
   Li X, 2000, INT J GEOGR INF SCI, V14, P131, DOI 10.1080/136588100240886
   Li X, 2002, INT J GEOGR INF SCI, V16, P323, DOI 10.1080/13658810210137004
   Li X, 2017, INT J GEOGR INF SCI, V31, P1606, DOI 10.1080/13658816.2017.1301457
   Li X, 2013, J ENVIRON MANAGE, V130, P106, DOI 10.1016/j.jenvman.2013.08.055
   Li ZL, 2018, SCI TOTAL ENVIRON, V636, P1180, DOI 10.1016/j.scitotenv.2018.04.361
   Liao JF, 2016, ENVIRON MODELL SOFTW, V75, P163, DOI 10.1016/j.envsoft.2015.10.014
   Lin YP, 2011, INT J GEOGR INF SCI, V25, P65, DOI 10.1080/13658811003752332
   Lipton ZC., 2015, ARXIV PREPRINT ARXIV, V0, P0
   Liu XP, 2017, LANDSCAPE URBAN PLAN, V168, P94, DOI 10.1016/j.landurbplan.2017.09.019
   Liu Y, 2012, INT J GEOGR INF SCI, V26, P151, DOI 10.1080/13658816.2011.577434
   Liu YL, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9050796
   Moghadam HS, 2013, APPL GEOGR, V40, P140, DOI 10.1016/j.apgeog.2013.01.009
   Mohammadi M, 2013, GEOGR TECH, V8, P57
   Mustafa A, 2018, INT J GEOGR INF SCI, V32, P2317, DOI 10.1080/13658816.2018.1503275
   Mustafa A, 2018, URBAN STUD, V55, P3279, DOI 10.1177/0042098017749176
   Mustafa A, 2018, EUR J REMOTE SENS, V51, P391, DOI 10.1080/22797254.2018.1442179
   Mustafa A, 2018, COMPUT ENVIRON URBAN, V67, P147, DOI 10.1016/j.compenvurbsys.2017.09.009
   Mustafa A, 2017, LAND USE POLICY, V69, P529, DOI 10.1016/j.landusepol.2017.10.009
   Narain V, 2017, LAND USE POLICY, V64, P145, DOI 10.1016/j.landusepol.2017.01.050
   Olden JD, 2002, ECOL MODEL, V154, P135, DOI 10.1016/S0304-3800(02)00064-9
   Paliwal M, 2009, EXPERT SYST APPL, V36, P2, DOI 10.1016/j.eswa.2007.10.005
   Park S, 2011, LANDSCAPE URBAN PLAN, V99, P104, DOI 10.1016/j.landurbplan.2010.09.001
   Pijanowski B. C., 2002, COMPUTERS, V0, P0
   Pijanowski BC, 2009, INT J ENVIRON RES, V3, P493
   Pijanowski BC, 2014, ENVIRON MODELL SOFTW, V51, P250, DOI 10.1016/j.envsoft.2013.09.015
   Poelmans L, 2010, COMPUT ENVIRON URBAN, V34, P17, DOI 10.1016/j.compenvurbsys.2009.06.001
   Pontius RG, 2010, SUSTAIN SCI, V5, P39, DOI 10.1007/s11625-009-0095-z
   Sante I, 2010, LANDSCAPE URBAN PLAN, V96, P108, DOI 10.1016/j.landurbplan.2010.03.001
   Seto KC, 2011, GLOBAL ENVIRON CHANG, V21, PS94, DOI 10.1016/j.gloenvcha.2011.08.005
   Shafizadeh-Moghadam H, 2017, COMPUT ENVIRON URBAN, V64, P297, DOI 10.1016/j.compenvurbsys.2017.04.002
   Shafizadeh-Moghadam H, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-5986-3
   Sudhira H., 2004, INT J APPL EARTH OBS, V5, P29, DOI 10.1016/J.JAG.2003.08.002
   Tayyebi A, 2016, ENVIRON MODELL SOFTW, V84, P70, DOI 10.1016/j.envsoft.2016.06.018
   Tayyebi A, 2014, ENVIRON MODELL SOFTW, V59, P202, DOI 10.1016/j.envsoft.2014.05.022
   Tayyebi A, 2014, INT J APPL EARTH OBS, V28, P102, DOI 10.1016/j.jag.2013.11.008
   Tong Fei, 2005, TSINGHUA SCIENCE AND TECHNOLOGY, V10, P233, DOI 10.1016/S1007-0214(05)70060-2
   van Vliet J, 2016, ENVIRON MODELL SOFTW, V82, P174, DOI 10.1016/j.envsoft.2016.04.017
   van Vliet J, 2013, ECOL MODEL, V261, P32, DOI 10.1016/j.ecolmodel.2013.03.019
   van Vliet J, 2011, ECOL MODEL, V222, P1367, DOI 10.1016/j.ecolmodel.2011.01.017
   Visser H, 2006, ENVIRON MODELL SOFTW, V21, P346, DOI 10.1016/j.envsoft.2004.11.013
   Wang HJ, 2013, LANDSCAPE URBAN PLAN, V110, P99, DOI 10.1016/j.landurbplan.2012.10.016
   White R., 2000, COMPUTERS, V0, P0
   White R., 1994, GEOGR SYST, V1, P237
   Wu FL, 1998, INT J GEOGR INF SCI, V12, P63, DOI 10.1080/136588198242012
   Wu FL, 2002, INT J GEOGR INF SCI, V16, P795, DOI 10.1080/13658810210157769
   Yang QS, 2008, COMPUT GEOSCI-UK, V34, P592, DOI 10.1016/j.cageo.2007.08.003
   Yang WR, 2011, ECOL COMPLEX, V8, P153, DOI 10.1016/j.ecocom.2011.01.004
   Yang X, 2016, GEOMAT NAT HAZ RISK, V7, P918, DOI 10.1080/19475705.2014.1001797
   Yin HW, 2018, CITIES, V81, P214, DOI 10.1016/j.cities.2018.04.010
   Zhang HH, 2015, STOCH ENV RES RISK A, V29, P63, DOI 10.1007/s00477-014-0942-z
NR 87
TC 56
Z9 58
U1 7
U2 74
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD JUN 15
PY 2019
VL 33
IS 10
BP 1960
EP 1983
DI 10.1080/13658816.2019.1600701
EA APR 2019
PG 24
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA IS7TS
UT WOS:000467186700001
DA 2023-04-26
ER

PT J
AU Masiero, A
   Tucci, G
   Conti, A
   Fiorini, L
   Vettore, A
AF Masiero, A.
   Tucci, G.
   Conti, A.
   Fiorini, L.
   Vettore, A.
TI INITIAL EVALUATION OF THE POTENTIAL OF SMARTPHONE STEREO-VISION IN MUSEUM VISITS
SO 2ND INTERNATIONAL CONFERENCE OF GEOMATICS AND RESTORATION (GEORES 2019)
LA English
DT Proceedings Paper
DE Smartphone; Stereo-vision; Mobile mapping; Recognition; Laser Scanning; Augmented Reality Museum
ID registration
AB The recent introduction of new technologies such as augmented reality, machine learning and the worldwide spread of mobile devices provided with imaging, navigation sensors and high computational power can be exploited in order to drammatically change the museum visit experience. Differently from the traditional use of museum docents or audio guides, the introduction of digital technologies already proved to be useful in order to improve the interest of the visitor thanks to the increased interaction and involvement, reached also by means of visual effects and animations. Actually, the availability of 3D representations, augmented reality and navigation abilities directly on the visitor's device can lead to a personalized visit, enabling the visitor to have an experience tailored on his/her needs. In this framework, this paper aims at investigating the potentialities of smartphone stereo-vision to improve the geometric information about the artworks available on the visitor's device. More specifically, in this work smartphone stereo-vision will used as a 3D model generation tool in a 3D artwork recognition system based on a neural network classifier.
C1 [Masiero, A.; Vettore, A.] Univ Padua, Interdept Res Ctr Geomat CIRGEO, Viale Univ 16, I-35020 Legnaro, PD, Italy.
   [Tucci, G.; Conti, A.; Fiorini, L.] Univ Florence, Dept Civil & Environm Engn, GeCO Lab, Via Micheli 8, I-50121 Florence, Italy.
C3 University of Padua; University of Florence
RP Masiero, A (corresponding author), Univ Padua, Interdept Res Ctr Geomat CIRGEO, Viale Univ 16, I-35020 Legnaro, PD, Italy.
EM masiero@dei.unipd.it; grazia.tucci@unifi.it; arch.a.conti@gmail.com; lidia.fiorini@gmail.com; antonio.vettore@unipd.it
CR Alsubaie NM, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17102237
   Banfi F, 2017, INT ARCH PHOTOGRAMM, V42-2, P57, DOI 10.5194/isprs-archives-XLII-2-W5-57-2017
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, P0, DOI 10.1145/3145534
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Dabove P, 2018, IEEE POSITION LOCAT, V0, P175
   Geppert M., 2018, EFFICIENT 2D 3D MATC, V0, P0
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li B, 2015, COMPUT VIS IMAGE UND, V131, P1, DOI 10.1016/j.cviu.2014.10.006
   Lingua A, 2009, SENSORS-BASEL, V9, P3745, DOI 10.3390/s90503745
   Lukianto C., 2011, ARCH FOTOGRAM KARTOG, V22, P311
   Masiero A., 2018, INT ARCH PHOTOGRAMM, VXLII-1, P289, DOI 10.5194/ISPRSARCHIVES-XLII-1-289-2018
   Masiero A, 2014, MICROMACHINES-BASEL, V5, P1012, DOI 10.3390/mi5041012
   Museums+Heritage Advisor, 2015, INS VIS EXP IS KEY M, V0, P0
   Poiesi F, 2017, 14TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION (CVMP), V0, P0, DOI DOI 10.1145/3150165.3150166
   Richter F., 2018, SMARTPHONE MARKET IS, V0, P0
   Saeedi S, 2014, SENSORS-BASEL, V14, P5742, DOI 10.3390/s140405742
   Sakr M., 2018, ISPRS INT ARCH PHOTO, VXLII-1, P379
   Steder B, 2010, PROC WORKSHOP DEFINI, V44, P0
   Su H, 2015, IEEE I CONF COMP VIS, V0, PP945, DOI 10.1109/ICCV.2015.114
   Tucci G, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8030401
   Zanuttigh P, 2017, IEEE IMAGE PROC, V0, P3615
NR 27
TC 2
Z9 2
U1 0
U2 1
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 1682-1750
EI 2194-9034
J9 INT ARCH PHOTOGRAMM
PD JUN 15
PY 2019
VL 42-2
IS W11
BP 837
EP 842
DI 10.5194/isprs-archives-XLII-2-W11-837-2019
PG 6
WC Architecture; Geography; Geography, Physical; Remote Sensing
SC Architecture; Geography; Physical Geography; Remote Sensing
GA BP8XP
UT WOS:000568508700115
DA 2023-04-26
ER

PT J
AU Kim, JS
   Baek, D
   Seo, IW
   Shin, J
AF Kim, Jun Song
   Baek, Donghae
   Seo, Il Won
   Shin, Jaehyun
TI Retrieving shallow stream bathymetry from UAV-assisted RGB imagery using a geospatial regression method
SO GEOMORPHOLOGY
LA English
DT Article
DE Shallow water bathymetry; RGB imagery; Spatial heterogeneity; Geographically weighted regression
ID geographically weighted regression; multispectral satellite imagery; matter concentration; spatial variability; coastal bathymetry; water depths; river; flow; bottom; model
AB Bathymetric mapping is a prerequisite procedure to conduct assessments of water quality, habitat and environmental flow for riverine ecosystems using hydraulic modelling. This study evaluates the capability of a geographically weighted regression (GWR) model, which can capture a spatially heterogeneous relationship between inputs and an output, to retrieve bathymetry of a shallow stream, of which water depth is less than about 1 m from simple RGB imagery. A field experiment was performed for measuring water depth and simultaneously for acquiring remotely-sensed data with RGB digital numbers (DN) using a digital camera mounted on an unmanned aerial vehicle (UAV). A 2D shallow water model, which was validated by comparison with the field-surveyed data, was used to simulate the water depth of unmeasured regions. Band ratios of ln(DNG/DNR) was selected as an optimal spectral input of bathymetric inversion models through the principal component analysis (PCA). Results showed that global inversion models based on multiple linear regression (MLR) and artificial neural network (ANN) resulted in large discrepancy between estimation and observation due to the spatially varying response of the PCA-selected band ratio to water depth over the experimental channel. In contrast, the GWR model successfully alleviated the biases of the conventional models as R-2 increased to 0.85 from 0.60 by accurately modelling the effect of spatial heterogeneity, which arose from variable bottom types attributed to submerged vegetation, on the remote-sensing radiance-water depth relationship. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Kim, Jun Song] Univ Minnesota, Dept Earth Sci, Minneapolis, MN 55455 USA.
   [Baek, Donghae; Seo, Il Won] Seoul Natl Univ, Dept Civil & Environm Engn, Seoul 08826, South Korea.
   [Kim, Jun Song; Shin, Jaehyun] Seoul Natl Univ, Inst Engn Res, Seoul 08826, South Korea.
C3 University of Minnesota System; University of Minnesota Twin Cities; Seoul National University (SNU); Seoul National University (SNU)
RP Seo, IW (corresponding author), Seoul Natl Univ, Dept Civil & Environm Engn, Seoul 08826, South Korea.
EM seoilwon@snu.ac.kr
CR Abdallah H, 2013, IEEE J-STARS, V6, P202, DOI 10.1109/JSTARS.2012.2209864
   Aguilera AM, 2006, COMPUT STAT DATA AN, V50, P1905, DOI 10.1016/j.csda.2005.03.011
   Baek D, 2019, ADV WATER RESOUR, V127, P76, DOI 10.1016/j.advwatres.2019.03.007
   Bartley R, 2002, IAHS-AISH P, V0, P35
   Beisel JN, 2000, HYDROBIOLOGIA, V422, P163, DOI 10.1023/A:1017094606335
   Brando VE, 2009, REMOTE SENS ENVIRON, V113, P755, DOI 10.1016/j.rse.2008.12.003
   Brasington J, 2000, EARTH SURF PROC LAND, V25, P973, DOI 10.1002/1096-9837(200008)25:9<973::AID-ESP111>3.0.CO;2-Y
   Brunsdon C, 1996, GEOGR ANAL, V28, P281, DOI 10.1111/j.1538-4632.1996.tb00936.x
   Cannizzaro JP, 2006, REMOTE SENS ENVIRON, V101, P13, DOI 10.1016/j.rse.2005.12.002
   Carbonneau PE, 2006, EARTH SURF PROC LAND, V31, P1413, DOI 10.1002/esp.1341
   Ceyhun O, 2010, ESTUAR COAST SHELF S, V89, P89, DOI 10.1016/j.ecss.2010.05.015
   Chen J, 2015, ESTUAR COAST SHELF S, V155, P104, DOI 10.1016/j.ecss.2015.01.018
   Cotton JA, 2006, GEOMORPHOLOGY, V77, P320, DOI 10.1016/j.geomorph.2006.01.010
   Crowder DW, 2000, J HYDROL, V230, P172, DOI 10.1016/S0022-1694(00)00177-3
   Ding K, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18020552
   Ferguson RI, 2003, WATER RESOUR RES, V39, P0, DOI 10.1029/2003WR001965
   Fonstad MA, 2005, GEOMORPHOLOGY, V72, P320, DOI 10.1016/j.geomorph.2005.06.005
   Fotheringham AS, 1998, ENVIRON PLANN A, V30, P1905, DOI 10.1068/a301905
   Fujita I, 1998, J HYDRAUL RES, V36, P397, DOI 10.1080/00221689809498626
   Guenther G.C., 2000, P 20 EARSEL S WORKSH, V0, P0
   Hilldale RC, 2008, EARTH SURF PROC LAND, V33, P773, DOI 10.1002/esp.1575
   Hondzo M, 2013, ECOHYDROLOGY, V6, P679, DOI 10.1002/eco.1391
   Jakob S, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010088
   Jia YF, 1999, J HYDRAUL ENG-ASCE, V125, P924, DOI 10.1061/(ASCE)0733-9429(1999)125:9(924)
   Julien PY, 2002, J HYDRAUL ENG-ASCE, V128, P1042, DOI 10.1061/(ASCE)0733-9429(2002)128:12(1042)
   KALKWIJK JPT, 1980, J HYDRAUL RES, V18, P327, DOI 10.1080/00221688009499539
   Kanno A, 2012, IEEE GEOSCI REMOTE S, V9, P715, DOI 10.1109/LGRS.2011.2179517
   Kim JongMin, 2015, JOURNAL OF KOREA WATER RESOURCES ASSOCIATION, V48, P367
   Kim JS, 2018, J HYDRO-ENVIRON RES, V20, P63, DOI 10.1016/j.jher.2018.04.008
   Kinzel PJ, 2007, J HYDRAUL ENG-ASCE, V133, P838, DOI 10.1061/(ASCE)0733-9429(2007)133:7(838)
   Kutser T, 2012, REMOTE SENS ENVIRON, V123, P334, DOI 10.1016/j.rse.2012.04.004
   Lamarre H, 2008, GEOMORPHOLOGY, V99, P270, DOI 10.1016/j.geomorph.2007.11.005
   Lee ZP, 1999, APPL OPTICS, V38, P3831, DOI 10.1364/AO.38.003831
   Legleiter CJ, 2013, RIVER RES APPL, V29, P760, DOI 10.1002/rra.2560
   Legleiter CJ, 2016, EARTH SURF PROC LAND, V41, P344, DOI 10.1002/esp.3794
   Legleiter CJ, 2009, EARTH SURF PROC LAND, V34, P1039, DOI 10.1002/esp.1787
   Legleiter CJ, 2006, REMOTE SENS ENVIRON, V93, P493
   Lyzenga DR, 2006, IEEE T GEOSCI REMOTE, V44, P2251, DOI 10.1109/TGRS.2006.872909
   Ma RH, 2011, J GREAT LAKES RES, V37, P18, DOI 10.1016/j.jglr.2010.12.002
   Ma S, 2014, IEEE T GEOSCI REMOTE, V52, P1205, DOI 10.1109/TGRS.2013.2248372
   Madej MA, 1999, EARTH SURF PROC LAND, V24, P1153, DOI 10.1002/(SICI)1096-9837(199911)24:12<1153::AID-ESP41>3.0.CO;2-8
   Merwade V, 2009, J HYDROL, V371, P169, DOI 10.1016/j.jhydrol.2009.03.026
   Monteys X, 2015, REMOTE SENS-BASEL, V7, P13782, DOI 10.3390/rs71013782
   MYNENI RB, 1995, IEEE T GEOSCI REMOTE, V33, P481, DOI 10.1109/36.377948
   Nazeer M, 2017, SCI TOTAL ENVIRON, V590, P125, DOI 10.1016/j.scitotenv.2017.02.182
   Pan ZG, 2015, IEEE GEOSCI REMOTE S, V12, P2165, DOI 10.1109/LGRS.2015.2453636
   Park I, 2018, ADV WATER RESOUR, V111, P105, DOI 10.1016/j.advwatres.2017.10.035
   Parsons DR, 2013, EARTH SURF PROC LAND, V38, P1244, DOI 10.1002/esp.3367
   Pasternack GB, 2004, RIVER RES APPL, V20, P205, DOI 10.1002/rra.748
   Peddle DR, 2001, COMPUT GEOSCI-UK, V27, P203, DOI 10.1016/S0098-3004(00)00096-0
   PHILPOT WD, 1989, APPL OPTICS, V28, P1569, DOI 10.1364/AO.28.001569
   Reichstetter M, 2015, REMOTE SENS-BASEL, V7, P16756, DOI 10.3390/rs71215852
   Sandidge JC, 1998, REMOTE SENS ENVIRON, V65, P341, DOI 10.1016/S0034-4257(98)00043-1
   Song CG, 2012, ADV WATER RESOUR, V41, P29, DOI 10.1016/j.advwatres.2012.02.003
   Stumpf RP, 2003, LIMNOL OCEANOGR, V48, P547, DOI 10.4319/lo.2003.48.1_part_2.0547
   Su HB, 2014, IEEE T GEOSCI REMOTE, V52, P465, DOI 10.1109/TGRS.2013.2241772
   Su HB, 2008, MAR GEOD, V31, P281, DOI 10.1080/01490410802466652
   Tharme RE, 2003, RIVER RES APPL, V19, P397, DOI 10.1002/rra.736
   Vinayaraj P, 2016, MAR GEOD, V39, P458, DOI 10.1080/01490419.2016.1245227
   Volpe V, 2011, REMOTE SENS ENVIRON, V115, P44, DOI 10.1016/j.rse.2010.07.013
   Wozencraft J, 2003, US HYDR C, V0, P24
   Wu WM, 2005, WATER RESOUR RES, V41, P0, DOI 10.1029/2004WR003730
   Yang GJ, 2017, FRONT PLANT SCI, V8, P0, DOI 10.3389/fpls.2017.01111
NR 63
TC 21
Z9 21
U1 0
U2 39
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-555X
EI 1872-695X
J9 GEOMORPHOLOGY
JI Geomorphology
PD SEP 15
PY 2019
VL 341
IS 
BP 102
EP 114
DI 10.1016/j.geomorph.2019.05.016
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary
SC Physical Geography; Geology
GA IL0DA
UT WOS:000476965100008
DA 2023-04-26
ER

PT J
AU Pokonieczny, K
   Borkowska, S
AF Pokonieczny, Krzysztof
   Borkowska, Sylwia
TI Using artificial neural network for labelling polygon features in topographic maps
SO GEOSCAPE
LA English
DT Article
DE Artificial neural network; Multilayer perceptron; Label localization; Topographic map
AB The purpose of this article was to present the methodology which enables automatic map labelling. This topic is particularly important in the context of the ongoing research into the full automation of visualization process of spatial data stored in the currently used topographic databases (e.g. OpenStreetMap, Vector Map Level 2, etc.). To carry out this task, the artificial neural network (multilayer perceptron) was used. The Vector Map Level 2 was used as a test database. The data for neural network learning (the reference label localization) was obtained from the military topographic map at scale 1 : 50 000. In the article, the method of applying artificial neural networks to the map labelling is presented. Detailed research was carried out on the basis of labels from the feature class "built-up area". The results of the analyses revealed that it is possible to use the artificial intelligence computational methods to automate the process of placing labels on maps. The results showed that 65% of the labels were put on the topographic map in the same place as in the case of the labelling which was done manually by a cartographer. The obtained results can contribute both to the enhancement of the quality of cartographic visualization (e.g. in geoportals) and the partial elimination of the human factor in this process.
C1 [Pokonieczny, Krzysztof; Borkowska, Sylwia] Mil Univ Technol Warsaw, Fac Civil Engn & Geodesy, Warsaw, Poland.
C3 Military University of Technology in Warsaw
RP Borkowska, S (corresponding author), Mil Univ Technol Warsaw, Fac Civil Engn & Geodesy, Warsaw, Poland.
EM sylwia.borkowska@wat.edu.pl
CR [Anonymous], 1998, 7074 STANAG DEP US A, V0, P0
   [Anonymous], 1993, MILV89032 NAT IM SPA, V0, P0
   Been K, 2006, IEEE T VIS COMPUT GR, V12, P773, DOI 10.1109/TVCG.2006.136
   Freeman H, 2005, PATTERN RECOGN LETT, V26, P287, DOI 10.1016/j.patrec.2004.10.023
   Freeman H, 2007, J VISUAL LANG COMPUT, V18, P458, DOI 10.1016/j.jvlc.2007.08.006
   Harrie L, 2005, DEVELOPMENTS IN SPATIAL DATA HANDLING, V0, PP493, DOI 10.1007/3-540-26772-7_38
   Kakoulis KG, 2006, COMP GEOM-THEOR APPL, V35, P143, DOI 10.1016/j.comgeo.2006.03.005
   Reimer A, 2015, CARTOGR GEOGR INF SC, V42, P333, DOI 10.1080/15230406.2015.1053986
   Rylov MA, 2015, GEOINFORMATICA, V19, P463, DOI 10.1007/s10707-014-0214-6
   Suzuki K, 2013, ARTIFICIAL NEURAL NE, V0, P0
   Wu CB, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-6190-4
NR 11
TC 5
Z9 6
U1 0
U2 1
PU SCIENDO
PI WARSAW
PA DE GRUYTER POLAND SP Z O O, BOGUMILA ZUGA 32A STR, 01-811 WARSAW, POLAND
SN 1802-1115
EI 
J9 GEOSCAPE
JI GeoScape
PD DEC 15
PY 2019
VL 13
IS 2
BP 125
EP 131
DI 10.2478/geosc-2019-0012
PG 7
WC Geography
SC Geography
GA JX8JQ
UT WOS:000503975000006
DA 2023-04-26
ER

PT J
AU Zhang, PB
   Wang, X
   Chen, JF
   You, W
   Zhang, WH
AF Zhang, Pengbo
   Wang, Xue
   Chen, Junfeng
   You, Wei
   Zhang, Weihang
TI Spectral and Temporal Feature Learning With Two-Stream Neural Networks for Mental Workload Assessment
SO IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING
LA English
DT Article
DE Mental workload; deep learning; feature fusion; convolutional neural network; EEG
ID working-memory; n-back; eeg; task; classification
AB People's mental workload profoundly affects their work efficiency and health. Mental workload assessment can be used to effectively avoid serious accidents caused by excessive mental workload. Both electroencephalogram (EEG) spectral features and its temporal features have proven to be useful in addressing this problem. The fusion of the two types of features can provide rich distinguishing information for improving mental workload assessment. Benefiting from the progress of deep learning, this study proposes the two-stream neural networks (TSNN) for fusing the two types of EEG features. Compared with hand-crafted features, the TSNN can learn and fuse EEG features from the spectral and temporal dimensions automatically without prior knowledge. The TSNN includes a spectral stream and a temporal stream. Each stream consists of a convolutional neural network (CNN) and a temporal convolutional network (TCN) to learn spectral or temporal features from EEG topographic maps. To fuse the learned spectral and temporal information, we concatenate the output of the two streams prior to the fully connected layer. EEG data were collected from 17 subjects who performed n-back tasks with easy, medium, and hard difficulty levels, leading to a three-class mental workload classification. The results show that the TSNN achieves an average accuracy of 91.9%, which is a significant improvement over baseline classifiers based on hand-crafted features. The TSNN also outperforms state-of-the-art deep learning methods developed for EEG classification. The results indicate that the proposed structure is promising for fusing spectral and temporal features for mental workload assessment. In addition, it provides a high-precision approach for potential applications during cognitive activities.
C1 [Zhang, Pengbo; Wang, Xue; Chen, Junfeng; You, Wei; Zhang, Weihang] Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, X (corresponding author), Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
EM zpb14@mails.tsinghua.edu.cn; wangxue@mail.tsinghua.edu.cn; chenjf17@mails.tsinghua.edu.cn; youw16@mails.tsinghua.edu.cn; zwh15@mails.tsinghua.edu.cn
FU National Key Research and Development Program of China [2018YFB2003501]; National Natural Science Foundation of China [61472216]
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Antonenko P, 2010, EDUC PSYCHOL REV, V22, P425, DOI 10.1007/s10648-010-9130-y
   Bai S., 2018, ARXIV PREPRINT ARXIV, V0, P0
   Baldwin CL, 2012, NEUROIMAGE, V59, P48, DOI 10.1016/j.neuroimage.2011.07.047
   Bashivan P., 2016, P INT C LEARN REPR S, V0, P0
   Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307
   Borghini G, 2014, NEUROSCI BIOBEHAV R, V44, P58, DOI 10.1016/j.neubiorev.2012.10.003
   Brouwer AM, 2012, J NEURAL ENG, V9, P0, DOI 10.1088/1741-2560/9/4/045008
   Chai RF, 2017, IEEE J BIOMED HEALTH, V21, P715, DOI 10.1109/JBHI.2016.2532354
   Chen YN, 2008, CLIN NEUROPHYSIOL, V119, P1546, DOI 10.1016/j.clinph.2008.03.003
   Christensen JC, 2012, NEUROIMAGE, V59, P57, DOI 10.1016/j.neuroimage.2011.07.091
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dimitrakopoulos GN, 2017, IEEE T NEUR SYS REH, V25, P1940, DOI 10.1109/TNSRE.2017.2701002
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Fan J, 2018, IEEE T BIO-MED ENG, V65, P43, DOI 10.1109/TBME.2017.2693157
   Gomez-Herrero G, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, V0, P130
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Hefron RG, 2017, PATTERN RECOGN LETT, V94, P96, DOI 10.1016/j.patrec.2017.05.020
   Hogervorst MA, 2014, FRONT NEUROSCI-SWITZ, V8, P0, DOI 10.3389/fnins.2014.00322
   HOLM S, 1979, SCAND J STAT, V6, P65
   Ioffe S., 2016, BATCH NORMALIZATION, V0, P0
   Jiao ZC, 2018, PATTERN RECOGN, V76, P582, DOI 10.1016/j.patcog.2017.12.002
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lea C, 2017, PROC CVPR IEEE, V0, PP1003, DOI 10.1109/CVPR.2017.113
   Li JP, 2018, COGN COMPUT, V10, P368, DOI 10.1007/s12559-017-9533-x
   Liu Y, 2015, IEEE T SMART GRID, V0, P0
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068
   Muhl C, 2014, FRONT NEUROSCI-SWITZ, V8, P0, DOI 10.3389/fnins.2014.00114
   Roy RN, 2016, J NEURAL ENG, V13, P0, DOI 10.1088/1741-2560/13/2/026019
   Scharinger C, 2015, PSYCHOPHYSIOLOGY, V52, P1293, DOI 10.1111/psyp.12500
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Simonyan K, 2015, ARXIV, V0, P0
   Stikic M, 2014, FRONT NEUROSCI-SWITZ, V8, P0, DOI 10.3389/fnins.2014.00342
   Supratak A, 2017, IEEE T NEUR SYS REH, V25, P1998, DOI 10.1109/TNSRE.2017.2721116
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   van den Oord A., 2016, PROC 9 ISCA SPEECH S, V0, P0
   Wang F, 2018, LECT NOTES COMPUT SC, V10705, P82, DOI 10.1007/978-3-319-73600-6_8
   Wang SY, 2016, IEEE T HUM-MACH SYST, V46, P424, DOI 10.1109/THMS.2015.2476818
   Wang YK, 2015, IEEE T NEUR SYS REH, V23, P1085, DOI 10.1109/TNSRE.2015.2415520
   Wang ZH, 2012, NEUROIMAGE, V59, P64, DOI 10.1016/j.neuroimage.2011.07.094
   WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901
   Xu K, 2017, IEEE T CIRC SYST VID, V27, P567, DOI 10.1109/TCSVT.2017.2665359
   Yang JX, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050800
   Yang JX, 2017, IEEE T GEOSCI REMOTE, V55, P4729, DOI 10.1109/TGRS.2017.2698503
   Yu K, 2015, J NEURAL ENG, V12, P0, DOI 10.1088/1741-2560/12/4/046020
   Zarjam P, 2013, COMPUT BIOL MED, V43, P2186, DOI 10.1016/j.compbiomed.2013.08.021
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang PB, 2019, IEEE T NEUR SYS REH, V27, P31, DOI 10.1109/TNSRE.2018.2884641
NR 51
TC 34
Z9 37
U1 6
U2 47
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1534-4320
EI 1558-0210
J9 IEEE T NEUR SYS REH
JI IEEE Trans. Neural Syst. Rehabil. Eng.
PD JUN 15
PY 2019
VL 27
IS 6
BP 1149
EP 1159
DI 10.1109/TNSRE.2019.2913400
PG 11
WC Engineering, Biomedical; Rehabilitation
SC Engineering; Rehabilitation
GA IC6ZG
UT WOS:000471121000005
PM 31034417
DA 2023-04-26
ER
