
PT J
AU Lin, ZS
   Wang, QY
   Lai, C
AF Lin, Zhishuang
   Wang, Qianyu
   Lai, Chang
TI Analysis of Airglow Image Classification Based on Feature Map Visualization
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE airglow images; image classification; convolutional neural network; feature map visualization
ID neural-networks; algorithm
AB All-sky airglow imagers (ASAIs) are used in the Meridian Project to observe the airglow in the middle and upper atmosphere to study the atmospheric perturbation. However, the ripples of airglow caused by the perturbation are only visible in the airglow images taken on a clear night. It is a problem to effectively select images suitable for scientific analysis from the enormous amount of airglow images captured under various environments due to the low efficiency and subjectivity of traditional manual classification. We trained a classification model based on convolutional neural network to distinguish between airglow images from clear nights and unclear nights. The data base contains 1688 images selected from the airglow images captured at Xinglong station (40.4 degrees N, 30.5 degrees E). The entire training process was tracked by feature maps which visualized every resulting classification model. The classification models with the clearest feature maps were saved for future use. We cropped the central part of the airglow images to avoid disturbance from the artificial lights at the edge of the vision field according to the feature maps of our first training. The accuracy of the saved model is 99%. The feature maps of five categories also indicate the reliability of the classification model.
C1 [Lin, Zhishuang; Lai, Chang] Chongqing Univ Posts & Telecommun, Sch Sci, Chongqing 400065, Peoples R China.
   [Wang, Qianyu] Univ Oxford, Merton Coll, Oxford OX1 4JD, England.
   [Lai, Chang] Natl Space Sci Ctr, State Key Lab Space Weather, Beijing 100190, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; University of Oxford; Chinese Academy of Sciences; National Space Science Center, CAS
RP Lai, C (corresponding author), Chongqing Univ Posts & Telecommun, Sch Sci, Chongqing 400065, Peoples R China.; Lai, C (corresponding author), Natl Space Sci Ctr, State Key Lab Space Weather, Beijing 100190, Peoples R China.
EM laichang@cqupt.edu.cn
FU Science Foundation of Chongqing [cstc2020jcyj-msxmX0914]; Specialized Research Fund for State Key Laboratories
CR [Anonymous], 1989, ADV NEURAL INFORM PR, V0, P0
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dosovitskiy A, 2020, ARXIV, V0, P0
   E. Hinton Geoffrey, 2012, ARXIV, V0, P0, DOI DOI 10.48550/arXiv:1207.0580
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Erhan Dumitru, 2009, TECHNICAL REPORT, V1341, P1
   Figueiredo CAOB, 2018, J GEOPHYS RES-SPACE, V123, P7843, DOI 10.1029/2018JA025438
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3
   GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219
   Glorot X., 2010, AISTATS, V0, PPPP 249, DOI 10.4236/JSIP.2015.62006
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lai C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131516
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li QZ, 2018, J GEOPHYS RES-SPACE, V123, P2168, DOI 10.1002/2017JA025081
   Linardatos P, 2021, ENTROPY-SWITZ, V23, P0, DOI 10.3390/e23010018
   Long J., 2015, P IEEE C COMP VIS PA, V0, P3431
   Mishra J, 2022, MULTIMED TOOLS APPL, V81, P18915, DOI 10.1007/s11042-022-12531-w
   Paul W., 1974, THESIS HARVARD U CAM, V0, P0
   PETERSON AW, 1973, NATURE, V242, P321, DOI 10.1038/242321a0
   Ramkumar TK, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-89694-3
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rocha MMM, 2022, MULTIMED TOOLS APPL, V0, P0, DOI DOI 10.1007/s11042-022-14206-y
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sau S, 2018, ADV SPACE RES, V62, P1762, DOI 10.1016/j.asr.2018.06.039
   Sedlak R, 2021, ATMOS MEAS TECH, V14, P6821, DOI 10.5194/amt-14-6821-2021
   Simonyan K, 2014, ARXIV, V0, P0
   Toshev A, 2014, PROC CVPR IEEE, V0, PP1653, DOI 10.1109/CVPR.2014.214
   Wang Chi, 2010, CHINESE JOURNAL OF SPACE SCIENCE, V30, P382
   Xu J.Y., 2021, UPPER ATMOSPHERE DYN, V0, P0
   Yu DH, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20071999
   Zagoruyko S, 2017, ARXIV, V0, P0
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, V0, PP2018, DOI 10.1109/ICCV.2011.6126474
   Zhou C, 2018, J GEOPHYS RES-SPACE, V123, P5195, DOI 10.1029/2018JA025352
NR 43
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD MAR 15
PY 2023
VL 13
IS 6
BP 
EP 
DI 10.3390/app13063671
PG 13
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA A8FI2
UT WOS:000957417400001
DA 2023-04-26
ER

PT J
AU Behera, TK
   Bakshi, S
   Nappi, M
   Sa, PK
AF Behera, Tanmay Kumar
   Bakshi, Sambit
   Nappi, Michele
   Sa, Pankaj Kumar
TI Superpixel-Based Multiscale CNN Approach Toward Multiclass Object Segmentation From UAV-Captured Aerial Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Aerial image; convolutional neural network (CNN); deep learning; mutliscale CNN; semantic segmentation; simple linear iterative clustering (SLIC); superpixel; unmanned aerial vehicle (UAV); very high resolution (VHR)
ID networks; features; models
AB Unmanned aerial vehicles (UAVs) are promising remote sensors capable of reforming remote sensing applications. However, for artificial-intelligence-guided tasks, such as land cover mapping and ground-object mapping, most deep-learning-based architectures fail to extract scale-invariant features, resulting in poor performance accuracy. In this context, the article proposes a superpixel-aided multiscale convolutional neural network (CNN) architecture to avoid misclassification in complex urban aerial images. The proposed framework is a two-tier deep-learning-based segmentation architecture. In the first stage, a superpixel-based simple linear iterative cluster algorithm produces superpixel images with crucial contextual information. The second stage comprises a multiscale CNN architecture that uses these information-rich superpixel images to extract scale-invariant features for predicting the object class of each pixel. Two UAV-image-based aerial image datasets: 1) NITRDrone dataset and 2) urban drone dataset (UDD), are considered to perform the experiment. The proposed model outperforms the considered state-of-the-art methods with an intersection of union of 76.39% and 86.85% on UDD and NITRDrone datasets, respectively. Experimentally obtained results prove that the proposed architecture performs superior by achieving better performance accuracy in complex and challenging scenarios.
C1 [Behera, Tanmay Kumar; Bakshi, Sambit; Sa, Pankaj Kumar] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, India.
   [Nappi, Michele] Univ Salerno, Dept Comp Sci, I-84084 Fisciano, Italy.
C3 National Institute of Technology (NIT System); National Institute of Technology Rourkela; University of Salerno
RP Bakshi, S (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, India.
EM tanmay.nitr@gmail.com; sambitbaksi@gmail.com; mnappi@unisa.it; pankajksa@nitrkl.ac.in
FU project titled "Deep learning applications for computer vision task" - NITROAA; Lenovo [P920]; Dell Inception [7820]; NVIDIA Corporation; NVIDIA Titan V and Quadro RTX 8000 GPU; project titled "Applications of Drone Vision using Deep Learning" - Technical Education Quality Improvement Programme; National Project Implementation Unit, Government of India; Project entitled "Computer vision-based smart solutions for UAV remote sensing applications through semantic segmentation" - Vishlesan I-Hub Foundation, IIT Patna (NMCPS-DST), Government of India
CR Achanta R, 2010, 149300 EPFL, V0, P0
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alvarez-Vanhard E., 2021, SCI REMOTE SENS, V3, P0, DOI 10.1016/J.SRS.2021.100019
   [Anonymous], 2013, LANDSAT SERIES, V0, P0
   [Anonymous], 2018, WORLDVIEW SERIES, V0, P0
   Attari N, 2017, PR INT CONF DATA SC, V0, PP50, DOI 10.1109/DSAA.2017.72
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bastani F, 2018, PROC CVPR IEEE, V0, PP4720, DOI 10.1109/CVPR.2018.00496
   Behera T.K., 2023, SUSTAIN COMPUT INFOR, V37, P100841, DOI 10.1016/j.suscom.2022.100841
   Behera Tanmay Kumar, 2022, IEEE J BIOMED HEALTH INFORM, VPP, P0, DOI 10.1109/JBHI.2022.3216270
   Behera TK, 2022, BIG DATA RES, V30, P0, DOI 10.1016/j.bdr.2022.100334
   Behera TK, 2022, COMPUT ELECTRON AGR, V198, P0, DOI 10.1016/j.compag.2022.107094
   Behera TK, 2022, J SIGNAL PROCESS SYS, V0, P0, DOI DOI 10.1007/s11265-022-01777-0
   Behera TK, 2021, IT PROF, V23, P82, DOI 10.1109/MITP.2020.3020433
   Chai DF, 2013, PROC CVPR IEEE, V0, PP1894, DOI 10.1109/CVPR.2013.247
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Y, 2018, LECT NOTES COMPUT SC, V11256, P347, DOI 10.1007/978-3-030-03398-9_30
   Cheng B, 2011, IEEE I CONF COMP VIS, V0, PP2439, DOI 10.1109/ICCV.2011.6126528
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai M, 2022, IEEE T CIRC SYST VID, V32, P4376, DOI 10.1109/TCSVT.2021.3135013
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Fan JY, 2018, IEEE T CIRC SYST VID, V28, P3163, DOI 10.1109/TCSVT.2017.2746684
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fischler M. A., 1987, READINGS COMPUTER VI, V0, PP741, DOI 10.1016/B978-0-08-051581-6.50071-4
   Frohlich B, 2013, ISPRS ANN PHOTO REM, VII-3/W1, P1
   Fukushima K., 1982, NEOCOGNITRON SELF OR, V0, PP267, DOI 10.1007/978-3-642-46466-9_18
   Gibril MBA, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13142787
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Jegou S, 2017, IEEE COMPUT SOC CONF, V0, PP1175, DOI 10.1109/CVPRW.2017.156
   Kattenborn T, 2021, ISPRS J PHOTOGRAMM, V173, P24, DOI 10.1016/j.isprsjprs.2020.12.010
   Kingma D. P., 2015, PROC INT C LEARN REP, V0, PP1, DOI 10.1145/1830483.1830503
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li ZG, 2012, PROC CVPR IEEE, V0, PP789, DOI 10.1109/CVPR.2012.6247750
   MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852
   Ortner M, 2007, INT J COMPUT VISION, V72, P107, DOI 10.1007/s11263-005-5033-7
   PyTorch Docs, 2016, PYTORCH DOC, V0, P0
   ReLu, 2019, RELU ACT FUNCT, V0, P0
   Ronneberger O., 2015, MICCAI, V0, P0, DOI DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmid C, 2001, PROC CVPR IEEE, V0, P39
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sohail A, 2022, IEEE ACCESS, V10, P134557, DOI 10.1109/ACCESS.2022.3230983
   Sommer L, 2019, IEEE T CIRC SYST VID, V29, P2733, DOI 10.1109/TCSVT.2018.2874396
   Statista, 2019, NUMB ACT SAT, V0, P0
   STILLA U, 1995, ISPRS J PHOTOGRAMM, V50, P3, DOI 10.1016/0924-2716(95)98232-O
   Tokarczyk P, 2015, IEEE T GEOSCI REMOTE, V53, P280, DOI 10.1109/TGRS.2014.2321423
   Tong HJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222627
   Van Etten A, 2019, IEEE WINT CONF APPL, V0, PP735, DOI 10.1109/WACV.2019.00083
   Viola P., 2001, IEEE COMPUT SOC C CO, V0, P0, DOI DOI 10.1109/CVPR.2001.990517
   Wang YF, 2020, IEEE T CIRC SYST VID, V30, P2590, DOI 10.1109/TCSVT.2019.2919482
   Wegner JD, 2013, PROC CVPR IEEE, V0, PP1698, DOI 10.1109/CVPR.2013.222
   Xie J, 2021, IEEE T CIRC SYST VID, V31, P246, DOI 10.1109/TCSVT.2020.2975566
   Zhang J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040701
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou HL, 2017, IEEE T INTELL TRANSP, V18, P1713, DOI 10.1109/TITS.2016.2622280
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 58
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2023
VL 16
IS 
BP 1771
EP 1784
DI 10.1109/JSTARS.2023.3239119
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 9B8RQ
UT WOS:000934999600002
DA 2023-04-26
ER

PT J
AU Izumi, H
   Aoki, H
   Nafie, LA
   Dukor, RK
AF Izumi, Hiroshi
   Aoki, Hiroshi
   Nafie, Laurence A.
   Dukor, Rina K.
TI Effect of Conformational Variability on Seasonable Thermal Stability and Cell Entry of Omicron Variants
SO ACS OMEGA
LA English
DT Article
ID homology
AB The Omicron BA.1 variant of SARS-CoV-2 preferentially infects through the cathepsin-mediated endocytic pathway, but the mechanism of cell entry has not been solved yet because BA.4/5 is more fusogenic and more efficiently spread in human lung cells than BA.2. It has been unclear why the Omicron spike is inefficiently cleaved in virions compared with Delta, and how the relatively effective reproduction proceeds without the cell entry through plasma membrane fusion. Conformational variability from deep neural network-based prediction correlates well with the thermodynamic stability of variants. The difference of seasonable pandemic variants in summer and those in winter is distinguishable by this conformational stability, and the geographical optimization of variants is also traceable. Further, the predicted conformational variability maps rationalize the less efficient S1/S2 cleavage of Omicron variants and provide a valuable insight into the cell entry through the endocytic pathway. It is concluded that conformational variability prediction is able to complement transformation information on motifs in protein structures for drug discovery.
C1 [Izumi, Hiroshi; Aoki, Hiroshi; Nafie, Laurence A.] Natl Inst Adv Ind Sci & Technol, Tsukuba, Ibaraki 3058569, Japan.
   [Dukor, Rina K.] BioTools Inc, Jupiter, FL 33458 USA.
C3 National Institute of Advanced Industrial Science & Technology (AIST)
RP Izumi, H (corresponding author), Natl Inst Adv Ind Sci & Technol, Tsukuba, Ibaraki 3058569, Japan.
EM izumi.h@aist.go.jp
FU JSPS KAKENHI [JP19K05431, JP22K05073]
CR Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754
   Bekker GJ, 2022, PROTEIN SCI, V31, P173, DOI 10.1002/pro.4211
   Biopython, 2022, PYTH TOOLS COMP MOL, V0, P0
   Cantuti-Castelvetri L, 2020, SCIENCE, V370, P856, DOI 10.1126/science.abd2985
   Cao YL, 2022, NATURE, V608, P593, DOI 10.1038/s41586-022-04980-y
   Centers for Disease Control and Prevention (CDC), 2022, COVID DAT TRACK, V0, P0
   Dacon C, 2022, SCIENCE, V377, P728, DOI 10.1126/science.abq3773
   Dahms SO, 2018, BIOCHEMISTRY-US, V57, P925, DOI 10.1021/acs.biochem.7b01124
   Daly James L, 2020, SCIENCE, V370, P861, DOI 10.1126/science.abd3072
   Dauparas J, 2022, SCIENCE, V378, P49, DOI 10.1126/science.add2187
   Finn RD, 2014, NUCLEIC ACIDS RES, V42, PD222, DOI 10.1093/nar/gkr1065
   Gruell H, 2022, LANCET INFECT DIS, V22, P1422, DOI 10.1016/S1473-3099(22)00580-1
   Izumi H, 2004, J AM CHEM SOC, V126, P194, DOI 10.1021/ja037752o
   Izumi H, 2021, ACS OMEGA, V6, P19323, DOI 10.1021/acsomega.1c03055
   Izumi H, 2020, ACS OMEGA, V5, P30556, DOI 10.1021/acsomega.0c04472
   Izumi H, 2019, METHODS MOL BIOL, V1958, P329, DOI 10.1007/978-1-4939-9161-7_17
   Izumi H, 2013, J CHEM INF MODEL, V53, P584, DOI 10.1021/ci300420d
   Izumi H, 2009, J ORG CHEM, V74, P1231, DOI 10.1021/jo802233s
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Kimura I, 2022, CELL, V185, P3992, DOI 10.1016/j.cell.2022.09.018
   Lubinski Bailey, 2022, BIORXIV, V0, P0, DOI DOI 10.1101/2022.04.20.488969
   Mannar D, 2022, SCIENCE, V375, P760, DOI 10.1126/science.abn7760
   McCallum Matthew, 2022, SCIENCE, V375, P864, DOI 10.1126/science.abn8652
   Meng B, 2022, NATURE, V603, P706, DOI 10.1038/s41586-022-04474-x
   Mustafa Z, 2022, PLOS ONE, V17, P0, DOI 10.1371/journal.pone.0264723
   Nextstrain, 2022, GEN EP SARS COV 2 SU, V0, P0
   Pasquato A, 2007, FEBS LETT, V581, P5807, DOI 10.1016/j.febslet.2007.11.050
   Pia L, 2022, NAT REV IMMUNOL, V22, P145, DOI 10.1038/s41577-022-00681-9
   Python Software Foundation, 2022, PYTH IS PROGR LANG L, V0, P0
   python-docx, 2022, US, V0, P0
   Schrodinger, 2022, PYMOL, V0, P0
   Sheward DJ, 2022, LANCET INFECT DIS, V22, P1421, DOI 10.1016/S1473-3099(22)00524-2
   Simonetti B, 2022, P NATL ACAD SCI USA, V119, P0, DOI 10.1073/pnas.2201980119
   Sony, 2022, NEUR NETW CONS, V0, P0
   Starr Tyler N, 2020, BIORXIV, V0, P0, DOI DOI 10.1016/j.cell.2020.08.012
   Suzuki R, 2022, NATURE, V603, P700, DOI 10.1038/s41586-022-04462-1
   Taft JM, 2022, CELL, V185, P4008, DOI 10.1016/j.cell.2022.08.024
   Travis J., 2022, ACM T INTEL SYST TEC, V0, P0, DOI DOI 10.1126/science.ade1829
   Tuekprakhon A, 2022, CELL, V185, P2422, DOI 10.1016/j.cell.2022.06.005
   Wang Q, 2022, CELL HOST MICROBE, V30, P1512, DOI 10.1016/j.chom.2022.09.002
   Wang S, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep18962
NR 41
TC 0
Z9 0
U1 0
U2 0
PU AMER CHEMICAL SOC
PI WASHINGTON
PA 1155 16TH ST, NW, WASHINGTON, DC 20036 USA
SN 2470-1343
EI 
J9 ACS OMEGA
JI ACS Omega
PD FEB 21
PY 2023
VL 8
IS 7
BP 7111
EP 7118
DI 10.1021/acsomega.2c08075
EA FEB 2023
PG 8
WC Chemistry, Multidisciplinary
SC Chemistry
GA C5VV2
UT WOS:000933564100001
PM 36844510
DA 2023-04-26
ER

PT J
AU Azariasgari, E
   Hosseinali, F
AF Azariasgari, Elaheh
   Hosseinali, Farhad
TI Evaluating the VGI Users' Level of Expertise: An Application of Statistical and Artificial Neural Network Approaches
SO INTERNATIONAL JOURNAL OF APPLIED GEOSPATIAL RESEARCH
LA English
DT Article
DE Artificial Neural Network; Data Quality; GIS; Statistical Analysis; Tehran; VGI
ID volunteered geographic information; quality; openstreetmap; reputation; systems
AB Currently, online maps are of the most innovative and significant sources of information in people's daily life. However, quality assessment of volunteered geographic information (VGI) data raises some challenges. This research aims to analyze the VGI participants' level of expertise through evaluation of their background information. Towards this goal, an android application was developed to test users' knowledge and cognition about some selected regions of city as well as their background information. In order to evaluate the quality of information expressed by participants, some changes were made in Tehran's online map, and users were asked to identify the changes and to guess the vanished attributes. Statistical and ANN approaches were applied for analysis. The results demonstrated that the ANN was able to predict the percentage of correct answers of a new volunteer with mean squared error of 0.2. This research suggests that users' age and familiarity with the specific region in the city play more significant roles in their expertise in using online maps and in probable participating in VGI.
C1 [Azariasgari, Elaheh] Islamic Azad Univ, South Tehran, Iran.
   [Hosseinali, Farhad] Shahid Rajaee Teacher Training Univ, Tehran, Iran.
C3 Islamic Azad University; Shahid Rajaee Teacher Training University (SRTTU)
RP Hosseinali, F (corresponding author), Shahid Rajaee Teacher Training Univ, Tehran, Iran.
CR Afyouni S, 2019, NEUROIMAGE, V199, P609, DOI 10.1016/j.neuroimage.2019.05.011
   Ali AL, 2014, LECT NOTES COMPUT SC, V8728, P126, DOI 10.1007/978-3-319-11593-1_9
   Antoniou V, 2015, ISPRS ANN PHOTO REM, VII-3, P345, DOI 10.5194/isprsannals-II-3-W5-345-2015
   Astaburuaga J., 2022, DIGITAL GEOGRAPHY SO, V3, P0
   Bordogna G, 2016, INT J DIGIT EARTH, V9, P134, DOI 10.1080/17538947.2014.976774
   Can R, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8070300
   Coleman DJ, 2009, INT J SPAT DATA INFR, V4, P332, DOI 10.2902/1725-0463.2009.04.art16
   Da Costa JN, 2016, GEOD VESTN, V60, P495, DOI 10.15292/geodetski-vestnik.2016.03.495-508
   Dai C., 2008, J CLIN EPIDEMIOL, V85, P45
   Feng Y, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7020039
   Fisek MH, 2013, SOC SCI RES, V42, P482, DOI 10.1016/j.ssresearch.2012.09.010
   Fogliaroni P, 2018, GEO-SPAT INF SCI, V21, P213, DOI 10.1080/10095020.2018.1496556
   Forghani M, 2014, ISPRS INT GEO-INF, V3, P750, DOI 10.3390/ijgi3020750
   Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y
   Goodchild MF, 2012, SPAT STAT-NETH, V1, P110, DOI 10.1016/j.spasta.2012.03.002
   Hosseinali F, 2014, POL J ENVIRON STUD, V23, P727
   Kessler F, 2011, CARTOGR GEOGR INF SC, V38, P258, DOI 10.1559/15230406382258
   Klonner C, 2021, INT J DISAST RISK SC, V12, P56, DOI 10.1007/s13753-020-00312-8
   Lin W, 2018, GEOFORUM, V89, P73, DOI 10.1016/j.geoforum.2018.01.005
   Martella R, 2019, GEOD VESTN, V63, P213, DOI 10.15292/geodetski-vestnik.2019.02.213-233
   Mohammadi N, 2021, GEOCARTO INT, V36, P1276, DOI 10.1080/10106049.2019.1641562
   Moreri KK, 2018, INT J GEOGR INF SCI, V32, P931, DOI 10.1080/13658816.2017.1409353
   Mullen WF, 2015, GEOJOURNAL, V80, P587, DOI 10.1007/s10708-014-9564-8
   Olszewski R, 2021, LAND USE POLICY, V109, P0, DOI 10.1016/j.landusepol.2021.105614
   Gomez-Barron JP, 2019, T GIS, V23, P976, DOI 10.1111/tgis.12544
   Rajaram G, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8110492
   Senaratne H, 2017, INT J GEOGR INF SCI, V31, P139, DOI 10.1080/13658816.2016.1189556
   Severinsen J, 2019, INT J GEOGR INF SCI, V33, P1683, DOI 10.1080/13658816.2019.1572893
   Teimoory N, 2021, EARTH SCI INFORM, V14, P1413, DOI 10.1007/s12145-021-00675-6
   van der Ham IJM, 2020, AGEING RES REV, V58, P0, DOI 10.1016/j.arr.2020.101020
   Xu C, 2013, CARTOGR GEOGR INF SC, V40, P103, DOI 10.1080/15230406.2013.776212
   Yang AR, 2016, ISPRS INT J GEO-INF, V5, P0, DOI 10.3390/ijgi5020021
   Zhang D, 2021, T GIS, V25, P1439, DOI 10.1111/tgis.12735
NR 33
TC 0
Z9 0
U1 1
U2 1
PU IGI GLOBAL
PI HERSHEY
PA 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA
SN 1947-9654
EI 1947-9662
J9 INT J APPL GEOSPAT R
JI Int. J. Appl. Geospat. Res.
PD JAN-MAR 15
PY 2023
VL 14
IS 1
BP 23
EP 23
DI 10.4018/IJAGR.316770
PG 1
WC Geography
SC Geography
GA 8P4ZV
UT WOS:000926534400003
DA 2023-04-26
ER

PT J
AU Tian, FY
   Wu, BF
   Zeng, HW
   Zhang, M
   Hu, YR
   Xie, Y
   Wen, CC
   Wang, ZD
   Qin, XL
   Han, W
   Yang, HH
AF Tian, Fuyou
   Wu, Bingfang
   Zeng, Hongwei
   Zhang, Miao
   Hu, Yueran
   Xie, Yan
   Wen, Congcong
   Wang, Zhengdong
   Qin, Xingli
   Han, Wei
   Yang, Honghai
TI A shape-attention Pivot-Net for identifying central pivot irrigation systems from satellite images using a cloud computing platform: an application in the contiguous US
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Shape-attention; multi-task learning; irrigation mapping; central pivot irrigation system; cloud computing
ID time-series; instance segmentation; resolution; areas; modis; evapotranspiration; sentinel-1; extent; scale; water
AB Forty percent of global food production relies upon irrigation, which accounts for 70% of total global freshwater use. Thus, the mapping of cropland irrigation plays a significant role in agricultural water management and estimating food production. However, current spaceborne irrigated cropland mapping is highly reliant upon its spectral behavior, which often has high uncertainty and lacks information about the method of irrigation. Deep learning (DL) allows for the classification of irrigated cropland according to unique spatial patterns, such as the central pivot irrigation system (CPIS). But convolutional neural networks (CNNs) are usually biased toward color and texture features, a spatial transferable and accurate CPIS identification model is lacking owing to previous model seldom involves the round shapes of CPIS, which is usually key to distinguishing CPIS. To address this lack, we proposed a shape attention neural network by integrating spatial-attention gate, residual block, and multi-task learning, Pivot-Net, to incorporate shape information identify CPIS in satellite imagery. Specifically, we employed CPIS in Kansas to train our model using Sentinel-2 and Landsat-8 optical images. We found that Pivot-Net is superior to seven state-of-the-art semantic segmentation models on second-stage validation. We also evaluated the performance of Pivot-Net at three validation sites, which had an average F-1-score and mean IOU of 90.68% and 90.45%, respectively, which further demonstrated the high accuracy of the proposed model. Moreover, to show that the proposed Pivot-Net can map CPIS at the country scale, we generated the first CPIS map at 30 m for the contiguous US using a cloud computing platform and our Pivot-Net model. The total CPIS area for the contiguous US was 61,094 km(2) in 2018, which comprised 26.22% of all irrigated lands. Our results can be accessed at . Therefore, the proposed shape-attention Pivot-Net demonstrates the ability to classify CPIS at large spatial scales and are feasible to map CPIS at national scales.
C1 [Tian, Fuyou; Wu, Bingfang; Zeng, Hongwei; Zhang, Miao; Hu, Yueran; Xie, Yan; Wang, Zhengdong; Qin, Xingli] Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing, Peoples R China.
   [Wu, Bingfang; Zeng, Hongwei; Hu, Yueran; Xie, Yan; Wang, Zhengdong] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing, Peoples R China.
   [Wen, Congcong] NYU Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
   [Han, Wei] China Univ Geosci, Sch Comp Sci, Wuhan, Peoples R China.
   [Yang, Honghai] Ctr Geomatics & Nat Resources Comprehens Survey Qi, Big Data Ctr Geospatial & Nat Resources, Xining, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; China University of Geosciences
RP Wu, BF (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing, Peoples R China.; Wu, BF (corresponding author), Univ Chinese Acad Sci, Coll Resources & Environm, Beijing, Peoples R China.
EM wubf@aircas.ac.cn
FU National Key Research and Development Project of China [2019YFE0126900]; National Natural Science Foundation of China [41861144019, 42071271]; Strategic Priority Research Program of Chinese Academy of Sciences [XDA19030201]
CR de Albuquerque AO, 2021, REMOTE SENS APPL, V23, P0, DOI 10.1016/j.rsase.2021.100537
   Bofana J, 2022, REMOTE SENS ENVIRON, V269, P0, DOI 10.1016/j.rse.2021.112808
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Brocca L, 2018, INT J APPL EARTH OBS, V73, P752, DOI 10.1016/j.jag.2018.08.023
   de Carvalho OLF, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010039
   Chen X, 2019, ECOL INDIC, V101, P274, DOI 10.1016/j.ecolind.2019.01.027
   Chen YL, 2018, REMOTE SENS ENVIRON, V204, P197, DOI 10.1016/j.rse.2017.10.030
   de Albuquerque AO, 2021, IEEE J-STARS, V14, P8447, DOI 10.1109/JSTARS.2021.3104726
   de Albuquerque AO, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12132159
   Deines JM, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111400
   Dheeravath V, 2010, ISPRS J PHOTOGRAMM, V65, P42, DOI 10.1016/j.isprsjprs.2009.08.004
   Dieter C.A., 2018, US GEOLOGICAL SURVEY, V1441, P0, DOI 10.3133/cir1441
   Droogers P, 2010, AGR WATER MANAGE, V97, P1351, DOI 10.1016/j.agwat.2010.03.017
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Flood N, 2019, INT J APPL EARTH OBS, V82, P0, DOI 10.1016/j.jag.2019.101897
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Geirhos R., 2018, INT C LEARNING REPRE, V0, P0
   Grafton RQ, 2018, SCIENCE, V361, P748, DOI 10.1126/science.aat9314
   He K., 2015, PROC CVPR IEEE, V5, P6
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Howell T. A., 2003, ENCY WATER SCI, V467, P0, DOI 10.1081/E-EWS120010252
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Jeppesen JH, 2019, REMOTE SENS ENVIRON, V229, P247, DOI 10.1016/j.rse.2019.03.039
   Johansen K, 2021, ISPRS J PHOTOGRAMM, V175, P1, DOI 10.1016/j.isprsjprs.2021.02.019
   Knox JW, 2012, AGR WATER MANAGE, V108, P3, DOI 10.1016/j.agwat.2011.06.007
   Li T, 2022, ISPRS J PHOTOGRAMM, V186, P83, DOI 10.1016/j.isprsjprs.2022.02.002
   Li YS, 2020, REMOTE SENS ENVIRON, V250, P0, DOI 10.1016/j.rse.2020.112045
   Li ZC, 2022, REMOTE SENS-BASEL, V14, P0, DOI 10.3390/rs14194738
   Li ZW, 2019, ISPRS J PHOTOGRAMM, V150, P197, DOI 10.1016/j.isprsjprs.2019.02.017
   Liu C, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112095
   Liu M, 2021, INT J APPL EARTH OBS, V103, P0, DOI 10.1016/j.jag.2021.102531
   Ma YF, 2018, REMOTE SENS ENVIRON, V216, P715, DOI 10.1016/j.rse.2018.07.019
   Mummadi C. K, 2021, INT C LEARNING REPRE, V0, P0
   Ozdogan M, 2008, REMOTE SENS ENVIRON, V112, P3520, DOI 10.1016/j.rse.2008.04.010
   Ozdogan M, 2010, REMOTE SENS-BASEL, V2, P2274, DOI 10.3390/rs2092274
   Pauls A, 2018, DETERMINING OPTIMUM, V0, P0
   Perez L., 2017, CONVOLUTIONAL NEURAL, V0, P11
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Pinto MM, 2020, ISPRS J PHOTOGRAMM, V160, P260, DOI 10.1016/j.isprsjprs.2019.12.014
   Ragettli S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111823
   Salmon JM, 2015, INT J APPL EARTH OBS, V38, P321, DOI 10.1016/j.jag.2015.01.014
   Saraiva M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030558
   Scanlon BR, 2012, P NATL ACAD SCI USA, V109, P9320, DOI 10.1073/pnas.1200311109
   Shi B., 2020, INT C MACHINE LEARNI, V0, P0
   Sun J, 2020, INT C MEDICAL IMAGE, V0, P0
   Takikawa T, 2019, IEEE I CONF COMP VIS, V0, PP5228, DOI 10.1109/ICCV.2019.00533
   Tian FY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060629
   USDA, 2021, IRR WAT US, V0, P0
   Vaswani A, 2017, ADV NEURAL INFORM PR, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Waldner F, 2020, REMOTE SENS ENVIRON, V245, P0, DOI 10.1016/j.rse.2020.111741
   Waller P., 2016, IRRIGATION DRAINAGE, V0, P0, DOI DOI 10.1007/978-3-319-05699-9
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang YM, 2021, COMPUT ELECTRON AGR, V184, P0, DOI 10.1016/j.compag.2021.106090
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu BF, 2022, J CLEAN PROD, V358, P0, DOI 10.1016/j.jclepro.2022.131891
   Xie YH, 2019, ISPRS J PHOTOGRAMM, V155, P136, DOI 10.1016/j.isprsjprs.2019.07.005
   Yi YN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151774
   You JX, 2017, AAAI CONF ARTIF INTE, V0, P4559
   Zha K, 2018, IEEE COMPUT SOC CONF, V0, PP242, DOI 10.1109/CVPRW.2018.00045
   Zhang C, 2022, AGR WATER MANAGE, V263, P0, DOI 10.1016/j.agwat.2022.107458
   Zhang CX, 2018, AGRICULTURE-BASEL, V8, P0, DOI 10.3390/agriculture8100147
   Zhang Q, 2021, REMOTE SENS ENVIRON, V264, P0, DOI 10.1016/j.rse.2021.112575
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zheng JP, 2020, ISPRS J PHOTOGRAMM, V167, P154, DOI 10.1016/j.isprsjprs.2020.07.002
   Zhou MT, 2020, ISPRS J PHOTOGRAMM, V168, P288, DOI 10.1016/j.isprsjprs.2020.08.019
NR 67
TC 1
Z9 1
U1 16
U2 16
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD DEC 31
PY 2023
VL 60
IS 1
BP 
EP 
DI 10.1080/15481603.2023.2165256
PG 25
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA 7Z5KK
UT WOS:000915597900001
DA 2023-04-26
ER
