
PT J
AU Liu, C
   Tao, R
   Li, W
   Zhang, MM
   Sun, WW
   Du, Q
AF Liu, Chang
   Tao, Ran
   Li, Wei
   Zhang, Mengmeng
   Sun, Weiwei
   Du, Qian
TI Joint Classification of Hyperspectral and Multispectral Images for Mapping Coastal Wetlands
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Wetlands; Sea measurements; Feature extraction; Vegetation mapping; Hyperspectral imaging; Spatial resolution; Earth; Coastal wetlands; convolutional neural network (CNN); data fusion; hyperspectral imagery (HSI); least squares regression (LSR); multispectral imagery (MSI)
ID land-cover classification; river delta; vegetation; representation
AB It is significant for restoration and protection of natural resources and ecological services in coastal wetlands to map different land cover types with satellite remote sensing data. Considering difficulties of wetland species classification, hyperspectral images (HSIs) with high spectral resolution and multispectral images (MSI) with high spatial resolution are considered to achieve complementary advantages of multisource data. An effective approach, named as multistream convolutional neural network, is proposed to achieve fine classification of coastal wetlands. First, regression processing is adopted to make chaotically scattered coastal wetland data more compact and different. Second, through appropriate feature extraction and feature fusion strategies, high-level information of multisource data in regression domain is fused to distinguish different land cover. Experiments on GF-5 HSIs and Sentinel-2 MSIs are carried out in order to validate the classification performance of the proposed approach in two coastal wetlands of research value in China, i.e., Yellow River Estuary and Yancheng coastal wetland. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art methods in the field, especially when the number of sample size is extremely small.
C1 [Liu, Chang; Tao, Ran; Li, Wei; Zhang, Mengmeng] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
   [Sun, Weiwei] Ningbo Univ, Dept Geog & Spatial Informat Tech, Ningbo 315211, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
C3 Beijing Institute of Technology; Ningbo University; Mississippi State University
RP Tao, R (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
EM 2929166864@qq.com; rantao@bit.edu.cn; leewei36@gmail.com; 7520200002@bit.edu.cn; nbsww@outlook.com; du@ece.msstate.edu
FU Beijing Natural Science Foundation [L191004]; National Natural Science Foundation of China [61922013, 61421001, U1833203]
CR Aboulela HA, 2020, ARAB J SCI ENG, V45, P327, DOI 10.1007/s13369-019-04085-1
   Adam E, 2010, WETL ECOL MANAG, V18, P281, DOI 10.1007/s11273-009-9169-z
   AKIRA H, 2003, WETLANDS, V23, P436
   Amani M, 2018, ISPRS J PHOTOGRAMM, V144, P119, DOI 10.1016/j.isprsjprs.2018.07.005
   Anna V., 2018, LAND-BASEL, V7, P0
   [Anonymous], 2014, NIPS, V0, P0
   Belluco E, 2006, REMOTE SENS ENVIRON, V105, P54, DOI 10.1016/j.rse.2006.06.006
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Dronova I, 2015, REMOTE SENS-BASEL, V7, P6380, DOI 10.3390/rs70506380
   Duan HL, 2020, GLOB ECOL CONSERV, V22, P0, DOI 10.1016/j.gecco.2020.e01031
   Duan PH, 2020, ISPRS J PHOTOGRAMM, V166, P359, DOI 10.1016/j.isprsjprs.2020.06.009
   Duan PH, 2019, IEEE T GEOSCI REMOTE, V57, P10336, DOI 10.1109/TGRS.2019.2933588
   Dubeau P, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101056
   Ghassabi Z, 2013, EURASIP J IMAGE VIDE, V0, P0, DOI DOI 10.1186/1687-5281-2013-25
   Guo M, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17040777
   Han XS, 2018, FRONT EARTH SCI-PRC, V12, P521, DOI 10.1007/s11707-017-0672-x
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hsu C-W, 2003, PRACTICAL GUIDE SUPP, V0, P0
   Hu S., 2017, WETLANDS, V37, P1943
   Hu YB, 2019, IEEE GEOSCI REMOTE S, V16, P1110, DOI 10.1109/LGRS.2018.2890421
   Hu YB, 2019, ACTA OCEANOL SIN, V38, P142, DOI 10.1007/s13131-019-1445-z
   Jahncke R, 2018, INT J APPL EARTH OBS, V68, P139, DOI 10.1016/j.jag.2018.01.012
   Jiao LL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192238
   Jingzhe W., 2020, SCI TOTAL ENVIRON, V707, P0
   Kang XD, 2015, IEEE T GEOSCI REMOTE, V53, P2241, DOI 10.1109/TGRS.2014.2358615
   Kang XD, 2015, IEEE T GEOSCI REMOTE, V53, P144, DOI 10.1109/TGRS.2014.2319373
   LaRocque A., 2020, P ISPRS ANN PHOTOGRA, VVolume V-3-2020, P301
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Lehner B, 2004, J HYDROL, V296, P1, DOI 10.1016/j.jhydrol.2004.03.028
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Li X, 2018, INT C PATT RECOG, V0, PP483, DOI 10.1109/ICPR.2018.8545289
   Lin Z., 2010, ARXIV10095055, V0, P0
   Liu JT, 2016, INT J REMOTE SENS, V37, P1845, DOI 10.1080/01431161.2016.1165888
   Liu T, 2018, ISPRS J PHOTOGRAMM, V139, P154, DOI 10.1016/j.isprsjprs.2018.03.006
   McCarthy MJ, 2017, ENVIRON MANAGE, V60, P323, DOI 10.1007/s00267-017-0880-x
   Michael M., 2020, J APPL REMOTE SENS, V14, P0
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Onojeghuo AO, 2017, INT J APPL EARTH OBS, V59, P79, DOI 10.1016/j.jag.2017.03.007
   Ozesmi Stacy L., 2002, WETLANDS ECOLOGY AND MANAGEMENT, V10, P381, DOI 10.1023/A:1020908432489
   Rebelo AJ, 2018, REMOTE SENS ENVIRON, V210, P25, DOI 10.1016/j.rse.2018.02.031
   Renato S., 2020, INT J AGR SUSTAIN DE, V2, P1
   Reschke J, 2014, INT J APPL EARTH OBS, V28, P220, DOI 10.1016/j.jag.2013.12.014
   Riaza A, 2017, INT J REMOTE SENS, V38, P3735, DOI 10.1080/01431161.2017.1302621
   Samantha Y., 2020, ESTUARINE COASTAL SH, V236, P0
   Santurkar S, 2018, ADV NEUR IN, V31, P0
   Schmidt KS, 2004, PHOTOGRAMM ENG REM S, V70, P703, DOI 10.14358/PERS.70.6.703
   Schuerch M, 2018, NATURE, V561, P231, DOI 10.1038/s41586-018-0476-5
   Seydi ST, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122010
   Shang K., 2020, P SOC PHOTO-OPT INS, V11432, P0
   Spencer T, 2016, GLOBAL PLANET CHANGE, V139, P15, DOI 10.1016/j.gloplacha.2015.12.018
   Stratoulias D, 2018, INT J REMOTE SENS, V39, P5689, DOI 10.1080/01431161.2018.1466081
   Su HJ, 2020, IEEE T GEOSCI REMOTE, V58, P3778, DOI 10.1109/TGRS.2019.2957135
   Sun B, 2017, IEEE T GEOSCI REMOTE, V55, P212, DOI 10.1109/TGRS.2016.2604290
   Sun WW, 2018, IEEE T GEOSCI REMOTE, V56, P3185, DOI 10.1109/TGRS.2018.2794443
   Sun XX, 2014, IEEE GEOSCI REMOTE S, V11, P1235, DOI 10.1109/LGRS.2013.2290531
   Tao R., 1900, P2020, V0, P0
   Turpie KR, 2015, REMOTE SENS ENVIRON, V167, P206, DOI 10.1016/j.rse.2015.05.008
   Tuxen K, 2011, WETL ECOL MANAG, V19, P141, DOI 10.1007/s11273-010-9207-x
   Wang XX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161927
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Xu Y, 2014, NEUROCOMPUTING, V135, P253, DOI 10.1016/j.neucom.2013.11.025
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yang JF, 2013, MATH COMPUT, V82, P301
   Zang Z, 2019, ANTHROPOCENE COASTS, V2, P87, DOI 10.1139/anc-2018-0007
   Zhang AZ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080952
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhao XD, 2020, IEEE T GEOSCI REMOTE, V58, P7355, DOI 10.1109/TGRS.2020.2982064
   Zifei Z., 2018, BEIJING SURVEYING MA, V0, P0
   Zomer RJ, 2009, J ENVIRON MANAGE, V90, P2170, DOI 10.1016/j.jenvman.2007.06.028
NR 72
TC 15
Z9 16
U1 25
U2 63
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 982
EP 996
DI 10.1109/JSTARS.2020.3040305
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900030
DA 2023-04-26
ER

PT J
AU Peng, B
   Huang, QY
   Vongkusolkit, J
   Gao, S
   Wright, DB
   Fang, ZN
   Qiang, Y
AF Peng, Bo
   Huang, Qunying
   Vongkusolkit, Jamp
   Gao, Song
   Wright, Daniel B.
   Fang, Zheng N.
   Qiang, Yi
TI Urban Flood Mapping With Bitemporal Multispectral Imagery Via a Self-Supervised Learning Framework
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Urban areas; Spatial resolution; Optical sensors; Optical imaging; Hurricanes; Labeling; Image registration; Flood mapping; multispectral (MS) imagery; self-supervised learning; urban
ID convolutional neural-network; change-vector analysis
AB Near realtime flood mapping in densely populated urban areas is critical for emergency response. The strong heterogeneity of urban areas poses a big challenge for accurate near realtime flood mapping. However, previous studies on automatic methods for urban flood mapping perform infeasible in near realtime or fail to generalize well to other floods, for several reasons. First, multitemporal pixel-wise flood mapping requires accurate image registration, hindering the efficiency of large-scale processing. Although automatic image registration has been investigated, precisely coregistered multitemporal image sequence requires time-consuming fine tuning. Additionally, the floods may lead to the loss of many corresponding image points across multitemporal images for accurate coregistration. Second, existing unsupervised methods generally rely on hand-crafted features for floodwater detection. Such features may not well represent the patterns of floodwaters in different areas due to inconsistent weather conditions, illumination, and floodwater spectra. This article proposes a self-supervised learning framework for patch-wise urban flood mapping using bitemporal multispectral satellite imagery. Patch-wise change vector analysis is used with patch features learned through a self-supervised autoencoder to produce patch-wise change maps showing potentially flood-affected areas. Postprocessing including spectral and spatial filtering is applied to these patch-wise change maps to remove nonflood related changes. Final flood maps and parameter sensitivities were evaluated using several performance metrics. Two flood events from areas with differing degrees of urbanization were considered: Hurricane Harvey flood (2017) in Houston, Texas, and Hurricane Florence flood (2018) in Lumberton, North Carolina. The proposed method shows strong performance for self-supervised urban flood mapping.
C1 [Peng, Bo] Univ Wisconsin, Dept Elect & Comp Engn, Dept Geog, 1415 Johnson Dr, Madison, WI 53706 USA.
   [Huang, Qunying; Vongkusolkit, Jamp; Gao, Song] Univ Wisconsin, Dept Geog, Madison, WI 53706 USA.
   [Wright, Daniel B.] Univ Wisconsin, Dept Civil & Environm Engn, Madison, WI 53706 USA.
   [Fang, Zheng N.] Univ Texas Arlington, Dept Civil Engn, Arlington, TX 76019 USA.
   [Qiang, Yi] Univ S Florida, Sch Geosci, Tampa, FL 33620 USA.
C3 University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; University of Texas System; University of Texas Arlington; State University System of Florida; University of South Florida
RP Huang, QY (corresponding author), Univ Wisconsin, Dept Geog, Madison, WI 53706 USA.
EM bo.peng@wisc.edu; qhuang46@wisc.edu; vongkusolkit@wisc.edu; song.gao@wisc.edu; danielb.wright@wisc.edu; nickfang@uta.edu; qiangy@usf.edu
FU National Science Foundation [1940091]; Microsoft AI for Earth Grant; Vilas Associates Competition Award from University ofWisconsin-Madison (UW-Madison); Trewartha Graduate Research Award from Department of Geography at UW-Madison; ICER; Directorate For Geosciences [1940091] Funding Source: National Science Foundation
CR Adam P., 2017, NIPS, V0, P0
   Amitrano D, 2018, IEEE T GEOSCI REMOTE, V56, P3290, DOI 10.1109/TGRS.2018.2797536
   Bruzzone L, 2003, IEEE T GEOSCI REMOTE, V41, P2455, DOI 10.1109/TGRS.2003.817268
   Byun Y, 2015, REMOTE SENS-BASEL, V7, P10347, DOI 10.3390/rs70810347
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Dhakal AS, 2002, PHOTOGRAMM ENG REM S, V68, P233
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P6003, DOI 10.1109/TGRS.2019.2903875
   Feng QL, 2015, WATER-SUI, V7, P1437, DOI 10.3390/w7041437
   Gebrehiwot A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071486
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Greifeneder F, 2014, INT J REMOTE SENS, V35, P2857, DOI 10.1080/01431161.2014.890299
   Huang Q., 2019, P 3 ACM SIGSPATIAL I, V0, P40
   Insom P, 2015, IEEE GEOSCI REMOTE S, V12, P1943, DOI 10.1109/LGRS.2015.2439575
   Jing LL, 2022, INT J OCCUP SAF ERGO, V28, P842, DOI 10.1080/10803548.2020.1835234
   Kingma D. P, 2015, PROC INT C LEARN REP, V0, P0
   KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kolesnikov A, 2019, PROC CVPR IEEE, V0, PP1920, DOI 10.1109/CVPR.2019.00202
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   LEVANDOWSKY M, 1971, NATURE, V234, P34, DOI 10.1038/234034a0
   Li LY, 2015, ISPRS J PHOTOGRAMM, V101, P10, DOI 10.1016/j.isprsjprs.2014.11.006
   Li Y, 2019, ISPRS J PHOTOGRAMM, V152, P178, DOI 10.1016/j.isprsjprs.2019.04.014
   Liu T, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), V0, PP420, DOI 10.1145/3347146.3359068
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Malila W. A., 1980, SIXTH ANNUAL SYMPOSIUM ON MACHINE PROCESSING OF REMOTELY SENSED DATA AND SOIL INFORMATION SYSTEMS AND REMOTE SENSING AND SOIL SURVEY, V0, P326
   Malinowski R, 2015, REMOTE SENS-BASEL, V7, P14853, DOI 10.3390/rs71114853
   Microsoft Bing Maps Team, 2018, MICROSOFT BUILDING F, V0, P0
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212492
   Peng B, 2016, INT GEOSCI REMOTE SE, V0, PP5868, DOI 10.1109/IGARSS.2016.7730533
   Pilon P. J., 2002, TECH REP, V0, P0
   Planet Team, 2018, PLANET APPL PROGRAM, V0, P0
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   Rosin PL, 2002, COMPUT VIS IMAGE UND, V86, P79, DOI 10.1006/cviu.2002.0960
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Schlaffer S, 2015, INT J APPL EARTH OBS, V38, P15, DOI 10.1016/j.jag.2014.12.001
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Skakun S, 2010, COMPUT INFORM, V29, P1013
   Song H, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020114
   Tong LY, 2019, IEEE T GEOSCI REMOTE, V57, P7872, DOI 10.1109/TGRS.2019.2917001
   UN, 2019, UN SUST DEV GOALS, V0, P0
   USGS, 2019, FLOOD INUNDATION MAP, V0, P0
   Wang P, 2019, IEEE GEOSCI REMOTE S, V16, P771, DOI 10.1109/LGRS.2018.2882516
   Wieland M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192330
   Xie M, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2545, DOI 10.1145/3219819.3220053
   Zhang LF, 2017, IEEE J-STARS, V10, P4614, DOI 10.1109/JSTARS.2017.2725382
NR 51
TC 9
Z9 9
U1 9
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2001
EP 2016
DI 10.1109/JSTARS.2020.3047677
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QC7WE
UT WOS:000615042800002
DA 2023-04-26
ER

PT J
AU Wang, WN
   Liu, WQ
   Chen, H
AF Wang, Weina
   Liu, Wanquan
   Chen, Hui
TI Information Granules-Based BP Neural Network for Long-Term Prediction of Time Series
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Time series analysis; Market research; Predictive models; Neural networks; Forecasting; Hidden Markov models; Semantics; Back-propagation neural network; information granulation; long-term prediction; time series forecasting
ID fuzzy cognitive maps; models
AB Long-term time series prediction is a challenging and essential task both in theory and practice. Recently, information granulation is shown to be an appropriate tool for the long-term forecast. Though some models for the long-term prediction problem have been proposed using information granulation recently, there is still a growing need to develop new prediction approaches for time series data based on information granule, which can capture the dynamic trend change with high accuracy. In this article, a long-term prediction approach, based on back-propagation neural network and information granule, is proposed. First, the individual numerical intervals for the time series are obtained by using the principle of justifiable granularity in information granule. Then, an automatic linear trend extraction method is developed to extract the trend change, which is inherited in granules. Finally, a hierarchy of neural network is constructed to carry out prediction by using information granule as input. Experiments using publicly available time series datasets demonstrate that the proposed approach can achieve better performance than the existing models for long-term prediction.
C1 [Wang, Weina] Jilin Inst Chem Technol, Sch Sci, Jilin 132022, Jilin, Peoples R China.
   [Liu, Wanquan] Curtin Univ, Dept Comp, Perth, WA 6102, Australia.
   [Chen, Hui] Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
C3 Jilin Institute of Chemical Technology; Curtin University; Shanghai University of Electric Power
RP Chen, H (corresponding author), Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
EM wangweina406@sina.com; w.liu@curtin.edu.au; chenhui@shiep.edu.cn
FU Natural Science Foundation of China [51705304]; "Thirteen Five" Science and Technology Program of Department of Education of Jilin Province [JJKH20200234KJ]; Natural Science Foundation of Shanghai [16ZR1413400]; Science and Technology Innovation Development Program of Jilin City [201831769, 20190104204]
CR Al-Hmouz R, 2016, KNOWL INF SYST, V48, P561, DOI 10.1007/s10115-015-0868-x
   Al-Hmouz R, 2015, EXPERT SYST APPL, V42, P4830, DOI 10.1016/j.eswa.2015.01.060
   [Anonymous], 1976, HOLDEN DAY SERIES TI, V0, P0
   Bargiela A., 2003, P IEEE P 22 INT C N, V0, P24
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Benmouiza K, 2013, ENERG CONVERS MANAGE, V75, P561, DOI 10.1016/j.enconman.2013.07.003
   Bodyanskiy Y, 2006, EUR J OPER RES, V175, P1357, DOI 10.1016/j.ejor.2005.02.012
   Chen H., 2007, NEUROCOMPUTING, V70, P697, DOI 10.1016/J.NEUCOM.2006.10.005
   Chen SM, 2011, IEEE T FUZZY SYST, V19, P1, DOI 10.1109/TFUZZ.2010.2073712
   Chen SM, 2010, IEEE T SYST MAN CY B, V40, P1343, DOI 10.1109/TSMCB.2009.2038358
   Cheng SH, 2016, INFORM SCIENCES, V327, P272, DOI 10.1016/j.ins.2015.08.024
   Das G., 1998, PROCEEDINGS FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P16
   Dincer NG, 2018, ECOL INFORM, V43, P157, DOI 10.1016/j.ecoinf.2017.12.001
   Dong XF, 2018, INFORM SCIENCES, V424, P39, DOI 10.1016/j.ins.2017.09.067
   Franses PH, 2005, INT J FORECASTING, V21, P87, DOI 10.1016/j.ijforecast.2004.05.005
   Froelich W, 2017, KNOWL-BASED SYST, V115, P110, DOI 10.1016/j.knosys.2016.10.017
   Guo HY, 2018, IEEE T FUZZY SYST, V26, P2807, DOI 10.1109/TFUZZ.2018.2802924
   Guo HY, 2016, J APPL STAT, V43, P2897, DOI 10.1080/02664763.2016.1155111
   Jang H, 2018, IEEE ACCESS, V6, P5427, DOI 10.1109/ACCESS.2017.2779181
   Kang IB, 2003, INT J FORECASTING, V19, P387, DOI 10.1016/S0169-2070(02)00010-9
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476
   Nguyen L, 2019, FUZZY SET SYST, V361, P114, DOI 10.1016/j.fss.2018.09.010
   Liu H, 2013, APPL ENERG, V107, P191, DOI 10.1016/j.apenergy.2013.02.002
   Liu S, 2018, ENG APPL ARTIF INTEL, V71, P60, DOI 10.1016/j.engappai.2018.02.012
   Pedrycz W, 2001, IEEE T SYST MAN CY B, V31, P106, DOI 10.1109/3477.907568
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Rahman MM, 2016, IEEE T CYBERNETICS, V46, P270, DOI 10.1109/TCYB.2015.2401038
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P26, DOI 10.1016/B978-1-4832-1446-7.50010-8
   Sadownik R, 1999, J FORECASTING, V18, P215, DOI 10.1002/(SICI)1099-131X(199905)18:3<215::AID-FOR719>3.0.CO;2-B
   Sagheer A, 2019, NEUROCOMPUTING, V323, P203, DOI 10.1016/j.neucom.2018.09.082
   Sivakumar S, 2018, IEEE T CYBERNETICS, V48, P2836, DOI 10.1109/TCYB.2017.2751005
   Wang L, 2018, APPL SOFT COMPUT, V66, P1, DOI 10.1016/j.asoc.2018.02.004
   Wang WN, 2015, ENG APPL ARTIF INTEL, V41, P17, DOI 10.1016/j.engappai.2015.01.006
   Wang WN, 2015, INFORM SCIENCES, V294, P78, DOI 10.1016/j.ins.2014.09.027
   Wang XN, 2016, INT J INNOV COMPUT I, V12, P15
   Yang SC, 2018, IEEE T FUZZY SYST, V26, P3391, DOI 10.1109/TFUZZ.2018.2831640
   Yang XY, 2017, INT J APPROX REASON, V81, P1, DOI 10.1016/j.ijar.2016.10.010
   Yao JT, 2013, IEEE T CYBERNETICS, V43, P1977, DOI 10.1109/TSMCC.2012.2236648
   Zadeh L.A., 1979, ADV FUZZY SET THEORY, V11, P3
   Zhang G., 1998, THESIS KENT STATE U, V0, P0
   Zhang GP, 2001, J OPER RES SOC, V52, P652, DOI 10.1057/palgrave.jors.2601133
NR 43
TC 8
Z9 9
U1 9
U2 52
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD OCT 15
PY 2021
VL 29
IS 10
BP 2975
EP 2987
DI 10.1109/TFUZZ.2020.3009764
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WC2XW
UT WOS:000704125600016
DA 2023-04-26
ER

PT J
AU Paliwal, S
   Sharma, M
   Vig, L
AF Paliwal, Shubham
   Sharma, Monika
   Vig, Lovekesh
TI OSSR-PID: One-Shot Symbol Recognition in P&ID Sheets using Path Sampling and GCN
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
LA English
DT Proceedings Paper
AB In this paper, we focus on recognition of line-drawn symbols in engineering drawings with only one prototypical example per symbol available for training. In particular, Piping and Instrumentation Diagrams (P&ID) are ubiquitous in several manufacturing, oil and gas enterprises for representing engineering schematics and equipment layout. There is an urgent need to extract and digitize information from P&IDs without the cost of annotating a varying set of symbols for each new use case. A robust one-shot learning approach for symbol recognition i.e., localization followed by classification, would therefore go a long way towards this goal. Our method works by sampling pixels sequentially along the different contour boundaries in the image. These sampled points form paths which are used in the prototypical line diagram to construct a graph that captures the structure of the contours. Subsequently, the prototypical graphs are fed into a Dynamic Graph Convolutional Neural Network (DGCNN) which is trained to classify graphs into one of the given symbol classes. Further, we append embeddings from a Resnet-34 network which is trained on symbol images containing sampled points to make the classification network more robust. Since, many symbols in P&ID are structurally very similar to each other, we utilize Arcface loss during DGCNN training which helps in maximizing symbol class separability by producing highly discriminative embeddings. During inference time, a similar line based sampling procedure is adopted for generating sampled points across P&ID image. The images consist of components attached on the pipeline (straight line). The sampled points segregated around the symbol regions are used for the classification task. The proposed pipeline, named OSSR-PID, is fast and gives outstanding performance for recognition of symbols on a synthetic dataset of 100 P&ID diagrams. We also compare our method against prior-work that uses full supervision (not one-shot) on a real-world private dataset of 12 P&ID sheets and obtain comparable/superior results. Remarkably, it is able to achieve such excellent performance using only one prototypical example per symbol.
C1 [Paliwal, Shubham; Sharma, Monika; Vig, Lovekesh] TCS Res, Pune, Maharashtra, India.
RP Paliwal, S (corresponding author), TCS Res, Pune, Maharashtra, India.
EM shubham.p3@tcs.com; monika.sharma1@tcs.com; lovekesh.vig@tcs.com
CR Arroyo E., 2014, P 2014 IEEE EM TECHN, V0, PP1, DOI 10.1109/ETFA.2014.7005098
   Arroyo E., 2015, PROCEEDING IEEE INT, V0, PP1, DOI 10.1109/
   BENJAMIN D, 1988, 1988 PROCEEDINGS 9TH, V1, P119
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Deng J., 2019, P IEEE CVF C COMP VI, V0, P4690
   DONG X, 2019, ARXIV, V0, P0
   FAHN CS, 1988, COMPUT VISION GRAPH, V44, P119, DOI 10.1016/S0734-189X(88)80001-X
   Gonzalez R C, 2004, DIGITAL IMAGE PROCES, V0, P0
   GUPTA G, 2017, ICDAR 2017, V0, P33
   JOSEPH SH, 1992, IEEE T PATTERN ANAL, V14, P928, DOI 10.1109/34.161351
   KATO H, 1990, PROCEEDINGS 10TH INT, V1, P578
   Khan A, 2019, IEEE INT C INT ROBOT, V0, PP7558, DOI 10.1109/IROS40897.2019.8968483
   Li Z., 2017, FSSD FEATURE FUSION, V0, P0
   Liu MY, 2019, IEEE I CONF COMP VIS, V0, PP10550, DOI 10.1109/ICCV.2019.01065
   MAINI R, 2009, INT J IMAGE PROCESSI, V0, P0
   RAHUL R, 2018, COMPUTER VISION ACCV, V0, P159
   Rahul R, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, V0, PP163, DOI 10.5220/0007376401630172
   Ren MY, 2018, PROC CVPR IEEE, V0, PP8711, DOI 10.1109/CVPR.2018.00908
   SATORRAS VG, 2018, ICLR 2018, V0, P0
   SELINGER P, 2003, POTRACE A POLYGONBAS, V0, P0
   Snell J, 2017, CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE (UAI2017), V0, P0
   Vinyals O., 2016, P ADV NEURAL INFORM, V29, P3630, DOI 10.48550/arXiv.1606.04080
   WANG DM, 1995, PATTERN RECOGN, V28, P1783, DOI 10.1016/0031-3203(95)00036-Y
   Wang X., 2019, IEEE CVPR, V0, P0
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Wojke N, 2018, IEEE WINT CONF APPL, V0, PP748, DOI 10.1109/WACV.2018.00087
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yan L, 2003, PROC INT CONF DOC, V0, P190
   Zhihu H, 2010, 2010 2 INT C COMP EN, V0, P0, DOI DOI 10.1109/ICCET.2010.5485542
NR 30
TC 2
Z9 2
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-4393
EI 
J9 IEEE IJCNN
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/IJCNN52387.2021.9534122
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA BS4TO
UT WOS:000722581706074
DA 2023-04-26
ER

PT J
AU Zhang, XQ
   An, WN
   Sun, JG
   Wu, H
   Zhang, WC
   Du, YH
AF Zhang, Xinqi
   An, Weining
   Sun, Jinggong
   Wu, Hang
   Zhang, Wenchang
   Du, Yaohua
TI Best Representation Branch Model for Remote Sensing Image Scene Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Semantics; Data mining; Residual neural networks; Convolutional neural networks; Remote sensing; Sun; Best representation branch model; deep learning (DL); remote sensing (RS) image; spatial information
ID convolutional neural-network; attention; descriptors; features
AB Remote sensing image scene classification is an important method for understanding the high-resolution remote sensing images. Based on convolutional neural network, various classification methods have been applied into this field and achieved remarkable results. These methods mainly rely on the semantic information to improve the classification performance. However, as the network goes deeper, the highly abstract and global semantic information makes it difficult for the network to accurately classify scene images with similar layout and structures, limiting further improvement of classification accuracy. Relying on the semantic information only is not sufficient to effectively classify these similar scene images and the network needs spatial information to enhance the classification capability. To solve this dilemma, this article proposes a best representation branch model, which reaches the optimal balance point where the network can make use of both the semantic information and spatial information to improve the final classification accuracy. In the proposed method, ResNet50 pretrained on the ImageNet dataset is first divided into four branches with different depths to extract feature maps and a capsule network is used as the classifier. The Grad-CAM algorithm is adopted to explain the mechanism of the optimal balance point from the perspective of attention and guide the further feature fusion. In addition, ablation studies are conducted to prove the effectiveness of our method and extensive experiments are conducted on three public benchmark remote sensing datasets. The results demonstrate that the proposed method can achieve competitive classification performance compared to the state-of-the-art methods.
C1 [Zhang, Xinqi; An, Weining; Wu, Hang; Zhang, Wenchang; Du, Yaohua] Acad Mil Sci, Res Dept Med Support Technol, Tianjin 300161, Peoples R China.
   [Sun, Jinggong] Acad Mil Sci, Inst Syst Engn, Beijing 100171, Peoples R China.
C3 Academy of Military Medical Sciences - China
RP Wu, H (corresponding author), Acad Mil Sci, Res Dept Med Support Technol, Tianjin 300161, Peoples R China.; Sun, JG (corresponding author), Acad Mil Sci, Inst Syst Engn, Beijing 100171, Peoples R China.
EM zhangxinqi_ams@126.com; asdawnasd@163.com; sunjg@vip.sina.com; 2008.wuhang@163.com; zwc0501@163.com; qsyaohua@sina.com
FU Foundation of Tianjin Science and Technology Plan [19YFZCSN01150]; Foundation of National Defense Science and Technology innovation [20-163-12-ZT-006-002-09]; Academy of Military Sciences Equipment Scientific Research [JK20191A010024]; Major Research Program of National Natural Science Foundation of China [91948303]; Tianjin Natural Science Foundation of China [18JCZDJC40300, 19ZXJRGX00080]
CR Alhichri H, 2021, IEEE ACCESS, V9, P14078, DOI 10.1109/ACCESS.2021.3051085
   [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   Bai L, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3078518
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chen C., 2015, SIGNAL IMAGE VIDEO P, V10, P1, DOI 10.1371/J0URNAL.P0NE.0139565
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Guo DE, 2021, IEEE J-STARS, V14, P2508, DOI 10.1109/JSTARS.2021.3056883
   Guo YY, 2019, IEEE ACCESS, V7, P67200, DOI 10.1109/ACCESS.2019.2918732
   Guo ZQ, 2021, IEEE GEOSCI REMOTE S, V18, P964, DOI 10.1109/LGRS.2020.2992661
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu Q, 2013, REMOTE SENS-BASEL, V5, P6026, DOI 10.3390/rs5116026
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jiang XF, 2021, IEEE GEOSCI REMOTE S, V18, P1094, DOI 10.1109/LGRS.2020.2991405
   Karimzadeh S, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20174751
   Li BY, 2020, IEEE GEOSCI REMOTE S, V17, P1687, DOI 10.1109/LGRS.2019.2952660
   Li BY, 2019, IEEE J-STARS, V12, P3508, DOI 10.1109/JSTARS.2019.2934165
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li HC, 2020, IEEE J-STARS, V13, P738, DOI 10.1109/JSTARS.2020.2968930
   Lin C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121397
   Liu XN, 2019, IEEE GEOSCI REMOTE S, V16, P1200, DOI 10.1109/LGRS.2019.2894399
   Liu YF, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030444
   Lu XQ, 2019, IEEE T GEOSCI REMOTE, V57, P7894, DOI 10.1109/TGRS.2019.2917161
   Luo B, 2013, IEEE J-STARS, V6, P1899, DOI 10.1109/JSTARS.2012.2228254
   Mazzia V, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-93977-0
   Mishra DR, 2005, IEEE T GEOSCI REMOTE, V43, P1592, DOI 10.1109/TGRS.2005.847790
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rau JY, 2012, NAT HAZARDS, V61, P469, DOI 10.1007/s11069-011-9929-y
   Sabour S., 2017, DYNAMIC ROUTING CAPS, V0, P0
   Shen Y, 2021, IEEE T GEOSCI REMOTE, V59, P6029, DOI 10.1109/TGRS.2020.3014286
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P82, DOI 10.1109/TGRS.2019.2931801
   Tian T, 2019, INT GEOSCI REMOTE SE, V0, PP525, DOI 10.1109/IGARSS.2019.8898656
   Tong W, 2020, IEEE J-STARS, V13, P4121, DOI 10.1109/JSTARS.2020.3009352
   Wang K, 2010, SENSORS-BASEL, V10, P9647, DOI 10.3390/s101109647
   Wu H, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/8513949
   Wu H, 2016, IEEE GEOSCI REMOTE S, V13, P1895, DOI 10.1109/LGRS.2016.2616440
   Wu H, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050436
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xiang CQ, 2018, IEEE SIGNAL PROC LET, V25, P1850, DOI 10.1109/LSP.2018.2873892
   Xiaohui D, 2021, REMOTE SENS-BASEL, V13, P0
   Xie J, 2019, IEEE T GEOSCI REMOTE, V57, P6916, DOI 10.1109/TGRS.2019.2909695
   Xu K., 1900, DOI 10.1109/LGRS.2021.3075712, V0, P0
   Xu KJ, 2022, IEEE T NEUR NET LEAR, V33, P5751, DOI 10.1109/TNNLS.2021.3071369
   Xu KJ, 2020, IEEE GEOSCI REMOTE S, V17, P1894, DOI 10.1109/LGRS.2019.2960026
   Xue W, 2020, IEEE ACCESS, V8, P28746, DOI 10.1109/ACCESS.2020.2968771
   Xue ZX, 2021, IEEE J-STARS, V14, P3566, DOI 10.1109/JSTARS.2021.3065987
   Yang Y, 2008, IEEE IMAGE PROC, V0, PP1852, DOI 10.1109/ICIP.2008.4712139
   Yu DH, 2020, IEEE J-STARS, V13, P6372, DOI 10.1109/JSTARS.2020.3030257
   Yu YT, 2020, IEEE GEOSCI REMOTE S, V17, P1263, DOI 10.1109/LGRS.2019.2940505
   Yu YL, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/8639367
   Zeng D, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050734
   Zhang W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050494
   Zhao B, 2017, IEEE GEOSCI REMOTE S, V14, P1436, DOI 10.1109/LGRS.2017.2691013
   Zhao LJ, 2014, IEEE J-STARS, V7, P4620, DOI 10.1109/JSTARS.2014.2339842
   Zhao LJ, 2014, INT J REMOTE SENS, V35, P2296, DOI 10.1080/01431161.2014.890762
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
   Zhu QQ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040568
   Zhu QQ, 2016, IEEE GEOSCI REMOTE S, V13, P747, DOI 10.1109/LGRS.2015.2513443
NR 61
TC 7
Z9 7
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9768
EP 9780
DI 10.1109/JSTARS.2021.3114404
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WD3DB
UT WOS:000704824700009
DA 2023-04-26
ER
