
PT J
AU Lima, B
   Ferreira, L
   Moura, JM
AF Lima, Bruno
   Ferreira, Luis
   Moura, Joao Martinho
TI Helping to detect legal swimming pools with Deep Learning and Data Visualization
SO INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS / INTERNATIONAL CONFERENCE ON PROJECT MANAGEMENT / INTERNATIONAL CONFERENCE ON HEALTH AND SOCIAL CARE INFORMATION SYSTEMS AND TECHNOLOGIES 2020 (CENTERIS/PROJMAN/HCIST 2020)
LA English
DT Proceedings Paper
DE Artificial Intelligence; Orthophotomaps; Detection; GIS; Data Visualization; Pattern Recognition
AB The municipalities have, as a primary responsibility, the administrative management of their territory. The use of geographic information systems (GIS) and orthophoto maps can help to handle this task. One of the great difficulties they face is related to the continuous and quick changes that the territory suffers, and whose inspection is challenging to support. An example of this is the maintenance of the swimming pool registration system, in order to validate or license them. Indeed, it requires a substantial manual intervention, yet. This paper describes a system prototype for helping on detecting swimming pools on aerial images. It explores and integrates artificial intelligence (AI), systems integration, GIS, and data visualization. The AI improves the detection of objects, and middleware supports the integration of the detection results with other municipality systems for georeferencing and private property data licensing data crossing. To the innovative interoperability services, visualization libraries were explored, and an advanced visualization and analysis system was constructed. A dataset of aerial images of swimming pools and correspondent classification metadata was created. The model was trained with several convolutional neural networks in order to obtain and compare the precision results. The more accurate model is described. (C) 2021 The Authors. Published by Elsevier B.V.
C1 [Ferreira, Luis] IPCA, 2Ai Sch Technol, Barcelos, Portugal.
   [Lima, Bruno; Ferreira, Luis; Moura, Joao Martinho] IPCA, Sch Technol, Barcelos, Portugal.
   [Moura, Joao Martinho] Univ Minho, Ctr ALGORITMI, P-4804533 Guimaraes, Portugal.
   [Lima, Bruno] Municipal Esposende, P-4740223 Esposende, Portugal.
C3 Instituto Politecnico do Cavado e do Ave - IPCA; Instituto Politecnico do Cavado e do Ave - IPCA; Universidade do Minho
RP Ferreira, L (corresponding author), IPCA, 2Ai Sch Technol, Barcelos, Portugal.; Ferreira, L (corresponding author), IPCA, Sch Technol, Barcelos, Portugal.
EM lufer@ipca.pt
FU National funds, through the Foundation for Science and Technology (FCT) [UIDB/05549/2020, UIDP/05549/2020]
CR Aldeborgh Nikki, 2017, DIGITALGLOBE POOLN, V0, P0
   Browne K., 2019, ARTIFICIALLY NEURAL, V0, P0
   Cresson R, 2019, IEEE GEOSCI REMOTE S, V16, P25, DOI 10.1109/LGRS.2018.2867949
   ERSI, 2018, ARCGIS ENT POOLD FUL, V0, P0
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Google, 2016, GOOGL AI BLOG INTR O, V0, P0
   Grizonnet M., 2017, OPEN GEOSPATIAL DATA, V2, P1
   Hui J., 2018, OBJECT DETECTION SPE, V0, P0
   Khursheed T., 2019, 2019 1 INT C UNM, V0, P0
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mahmood H., 2018, SOFTMAX FUNCTION SIM, V0, P0
   Mango, 2014, GIS MAPP THE BEG GUI, V0, P0
   MathWorks, 2016, MACH LEARN MATLAB, V0, P0
   Nielsen J, 2016, 10 USABILITY HEURIST, V0, P0
   Ren S., 2015, PROC INT C NEURAL IN, V0, PP91, DOI 10.1109/ICCV.2015.169.
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Vujkovic M., 2017, INT J MOL SCI, V0, P0, DOI DOI 10.1016/j.jcms.2021.02.007
   Zeng GD, 2019, LECT NOTES COMPUT SC, V11404, P35, DOI 10.1007/978-3-030-11166-3_4
   Zhang Q., 2017, LEARNING HUMANS DEEP, V0, P0
NR 20
TC 2
Z9 2
U1 1
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
EI 
J9 PROCEDIA COMPUT SCI
PD JUN 15
PY 2021
VL 181
IS 
BP 1058
EP 1065
DI 10.1016/j.procs.2021.01.301
PG 8
WC Computer Science, Information Systems; Computer Science, Theory & Methods; Information Science & Library Science; Management; Operations Research & Management Science; Medical Informatics
SC Computer Science; Information Science & Library Science; Business & Economics; Operations Research & Management Science; Medical Informatics
GA BR5HQ
UT WOS:000655346400130
DA 2023-04-26
ER

PT J
AU Laguarta, J
   Subirana, B
AF Laguarta, Jordi
   Subirana, Brian
TI Longitudinal Speech Biomarkers for Automated Alzheimer's Detection
SO FRONTIERS IN COMPUTER SCIENCE
LA English
DT Article
DE multimodal deep learning; transfer learning; explainable speech recognition; brain model; graph neural-networks; AI diagnostics
ID cognitive impairment; substance-p; disease; dementia; cough; dysphagia; covid-19; scale
AB We introduce a novel audio processing architecture, the Open Voice Brain Model (OVBM), improving detection accuracy for Alzheimer's (AD) longitudinal discrimination from spontaneous speech. We also outline the OVBM design methodology leading us to such architecture, which in general can incorporate multimodal biomarkers and target simultaneously several diseases and other AI tasks. Key in our methodology is the use of multiple biomarkers complementing each other, and when two of them uniquely identify different subjects in a target disease we say they are orthogonal. We illustrate the OBVM design methodology by introducing sixteen biomarkers, three of which are orthogonal, demonstrating simultaneous above state-of-the-art discrimination for two apparently unrelated diseases such as AD and COVID-19. Depending on the context, throughout the paper we use OVBM indistinctly to refer to the specific architecture or to the broader design methodology. Inspired by research conducted at the MIT Center for Brain Minds and Machines (CBMM), OVBM combines biomarker implementations of the four modules of intelligence: The brain OS chunks and overlaps audio samples and aggregates biomarker features from the sensory stream and cognitive core creating a multi-modal graph neural network of symbolic compositional models for the target task. In this paper we apply the OVBM design methodology to the automated diagnostic of Alzheimer's Dementia (AD) patients, achieving above state-of-the-art accuracy of 93.8% using only raw audio, while extracting a personalized subject saliency map designed to longitudinally track relative disease progression using multiple biomarkers, 16 in the reported AD task. The ultimate aim is to help medical practice by detecting onset and treatment impact so that intervention options can be longitudinally tested. Using the OBVM design methodology, we introduce a novel lung and respiratory tract biomarker created using 200,000+ cough samples to pre-train a model discriminating cough cultural origin. Transfer Learning is subsequently used to incorporate features from this model into various other biomarker-based OVBM architectures. This biomarker yields consistent improvements in AD detection in all the starting OBVM biomarker architecture combinations we tried. This cough dataset sets a new benchmark as the largest audio health dataset with 30,000+ subjects participating in April 2020, demonstrating for the first time cough cultural bias.
C1 [Laguarta, Jordi; Subirana, Brian] MIT, AutoID Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Subirana, Brian] Harvard Univ, Fac Arts & Sci, Cambridge, MA 02138 USA.
C3 Massachusetts Institute of Technology (MIT); Harvard University
RP Subirana, B (corresponding author), MIT, AutoID Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.; Subirana, B (corresponding author), Harvard Univ, Fac Arts & Sci, Cambridge, MA 02138 USA.
EM subirana@mit.edu
CR Abeyratne UR, 2013, ANN BIOMED ENG, V41, P2448, DOI 10.1007/s10439-013-0836-0
   Alagiakrishnan K, 2013, ARCH GERONTOL GERIAT, V56, P1, DOI 10.1016/j.archger.2012.04.011
   Altinkaya Emre, 2020, J INSTIT ELECT COMPU, V1, P39, DOI 10.33969/JIEC.2019.11005
   [Anonymous], 2020, ALZHEIMERS DEMENT, V16, P391, DOI 10.1002/alz.12068
   Azarpazhooha MR, 2020, J NEUROL SCI, V416, P0, DOI 10.1016/j.jns.2020.117013
   Babulal GM, 2016, AM J GERIAT PSYCHIAT, V24, P1095, DOI 10.1016/j.jagp.2016.04.004
   Baldwin Sharelle, 2009, CURR PROTOC NEUROSCI, VChapter 10, P0, DOI 10.1002/0471142301.ns1003s49
   Pulido MLB, 2020, EXPERT SYST APPL, V150, P0, DOI 10.1016/j.eswa.2020.113213
   Barthelemy NR, 2020, J EXP MED, V217, P0, DOI 10.1084/jem.20200861
   Bennett WD, 2010, J AEROSOL MED PULM D, V23, P261, DOI 10.1089/jamp.2010.0823
   Bidzan M, 2014, PSYCHIATR POL, V48, P319
   Bowling A, 2015, AGING MENT HEALTH, V19, P13, DOI 10.1080/13607863.2014.915923
   Briggs R, 2016, CLIN MED, V16, P247, DOI 10.7861/clinmedicine.16-3-247
   Cano-Cordoba F., 2017, 71 MIT CBMM, V0, P0
   Cassani R, 2018, DIS MARKERS, V2018, P0, DOI 10.1155/2018/5174815
   Cera ML, 2013, INT PSYCHOGERIATR, V25, P1679, DOI 10.1017/S1041610213000781
   CHERTKOW H, 1990, BRAIN, V113, P397, DOI 10.1093/brain/113.2.397
   Clark CM, 1996, ALZ DIS ASSOC DIS, V10, P31, DOI 10.1097/00002093-199601010-00006
   Coffey CS, 2008, DRUGS R&D, V9, P229, DOI 10.2165/00126839-200809040-00003
   Costa A, 2017, ALZHEIMERS RES THER, V9, P0, DOI 10.1186/s13195-017-0254-x
   Cummings L, 2019, PRAGMAT SOC, V10, P153, DOI 10.1075/ps.17011.cum
   Ding Y, 2019, RADIOLOGY, V290, P456, DOI 10.1148/radiol.2018180958
   Dodd JW, 2015, ALZHEIMERS RES THER, V7, P0, DOI 10.1186/s13195-015-0116-3
   Ebihara T, 2020, ERJ OPEN RES, V6, P0, DOI 10.1183/23120541.00108-2019
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fuller SJ, 2019, NEURODEGENERATION AND ALZHEIMERS DISEASE: THE ROLE OF DIABETES, V0, P0
   Galvin J., 2020, SCREEN INTERVENE IMP, V0, P0
   Garcia SD, 2020, J ALZHEIMERS DIS, V78, P1547, DOI 10.3233/JAD-200888
   Gaugler J, 2019, ALZHEIMERS DEMENT, V15, P321, DOI 10.1016/j.jalz.2019.01.010
   Ghoniem RM, 2019, LECT NOTES COMPUT SC, V11608, P220, DOI 10.1007/978-3-030-23281-8_18
   Giannakopoulos P, 1998, ARCH NEUROL-CHICAGO, V55, P689, DOI 10.1001/archneur.55.5.689
   Goodglass H., 1983, COOKIE THEFT PICTURE, V0, P0
   Guinjoan S.M., 2021, PERS MED PSYCHIAT, V2021, P100071, DOI 10.1016/j.pmip.2021.100071
   Hariyanto TI, 2021, EUR ARCH PSY CLIN N, V271, P393, DOI 10.1007/s00406-020-01205-z
   Haulcy R, 2021, FRONT PSYCHOL, V11, P0, DOI 10.3389/fpsyg.2020.624137
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Heckman Pim R A, 2017, ADV NEUROBIOL, V17, P135, DOI 10.1007/978-3-319-58811-7_6
   Henriksen K, 2014, ALZHEIMERS DEMENT, V10, P115, DOI 10.1016/j.jalz.2013.01.013
   Holmes RJ, 2000, INT J LANG COMM DIS, V35, P407
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, P0, DOI 10.1002/widm.1312
   HUGHES CP, 1982, BRIT J PSYCHIAT, V140, P566, DOI 10.1192/bjp.140.6.566
   Isaia G, 2020, AM J GERIAT PSYCHIAT, V28, P790, DOI 10.1016/j.archger.2004.04.022
   James HJ, 2020, J ALZHEIMERS DIS, V74, P625, DOI 10.3233/JAD-190922
   Johnen A, 2019, FRONT NEUROL, V10, P0, DOI 10.3389/fneur.2019.00594
   Kalia M, 2003, METABOLISM, V52, P36, DOI 10.1053/S0026-0495(03)00300-6
   Karlekar S., 2018, PROC NAACL, V2, P701
   King DB, 2015, ACS SYM SER, V1214, P1
   Krijnders J., 2017, ENERGY, V400, P500
   Kuo CL, 2020, AGING-US, V12, P12222, DOI 10.18632/aging.103405
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), V0, P109
   Laguarta J, 2020, IEEE OPEN J ENG MED, V1, P275, DOI 10.1109/OJEMB.2020.3026928
   Livingstone SR, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0196391
   Luz S, 2020, INTERSPEECH, V0, PP2172, DOI 10.21437/Interspeech.2020-2571
   Lyons J., 2020, JAMESLYONS PYTHON SP, V0, P0
   Lyu G, 2018, 2018 11TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, V0, P0
   Maclin JMA, 2019, GEN PSYCHIAT, V32, P0, DOI 10.1136/gpsych-2019-100054
   Manabe T, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0213825
   Michel A, 2021, J GERIATR PSYCH NEUR, V34, P150, DOI 10.1177/0891988720915519
   MORRIS RG, 1986, Q J EXP PSYCHOL-A, V38, P575, DOI 10.1080/14640748608401615
   Morsy A, 2019, J ALZHEIMERS DIS, V72, PS145, DOI 10.3233/JAD-190744
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Orimaye S.O., 2014, P WORKSHOP COMPUTATI, V0, PP78, DOI 10.3115/V1/W14-3210
   Palmqvist S, 2020, JAMA-J AM MED ASSOC, V324, P772, DOI 10.1001/jama.2020.12134
   Panayotov V, 2015, INT CONF ACOUST SPEE, V0, PP5206, DOI 10.1109/ICASSP.2015.7178964
   Parisot S, 2018, MED IMAGE ANAL, V48, P117, DOI 10.1016/j.media.2018.06.001
   Pawlowski M, 2019, J NEUROL NEUROSUR PS, V90, P562, DOI 10.1136/jnnp-2018-318470
   Pearl Judea., 2018, THE BOOK OF WHY, V0, P0
   Petti U, 2020, J AM MED INFORM ASSN, V27, P1784, DOI 10.1093/jamia/ocaa174
   Pramono RXA, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0162128
   Ralph MAL, 2003, BRAIN, V126, P2350, DOI 10.1093/brain/awg236
   Reed WJ, 2002, PHYS REV E, V66, P0, DOI 10.1103/PhysRevE.66.067103
   Rikkert MGMO, 2011, AM J ALZHEIMERS DIS, V26, P357, DOI 10.1177/1533317511418954
   Sekizawa K, 1996, PULM PHARMACOL THER, V9, P323, DOI 10.1006/pulp.1996.0042
   Severini C, 2016, CURR ALZHEIMER RES, V13, P964, DOI 10.2174/1567205013666160401114039
   Shaw LM, 2009, ANN NEUROL, V65, P403, DOI 10.1002/ana.21610
   Small BJ, 2000, ARCH NEUROL-CHICAGO, V57, P839, DOI 10.1001/archneur.57.6.839
   Song XW, 2011, NEUROLOGY, V77, P227, DOI 10.1212/WNL.0b013e318225c6bc
   Subirana B., 2017, TIME TALK FUTURE BRA, V0, P0
   Subirana B., 2020, ALGORITHMS LAW, V0, P0, DOI DOI 10.1017/9781108347846.010
   Subirana B., 2020, HISIGMA HAVE CORONAV, V0, P0
   Subirana B., 2017, 68 MIT CBMM, V0, P0, DOI DOI 10.21125/edulearn.2017.0672
   Subirana B, 2020, COMMUN ACM, V63, P32, DOI 10.1145/3402193
   Syed MSS, 2020, INTERSPEECH, V0, PP2222, DOI 10.21437/Interspeech.2020-3158
   Wirths O, 2008, GENES BRAIN BEHAV, V7, P1, DOI 10.1111/j.1601-183X.2007.00373.x
   Wise J, 2016, BMJ-BRIT MED J, V353, P0, DOI 10.1136/bmj.i2022
   Won HK, 2018, RESP PHYSIOL NEUROBI, V257, P65, DOI 10.1016/j.resp.2018.01.009
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yu YZ, 2021, GERIATRICS-BASEL, V6, P0, DOI 10.3390/geriatrics6010010
   Yuan JH, 2020, INTERSPEECH, V0, PP2162, DOI 10.21437/Interspeech.2020-2516
   Zetterberg H, 2019, J NEUROSCI METH, V319, P2, DOI 10.1016/j.jneumeth.2018.10.025
   Zunic A, 2020, JMIR MED INF, V8, P34, DOI 10.2196/16023
NR 91
TC 8
Z9 8
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 2624-9898
J9 FRONT COMP SCI-SWITZ
JI Front. Comput. Sci.-Switz
PD APR 8
PY 2021
VL 3
IS 
BP 
EP 
DI 10.3389/fcomp.2021.624694
PG 12
WC Computer Science, Interdisciplinary Applications
SC Computer Science
GA WE9UP
UT WOS:000705962900001
DA 2023-04-26
ER

PT J
AU Boughariou, E
   Allouche, N
   Ben Brahim, F
   Nasri, G
   Bouri, S
AF Boughariou, Emna
   Allouche, Nabila
   Ben Brahim, Fatma
   Nasri, Ghada
   Bouri, Salem
TI Delineation of groundwater potentials of Sfax region, Tunisia, using fuzzy analytical hierarchy process, frequency ratio, and weights of evidence models
SO ENVIRONMENT DEVELOPMENT AND SUSTAINABILITY
LA English
DT Article
DE Groundwater potential; Fuzzy analytical hierarchy process; Frequency ratio; Weights of evidence; Water management; Tunisia
ID geographical information-system; of-evidence; logistic-regression; multicriteria evaluation; aquifer vulnerability; spatial-analysis; coastal aquifer; neural-networks; drastic model; random forest
AB Groundwater in semiarid regions is of extreme importance due to limited water resources and increasing population demand. Hence, a better knowledge of aquifer potentialities is required for better management of this precious resource. This study aims to assess the groundwater potential map (GPM) by both statistical methods and geographical information system (GIS) in Sfax region, Tunisia. A number of 11,868 wells in the region were mapped in GIS and divided into two data sets: 8308 wells (70%) were selected in a random way and defined as training, wells while the remaining ones (3560 as 30%) were considered as testing wells for model validation. First, the groundwater conditioning factors, namely altitude, slope, lithology, drainage density, lineament density and land use maps, were evaluated and then processed by the fuzzy analytical hierarchy process (FAHP), frequency ratio (FR), and weights of evidence (WOE) statistical models. Then, the groundwater potential index (GWPI) was generated from an overlap of the weighted and rated of all the conditioning factors for the three methods. The groundwater potential maps were produced in ArcGIS 10.3 for the three models and classified by means of the quantile classification method. As a final step, the receiver operating characteristics (ROC) curves validated these maps. The validation results show from the areas under the curves (AUC) that the WOE model (AUC = 71.4%) performs similarly to the FR model (AUC = 71.1%), and both are slightly better than the FAHP (AUC = 65.1%) model. Thus, the delineation of groundwater potential zones supports the decision makers for the management of the aquifer exploitation. The appropriate groundwater potential map is established for a suitable management and a better planning of the water resources. Preventive works in low potential coastal areas should be conducted in the present and considered for a long-term management. Given the close results of the three adopted methods, it is possible to apply them in other regions with a consideration of their specific characteristics.
C1 [Boughariou, Emna; Allouche, Nabila; Ben Brahim, Fatma; Nasri, Ghada; Bouri, Salem] ENI Sfax, LR3E, Sfax, Tunisia.
   [Ben Brahim, Fatma] Univ Gabes, Fac Sci Gabes, Gabes, Tunisia.
   [Bouri, Salem] Univ Sfax, Fac Sci Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Universite de Gabes; Universite de Sfax; Faculty of Sciences Sfax
RP Boughariou, E (corresponding author), ENI Sfax, LR3E, Sfax, Tunisia.
EM boughariouemna@live.fr
CR Abd Manap M, 2014, ARAB J GEOSCI, V7, P711, DOI 10.1007/s12517-012-0795-z
   Al-Abadi AM, 2015, ENVIRON EARTH SCI, V74, P1109, DOI 10.1007/s12665-015-4097-0
   Allouche N, 2015, J WATER SUPPLY RES T, V64, P719, DOI 10.2166/aqua.2015.105
   Antonakos AK, 2007, J HYDROL, V333, P288, DOI 10.1016/j.jhydrol.2006.08.014
   Aryafar A, 2013, ENVIRON EARTH SCI, V68, P2313, DOI 10.1007/s12665-012-1910-x
   Ayadi R, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5445-4
   Ben Brahim F, 2013, ARAB J GEOSCI, V6, P2089, DOI 10.1007/s12517-011-0481-6
   Bonham-Carter GF., 1994, COMPUT METHODS GEOSC, V13, P398
   Bouaziz S, 2002, TECTONOPHYSICS, V357, P227, DOI 10.1016/S0040-1951(02)00370-0
   Boughariou E, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3408-7
   Boughariou E, 2015, ARAB J GEOSCI, V8, P5203, DOI 10.1007/s12517-014-1512-x
   Bouri S, 2008, ENVIRON GEOL, V53, P1421, DOI 10.1007/s00254-007-0751-5
   BUCKLEY JJ, 1985, FUZZY SET SYST, V17, P233, DOI 10.1016/0165-0114(85)90090-9
   Chang D.Y., 1992, EXTENT ANAL SYNTHETI, VVolume 1, P352
   Chen W, 2018, SCI TOTAL ENVIRON, V634, P853, DOI 10.1016/j.scitotenv.2018.04.055
   Cheng CH, 1999, EUR J OPER RES, V116, P423, DOI 10.1016/S0377-2217(98)00156-8
   Chenini I, 2010, WATER RESOUR MANAG, V24, P921, DOI 10.1007/s11269-009-9479-1
   Corsini A, 2009, GEOMORPHOLOGY, V111, P79, DOI 10.1016/j.geomorph.2008.03.015
   Daneshfar M., 2015, J APPL HYDROL, V2, P45
   DGRE, 2005, REPORT CO SGF INC SU, V0, P460
   Douglas SH, 2018, PHYS GEOGR, V39, P487, DOI 10.1080/02723646.2017.1406300
   Ebrahimi S. H., 2019, MODIFICATION DRASTIC, V0, P0
   Elmahdy SI, 2015, ARAB J GEOSCI, V8, P2405, DOI 10.1007/s12517-014-1327-9
   Fenta AA, 2015, HYDROGEOL J, V23, P195, DOI 10.1007/s10040-014-1198-x
   Ghribi R., 2010, THESIS U SFAX, V0, P256
   Gontara M., 2016, TUNISIA ARAB J GEOSC, V9, P1
   Hagedorn B, 2018, SCI TOTAL ENVIRON, V624, P1550, DOI 10.1016/j.scitotenv.2017.12.115
   Hua SS, 2015, WATER RES, V85, P31, DOI 10.1016/j.watres.2015.08.007
   Jha MK, 2010, HYDROGEOL J, V18, P1713, DOI 10.1007/s10040-010-0631-z
   Jmal I, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-3143-5
   Kahraman C, 2004, INT J PROD ECON, V87, P171, DOI 10.1016/S0925-5273(03)00099-9
   Kahraman C, 2008, SPRINGER SER OPTIM A, V16, P1, DOI 10.1007/978-0-387-76813-7
   Karan SK, 2018, LAND DEGRAD DEV, V29, P2351, DOI 10.1002/ldr.2990
   Kishore P, 2016, J MANUF SCI PROD, V16, P51, DOI 10.1515/jmsp-2015-0017
   Kordestani MD, 2019, HYDROGEOL J, V27, P211, DOI 10.1007/s10040-018-1848-5
   Kumar T, 2014, WATER RESOUR MANAG, V28, P4449, DOI 10.1007/s11269-014-0663-6
   Kura NU, 2015, ENVIRON SCI POLLUT R, V22, P1512, DOI 10.1007/s11356-014-3444-0
   Lee S, 2012, J ENVIRON MANAGE, V96, P91, DOI 10.1016/j.jenvman.2011.09.016
   Machiwal D, 2011, WATER RESOUR MANAG, V25, P1359, DOI 10.1007/s11269-010-9749-y
   Masetti M., 2007, NAT RESOUR RES, V16, P109, DOI 10.1007/s11053-007-9045-6
   Miraki S, 2019, WATER RESOUR MANAG, V33, P281, DOI 10.1007/s11269-018-2102-6
   Moghaddam DD, 2015, ARAB J GEOSCI, V8, P913, DOI 10.1007/s12517-013-1161-5
   Mohammadi-Behzad HR, 2019, CARBONATE EVAPORITE, V34, P1307, DOI 10.1007/s13146-018-0420-7
   Mokadem N, 2018, J AFR EARTH SCI, V141, P107, DOI 10.1016/j.jafrearsci.2018.02.007
   Msaddek MH, 2019, GEOL Q, V63, P3, DOI 10.7306/gq.1451
   Nampak H, 2014, J HYDROL, V513, P283, DOI 10.1016/j.jhydrol.2014.02.053
   Nejad SG, 2017, GEOCARTO INT, V32, P167, DOI 10.1080/10106049.2015.1132481
   NIM, 2018, ANN HYDROLOGICAL REP, V0, P0
   Oh HJ, 2011, J HYDROL, V399, P158, DOI 10.1016/j.jhydrol.2010.12.027
   Ozdagoglu A., 2007, COMP AHP FUZZY AHP M, V0, P0
   Ozdemir A, 2011, J HYDROL, V411, P290, DOI 10.1016/j.jhydrol.2011.10.010
   Rahmati O, 2016, CATENA, V137, P360, DOI 10.1016/j.catena.2015.10.010
   Rahmati O, 2015, ARAB J GEOSCI, V8, P7059, DOI 10.1007/s12517-014-1668-4
   Razandi Y, 2015, EARTH SCI INFORM, V8, P867, DOI 10.1007/s12145-015-0220-8
   RCAD : Sfax, 2014, RAPPORT ANNUEL LANNE, V0, P0
   Reis AP, 2004, APPL GEOCHEM, V19, P623, DOI 10.1016/j.apgeochem.2003.09.003
   Saaty T, 1980, ANAL HIERARCHY PROCE, V0, P287
   Sener E, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3510-x
   Sener E, 2015, ENVIRON EARTH SCI, V73, P8405, DOI 10.1007/s12665-014-4001-3
   Shekhar S, 2015, GEOCARTO INT, V30, P402, DOI 10.1080/10106049.2014.894584
   Smida Habib, 2010, SECHERESSE (MONTROUGE), V21, P131, DOI 10.1684/sec.2010.0246
   Tahmassebipoor N, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2166-z
   Tehrany MS, 2014, J HYDROL, V512, P332, DOI 10.1016/j.jhydrol.2014.03.008
   Trabelsi R., 2005, TUNISIE GEOSCI, V337, P515, DOI 10.1016/J.CRTE.2005.01.010
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Zabihi M, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5424-9
   Zeinivand H, 2018, GEOCARTO INT, V33, P651, DOI 10.1080/10106049.2017.1289560
NR 67
TC 12
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1387-585X
EI 1573-2975
J9 ENVIRON DEV SUSTAIN
JI Environ. Dev. Sustain.
PD OCT 15
PY 2021
VL 23
IS 10
BP 14749
EP 14774
DI 10.1007/s10668-021-01270-x
EA FEB 2021
PG 26
WC Green & Sustainable Science & Technology; Environmental Sciences
SC Science & Technology - Other Topics; Environmental Sciences & Ecology
GA UE1ZX
UT WOS:000616877200001
DA 2023-04-26
ER

PT J
AU Marchesi, G
   Eichhorn, C
   Plecher, DA
   Itoh, Y
   Klinker, G
AF Marchesi, Giulia
   Eichhorn, Christian
   Plecher, David A.
   Itoh, Yuta
   Klinker, Gudrun
TI EnvSLAM: Combining SLAM Systems and Neural Networks to Improve the Environment Fusion in AR Applications
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE SLAM; semantic segmentation; Semantic SLAM; GPS; Augmented Reality; machine learning; AR games; robotics; autonomous driving
ID tracking
AB Augmented Reality (AR) has increasingly benefited from the use of Simultaneous Localization and Mapping (SLAM) systems. This technology has enabled developers to create AR markerless applications, but lack semantic understanding of their environment. The inclusion of this information would empower AR applications to better react to the surroundings more realistically. To gain semantic knowledge, in recent years, focus has shifted toward fusing SLAM systems with neural networks, giving birth to the field of Semantic SLAM. Building on existing research, this paper aimed to create a SLAM system that generates a 3D map using ORB-SLAM2 and enriches it with semantic knowledge originated from the Fast-SCNN network. The key novelty of our approach is a new method for improving the predictions of neural networks, employed to balance the loss of accuracy introduced by efficient real-time models. Exploiting sensor information provided by a smartphone, GPS coordinates are utilized to query the OpenStreetMap database. The returned information is used to understand which classes are currently absent in the environment, so that they can be removed from the network's prediction with the goal of improving its accuracy. We achieved 87.40% Pixel Accuracy with Fast-SCNN on our custom version of COCO-Stuff and showed an improvement by involving GPS data for our self-made smartphone dataset resulting in 90.24% Pixel Accuracy. Having in mind the use on smartphones, the implementation aimed to find a trade-off between accuracy and efficiency, making the system achieve an unprecedented speed. To this end, the system was carefully designed and a strong focus on lightweight neural networks is also fundamental. This enabled the creation of an above real-time Semantic SLAM system that we called EnvSLAM (Environment SLAM). Our extensive evaluation reveals the efficiency of the system features and the operability in above real-time (48.1 frames per second with an input image resolution of 640 x 360 pixels). Moreover, the GPS integration indicates an effective improvement of the network's prediction accuracy.
C1 [Marchesi, Giulia; Eichhorn, Christian; Plecher, David A.; Klinker, Gudrun] Tech Univ Munich, Fac Comp Sci, D-85748 Garching, Germany.
   [Itoh, Yuta] Tokyo Inst Technol, Yokohama, Kanagawa 2260026, Japan.
C3 Technical University of Munich; Tokyo Institute of Technology
RP Eichhorn, C (corresponding author), Tech Univ Munich, Fac Comp Sci, D-85748 Garching, Germany.
EM giulia.marchesi@tum.de; christian.eichhorn@tum.de; plecher@in.tum.de; yuta.itoh@c.titech.ac.jp; klinker@in.tum.de
CR Ardeshir S, 2015, PROC CVPR IEEE, V0, PP2792, DOI 10.1109/CVPR.2015.7298896
   Ardeshir S, 2014, LECT NOTES COMPUT SC, V8694, P602, DOI 10.1007/978-3-319-10599-4_39
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bao SY, 2012, PROC CVPR IEEE, V0, PP2703, DOI 10.1109/CVPR.2012.6247992
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Caesar H, 2018, PROC CVPR IEEE, V0, PP1209, DOI 10.1109/CVPR.2018.00132
   Cavallari T., 2017, SEMANTIC SLAM NEW PA, V0, P0
   Chao P, 2019, IEEE I CONF COMP VIS, V0, PP3551, DOI 10.1109/ICCV.2019.00365
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Costante G, 2016, IEEE ROBOT AUTOM LET, V1, P18, DOI 10.1109/LRA.2015.2505717
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   DeTone D., 2017, ARXIV170707410, V0, P0
   Eichhorn C, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), V0, PP24, DOI 10.1109/ISMAR-Adjunct51615.2020.00022
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335
   Frese U, 2010, KUNSTL INTELL, V24, P191, DOI 10.1007/s13218-010-0040-4
   Hachiuma Ryo, 2019, BMVC, V0, P0
   Han SY, 2016, IEEE ICC, V0, P0, DOI DOI 10.1109/ICC.2016.7511104
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Hosseinyalamdary S, 2015, ISPRS INT J GEO-INF, V4, P1301, DOI 10.3390/ijgi4031301
   Howard A, 2019, IEEE I CONF COMP VIS, V0, PP1314, DOI 10.1109/ICCV.2019.00140
   Hubara I, 2016, ADV NEUR IN, V29, P0
   Kiss-Illes D, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19224973
   Klein George, 2007, P1, V0, P0
   Li B, 2018, INT CONF DAT MIN WOR, V0, PP1233, DOI 10.1109/ICDMW.2018.00176
   Li H., 2017, PROC INT C LEARN REP, V0, P1
   Li RH, 2018, COGN COMPUT, V10, P875, DOI 10.1007/s12559-018-9591-8
   LI X, 2016, ARXIV161104144, V0, P0
   Li X, 2019, PROC CVPR IEEE, V0, PP9137, DOI 10.1109/CVPR.2019.00936
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   McCormac John, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP4628, DOI 10.1109/ICRA.2017.7989538
   McCormac J, 2018, INT CONF 3D VISION, V0, PP32, DOI 10.1109/3DV.2018.00015
   Meingast M., 2009, P OMN VIS CAM NETW N, V0, P0
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nakajima Y, 2018, IEEE INT C INT ROBOT, V0, PP385, DOI 10.1109/IROS.2018.8593993
   Newcombe RA, 2011, IEEE I CONF COMP VIS, V0, PP2320, DOI 10.1109/ICCV.2011.6126513
   Oufqir Zainab, 2020, EMBEDDED SYSTEMS AND ARTIFICIAL INTELLIGENCE. PROCEEDINGS OF ESAI 2019. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1076), V0, PP599, DOI 10.1007/978-981-15-0947-6_57
   Plecher DA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), V0, PP1618, DOI 10.1109/VR.2019.8797846
   Poudel R., 2018, ARXIV180504554, V0, P0
   Poudel R. P. K., 2019, ARXIV190204502, V0, P0
   Poulose A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19235084
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reitmayr G., 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON UBIQUITOUS VIRTUAL REALITY (ISUVR 2010), V0, PP5, DOI 10.1109/ISUVR.2010.12
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosinol A., 2020, ARXIV200206289, V0, P0
   Runz M, 2018, INT SYM MIX AUGMENT, V0, PP10, DOI 10.1109/ISMAR.2018.00024
   Saffar M.H., 2018, ARXIV180606172, V0, P0
   Salas-Moreno RF, 2013, PROC CVPR IEEE, V0, PP1352, DOI 10.1109/CVPR.2013.178
   Shrivastava A, 2016, PROC CVPR IEEE, V0, PP761, DOI 10.1109/CVPR.2016.89
   Siam M, 2018, IEEE IMAGE PROC, V0, PP1603, DOI 10.1109/ICIP.2018.8451495
   Siltanen S., 2012, THESIS AALTO U ESPOO, V0, P0
   Tateno K, 2017, PROC CVPR IEEE, V0, PP6565, DOI 10.1109/CVPR.2017.695
   Tateno K, 2015, IEEE INT C INT ROBOT, V0, PP4465, DOI 10.1109/IROS.2015.7354011
   Ulku I., 2020, ARXIV191210230, V0, P0
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Wang Y, 2019, IEEE IMAGE PROC, V0, PP1860, DOI 10.1109/ICIP.2019.8803154
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), V0, P0, DOI DOI 10.1109/CISS.2018.8362280
   Xu JG, 2020, IEEE INFOCOM SER, V0, PP1828, DOI 10.1109/INFOCOM41043.2020.9155438
   Younes G., 2018, ARXIV160700470V1, V0, P0
   Younes G, 2017, ROBOT AUTON SYST, V98, P67, DOI 10.1016/j.robot.2017.09.010
   Yu C, 2018, IEEE INT C INT ROBOT, V0, PP1168, DOI 10.1109/IROS.2018.8593691
   Yun DS, 2014, I C INF COMM TECH CO, V0, PP609, DOI 10.1109/ICTC.2014.6983225
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhao Z., 2019, P 2019 2 CHIN S COGN, V0, PP149, DOI 10.1109/CCHI.2019.8901910
   Zhong FW, 2018, IEEE WINT CONF APPL, V0, PP1001, DOI 10.1109/WACV.2018.00115
NR 71
TC 3
Z9 3
U1 3
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD NOV 15
PY 2021
VL 10
IS 11
BP 
EP 
DI 10.3390/ijgi10110772
PG 21
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA XG5RB
UT WOS:000724808900001
DA 2023-04-26
ER

PT J
AU Emmi, L
   Le Flecher, E
   Cadenat, V
   Devy, M
AF Emmi, L.
   Le Flecher, E.
   Cadenat, V.
   Devy, M.
TI A hybrid representation of the environment to improve autonomous navigation of mobile robots in agriculture
SO PRECISION AGRICULTURE
LA English
DT Article
DE Hybrid topological map; Crop classification; Semantic identification; Autonomous navigation; Agricultural robotics
ID identification; segmentation; orchards; position; crop
AB This paper considers the problem of autonomous navigation in agricultural fields. It proposes a localization and mapping framework based on semantic place classification and key location estimation, which together build a hybrid topological map. This map benefits from generic partitioning of the field, which contains a finite set of well-differentiated workspaces and, through a semantic analysis, it is possible to estimate in a probabilistic way the position (state) of a mobile system in the field. Moreover, this map integrates both metric (key locations) and semantic features (working areas). One of its advantages is that a full and precise map prior to navigation is not necessary. The identification of the key locations and working areas is carried out by a perception system based on 2D LIDAR and RGB cameras. Fusing these data with odometry allows the robot to be located in the topological map. The approach is assessed through off-line data recorded in real conditions in diverse fields during different seasons. It exploits a real-time object detector based on a convolutional neural network called you only look once, version 3, which has been trained to classify a considerable number of crops, including market-garden crops such as broccoli and cabbage, and to identify grapevine trunks. The results show the interest in the approach, which allows (i) obtaining a simple and easy-to-update map, (ii) avoiding the use of artificial landmarks, and thus (iii) improving the autonomy of agricultural robots.
C1 [Emmi, L.; Le Flecher, E.; Cadenat, V.; Devy, M.] Univ Toulouse, CNRS, LAAS, 7 Ave Colonel Roche, F-31077 Toulouse, France.
   [Cadenat, V.] Univ Toulouse, UPS, LAAS, F-31400 Toulouse, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de Toulouse; Universite de Toulouse; Universite Toulouse III - Paul Sabatier
RP Emmi, L; Cadenat, V (corresponding author), Univ Toulouse, CNRS, LAAS, 7 Ave Colonel Roche, F-31077 Toulouse, France.; Cadenat, V (corresponding author), Univ Toulouse, UPS, LAAS, F-31400 Toulouse, France.
EM luis.emmi@laas.fr; cadenat@laas.fr
FU program "Investment for the Future" of the French government
CR Adao T, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111110
   Ampatzidis Y, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9061010
   [Anonymous], 2014, INT J DISTRIB SENS N, V0, P0, DOI DOI 10.1371/J0URNAL.P0NE.0110734
   Bechar A, 2016, BIOSYST ENG, V149, P94, DOI 10.1016/j.biosystemseng.2016.06.014
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P1, DOI 10.1007/978-3-642-00296-0_1
   Bergerman M, 2016, SPRINGER HANDBOOK OF ROBOTICS, V0, P1463
   Biber P., 2010, P IROS WORKSH SEM MA, V0, P0
   Blanke M, 2012, FAULT DIAGNOSIS ROBO, V0, P1
   Blok PM, 2019, COMPUT ELECTRON AGR, V157, P261, DOI 10.1016/j.compag.2018.12.046
   Bochtis DD, 2010, COMPUT ELECTRON AGR, V74, P80, DOI 10.1016/j.compag.2010.06.008
   Chen KH, 2000, AUTOMAT CONSTR, V10, P1, DOI 10.1016/S0926-5805(99)00010-2
   Cherubini A, 2014, IEEE T INTELL TRANSP, V15, P2101, DOI 10.1109/TITS.2014.2308977
   Comba L., 2010, INTERNATIONAL CONFERENCE, V0, P471
   Durand-Petiteville A, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, V0, P172, DOI 10.5220/0006478601720181
   Futterlieb Marcus, 2014, ICINCO 2014. 11TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, V0, P57
   Garcia-Santillan I, 2018, PRECIS AGRIC, V19, P18, DOI 10.1007/s11119-016-9494-1
   Gonzalez-de-Santos P, 2017, PRECIS AGRIC, V18, P574, DOI 10.1007/s11119-016-9476-3
   Hague T, 2000, COMPUT ELECTRON AGR, V25, P11, DOI 10.1016/S0168-1699(99)00053-8
   Hamuda E, 2016, COMPUT ELECTRON AGR, V125, P184, DOI 10.1016/j.compag.2016.04.024
   IFV, 2020, I FRANC VIGN VIN, V0, P0
   Kanagasingham S, 2020, PRECIS AGRIC, V21, P831, DOI 10.1007/s11119-019-09697-z
   Kayacan E, 2015, COMPUT ELECTRON AGR, V115, P78, DOI 10.1016/j.compag.2015.05.012
   Keskin M, 2017, PRECIS AGRIC, V18, P264, DOI 10.1007/s11119-016-9453-x
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006
   Kuipers B., 1991, ROBOTICS AND AUTONOMOUS SYSTEMS, V8, P47, DOI 10.1016/0921-8890(91)90014-C
   Lee SH, 2017, PATTERN RECOGN, V71, P1, DOI 10.1016/j.patcog.2017.05.015
   Li M, 2010, T ASABE, V53, P297
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Malavazi FBP, 2018, COMPUT ELECTRON AGR, V154, P71, DOI 10.1016/j.compag.2018.08.034
   Naio, 2020, ROB AGR NAIO TECHN, V0, P0
   Penizzotto F, 2015, IEEE LAT AM T, V13, P1303, DOI 10.1109/TLA.2015.7111983
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7_9
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Rottmann A., 2005, PROC NAT C ARTIF INT, V5, P1306
   Royakkers L, 2015, INT J SOC ROBOT, V7, P549, DOI 10.1007/s12369-015-0295-x
   Shamshiri RR, 2018, INT J AGR BIOL ENG, V11, P1, DOI 10.25165/j.ijabe.20181101.3210
   Sharifi M, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, V0, P251, DOI 10.1109/ICARA.2015.7081155
   Shi WN, 2019, BIOSYST ENG, V187, P81, DOI 10.1016/j.biosystemseng.2019.08.014
   STERELA, 2020, SOC IND ING SERV, V0, P0
   Thanpattranon P, 2016, BIOSYST ENG, V147, P90, DOI 10.1016/j.biosystemseng.2016.02.009
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7
   Tu CL, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), V0, PP655, DOI 10.1109/CISP.2014.7003860
   Vougioukas SG, 2019, ANNU REV CONTR ROBOT, V2, P365, DOI 10.1146/annurev-control-053018-023617
   Waldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Xue JR, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/1353691
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 47
TC 18
Z9 18
U1 11
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1385-2256
EI 1573-1618
J9 PRECIS AGRIC
JI Precis. Agric.
PD APR 15
PY 2021
VL 22
IS 2
BP 524
EP 549
DI 10.1007/s11119-020-09773-9
EA JAN 2021
PG 26
WC Agriculture, Multidisciplinary
SC Agriculture
GA RL6QE
UT WOS:000604197700005
DA 2023-04-26
ER
