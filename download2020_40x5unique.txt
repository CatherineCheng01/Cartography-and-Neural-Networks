
PT J
AU Chang, HC
   Borghesani, P
   Peng, ZX
AF Chang, Haichuan
   Borghesani, Pietro
   Peng, Zhongxiao
TI Automated assessment of gear wear mechanism and severity using mould images and convolutional neural networks
SO TRIBOLOGY INTERNATIONAL
LA English
DT Article
DE Wear assessment; Condition monitoring; Surface replication; Deep learning
ID particle classification; fault-diagnosis; surface; debris; system; model
AB A novel methodology for automated wear mechanism and severity assessment combining surface replication, imaging and deep learning is proposed. A large dataset of images of gear teeth moulds was built and covers abrasive wear, macropitting and scuffing, and three severity levels for each mechanism, i.e., mild, moderate and severe. A two-level inference methodology was implemented, based on a first convolutional neural network (CNN), which contains multiple convolutional layers and is commonly used for image classification, for wear mechanism identification, followed by three CNNs for wear severity estimation. The first level obtained a test classification accuracy of 98.22% and the second of 95.16% on average. The two-level system was also applied to full tooth flank mould images to generate wear mechanism and severity maps showing the geographical distribution of wear.
C1 [Chang, Haichuan; Borghesani, Pietro; Peng, Zhongxiao] UNSW, Sch Mech & Mfg Engn, Sydney, NSW 2052, Australia.
C3 University of New South Wales Sydney
RP Chang, HC (corresponding author), UNSW, Sch Mech & Mfg Engn, Sydney, NSW 2052, Australia.
EM haichuan.chang@student.unsw.edu.au
FU Australian Government through the Australian Research Council [DP160103501]
CR AGMA, 2014, 1010F14 AGMA ANSI, V0, P0
   ANDERSSON S, 1977, TRIBOL INT, V10, P206, DOI 10.1016/0301-679X(77)90021-4
   ANDERSSON S, 1974, WEAR, V29, P271, DOI 10.1016/0043-1648(74)90077-5
   Blau PJ, 2016, TRIBOSYSTEM ANAL PRA, V0, P0
   Bodini I, 2018, WEAR, V400, P156, DOI 10.1016/j.wear.2017.12.023
   Burwell J.T., 1957, WEAR, V1, P119, DOI 10.1016/0043-1648(57)90005-4
   Castro J, 2008, TRIBOL INT, V41, P244, DOI 10.1016/j.triboint.2007.07.005
   Chang HC, 2019, WEAR, V430, P355, DOI 10.1016/j.wear.2019.05.024
   Cheng HS, 2000, MODERN TRIBOLOGY HDB, V0, P0
   Duzcukoglu H, 2008, ENG FRACT MECH, V75, P4431, DOI 10.1016/j.engfracmech.2008.05.004
   Dyson A., 1975, TRIBOL INT, V8, P77, DOI 10.1016/0301-679X(75)90056-0
   Ebersbach S., 2007, ARTIFICIAL INTELLIGE, V0, P0
   Flodin A., 2000, THESIS ROYAL I TECHN, V0, P0
   Godfrey D, 1980, NEW YORK AM SOC MECH, V0, P283
   Gonzalez-Arias C, 2019, WEAR, V426, P1702, DOI 10.1016/j.wear.2018.11.028
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Hasan MJ, 2019, MEASUREMENT, V138, P620, DOI 10.1016/j.measurement.2019.02.075
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee BY, 2004, MECHATRONICS, V14, P129, DOI 10.1016/S0957-4158(02)00096-X
   Lei YG, 2016, IEEE T IND ELECTRON, V63, P3137, DOI 10.1109/TIE.2016.2519325
   Lei YG, 2014, MEASUREMENT, V48, P292, DOI 10.1016/j.measurement.2013.11.012
   Mba D., 2006, SHOCK AND VIBRATION DIGEST, V38, P3, DOI 10.1177/0583102405059054
   Moorthy V, 2012, TRIBOL INT, V51, P61, DOI 10.1016/j.triboint.2012.02.025
   Nielsen MA, 2015, NEURAL NETWORKS DEEP, V0, P0
   ODIOWEI S, 1987, WEAR, V117, P267, DOI 10.1016/0043-1648(87)90149-9
   Peng P, 2019, WEAR, V432, P0, DOI 10.1016/j.wear.2019.202968
   Peng YP, 2017, WEAR, V376, P1885, DOI 10.1016/j.wear.2017.01.012
   Peng Z, 1999, WEAR, V225, P1238, DOI 10.1016/S0043-1648(98)00400-1
   Peng ZX, 2002, WEAR, V252, P730, DOI 10.1016/S0043-1648(02)00031-5
   Prosvirin A, 2018, LECT NOTES ELECTR EN, V474, P21, DOI 10.1007/978-981-10-7605-3_4
   Raadnui S, 2005, TRIBOL INT, V38, P871, DOI 10.1016/j.triboint.2005.03.013
   Radzevich SP, 2012, DUDLEYS HDB PRACTICA, V0, P0, DOI DOI 10.1201/b11842.
   Randall R.B., 2011, VIBRATION BASED COND, V0, P0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Soleimani S, 2014, WEAR, V319, P123, DOI 10.1016/j.wear.2014.07.018
   Stachowiak G, 2013, ENG TRIBOLOGY, V0, P0, DOI DOI 10.1016/C2011-0-07515-4
   Stachowiak GW, 2006, TRIBOL INT, V39, P1615, DOI 10.1016/j.triboint.2006.01.019
   Stachowla GP, 2008, TRIBOL INT, V41, P34, DOI 10.1016/j.triboint.2007.04.004
   Wang HQ, 2019, COMPUT IND, V105, P182, DOI 10.1016/j.compind.2018.12.013
   Wang S, 2019, WEAR, V426, P1761, DOI 10.1016/j.wear.2018.12.087
   Wang W, 1998, TRIBOL INT, V31, P281, DOI 10.1016/S0301-679X(98)00034-6
   Wu HK, 2019, WEAR, V426, P1740, DOI 10.1016/j.wear.2018.12.089
   Younes MA, 2005, OPT ENG, V44, P0, DOI 10.1117/1.2114987
   Zhang J, 1900, P1960, V0, P0
   Zhang W, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17020425
   Zhu XL, 2017, TRIBOL INT, V109, P473, DOI 10.1016/j.triboint.2017.01.015
NR 49
TC 11
Z9 13
U1 5
U2 31
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0301-679X
EI 1879-2464
J9 TRIBOL INT
JI Tribol. Int.
PD JUL 15
PY 2020
VL 147
IS 
BP 
EP 
DI 10.1016/j.triboint.2020.106280
PG 16
WC Engineering, Mechanical
SC Engineering
GA LG7JR
UT WOS:000528273000025
DA 2023-04-26
ER

PT J
AU Abujayyab, SKM
   Karas, IR
AF Abujayyab, Sohaib K. M.
   Karas, Ismail Rakip
TI Employing Neural Networks Algorithm for LULC Mapping
SO BALTIC JOURNAL OF MODERN COMPUTING
LA English
DT Article; Proceedings Paper
DE Machine Learning; Neural Networks; Land Use/Land Cover (LULC); Satellite Image Classification
AB Land use/land cover (LULC) maps represent a primary requirement for several geospatial applications around the world such as change detection, time series analysis, environment, and urban researches. Mapping LULC from remotely sensed data based on satellite image classification handle the rapid changes in extensive geographical areas. Several effective and efficient mechanisms suggested for supervised satellite image classification. The neural networks machine learning algorithm became a major method in supervised satellite image classification. The objective of this article is to employ neural networks as a machine learning algorithm for LULC mapping. The study applied in Ankara area, which is the capital city of Turkey. This work utilized a free Landsat 8 satellite image with the Operational Land Imager OLI sensor to implement the analysis. The image was obtained and processed in ArcGIS software. Then, the machine learning data set developed using Python scripting language. Every band out of 8 bands from Landsat 8 image considered as an explanatory variable, while the output variable defined based on visual interpretation. The training dataset built based on the signature file and random sample points. The training dataset divided into three sections, for training, for validation and the last section for testing. The training and testing processes were implemented using Google-Tensor Flow Keres library from Anaconda distribution. Feedforward neural network structure implemented with 500 neurons in the hidden layer. Confusion matrix used as accuracy assessment metrics to measure the performance of the developed model. The overall accuracy of the developed model was 92%. In terms of overall accuracy and robustness, the neural networks algorithm was effectively implemented and the LULC map produces. The model gained high accuracy that it is satisfied with the geospatial accuracy target. The consequence showed the competence of neural networks algorithm to generating LULC maps from Landsat 8 satellite images.
C1 [Abujayyab, Sohaib K. M.] Karabuk Univ, Dept Geog, Demir Celik Campus, TR-78050 Karabuk, Turkey.
   [Karas, Ismail Rakip] Karabuk Univ, Dept Comp Engn, Demir Celik Campus, TR-78050 Karabuk, Turkey.
C3 Karabuk University; Karabuk University
RP Abujayyab, SKM (corresponding author), Karabuk Univ, Dept Geog, Demir Celik Campus, TR-78050 Karabuk, Turkey.
EM sjayyab@karabuk.edu.tr; ismail.karas@karabuk.edu.tr
FU TUBITAK (The Scientific and Technological Research Council of Turkey) [2221]
CR Abdullahi S, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7429-z
   Aydinoglu AC, 2010, SCI RES ESSAYS, V5, P275
   Conforti M, 2014, CATENA, V113, P236, DOI 10.1016/j.catena.2013.08.006
   Dorofki M, 2014, WATER RESOUR MANAG, V28, P391, DOI 10.1007/s11269-013-0489-7
   Hakkenberg CR, 2019, INT J REMOTE SENS, V40, P693, DOI 10.1080/01431161.2018.1516318
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Ikiel C., 2012, THE ONLINE JOURNAL OF SCIENCE AND TECHNOLOGY (TOJSAT), V2, P37
   Jacobson L., 2017, PROJECT SPOT, V19, P0
   Jafar R, 2010, MATH COMPUT MODEL, V51, P1170, DOI 10.1016/j.mcm.2009.12.033
   Liao W, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-38818-x
   Lu S, 2019, CHIN HERB MED, V11, P3, DOI 10.1016/j.chmed.2018.12.003
   Pavel M, 2008, GEOMORPHOLOGY, V97, P356, DOI 10.1016/j.geomorph.2007.08.012
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050523
   Saputra MH, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11113024
   Tayyebi A, 2011, LANDSCAPE URBAN PLAN, V100, P35, DOI 10.1016/j.landurbplan.2010.10.007
   Wang L., 2019, NAT ENVIRON POLLUT T, V18, P335
   Yi YN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151774
NR 18
TC 0
Z9 0
U1 0
U2 3
PU UNIV LATVIA
PI RIGA
PA RAINA BULVARIS 19, RIGA, LV-1586, LATVIA
SN 2255-8942
EI 2255-8950
J9 BALT J MOD COMPUT
JI Balt. J. Mod. Comput.
PD JUN 15
PY 2020
VL 8
IS 2
BP 370
EP 378
DI 10.22364/bjmc.2020.8.2.12
PG 9
WC Computer Science, Software Engineering
SC Computer Science
GA MC5ON
UT WOS:000543336000013
DA 2023-04-26
ER

PT J
AU Estevez, J
   Vicent, J
   Rivera-Caicedo, JP
   Morcillo-Pallares, P
   Vuolo, F
   Sabater, N
   Camps-Valls, G
   Moreno, J
   Verrelst, J
AF Estevez, Jose
   Vicent, Jorge
   Pablo Rivera-Caicedo, Juan
   Morcillo-Pallares, Pablo
   Vuolo, Francesco
   Sabater, Neus
   Camps-Valls, Gustau
   Moreno, Jose
   Verrelst, Jochem
TI Gaussian processes retrieval of LAI from Sentinel-2 top-of-atmosphere radiance data
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Biophysical variables; LAI estimation; Top-of-atmosphere radiance data; Sentinel-2; Gaussian process regression; Radiative transfer model
ID leaf-area index; radiative-transfer calculations; libradtran software package; neural-network estimation; biophysical parameters; chlorophyll content; vegetation property; surface reflectance; vector version; satellite data
AB Retrieval of vegetation properties from satellite and airborne optical data usually takes place after atmospheric correction, yet it is also possible to develop retrieval algorithms directly from top-of-atmosphere (TOA) radiance data. One of the key vegetation variables that can be retrieved from at-sensor TOA radiance data is leaf area index (LAI) if algorithms account for variability in atmosphere. We demonstrate the feasibility of LAI retrieval from Sentinel-2 (S2) TOA radiance data (L1C product) in a hybrid machine learning framework. To achieve this, the coupled leaf-canopy-atmosphere radiative transfer models PROSAIL-6SV were used to simulate a look-up table (LUT) of TOA radiance data and associated input variables. This LUT was then used to train the Bayesian machine learning algorithms Gaussian processes regression (GPR) and variational heteroscedastic GPR (VHGPR). PROSAIL simulations were also used to train GPR and VHGPR models for LAI retrieval from S2 images at bottom-of-atmosphere (BOA) level (L2A product) for comparison purposes. The BOA and TOA LAI products were consistently validated against a field dataset with GPR (R-2 of 0.78) and with VHGPR (R-2 of 0.80) and for both cases a slightly lower RMSE for the TOA LAI product (about 10% reduction). Because of delivering superior accuracies and lower uncertainties, the VHGPR models were further applied for LAI mapping using S2 acquisitions over the agricultural sites Marchfeld (Austria) and Barrax (Spain). The models led to consistent LAI maps at BOA and TOA scale. The LAI maps were also compared against LAI maps as generated by the SNAP toolbox, which is based on a neural network (NN). Maps were again consistent, however the SNAP NN model tends to overestimate over dense vegetation cover. Overall, this study demonstrated that hybrid LAI retrieval algorithms can be developed from TOA radiance data given a cloud-free sky, thus without the need of atmospheric correction. To the benefit of the community, the development of such hybrid models for the retrieval vegetation properties from BOA or TOA images has been streamlined in the freely downloadable ALG-ARTMO software framework.
C1 [Estevez, Jose; Morcillo-Pallares, Pablo; Camps-Valls, Gustau; Moreno, Jose; Verrelst, Jochem] Univ Valencia, Image Proc Lab IPL, Parc Cient, Valencia 46980, Spain.
   [Vicent, Jorge] Magellium, Toulouse, France.
   [Pablo Rivera-Caicedo, Juan] CONACYT UAN, Res & Grad Studies, Tepic 63155, Nayarit, Mexico.
   [Vuolo, Francesco] Univ Nat Resources & Life Sci, Inst Geomat, Vienna BOKU, Peter Jordan Str 82, A-1190 Vienna, Austria.
   [Sabater, Neus] Finnish Meteorol Inst, Erik Palmenin Aukio 1,POB 501, Helsinki 00101, Finland.
C3 University of Valencia; University of Natural Resources & Life Sciences, Vienna; Finnish Meteorological Institute
RP Verrelst, J (corresponding author), Univ Valencia, Image Proc Lab IPL, Parc Cient, Valencia 46980, Spain.
EM jochem.verrelst@uv.es
FU European Research Council (ERC) under the ERC-2017-STG SENTIFLEX project [755617]; Ramon y Cajal Contract (Spanish Ministry of Science, Innovation and Universities); European Research Council (ERC) under the ERC-CoG-2014 SEDAL project [647423]
CR Bacour C, 2006, REMOTE SENS ENVIRON, V105, P313, DOI 10.1016/j.rse.2006.07.014
   Baret F, 2013, REMOTE SENS ENVIRON, V137, P299, DOI 10.1016/j.rse.2012.12.027
   Bayat B, 2020, REMOTE SENS ENVIRON, V238, P0, DOI 10.1016/j.rse.2018.09.030
   Berger K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010085
   Berk A., 2006, MODTRAN5 2006, V0, P0
   Camps-Valls G, 2019, NATL SCI REV, V6, P616, DOI 10.1093/nsr/nwz028
   Camps-Valls G, 2016, IEEE GEOSC REM SEN M, V4, P58, DOI 10.1109/MGRS.2015.2510084
   Clerc S., 2020, TECHNICAL REPORT, V0, P0
   Doxani G, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020352
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Emde C, 2016, GEOSCI MODEL DEV, V9, P1647, DOI 10.5194/gmd-9-1647-2016
   ESA, 2018, TECHNICAL REPORT, V0, P0
   Fang HL, 2003, IEEE T GEOSCI REMOTE, V41, P2052, DOI 10.1109/TGRS.2003.813493
   Fang HL, 2019, REV GEOPHYS, V57, P739, DOI 10.1029/2018RG000608
   Feret JB, 2008, REMOTE SENS ENVIRON, V112, P3030, DOI 10.1016/j.rse.2008.02.012
   Fourty T, 1997, REMOTE SENS ENVIRON, V61, P34, DOI 10.1016/S0034-4257(96)00238-6
   Gao BC, 2009, REMOTE SENS ENVIRON, V113, PS17, DOI 10.1016/j.rse.2007.12.015
   Gascon F, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060584
   GCOS G., 2011, SYST OBS REQ SAT BAS, V0, P0
   JACQUEMOUD S, 1992, REMOTE SENS ENVIRON, V41, P123, DOI 10.1016/0034-4257(92)90072-R
   Jacquemoud S, 2009, REMOTE SENS ENVIRON, V113, PS56, DOI 10.1016/j.rse.2008.01.026
   KAUFMAN YJ, 1988, INT J REMOTE SENS, V9, P1357, DOI 10.1080/01431168808954942
   Kokaly R., 2017, USGS SPECTRAL LIB VE, V1035, P0
   Kotchenova SY, 2007, APPL OPTICS, V46, P4455, DOI 10.1364/AO.46.004455
   Kotchenova SY, 2006, APPL OPTICS, V45, P6762, DOI 10.1364/AO.45.006762
   Laurent VCE, 2013, REMOTE SENS ENVIRON, V139, P6, DOI 10.1016/j.rse.2013.07.032
   Laurent VCE, 2014, REMOTE SENS ENVIRON, V140, P318, DOI 10.1016/j.rse.2013.09.005
   Laurent VCE, 2011, REMOTE SENS ENVIRON, V115, P2603, DOI 10.1016/j.rse.2011.05.016
   Laurent VCE, 2011, REMOTE SENS ENVIRON, V115, P1043, DOI 10.1016/j.rse.2010.12.009
   Lauvernet C, 2008, REMOTE SENS ENVIRON, V112, P851, DOI 10.1016/j.rse.2007.06.027
   Lazaro-Gredilla M., 2011, ICML, V0, P841
   Lazaro-Gredilla M, 2014, IEEE GEOSCI REMOTE S, V11, P838, DOI 10.1109/LGRS.2013.2279695
   Lenoble J, 2007, J QUANT SPECTROSC RA, V107, P479, DOI 10.1016/j.jqsrt.2007.03.010
   Li-Cor I., 1992, LAI 2000 PLANT CANOP, V0, P0
   Liu WD, 2002, REMOTE SENS ENVIRON, V81, P238, DOI 10.1016/S0034-4257(01)00347-9
   Louis J., 2010, P ESA LIV PLAN S BER, V0, P0
   Main-Knorn M., 2017, P SPIE, V0, P0
   Malenovsky Z, 2012, REMOTE SENS ENVIRON, V120, P91, DOI 10.1016/j.rse.2011.09.026
   Martins VS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040322
   Mayer B, 2005, ATMOS CHEM PHYS, V5, P1855, DOI 10.5194/acp-5-1855-2005
   Meerdink SK, 2019, REMOTE SENS ENVIRON, V230, P0, DOI 10.1016/j.rse.2019.05.015
   Mousivand A, 2015, REMOTE SENS ENVIRON, V158, P311, DOI 10.1016/j.rse.2014.10.030
   Mousivand A, 2014, REMOTE SENS ENVIRON, V145, P131, DOI 10.1016/j.rse.2014.01.023
   Pasolli E, 2012, IEEE T GEOSCI REMOTE, V50, P4071, DOI 10.1109/TGRS.2012.2187906
   Prikaziuk E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202424
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, V0, P1
   Richter R., 2011, TECHNICAL REPORT, V0, P0
   Richter R, 2011, INT J REMOTE SENS, V32, P2931, DOI 10.1080/01431161.2010.520346
   Caicedo JPR, 2014, IEEE J-STARS, V7, P1249, DOI 10.1109/JSTARS.2014.2298752
   Rivera JP, 2013, REMOTE SENS-BASEL, V5, P3280, DOI 10.3390/rs5073280
   Schlapfer D, 1998, REMOTE SENS ENVIRON, V65, P353, DOI 10.1016/S0034-4257(98)00044-3
   Shi HY, 2017, IEEE T GEOSCI REMOTE, V55, P5158, DOI 10.1109/tgrs.2017.2702609
   Shi HY, 2016, REMOTE SENS ENVIRON, V184, P40, DOI 10.1016/j.rse.2016.06.008
   Sola I, 2018, INT J APPL EARTH OBS, V73, P63, DOI 10.1016/j.jag.2018.05.020
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Svendsen D., 2020, PATTERN RECOGN, V100, P1
   Thompson DR, 2019, SURV GEOPHYS, V40, P333, DOI 10.1007/s10712-018-9488-9
   Thuillier G, 2003, SOL PHYS, V214, P1, DOI 10.1023/A:1024048429145
   Upreti D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050481
   Verger A, 2011, REMOTE SENS ENVIRON, V115, P415, DOI 10.1016/j.rse.2010.09.012
   Verhoef W, 2003, REMOTE SENS ENVIRON, V87, P23, DOI 10.1016/S0034-4257(03)00143-3
   VERHOEF W, 1984, REMOTE SENS ENVIRON, V16, P125, DOI 10.1016/0034-4257(84)90057-9
   Verhoef W, 2007, REMOTE SENS ENVIRON, V109, P166, DOI 10.1016/j.rse.2006.12.013
   Vermote EF, 1997, IEEE T GEOSCI REMOTE, V35, P675, DOI 10.1109/36.581987
   Verrelst J., 2019, REMOTE SENS, V11, P0
   Verrelst J, 2019, SURV GEOPHYS, V40, P589, DOI 10.1007/s10712-018-9478-y
   Verrelst J, 2016, INT J APPL EARTH OBS, V52, P554, DOI 10.1016/j.jag.2016.07.016
   Verrelst J, 2016, IEEE GEOSCI REMOTE S, V13, P1012, DOI 10.1109/LGRS.2016.2560799
   Verrelst J, 2015, ISPRS J PHOTOGRAMM, V108, P273, DOI 10.1016/j.isprsjprs.2015.05.005
   Verrelst J, 2015, ISPRS J PHOTOGRAMM, V108, P260, DOI 10.1016/j.isprsjprs.2015.04.013
   Verrelst J, 2013, ISPRS J PHOTOGRAMM, V86, P157, DOI 10.1016/j.isprsjprs.2013.09.012
   Verrelst J, 2014, IEEE T GEOSCI REMOTE, V52, P257, DOI 10.1109/TGRS.2013.2238242
   Verrelst J, 2013, IEEE J-STARS, V6, P867, DOI 10.1109/JSTARS.2012.2222356
   Verrelst J, 2012, REMOTE SENS-BASEL, V4, P2866, DOI 10.3390/rs4092866
   Verrelst J, 2012, IEEE T GEOSCI REMOTE, V50, P1832, DOI 10.1109/TGRS.2011.2168962
   Verrelst J, 2012, REMOTE SENS ENVIRON, V118, P127, DOI 10.1016/j.rse.2011.11.002
   Vicent J, 2020, GEOSCI MODEL DEV, V13, P1945, DOI 10.5194/gmd-13-1945-2020
   Vicent J, 2018, IEEE J-STARS, V11, P4918, DOI 10.1109/JSTARS.2018.2875330
   Vuolo F, 2018, INT J APPL EARTH OBS, V72, P122, DOI 10.1016/j.jag.2018.06.007
   Vuolo F, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110938
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111402
   Weiss M., 2016, 400011061214IBG ESA, V0, P52
   Yan GJ, 2019, AGR FOREST METEOROL, V265, P390, DOI 10.1016/j.agrformet.2018.11.033
   Yang PQ, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111870
NR 84
TC 25
Z9 26
U1 4
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD SEP 15
PY 2020
VL 167
IS 
BP 289
EP 304
DI 10.1016/j.isprsjprs.2020.07.004
PG 16
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA NC6SC
UT WOS:000561346200020
PM 36082068
DA 2023-04-26
ER

PT J
AU Nice, KA
   Thompson, J
   Wijnands, JS
   Aschwanden, GDPA
   Stevenson, M
AF Nice, Kerry A.
   Thompson, Jason
   Wijnands, Jasper S.
   Aschwanden, Gideon D. P. A.
   Stevenson, Mark
TI The "Paris-End" of Town? Deriving Urban Typologies Using Three Imagery Types
SO URBAN SCIENCE
LA English
DT Article
DE machine learning; urban typology; urban design; transport; health
ID city-planning ordinances; open-source tool; classification; associations; transport; laws
AB Urban typologies allow areas to be categorised according to form and the social, demographic, and political uses of the areas. The use of these typologies and finding similarities and dissimilarities between cities enables better targeted interventions for improved health, transport, and environmental outcomes in urban areas. A better understanding of local contexts can also assist in applying lessons learned from other cities. Constructing urban typologies at a global scale through traditional methods, such as functional or network analysis, requires the collection of data across multiple political districts, which can be inconsistent and then require a level of subjective classification. To overcome these limitations, we use neural networks to analyse millions of images of urban form (consisting of street view, satellite imagery, and street maps) to find shared characteristics between the largest 1692 cities in the world. The comparison city of Paris is used as an exemplar and we perform a case study using two Australian cities, Melbourne and Sydney, to determine if a "Paris-end" of town exists or can be found in these cities using these three big data imagery sets. The results show specific advantages and disadvantages of each type of imagery in constructing urban typologies. Neural networks trained with map imagery will be highly influenced by the structural mix of roads, public transport, and green and blue space. Satellite imagery captures a combination of both urban form and decorative and natural details. The use of street view imagery emphasises the features of a human-scaled visual geography of streetscapes. However, for both satellite and street view imagery to be highly effective, a reduction in scale and more aggressive pre-processing might be required in order to reduce detail and create greater abstraction in the imagery.
C1 [Nice, Kerry A.; Thompson, Jason; Wijnands, Jasper S.; Aschwanden, Gideon D. P. A.; Stevenson, Mark] Univ Melbourne, Transport Hlth & Urban Design Lab, Fac Architecture Bldg & Planning, Melbourne, Vic 3010, Australia.
   [Stevenson, Mark] Univ Melbourne, Melbourne Sch Engn, Melbourne, Vic 3010, Australia.
C3 University of Melbourne; University of Melbourne
RP Nice, KA (corresponding author), Univ Melbourne, Transport Hlth & Urban Design Lab, Fac Architecture Bldg & Planning, Melbourne, Vic 3010, Australia.
EM kerry.nice@unimelb.edu.au; jason.thompson@unimelb.edu.au; jasper.wijnands@unimelb.edu.au; gideon.aschwanden@unimelb.edu.au; mark.stevenson@unimelb.edu.au
FU National Health and Medical Research Council (Australia) Fellowship [APP1136250]
CR Anholt S, 2006, PLACE BRANDING PUBLI, V2, P18, DOI 10.1057/palgrave.pb.5990042
   [Anonymous], 2015, MSRTR2014112, V0, P0
   ARGAN Giulio Carlo, 1962, ARCHIT DESIGN, V0, P564
   Arribas-Bel D., 2019, J URBAN EC, V0, P0
   Baidu, 2017, BAID STREET VIEW API, V0, P0
   Bandini M., 1984, AA FILES, V6, P73
   Barthelemy M., 2016, STRUCTURE DYNAMICS C, V0, P278
   Bishop C.M., 1995, STATA J, V6, P40, DOI 10.2307/2965437
   BRUCE GD, 1971, SOCIOL QUART, V12, P238, DOI 10.1111/j.1533-8525.1971.tb01354.x
   Cepeda M, 2017, LANCET PUBLIC HEALTH, V2, PE23, DOI 10.1016/S2468-2667(16)30021-4
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   CROUCH DP, 1977, TOWN PLAN REV, V48, P397, DOI 10.3828/tpr.48.4.f646k8765512762n
   Daley M, 2011, TRANSPORT POLICY, V18, P211, DOI 10.1016/j.tranpol.2010.08.004
   Day Jennifer, 2017, ENVIRONMENT SYSTEMS & DECISIONS, V37, P68, DOI 10.1007/s10669-017-9623-z
   Day J, 2016, SPAT ECON ANAL, V11, P67, DOI 10.1080/17421772.2016.1102957
   Dijkstra L., 2019, OECD REGIONAL DEV WO, V0, P0, DOI DOI 10.1787/d58cb34d-en
   Doersch C, 2012, ACM T GRAPHIC, V31, P0, DOI 10.1145/2185520.2185597
   Dubey A, 2016, LECT NOTES COMPUT SC, V9905, P196, DOI 10.1007/978-3-319-46448-0_12
   Giles-Corti B, 2016, LANCET, V388, P2912, DOI 10.1016/S0140-6736(16)30066-6
   Goenka S., 2016, LANCET, V6736, P8
   Google Maps, 2017, GOOGL STAT MAPS API, V0, P0
   Google Maps, 2017, GOOGL STREET VIEW AP, V0, P0
   Graupe D., 2013, ADV SERIES CIRCUITS, V7, P0
   Harris CD, 1943, GEOGR REV, V33, P86, DOI 10.2307/210620
   Heesch KC, 2014, PREV MED, V63, P29, DOI 10.1016/j.ypmed.2014.03.003
   Hermosilla T, 2014, COMPUT ENVIRON URBAN, V44, P68, DOI 10.1016/j.compenvurbsys.2013.12.002
   Hillier B., 1996, SPACE IS MACHINE, V0, P0
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Kleinert S., 2016, LANCET, V6736, P1
   Kohavi R., 1998, MACH LEARN, V30, P271, DOI 10.1023/A:1017181826899
   Krier R., 1979, URBAN SPACE, V0, P173
   Li XJ, 2015, URBAN FOR URBAN GREE, V14, P675, DOI 10.1016/j.ufug.2015.06.006
   Liu L, 2016, GEOJOURNAL, V81, P817, DOI 10.1007/s10708-016-9739-6
   MUNDIGO AI, 1977, TOWN PLANN REV, V48, P247, DOI 10.3828/tpr.48.3.g58m031x54655ll5
   Naik N, 2014, IEEE COMPUT SOC CONF, V0, PP793, DOI 10.1109/CVPRW.2014.121
   Nelson HJ, 1955, ECON GEOGR, V31, P189, DOI 10.2307/142045
   Norman J, 2006, J URBAN PLAN DEV, V132, P10, DOI 10.1061/(ASCE)0733-9488(2006)132:1(10)
   Pymeanshift, 2017, PYTH MOD MEAN SHIFT, V0, P0
   Quistberg DA, 2019, J URBAN HEALTH, V96, P311, DOI 10.1007/s11524-018-00326-0
   Rossi A., 1982, ARCHITECTURE CITY, V0, P201
   Salesses P, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0068400
   Samarasinghe S., 2016, NEURAL NETWORKS APPL, V0, P570
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   SINNOTT RW, 1984, SKY TELESCOPE, V68, P159
   Stewart ID, 2012, B AM METEOROL SOC, V93, P1879, DOI 10.1175/BAMS-D-11-00019.1
   Stewart ID, 2014, INT J CLIMATOL, V34, P1062, DOI 10.1002/joc.3746
   Strano E, 2012, SCI REP-UK, V2, P0, DOI 10.1038/srep00296
   Thompson J, 2020, LANCET PLANET HEALTH, V4, PE32, DOI 10.1016/S2542-5196(19)30263-3
   United Nations, 2014, WORLD URB PROSP 2014, V0, P0
   Wegener M., 1986, ADV URBAN SYSTEMS MO, V0, P175
   Wen LM, 2008, PREV MED, V46, P29, DOI 10.1016/j.ypmed.2007.08.009
   Wijnands JS, 2019, SUSTAIN CITIES SOC, V49, P0, DOI 10.1016/j.scs.2019.101602
   Wilden N., 2013, AUSTRALIAN, V0, P0
   Williams P, 2010, TLS-TIMES LIT SUPPL, V0, P10
   Zapata-Diomedi B, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0184799
   Zhang Q, 2013, REMOTE SENS-BASEL, V5, P3476, DOI 10.3390/rs5073476
   Zhou BL, 2014, LECT NOTES COMPUT SC, V8691, P519, DOI 10.1007/978-3-319-10578-9_34
NR 58
TC 3
Z9 3
U1 1
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2413-8851
J9 URBAN SCI
JI Urban Sci.
PD JUN 15
PY 2020
VL 4
IS 2
BP 
EP 
DI 10.3390/urbansci4020027
PG 18
WC Environmental Sciences; Environmental Studies; Geography; Regional & Urban Planning; Urban Studies
SC Environmental Sciences & Ecology; Geography; Public Administration; Urban Studies
GA QL3BN
UT WOS:000620955400013
DA 2023-04-26
ER

PT J
AU Scharvogel, D
   Brandmeier, M
   Weis, M
AF Scharvogel, Daniel
   Brandmeier, Melanie
   Weis, Manuel
TI A Deep Learning Approach for Calamity Assessment Using Sentinel-2 Data
SO FORESTS
LA English
DT Article
DE CNNs; remote sensing; windthrow; forest; Deep Learning; GIS
ID forest; disturbances; impact; sar
AB The number of severe storm events has increased in recent decades due to climate change. These storms are one of the main causes for timber loss in European forests and damaged areas are prone to further degradation by, for example, bark beetle infestations. Usually, manual mapping of damaged areas based on aerial photographs is conducted by forest departments. This is very time-consuming and therefore automatic detection of windthrows based on active and passive remote sensing data is an ongoing research topic. In this study we evaluated state-of-the-art Convolutional Neural Networks (CNNs) in combination with Geographic Information Systems (GIS) for calamity assessment. The study area is in in the northern part of Hesse (Germany) and was covered by twelve Sentinel-2 scenes from 2018. Labels of damaged areas from the Friedericke storm (18 January 2018) were provided by HessenForst. We conducted several experiments based on a custom U-Net setup to derive the optimal architecture and input data as well as to assess the transferability of the model. Results highlight the possibility to detect damaged forest areas using Sentinel-2 data. Using a binary classification, accuracies of more than 92% were achieved with an Intersection over Union (IoU) score of 46.6%. The proposed workflow was integrated into ArcGIS and is suitable for fast detection of damaged areas directly after a storm and for disaster management but is limited by the deca-meter spatial resolution of the Sentinel-2 data.
C1 [Scharvogel, Daniel; Brandmeier, Melanie] Esri Deutschland, Dept Sci & Educ, Ringstr 7, D-85402 Kranzberg, Germany.
   [Scharvogel, Daniel] Weihenstephan Triesdorf Univ Appl Sci, Dept Forestry, Hans Carl von Carlowitz Pl 3, D-85354 Freising Weihenstephan, Germany.
   [Weis, Manuel] HessenForst, Europastr 10-12, D-35394 Giessen, Germany.
RP Scharvogel, D (corresponding author), Esri Deutschland, Dept Sci & Educ, Ringstr 7, D-85402 Kranzberg, Germany.; Scharvogel, D (corresponding author), Weihenstephan Triesdorf Univ Appl Sci, Dept Forestry, Hans Carl von Carlowitz Pl 3, D-85354 Freising Weihenstephan, Germany.
EM D.Scharvogel@gmx.net; m.brandmeier@esri.de; Manuel.Weis@forst.hessen.de
CR [Anonymous], 2010, FINAL REPORT EUROPEA, V0, P0
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Chehata N, 2014, INT J REMOTE SENS, V35, P4758, DOI 10.1080/01431161.2014.930199
   Chehata N, 2011, INT ARCH PHOTOGRAMM, V38-3, P49
   Chirici G, 2018, FORESTRY, V91, P27, DOI 10.1093/forestry/cpx029
   Deigele W, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12132121
   Duan FZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040306
   Einzmann K, 2017, FORESTS, V8, P0, DOI 10.3390/f8010021
   Eriksson LEB, 2012, INT GEOSCI REMOTE SE, V0, PP6435, DOI 10.1109/IGARSS.2012.6352732
   Fink AH, 2009, NAT HAZARD EARTH SYS, V9, P405, DOI 10.5194/nhess-9-405-2009
   Forster B., 2010, STURM WITTERUNG BORK, V0, P0
   Forzieri G, 2020, EARTH SYST SCI DATA, V12, P257, DOI 10.5194/essd-12-257-2020
   Fransson JES, 2002, IEEE T GEOSCI REMOTE, V40, P2170, DOI 10.1109/TGRS.2002.804913
   Fransson JES, 2010, INT GEOSCI REMOTE SE, V0, PP1242, DOI 10.1109/IGARSS.2010.5654183
   Fuhrer J, 2006, CLIMATIC CHANGE, V79, P79, DOI 10.1007/s10584-006-9106-6
   Haidu I, 2019, OPEN GEOSCI, V11, P492, DOI 10.1515/geo-2019-0040
   Hamdi ZM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171976
   Hanewinkel M., 2013, LIVING STORM DAMAGE, V0, P55
   Honkavaara E, 2013, REMOTE SENS-BASEL, V5, P1405, DOI 10.3390/rs5031405
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Molter T, 2016, ATMOSPHERE-BASEL, V7, P0, DOI 10.3390/atmos7040060
   Mokros M, 2017, FORESTS, V8, P0, DOI 10.3390/f8090306
   Ningthoujam RK, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070577
   Nystrom M, 2014, INT J APPL EARTH OBS, V30, P21, DOI 10.1016/j.jag.2014.01.012
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Ruetschi M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020115
   Seidl R, 2017, LANDSCAPE ECOL, V32, P1485, DOI 10.1007/s10980-016-0396-4
   Seidl R, 2014, NAT CLIM CHANGE, V4, P806, DOI 10.1038/NCLIMATE2318
   Seitz R., 2017, FASTRESPONSE SCHNELL, V0, P0
   Statistisches Bundesamt, 2019, 30 FLACH DEUTSCHL SI, V0, P0
   Tanase MA, 2018, REMOTE SENS ENVIRON, V209, P700, DOI 10.1016/j.rse.2018.03.009
   Thunen-Institut, 2012, WALDFL HA NACH LAND, V0, P0
   Wessel M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091419
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhu Z, 2012, REMOTE SENS ENVIRON, V122, P75, DOI 10.1016/j.rse.2011.10.030
NR 38
TC 3
Z9 4
U1 5
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1999-4907
J9 FORESTS
JI Forests
PD DEC 15
PY 2020
VL 11
IS 12
BP 
EP 
DI 10.3390/f11121239
PG 21
WC Forestry
SC Forestry
GA PJ8GY
UT WOS:000602000000001
DA 2023-04-26
ER
