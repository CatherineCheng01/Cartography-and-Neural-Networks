
PT J
AU Hu, Y
   Subagdja, B
   Tan, AH
   Yin, QJ
AF Hu, Yue
   Subagdja, Budhitama
   Tan, Ah-Hwee
   Yin, Quanjun
TI Vision-Based Topological Mapping and Navigation With Self-Organizing Neural Networks
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Navigation; Subspace constraints; Visualization; Layout; Hippocampus; Computational modeling; Aerospace electronics; Episodic memory; fine-tuned motion control; fusion adaptive resonance theory (ART) networks; spatial memory; topological graphs
ID landmark salience; hippocampus; memory; representation; humans
AB Spatial mapping and navigation are critical cognitive functions of autonomous agents, enabling one to learn an internal representation of an environment and move through space with real-time sensory inputs, such as visual observations. Existing models for vision-based mapping and navigation, however, suffer from memory requirements that increase linearly with exploration duration and indirect path following behaviors. This article presents e-TM, a self-organizing neural network-based framework for incremental topological mapping and navigation. e-TM models the exploration trajectories explicitly as episodic memory, wherein salient landmarks are sequentially extracted as ``events'' from streaming observations. A memory consolidation procedure then performs a playback mechanism and transfers the embedded knowledge of the environmental layout into spatial memory, encoding topological relations between landmarks. Fusion adaptive resonance theory (ART) networks, as the building block of the two memory modules, can generalize multiple input patterns into memory templates and, therefore, provide a compact spatial representation and support the discovery of novel shortcuts through inferences. For navigation, e-TM applies a transfer learning paradigm to integrate human demonstrations into a pretrained locomotion network for smoother movements. Experimental results based on VizDoom, a simulated 3-D environment, have shown that, compared to semiparametric topological memory (SPTM), a state-of-the-art model, e-TM reduces the time costs of navigation significantly while learning much sparser topological graphs.
C1 [Hu, Yue; Yin, Quanjun] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Peoples R China.
   [Subagdja, Budhitama; Tan, Ah-Hwee] Singapore Management Univ, Sch Comp & Informat Syst, Singapore 178902, Singapore.
C3 National University of Defense Technology - China; Singapore Management University
RP Hu, Y (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Peoples R China.
EM huyue.cse@gmail.com; budhitamas@smu.edu.sg; ahtan@smu.edu.sg; yin_quanjun@163.com
FU National Natural Science Foundation of China [61273300]; China Scholarship Council; National Research Foundation, Singapore, under its AI Singapore Programme (AISG) [AISG2-RP-2020-019]; Singapore Ministry of Education Academic Research Fund (AcRF) Tier-1 [19-C220-SMU-023]
CR Aronov D, 2017, NATURE, V543, P719, DOI 10.1038/nature21692
   Burgess N, 2002, NEURON, V35, P625, DOI 10.1016/S0896-6273(02)00830-9
   Burgess N, 2008, ANN NY ACAD SCI, V1124, P77, DOI 10.1196/annals.1440.002
   Caduff D, 2008, COGN PROCESS, V9, P249, DOI 10.1007/s10339-007-0199-2
   Campbell MG, 2018, NAT NEUROSCI, V21, P1096, DOI 10.1038/s41593-018-0189-y
   CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2
   Chopra S, 2005, PROC CVPR IEEE, V0, PP539, DOI 10.1109/cvpr.2005.202
   Deshmukh SS, 2013, HIPPOCAMPUS, V23, P253, DOI 10.1002/hipo.22101
   Eichenbaum H, 2017, J NEUROPHYSIOL, V117, P1785, DOI 10.1152/jn.00005.2017
   Eichenbaum H, 2014, NEURON, V83, P764, DOI 10.1016/j.neuron.2014.07.032
   Ekstrom AD, 2018, HIPPOCAMPUS, V28, P680, DOI 10.1002/hipo.22750
   Eysenbach B, 2019, ADV NEUR IN, V32, P0
   Fang K, 2019, PROC CVPR IEEE, V0, PP538, DOI 10.1109/CVPR.2019.00063
   Foo P, 2005, J EXP PSYCHOL LEARN, V31, P195, DOI 10.1037/0278-7393.31.2.195
   Foo P, 2007, PSYCHOL RES-PSYCH FO, V71, P240, DOI 10.1007/s00426-006-0080-4
   Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901
   Gotze J, 2016, J LOCAT BASED SERV, V10, P47, DOI 10.1080/17489725.2016.1172739
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Graves A., 2014, ARXIV14105401, V0, P0
   Gupta S., 2017, CORR, V0, P0
   Gupta S, 2017, PROC CVPR IEEE, V0, PP7272, DOI 10.1109/CVPR.2017.769
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Janzen G, 2004, NAT NEUROSCI, V7, P673, DOI 10.1038/nn1257
   Kalra N, 2009, ROBOT AUTON SYST, V57, P123, DOI 10.1016/j.robot.2007.01.009
   Kempka M., 2016, 2016 IEEE C COMP INT, V0, PP1, DOI 10.1109/CIG.2016.7860433
   Klippel A, 2005, LECT NOTES COMPUT SC, V3693, P347
   Koltun V., 2018, P ICLR, V0, P0
   Lisman J, 2017, NAT NEUROSCI, V20, P1434, DOI 10.1038/nn.4661
   Merity Stephen, 2017, ICLR, V0, P0
   Mirowski P., 2016, CORR, V0, P0
   Oh J, 2016, PR MACH LEARN RES, V48, P0
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   Parisotto E., 2017, ARXIV170208360, V0, P0
   Seelig JD, 2015, NATURE, V521, P186, DOI 10.1038/nature14446
   SQUIRE LR, 2015, CSH PERSPECT BIOL, V7, P0, DOI 10.1101/CSHPERSPECT.A021766
   Subagdja B, 2015, NEUROCOMPUTING, V161, P229, DOI 10.1016/j.neucom.2015.02.038
   Sukhbaatar S, 2015, ADV NEUR IN, V28, P0
   Tan AH, 2007, LECT NOTES COMPUT SC, V4491, P1094
   Tan AH, 2019, NEURAL NETWORKS, V120, P58, DOI 10.1016/j.neunet.2019.08.020
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Venugopalan S., 2016, ARXIV160401729, V0, PP1961, DOI 10.18653/V1/D16-1204
   Wang WW, 2017, IEEE T SYST MAN CY-S, V47, P2882, DOI 10.1109/TSMC.2016.2531683
   Wang WW, 2012, IEEE T NEUR NET LEAR, V23, P1574, DOI 10.1109/TNNLS.2012.2208477
   Zhang J., 2017, ARXIV170609520, V0, P0
NR 44
TC 3
Z9 3
U1 1
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD DEC 15
PY 2022
VL 33
IS 12
BP 7101
EP 7113
DI 10.1109/TNNLS.2021.3084212
EA JUN 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 6S5MN
UT WOS:000732118600001
PM 34138715
DA 2023-04-26
ER

PT J
AU Pradhan, A
   Niaz, SY
   Pradhan, MP
   Pradhan, R
AF Pradhan, Ashis
   Niaz, Shaikh Yusuf
   Pradhan, Mohan P.
   Pradhan, Ratika
TI DETECTION AND RECOGNITION OF TEXTS FEATURES FROM A TOPOGRAPHIC MAP USING DEEP LEARNING
SO SURANAREE JOURNAL OF SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Digitization; topographic map; faster R-CNN; convolutional recurrent neural network; text detection and text recognition
AB The aim of this research is to digitize texts present on topographic maps. Digitization is critical for information processing, hence texts on topographic maps that are in pixel format are digitized. The above is achieved using deep learning technology. Detection and recognition deep learning models are leveraged for first detecting texts on topographic maps and then recognition the detected texts. Detection model is inspired by Faster Region Based Convolutional Neural Networks (Faster R-CNN) to achieve real time text detection using region proposal networks and recognition model is inspired by Convolutional Recurrent Neural Network (CRNN), which is an end to end trainable neural network to achieve image-based sequence recognition that is suitable for recognizing texts on character level. The models have been trained and validated on self-curated dataset of topographic maps. The digitized information may be very helpful for many GIS applications like automated construction of Digital Elevation Model, Digital Surface Model, etc.
C1 [Pradhan, Ashis] Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept CSE, Gangtok, Sikkim, India.
   [Niaz, Shaikh Yusuf; Pradhan, Ratika] Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept CSE, Gangtok, Sikkim, India.
   [Pradhan, Mohan P.] Sikkim Univ, Dept Comp Applicat, Gangtok, Sikkim, India.
C3 Sikkim Manipal Institute of Technology; Sikkim Manipal University; Sikkim Manipal Institute of Technology; Sikkim Manipal University; Sikkim University
RP Pradhan, A (corresponding author), Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept CSE, Gangtok, Sikkim, India.
EM ratika.p@smit.smu.edu.in
CR [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   [Anonymous], 2014, 2 INT C LEARN REPR, V0, P0
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bissacco A, 2013, IEEE I CONF COMP VIS, V0, PP785, DOI 10.1109/ICCV.2013.102
   Deng J., 2009, P IEEE C COMP VIS PA, V0, P248
   Fu B, 2019, MULTIMED TOOLS APPL, V78, P30707, DOI 10.1007/s11042-018-6521-4
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Girshick R., 2014, P IEEE C COMP VIS PA, V0, P580
   Girshick R., 2015, P IEEE ICCV SANT CHI, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Graves A., 2013, IEEE INT C ACOUSTICS, V0, P645
   Graves A., 2006, PROC ICML, V0, P369
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang J, 2017, PROC CVPR IEEE, V0, PP3296, DOI 10.1109/CVPR.2017.351
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Olson M, 2018, ADV NEUR IN, V31, P0
   Redmon J, 2017, P IEEE C COMPUTER VI, V0, P7263
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Szegedy C., 2016, INCEPTION V4 INCEPTI, V2, P0
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang T, 2012, INT C PATT RECOG, V0, P3304
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SURANAREE UNIV TECHNOLOGY
PI NAKHON RATCHASIMA
PA 111, THANON MAHA WITTHAYALAI, SURANARI, MUEANG NAKHON RATCHASIMA DIST, NAKHON RATCHASIMA, 30000, THAILAND
SN 0858-849X
EI 
J9 SURANAREE J SCI TECH
JI Suranaree J. Sci. Technol.
PD JUN 15
PY 2022
VL 29
IS 5
BP 
EP 
DI 
PG 7
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA 4V0CS
UT WOS:000859152500002
DA 2023-04-26
ER

PT J
AU Alghamdi, HA
AF Alghamdi, Hisham A.
TI A Time Series Forecasting of Global Horizontal Irradiance on Geographical Data of Najran Saudi Arabia
SO ENERGIES
LA English
DT Article
DE solar energy; machine learning; forecasting; GHI; GSR
ID support vector machine; solar-radiation prediction; artificial neural-networks; empirical equations; models; ann; regression; temperatures; selection; regions
AB Environment-friendly and renewable energy resources are the need of each developed and undeveloped country. Solar energy is one of them, thus accurate forecasting of it can be useful for electricity supply companies. This research focuses on analyzing the daily global solar radiation (GSR) data of Najran province located in Saudi Arabia and proposed a model for the prediction of global horizontal irradiance (GHI). The weather data is collected from Najran University. After inspecting the data, I we found the dependent and independent variables for calculating the GHI. A dataset model has been trained by creating tensor of variables belonging to air, wind, peak wind, relative humidity, and barometric pressure. Furthermore, six machine learning algorithms convolutional neural networks (CNN), K-nearest neighbors (KNN), support vector machines (SVM), logistic regression (LR), random forest classifier (RFC), and support vector classifier (SVC) techniques are used on dataset model to predict the GHI. The evaluation metrics determination coefficients (R-2), root mean square error (RMSE), relative root mean square error (rRMSE), mean bias error (MBE), mean absolute bias error (MABE), mean absolute percentage error (MAPE), and T-statistic (t-stat) are used for the result verification of proposed models. Finally, the current work reports that all methods examined in this work may be utilized to accurately predict GHI; however, the SVC technique is the most suitable method amongst all techniques by claiming the precise results using the evaluation metrics.
C1 [Alghamdi, Hisham A.] Najran Univ, Elect Engn Dept, Coll Engn, Najran 55461, Saudi Arabia.
C3 Najran University
RP Alghamdi, HA (corresponding author), Najran Univ, Elect Engn Dept, Coll Engn, Najran 55461, Saudi Arabia.
EM hg@nu.edu.sa
FU Deanship of Scientific Research at Najran University [NU/-/SERC/10/655]
CR Agbulut U, 2021, RENEW SUST ENERG REV, V135, P0, DOI 10.1016/j.rser.2020.110114
   Antonopoulos VZ, 2019, COMPUT ELECTRON AGR, V160, P160, DOI 10.1016/j.compag.2019.03.022
   Azlah MAF, 2019, COMPUTERS, V8, P0, DOI 10.3390/computers8040077
   Bakirci K, 2009, ENERGY, V34, P485, DOI 10.1016/j.energy.2009.02.005
   Baser F, 2017, ENERGY, V123, P229, DOI 10.1016/j.energy.2017.02.008
   Behrang MA, 2010, SOL ENERGY, V84, P1468, DOI 10.1016/j.solener.2010.05.009
   Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898
   Birzhandi P, 2019, APPL ARTIF INTELL, V33, P497, DOI 10.1080/08839514.2019.1583449
   Ceylan I, 2017, INT J HYDROGEN ENERG, V42, P19641, DOI 10.1016/j.ijhydene.2017.06.004
   Chen HL, 2013, EXPERT SYST APPL, V40, P263, DOI 10.1016/j.eswa.2012.07.014
   Chen JL, 2013, ENERG CONVERS MANAGE, V75, P311, DOI 10.1016/j.enconman.2013.06.034
   Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI 10.1561/0600000035
   Deo RC, 2016, APPL ENERG, V168, P568, DOI 10.1016/j.apenergy.2016.01.130
   Dong N, 2020, INT J ELEC POWER, V114, P0, DOI 10.1016/j.ijepes.2019.105411
   Fan JL, 2019, RENEW SUST ENERG REV, V105, P168, DOI 10.1016/j.rser.2019.01.040
   Fan JL, 2018, ENERG CONVERS MANAGE, V156, P618, DOI 10.1016/j.enconman.2017.11.085
   Feng Y, 2019, ENERG CONVERS MANAGE, V198, P0, DOI 10.1016/j.enconman.2019.111780
   Gouda SG, 2019, J CLEAN PROD, V221, P132, DOI 10.1016/j.jclepro.2019.02.211
   Gurel AE, 2020, J CLEAN PROD, V277, P0, DOI 10.1016/j.jclepro.2020.122353
   Hu LY, 2016, SPRINGERPLUS, V5, P0, DOI 10.1186/s40064-016-2941-7
   Hua Y., 2015, DEEP BELIEF NETWORKS, V0, P1
   Huang C, 2020, IET RENEW POWER GEN, V14, P1020, DOI 10.1049/iet-rpg.2019.0769
   Jagadeesh V, 2020, J STAT MANAG SYST, V23, P1, DOI 10.1080/09720510.2020.1714146
   Jahani B, 2019, THEOR APPL CLIMATOL, V137, P1257, DOI 10.1007/s00704-018-2666-3
   Jiang YN, 2008, ENERG POLICY, V36, P3833, DOI 10.1016/j.enpol.2008.06.030
   Khanlari A, 2020, J CLEAN PROD, V251, P0, DOI 10.1016/j.jclepro.2019.119672
   Khanlari A, 2020, SCI TOTAL ENVIRON, V709, P0, DOI 10.1016/j.scitotenv.2019.136198
   Kim S, 2018, APPL INTELL, V48, P791, DOI 10.1007/s10489-017-1011-3
   Kisi O, 2016, J HYDROL, V534, P104, DOI 10.1016/j.jhydrol.2015.12.014
   Knowles R. L, 2006, RITUAL HOUSE DRAWING, V0, P0
   Lau KW, 2003, PATTERN RECOGN, V36, P1913, DOI 10.1016/S0031-3203(03)00038-4
   Lin YZ, 2017, COMPUT-AIDED CIV INF, V32, P1025, DOI 10.1111/mice.12313
   Liu J., 2019, SOLAR RAD PREDICTION, V0, P0
   Long H, 2014, APPL ENERG, V126, P29, DOI 10.1016/j.apenergy.2014.03.084
   Lou SW, 2016, APPL ENERG, V181, P367, DOI 10.1016/j.apenergy.2016.08.093
   Mabel MC, 2008, RENEW ENERG, V33, P986, DOI 10.1016/j.renene.2007.06.013
   Maillo J., 2017, EXACT FUZZY K NEARES, V0, P1
   Malik H, 2019, ADV INTELL SYST COMP, V697, P285, DOI 10.1007/978-981-13-1822-1_26
   Marzo A, 2017, RENEW ENERG, V113, P303, DOI 10.1016/j.renene.2017.01.061
   Marzouq M, 2019, J CLEAN PROD, V209, P1105, DOI 10.1016/j.jclepro.2018.10.254
   Meenal R, 2018, RENEW ENERG, V121, P324, DOI 10.1016/j.renene.2017.12.005
   Mehdizadeh S, 2016, J ATMOS SOL-TERR PHY, V146, P215, DOI 10.1016/j.jastp.2016.06.006
   Methaprayoon K, 2007, IEEE T IND APPL, V43, P1441, DOI 10.1109/TIA.2007.908203
   Mohammadi K, 2015, ENERG CONVERS MANAGE, V92, P162, DOI 10.1016/j.enconman.2014.12.050
   Mohammadi K, 2015, ENERG CONVERS MANAGE, V91, P433, DOI 10.1016/j.enconman.2014.12.015
   Moreno A, 2011, SOL ENERGY, V85, P2072, DOI 10.1016/j.solener.2011.05.017
   Myhre JN, 2018, PATTERN RECOGN, V76, P491, DOI 10.1016/j.patcog.2017.11.023
   Najafabadi M.M., 2015, J BIG DATA-GER, V2, P21, DOI 10.1186/S40537-014-0007-7
   Onel M, 2018, COMPUT CHEM ENG, V115, P46, DOI 10.1016/j.compchemeng.2018.03.025
   Palani S, 2008, MAR POLLUT BULL, V56, P1586, DOI 10.1016/j.marpolbul.2008.05.021
   Park H, 2014, EXPERT SYST APPL, V41, P5227, DOI 10.1016/j.eswa.2014.01.032
   Quej VH, 2017, J ATMOS SOL-TERR PHY, V155, P62, DOI 10.1016/j.jastp.2017.02.002
   Ramil A, 2018, MEASUREMENT, V117, P90, DOI 10.1016/j.measurement.2017.12.006
   Rehman S, 1998, ENERGY, V23, P1077, DOI 10.1016/S0360-5442(98)00057-7
   Rodrigues EO, 2018, PATTERN RECOGN LETT, V110, P66, DOI 10.1016/j.patrec.2018.03.021
   Saikia J, 2019, I SYMPOS LOW POWER E, V0, P0
   Samadianfard S, 2019, ENG APPL COMP FLUID, V13, P142, DOI 10.1080/19942060.2018.1560364
   Shamshirband S, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4970-x
   Shamshirband S, 2015, J ATMOS SOL-TERR PHY, V134, P109, DOI 10.1016/j.jastp.2015.09.014
   Tymvios FS, 2005, SOL ENERGY, V78, P752, DOI 10.1016/j.solener.2004.09.007
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang LC, 2016, RENEW SUST ENERG REV, V61, P384, DOI 10.1016/j.rser.2016.04.024
   Yang L, 2020, ENERGY, V191, P0, DOI 10.1016/j.energy.2019.116571
   Yildirim HB, 2018, RENEW SUST ENERG REV, V82, P1528, DOI 10.1016/j.rser.2017.06.030
   Yoon M, 2003, IEEE IJCNN, V0, P2049
   Zang HX, 2020, ENERGY, V191, P0, DOI 10.1016/j.energy.2019.116502
   Zendehboudi A, 2018, J CLEAN PROD, V199, P272, DOI 10.1016/j.jclepro.2018.07.164
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
NR 70
TC 3
Z9 3
U1 0
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1996-1073
J9 ENERGIES
JI Energies
PD FEB 15
PY 2022
VL 15
IS 3
BP 
EP 
DI 10.3390/en15030928
PG 19
WC Energy & Fuels
SC Energy & Fuels
GA YY6NC
UT WOS:000754904000001
DA 2023-04-26
ER

PT J
AU Zhang, L
   Cai, YY
   Huang, HL
   Li, AQ
   Yang, L
   Zhou, CH
AF Zhang, Lei
   Cai, Yanyan
   Huang, Haili
   Li, Anqi
   Yang, Lin
   Zhou, Chenghu
TI A CNN-LSTM Model for Soil Organic Carbon Content Prediction with Long Time Series of MODIS-Based Phenological Variables
SO REMOTE SENSING
LA English
DT Article
DE soil organic carbon; land surface phenology; deep learning; predictive mapping; convolutional neural network (CNN); long short-term memory (LSTM)
ID land-surface phenology; convolutional neural-networks; vegetation phenology; cover dynamics; regression; variability; system
AB The spatial distribution of soil organic carbon (SOC) serves as critical geographic information for assessing ecosystem services, climate change mitigation, and optimal agriculture management. Digital mapping of SOC is challenging due to the complex relationships between the soil and its environment. Except for the well-known terrain and climate environmental covariates, vegetation that interacts with soils influences SOC significantly over long periods. Although several remote-sensing-based vegetation indices have been widely adopted in digital soil mapping, variables indicating long term vegetation growth have been less used. Vegetation phenology, an indicator of vegetation growth characteristics, can be used as a potential time series environmental covariate for SOC prediction. A CNN-LSTM model was developed for SOC prediction with inputs of static and dynamic environmental variables in Xuancheng City, China. The spatially contextual features in static variables (e.g., topographic variables) were extracted by the convolutional neural network (CNN), while the temporal features in dynamic variables (e.g., vegetation phenology over a long period of time) were extracted by a long short-term memory (LSTM) network. The ten-year phenological variables derived from moderate-resolution imaging spectroradiometer (MODIS) observations were adopted as predictors with historical temporal changes in vegetation in addition to the commonly used static variables. The random forest (RF) model was used as a reference model for comparison. Our results indicate that adding phenological variables can produce a more accurate map, as tested by the five-fold cross-validation, and demonstrate that CNN-LSTM is a potentially effective model for predicting SOC at a regional spatial scale with long-term historical vegetation phenology information as an extra input. We highlight the great potential of hybrid deep learning models, which can simultaneously extract spatial and temporal features from different types of environmental variables, for future applications in digital soil mapping.
C1 [Zhang, Lei; Cai, Yanyan; Huang, Haili; Li, Anqi; Yang, Lin; Zhou, Chenghu] Nanjing Univ, Sch Geog & Ocean Sci, Nanjing 210023, Peoples R China.
   [Zhou, Chenghu] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.
C3 Nanjing University; Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS
RP Yang, L (corresponding author), Nanjing Univ, Sch Geog & Ocean Sci, Nanjing 210023, Peoples R China.
EM yanglin@nju.edu.cn
FU National Natural Science Foundation of China [41971054]; Leading Funds for First-Class Universities [020914912203, 020914902302]; Postgraduate Research and Practice Innovation Program of Jiangsu Province [KYCX22_0109]
CR Amatulli G, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-0479-6
   Amundson R, 2015, SCIENCE, V348, P0, DOI 10.1126/science.1261071
   Batjes NH, 1996, EUR J SOIL SCI, V47, P151, DOI 10.1111/ejss.12114_2
   Behrens T, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-33516-6
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brungard CW, 2015, GEODERMA, V239, P68, DOI 10.1016/j.geoderma.2014.09.019
   Caparros-Santiago JA, 2021, ISPRS J PHOTOGRAMM, V171, P330, DOI 10.1016/j.isprsjprs.2020.11.019
   Fang K, 2017, GEOPHYS RES LETT, V44, P11030, DOI 10.1002/2017GL075619
   Fick SE, 2017, INT J CLIMATOL, V37, P4302, DOI 10.1002/joc.5086
   Ganguly S, 2010, REMOTE SENS ENVIRON, V114, P1805, DOI 10.1016/j.rse.2010.04.005
   Goydaragh MG, 2021, CATENA, V202, P0, DOI 10.1016/j.catena.2021.105280
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   He XL, 2021, CATENA, V205, P0, DOI 10.1016/j.catena.2021.105442
   Hengl T, 2004, GEODERMA, V120, P75, DOI 10.1016/j.geoderma.2003.08.018
   Hengl T, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0169748
   Heung B, 2016, GEODERMA, V265, P62, DOI 10.1016/j.geoderma.2015.11.014
   Heuvelink GBM, 2021, EUR J SOIL SCI, V72, P1607, DOI 10.1111/ejss.12998
   Hong SB, 2020, NAT SUSTAIN, V3, P694, DOI 10.1038/s41893-020-0557-y
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2
   Huete AR, 1997, REMOTE SENS ENVIRON, V59, P440, DOI 10.1016/S0034-4257(96)00112-5
   James T, 2021, INT J REMOTE SENS, V42, P5342, DOI 10.1080/01431161.2021.1913298
   Kariyeva J, 2011, REMOTE SENS-BASEL, V3, P203, DOI 10.3390/rs3020203
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lal R, 2004, GEODERMA, V123, P1, DOI 10.1016/j.geoderma.2004.01.032
   Lange M, 2015, NAT COMMUN, V6, P0, DOI 10.1038/ncomms7707
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee WY, 2018, OPTIK, V172, P359, DOI 10.1016/j.ijleo.2018.07.044
   Li QL, 2022, GEODERMA, V409, P0, DOI 10.1016/j.geoderma.2021.115651
   Li XY, 2020, COMPUT GEOSCI-UK, V135, P0, DOI 10.1016/j.cageo.2019.104392
   Maynard JJ, 2017, GEODERMA, V285, P94, DOI 10.1016/j.geoderma.2016.09.024
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   Melillo JM, 2017, SCIENCE, V358, P101, DOI 10.1126/science.aan2874
   Minasny B, 2022, GEODERMA, V424, P0, DOI 10.1016/j.geoderma.2022.115975
   Minasny B, 2016, GEODERMA, V264, P301, DOI 10.1016/j.geoderma.2015.07.017
   Minasny B, 2017, GEODERMA, V292, P59, DOI 10.1016/j.geoderma.2017.01.002
   Moon M, 2019, REMOTE SENS ENVIRON, V226, P74, DOI 10.1016/j.rse.2019.03.034
   Nelson D.W., 1996, CHEM METHODS, V5, P961
   Padarian J, 2019, SOIL-GERMANY, V5, P79, DOI 10.5194/soil-5-79-2019
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Piao SL, 2008, NATURE, V451, P49, DOI 10.1038/nature06444
   Piao SL, 2019, GLOBAL CHANGE BIOL, V25, P1922, DOI 10.1111/gcb.14619
   Poggio L, 2021, SOIL-GERMANY, V7, P217, DOI 10.5194/soil-7-217-2021
   POST WM, 1982, NATURE, V298, P156, DOI 10.1038/298156a0
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Richardson AD, 2010, PHILOS T R SOC B, V365, P3227, DOI 10.1098/rstb.2010.0102
   Sanchez PA, 2009, SCIENCE, V325, P680, DOI 10.1126/science.1175084
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Schillaci C, 2017, GEODERMA, V286, P35, DOI 10.1016/j.geoderma.2016.10.019
   Singh S, 2022, CHEMOSPHERE, V287, P0, DOI 10.1016/j.chemosphere.2021.131889
   Singh S, 2019, GEODERMA REG, V18, P0, DOI 10.1016/j.geodrs.2019.e00233
   van der Putten WH, 2013, J ECOL, V101, P265, DOI 10.1111/1365-2745.12054
   Van Houdt G, 2020, ARTIF INTELL REV, V53, P5929, DOI 10.1007/s10462-020-09838-1
   Wadoux AMJC, 2019, GEODERMA, V351, P59, DOI 10.1016/j.geoderma.2019.05.012
   Wang MY, 2017, ARCH AGRON SOIL SCI, V63, P375, DOI 10.1080/03650340.2016.1213812
   Were K, 2015, ECOL INDIC, V52, P394, DOI 10.1016/j.ecolind.2014.12.028
   White MA, 1999, INT J BIOMETEOROL, V42, P139, DOI 10.1007/s004840050097
   Wilson BR, 2013, SOIL RES, V51, P668, DOI 10.1071/SR12376
   Yang L, 2021, INT J APPL EARTH OBS, V102, P0, DOI 10.1016/j.jag.2021.102428
   Yang L, 2021, J CLEAN PROD, V280, P0, DOI 10.1016/j.jclepro.2020.124330
   Yang L, 2021, INT J GEOGR INF SCI, V35, P250, DOI 10.1080/13658816.2020.1806284
   Yang L, 2020, SOIL TILL RES, V196, P0, DOI 10.1016/j.still.2019.104465
   Yang L, 2019, GEODERMA, V340, P289, DOI 10.1016/j.geoderma.2019.01.015
   Yang L, 2017, PEDOSPHERE, V27, P344, DOI 10.1016/S1002-0160(17)60322-9
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zeng CY, 2016, GEODERMA, V281, P69, DOI 10.1016/j.geoderma.2016.06.033
   Zhang L, 2022, GEODERMA, V406, P0, DOI 10.1016/j.geoderma.2021.115531
   Zhang L, 2021, COMPUT GEOSCI-UK, V155, P0, DOI 10.1016/j.cageo.2021.104869
   Zhang L, 2021, GEODERMA, V384, P0, DOI 10.1016/j.geoderma.2020.114809
   Zhang XY, 2018, AGR FOREST METEOROL, V256, P137, DOI 10.1016/j.agrformet.2018.03.003
   Zhang XY, 2003, REMOTE SENS ENVIRON, V84, P471, DOI 10.1016/S0034-4257(02)00135-9
   Zhao YC, 2018, P NATL ACAD SCI USA, V115, P4045, DOI 10.1073/pnas.1700292114
NR 73
TC 4
Z9 4
U1 53
U2 63
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2022
VL 14
IS 18
BP 
EP 
DI 10.3390/rs14184441
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA 4R4UH
UT WOS:000856760700001
DA 2023-04-26
ER

PT J
AU Gruszczynski, W
   Puniach, E
   Cwiakala, P
   Matwij, W
AF Gruszczynski, Wojciech
   Puniach, Edyta
   Cwiakala, Pawel
   Matwij, Wojciech
TI Correction of Low Vegetation Impact on UAV-Derived Point Cloud Heights With U-Net Networks
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Three-dimensional displays; Vegetation mapping; Training; Task analysis; Earth; Unmanned aerial vehicles; Surface treatment; Digital elevation model (DEM); ground filter; deep learning; U-Net; unmanned aerial vehicle (UAV)
ID structure-from-motion; photogrammetry; imagery; lidar; accuracy; filter
AB This study presents an approach to the problem of minimizing the impact of low vegetation on the accuracy of a UAV-derived DEM, based on the use of a deep neural network (DNN). It is proposed to use the U-Net network to determine corrections to the height of the raw point cloud so that the processed data reflect the actual earthx2019;s surface. The implemented solution is therefore based on regression, not classification. As a result of the proposed processing method, the expected value of the land surface height is determined for each point of the unified point cloud. In addition, a second U-Net network is trained, enabling the uncertainty of the corrected heights of the land surface to be determined for each point of the unified cloud. The training set includes data from different seasons, which makes the models more resistant and allows for assessment of the impact of the season and more generally the related vegetation status on the model accuracy. The processing results can be used in DEM generation, and also for determining the vertical displacements of the terrain surface associated with underground mining, as well as natural phenomena such as landslides. A key advantage of the proposed processing method is the ability to predict the uncertainty of the results.
C1 [Gruszczynski, Wojciech; Puniach, Edyta; Cwiakala, Pawel; Matwij, Wojciech] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Science & Technology
RP Gruszczynski, W (corresponding author), AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
EM wgrusz@agh.edu.pl
FU AGH University of Science and Technology [16.16.150.545]; PL-Grid Infrastructure
CR Aguilar FJ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19081934
   Al-Najjar HAH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121461
   Anders N, 2019, DRONES-BASEL, V3, P0, DOI 10.3390/drones3030061
   [Anonymous], 2006, MACH LEARN, V0, P0
   Ciresan D, 2012, PROC CVPR IEEE, V0, PP3642, DOI 10.1109/CVPR.2012.6248110
   Cook KL, 2017, GEOMORPHOLOGY, V278, P195, DOI 10.1016/j.geomorph.2016.11.009
   Cwiakala P, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9173488
   Cwiakala P, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010081
   Diao XP, 2019, IEEE ACCESS, V7, P172296, DOI 10.1109/ACCESS.2019.2956094
   Diao XP, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0210021
   Villanueva JRE, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19143205
   Fawcett D, 2019, INT J REMOTE SENS, V40, P7538, DOI 10.1080/01431161.2019.1591651
   Gagliolo S., 2018, ISPRS INT ARCH PHOTO, V42, P347, DOI 10.5194/isprs-archives-XLII-2-347-2018
   Gevaert CM, 2018, ISPRS J PHOTOGRAMM, V142, P106, DOI 10.1016/j.isprsjprs.2018.06.001
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gruszczyniski W, 2019, ISPRS J PHOTOGRAMM, V158, P1, DOI 10.1016/j.isprsjprs.2019.09.014
   Gruszczynski W, 2017, ISPRS J PHOTOGRAMM, V126, P168, DOI 10.1016/j.isprsjprs.2017.02.015
   Hinton G.E., 1988, NEURAL NETWORK ARCHI, V0, P0
   Hu XY, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8090730
   Iglhaut J, 2019, CURR FOR REP, V5, P155, DOI 10.1007/s40725-019-00094-3
   Janssens-Coron E., 2019, INT ARCH PHOTOGRAMM, V42, P1559, DOI 10.5194/isprs-archives-XLII-2-W13-1559-2019
   Johansen K, 2010, REMOTE SENS ENVIRON, V114, P2679, DOI 10.1016/j.rse.2010.06.004
   Kattenborn T, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-53797-9
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Krsak B, 2016, MEASUREMENT, V91, P276, DOI 10.1016/j.measurement.2016.05.028
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee G, 2019, QUATERN INT, V519, P255, DOI 10.1016/j.quaint.2019.04.005
   Liu KQ, 2019, IEEE ACCESS, V7, P23270, DOI 10.1109/ACCESS.2019.2899674
   Liu T, 2018, ISPRS J PHOTOGRAMM, V139, P154, DOI 10.1016/j.isprsjprs.2018.03.006
   Liu Y, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18103232
   Liu ZQ, 2019, AUTOMAT CONSTR, V104, P129, DOI 10.1016/j.autcon.2019.04.005
   Liu ZY, 2019, IOP C SER EARTH ENV, V330, P0, DOI 10.1088/1755-1315/330/5/052050
   Torres DL, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20020563
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Maciuk K, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232754
   Maciuk K, 2019, ARAB J GEOSCI, V12, P0, DOI 10.1007/s12517-018-4069-2
   Mboga N, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111106
   Moudry V, 2020, MEASUREMENT, V150, P0, DOI 10.1016/j.measurement.2019.107047
   Polat N, 2018, J INDIAN SOC REMOTE, V46, P1135, DOI 10.1007/s12524-018-0760-8
   Remondino F, 2017, INT ARCH PHOTOGRAMM, V42-2, P591, DOI 10.5194/isprs-archives-XLII-2-W5-591-2017
   Ren H, 2019, INT J COAL SCI TECHN, V6, P320, DOI 10.1007/s40789-019-00264-5
   Rizaldi A., 2018, ISPRS ANN PHOTOGRAMM, V4, P231, DOI 10.5194/ISPRS-ANNALS-IV-2-231-2018
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusek J, 2017, EKSPLOAT NIEZAWODN, V19, P54, DOI 10.17531/ein.2017.1.8
   Rusnak M, 2018, MEASUREMENT, V115, P139, DOI 10.1016/j.measurement.2017.10.023
   Saeidi A, 2013, GEOTECH GEOL ENG, V31, P1073, DOI 10.1007/s10706-013-9633-7
   Satchwell C., 1994, NEUR COMP APPL FOR C, V0, P0
   Soilan M, 2020, INT J DIGIT EARTH, V13, P1115, DOI 10.1080/17538947.2019.1663948
   Sun GY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030227
   Tan YM, 2018, ISPRS J PHOTOGRAMM, V146, P421, DOI 10.1016/j.isprsjprs.2018.10.013
   Ural S, 2016, INT ARCH PHOTOGRAMM, V41, P395, DOI 10.5194/isprsarchives-XLI-B3-395-2016
   Wallace L, 2019, FORESTS, V10, P0, DOI 10.3390/f10030284
   Yao H, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121443
   Yao W, 2018, NEUROCOMPUTING, V312, P364, DOI 10.1016/j.neucom.2018.05.103
   Yilmaz CS, 2018, INT J REMOTE SENS, V39, P5016, DOI 10.1080/01431161.2017.1420942
   Yilmaz CS, 2018, GEOCARTO INT, V33, P522, DOI 10.1080/10106049.2016.1265599
   Yilmaz V, 2018, GEOCARTO INT, V33, P310, DOI 10.1080/10106049.2016.1250825
   Zeybek M, 2019, MEASUREMENT, V133, P99, DOI 10.1016/j.measurement.2018.10.013
   Zhang Z., 2018, ISPRS ANN PHOTOGRAMM, VIV-2, P319, DOI 10.5194/isprs-annals-IV-2-319-2018
   Zhou YL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010022
   Zhou YL, 2020, ISPRS J PHOTOGRAMM, V160, P51, DOI 10.1016/j.isprsjprs.2019.11.020
NR 62
TC 2
Z9 2
U1 8
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JUN 15
PY 2022
VL 60
IS 
BP 
EP 
DI 10.1109/TGRS.2021.3057272
PG 18
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology
GA XL6PS
UT WOS:000728266600020
DA 2023-04-26
ER
