
PT J
AU Baig, MF
   Mustafa, MRU
   Baig, I
   Takaijudin, HB
   Zeshan, MT
AF Baig, Mohammed Feras
   Mustafa, Muhammad Raza Ul
   Baig, Imran
   Takaijudin, Husna Binti
   Zeshan, Muhammad Talha
TI Assessment of Land Use Land Cover Changes and Future Predictions Using CA-ANN Simulation for Selangor, Malaysia
SO WATER
LA English
DT Article
DE land use land cover (LULC); support vector machine (SVM); cellular automata-artificial neural network (CA-ANN); change detection; sustainable development
ID groundwater quality; urban sprawl; gis; impacts; dynamics; area; city; classification; district; models
AB Land use land cover (LULC) has altered dramatically because of anthropogenic activities, particularly in places where climate change and population growth are severe. The geographic information system (GIS) and remote sensing are widely used techniques for monitoring LULC changes. This study aimed to assess the LULC changes and predict future trends in Selangor, Malaysia. The satellite images from 1991-2021 were classified to develop LULC maps using support vector machine (SVM) classification in ArcGIS. The image classification was based on six different LULC classes, i.e., (i) water, (ii) developed, (iii) barren, (iv) forest, (v) agriculture, and (vi) wetlands. The resulting LULC maps illustrated the area changes from 1991 to 2021 in different classes, where developed, barren, and water lands increased by 15.54%, 1.95%, and 0.53%, respectively. However, agricultural, forest, and wetlands decreased by 3.07%, 14.01%, and 0.94%, respectively. The cellular automata-artificial neural network (CA-ANN) technique was used to predict the LULC changes from 2031-2051. The percentage of correctness for the simulation was 82.43%, and overall kappa value was 0.72. The prediction maps from 2031-2051 illustrated decreasing trends in (i) agricultural by 3.73%, (ii) forest by 1.09%, (iii) barren by 0.21%, (iv) wetlands by 0.06%, and (v) water by 0.04% and increasing trends in (vi) developed by 5.12%. The outcomes of this study provide crucial knowledge that may help in developing future sustainable planning and management, as well as assist authorities in making informed decisions to improve environmental and ecological conditions.
C1 [Baig, Mohammed Feras; Mustafa, Muhammad Raza Ul; Takaijudin, Husna Binti; Zeshan, Muhammad Talha] Univ Teknol Petronas, Dept Civil & Environm Engn, Seri Iskandar 32610, Perak, Malaysia.
   [Mustafa, Muhammad Raza Ul; Takaijudin, Husna Binti] Univ Teknol Petronas, Inst Self Sustainable Bldg, Ctr Urban Resource Sustainabil, Seri Iskandar 32610, Perak, Malaysia.
   [Baig, Imran] Dhofar Univ, Dept Elect & Comp Engn, Coll Engn, Salalah 211, Oman.
C3 Universiti Teknologi Petronas; Universiti Teknologi Petronas; Dhofar University
RP Baig, MF; Mustafa, MRU (corresponding author), Univ Teknol Petronas, Dept Civil & Environm Engn, Seri Iskandar 32610, Perak, Malaysia.; Mustafa, MRU (corresponding author), Univ Teknol Petronas, Inst Self Sustainable Bldg, Ctr Urban Resource Sustainabil, Seri Iskandar 32610, Perak, Malaysia.
EM Feras_19001701@utp.edu.my; raza.mustafa@utp.edu.my; ibaig@du.edu.om; husna_takaijudin@utp.edu.my; talhaansari510@gmail.com
FU YUTP research project (cost center) [015LC0-190];  [015LCO-190]
CR Abbas Z, 2021, LAND-BASEL, V10, P0, DOI 10.3390/land10060584
   Abdullah J, 2012, PROCD SOC BEHV, V50, P20, DOI 10.1016/j.sbspro.2012.08.012
   Abdullah SA, 2007, FOREST ECOL MANAG, V241, P39, DOI 10.1016/j.foreco.2006.12.016
   Akinyemi FO, 2017, APPL GEOGR, V87, P127, DOI 10.1016/j.apgeog.2017.07.016
   Al-Najjar HAH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121461
   Alexakis DD, 2014, NAT HAZARDS, V72, P119, DOI 10.1007/s11069-013-0770-3
   Ayub Mohammadi, 2019, ENVIRONMENT ASIA, V12, P145
   Carranza-Garcia M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030274
   CIVCO DL, 1993, INT J GEOGR INF SYST, V7, P173, DOI 10.1080/02693799308901949
   Congalton R.G., 2009, ASSESS ACCUR REMOTE, V0, P55
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   El Gammal EA, 2010, EGYPT J REMOTE SENS, V13, P89, DOI 10.1016/j.ejrs.2010.08.001
   El-Tantawi AM, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7478-0
   Gao J, 2010, INT J APPL EARTH OBS, V12, P9, DOI 10.1016/j.jag.2009.08.003
   Guerra F, 1998, INT J REMOTE SENS, V19, P2061, DOI 10.1080/014311698214866
   Hadi Memarian, 2012, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V4, P542, DOI 10.4236/jgis.2012.46059
   Hassan A.A.G., 2018, DEVELOPMENT, V15, P2
   Hathout S, 2002, J ENVIRON MANAGE, V66, P229, DOI 10.1006/jema.2002.0596
   Hazarika N, 2015, EGYPT J REMOTE SENS, V18, P107, DOI 10.1016/j.ejrs.2015.02.001
   He S, 2019, EXPOS HEALTH, V11, P125, DOI 10.1007/s12403-018-0289-7
   Helmer EH, 2000, INT J REMOTE SENS, V21, P2163, DOI 10.1080/01431160050029495
   HOUGHTON RA, 1994, BIOSCIENCE, V44, P305, DOI 10.2307/1312380
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Hyandye C., 2015, AM J REMOTE SENS, V3, P6, DOI 10.11648/j.ajrs.20150301.12
   Iqbal MF, 2014, EGYPT J REMOTE SENS, V17, P209, DOI 10.1016/j.ejrs.2014.09.004
   Jat MK, 2008, INT J APPL EARTH OBS, V10, P26, DOI 10.1016/j.jag.2007.04.002
   Jiang XD, 2018, APPL GEOGR, V97, P35, DOI 10.1016/j.apgeog.2018.05.019
   Khan R, 2018, J GEOL SOC INDIA, V92, P59, DOI 10.1007/s12594-018-0953-3
   Laliberte AS, 2004, REMOTE SENS ENVIRON, V93, P198, DOI 10.1016/j.rse.2004.07.011
   Lamchin M, 2018, SCI TOTAL ENVIRON, V618, P1089, DOI 10.1016/j.scitotenv.2017.09.145
   Li F, 2018, ECOSYST SERV, V31, P12, DOI 10.1016/j.ecoser.2018.03.009
   Li PY, 2017, ENVIRON SCI POLLUT R, V24, P13224, DOI 10.1007/s11356-017-8753-7
   Li XM, 2016, DISCRETE DYN NAT SOC, V2016, P0, DOI 10.1155/2016/8061069
   Lipczynska-Kochany E, 2018, SCI TOTAL ENVIRON, V640, P1548, DOI 10.1016/j.scitotenv.2018.05.376
   Lopez E, 2001, LANDSCAPE URBAN PLAN, V55, P271, DOI 10.1016/S0169-2046(01)00160-8
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Mohamed MA., 2017, NAT RESOUR, V8, P353, DOI 10.4236/nr.2017.85022
   Mohammad Imam H. R., 2016, BULLETIN OF SCIENCE, V0, P0
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Nedd R, 2021, LAND-BASEL, V10, P0, DOI 10.3390/land10090994
   Olaniyi A. O., 2013, BULGARIAN JOURNAL OF AGRICULTURAL SCIENCE, V19, P60
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Pocewicz A, 2008, LANDSCAPE ECOL, V23, P195, DOI 10.1007/s10980-007-9159-6
   Rahman MTU, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-6272-0
   Rekha PN, 2017, CURR SCI INDIA, V113, P1763, DOI 10.18520/cs/v113/i09/1763-1770
   Richards J.A., 2006, REMOTE SENSING DIGIT, V0, PP295, DOI 10.1007/3-540-29711-1_11
   Roy A, 2019, HELIYON, V5, P0, DOI 10.1016/j.heliyon.2019.e01478
   Sadeghi A, 2021, APPL WATER SCI, V11, P0, DOI 10.1007/s13201-021-01508-z
   Serneels S, 2001, AGR ECOSYST ENVIRON, V85, P65, DOI 10.1016/S0167-8809(01)00188-8
   Seto KC, 2012, P NATL ACAD SCI USA, V109, P16083, DOI 10.1073/pnas.1211658109
   Seto KC, 2005, INT J REMOTE SENS, V26, P563, DOI 10.1080/01431160512331299270
   Seto KC, 2003, LAND ECON, V79, P106, DOI 10.2307/3147108
   Shamsi S.F., 2010, J APPL SCI ENVIRON M, V14, P2
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh Y, 2013, INT J REMOTE SENS, V34, P4967, DOI 10.1080/01431161.2013.786194
   Srivastava PK, 2012, ADV SPACE RES, V50, P1250, DOI 10.1016/j.asr.2012.06.032
   Talukdar S, 2020, ECOL INDIC, V112, P0, DOI 10.1016/j.ecolind.2020.106121
   THEOBALD DM, 1998, GEOGRAPHICAL ENV MOD, V2, P65
   Tian GJ, 2016, ADV METEOROL, V2016, P0, DOI 10.1155/2016/3109396
   Vapnik V, 1998, STAT LEARNING THEORY, V1, P2
   Vibhute AD, 2013, INT J ENG RES APPL, V3, P081
   Wu Q, 2006, LANDSCAPE URBAN PLAN, V78, P322, DOI 10.1016/j.landurbplan.2005.10.002
   Wu R, 2021, SCI TOTAL ENVIRON, V766, P0, DOI 10.1016/j.scitotenv.2020.142591
   Yatoo SA, 2022, GEOJOURNAL, V87, P765, DOI 10.1007/s10708-020-10274-5
   Yin J, 2011, ENVIRON MONIT ASSESS, V177, P609, DOI 10.1007/s10661-010-1660-8
   Yiridomoh GY, 2021, GEOJOURNAL, V86, P2367, DOI 10.1007/s10708-020-10191-7
   Zeshan MT, 2021, WATER-SUI, V13, P0, DOI 10.3390/w13162286
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
NR 69
TC 32
Z9 31
U1 23
U2 46
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2073-4441
J9 WATER-SUI
JI Water
PD FEB 15
PY 2022
VL 14
IS 3
BP 
EP 
DI 10.3390/w14030402
PG 17
WC Environmental Sciences; Water Resources
SC Environmental Sciences & Ecology; Water Resources
GA ZA3XD
UT WOS:000756099700001
DA 2023-04-26
ER

PT J
AU Filipova, V
   Hammond, A
   Leedal, D
   Lamb, R
AF Filipova, Valeriya
   Hammond, Anthony
   Leedal, David
   Lamb, Rob
TI Prediction of flood quantiles at ungauged catchments for the contiguous USA using Artificial Neural Networks
SO HYDROLOGY RESEARCH
LA English
DT Article
DE ANN models; flood frequency analysis; machine learning; ungauged basins
ID frequency-analysis; world map
AB In this study, we utilise Artificial Neural Network (ANN) models to estimate the 100- and 1500-year return levels for around 900,000 ungauged catchments in the contiguous USA. The models were trained and validated using 4,079 gauges and several selected catchment descriptors out of a total of 25 available. The study area was split into 15 regions, which represent major watersheds. ANN models were developed for each region and evaluated by calculating several performance metrics such as root-mean-squared error (RMSE), coefficient of determination ( R (2) ) and absolute percent error. The availability of a large dataset of gauges made it possible to test different model architectures and assess the regional performance of the models. The results indicate that ANN models with only one hidden layer are sufficient to describe the relationship between flood quantiles and catchment descriptors. The regional performance depends on climate type as models perform worse in arid and humid continental climates. Overall, the study suggests that ANN models are particularly applicable for predicting ungauged flood quantiles across a large geographic area. The paper presents recommendations about future application of ANN in regional flood frequency analysis.
C1 [Filipova, Valeriya; Hammond, Anthony; Leedal, David] JBA Risk Management, Skipton, England.
   [Lamb, Rob] JBA Trust, Skipton, England.
   [Lamb, Rob] Lancaster Environm Ctr, Lancaster, England.
C3 Lancaster University
RP Filipova, V (corresponding author), JBA Risk Management, Skipton, England.
EM valeriya.filipova@jbarisk.com
CR Ahn KH, 2016, J HYDROL, V540, P515, DOI 10.1016/j.jhydrol.2016.06.047
   Aziz K, 2014, STOCH ENV RES RISK A, V28, P541, DOI 10.1007/s00477-013-0771-5
   Aziz K, 2014, PROQUEST DISSERTATIO, V0, P0
   Beck HE, 2015, J HYDROMETEOROL, V16, P1478, DOI 10.1175/JHM-D-14-0155.1
   Cheng R., 2018, THESIS TIANJIN U CHI, V0, P0
   Dawson CW, 2006, J HYDROL, V319, P391, DOI 10.1016/j.jhydrol.2005.07.032
   de Vos NJ, 2005, HYDROL EARTH SYST SC, V9, P111, DOI 10.5194/hess-9-111-2005
   Dillow K.G, 2006, 20065146 US GEOL SUR, V0, P0
   Duerr O., 2020, PROBABILISTIC DEEP L, V0, P0
   Durocher M, 2015, J HYDROMETEOROL, V16, P1561, DOI 10.1175/JHM-D-14-0227.1
   Engl J.F., 2018, GUIDELINES DETERMINI, V0, P0, DOI DOI 10.3133/TM4B5
   Faulkner D, 2016, CAN WATER RESOUR J, V41, P398, DOI 10.1080/07011784.2016.1141665
   Friedman J., 2009, ELEMENTS STAT LEARNI, V0, P0
   Gevrey M, 2003, ECOL MODEL, V160, P249, DOI 10.1016/S0304-3800(02)00257-0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gotvald A. J., 2012, 20125113 US GEOL SUR, V0, P0
   Gunther F, 2010, R J, V2, P30
   Haddad K, 2012, HYDROL PROCESS, V26, P1008, DOI 10.1002/hyp.8189
   Hrachowitz M, 2013, HYDROLOG SCI J, V58, P1198, DOI 10.1080/02626667.2013.803183
   Institute of Hydrology, 1999, FLOOD ESTIMATION HDB, V0, P0
   Kjeldsen TR, 2015, J FLOOD RISK MANAG, V8, P237, DOI 10.1111/jfr3.12090
   Kordrostami S, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10040127
   Kottek M, 2006, METEOROL Z, V15, P259, DOI 10.1127/0941-2948/2006/0130
   Kratzert F, 2019, HYDROL EARTH SYST SC, V23, P5089, DOI 10.5194/hess-23-5089-2019
   Kratzert Frederik, 2018, HYDROL EARTH SYST SC, V22, P6005, DOI 10.5194/hess-22-6005-2018
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Mason R.R.J., 2017, US GEOLOGICAL SURVEY, V0, P0
   Merz R, 2008, NAT HAZARDS, V46, P53, DOI 10.1007/s11069-007-9181-7
   Muttiah RS, 1997, J AM WATER RESOUR AS, V33, P625, DOI 10.1111/j.1752-1688.1997.tb03537.x
   Paltan H, 2018, ENVIRON RES LETT, V13, P0, DOI 10.1088/1748-9326/aad985
   Pang B, 2020, HYDROLOGY EARTH SYST, V0, P0
   Peel MC, 2007, HYDROL EARTH SYST SC, V11, P1633, DOI 10.5194/hess-11-1633-2007
   Ries K.G, 2007, HYDROLOGIC ANAL INTE, V4-A6, P37
   Rosso, 2008, ENGINEERING, V0, P0
   Salinas JL, 2013, HYDROL EARTH SYST SC, V17, P2637, DOI 10.5194/hess-17-2637-2013
   Schmidt L, 2020, WATER RESOUR RES, V56, P0, DOI 10.1029/2019WR025924
   Shen CP, 2018, HYDROL EARTH SYST SC, V22, P5639, DOI 10.5194/hess-22-5639-2018
   Shu C, 2007, WATER RESOUR RES, V43, P0, DOI 10.1029/2006WR005142
   Smith A, 2015, WATER RESOUR RES, V51, P539, DOI 10.1002/2014WR015814
   Snieder E, 2020, J HYDROL, V583, P0, DOI 10.1016/j.jhydrol.2019.124299
   Veilleux, 2014, METHODS ESTIMATING A, V0, P0
   Walton R, 2019, J HYDROL, V575, P671, DOI 10.1016/j.jhydrol.2019.05.068
   Yu G, 2019, HYDROL EARTH SYST SC, V23, P2225, DOI 10.5194/hess-23-2225-2019
NR 45
TC 4
Z9 4
U1 2
U2 8
PU IWA PUBLISHING
PI LONDON
PA REPUBLIC-EXPORT BLDG, UNITS 1 04 & 1 05, 1 CLOVE CRESCENT, LONDON, ENGLAND
SN 1998-9563
EI 2224-7955
J9 HYDROL RES
JI Hydrol. Res.
PD JAN 15
PY 2022
VL 53
IS 1
BP 107
EP 123
DI 10.2166/nh.2021.082
EA DEC 2021
PG 17
WC Water Resources
SC Water Resources
GA ZS6IW
UT WOS:000731400500001
DA 2023-04-26
ER

PT J
AU Chen, SX
   Shi, WZ
   Zhou, MT
   Zhang, M
   Xuan, ZX
AF Chen, Shanxiong
   Shi, Wenzhong
   Zhou, Mingting
   Zhang, Min
   Xuan, Zhaoxin
TI CGSANet: A Contour-Guided and Local Structure-Aware Encoder-Decoder Network for Accurate Building Extraction From Very High-Resolution Remote Sensing Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Buildings; Feature extraction; Remote sensing; Semantics; Data mining; Convolutional neural networks; Shape; Building extraction; fully convolutional network (FCN); hybrid loss function; multitask learning; very high resolution (VHR) remote sensing imagery
ID semantic segmentation; boundary
AB Extracting buildings accurately from very high-resolution (VHR) remote sensing imagery is challenging due to diverse building appearances, spectral variability, and complex background in VHR remote sensing images. Recent studies mainly adopt a variant of the fully convolutional network (FCN) with an encoder-decoder architecture to extract buildings, which has shown promising improvement over conventional methods. However, FCN-based encoder-decoder models still fail to fully utilize the implicit characteristics of building shapes. This adversely affects the accurate localization of building boundaries, which is particularly relevant in building mapping. A contour-guided and local structure-aware encoder-decoder network (CGSANet) is proposed to extract buildings with more accurate boundaries. CGSANet is a multitask network composed of a contour-guided (CG) and a multiregion-guided (MRG) module. The CG module is supervised by a building contour that effectively learns building contour-related spatial features to retain the shape pattern of buildings. The MRG module is deeply supervised by four building regions that further capture multiscale and contextual features of buildings. In addition, a hybrid loss function was designed to improve the structure learning ability of CGSANet. These three improvements benefit each other synergistically to produce high-quality building extraction results. Experimental results on the WHU and NZ32km2 building datasets demonstrate that compared with the tested algorithms, CGSANet can produce more accurate building extraction results and achieve the best intersection over union value 91.55% and 90.02%, respectively. Experiments on the INRIA building dataset further demonstrate the ability for generalization of the proposed framework, indicating great practical potential.
C1 [Chen, Shanxiong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Chen, Shanxiong; Shi, Wenzhong; Zhang, Min] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Peoples R China.
   [Shi, Wenzhong; Zhang, Min] Hong Kong Polytech Univ, Smart Cities Res Inst, Hong Kong, Peoples R China.
   [Zhou, Mingting] Wuhan Univ, Key Lab Informat Engn Surveying Mapping & Remote, Wuhan 430079, Peoples R China.
   [Xuan, Zhaoxin] Beijing Inst Surveying & Mapping, Beijing 100038, Peoples R China.
   [Xuan, Zhaoxin] Beijing Key Lab Urban Spatial Informat Engn, Beijing 100038, Peoples R China.
C3 Wuhan University; Hong Kong Polytechnic University; Hong Kong Polytechnic University; Wuhan University
RP Chen, SX (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM shanxiongchen@whu.edu.cn; john.wz.shi@polyu.edu.hk; mintyzhou@whu.edu.cn; 007zhang-min@whu.edu.cn; 54786060@qq.com
FU Hong Kong Polytechnic University [1-ZVN6, ZVU1, 4-BCF7]; Hong Kong Innovation, and Technology Commission [SST/051/20GP]; BeijingKey Laboratory of Urban Spatial Information Engineering [2020101]
CR Bischke B, 2019, IEEE IMAGE PROC, V0, PP1480, DOI 10.1109/ICIP.2019.8803050
   Bittner K, 2018, IEEE J-STARS, V11, P2615, DOI 10.1109/JSTARS.2018.2849363
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, PP801, DOI 10.1007/978-3-030-01234-2_49
   Chen SX, 2020, IEEE J-STARS, V13, P2081, DOI 10.1109/JSTARS.2020.2992298
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.32
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Fazan AJ, 2013, INT J APPL EARTH OBS, V25, P1, DOI 10.1016/j.jag.2013.03.003
   Guo MQ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091400
   Hao SJ, 2020, NEUROCOMPUTING, V406, P302, DOI 10.1016/j.neucom.2019.11.118
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Huang X, 2011, PHOTOGRAMM ENG REM S, V77, P721, DOI 10.14358/PERS.77.7.721
   Huang ZM, 2016, INT GEOSCI REMOTE SE, V0, PP1835, DOI 10.1109/IGARSS.2016.7729471
   Ji SP, 2019, INT J REMOTE SENS, V40, P3308, DOI 10.1080/01431161.2018.1528024
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang Z., 2020, P SPIE, V0, P60
   Karantzalos K, 2009, IEEE T GEOSCI REMOTE, V47, P133, DOI 10.1109/TGRS.2008.2002027
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li WJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040403
   Li X, 2018, IEEE J-STARS, V11, P3680, DOI 10.1109/JSTARS.2018.2865187
   Liao C, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13061049
   Liu PH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070830
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Mnih V., 2013, MACHINE LEARNING AER, V0, P0
   Moussa A, 2012, INT ARCH PHOTOGRAMM, V39-B3, P309
   Noronha S, 2001, IEEE T PATTERN ANAL, V23, P501, DOI 10.1109/34.922708
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Pan XR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080917
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Qin XB, 2019, PROC CVPR IEEE, V0, PP7471, DOI 10.1109/CVPR.2019.00766
   Rahman Md Atiqur, 2016, ADVANCES IN VISUAL COMPUTING. 12TH INTERNATIONAL SYMPOSIUM, V0, P234, DOI 10.1007/978-3-319-50835-1_22
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saito S, 2015, PROC SPIE, V9405, P0, DOI 10.1117/12.2083273
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, V0, PP618, DOI 10.1109/ICCV.2017.74
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shrestha S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071135
   Sirmacek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, V0, PP1873, DOI 10.1109/IGARSS.2015.7326158
   Wei J., 2020, ASS ADVANCEMENT ARTI, V0, PP12321, DOI 10.1609/AAAI.V34I07.6916
   Wei SQ, 2020, IEEE T GEOSCI REMOTE, V58, P2178, DOI 10.1109/TGRS.2019.2954461
   Wu GM, 2019, INT GEOSCI REMOTE SE, V0, PP158, DOI 10.1109/IGARSS.2019.8900475
   Wu GM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030407
   Wu GM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081195
   Xia LG, 2020, INT J REMOTE SENS, V41, P8352, DOI 10.1080/01431161.2020.1775322
   Xiangtai Li, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12362), V0, PP435, DOI 10.1007/978-3-030-58520-4_26
   Yang H, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111768
   Ye ZR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242970
   Yuan JY, 2018, IEEE T PATTERN ANAL, V40, P2793, DOI 10.1109/TPAMI.2017.2750680
   Zha K, 2018, IEEE COMPUT SOC CONF, V0, PP242, DOI 10.1109/CVPRW.2018.00045
   Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203
   Zheng XW, 2020, ISPRS J PHOTOGRAMM, V170, P15, DOI 10.1016/j.isprsjprs.2020.09.019
   Zhou F, 2021, IEEE T GEOSCI REMOTE, V59, P2245, DOI 10.1109/TGRS.2020.3006872
   Zhou MT, 2020, ISPRS J PHOTOGRAMM, V168, P288, DOI 10.1016/j.isprsjprs.2020.08.019
   Zhu Q, 2021, IEEE T GEOSCI REMOTE, V59, P6169, DOI 10.1109/TGRS.2020.3026051
NR 57
TC 5
Z9 5
U1 12
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2022
VL 15
IS 
BP 1526
EP 1542
DI 10.1109/JSTARS.2021.3139017
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA YX6YE
UT WOS:000754245300001
DA 2023-04-26
ER

PT J
AU Shen, X
   Weng, LG
   Xia, M
   Lin, HF
AF Shen, Xu
   Weng, Liguo
   Xia, Min
   Lin, Haifeng
TI Multi-Scale Feature Aggregation Network for Semantic Segmentation of Land Cover
SO REMOTE SENSING
LA English
DT Article
DE land cover; remote sensing image; deep learning; semantic segmentation
AB Land cover semantic segmentation is an important technique in land. It is very practical in land resource protection planning, geographical classification, surveying and mapping analysis. Deep learning shows excellent performance in picture segmentation in recent years, but there are few semantic segmentation algorithms for land cover. When dealing with land cover segmentation tasks, traditional semantic segmentation networks often have disadvantages such as low segmentation precision and weak generalization due to the loss of image detail information and the limitation of weight distribution. In order to achieve high-precision land cover segmentation, this article develops a multi-scale feature aggregation network. Traditional convolutional neural network downsampling procedure has problems of detail information loss and resolution degradation; to fix these problems, a multi-scale feature extraction spatial pyramid module is made to assemble regional context data from different areas. In order to address the issue of incomplete information of traditional convolutional neural networks at multiple sizes, a multi-scale feature fusion module is developed to fuse attributes from various layers and several sizes to boost segmentation accuracy. Finally, a multi-scale convolutional attention module is presented to enhance the segmentation's attention to the target in order to address the issue that the classic convolutional neural network has low attention capacity to the building waters in land cover segmentation. Through the contrast experiment and generalization experiment, it can be clearly demonstrated that the segmentation algorithm proposed in this paper realizes the high precision segmentation of land cover.
C1 [Shen, Xu; Weng, Liguo; Xia, Min] Nanjing Univ Informat Sci & Technol, Collaborat Innovat Ctr Atmospher Environm & Equipm, Nanjing 210044, Peoples R China.
   [Lin, Haifeng] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 210000, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing Forestry University
RP Weng, LG (corresponding author), Nanjing Univ Informat Sci & Technol, Collaborat Innovat Ctr Atmospher Environm & Equipm, Nanjing 210044, Peoples R China.
EM 002311@nuist.edu.cn
FU National Natural Science Foundation of PR China;  [42075130]
CR Albawi S, 2017, I C ENG TECHNOL, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chattopadhay A, 2018, IEEE WINT CONF APPL, V0, PP839, DOI 10.1109/WACV.2018.00097
   Chen BY, 2022, INT J REMOTE SENS, V43, P5874, DOI 10.1080/01431161.2022.2073795
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Chollet F., 2017, P IEEE C COMP VIS PA, V0, PP1251, DOI 10.1109/CVPR.2017.195
   Cubuk ED, 2019, PROC CVPR IEEE, V0, PP113, DOI 10.1109/CVPR.2019.00020
   Du YN, 2019, IEEE J-STARS, V12, P151, DOI 10.1109/JSTARS.2018.2883772
   Dubey Arun Kumar, 2019, APPLICATIONS OF COMPUTING, V0, P873, DOI 10.1007/978-981-13-6772-4_76
   Gao JH, 2022, J APPL REMOTE SENS, V16, P0, DOI 10.1117/1.JRS.16.016513
   Hannv Zhang, 2013, JOURNAL OF MULTIMEDIA, V8, P175, DOI 10.4304/jmm.8.2.175-182
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hong Y., 2021, ARXIV, V0, P0
   Hou QB, 2021, PROC CVPR IEEE, V0, PP13708, DOI 10.1109/CVPR46437.2021.01350
   Howard A. G., 2017, MOBILENETS EFFICIENT, V0, P0
   Hu J., 2018, P IEEECVF C COMPUTER, V0, P7132
   HUANG G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang HB, 2017, REMOTE SENS ENVIRON, V202, P166, DOI 10.1016/j.rse.2017.02.021
   Huang ZL, 2019, IEEE I CONF COMP VIS, V0, PP603, DOI 10.1109/ICCV.2019.00069
   Karlik B, 2011, INT J ARTIFICIAL INT, V4, P111
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Leng Y, 2017, J ELECTRON INF TECHN, V39, P1064, DOI 10.11999/JEIT160870
   Li M, 2014, EUR J REMOTE SENS, V47, P389, DOI 10.5721/EuJRS20144723
   Li X, 2019, IEEE I CONF COMP VIS, V0, PP9166, DOI 10.1109/ICCV.2019.00926
   Long J., 2015, P IEEE C COMPUTER VI, V0, PP3431, DOI 10.48550/ARXIV.1411.4038
   Lu C, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2022.3175613
   Lu C, 2022, NEURAL COMPUT APPL, V34, P6149, DOI 10.1007/s00521-021-06802-0
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Miao SK, 2022, INT J REMOTE SENS, V43, P5940, DOI 10.1080/01431161.2021.2014077
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Pang K, 2022, INT J REMOTE SENS, V43, P5917, DOI 10.1080/01431161.2021.2022805
   Qu Y, 2021, COMPUT GEOSCI-UK, V157, P0, DOI 10.1016/j.cageo.2021.104940
   Ronneberger O., 2015, INT C MEDICAL IMAGE, V0, P234
   Simonyan K, 2015, ARXIV, V0, P0
   Song L, 2023, IEEE J-STARS, V16, P32, DOI 10.1109/JSTARS.2022.3224081
   Song L, 2021, INT J APPL EARTH OBS, V105, P0, DOI 10.1016/j.jag.2021.102597
   Vaswani A., 2017, ADV NEURAL INFORM PR, V30, P5998
   Wang ZW, 2022, IEEE T POWER DELIVER, V37, P3155, DOI 10.1109/TPWRD.2021.3124528
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia M, 2022, ELECTR POW SYST RES, V207, P0, DOI 10.1016/j.epsr.2022.107855
   Xia M, 2021, J APPL REMOTE SENS, V15, P0, DOI 10.1117/1.JRS.15.046512
   Yang LX, 2021, PR MACH LEARN RES, V139, P0
   Ye Q, 2016, LECT NOTES COMPUT SC, V9912, P346, DOI 10.1007/978-3-319-46484-8_21
   Yu CQ, 2021, INT J COMPUT VISION, V129, P3051, DOI 10.1007/s11263-021-01515-2
   Yu F., 2016, INT C LEARN REPR ICL, V0, P1
   Zhang F, 2019, IEEE I CONF COMP VIS, V0, PP6797, DOI 10.1109/ICCV.2019.00690
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
NR 48
TC 2
Z9 2
U1 6
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 15
PY 2022
VL 14
IS 23
BP 
EP 
DI 10.3390/rs14236156
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA 6X6MF
UT WOS:000896525000001
DA 2023-04-26
ER

PT J
AU Dvorak, J
   Potuckova, M
   Treml, V
AF Dvorak, Jakub
   Potuckova, Marketa
   Treml, Vaclav
TI WEAKLY SUPERVISED LEARNING FOR TREELINE ECOTONE CLASSIFICATION BASED ON AERIAL ORTHOIMAGES AND AN ANCILLARY DSM
SO XXIV ISPRS CONGRESS: IMAGING TODAY, FORESEEING TOMORROW, COMMISSION III
LA English
DT Proceedings Paper
DE deep learning; U-Net; Krkonose mountains; classification; nDSM; picea abies; pinus mugo; orthoimage
AB Convolutional neural networks (CNNs) effectively classify standard datasets in remote sensing (RS). Yet, real-world data are more difficult to classify using CNNs because these networks require relatively large amounts of training data. To reduce training data requirements, two approaches can be followed - either pretraining models on larger datasets or augmenting the available training data. However, these commonly used strategies do not fully resolve the lack of training data for land cover classification in RS. Our goal is to classify trees and shrubs from aerial orthoimages in the treeline ecotone of the Krkonose Mountains, Czechia. Instead of training a model on a smaller, human-labelled dataset, we semiautomatically created training data using an ancillary normalised Digital Surface Model (nDSM) and image spectral information. This approach can complement existing techniques, trading accuracy for a larger labelled dataset while assuming that the classifier can handle the training data noise. Weakly supervised learning on a CNN led to 68.99% mean Intersection over Union ( IoU) and 81.65% mean F1-score for U-Net and 72.94% IoU and 84.35% mean F1-score for our modified U-Net on a test set comprising over 1000 manually labelled points. Notwithstanding the bias resulting from the noise in training data (especially in the least occurring tree class), our data show that standard semantic segmentation networks can be used for weakly supervised learning for local-scale land cover mapping.
C1 [Dvorak, Jakub; Potuckova, Marketa] Charles Univ Prague, Fac Sci, Dept Appl Geoinformat & Cartog, Prague, Czech Republic.
   [Treml, Vaclav] Charles Univ Prague, Fac Sci, Dept Phys Geog & Geoecol, Prague, Czech Republic.
C3 Charles University Prague; Charles University Prague
RP Dvorak, J (corresponding author), Charles Univ Prague, Fac Sci, Dept Appl Geoinformat & Cartog, Prague, Czech Republic.
EM jakub.dvorak@natur.cuni.cz; marketa.potuckova@natur.cuni.cz; vaclav.treml@natur.cuni.cz
CR Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Brandt M, 2020, NATURE, V587, P78, DOI 10.1038/s41586-020-2824-5
   Cattaneo Andrea, 2020, COMPLEMENTTHERCLINPR, V13, P742, DOI 10.1016/j.envsci.2010.08.009
   Chen Wei, 1900, V172, V0, PP212, DOI 10.1016/j.catena.2018.08.025
   Duarte D., 2019, ISPRS ANN PHOTOGRAMM, V4, P29
   Dvorak J., 2020, THESIS CHARLES U PRA, V0, P0
   Foody GM, 2009, INT J REMOTE SENS, V30, P5273, DOI 10.1080/01431160903130937
   Huang BH, 2018, INT GEOSCI REMOTE SE, V0, P6947
   Idol Travis W., 2019, DRUGS, V94, P81, DOI 10.1007/s10457-019-00370-y
   Nwankpa C, 2018, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.1811.03378
   Puchrik L., 2013, GEODIS NEWS, V12, P24
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schmitt Michael, 2020, ARXIV, V0, P0
   Treml V, 2015, ARCT ANTARCT ALP RES, V47, P133, DOI 10.1657/AAAR0013-108
   UNESCO, 2016, KRKON KARK WWW DOC, V0, P0
   Wagner FH, 2019, REMOTE SENS ECOL CON, V5, P360, DOI 10.1002/rse2.111
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111309
NR 17
TC 0
Z9 0
U1 2
U2 3
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 2194-9042
EI 2194-9050
J9 ISPRS ANN PHOTO REM
PD JUN 15
PY 2022
VL 5-3
IS 
BP 33
EP 38
DI 10.5194/isprs-annals-V-3-2022-33-2022
PG 6
WC Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA BT8SD
UT WOS:000855203200006
DA 2023-04-26
ER
