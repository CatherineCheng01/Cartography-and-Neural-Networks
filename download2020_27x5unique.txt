
PT J
AU Yan, Y
   Han, Y
   Zhang, PH
   Wang, HF
AF Yan, Yan
   Han, Yan
   Zhang, Puhua
   Wang, Huifang
TI Water Quality Detection Based on FCN and Embedded System
SO JOURNAL OF COASTAL RESEARCH
LA English
DT Article
DE Deep learning; convolution neural network; full convolution neural network; embedded system
AB In this paper, the convolutional neural network (CNN) based on deep learning is applied to embedded systems. After summarizing the shortcomings of traditional algorithms, the image processing technology of full convolutional neural network (FCN) is adopted to study a method for online water quality measurement, which solves the key problem of image recognition. In view of the complex nonlinear characteristics of water quality related data, the full convolutional neural network is used to train water quality data, determine the mapping relationship between input and output, and input the obtained relationship into the embedded system to form a water quality detection system, so as to quickly and efficiently detect water pollution. The experimental results show that the accuracy of the predicted grade and the measured grade of water quality in the test area can be as high as 90%.
C1 [Yan, Yan] Hebei Normal Univ, Sch Math Sci, Shijiazhuang 050024, Hebei, Peoples R China.
   [Yan, Yan; Han, Yan; Zhang, Puhua; Wang, Huifang] North China Univ Sci & Technol, Coll Sci, Tangshan 063210, Peoples R China.
C3 Hebei Normal University; North China University of Science & Technology
RP Han, Y (corresponding author), North China Univ Sci & Technol, Coll Sci, Tangshan 063210, Peoples R China.
EM hany_ncst@163.com
FU National Natural Science Foundation of China [11671117, 11871018, 61370168]
CR Acharya K, 2020, WATER RES, V184, P0, DOI 10.1016/j.watres.2020.116112
   [Anonymous], 2014, PROC IEEE C COMPUT V, V0, P0
   Cai XX, 2016, J VIS COMMUN IMAGE R, V40, P366, DOI 10.1016/j.jvcir.2016.07.009
   Gatys L.A., 2015, PROC CVPR IEEE, V0, P0, DOI DOI 10.1109/CVPR.2016.265
   Girshick R., 2015, COMPUTER SCI, V21, P3353
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Mix N, 2020, J AM WATER WORKS ASS, V112, P44, DOI 10.1002/awwa.1555
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Yu HL, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17010013
NR 10
TC 0
Z9 0
U1 2
U2 21
PU COASTAL EDUCATION & RESEARCH FOUNDATION
PI COCONUT CREEK
PA 5130 NW 54TH STREET, COCONUT CREEK, FL 33073 USA
SN 0749-0208
EI 1551-5036
J9 J COASTAL RES
JI J. Coast. Res.
PD FAL 15
PY 2020
VL 0
IS 
BP 72
EP 76
DI 10.2112/JCR-SI104-013.1
PG 5
WC Environmental Sciences; Geography, Physical; Geosciences, Multidisciplinary
SC Environmental Sciences & Ecology; Physical Geography; Geology
GA OK2VS
UT WOS:000584510900013
DA 2023-04-26
ER

PT J
AU Yoon, S
   Lee, YJ
   Jung, HJ
AF Yoon, Sungsik
   Lee, Young-Joo
   Jung, Hyung-Jo
TI Accelerated Monte Carlo analysis of flow-based system reliability through artificial neural network-based surrogate models
SO SMART STRUCTURES AND SYSTEMS
LA English
DT Article
DE Aartificial Neural Networks; surrogate model; accelerated Monte Carlo simulation; seismic risk assessment; flow-based system reliability
ID peak ground acceleration; seismic risk-assessment; spatial correlation; damage detection; middle-east; earthquake; motions; vulnerability; resilience; northridge
AB Conventional Monte Carlo simulation-based methods for seismic risk assessment of water networks often require excessive computational time costs due to the hydraulic analysis. In this study, an Artificial Neural Network-based surrogate model was proposed to efficiently evaluate the flow-based system reliability of water distribution networks. The surrogate model was constructed with appropriate training parameters through trial-and-error procedures. Furthermore, a deep neural network with hidden layers and neurons was composed for the high-dimensional network. For network training, the input of the neural network was defined as the damage states of the k-dimensional network facilities, and the output was defined as the network system performance. To generate training data, random sampling was performed between earthquake magnitudes of 5.0 and 7.5, and hydraulic analyses were conducted to evaluate network performance. For a hydraulic simulation, EPANET-based MATLAB code was developed, and a pressure-driven analysis approach was adopted to represent an unsteady-state network. To demonstrate the constructed surrogate model, the actual water distribution network of A-city, South Korea, was adopted, and the network map was reconstructed from the geographic information system data. The surrogate model was able to predict network performance within a 3% relative error at trained epicenters in drastically reduced time. In addition, the accuracy of the surrogate model was estimated to within 3% relative error (5% for network performance lower than 0.2) at different epicenters to verify the robustness of the epicenter location. Therefore, it is concluded that ANN-based surrogate model can be utilized as an alternative model for efficient seismic risk assessment to within 5% of relative error.
C1 [Yoon, Sungsik; Jung, Hyung-Jo] Korea Adv Inst Sci & Technol, Dept Civil & Environm Engn, 291 Daehak Ro, Daejeon 34141, South Korea.
   [Lee, Young-Joo] Ulsan Natl Inst Sci & Technol, Sch Urban & Environm Engn, 50 UNIST Gil, Ulsan 44919, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Ulsan National Institute of Science & Technology (UNIST)
RP Jung, HJ (corresponding author), Korea Adv Inst Sci & Technol, Dept Civil & Environm Engn, 291 Daehak Ro, Daejeon 34141, South Korea.
EM yss3366@kaist.ac.kr; ylee@unist.ac.kr; hjung@kaist.edu
FU Korea Institute of Energy Technology Evaluation and Planning (KETEP); Ministry of Trade, Industry & Energy (MOTIE) of the Republic of Korea [20181510102410]; National Research Foundation Korea (NRF) - Korean government (MSIP) [2017R1A5A1014883]
CR ABRAHAMSON NA, 1992, B SEISMOL SOC AM, V82, P505
   Akin O, 2017, SMART STRUCT SYST, V20, P657, DOI 10.12989/sss.2017.20.6.657
   Ambraseys NN, 2005, B EARTHQ ENG, V3, P55, DOI 10.1007/s10518-005-0186-x
   Ambraseys NN, 2005, B EARTHQ ENG, V3, P1, DOI 10.1007/s10518-005-0183-0
   Bonneau A.L, 2009, MCEER090003, V0, P0
   Boore DM, 2003, B SEISMOL SOC AM, V93, P2737, DOI 10.1785/0120020197
   Cerchiello V, 2018, INT J DISAST RISK RE, V28, P491, DOI 10.1016/j.ijdrr.2017.12.012
   Duenas-Osorio L, 2007, EARTHQ ENG STRUCT D, V36, P285, DOI 10.1002/eqe.626
   Duenas-Osorio L, 2011, COMPUT-AIDED CIV INF, V26, P111, DOI 10.1111/j.1467-8667.2010.00661.x
   Esposito S, 2015, COMPUT-AIDED CIV INF, V30, P508, DOI 10.1111/mice.12105
   Esposito S, 2012, B SEISMOL SOC AM, V102, P2781, DOI 10.1785/0120120068
   Farahmandfar Z, 2017, J PIPELINE SYST ENG, V8, P0, DOI 10.1061/(ASCE)PS.1949-1204.0000251
   FEMA, 2003, MR3 HAZUSMH US DEP H, V0, P0
   Goda K, 2008, B SEISMOL SOC AM, V98, P354, DOI 10.1785/0120070078
   Guidotti R, 2016, SUSTAIN RESIL INFRAS, V1, P153, DOI 10.1080/23789689.2016.1254999
   Gupta R, 1996, J WATER RES PL-ASCE, V122, P214, DOI 10.1061/(ASCE)0733-9496(1996)122:3(214)
   Hakim SJS, 2014, SMART STRUCT SYST, V14, P159, DOI 10.12989/sss.2014.14.2.159
   Hwang H. H. M., 1998, J INFRASTRUCT SYST, V4, P118, DOI 10.1061/(ASCE)1076-0342(1998)4:3(118)
   Isoyama R., 2000, P 12 WORLD C EARTHQ, V0, P0
   Jeon SS, 2005, B SEISMOL SOC AM, V95, P294, DOI 10.1785/0120040020
   JOYNER WB, 1993, B SEISMOL SOC AM, V83, P469
   Kang WH, 2008, RELIAB ENG SYST SAFE, V93, P1584, DOI 10.1016/j.ress.2008.02.011
   Kang WH, 2017, MATH PROBL ENG, V2017, P0, DOI 10.1155/2017/2017046
   Kim JT, 2008, SMART STRUCT SYST, V4, P583, DOI 10.12989/sss.2008.4.5.583
   Kim J, 2018, INT J DISAST RISK RE, V28, P674, DOI 10.1016/j.ijdrr.2018.01.028
   Lee DH, 2009, ENG STRUCT, V31, P1011, DOI 10.1016/j.engstruct.2008.12.012
   Lee YJ, 2011, STRUCT INFRASTRUCT E, V7, P509, DOI 10.1080/15732479.2010.493338
   Li PH, 2015, SMART STRUCT SYST, V15, P227, DOI 10.12989/sss.2015.15.1.227
   Lim HW, 2012, EARTHQ ENG STRUCT D, V41, P1861, DOI 10.1002/eqe.2162
   Mangalathu S, 2018, ENG STRUCT, V162, P166, DOI 10.1016/j.engstruct.2018.01.053
   Nguyen DH, 2019, STRUCT ENG MECH, V71, P175, DOI 10.12989/sem.2019.71.2.175
   Okumura T., 1991, P 3 US C LIF EARTHQ, V0, P0
   Onat O, 2018, SMART STRUCT SYST, V21, P521, DOI 10.12989/sss.2018.21.4.521
   OROURKE M, 1993, J GEOTECH ENG-ASCE, V119, P1490, DOI 10.1061/(ASCE)0733-9410(1993)119:9(1490)
   PAHO, 2002, EM DIS DRINK WAT SUP, V0, P0
   Park S, 2010, WATER RESOUR MANAG, V24, P3195, DOI 10.1007/s11269-010-9602-3
   Puchovsky M.T., 1999, AUTOMATIC SPRINKLER, V0, P0
   Rizzo P, 2006, SMART STRUCT SYST, V2, P253, DOI 10.12989/sss.2006.2.3.253
   Rokneddin K, 2013, STRUCT INFRASTRUCT E, V9, P1050, DOI 10.1080/15732479.2011.654230
   Seo J, 2013, ENG STRUCT, V52, P642, DOI 10.1016/j.engstruct.2013.03.023
   Seo J, 2012, ENG STRUCT, V45, P585, DOI 10.1016/j.engstruct.2012.07.003
   Shahbazi Y, 2014, SMART STRUCT SYST, V13, P81, DOI 10.12989/sss.2013.13.1.081
   Shi P., 2006, MCEER080016, V0, P0
   Sokolov V, 2010, TERR ATMOS OCEAN SCI, V21, P905, DOI 10.3319/TAO.2010.05.03.01(T)
   Stern RE, 2017, RELIAB ENG SYST SAFE, V164, P1, DOI 10.1016/j.ress.2017.01.021
   Wagener T, 2016, SOIL DYN EARTHQ ENG, V85, P166, DOI 10.1016/j.soildyn.2016.03.016
   WAGNER JM, 1988, J WATER RES PL-ASCE, V114, P276, DOI 10.1061/(ASCE)0733-9496(1988)114:3(276)
   Wang M, 2005, EARTHQ SPECTRA, V21, P1137, DOI 10.1193/1.2083887
   Wang Y, 2006, MCEER080015, V0, P0
   Wang Y, 2010, EARTHQ SPECTRA, V26, P257, DOI 10.1193/1.3276900
   Yoon S, 2020, STRUCT ENG MECH, V73, P339, DOI 10.12989/sem.2020.73.3.339
   Yoon S, 2018, INT J DISAST RISK RE, V31, P983, DOI 10.1016/j.ijdrr.2018.09.002
NR 52
TC 3
Z9 3
U1 2
U2 19
PU TECHNO-PRESS
PI DAEJEON
PA PO BOX 33, YUSEONG, DAEJEON 305-600, SOUTH KOREA
SN 1738-1584
EI 1738-1991
J9 SMART STRUCT SYST
JI Smart. Struct. Syst.
PD AUG 15
PY 2020
VL 26
IS 2
BP 175
EP 184
DI 10.12989/sss.2020.26.2.175
PG 10
WC Engineering, Civil; Engineering, Mechanical; Instruments & Instrumentation
SC Engineering; Instruments & Instrumentation
GA MZ1VP
UT WOS:000558910200004
DA 2023-04-26
ER

PT J
AU Khoshboresh-Masouleh, M
   Shah-Hosseini, R
AF Khoshboresh-Masouleh, Mehdi
   Shah-Hosseini, Reza
TI A Deep Learning Method for Near-Real-Time Cloud and Cloud Shadow Segmentation from Gaofen-1 Images
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
LA English
DT Article
ID neural-networks; algorithm; snow; cover
AB In this study, an essential application of remote sensing using deep learning functionality is presented. Gaofen-1 satellite mission, developed by the China National Space Administration (CNSA) for the civilian high-definition Earth observation satellite program, provides near-real-time observations for geographical mapping, environment surveying, and climate change monitoring. Cloud and cloud shadow segmentation are a crucial element to enable automatic near-real-time processing of Gaofen-1 images, and therefore, their performances must be accurately validated. In this paper, a robust multiscale segmentation method based on deep learning is proposed to improve the efficiency and effectiveness of cloud and cloud shadow segmentation from Gaofen-1 images. The proposed method first implements feature map based on the spectral-spatial features from residual convolutional layers and the cloud/cloud shadow footprints extraction based on a novel loss function to generate the final footprints. The experimental results using Gaofen-1 images demonstrate the more reasonable accuracy and efficient computational cost achievement of the proposed method compared to the cloud and cloud shadow segmentation performance of two existing state-of-the-art methods.
C1 [Khoshboresh-Masouleh, Mehdi; Shah-Hosseini, Reza] Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran, Iran.
C3 University of Tehran
RP Shah-Hosseini, R (corresponding author), Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran, Iran.
EM m.khoshboresh@ut.ac.ir; rshahosseini@ut.ac.ir
CR AMCharts, 2020, AMCHARTS JAVASCRIPT, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baetens L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040433
   Bai T, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8090715
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Beruvides G, 2014, INT J PRECIS ENG MAN, V15, P1801, DOI 10.1007/s12541-014-0532-5
   Castano F, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18051508
   Castano F, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17092109
   Chai D, 2019, REMOTE SENS ENVIRON, V225, P307, DOI 10.1016/j.rse.2019.03.007
   Chen Y, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7050181
   Chollet F., 2018, DEEP LEARNING WITH R, V0, P0
   Coluzzi R, 2018, REMOTE SENS ENVIRON, V217, P426, DOI 10.1016/j.rse.2018.08.009
   Frantz D, 2018, REMOTE SENS ENVIRON, V215, P471, DOI 10.1016/j.rse.2018.04.046
   Gang C, 2007, GEO-SPAT INF SCI, V10, P117, DOI 10.1007/s11806-007-0047-7
   GESELL G, 1989, INT J REMOTE SENS, V10, P897, DOI 10.1080/01431168908903929
   Gomez-Chova L, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.015005
   Guo J., 2016, P IEEE INT C MULT EX, V0, PP1, DOI 10.1109/ICME.2016.7552907
   Haber RE, 2017, IEEE ACCESS, V5, P22272, DOI 10.1109/ACCESS.2017.2764047
   Hagolle O, 2010, REMOTE SENS ENVIRON, V114, P1747, DOI 10.1016/j.rse.2010.03.002
   Heipke C, 2020, GEO-SPAT INF SCI, V23, P10, DOI 10.1080/10095020.2020.1718003
   Hollstein A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080666
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Hughes MJ, 2014, REMOTE SENS-BASEL, V6, P4907, DOI 10.3390/rs6064907
   Irish RR, 2006, PHOTOGRAMM ENG REM S, V72, P1179, DOI 10.14358/PERS.72.10.1179
   Khoshboresh Masouleh M., 2019, INT ARCH PHOTOGRAMM, V0, PP615, DOI 10.5194/ISPRSARCHIVES-XLII-4-W18-615-2019
   Khoshboresh-Masouleh M, 2020, J APPL REMOTE SENS, V14, P0, DOI 10.1117/1.JRS.14.034503
   Latry C, 2007, INT GEOSCI REMOTE SE, V0, PP448, DOI 10.1109/IGARSS.2007.4422827
   Li D, 2020, GEO-SPAT INF SCI, V23, P40, DOI 10.1080/10095020.2020.1718001
   Li QY, 2012, IEEE GEOSCI REMOTE S, V9, P417, DOI 10.1109/LGRS.2011.2170953
   Li ZW, 2019, ISPRS J PHOTOGRAMM, V150, P197, DOI 10.1016/j.isprsjprs.2019.02.017
   Li ZW, 2017, REMOTE SENS ENVIRON, V191, P342, DOI 10.1016/j.rse.2017.01.026
   Li ZW, 2016, INT GEOSCI REMOTE SE, V0, PP7612, DOI 10.1109/IGARSS.2016.7730985
   Masouleh MK, 2020, APPL GEOMAT, V12, P107, DOI 10.1007/s12518-019-00285-4
   Masouleh MK, 2019, ISPRS J PHOTOGRAMM, V155, P172, DOI 10.1016/j.isprsjprs.2019.07.009
   Masouleh MK, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.024508
   Masouleh MK, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.046018
   Murty M., 2016, SUPPORT VECTOR MACHI, V0, P0
   Muzahid AAM, 2020, COMPUT INTEL NEUROSC, V2020, P0, DOI 10.1155/2020/5851465
   Qiu S, 2017, REMOTE SENS ENVIRON, V199, P107, DOI 10.1016/j.rse.2017.07.002
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSSOW WB, 1993, J CLIMATE, V6, P2341, DOI 10.1175/1520-0442(1993)006<2341:CDUSMO>2.0.CO;2
   Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419
   Sen S, 2005, PROCEEDINGS OF THE 8TH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1-3, P1256
   STOWE LL, 1991, ADV SPACE RES-SERIES, V11, P51, DOI 10.1016/0273-1177(91)90402-6
   Sun L, 2017, ISPRS J PHOTOGRAMM, V124, P70, DOI 10.1016/j.isprsjprs.2016.12.005
   Tan K, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110963
   Tracewski L, 2017, GEO-SPAT INF SCI, V20, P252, DOI 10.1080/10095020.2017.1373955
   Wang L, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10111666
   Wieland M, 2019, REMOTE SENS ENVIRON, V230, P0, DOI 10.1016/j.rse.2019.05.022
   Xia M, 2020, J APPL REMOTE SENS, V14, P0, DOI 10.1117/1.JRS.14.032609
   Yang AX, 2015, REMOTE SENS-BASEL, V7, P10763, DOI 10.3390/rs70810763
   Yang JY, 2019, IEEE T GEOSCI REMOTE, V57, P6195, DOI 10.1109/TGRS.2019.2904868
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zhang Q, 2020, ISPRS J PHOTOGRAMM, V162, P148, DOI 10.1016/j.isprsjprs.2020.02.008
   Zheng LJ, 2017, OPT ENG, V56, P0, DOI 10.1117/1.OE.56.7.073103
   Zhou K, 2020, COMPUT INTEL NEUROSC, V2020, P0, DOI 10.1155/2020/8562323
   Zhou Meng-li, 2019, FOREST RESEARCH, V32, P49, DOI 10.13275/j.cnki.lykxyj.2019.03.007
NR 57
TC 9
Z9 9
U1 5
U2 35
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-5265
EI 1687-5273
J9 COMPUT INTEL NEUROSC
JI Comput. Intell. Neurosci.
PD OCT 29
PY 2020
VL 2020
IS 
BP 
EP 
DI 10.1155/2020/8811630
PG 13
WC Mathematical & Computational Biology; Neurosciences
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA OT5LQ
UT WOS:000590888100001
PM 33178258
DA 2023-04-26
ER

PT J
AU Xu, S
   Zhou, HD
   Chou, WS
AF Xu, Song
   Zhou, Huaidong
   Chou, Wusheng
TI ERF-IMCS: An Efficient and Robust Framework with Image-Based Monte Carlo Scheme for Indoor Topological Navigation
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE vision-based topological mapping and navigation; image-based monte carlo localization; image retrieval; CNN features
ID retrieval; localization; quantization; features; model
AB Conventional approaches to global localization and navigation mainly rely on metric maps to provide precise geometric coordinates, which may cause the problem of large-scale structural ambiguity and lack semantic information of the environment. This paper presents a scalable vision-based topological mapping and navigation method for a mobile robot to work robustly and flexibly in large-scale environment. In the vision-based topological navigation, an image-based Monte Carlo localization method is presented to realize global topological localization based on image retrieval, in which fine-tuned local region features from an object detection convolutional neural network (CNN) are adopted to perform image matching. The combination of image retrieval and Monte Carlo provide the robot with the ability to effectively avoid perceptual aliasing. Additionally, we propose an effective visual localization method, simultaneously employing the global and local CNN features of images to construct discriminative representation for environment, which makes the navigation system more robust to the interference of occlusion, translation, and illumination. Extensive experimental results demonstrate that ERF-IMCS exhibits great performance in the robustness and efficiency of navigation.
C1 [Xu, Song; Zhou, Huaidong; Chou, Wusheng] Beihang Univ, Sch Mech Engn & Automat, Beijing 100191, Peoples R China.
   [Chou, Wusheng] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Xu, S (corresponding author), Beihang Univ, Sch Mech Engn & Automat, Beijing 100191, Peoples R China.
EM keithxs@buaa.edu.cn; hdzhou@buaa.edu.cn; wschou@buaa.edu.cn
FU National Key R&D Program of China [2019YFB1310802]
CR Maldonado-Ramirez AA, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9020261
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI 10.1109/CVPR.2016.572
   Babenko A, 2015, IEEE I CONF COMP VIS, V0, PP1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bista SR, 2017, IEEE INT C INT ROBOT, V0, P2960
   Blochliger F, 2018, IEEE INT CONF ROBOT, V0, P3818
   Byju AP, 2020, IEEE T GEOSCI REMOTE, V58, P5739, DOI 10.1109/TGRS.2020.2969374
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen XH, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9071352
   Cheng HT, 2015, IEEE T AUTOM SCI ENG, V12, P729, DOI 10.1109/TASE.2014.2351814
   Chum O, 2007, IEEE I CONF COMP VIS, V0, PP496, DOI 10.1109/cvpr.2007.383172
   Ferro M, 2019, IEEE ROBOT AUTOM LET, V4, P2691, DOI 10.1109/LRA.2019.2913077
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Hao J, 2016, ARXIV161101640, V0, P0
   Jegou H, 2014, PROC CVPR IEEE, V0, PP3310, DOI 10.1109/CVPR.2014.417
   Jegou H, 2010, PROC CVPR IEEE, V0, PP3304, DOI 10.1109/CVPR.2010.5540039
   Jing F, 2005, IEEE T IMAGE PROCESS, V14, P979, DOI 10.1109/TIP.2005.847289
   Joe Yue-Hei Ng, 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP53, DOI 10.1109/CVPRW.2015.7301272
   Jose A, 2018, IEEE IMAGE PROC, V0, PP480, DOI 10.1109/ICIP.2018.8451361
   Kalantidis Y, 2011, MULTIMED TOOLS APPL, V51, P555, DOI 10.1007/s11042-010-0651-7
   Li MH, 2013, ENG APPL ARTIF INTEL, V26, P1942, DOI 10.1016/j.engappai.2013.05.010
   Liu M, 2014, IEEE T ROBOT, V30, P310, DOI 10.1109/TRO.2013.2272250
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo RZ, 2020, PSYCHOL HEALTH MED, V25, P389, DOI 10.1080/13548506.2019.1659985
   Ma JY, 2017, IEEE ACCESS, V5, P20707, DOI 10.1109/ACCESS.2017.2757765
   Mansourian L, 2018, MULTIMED TOOLS APPL, V77, P16131, DOI 10.1007/s11042-017-5192-x
   Marinho LB, 2017, EXPERT SYST APPL, V72, P1, DOI 10.1016/j.eswa.2016.12.007
   Park S, 2016, IEEE T ROBOT, V32, P528, DOI 10.1109/TRO.2016.2544301
   Perronnin F, 2007, PROC CVPR IEEE, V0, P2272
   Philbin J, 2008, PROC CVPR IEEE, V0, P2285
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Salvador A, 2016, IEEE COMPUT SOC CONF, V0, PP394, DOI 10.1109/CVPRW.2016.56
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662
   Shalev O, 2020, IEEE ROBOT AUTOM LET, V5, P2403, DOI 10.1109/LRA.2020.2970975
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8
   Thrun S., 2005, PROBABILISTIC ROBOTI, V0, P0, DOI DOI 10.1108/03684920610675292
   Tolias G., 2016, P 4 INT C LEARN REPR, V0, P0
   Valiente D, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7121294
   Wang JQ, 2006, IEEE T SYST MAN CY B, V36, P413, DOI 10.1109/TSMCB.2005.859085
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 46
TC 0
Z9 0
U1 4
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD OCT 15
PY 2020
VL 10
IS 19
BP 
EP 
DI 10.3390/app10196829
PG 18
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA OO2JF
UT WOS:000587209800001
DA 2023-04-26
ER

PT J
AU Duan, WW
   Chiang, YY
   Leyk, S
   Uhl, JH
   Knoblock, CA
AF Duan, Weiwei
   Chiang, Yao-Yi
   Leyk, Stefan
   Uhl, Johannes H.
   Knoblock, Craig A.
TI Automatic alignment of contemporary vector data and georeferenced historical maps using reinforcement learning
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Vector-to-raster alignment; reinforcement learning; USGS historical topographic maps; digital map processing; digital humanities
AB With large amounts of digital map archives becoming available, automatically extracting information from scanned historical maps is needed for many domains that require long-term historical geographic data. Convolutional Neural Networks (CNN) are powerful techniques that can be used for extracting locations of geographic features from scanned maps if sufficient representative training data are available. Existing spatial data can provide the approximate locations of corresponding geographic features in historical maps and thus be useful to annotate training data automatically. However, the feature representations, publication date, production scales, and spatial reference systems of contemporary vector data are typically very different from those of historical maps. Hence, such auxiliary data cannot be directly used for annotation of the precise locations of the features of interest in the scanned historical maps. This research introduces an automatic vector-to-raster alignment algorithm based on reinforcement learning to annotate precise locations of geographic features on scanned maps. This paper models the alignment problem using the reinforcement learning framework, which enables informed, efficient searches for matching features without pre-processing steps, such as extracting specific feature signatures (e.g. road intersections). The experimental results show that our algorithm can be applied to various features (roads, water lines, and railroads) and achieve high accuracy.
C1 [Duan, Weiwei] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90007 USA.
   [Chiang, Yao-Yi] Univ Southern Calif, Spatial Sci Inst, Los Angeles, CA 90007 USA.
   [Leyk, Stefan; Uhl, Johannes H.] Univ Colorado, Dept Geog, Boulder, CO 80309 USA.
   [Knoblock, Craig A.] Univ Southern Calif, Informat Sci Inst, Los Angeles, CA 90007 USA.
C3 University of Southern California; University of Southern California; University of Colorado System; University of Colorado Boulder; University of Southern California
RP Duan, WW (corresponding author), Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90007 USA.
EM weiweidu@usc.edu
FU National Science Foundation [1563933,1564164]
CR [Anonymous], 2015, ICLR, V0, P0
   Chen B, 2014, INT GEOSCI REMOTE SE, V0, PP4958, DOI 10.1109/IGARSS.2014.6947608
   Chen CC, 2006, GEOINFORMATICA, V10, P495, DOI 10.1007/s10707-006-0344-6
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chiang YY, 2015, GEOINFORMATICA, V19, P1, DOI 10.1007/s10707-014-0203-9
   Chiang YY, 2014, ACM COMPUT SURV, V47, P0, DOI 10.1145/2557423
   Duan WJ, 2018, J HAPPINESS STUD, V19, P1045, DOI 10.1007/s10902-017-9864-z
   Heipke C., 1997, INT ARCH PHOTOGRAMM, VXXXII, P151
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Le Moigne J, 2002, IEEE T GEOSCI REMOTE, V40, P1849, DOI 10.1109/TGRS.2002.802501
   Leyk S, 2010, GEOINFORMATICA, V14, P1, DOI 10.1007/s10707-008-0074-z
   Osmankovic D., 2011, 2011 PROCEEDINGS OF 34TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, V0, P1619
   Ostafin K, 2017, GEOSCI DATA J, V4, P29, DOI 10.1002/gdj3.46
   Razavian A.S., 2014, ARXIV14036382, V0, P0
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Ruiz-Lendinez JJ, 2019, SURV REV, V51, P123, DOI 10.1080/00396265.2017.1388959
   Song WB, 2013, PHOTOGRAMM ENG REM S, V79, P535, DOI 10.14358/PERS.79.6.535
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Sutton RS, 1996, ADV NEUR IN, V8, P1038
   Tong XH, 2009, INT J REMOTE SENS, V30, P5453, DOI 10.1080/01431160903130986
   Touya G., 2018, THESIS, V0, P0
   Uhl J.H., 2017, 8 INT C PATT REC SYS, V0, P1
   Uhl JH, 2018, IET IMAGE PROCESS, V12, P2084, DOI 10.1049/iet-ipr.2018.5484
   Uhl JH, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7040148
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Weiwei Duan, 2017, SIGSPATIAL SPECIAL, V9, P6, DOI 10.1145/3178392.3178396
   Wu X., 2011, US PATENT, V0, Patent No. [7,869,667, 7869667]
   Wu X, 2007, P 15 ANN ACM INT S A, V0, P17
NR 30
TC 11
Z9 14
U1 4
U2 29
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD APR 2
PY 2020
VL 34
IS 4
BP 824
EP 849
DI 10.1080/13658816.2019.1698742
EA DEC 2019
PG 26
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA KS1TX
UT WOS:000501711200001
DA 2023-04-26
ER
