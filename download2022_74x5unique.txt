
PT J
AU Yamaguchi, T
   Mizutani, T
   Meguro, K
   Hirano, T
AF Yamaguchi, Takahiro
   Mizutani, Tsukasa
   Meguro, Kimiro
   Hirano, Takuichi
TI Detecting Subsurface Voids From GPR Images by 3-D Convolutional Neural Network Using 2-D Finite Difference Time Domain Method
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE 3-D convolutional neural network (3D-CNN); deep learning; finite difference time domain (FDTD) method; ground penetrating radar (GPR); subsurface voids
ID ground-penetrating radar; migration; cavity; objects; pipes
AB In this article, an algorithm for detecting subsurface voids under the road from ground penetrating radar images is proposed. A multichannel radar system mounted on vehicle enables dense and highspeed monitoring. The novelty of the algorithm is a unique ElectroMagnetic simulation method and state-of-the-art deep learning technique to consider three-dimensional (3-D) reflection patterns of voids. To train deep learning models, 3-D reflection patterns were reproduced by 2-D finite difference time domain method to drastically reduce the calculation cost. Hyperboloid reflection patterns of voids were extracted by 3-D convolutional neural network (3D-CNN). The classification accuracy of 3D-CNN was up to 90%, about 10% improvement compared to previous 2D-CNN to demonstrate the effectiveness of 3-D subsurface sensing and detection. The results were validated by real void measurement data. After applying trained 3D-CNN to radar data, regions of voids were plotted in a 3-D map, offering clear visualization of areas of voids.
C1 [Yamaguchi, Takahiro; Mizutani, Tsukasa; Meguro, Kimiro] Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan.
   [Hirano, Takuichi] Tokyo City Univ, Dept Elect Elect & Commun Engn, Tokyo 1588557, Japan.
C3 University of Tokyo; Tokyo City University
RP Yamaguchi, T (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan.
EM tyamag@iis.u-tokyo.ac.jp; mizu-t@iis.u-tokyo.ac.jp; meguro@iis.u-tokyo.ac.jp; thirano@tcu.ac.jp
CR Al-Nuaimy W, 2000, J APPL GEOPHYS, V43, P157, DOI 10.1016/S0926-9851(99)00055-5
   Belli K, 2009, IEEE T GEOSCI REMOTE, V47, P3656, DOI 10.1109/TGRS.2009.2016846
   Benedetto A, 2017, SIGNAL PROCESS, V132, P201, DOI 10.1016/j.sigpro.2016.05.016
   BERENGER JP, 1994, J COMPUT PHYS, V114, P185, DOI 10.1006/jcph.1994.1159
   Boniger U, 2012, IEEE T GEOSCI REMOTE, V50, P736, DOI 10.1109/TGRS.2011.2163413
   Cassidy NJ, 2011, J APPL GEOPHYS, V74, P263, DOI 10.1016/j.jappgeo.2011.06.003
   Chen DH, 2008, GEOTECH TEST J, V31, P217
   Daniels D., 2004, GROUND PENETRATING R, V0, P0
   Davis J., 2006, P 23 INT C MACH LEAR, V23, P233, DOI 10.1145/1143844.1143874
   FRIIS HT, 1946, P IRE, V34, P254, DOI 10.1109/JRPROC.1946.234568
   Gamba P, 2000, IEEE T GEOSCI REMOTE, V38, P790, DOI 10.1109/36.842008
   Ge A, 2008, INT J COAL GEOL, V73, P201, DOI 10.1016/j.coal.2007.05.004
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Grandjean G, 2004, J APPL GEOPHYS, V56, P93, DOI 10.1016/j.jappgeo.2004.04.004
   Hayt W. H, 1979, ENG ELECTROMAGNETICS, V1st, P0
   Hugenschmidt J, 2002, CONSTR BUILD MATER, V16, P147, DOI 10.1016/S0950-0618(02)00015-6
   IIZUKA K, 1984, J APPL PHYS, V56, P2572, DOI 10.1063/1.334286
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jol HM, 2009, GROUND PENETRATING RADAR THEORY AND APPLICATIONS, V0, P1
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kawamura N., 2017, J JPN SOC CIVIL ENG, V73, P0
   Lobo JM, 2008, GLOBAL ECOL BIOGEOGR, V17, P145, DOI 10.1111/j.1466-8238.2007.00358.x
   Maierhofer C, 2006, CEMENT CONCRETE COMP, V28, P393, DOI 10.1016/j.cemconcomp.2006.02.011
   Omar T, 2017, AUTOMAT CONSTR, V83, P360, DOI 10.1016/j.autcon.2017.06.024
   PEPLINSKI NR, 1995, IEEE T GEOSCI REMOTE, V33, P803, DOI 10.1109/36.387598
   Sato K., 2015, J JPN SOC CIVIL ENG, V71, P0
   Sato M, 2015, SOILS FOUND, V55, P829, DOI 10.1016/j.sandf.2015.06.014
   Shaari A, 2010, NDT&E INT, V43, P403, DOI 10.1016/j.ndteint.2010.03.006
   Simonyan K, 2015, ARXIV, V0, P0
   Soldovieri F, 2008, IEEE T GEOSCI REMOTE, V46, P3031, DOI 10.1109/TGRS.2008.921959
   Sonoda J., 2018, P ANN C JPN SOC ART, V0, P0
   Sonoda J., 1900, VJ104-C, V0, P60
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Volakis J. L, 2007, ANTENNA ENG HDB, V0, P0
   Wang TL, 2000, GEOPHYSICS, V65, P1560, DOI 10.1190/1.1444844
   Warren C, 2016, COMPUT PHYS COMMUN, V209, P163, DOI 10.1016/j.cpc.2016.08.020
   Yamaguchi T., 2020, THESIS U TOKYO TOKYO, V0, P0
   Yamaguchi T, 2021, IEEE T GEOSCI REMOTE, V59, P6525, DOI 10.1109/TGRS.2020.3030079
   YEE KS, 1966, IEEE T ANTENN PROPAG, VAP14, P302
   Zhao S, 2017, SIGNAL PROCESS, V132, P261, DOI 10.1016/j.sigpro.2016.06.015
   Zhou H, 2005, IEEE T GEOSCI REMOTE, V43, P86, DOI 10.1109/TGRS.2004.839920
NR 48
TC 3
Z9 3
U1 13
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2022
VL 15
IS 
BP 3061
EP 3073
DI 10.1109/JSTARS.2022.3165660
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 0Z1EL
UT WOS:000790822800008
DA 2023-04-26
ER

PT J
AU Niroshan, L
   Carswell, JD
AF Niroshan, Lasith
   Carswell, James D.
TI Post-analysis of OSM-GAN Spatial Change Detection
SO WEB AND WIRELESS GEOGRAPHICAL INFORMATION SYSTEMS
LA English
DT Proceedings Paper
DE Generative Adversarial Networks; OpenStreetMap; Remote sensing; Spatial change detection
AB Keeping crowdsourced maps up-to-date is important for a wide range of location-based applications (route planning, urban planning, navigation, tourism, etc.). We propose a novel map updating mechanism that combines the latest freely available remote sensing data with the current state of online vector map data to train a Deep Learning (DL) neural network. It uses a Generative Adversarial Network (GAN) to perform image-to-image translation, followed by segmentation and raster-vector comparison processes to identify changes to map features (e.g. buildings, roads, etc.) when compared to existing map data. This paper evaluates various GAN models trained with sixteen different datasets designed for use by our change detection/map updating procedure. Each GAN model is evaluated quantitatively and qualitatively to select the most accurate DL model for use in future spatial change detection applications.
C1 [Niroshan, Lasith; Carswell, James D.] Technol Univ Dublin, Dublin, Ireland.
RP Niroshan, L (corresponding author), Technol Univ Dublin, Dublin, Ireland.
EM D19126805@mytudublin.ie; james.carswell@TUDublin.ie
FU Technological University Dublin College of Arts and Tourism, SEED FUNDING INITIATIVE 2019-2020
CR Albert A, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1357, DOI 10.1145/3097983.3098070
   Albrecht CM, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9070427
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Buslaev A, 2018, IEEE COMPUT SOC CONF, V0, PP197, DOI 10.1109/CVPRW.2018.00035
   Cao R, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101553
   Tiecke TG, 2017, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1712.05839
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   He K., 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Iglovikov V, 2018, IEEE COMPUT SOC CONF, V0, PP228, DOI 10.1109/CVPRW.2018.00042
   Isola P, 2017, PROC CVPR IEEE, V0, PP5967, DOI 10.1109/CVPR.2017.632
   Kuo TS, 2018, IEEE COMPUT SOC CONF, V0, PP247, DOI 10.1109/CVPRW.2018.00046
   Lebedev M., 2018, INT ARCH PHOTOGRAM R, V42, P565, DOI 10.5194/isprs-archives-XLII-2-565-2018
   Niroshan L., 2022, SPRINGER LECT NOTES, V0, P0
   Oehmcke S., 2019, ARXIV, V0, P0
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, V0, PP214, DOI 10.1109/IGARSS.2019.8900330
   Rakhlin A, 2018, IEEE COMPUT SOC CONF, V0, PP257, DOI 10.1109/CVPRW.2018.00048
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruan SJ, 2020, AAAI CONF ARTIF INTE, V34, P890
   Schmidhuber J, 2020, ARXIV, V0, P0
   Sun T, 2019, PROC CVPR IEEE, V0, PP7501, DOI 10.1109/CVPR.2019.00769
   Wu SB, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8110478
   Xia W., 2018, P 2 INT EL C REM SEN, V2, P325
   Xia W., 2017, P 2017 INT WORKSHOP, V0, P1
   Yousif O, 2013, IEEE T GEOSCI REMOTE, V51, P2032, DOI 10.1109/TGRS.2013.2245900
   Zhou LC, 2018, IEEE COMPUT SOC CONF, V0, PP192, DOI 10.1109/CVPRW.2018.00034
NR 30
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
J9 LECT NOTES COMPUT SC
PD JUN 15
PY 2022
VL 13238
IS 
BP 28
EP 42
DI 10.1007/978-3-031-06245-2_3
PG 15
WC Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Geography, Physical
SC Computer Science; Physical Geography
GA BU1FD
UT WOS:000877296000003
DA 2023-04-26
ER

PT J
AU Aliabad, FA
   Zare, M
   Solgi, R
   Shojaei, S
AF Aliabad, Fahime Arabi
   Zare, Mohamad
   Solgi, Razieh
   Shojaei, Saeed
TI Comparison of neural network methods (fuzzy ARTMAP, Kohonen and Perceptron) and maximum likelihood efficiency in preparation of land use map
SO GEOJOURNAL
LA English
DT Article; Early Access
DE Maximum likelihood; Yazd plain-Ardakan; Neural network; Supervised classification; Land use
ID cover; classification
AB With the development of various methods in the field of satellite image classification and change detection, especially in recent decades, choosing the best and accurate method for preparation of lands use map and lands cover in different regions has become increasingly grown. For this purpose, classification of satellite images in Yazd plain-Ardakan was done as 7 categories of lands use including (poor pasture, bare lands, residential areas, sand dunes, Semi-dense pasture, agricultural and rocky lands) and then training samples were collected from the area by using 1: 20,000 aerial photos, satellite images, Google Earth and field visit. Then, by using the properties of the images, land-use classes in the study area was chose and after determining the classes` resolution, the classification in a supervised way and by using artificial neural network techniques, Fuzzy ARTMAP, Kohonen, Perceptron and maximum likelihood was done. The aim of this study was to compare the maximum likelihood algorithm and three methods of artificial neural network to classify the land cover in the study area (Yazd plain-Ardakan). The results of evaluation of the accuracy of these four methods showed that the overall accuracy of maximum likelihood classification methods, Kohonen, Fuzzy ARTMAP and Perceptron neural network method is 89/0, 89/0, 87/0 and 23/0 respectively and their kappa coefficient is 91%, 80%, 73% and 21% respectively. Therefore, according to the results, the maximum likelihood method has the best performance in land use mapping in the study area.
C1 [Aliabad, Fahime Arabi; Zare, Mohamad; Shojaei, Saeed] Univ Tehran, Fac Nat Resources, Dept Arid & Mt Reg Reclamat, Tehran, Iran.
   [Solgi, Razieh] Univ Tehran, Res Ctr Imaging Proc, Tehran, Iran.
C3 University of Tehran; University of Tehran
RP Shojaei, S (corresponding author), Univ Tehran, Fac Nat Resources, Dept Arid & Mt Reg Reclamat, Tehran, Iran.
EM S_Shojaei@ut.ac.ir
CR Akbari E., 2014, AMAYESH J, V23, P127
   Al-Ahmadi F. S., 2009, JOURNAL OF KING ABDULAZIZ UNIVERSITY - EARTH SCIENCES, V20, P167, DOI 10.4197/Ear.20-1.9
   Alavipanah SK., 2003, APPL REMOTE SENSING, V0, P0
   Ali-Mohammadi A., 2010, SCI J MANAGEMENT SYS, V9, P7
   [Anonymous], 2007, REMOTE SENSING ENV E, V0, P0
   [Anonymous], 2009, ASSESSING ACCURACY R, V0, P0
   [Anonymous], 2006, REMOTE SENSING DIGIT, V0, P0
   CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B
   Coleou T., 2003, LEAD EDGE, V22, P942, DOI 10.1190/1.1623635
   CONGALTON RG, 1993, PHOTOGRAMM ENG REM S, V59, P641
   DEFRIES RS, 1994, INT J REMOTE SENS, V15, P3567, DOI 10.1080/01431169408954345
   Fatemi B., 2011, BASICS REMOTE SENSIN, V2nd, P0
   Fathizadeh H., 2015, RANGE DESERT RES, V22, P72
   Fayos J, 2007, PLOS ONE, V2, P0, DOI 10.1371/journal.pone.0000210
   Foody GM, 2000, J INTELL ROBOT SYST, V29, P433, DOI 10.1023/A:1008112125526
   Gil-Sanchez L, 2015, APPL SOFT COMPUT, V30, P421, DOI 10.1016/j.asoc.2014.12.037
   Hosseini Aria E., 2003, P C HIGH RES MAPP, V0, P0
   Izarazo I.`, 2006, P 2 WORKSHOP EARSEL, V0, P292
   Knorn J, 2009, REMOTE SENS ENVIRON, V113, P957, DOI 10.1016/j.rse.2009.01.010
   Kohonen T, 1997, NEURAL COMPUT, V9, P1321, DOI 10.1162/neco.1997.9.6.1321
   Koomen E, 2007, GEOJOURNAL LIB, V90, P1
   Liu XH, 2002, ISPRS J PHOTOGRAMM, V56, P257, DOI 10.1016/S0924-2716(02)00061-8
   Mas JF, 2003, INT GEOSCI REMOTE SE, V0, P3498
   Mirzapour H., 2020, J GEOMATICS SCI TECH, V9, P201
   Mukherjee A, 1997, J COMPUT CIVIL ENG, V11, P74, DOI 10.1061/(ASCE)0887-3801(1997)11:1(74)
   Niyazi Y., 2011, GEOGRAPHY DEV IRANIA, V8, P119
   Omo-Irabor O., 2007, 5 INT S SPAT DAT QUA, V0, P0
   Parker DC, 2003, ANN ASSOC AM GEOGR, V93, P314, DOI 10.1111/1467-8306.9302004
   Richards J. A., 1999, REMOTE SENSING DIGIT, V3, P10, DOI 10.1007/978-3-662-03978-6_8
   Shataee Sh., 2007, J AGR SCI NATURAL RE, V14, P129
   Sugumaran R., 2001, GEOCARTO INTERVENTIO, V16, P39, DOI 10.1080/10106040108542192
   Villmann T, 2003, NEURAL NETWORKS, V16, P389, DOI 10.1016/S0893-6080(03)00021-2
   Wijaya A., 2005, THESIS ITC NETHERLAN, V0, P0
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zehtabian GH., 1999, J DESERT, V4, P57
NR 35
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0343-2521
EI 1572-9893
J9 GEOJOURNAL
JI GeoJournal
PD JUN 15
PY 2022
VL 0
IS 
BP 
EP 
DI 10.1007/s10708-022-10744-y
PG 16
WC Geography
SC Geography
GA 4D6KK
UT WOS:000847247600001
DA 2023-04-26
ER

PT J
AU Imperatore, N
   Dumas, L
AF Imperatore, N.
   Dumas, L.
TI CONTRIBUTION OF SUPER RESOLUTION TO 3D RECONSTRUCTION FROM PAIRS OF SATELLITE IMAGES
SO XXIV ISPRS CONGRESS IMAGING TODAY, FORESEEING TOMORROW, COMMISSION II
LA English
DT Proceedings Paper
DE Super resolution; Digital Surface Model; Stereo-Matching; Deep Neural Network; Generative Adversarial Network
AB The photogrammetric 3D stereo reconstruction from pairs of strereo images is rising interest in the past few years in space field downstream. Nowadays, it is conceivable that a large production of DSMs from satellite images can become the primary source of 3D information on a global scale. However, in urban areas, DSMs produced with current technology suffer from poor quality. Indeed, even using very high resolution (VHR) images, there is too little information to generate disparity maps that reproduce very well defined shaped objects such as buildings. To address this issue, one solution may be to artificially increase image resolution beyond the sensor limits. Super resolution (SR) algorithms are designed to recover high frequencies, introducing significant information in a scene characterized by strong and frequent discontinuities such as a city. State-of-the-art methods relying on Deep Learning have shown remarkable results in this sense. The aim of this work is therefore to assess the contribution of single image SR Deep Learning techniques to the stereo matching and DSMs generation in an urban context, highlighting potential advantages and limitations that can show up when introducing such a technology in a multi-view stereo pipeline. The proposed contributions are: a methodology for super resolution of VHR data that takes into account realistic simulation of a satellite product; a testbed for the evaluation of the impact of super resolution on 3D photogrammetric reconstruction; a local analysis of the consequences of deep learning SR of VHR images on stereo matching.
C1 [Imperatore, N.; Dumas, L.] CS, 5 Rue Brindejonc des Moulinaid, Toulouse 5, France.
RP Imperatore, N (corresponding author), CS, 5 Rue Brindejonc des Moulinaid, Toulouse 5, France.
CR Anwar S, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3390462
   Burdziakowski P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162586
   Burdziakowski P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050810
   Cournet M., 2020, INT ARCH PHOTOGRAMME, V43, P127, DOI 10.5194/ISPRS
   Defonte Veronique, 2021, 2021 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM IGARSS, V0, PP7670, DOI 10.1109/IGARSS47720.2021.9553726
   Deliot P, 2006, PROC SPIE, V6031, P0, DOI 10.1117/12.667894
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hohle J, 2009, ISPRS J PHOTOGRAMM, V64, P398, DOI 10.1016/j.isprsjprs.2009.02.003
   Kim J, 2016, PROC CVPR IEEE, V0, PP1637, DOI 10.1109/CVPR.2016.181
   Lebe`gue L., 2020, INT ARCH PHOTOGRAMME, V43, P299
   Haut JM, 2018, IEEE T GEOSCI REMOTE, V56, P6792, DOI 10.1109/TGRS.2018.2843525
   Michel J., 2020, ISPRS ANN PHOTOGRAMM, VVolume V-2-2020, P171, DOI 10.5194/isprs-annals-V-2-2020-171-2020
   Pashaei M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111757
   Sarrazin E., 2021, INT ARCH PHOTOGRAMME, V43, P383
   Szeliski R, 2004, IEEE T PATTERN ANAL, V26, P419, DOI 10.1109/TPAMI.2004.1262341
   Tsagkatakis G, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19183929
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Zhang YJ, 2019, PHOTOGRAMM ENG REM S, V85, P765, DOI 10.14358/PERS.85.10.765
   Zhang YL, 2018, PROC CVPR IEEE, V0, PP2472, DOI 10.1109/CVPR.2018.00262
NR 20
TC 1
Z9 1
U1 1
U2 1
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 2194-9042
EI 2194-9050
J9 ISPRS ANN PHOTO REM
PD JUN 15
PY 2022
VL 5-2
IS 
BP 61
EP 68
DI 10.5194/isprs-annals-V-2-2022-61-2022
PG 8
WC Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA BT8SC
UT WOS:000855196400010
DA 2023-04-26
ER

PT J
AU van Geffen, F
   Heim, B
   Brieger, F
   Geng, RW
   Shevtsova, IA
   Schulte, L
   Stuenzi, SM
   Bernhardt, N
   Troeva, EI
   Pestryakova, LA
   Zakharov, ES
   Pflug, B
   Herzschuh, U
   Kruse, S
AF van Geffen, Femke
   Heim, Birgit
   Brieger, Frederic
   Geng, Rongwei
   Shevtsova, Iuliia A.
   Schulte, Luise
   Stuenzi, Simone M.
   Bernhardt, Nadine
   Troeva, Elena, I
   Pestryakova, Luidmila A.
   Zakharov, Evgenii S.
   Pflug, Bringfried
   Herzschuh, Ulrike
   Kruse, Stefan
TI SiDroForest: a comprehensive forest inventory of Siberian boreal forest investigations including drone-based point clouds, individually labeled trees, synthetically generated tree crowns, and Sentinel-2 labeled image patches
SO EARTH SYSTEM SCIENCE DATA
LA English
DT Article
ID climate-change
AB The SiDroForest (Siberian drone-mapped forest inventory) data collection is an attempt to remedy the scarcity of forest structure data in the circumboreal region by providing adjusted and labeled tree-level and vegetation plot-level data for machine learning and upscaling purposes. We present datasets of vegetation composition and tree and plot level forest structure for two important vegetation transition zones in Siberia, Russia; the summergreen-evergreen transition zone in Central Yakutia and the tundra-taiga transition zone in Chukotka (NE Siberia). The SiDroForest data collection consists of four datasets that contain different complementary data types that together support in-depth analyses from different perspectives of Siberian Forest plot data for multi-purpose applications. i. Dataset 1 provides unmanned aerial vehicle (UAV)-borne data products covering the vegetation plots surveyed during fieldwork (Kruse et al., 2021, ). The dataset includes structure-from-motion (SfM) point clouds and red-green-blue (RGB) and red-green-near-infrared (RGN) orthomosaics. From the orthomosaics, point-cloud products were created such as the digital elevation model (DEM), canopy height model (CHM), digital surface model (DSM) and the digital terrain model (DTM). The point-cloud products provide information on the three-dimensional (3D) structure of the forest at each plot. Dataset 2 contains spatial data in the form of point and polygon shapefiles of 872 individually labeled trees and shrubs that were recorded during fieldwork at the same vegetation plots (van Geffen et al., 2021c, ). The dataset contains information on tree height, crown diameter, and species type. These tree and shrub individually labeled point and polygon shapefiles were generated on top of the RGB UVA orthoimages. The individual tree information collected during the expedition such as tree height, crown diameter, and vitality are provided in table format. This dataset can be used to link individual information on trees to the location of the specific tree in the SfM point clouds, providing for example, opportunity to validate the extracted tree height from the first dataset. The dataset provides unique insights into the current state of individual trees and shrubs and allows for monitoring the effects of climate change on these individuals in the future. Dataset 3 contains a synthesis of 10 000 generated images and masks that have the tree crowns of two species of larch ( and ) automatically extracted from the RGB UAV images in the common objects in context (COCO) format (van Geffen et al., 2021a, ). As machine-learning algorithms need a large dataset to train on, the synthetic dataset was specifically created to be used for machine-learning algorithms to detect Siberian larch species. Larix gmeliniiLarix cajanderiDataset 4 contains Sentinel-2 (S-2) Level-2 bottom-of-atmosphere processed labeled image patches with seasonal information and annotated vegetation categories covering the vegetation plots (van Geffen et al., 2021b, ). The dataset is created with the aim of providing a small ready-to-use validation and training dataset to be used in various vegetation-related machine-learning tasks. It enhances the data collection as it allows classification of a larger area with the provided vegetation classes. The SiDroForest data collection serves a variety of user communities. The detailed vegetation cover and structure information in the first two datasets are of use for ecological applications, on one hand for summergreen and evergreen needle-leaf forests and also for tundra-taiga ecotones. Datasets 1 and 2 further support the generation and validation of land cover remote-sensing products in radar and optical remote sensing. In addition to providing information on forest structure and vegetation composition of the vegetation plots, the third and fourth datasets are prepared as training and validation data for machine-learning purposes. For example, the synthetic tree-crown dataset is generated from the raw UAV images and optimized to be used in neural networks. Furthermore, the fourth SiDroForest dataset contains S-2 labeled image patches processed to a high standard that provide training data on vegetation class categories for machine-learning classification with JavaScript Object Notation (JSON) labels provided. The SiDroForest data collection adds unique insights into remote hard-to-reach circumboreal forest regions.
C1 [van Geffen, Femke; Heim, Birgit; Brieger, Frederic; Geng, Rongwei; Shevtsova, Iuliia A.; Schulte, Luise; Stuenzi, Simone M.; Bernhardt, Nadine; Herzschuh, Ulrike; Kruse, Stefan] Helmholtz Ctr Polar & Marine Res, Alfred Wegener Inst AWI, Res Unit Potsdam, Bremerhaven, Germany.
   [van Geffen, Femke; Shevtsova, Iuliia A.; Schulte, Luise; Herzschuh, Ulrike] Univ Potsdam, Inst Biochem & Biol, Potsdam, Germany.
   [Brieger, Frederic] Carleton Univ, Dept Geog & Environm Studies, Ottawa, ON, Canada.
   [Geng, Rongwei] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, Key Lab Land Surface Pattern & Simulat, Beijing, Peoples R China.
   [Geng, Rongwei] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Stuenzi, Simone M.] Humboldt Univ, Geog Dept, Berlin, Germany.
   [Bernhardt, Nadine] Julius Kuhn Inst Bundesforschungsinst Kulturpflan, Quedlinburg, Germany.
   [Troeva, Elena, I; Zakharov, Evgenii S.] Russian Acad Sci, Inst Biol Problems Cryolithozone, Siberian Branch, Yakutsk, Russia.
   [Pestryakova, Luidmila A.; Zakharov, Evgenii S.] North Eastern Fed Univ Yakutsk, Inst Nat Sci NEFU, Yakutsk, Russia.
   [Pflug, Bringfried] German Aerosp Ctr DLR, Berlin, Germany.
   [Herzschuh, Ulrike] Univ Potsdam, Inst Environm Sci & Geog, Potsdam, Germany.
C3 Helmholtz Association; Alfred Wegener Institute, Helmholtz Centre for Polar & Marine Research; University of Potsdam; Carleton University; Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Humboldt University of Berlin; Julius Kuhn-Institut; Institute for Biological Problems of Cryolithozone; Russian Academy of Sciences; North-Eastern Federal University in Yakutsk; Helmholtz Association; German Aerospace Centre (DLR); University of Potsdam
RP van Geffen, F; Kruse, S (corresponding author), Helmholtz Ctr Polar & Marine Res, Alfred Wegener Inst AWI, Res Unit Potsdam, Bremerhaven, Germany.; van Geffen, F (corresponding author), Univ Potsdam, Inst Biochem & Biol, Potsdam, Germany.
EM femke.van.geffen@awi.de; stefan.kruse@awi.de
FU ERC [772852]
CR Abdi AM, 2020, GISCI REMOTE SENS, V57, P1, DOI 10.1080/15481603.2019.1650447
   Agisoft LLC, 2018, AGISOFT PHOTOSCAN PR, V0, P0
   [Anonymous], 2022, CLOUDCOMPARE CLOUDCO, V0, P0
   [Anonymous], 2017, P IEEE INT C COMP VI, V0, P0
   Astola H, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13122392
   Beamish A, 2020, REMOTE SENS ENVIRON, V246, P0, DOI 10.1016/j.rse.2020.111872
   Bonan GB, 2008, SCIENCE, V320, P1444, DOI 10.1126/science.1155121
   Braga JRG, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081288
   Brieger F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121447
   CAVM Team, 2003, CONSERVATION ARCTIC, V0, P0
   Chave J, 2019, SURV GEOPHYS, V40, P863, DOI 10.1007/s10712-019-09528-w
   Cherosov, 2010, FAR N PLANT BIODIVER, V3, P0
   Copernicus, 2021, COP DIG EL MOD PROD, V0, P0
   ESA (European Space Agency), 2021, SEN2COR SOFTW REL NO, V0, P0
   ESA (European Space Agency), 2015, SENT 2 US HDB, V2, P0
   Fraser RH, 2016, ARCT SCI, V2, P79, DOI 10.1139/as-2016-0008
   Hao ZB, 2021, ISPRS J PHOTOGRAMM, V178, P112, DOI 10.1016/j.isprsjprs.2021.06.003
   Herzschuh U, 2020, GLOBAL ECOL BIOGEOGR, V29, P198, DOI 10.1111/geb.13018
   Jensen JLR, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010050
   Kelley A., 2019, GITHUB REPOSITORY, V0, P0
   Kruse S., 2019, REP POLAR MAR RES, V734, P0, DOI 10.2312/BzPM_0734_2019
   Kruse S., 2021, PANGAEA, V0, P0, DOI DOI 10.1594/PANGAEA.933263
   Lin Tsung-Yi, 2014, P 31 EUR C COMP VIS, V0, P740
   Long Y., 2020, ARXIV, V0, P0
   Loranty MM, 2018, BIOGEOSCIENCES, V15, P5287, DOI 10.5194/bg-15-5287-2018
   MacDonald GM, 2008, PHILOS T R SOC B, V363, P2285, DOI 10.1098/rstb.2007.2200
   Mamet SD, 2019, J BIOGEOGR, V46, P30, DOI 10.1111/jbi.13465
   Montesano PM, 2014, REMOTE SENS ENVIRON, V154, P398, DOI 10.1016/j.rse.2014.01.027
   Montesano PM, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070551
   Panagiotidis D, 2017, INT J REMOTE SENS, V38, P2392, DOI 10.1080/01431161.2016.1264028
   Noi PT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010018
   Plowright A., 2021, FORESTTOOLS ANAL REM, V0, P0
   Rees WG, 2020, GLOBAL CHANGE BIOL, V26, P3965, DOI 10.1111/gcb.15113
   Schepaschenko D, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0196-1
   Schepaschenko D, 2017, SCI DATA, V4, P0, DOI 10.1038/sdata.2017.70
   Shevtsova I., 1900, DOI 10.1594/PANGAEA.923664, V0, P0
   Shevtsova I, 2021, BIOGEOSCIENCES, V18, P3343, DOI 10.5194/bg-18-3343-2021
   Shevtsova I, 2020, ENVIRON RES LETT, V15, P0, DOI 10.1088/1748-9326/ab9059
   Simard M, 2011, J GEOPHYS RES-BIOGEO, V116, P0, DOI 10.1029/2011JG001708
   Sumbul G, 2019, INT GEOSCI REMOTE SE, V0, PP5901, DOI 10.1109/IGARSS.2019.8900532
   The GIMP Development Team, 2019, GIMP, V0, P0
   Walker DA, 2005, J VEG SCI, V16, P267, DOI 10.1111/j.1654-1103.2005.tb02365.x
   Wang DZ, 2020, INT J APPL EARTH OBS, V85, P0, DOI 10.1016/j.jag.2019.101986
   Weinstein B, 2021, ELIFE, V10, P0, DOI 10.7554/eLife.62922
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111309
   Xiao K., 2020, ARXIV, V0, P0
   Zhang WM, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060501
NR 48
TC 0
Z9 0
U1 5
U2 5
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1866-3508
EI 1866-3516
J9 EARTH SYST SCI DATA
JI Earth Syst. Sci. Data
PD NOV 11
PY 2022
VL 14
IS 11
BP 4967
EP 4994
DI 10.5194/essd-14-4967-2022
PG 28
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences
SC Geology; Meteorology & Atmospheric Sciences
GA 6I8XI
UT WOS:000886413700001
DA 2023-04-26
ER
