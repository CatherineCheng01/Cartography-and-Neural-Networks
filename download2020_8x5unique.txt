
PT J
AU Gao, F
   Lin, JH
   Liu, HR
   Lu, SF
AF Gao, Fei
   Lin, Junhui
   Liu, Haoran
   Lu, Shufang
TI A Novel VBM Framework of Fiber Recognition Based on Image Segmentation and DCNN
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Optical fiber networks; Image segmentation; Optical fiber testing; Optical fiber sensors; Training; Fabrics; Optical fiber cables; Deep convolutional neural networks (DCNNs); fiber recognition; image segmentation; object recognition; vision-based measurement (VBM)
ID foreign fibers; cotton; vision; identification; classification; instrument
AB Manual approaches of fiber recognition are often time-consuming, laborious, and subjective. In this paper, a novel vision-based measurement (VBM) framework of fiber recognition based on image segmentation and deep convolutional neural networks (DCNNs) is proposed. The proposed segmentation method can be applied to the segmentation of overlapping and adhering translucent fibers and has better segmentation performance. At the same time, the segmentation method provides a large number of single-fiber training samples and test samples for DCNN and provides a basis for multifiber map recognition using voting strategies. Finally, four frequently used kinds of fibers, i.e., cotton, camel hair, viscose, and yak cashmere, are selected for experiments. In order to decrease the chance of overfitting, the data augmentation methods are utilized to enlarge the data sets formed by the segmented single-fiber images. In the experimental phase, performance differences are evaluated between the four network architectures, namely, AlexNet, cashmere and wool classification-Net, VGG-Net-16, and GoogLeNet. The GoogLeNet & x2019;s single-fiber classification accuracy rate reaches 96.6 & x0025;, and the average accuracy rate of multifiber identification strategy reaches 99.5 & x0025;. The results show that the proposed VBM framework of fiber recognition is effective.
C1 [Gao, Fei; Lin, Junhui; Liu, Haoran; Lu, Shufang] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Technology
RP Gao, F (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
EM feig@zjut.edu.cn
FU National Natural Science Foundation of China [61402410]; Zhejiang Provincial Science and Technology Planning Key Project of China [2018C01064]; Zhejiang Provincial Natural Science Foundation of China [LY19F020027]
CR Bel PD, 2010, TEXT RES J, V80, P1047, DOI 10.1177/0040517509352516
   [陈晓春 Chen Xiaochun], 2017, 纺织学报 JOURNAL OF TEXTILE RESEARCH, V38, P143
   Di Ruberto C, 2002, IMAGE VISION COMPUT, V20, P133, DOI 10.1016/S0262-8856(01)00092-0
   [丁伟杰 DING Weijie], 2007, 计算机工程与应用 COMPUTER ENGINEERING AND APPLICATION, V43, P70
   Grau V, 2004, IEEE T MED IMAGING, V23, P447, DOI 10.1109/TMI.2004.824224
   He W, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P397, DOI 10.1109/ICAL.2008.4636183
   Ilea DE, 2011, PATTERN RECOGN, V44, P2479, DOI 10.1016/j.patcog.2011.03.005
   Ji RH, 2010, MATH COMPUT MODEL, V51, P1433, DOI 10.1016/j.mcm.2009.10.007
   Jia DY, 2004, CONFERENCE DIGEST OF THE 2004 JOINT 29TH INTERNATIONAL CONFERENCE ON INFRARED AND MILLIMETER WAVES AND 12TH INTERNATIONAL CONFERENCE ON TERAHERTZ ELECTRONICS, V0, P751
   [贾立锋 JIA Lifeng], 2011, 纺织学报 JOURNAL OF TEXTILE RESEARCH, V32, P43
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Li BL, 2018, IEEE T INSTRUM MEAS, V67, P497, DOI 10.1109/TIM.2017.2684558
   Li DL, 2010, COMPUT ELECTRON AGR, V74, P274, DOI 10.1016/j.compag.2010.09.002
   Li Q, 2015, PROC SPIE, V9618, P0, DOI 10.1117/12.2193132
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Rizvandi NB, 2008, LECT NOTES COMPUT SC, V5112, P817, DOI 10.1007/978-3-540-69812-8_81
   Schneider D, 2015, IEEE T INSTRUM MEAS, V64, P1063, DOI 10.1109/TIM.2014.2363580
   Shirmohammadi S, 2014, IEEE INSTRU MEAS MAG, V17, P41, DOI 10.1109/MIM.2014.6825388
   Shu-Yuan Shang, 2010, 2010 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS (ICMLC 2010), V0, PP833, DOI 10.1109/ICMLC.2010.5580587
   Song AG, 2014, IEEE T INSTRUM MEAS, V63, P1739, DOI 10.1109/TIM.2013.2293812
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tao Weisen, 2018, CHINA TEXTILE SCIENCE, V0, P1
   Turner C, 2017, IEEE T INSTRUM MEAS, V66, P1668, DOI 10.1109/TIM.2017.2666203
   Wang F, 2018, INT J CLOTH SCI TECH, V30, P710, DOI 10.1108/IJCST-11-2017-0171
   Wang X, 2015, COMPUT ELECTR ENG, V46, P500, DOI 10.1016/j.compeleceng.2015.06.022
   Wang X, 2011, IEEE T INSTRUM MEAS, V60, P44, DOI 10.1109/TIM.2010.2069850
   Yanez-Suarez O, 1999, IEEE T INSTRUM MEAS, V48, P55, DOI 10.1109/19.755060
   Zhang LW, 2005, REAL-TIME IMAGING, V11, P257, DOI 10.1016/j.rti.2004.09.003
   Zhao XH, 2016, IEEE ACCESS, V4, P8465, DOI 10.1109/ACCESS.2016.2615520
NR 31
TC 16
Z9 16
U1 2
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PD APR 15
PY 2020
VL 69
IS 4
BP 963
EP 973
DI 10.1109/TIM.2019.2912238
PG 11
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Engineering; Instruments & Instrumentation
GA KW4VG
UT WOS:000521163500003
DA 2023-04-26
ER

PT J
AU Luo, ZP
   Liu, D
   Li, J
   Chen, YP
   Xiao, ZL
   Marcato, J
   Goncalves, WN
   Wang, C
AF Luo, Zhipeng
   Liu, Di
   Li, Jonathan
   Chen, Yiping
   Xiao, Zhenlong
   Marcato Junior, Jose
   Goncalves, Wesley Nunes
   Wang, Cheng
TI Learning sequential slice representation with an attention-embedding network for 3D shape recognition and retrieval in MLS point clouds
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE MLS point clouds; Sequential slice representation; Shape recognition; Shape retrieval; Deep learning; Embedding attention strategy
ID laser-scanning data; object recognition; automated extraction; neural-networks; road markings; mobile; surface; features; registration; information
AB The representation of 3D data is the key issue for shape analysis. However, most of the existing representations suffer from high computational cost and structure information loss. This paper presents a novel sequential slice representation with an attention-embedding network, named RSSNet, for 3D point cloud recognition and retrieval in road environments. RSSNet has two main branches. Firstly, a sequential slice module is designed to map disordered 3D point clouds to ordered sequence of shallow feature vectors. A gated recurrent unit (GRU) module is applied to encode the spatial and content information of these sequential vectors. The second branch consists of a key-point based graph convolution network (GCN) with an embedding attention strategy to fuse the sequential and global features to refine the structure discriminability. Three datasets were used to evaluate the proposed method, one acquired by our mobile laser scanning (MLS) system and two public datasets (KITTI and Sydney Urban Objects). Experimental results indicated that the proposed method achieved better performance than recognition and retrieval state-of-the-art methods. RSSNet provided recognition rates of 98.08%, 95.77% and 70.83% for the above three datasets, respectively. For the retrieval task, RSSNet obtained excellent mAP values of 95.56%, 87.16% and 69.99% on three datasets, respectively.
C1 [Luo, Zhipeng; Liu, Di; Li, Jonathan; Chen, Yiping; Xiao, Zhenlong; Wang, Cheng] Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart Cities, 422 Siming Rd South, Xiamen 361005, Fujian, Peoples R China.
   [Li, Jonathan] Univ Waterloo, Dept Geog & Environm Management, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
   [Li, Jonathan] Univ Waterloo, Dept Syst Design Eng, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
   [Marcato Junior, Jose; Goncalves, Wesley Nunes] Univ Fed Mato Grosso do Sul, Fac Engn Architecture & Urbanism & Geog, Costa & Silva Ave, BR-79070900 Campo Grande, MS, Brazil.
C3 Xiamen University; University of Waterloo; University of Waterloo; Universidade Federal de Mato Grosso do Sul
RP Li, J (corresponding author), Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart Cities, 422 Siming Rd South, Xiamen 361005, Fujian, Peoples R China.
EM junli@xmu.edu.cn
FU National Natural Science Foundation of China [1471379, 41871380, 61371144, U1605254]; Natural Sciences and Engineering Research Council of Canada [50503-10284]; CNPq [304173/2016-9]; CAPES/Print [88881.311850/2018-01]
CR Bai S, 2016, PROC CVPR IEEE, V0, PP5023, DOI 10.1109/CVPR.2016.543
   Boulch A, 2018, COMPUT GRAPH-UK, V71, P189, DOI 10.1016/j.cag.2017.11.010
   Broggi A, 2013, IEEE T INTELL TRANSP, V14, P1403, DOI 10.1109/TITS.2013.2262331
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Caicedo JC, 2015, IEEE I CONF COMP VIS, V0, PP2488, DOI 10.1109/ICCV.2015.286
   Cao CS, 2015, IEEE I CONF COMP VIS, V0, PP2956, DOI 10.1109/ICCV.2015.338
   Chen XZ, 2017, PROC CVPR IEEE, V0, PP6526, DOI 10.1109/CVPR.2017.691
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Davis JE, 2006, DEAF WAY II READER: PERSPECTIVES FROM THE SECOND INTERNATIONAL CONFERENCE ON DEAF CULTURE, V0, P233
   Deuge M. D, 2013, AUSTR C ROB AUT ARAA, V0, P1097
   Feng YF, 2018, PROC CVPR IEEE, V0, PP264, DOI 10.1109/CVPR.2018.00035
   Gonzalez A, 2017, IEEE T CYBERNETICS, V47, P3980, DOI 10.1109/TCYB.2016.2593940
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Gressin A, 2013, ISPRS J PHOTOGRAMM, V79, P240, DOI 10.1016/j.isprsjprs.2013.02.019
   Guan HY, 2014, ISPRS J PHOTOGRAMM, V87, P93, DOI 10.1016/j.isprsjprs.2013.11.005
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2015, INFORM SCIENCES, V293, P196, DOI 10.1016/j.ins.2014.09.015
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hoffman J, 2016, PROC CVPR IEEE, V0, PP826, DOI 10.1109/CVPR.2016.96
   Holopainen M, 2013, URBAN FOR URBAN GREE, V12, P546, DOI 10.1016/j.ufug.2013.06.002
   Hori C, 2017, IEEE I CONF COMP VIS, V0, PP4203, DOI 10.1109/ICCV.2017.450
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ioannidou A, 2017, ACM COMPUT SURV, V50, P0, DOI 10.1145/3042064
   Johns E, 2016, PROC CVPR IEEE, V0, PP3813, DOI 10.1109/CVPR.2016.414
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Klokov R, 2017, IEEE I CONF COMP VIS, V0, PP863, DOI 10.1109/ICCV.2017.99
   Kumar P, 2014, INT J APPL EARTH OBS, V32, P125, DOI 10.1016/j.jag.2014.03.023
   Li YY, 2018, ADV NEUR IN, V31, P0
   Lin CH, 2014, ISPRS J PHOTOGRAMM, V94, P70, DOI 10.1016/j.isprsjprs.2014.04.016
   Luo ZP, 2019, ISPRS J PHOTOGRAMM, V150, P44, DOI 10.1016/j.isprsjprs.2019.01.024
   Ma C, 2019, IEEE T MULTIMEDIA, V21, P1169, DOI 10.1109/TMM.2018.2875512
   Ma C, 2019, IEEE T INSTRUM MEAS, V68, P38, DOI 10.1109/TIM.2018.2840598
   Ma YW, 2017, INT CONF ADV COMMUN, V0, PP199, DOI 10.23919/ICACT.2017.7890083
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Pu S, 2011, ISPRS J PHOTOGRAMM, V66, PS28, DOI 10.1016/j.isprsjprs.2011.08.006
   Qi CR, 2017, ADV NEUR IN, V30, P0
   Qi CR, 2016, PROC CVPR IEEE, V0, PP5648, DOI 10.1109/CVPR.2016.609
   Qin NN, 2018, ISPRS J PHOTOGRAMM, V143, P205, DOI 10.1016/j.isprsjprs.2018.03.011
   Riegler G, 2017, PROC CVPR IEEE, V0, PP6620, DOI 10.1109/CVPR.2017.701
   Rusu RB, 2010, IEEE INT C INT ROBOT, V0, PP2155, DOI 10.1109/IROS.2010.5651280
   Rusu RB, 2009, IEEE INT CONF ROBOT, V0, P1848
   Rutzinger M, 2011, PHOTOGRAMM REC, V26, P361, DOI 10.1111/j.1477-9730.2011.00635.x
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Serna A, 2013, ISPRS J PHOTOGRAMM, V84, P23, DOI 10.1016/j.isprsjprs.2013.07.001
   Shang LM, 2010, INT J COMPUT VISION, V89, P211, DOI 10.1007/s11263-009-0276-3
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Song SR, 2016, PROC CVPR IEEE, V0, PP808, DOI 10.1109/CVPR.2016.94
   Su H, 2015, IEEE I CONF COMP VIS, V0, PP945, DOI 10.1109/ICCV.2015.114
   Sutskever I., 2014, ADV NEURAL INF PROCE, V2, P3104, DOI 10.48550/ARXIV.1409.3215
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, V0, PP2107, DOI 10.1109/ICCV.2017.230
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang J, 2016, PROC CVPR IEEE, V0, PP2285, DOI 10.1109/CVPR.2016.251
   Wang PS, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3072959.3073608
   Wang YX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP1267, DOI 10.1145/3343031.3351004
   Wen CL, 2016, IEEE GEOSCI REMOTE S, V13, P992, DOI 10.1109/LGRS.2016.2558486
   Wu WX, 2019, PROC CVPR IEEE, V0, PP9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, V0, PP1912, DOI 10.1109/CVPR.2015.7298801
   Xiao TJ, 2015, PROC CVPR IEEE, V0, PP842, DOI 10.1109/CVPR.2015.7298685
   Xuanhan Wang, 2017, IEEE SIGNAL PROCESSING LETTERS, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yang BS, 2017, ISPRS J PHOTOGRAMM, V130, P329, DOI 10.1016/j.isprsjprs.2017.06.007
   Yang BS, 2015, ISPRS J PHOTOGRAMM, V99, P45, DOI 10.1016/j.isprsjprs.2014.10.005
   Yoo D, 2015, IEEE I CONF COMP VIS, V0, PP2659, DOI 10.1109/ICCV.2015.305
   Yu YT, 2016, IEEE T GEOSCI REMOTE, V54, P4130, DOI 10.1109/TGRS.2016.2537830
   Yu YT, 2015, IEEE T INTELL TRANSP, V16, P2167, DOI 10.1109/TITS.2015.2399492
   Yu YT, 2015, IEEE J-STARS, V8, P709, DOI 10.1109/JSTARS.2014.2347276
   Yu YT, 2015, IEEE T GEOSCI REMOTE, V53, P1374, DOI 10.1109/TGRS.2014.2338915
   Zai DW, 2017, ISPRS J PHOTOGRAMM, V134, P15, DOI 10.1016/j.isprsjprs.2017.10.001
   Zhi S, 2017, P EUROGRAPHICS WORKS, V0, P9
   Zhou L, 2012, INT J APPL EARTH OBS, V18, P293, DOI 10.1016/j.jag.2012.01.024
NR 82
TC 8
Z9 9
U1 5
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAR 15
PY 2020
VL 161
IS 
BP 147
EP 163
DI 10.1016/j.isprsjprs.2020.01.003
PG 17
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA KR8EU
UT WOS:000517849600012
DA 2023-04-26
ER

PT J
AU Sang, XJ
   Xue, LF
   Ran, XJ
   Li, XS
   Liu, JW
   Liu, ZY
AF Sang, Xuejia
   Xue, Linfu
   Ran, Xiangjin
   Li, Xiaoshun
   Liu, Jiwen
   Liu, Zeyu
TI Intelligent High-Resolution Geological Mapping Based on SLIC-CNN
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE geological survey; geological mapping; deep learning; SLIC-CNN; UAV; ductile shear zone
ID neural-network; image-analysis
AB High-resolution geological mapping is an important supporting condition for mineral and energy exploration. However, high-resolution geological mapping work still faces many problems. At present, high-resolution geological mapping is still generated by expert interpretation of survey lines, compasses, and field data. The work in the field is constrained by the weather, terrain, and personnel, and the working methods need to be improved. This paper proposes a new method for high-resolution mapping using Unmanned Aerial Vehicle (UAV) and deep learning algorithms. This method uses the UAV to collect high-resolution remote sensing images, cooperates with some groundwork to anchor the lithology, and then completes most of the mapping work on high-resolution remote sensing images. This method transfers a large amount of field work into the room and provides an automatic mapping process based on the Simple Linear Iterative Clustering-Convolutional Neural Network (SLIC-CNN) algorithm. It uses the convolutional neural network (CNN) to identify the image content and confirms the lithologic distribution, the simple linear iterative cluster (SLIC) algorithm can be used to outline the boundary of the rock mass and determine the contact interface of the rock mass, and the mode and expert decision method is used to clarify the results of the fusion and mapping. The mapping method was applied to the Taili waterfront in Xingcheng City, Liaoning Province, China. In this study, the Area Under the Curve (AUC) of the mapping method was 0.937. The Kappa test result was k = 0.8523, and a high-resolution geological map was obtained.
C1 [Sang, Xuejia; Li, Xiaoshun] China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
   [Sang, Xuejia] Minist Nat Resource, Key Lab Coastal Zone Exploitat & Protect, Nanjing 210019, Peoples R China.
   [Xue, Linfu; Liu, Jiwen; Liu, Zeyu] Jilin Univ, Coll Earth Sci, Changchun 130061, Peoples R China.
   [Ran, Xiangjin] Jilin Univ, Coll Appl Technol, Changchun 130061, Peoples R China.
C3 China University of Mining & Technology; Jilin University; Jilin University
RP Li, XS (corresponding author), China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
EM sangxj@cumt.edu.cn; xuelf@jlu.edu.cn; ranxiangjin@jlu.edu.cn; lxsh@cumt.edu.cn; jwliu2213@mails.jlu.edu.cn; zyliu17@mails.jlu.edu.cn
FU National Natural Science Foundation of China [71704177, 71874192]; Open Fund of Key Laboratory of Coastal Zone Exploitation and Protection, Ministry of Natural Resource [2019CZEPK11]; Fundamental Research Funds for the Central Universities [2019CXNL08, 2019ZDPY-RH02]
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI 10.1145/3022670.2976746
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Almalki KA, 2017, J MAPS, V13, P900, DOI 10.1080/17445647.2017.1401492
   Balestro G, 2007, B SOC GEOL ITAL, V126, P487
   Bejiga MB, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9020100
   Bemis SP, 2014, J STRUCT GEOL, V69, P163, DOI 10.1016/j.jsg.2014.10.007
   Bouvrie J., 2006, PRACTICES, V0, PP47, DOI 10.1016/J.PROTCY.2014.09.007
   Chatterjee S, 2010, COMPUT IND, V61, P391, DOI 10.1016/j.compind.2009.10.003
   Cracknell MJ, 2013, GEOPHYSICS, V78, PWB113, DOI 10.1190/GEO2012-0411.1
   Derksen D, 2019, IEEE T GEOSCI REMOTE, V57, P3073, DOI 10.1109/TGRS.2018.2880248
   Ferreira A, 2017, EXPERT SYST APPL, V84, P1, DOI 10.1016/j.eswa.2017.04.053
   Fu G, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050498
   Guidici D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060629
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He Z, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101042
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Holden D, 2016, ACM T GRAPHIC, V35, P0, DOI 10.1145/2897824.2925975
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Jia F, 2018, NEUROCOMPUTING, V272, P619, DOI 10.1016/j.neucom.2017.07.032
   Jing LY, 2017, MEASUREMENT, V111, P1, DOI 10.1016/j.measurement.2017.07.017
   Jones R.R., 2004, GEOLOGICAL PRIOR INF, V239, P43, DOI 10.1144/GSL.SP.2004.239.01.04
   Krizhevsky A., 2012, NEURAL INF PROCESS S, V25, P1145
   Kroupi E, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.024525
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lary DJ, 2016, GEOSCI FRONT, V7, P3, DOI 10.1016/j.gsf.2015.07.003
   Latifovic R, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020307
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   [李健 Li Jian], 2014, 吉林大学学报. 地球科学版 JOURNAL OF JILIN UNIVERSITY. EARTH SCIENCE EDITION, V44, P1219
   Li WM, 2017, J ASIAN EARTH SCI, V139, P202, DOI 10.1016/j.jseaes.2017.01.020
   Li XJ, 2015, REMOTE SENS-BASEL, V7, P9705, DOI 10.3390/rs70809705
   Liang C.Y., 2015, THESIS, V0, PP1, DOI 10.31274/ETD-180810-4122
   Liang CY, 2015, J STRUCT GEOL, V78, P27, DOI 10.1016/j.jsg.2015.06.007
   Liang CY, 2015, TECTONOPHYSICS, V650, P80, DOI 10.1016/j.tecto.2014.05.010
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lu L, 2019, 2019 8 INT C AGRO GE, V0, PP1, DOI 10.1109/Agro-Geoinformatics.2019.8820692
   [罗威 Luo Wei], 2014, 世界地质 GLOBAL GEOLOGY, V33, P844
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Machado G.M., 2017, OCEAN COAST MANAGE, V10, P151
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Martins J, 2019, INT GEOSCI REMOTE SE, V0, PP6543, DOI 10.1109/IGARSS.2019.8898969
   Mukherjee DP, 2009, PATTERN RECOGN LETT, V30, P615, DOI 10.1016/j.patrec.2008.12.015
   Patel AK, 2016, GEOSCI FRONT, V7, P53, DOI 10.1016/j.gsf.2014.10.005
   Ran XJ, 2019, MATHEMATICS-BASEL, V7, P0, DOI 10.3390/math7080755
   Sajjad M, 2019, PATTERN RECOGN LETT, V126, P123, DOI 10.1016/j.patrec.2018.02.015
   Santos JA, 2010, INT GEOSCI REMOTE SE, V0, PP3418, DOI 10.1109/IGARSS.2010.5650273
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Tam VWY, 2019, FRONT ENG MANAG, V6, P395, DOI 10.1007/s42524-019-0019-2
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Tao YT, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121328
   Tziavou O., 2017, ENG GEOL, V11, P232
   Vasuki Y, 2017, COMPUT GEOSCI-UK, V100, P27, DOI 10.1016/j.cageo.2016.12.001
   Vasuki Y, 2014, COMPUT GEOSCI-UK, V69, P22, DOI 10.1016/j.cageo.2014.04.012
   [王庆龙 Wang Qinglong], 2012, 世界地质 WORLD GEOLOGY, V31, P479
   Wu FY, 2006, ACTA PETROL SIN, V22, P315
   Yang ML, 2017, NEUROCOMPUTING, V267, P195, DOI 10.1016/j.neucom.2017.06.007
   Yuxiang Z., 2019, IEEE GEOSCI REMOTE S, V0, P0
   Zheng CG, 2013, APPL MECH MATER, V239-240, P516, DOI 10.4028/www.scientific.net/AMM.239-240.516
NR 59
TC 12
Z9 14
U1 8
U2 36
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD FEB 15
PY 2020
VL 9
IS 2
BP 
EP 
DI 10.3390/ijgi9020099
PG 23
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA KY3CX
UT WOS:000522449700039
DA 2023-04-26
ER

PT J
AU Yang, QQ
   Yuan, QQ
   Yue, LW
   Li, TW
   Shen, HF
   Zhang, LP
AF Yang, Qianqian
   Yuan, Qiangqiang
   Yue, Linwei
   Li, Tongwen
   Shen, Huanfeng
   Zhang, Liangpei
TI Mapping PM2.5 concentration at a sub-km level resolution: A dual-scale retrieval approach
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE PM2.5; Retrieval; Aerosol optical depth; High resolution; Dual-scale; Scale difference
ID aerosol optical depth; geographically weighted regression; particulate matter pm2.5; satellite-derived pm2.5; air-pollution; meteorological variables; china; land; mortality; region
AB Satellite-based retrieval has become a popular PM2.5 monitoring method. To improve the retrieval performance, multiple variables are usually introduced as auxiliary variables, in addition to aerosol optical depth (AOD). The different kinds of variables are usually at different resolutions, varying from sub-kilometer to dozens of kilometers. Generally speaking, when undertaking the retrieval, the variables at different resolutions are resampled to the same resolution as the AOD product to ensure scale consistency (single-scale retrieval). However, a drawback of doi ng this is that the information contained within the different resolutions (scales) is discarded. To fully utilize the information contained in the different scales, a dual-scale retrieval approach is proposed in this paper. In the first stage, the variables which influence PM2.5 concentration at a large scale are used for PM2.5 retrieval at a coarse resolution. Then, in the second stage, the variables which affect PM2.5 distribution at a finer scale are used for the further PM2.5 retrieval at a high resolution (sub-km level resolution), with the retrieved low-resolution PM2.5 from the first stage also acting as input. In this study, four different regression models were adopted to test the performance of the dual-scale retrieval approach at both daily and annual scales: multiple linear regression (MLR), geographically weighted regression (GWR), random forest (RF), and the generalized regression neural network (GRNN). Compared with the traditional single-scale retrieval approach, the proposed dual-scale retrieval approach can achieve PM2.5 mapping at a finer resolution and with a higher accuracy. Dual-scale retrieval can utilize the information contained in different scales, thus achieving an improvement in both resolution and retrieval accuracy. The proposed approach has the potential to be used for the generation of quantitative remote sensing products in various fields, and will promote the quality improvement of these quantitative remote sensing products.
C1 [Yang, Qianqian; Yuan, Qiangqiang] Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430079, Peoples R China.
   [Yuan, Qiangqiang] Wuhan Univ, Key Lab Geospace Environm & Geodesy, Minist Educ, Wuhan 430079, Peoples R China.
   [Yue, Linwei] China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
   [Li, Tongwen; Shen, Huanfeng] Wuhan Univ, Sch Resource & Environm Sci, Wuhan 430079, Peoples R China.
   [Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn, Survey Mapping & Remote Sensing, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University; China University of Geosciences; Wuhan University; Wuhan University
RP Yuan, QQ (corresponding author), Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430079, Peoples R China.; Li, TW (corresponding author), Wuhan Univ, Sch Resource & Environm Sci, Wuhan 430079, Peoples R China.
EM qqyuan@sgg.whu.edu.cn; litw@whu.edu.cn
FU Strategic Priority Research Program of the Chinese Academy of Sciences [XDA19090104]; National Natural Science Foundation of China [41922008]; Fundamental Research Funds for the Central Universities of Wuhan Univeristy [2042019kf0213]; Science and Technology Major Project of Hubei Province [2019AAA046]
CR Beloconi A, 2016, REMOTE SENS ENVIRON, V172, P148, DOI 10.1016/j.rse.2015.10.017
   Bi JZ, 2019, REMOTE SENS ENVIRON, V221, P665, DOI 10.1016/j.rse.2018.12.002
   Bottenberg R.A., 1963, APPL MULTIPLE LINEAR, V63, P0
   Boys BL, 2014, ENVIRON SCI TECHNOL, V48, P11109, DOI 10.1021/es502113p
   Brunsdon C, 1996, GEOGR ANAL, V28, P281, DOI 10.1111/j.1538-4632.1996.tb00936.x
   Cao C, 2016, NAT COMMUN, V7, P0, DOI 10.1038/ncomms12509
   Chen GB, 2018, SCI TOTAL ENVIRON, V636, P52, DOI 10.1016/j.scitotenv.2018.04.251
   Chen RJ, 2019, ENVIRON HEALTH PERSP, V127, P0, DOI 10.1289/EHP2711
   Chen Z., 2017, J POWER ENERGY ENG, V5, P1
   Chung C. E., 2012, ATMOSPHERIC AEROSOLS, V0, PP379, DOI 10.5772/50248
   Cigizoglu HK, 2006, ADV ENG SOFTW, V37, P63, DOI 10.1016/j.advengsoft.2005.05.002
   de Hoogh K, 2018, ENVIRON POLLUT, V233, P1147, DOI 10.1016/j.envpol.2017.10.025
   Guo JP, 2009, ATMOS ENVIRON, V43, P5876, DOI 10.1016/j.atmosenv.2009.08.026
   Guo YX, 2017, REMOTE SENS ENVIRON, V198, P140, DOI 10.1016/j.rse.2017.06.001
   Gupta P, 2006, ATMOS ENVIRON, V40, P5880, DOI 10.1016/j.atmosenv.2006.03.016
   He QS, 2018, SCI TOTAL ENVIRON, V612, P1417, DOI 10.1016/j.scitotenv.2017.09.027
   He QQ, 2018, REMOTE SENS ENVIRON, V206, P72, DOI 10.1016/j.rse.2017.12.018
   Ho HC, 2018, ENVIRON POLLUT, V235, P155, DOI 10.1016/j.envpol.2017.12.047
   Hu XF, 2017, ENVIRON SCI TECHNOL, V51, P6936, DOI 10.1021/acs.est.7b01210
   Hu XF, 2014, REMOTE SENS ENVIRON, V140, P220, DOI 10.1016/j.rse.2013.08.032
   Huang KY, 2018, ENVIRON POLLUT, V242, P675, DOI 10.1016/j.envpol.2018.07.016
   Jackson JM, 2013, J GEOPHYS RES-ATMOS, V118, P12673, DOI 10.1002/2013JD020449
   Jiang M, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040346
   Jung CR, 2018, ENVIRON POLLUT, V237, P1000, DOI 10.1016/j.envpol.2017.11.016
   Lelieveld J, 2015, NATURE, V525, P367, DOI 10.1038/nature15371
   Levy RC, 2013, ATMOS MEAS TECH, V6, P2989, DOI 10.5194/amt-6-2989-2013
   Levy RC, 2007, J GEOPHYS RES-ATMOS, V112, P0, DOI 10.1029/2006JD007811
   Li GD, 2016, ENVIRON SCI TECHNOL, V50, P11452, DOI 10.1021/acs.est.6b02562
   Li TW, 2017, GEOPHYS RES LETT, V44, P11985, DOI 10.1002/2017GL075710
   Li TW, 2017, ATMOS ENVIRON, V152, P477, DOI 10.1016/j.atmosenv.2017.01.004
   Liu N, 2021, ANIM BIOTECHNOL, V32, P213, DOI 10.1080/10495398.2019.1677682
   Ma ZW, 2016, ENVIRON HEALTH PERSP, V124, P184, DOI 10.1289/ehp.1409481
   Ma ZW, 2014, ENVIRON SCI TECHNOL, V48, P7436, DOI 10.1021/es5009399
   Ning GC, 2018, SCI TOTAL ENVIRON, V612, P975, DOI 10.1016/j.scitotenv.2017.08.205
   Peng J, 2017, REV GEOPHYS, V55, P341, DOI 10.1002/2016RG000543
   Shi YL, 2015, MT RES DEV, V35, P180, DOI 10.1659/MRD-JOURNAL-D-14-00119.1
   Della Ceca LS, 2018, ISPRS J PHOTOGRAMM, V145, P250, DOI 10.1016/j.isprsjprs.2018.08.016
   Stafoggia M, 2019, ENVIRON INT, V124, P170, DOI 10.1016/j.envint.2019.01.016
   Tai APK, 2010, ATMOS ENVIRON, V44, P3976, DOI 10.1016/j.atmosenv.2010.06.060
   Tian J, 2010, REMOTE SENS ENVIRON, V114, P221, DOI 10.1016/j.rse.2009.09.011
   van Donkelaar A, 2015, ENVIRON SCI TECHNOL, V49, P10482, DOI 10.1021/acs.est.5b02076
   van Donkelaar A, 2010, ENVIRON HEALTH PERSP, V118, P847, DOI 10.1289/ehp.0901623
   Wang Y, 2019, ISPRS J PHOTOGRAMM, V157, P1, DOI 10.1016/j.isprsjprs.2019.08.017
   Wang Y, 2019, ATMOS ENVIRON, V200, P280, DOI 10.1016/j.atmosenv.2018.12.023
   Wei X, 2019, CLUSTER COMPUTING, V0, P1
   Xiao QY, 2017, REMOTE SENS ENVIRON, V199, P437, DOI 10.1016/j.rse.2017.07.023
   Xu YM, 2018, ENVIRON POLLUT, V242, P1417, DOI 10.1016/j.envpol.2018.08.029
   Xue T, 2019, ENVIRON INT, V123, P345, DOI 10.1016/j.envint.2018.11.075
   Yang QQ, 2017, INT J ENV RES PUB HE, V14, P0, DOI 10.3390/ijerph14121510
   Yang XF, 2017, ENVIRON POLLUT, V226, P143, DOI 10.1016/j.envpol.2017.03.079
   Yuan QQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121440
   Yue LW, 2017, ISPRS J PHOTOGRAMM, V123, P20, DOI 10.1016/j.isprsjprs.2016.11.002
   Yue LW, 2015, INT J GEOGR INF SCI, V29, P2095, DOI 10.1080/13658816.2015.1063639
   Zhang TH, 2018, REMOTE SENS ENVIRON, V216, P91, DOI 10.1016/j.rse.2018.06.030
   Zhao XD, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9101912
NR 58
TC 19
Z9 20
U1 1
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUL 15
PY 2020
VL 165
IS 
BP 140
EP 151
DI 10.1016/j.isprsjprs.2020.05.018
PG 12
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA LY2SN
UT WOS:000540373500012
DA 2023-04-26
ER

PT J
AU Geng, J
   Jiang, W
   Deng, XY
AF Geng, Jie
   Jiang, Wen
   Deng, Xinyang
TI Multi-scale deep feature learning network with bilateral filtering for SAR image classification
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE SAR image classification; Deep neural networks; Feature learning; Bilateral filtering
ID convolutional neural-network
AB Synthetic aperture radar (SAR) image classification using deep neural network has drawn great attention, which generally requires various layers of deep model for feature learning. However, a deeper neural network will result in overfitting with limited training samples. In this paper, a multi-scale deep feature learning network with bilateral filtering (MDFLN-BF) is proposed for SAR image classification, which aims to extract discriminative features and reduce the requirement of labeled samples. In the proposed framework, MDFLN is proposed to extract features from SAR image on multiple scales, where the SAR image is stratified into different scales and a full convolutional network is utilized to extract features from each scale sub-image. Then, features of multiple scales are classified by multiple softmax classifiers and combined by majority vote algorithm. Further, bilateral filtering is developed to optimize the classification map based on spatial relation, which aims to improve the spatial smoothness. Experiments are tested on three SAR images with different sensors, bands, resolutions, and polarizations in order to prove the generalization ability. It is demonstrated that the proposed MDFLN-BF is able to yield superior results than other related deep networks.
C1 [Geng, Jie; Jiang, Wen; Deng, Xinyang] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Geng, J (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM gengjie@nwpu.edu.cn
FU National Natural Science Foundation of China [61901376]
CR Bai XR, 2019, IEEE T GEOSCI REMOTE, V57, P9223, DOI 10.1109/TGRS.2019.2925636
   Caraffa L, 2015, IEEE T IMAGE PROCESS, V24, P1199, DOI 10.1109/TIP.2015.2389617
   Chen SW, 2018, IEEE GEOSCI REMOTE S, V15, P627, DOI 10.1109/LGRS.2018.2799877
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Deng XY, 2019, INT J APPROX REASON, V106, P194, DOI 10.1016/j.ijar.2019.01.007
   Dong G, 2007, IEEE SIGNAL PROC LET, V14, P617, DOI 10.1109/LSP.2007.894966
   Du PJ, 2015, ISPRS J PHOTOGRAMM, V105, P38, DOI 10.1016/j.isprsjprs.2015.03.002
   Dumitru CO, 2015, IEEE J-STARS, V8, P1635, DOI 10.1109/JSTARS.2014.2363595
   Gao F, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060846
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Geng J, 2018, IEEE T GEOSCI REMOTE, V56, P2255, DOI 10.1109/TGRS.2017.2777868
   Geng J, 2017, IEEE T GEOSCI REMOTE, V55, P2442, DOI 10.1109/TGRS.2016.2645226
   Geng J, 2015, IEEE GEOSCI REMOTE S, V12, P2351, DOI 10.1109/LGRS.2015.2478256
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hou B, 2016, IEEE GEOSCI REMOTE S, V13, P33, DOI 10.1109/LGRS.2015.2493242
   Jiang GQ, 2019, IEEE T IND ELECTRON, V66, P3196, DOI 10.1109/TIE.2018.2844805
   Jiang W, 2020, IEEE T FUZZY SYST, V28, P1585, DOI 10.1109/TFUZZ.2019.2918999
   Jie Geng, 2019, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Khosravi I, 2018, INT J REMOTE SENS, V39, P7547, DOI 10.1080/01431161.2018.1471543
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P2707, DOI 10.1109/TNNLS.2018.2885799
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma ZY, 2019, IEEE T VEH TECHNOL, V68, P3224, DOI 10.1109/TVT.2019.2899972
   Mohammadimanesh F, 2019, ISPRS J PHOTOGRAMM, V151, P223, DOI 10.1016/j.isprsjprs.2019.03.015
   Moreira A, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2248301
   Mou LC, 2018, IEEE T GEOSCI REMOTE, V56, P6699, DOI 10.1109/TGRS.2018.2841808
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Qin FC, 2017, REMOTE SENS LETT, V8, P204, DOI 10.1080/2150704X.2016.1258128
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI 10.1162/NECO_a_00990
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Tombak A, 2019, IEEE GEOSCI REMOTE S, V16, P564, DOI 10.1109/LGRS.2018.2879880
   Vedaldi A, 2015, MM15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, V0, PP689, DOI 10.1145/2733373.2807412
   Wang J, 2018, IEEE J-STARS, V11, P4180, DOI 10.1109/JSTARS.2018.2871556
   Wang Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020342
   Wang ZY, 2019, IEEE T IMAGE PROCESS, V28, P2530, DOI 10.1109/TIP.2018.2887017
   Xie W, 2017, IEEE J-STARS, V10, P3604, DOI 10.1109/JSTARS.2017.2698076
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
   Zhao ZQ, 2017, PATTERN RECOGN, V61, P686, DOI 10.1016/j.patcog.2016.05.028
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zhu XX, 2014, IEEE SIGNAL PROC MAG, V31, P51, DOI 10.1109/MSP.2014.2312098
NR 47
TC 32
Z9 32
U1 7
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD SEP 15
PY 2020
VL 167
IS 
BP 201
EP 213
DI 10.1016/j.isprsjprs.2020.07.007
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA NC6SC
UT WOS:000561346200015
DA 2023-04-26
ER
