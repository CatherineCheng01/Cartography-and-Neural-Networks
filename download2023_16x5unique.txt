
PT J
AU Zhang, Y
   Liu, PY
   Biljecki, F
AF Zhang, Yan
   Liu, Pengyuan
   Biljecki, Filip
TI Knowledge and topology: A two layer spatially dependent graph neural networks to identify urban functions with time-series street view image
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE GeoAI; Natural language processing; GeoKG; Pretrained model; Knowledge graph; Multi-modal
ID points-of-interest; land-use; remote; areas
AB With the rise of GeoAI research, streetscape imagery has received extensive attention due to its comprehensive coverage, abundant information, and accessibility. However, obtaining a holistic spatial-temporal scene representation is difficult because places are often composed of multiple images from different angles, times and locations. This problem also exists in other types of geo-tagged imagery. To solve it, we propose a purely visual, robust, and reliable method for urban function identification at the street scale. We introduce a method based on a two-layer spatially dependent graph neural network structure, which handles sequential street view imagery as input (typically available in services such as Google Street View, Baidu Maps, and Mapillary), with full consideration of the spatial dependencies among road networks. In this paper, we construct an urban topological map network using OpenStreetMap data in Wuhan, China, and compute a semantic representation of the scene as a whole at the street scale using a large-scale pre-trained model. We construct the graph network with streets as nodes based on 28,693 mapping relationships constructed from 75,628 street view images and 5,458 streets. Only 5.3% of the node labels were required to obtain 10 categories of functions for all nodes in the study area. The results demonstrate that by using appropriate spatial weights, street encoder, and graph structure, our novel method achieves high accuracy of P@1 46.2%, P@3 73.0%, P@5 82.4%, and P@10 89.9%, fully demonstrating the effectiveness of the introduced approach. We also use the model to sense urban spatial-temporal renewal by computing time series street images. The model is also applicable to the prediction of other attributes, where only a small number of labels are required to obtain valid and reliable scene perception results. The example data and code is shared at: https://github.com/yemanzhongting/Knowledge-and-Topology.
C1 [Zhang, Yan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & Re, Wuhan, Peoples R China.
   [Zhang, Yan; Liu, Pengyuan; Biljecki, Filip] Natl Univ Singapore, Dept Architecture, Singapore, Singapore.
   [Biljecki, Filip] Natl Univ Singapore, Dept Real Estate, Singapore, Singapore.
C3 Wuhan University; National University of Singapore; National University of Singapore
RP Biljecki, F (corresponding author), Natl Univ Singapore, Dept Architecture, Singapore, Singapore.; Biljecki, F (corresponding author), Natl Univ Singapore, Dept Real Estate, Singapore, Singapore.
EM sggzhang@whu.edu.cn; pyliu93@nus.edu.sg; filip@nus.edu.sg
FU National Key RD Program [2018YFB2100500]; National Nature Science Foundation of China [41971351]; Singapore Ministry of Education Academic Research Fund Tier 1 (project Multi-scale Digital Twins for the Urban Environment: From Heartbeats to Cities)
CR Abdelrahman MM, 2022, BUILD ENVIRON, V218, P0, DOI 10.1016/j.buildenv.2022.109090
   Amiruzzaman M, 2021, J COMPUT SOC SCI, V4, P813, DOI 10.1007/s42001-021-00107-x
   Anderson P, 2018, PROC CVPR IEEE, V0, PP6077, DOI 10.1109/CVPR.2018.00636
   Biljecki F, 2022, COMPUT ENVIRON URBAN, V95, P0, DOI 10.1016/j.compenvurbsys.2022.101809
   Biljecki F, 2021, LANDSCAPE URBAN PLAN, V215, P0, DOI 10.1016/j.landurbplan.2021.104217
   Bruna J, 2014, ARXIV, V0, P0
   Campbell A, 2019, COMPUT ENVIRON URBAN, V77, P0, DOI 10.1016/j.compenvurbsys.2019.101350
   Cao R, 2020, ISPRS J PHOTOGRAMM, V163, P82, DOI 10.1016/j.isprsjprs.2020.02.014
   Cao R, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101553
   Chadzynski A., 2022, ENERGY, V8, P0
   Chen B, 2021, ISPRS J PHOTOGRAMM, V178, P203, DOI 10.1016/j.isprsjprs.2021.06.010
   Chen L., 2022, CITIES103734, V0, P0
   Chen L, 2020, COMPUT ENVIRON URBAN, V81, P0, DOI 10.1016/j.compenvurbsys.2020.101481
   Chen WY, 2021, COMPUT ENVIRON URBAN, V90, P0, DOI 10.1016/j.compenvurbsys.2021.101706
   Chen YM, 2017, LANDSCAPE URBAN PLAN, V160, P48, DOI 10.1016/j.landurbplan.2016.12.001
   Crooks A, 2015, INT J GEOGR INF SCI, V29, P720, DOI 10.1080/13658816.2014.977905
   Fang F, 2021, INT J GEOGR INF SCI, V35, P1802, DOI 10.1080/13658816.2020.1831515
   Filomena G, 2019, CITIES, V89, P14, DOI 10.1016/j.cities.2019.01.006
   Gao S, 2017, T GIS, V21, P446, DOI 10.1111/tgis.12289
   Ge M., 2010, P 4 ACM C RECOMMENDE, V0, PP257, DOI 10.1145/1864708.1864761
   Georganos S, 2021, GEOCARTO INT, V36, P121, DOI 10.1080/10106049.2019.1595177
   Gong P, 2020, SCI BULL, V65, P182, DOI 10.1016/j.scib.2019.12.007
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Hamilton WL, 2017, ADV NEUR IN, V30, P0
   Hong DF, 2020, ISPRS J PHOTOGRAMM, V167, P12, DOI 10.1016/j.isprsjprs.2020.06.014
   Hossain MZ, 2019, ACM COMPUT SURV, V51, P0, DOI 10.1145/3295748
   Hu CB, 2020, BUILD ENVIRON, V167, P0, DOI 10.1016/j.buildenv.2019.106424
   Hu S, 2021, COMPUT ENVIRON URBAN, V87, P0, DOI 10.1016/j.compenvurbsys.2021.101619
   Hu S, 2020, COMPUT ENVIRON URBAN, V80, P0, DOI 10.1016/j.compenvurbsys.2019.101442
   Huang X, 2021, ISPRS J PHOTOGRAMM, V175, P403, DOI 10.1016/j.isprsjprs.2021.03.019
   Inoue T, 2022, LANDSCAPE URBAN PLAN, V221, P0, DOI 10.1016/j.landurbplan.2022.104357
   Jiasen Lu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10434, DOI 10.1109/CVPR42600.2020.01045
   Kang J, 2018, ISPRS J PHOTOGRAMM, V145, P44, DOI 10.1016/j.isprsjprs.2018.02.006
   Kipf TN, 2016, PROC INT C LEARN REP, V0, P0, DOI DOI 10.48550/ARXIV.1609.02907
   Lai KL, 2022, INFORM PROCESS MANAG, V59, P0, DOI 10.1016/j.ipm.2021.102735
   Lauko IG, 2020, GEO-SPAT INF SCI, V23, P222, DOI 10.1080/10095020.2020.1805367
   Li XT, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030477
   Li YS, 2021, ISPRS J PHOTOGRAMM, V179, P145, DOI 10.1016/j.isprsjprs.2021.08.001
   Li YP, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3102590
   Lin L, 2017, IEEE T PATTERN ANAL, V39, P1089, DOI 10.1109/TPAMI.2016.2567386
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu BH, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11219968
   Liu PY, 2022, INT J APPL EARTH OBS, V112, P0, DOI 10.1016/j.jag.2022.102936
   Liu XP, 2017, INT J GEOGR INF SCI, V31, P1675, DOI 10.1080/13658816.2017.1324976
   Liu YL, 2018, APPL GEOGR, V94, P163, DOI 10.1016/j.apgeog.2018.03.016
   Liu Y, 2015, ANN ASSOC AM GEOGR, V105, P512, DOI 10.1080/00045608.2015.1018773
   Lu WP, 2022, REMOTE SENS ENVIRON, V270, P0, DOI 10.1016/j.rse.2021.112830
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Murali Nirmala, 2022, INNOVATIONS IN COMPUTATIONAL INTELLIGENCE AND COMPUTER VISION: PROCEEDINGS OF ICICV 2021. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (1424), V0, PP465, DOI 10.1007/978-981-19-0475-2_41
   Ning H, 2022, INT J GEOGR INF SCI, V36, P1317, DOI 10.1080/13658816.2021.1981334
   Niu HF, 2021, COMPUT ENVIRON URBAN, V88, P0, DOI 10.1016/j.compenvurbsys.2021.101651
   Paden I, 2022, FRONT BUILT ENVIRON, V8, P0, DOI 10.3389/fbuil.2022.899332
   Qi Y, 2020, GEO-SPAT INF SCI, V23, P341, DOI 10.1080/10095020.2020.1847002
   Qiao ZN, 2021, INT J GEOGR INF SCI, V35, P2129, DOI 10.1080/13658816.2021.1919682
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, V0, PP1179, DOI 10.1109/CVPR.2017.131
   Shen XQ, 2020, KNOWL-BASED SYST, V203, P0, DOI 10.1016/j.knosys.2020.105920
   Song ZL, 2022, ISPRS INT J GEO-INF, V11, P0, DOI 10.3390/ijgi11020072
   Suryowati K, 2018, IOP CONF SER-MAT SCI, V335, P0, DOI 10.1088/1757-899X/335/1/012052
   Traag VA, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-41695-z
   Van de Voorde T, 2011, LANDSCAPE URBAN PLAN, V102, P143, DOI 10.1016/j.landurbplan.2011.03.017
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Veliƒçkovic P, 2018, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1710.10903
   Venerandi A, 2023, ENVIRON PLAN B-URBAN, V50, P386, DOI 10.1177/23998083221115196
   von Richthofen A, 2022, J PLAN LIT, V37, P415, DOI 10.1177/08854122211068526
   Wang JL, 2020, ENVIRON RES LETT, V15, P0, DOI 10.1088/1748-9326/ab9db0
   Wang PX, 2022, IEEE INTERNET THINGS, V9, P16343, DOI 10.1109/JIOT.2022.3151238
   Wang PX, 2022, INT J GEOGR INF SCI, V36, P1231, DOI 10.1080/13658816.2022.2032081
   Wang RY, 2021, SUSTAIN CITIES SOC, V66, P0, DOI 10.1016/j.scs.2020.102664
   Wolf T., 2020, P 2020 C EMP METH NA, V0, PP38, DOI 10.18653/V1/2020.EMNLP-DEMOS.6
   Xu X, 2022, REMOTE SENS-BASEL, V14, P0, DOI 10.3390/rs14040891
   Xu YY, 2022, COMPUT ENVIRON URBAN, V95, P0, DOI 10.1016/j.compenvurbsys.2022.101807
   Xu YY, 2022, INT J GEOGR INF SCI, V36, P2009, DOI 10.1080/13658816.2022.2048834
   Yang M, 2022, INT J APPL EARTH OBS, V108, P0, DOI 10.1016/j.jag.2022.102753
   Yang QQ, 2022, ISPRS J PHOTOGRAMM, V186, P190, DOI 10.1016/j.isprsjprs.2022.02.001
   Yao Y, 2021, INT J GEOGR INF SCI, V35, P1927, DOI 10.1080/13658816.2021.1895170
   Yao Y, 2017, INT J GEOGR INF SCI, V31, P825, DOI 10.1080/13658816.2016.1244608
   Yin JD, 2021, INT J APPL EARTH OBS, V103, P0, DOI 10.1016/j.jag.2021.102514
   Yu B, 2020, TRANSPORT RES C-EMER, V114, P189, DOI 10.1016/j.trc.2020.02.013
   Yu WH, 2017, INT J GEOGR INF SCI, V31, P280, DOI 10.1080/13658816.2016.1194423
   Zhang F, 2021, LANDSCAPE URBAN PLAN, V207, P0, DOI 10.1016/j.landurbplan.2020.104003
   Zhang F, 2020, COMPUT ENVIRON URBAN, V81, P0, DOI 10.1016/j.compenvurbsys.2020.101478
   Zhang F, 2019, ISPRS J PHOTOGRAMM, V153, P48, DOI 10.1016/j.isprsjprs.2019.04.017
   Zhang F, 2018, LANDSCAPE URBAN PLAN, V180, P148, DOI 10.1016/j.landurbplan.2018.08.020
   Zhang S., 2019, COMPUT SOC NETW, V6, P1, DOI 10.1186/S40649-019-0069-Y
   Zhang Y, 2022, INT J APPL EARTH OBS, V113, P0, DOI 10.1016/j.jag.2022.102989
   Zhang Y, 2022, SUSTAIN CITIES SOC, V85, P0, DOI 10.1016/j.scs.2022.104000
   Zhang Y, 2021, J HYDROL, V603, P0, DOI 10.1016/j.jhydrol.2021.127053
   Zhang Y, 2021, BUILD ENVIRON, V198, P0, DOI 10.1016/j.buildenv.2021.107883
   Zhao BG, 2021, IEEE ACCESS, V9, P154086, DOI 10.1109/ACCESS.2021.3128140
   Zhao L, 2020, IEEE T INTELL TRANSP, V21, P3848, DOI 10.1109/TITS.2019.2935152
   Zhao TH, 2022, COMPUT ENVIRON URBAN, V94, P0, DOI 10.1016/j.compenvurbsys.2022.101776
   Zhou GL, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0234522
   Zhu D, 2020, ANN AM ASSOC GEOGR, V110, P408, DOI 10.1080/24694452.2019.1694403
NR 94
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2023
VL 198
IS 
BP 153
EP 168
DI 10.1016/j.isprsjprs.2023.03.008
EA MAR 2023
PG 16
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA A6RU4
UT WOS:000956382200001
DA 2023-04-26
ER

PT J
AU Yang, ZJ
   Diao, CY
   Gao, F
AF Yang, Zijun
   Diao, Chunyuan
   Gao, Feng
TI Towards Scalable Within-Season Crop Mapping With Phenology Normalization and Deep Learning
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Crops; Data models; Remote sensing; MODIS; Deep learning; Market research; Time series analysis; Agriculture; crop mapping; crop phenology; deep learning; remote sensing; time series analysis
ID time-series; satellite data; fusion; classification; landsat; model
AB Crop-type mapping using time-series remote sensing data is crucial for a wide range of agricultural applications. Crop mapping during the growing season is particularly critical in timely monitoring of the agricultural system. Most existing studies focusing on within-season crop mapping leverage historical remote sensing and crop type reference data for model building, due to the difficulty in obtaining timely crop type samples for the current growing season. Yet the crop type samples from previous years may not be used directly considering the diverse patterns of crop phenology across years and locations, which hampers the scalability and transferability of the model to the current season for timely crop mapping. This article proposes an innovative within-season emergence (WISE) phenology normalized deep learning model towards scalable within-season crop mapping. The crop time-series remote sensing data are first normalized by the WISE crop emergence dates before being fed into an attention-based one-dimensional convolutional neural network classifier. Compared to conventional calendar-based approaches, the WISE-phenology normalization approach substantially helps the deep learning crop mapping model accommodate the spatiotemporal variations in crop phenological dynamics. Results in Illinois from 2017 to 2020 indicate that the proposed model outperforms calendar-based approaches and yields over 90% overall accuracy for classifying corn and soybeans at the end of season. During the growing season, the proposed model can give satisfactory performance (85% overall accuracy) one to four weeks earlier than calendar-based approaches. With WISE-phenology normalization, the proposed model exhibits more stable performance across Illinois and can be transferred to different years with enhanced scalability and robustness.
C1 [Yang, Zijun; Diao, Chunyuan] Univ Illinois, Dept Geog & Geog Informat Sci, Urbana, IL 61801 USA.
   [Gao, Feng] USDA ARS, Hydrol & Remote Sensing Lab, Beltsville, MD 20705 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign; United States Department of Agriculture (USDA)
RP Diao, CY (corresponding author), Univ Illinois, Dept Geog & Geog Informat Sci, Urbana, IL 61801 USA.
EM zijuny2@illinois.edu; chunyuan@illinois.edu; feng.gao@ars.usda.gov
FU National Science Foundation [2048068]; National Aeronautics and Space Administration [80NSSC21K0946]; United States Department of Agriculture [2021-67021-33446]; Office of Advanced Cyberinfrastructure (OAC); Direct For Computer & Info Scie & Enginr [2048068] Funding Source: National Science Foundation
CR [Anonymous], 2014, AR5 CLIM CHANG 2014, V0, P0
   Appel G., 2005, TECHNICAL ANAL POWER, V0, P0
   Atzberger C, 2013, REMOTE SENS-BASEL, V5, P949, DOI 10.3390/rs5020949
   Azar R, 2016, EUR J REMOTE SENS, V49, P361, DOI 10.5721/EuJRS20164920
   Beck PSA, 2006, REMOTE SENS ENVIRON, V100, P321, DOI 10.1016/j.rse.2005.10.021
   Begue A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010099
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Burke M, 2017, P NATL ACAD SCI USA, V114, P2189, DOI 10.1073/pnas.1616919114
   Cai YP, 2018, REMOTE SENS ENVIRON, V210, P35, DOI 10.1016/j.rse.2018.02.045
   Diao CY, 2022, REMOTE SENS-BASEL, V14, P0, DOI 10.3390/rs14091957
   Diao CY, 2021, ISPRS J PHOTOGRAMM, V181, P308, DOI 10.1016/j.isprsjprs.2021.09.011
   Diao CY, 2020, REMOTE SENS ENVIRON, V248, P0, DOI 10.1016/j.rse.2020.111960
   Diao CY, 2019, ISPRS J PHOTOGRAMM, V153, P96, DOI 10.1016/j.isprsjprs.2019.04.012
   Fontanelli G, 2022, IEEE J-STARS, V15, P6789, DOI 10.1109/JSTARS.2022.3198475
   Foody GM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111630
   Gao F., 2021, J REMOTE SENS, V2021, P0, DOI 10.34133/2021/8379391
   Gao F, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13245074
   Gao F, 2020, REMOTE SENS ENVIRON, V242, P0, DOI 10.1016/j.rse.2020.111752
   Gao F, 2017, REMOTE SENS ENVIRON, V188, P9, DOI 10.1016/j.rse.2016.11.004
   Irwin S, 2022, FARMDOC DAILY, V12, P1
   Isengildina-Massa O, 2021, J COMMOD MARK, V22, P0, DOI 10.1016/j.jcomm.2020.100137
   Isengildina-Massa O, 2020, J AGRIC APPL ECON, V52, P545, DOI 10.1017/aae.2020.18
   Johnson DM, 2021, REMOTE SENS ENVIRON, V264, P0, DOI 10.1016/j.rse.2021.112576
   Karali B, 2019, FOOD POLICY, V84, P66, DOI 10.1016/j.foodpol.2019.02.005
   Kerner H. R., 2022, SCI REMOTE SENSING, V6, P0, DOI 10.1016/j.srs.2022.100059
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liao CH, 2019, SCI TOTAL ENVIRON, V650, P1707, DOI 10.1016/j.scitotenv.2018.09.308
   Liu LC, 2022, REMOTE SENS ENVIRON, V277, P0, DOI 10.1016/j.rse.2022.113060
   Liu XK, 2020, IEEE J-STARS, V13, P414, DOI 10.1109/JSTARS.2019.2963539
   Lobell DB, 2015, REMOTE SENS ENVIRON, V164, P324, DOI 10.1016/j.rse.2015.04.021
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050523
   Prosekov AY, 2018, GEOFORUM, V91, P73, DOI 10.1016/j.geoforum.2018.02.030
   Russwurm M, 2020, ISPRS J PHOTOGRAMM, V169, P421, DOI 10.1016/j.isprsjprs.2020.06.006
   Sachs J, 2010, NATURE, V466, P558, DOI 10.1038/466558a
   Sakamoto T, 2010, REMOTE SENS ENVIRON, V114, P2146, DOI 10.1016/j.rse.2010.04.019
   Tan ZY, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3050551
   Vose RS, 2014, J APPL METEOROL CLIM, V53, P1232, DOI 10.1175/JAMC-D-13-0248.1
   Wang PJ, 2014, IEEE T GEOSCI REMOTE, V52, P7353, DOI 10.1109/TGRS.2014.2311445
   Wang S, 2019, REMOTE SENS ENVIRON, V222, P303, DOI 10.1016/j.rse.2018.12.026
   Xu JF, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111946
   Yang ZJ, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13245005
   Yaramasu R, 2020, COMPUT ELECTRON AGR, V176, P0, DOI 10.1016/j.compag.2020.105664
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zeng LL, 2016, REMOTE SENS ENVIRON, V181, P237, DOI 10.1016/j.rse.2016.03.039
   Zhang XY, 2018, REMOTE SENS ENVIRON, V216, P212, DOI 10.1016/j.rse.2018.06.047
   Zhang XY, 2003, REMOTE SENS ENVIRON, V84, P471, DOI 10.1016/S0034-4257(02)00135-9
   Zhong LH, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111411
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhong LH, 2014, REMOTE SENS ENVIRON, V140, P1, DOI 10.1016/j.rse.2013.08.023
NR 52
TC 0
Z9 0
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2023
VL 16
IS 
BP 1390
EP 1402
DI 10.1109/JSTARS.2023.3237500
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 8L5GZ
UT WOS:000923811200005
DA 2023-04-26
ER

PT J
AU Baudoux, L
   Inglada, J
   Mallet, C
AF Baudoux, Luc
   Inglada, Jordi
   Mallet, Clement
TI Multi-nomenclature, multi-resolution joint translation: an application to land-cover mapping
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Land-cover; land-use; translation; deep learning; harmonization
ID data fusion; classification; accuracy; challenges; products; generate; datasets; glc2000; maps; area
AB Land-use/land-cover (LULC) maps describe the Earth's surface with discrete classes at a specific spatial resolution. The chosen classes and resolution highly depend on peculiar uses, making it mandatory to develop methods to adapt these characteristics for a large range of applications. Recently, a convolutional neural network (CNN)-based method was introduced to take into account both spatial and geographical context to translate a LULC map into another one. However, this model only works for two maps: one source and one target. Inspired by natural language translation using multiple-language models, this article explores how to translate one LULC map into several targets with distinct nomenclatures and spatial resolutions. We first propose a new data set based on six open access LULC maps to train our CNN-based encoder-decoder framework. We then apply such a framework to convert each of these six maps into each of the others using our Multi-Landcover Translation network (MLCT-Net). Extensive experiments are conducted at a country scale (namely France). The results reveal that our MLCT-Net outperforms its semantic counterparts and gives on par results with mono-LULC models when evaluated on areas similar to those used for training. Furthermore, it outperforms the mono-LULC models when applied to totally new landscapes.
C1 [Baudoux, Luc; Mallet, Clement] Univ Gustave Eiffel, ENSG, IGN, LASTIG, St Mande, France.
   [Inglada, Jordi] Univ Toulouse, CESBIO, CNES, CNRS,IRD,INRAE,UPS, Toulouse, France.
C3 Universite Gustave-Eiffel; INRAE; Universite de Toulouse; Universite Toulouse III - Paul Sabatier; Centre National de la Recherche Scientifique (CNRS); Institut de Recherche pour le Developpement (IRD)
RP Baudoux, L (corresponding author), Univ Gustave Eiffel, ENSG, IGN, LASTIG, St Mande, France.
EM luc.baudoux@ign.fr
FU MAESTRIA project [ANR-18-CE23-0023]; AI4GEO project; Agence Nationale de la Recherche
CR Adamo M, 2014, LANDSCAPE ECOL, V29, P1045, DOI 10.1007/s10980-014-0028-9
   Ahlqvist O, 2005, INT J GEOGR INF SCI, V19, P831, DOI 10.1080/13658810500106729
   Ahlqvist O, 2008, ENVIRON PLANN B, V35, P169, DOI 10.1068/b3344
   Al-Mubaid H, 2009, IEEE T SYST MAN CY C, V39, P389, DOI 10.1109/TSMCC.2009.2020689
   Anderson J. R., 1976, LAND USE LAND COVER, V964, P0
   Arnold S., 2015, LAND USE LAND COVER, V0, P107
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Bartholome E, 2005, INT J REMOTE SENS, V26, P1959, DOI 10.1080/01431160412331291297
   Baudoux L., 2022, MULTIPLE LAND USE LA, V0, P0
   Baudoux L, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13061060
   Bechtel B, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111769
   Brown DG, 2004, INT J GEOGR INF SCI, V18, P35, DOI 10.1080/13658810310001620906
   Buchhorn M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12061044
   Cantelaube P., 2014, CAHIER TECHNIQUES LI, V0, P58
   Cao S., 2020, MULTILINGUAL ALIGNME, V0, P0
   Chakravarty P, 2019, IEEE INT CONF ROBOT, V0, PP147, DOI 10.1109/ICRA.2019.8793530
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cochran W G, 1977, SAMPLING TECHNIQUES, V0, P0
   Comber A, 2005, ENVIRON PLANN B, V32, P199, DOI 10.1068/b31135
   Comber A, 2004, PHOTOGRAMM ENG REM S, V70, P931, DOI 10.14358/PERS.70.8.931
   Conneau A, 2020, P 58 ANN M ASS COMP, V0, P0, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Devlin J, 2019, P 2019 C N, V0, P0
   Di Gregorio A., 2005, LAND COVER CLASSIFIC, V0, P0
   Di Gregorio A., 2000, LAND COVER CLASSIFIC, V0, P0
   Farahani A., 2021, ADV DATA SCI INFORM, V0, PP877, DOI 10.1007/978-3-030-71704-9_65
   Feng C.-C., 2004, COMPUTERS, V0, P0
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Fritz S, 2005, INT J GEOGR INF SCI, V19, P787, DOI 10.1080/13658810500072020
   Ghamisi P, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2018.2890023
   Grekousis G, 2015, INT J REMOTE SENS, V36, P5309, DOI 10.1080/01431161.2015.1093195
   Herold M, 2008, REMOTE SENS ENVIRON, V112, P2538, DOI 10.1016/j.rse.2007.11.013
   HEYMANN Y, 1994, CORINE LAND COVER TE, V0, P0
   Hong DF, 2021, ISPRS J PHOTOGRAMM, V178, P68, DOI 10.1016/j.isprsjprs.2021.05.011
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Huang WC, 2020, IEEE TETCI, V4, P468, DOI 10.1109/TETCI.2020.2977678
   Inamdar S, 2008, IEEE T GEOSCI REMOTE, V46, P1243, DOI 10.1109/TGRS.2007.912445
   Inglada J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010095
   Iwao K., 2011, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V3, P160
   Jansen LJM, 2008, J LAND USE SCI, V3, P131, DOI 10.1080/17474230802332076
   Jepsen MR, 2013, INT J GEOGR INF SCI, V27, P2375, DOI 10.1080/13658816.2013.803555
   Jo DU, 2020, AAAI CONF ARTIF INTE, V34, P11197
   Jung M, 2006, REMOTE SENS ENVIRON, V101, P534, DOI 10.1016/j.rse.2006.01.020
   Kavouras M, 2002, INT J GEOGR INF SCI, V16, P439, DOI 10.1080/13658810210129120
   Kim D, 2020, AAAI CONF ARTIF INTE, V34, P11254
   Kouw WM, 2021, IEEE T PATTERN ANAL, V43, P766, DOI 10.1109/TPAMI.2019.2945942
   Lample Guillaume, 2019, ADV NEURAL INFORM PR, V32, P0
   Leiva-Murillo JM, 2013, IEEE T GEOSCI REMOTE, V51, P151, DOI 10.1109/TGRS.2012.2200043
   Li Z, 2021, INT J GEOGR INF SCI, V35, P348, DOI 10.1080/13658816.2020.1796131
   Lu M, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17071613
   Ma L, 2020, GEOSCI MODEL DEV, V13, P3203, DOI 10.5194/gmd-13-3203-2020
   Mai GC, 2022, INT J GEOGR INF SCI, V36, P639, DOI 10.1080/13658816.2021.2004602
   Malkin K., 2019, 7 INT C LEARN REPR 6, V0, P0
   Mallet C., 2020, INT ARCH PHOTOGRAMME, V43, P703, DOI 10.5194/isprs-archives-XLIII-B2-2020-703-2020
   Moiret-Guigand A., 2021, CLC2018CLCC1218 VALI, V0, P0
   Mura MD, 2015, P IEEE, V103, P1585, DOI 10.1109/JPROC.2015.2462751
   Natarajan N., 2013, ADV NEURAL INFORM PR, V26, P0
   Neumann K, 2007, INT J APPL EARTH OBS, V9, P425, DOI 10.1016/j.jag.2007.02.004
   Neyshabur B, 2017, ADV NEUR IN, V30, P0
   Nielsen A.A., 2009, SPIE P, V8, P0
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Othman E, 2017, IEEE T GEOSCI REMOTE, V55, P4441, DOI 10.1109/TGRS.2017.2692281
   PARMAR N, 2018, PR MACH LEARN RES, V80, P0
   Paul D, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, V0, P29
   Perez-Hoyos A, 2020, INT J APPL EARTH OBS, V88, P0, DOI 10.1016/j.jag.2020.102064
   Perez-Hoyos A, 2012, INT J APPL EARTH OBS, V19, P72, DOI 10.1016/j.jag.2012.04.011
   Perez-Hoyos A, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111118
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P4996
   Raposo P., 2017, CARTOGR PERSPECT, V0, PP5, DOI 10.14714/CP83.1351
   Rodriguez MA, 1999, LECT NOTES COMPUT SC, V1580, P189
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schepaschenko D, 2015, REMOTE SENS ENVIRON, V162, P208, DOI 10.1016/j.rse.2015.02.011
   See L, 2015, ISPRS J PHOTOGRAMM, V103, P48, DOI 10.1016/j.isprsjprs.2014.06.016
   Singh P, 2018, INT GEOSCI REMOTE SE, V0, P1772
   Tran C., 2021, CORR, V0, P0
   Tsendbazar N.E., 2020, COPERNICUS GLOBAL LA, V0, P0
   Tsendbazar NE, 2017, INT J DIGIT EARTH, V10, P219, DOI 10.1080/17538947.2016.1217942
   Tuanmu MN, 2014, GLOBAL ECOL BIOGEOGR, V23, P1031, DOI 10.1111/geb.12182
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   Vancutsem C, 2013, REMOTE SENS-BASEL, V5, P19, DOI 10.3390/rs5010019
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Verma, 2014, P BRIT MACHINE VISIO, V0, P0
   Waser LT, 2006, INT J APPL EARTH OBS, V8, P196, DOI 10.1016/j.jag.2005.10.001
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w
   Xing N, 2021, IEEE ACCESS, V9, P733, DOI 10.1109/ACCESS.2020.3046573
   Xing YF, 2020, WIREL COMMUN MOB COM, V2020, P0, DOI 10.1155/2020/8861886
   Xu G, 2014, REMOTE SENS-BASEL, V6, P5589, DOI 10.3390/rs6065589
   Yan L, 2020, IEEE T GEOSCI REMOTE, V58, P3558, DOI 10.1109/TGRS.2019.2958123
   Yang H, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6050154
   Yang Y, 2019, IMPROVING MULTILINGU, V0, P0
   Yu W., 2020, PROC ANN M ASS COMPU, V0, P5635
NR 91
TC 0
Z9 0
U1 3
U2 3
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD FEB 1
PY 2023
VL 37
IS 2
BP 403
EP 437
DI 10.1080/13658816.2022.2120996
EA OCT 2022
PG 35
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA 7T1FH
UT WOS:000865701600001
DA 2023-04-26
ER

PT J
AU Xu, XB
   Du, CW
   Ma, F
   Qiu, ZC
   Zhou, JM
AF Xu, Xuebin
   Du, Changwen
   Ma, Fei
   Qiu, Zhengchao
   Zhou, Jianmin
TI A Framework for High-Resolution Mapping of Soil Organic Matter (SOM) by the Integration of Fourier Mid-Infrared Attenuation Total Reflectance Spectroscopy (FTIR-ATR), Sentinel-2 Images, and DEM Derivatives
SO REMOTE SENSING
LA English
DT Article
DE digital soil mapping; proximal sensing; satellite sensing; machine learning; data fusion
ID difference water index; remote-sensing data; carbon prediction; nir spectroscopy; river-basin; vegetation; regression; salinity; performance; variables
AB Soil organic matter (SOM), as the greatest carbon storage in the terrestrial environment, is inextricably related to the global carbon cycle and global climate change. Accurate estimation and mapping of SOM content are crucial for guiding agricultural output and management, as well as controlling the climate issue. Traditional chemical analysis is unable to satisfy the dynamic estimation of SOM due to its low timeliness. Remote and proximal sensing have significant advantages in terms of ease of use, estimation accuracy, and geographical resolution. In this study, we developed a framework based on machine learning to estimate SOM with high accuracy and resolution using Fourier mid-infrared attenuation total reflectance spectroscopy (FTIR-ATR), Sentinel-2 images, and DEM derivatives. This framework's performance was evaluated on a regional scale using 245 soil samples from northeast China. Results indicated that the calibration size could be shrunk to 50% while achieving a fair prediction performance for SOM content. The Lasso, partial least squares (PLS), support vector regression (SVR), and convolutional neural networks (CNN) performed well in predicting SOM from FTIR-ATR spectra, and the performance was enhanced further by using Sentinel-2 images and DEM derivates. The PLS, SVR, and CNN models created SOM maps with higher spatial resolution and variation than the Kriging approach. The PLS and SVR models provided enough variety and were more realistic in the local SOM map, making them usable at the field scale, and the suggested framework took a fresh look at high-resolution SOM mapping.
C1 [Xu, Xuebin; Du, Changwen; Ma, Fei; Qiu, Zhengchao; Zhou, Jianmin] Chinese Acad Sci, State Key Lab Soil & Sustainable Agr, Inst Soil Sci, Nanjing 210008, Peoples R China.
   [Du, Changwen] Univ Chinese Acad Sci, Coll Adv Agr Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Soil Science, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Du, CW (corresponding author), Chinese Acad Sci, State Key Lab Soil & Sustainable Agr, Inst Soil Sci, Nanjing 210008, Peoples R China.; Du, CW (corresponding author), Univ Chinese Acad Sci, Coll Adv Agr Sci, Beijing 100049, Peoples R China.
EM chwdu@issas.ac.cn
FU Strategic Priority Research Program of the Chinese Academy of Sciences [XDA28040500, XDA28120400]; R & D Project for Promoting Mongolia [NMKJXM202107]
CR Abadi M., 2016, TENSORFLOW LARGE SCA, V0, P0
   Bangroo SA, 2020, CATENA, V193, P0, DOI 10.1016/j.catena.2020.104632
   Beguin J, 2017, GEODERMA, V306, P195, DOI 10.1016/j.geoderma.2017.06.016
   Beretta AN, 2014, CIENC INVESTIG AGRAR, V41, P263, DOI 10.4067/S0718-16202014000200013
   Calderon F, 2013, SOIL SCI SOC AM J, V77, P1591, DOI 10.2136/sssaj2013.04.0131
   Castaldi F, 2019, ISPRS J PHOTOGRAMM, V147, P267, DOI 10.1016/j.isprsjprs.2018.11.026
   Castaldi F, 2016, REMOTE SENS ENVIRON, V179, P54, DOI 10.1016/j.rse.2016.03.025
   Ceccato P, 2002, REMOTE SENS ENVIRON, V82, P188, DOI 10.1016/S0034-4257(02)00037-8
   Chen SC, 2021, GEODERMA, V400, P0, DOI 10.1016/j.geoderma.2021.115159
   Churchman GJ, 2010, SOIL TILL RES, V109, P23, DOI 10.1016/j.still.2010.03.012
   Conforti M, 2023, LAND-BASEL, V12, P0, DOI 10.3390/land12010044
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CRIPPEN RE, 1990, REMOTE SENS ENVIRON, V34, P71, DOI 10.1016/0034-4257(90)90085-Z
   Daughtry CST, 2000, REMOTE SENS ENVIRON, V74, P229, DOI 10.1016/S0034-4257(00)00113-9
   Delegido J, 2011, SENSORS-BASEL, V11, P7063, DOI 10.3390/s110707063
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Du CW, 2007, APPL SPECTROSC, V61, P1063, DOI 10.1366/000370207782217743
   Du CW, 2014, AGRON SUSTAIN DEV, V34, P803, DOI 10.1007/s13593-013-0201-6
   Du CW, 2009, VIB SPECTROSC, V49, P32, DOI 10.1016/j.vibspec.2008.04.009
   Ellerbrock RH, 2004, EUR J SOIL SCI, V55, P219, DOI 10.1046/j.1365-2389.2004.00593.x
   Escadafal R., 1989, REMOTE SENSING OF THE EARTHS SURFACE., V0, PP159, DOI 10.1016/0273-1177(89)90481-X
   Frampton WJ, 2013, ISPRS J PHOTOGRAMM, V82, P83, DOI 10.1016/j.isprsjprs.2013.04.007
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Gardin L, 2021, GEODERMA, V404, P0, DOI 10.1016/j.geoderma.2021.115386
   Gholizadeh A, 2018, REMOTE SENS ENVIRON, V218, P89, DOI 10.1016/j.rse.2018.09.015
   Gitelson AA, 1996, REMOTE SENS ENVIRON, V58, P289, DOI 10.1016/S0034-4257(96)00072-7
   Goffart D, 2021, EUR J AGRON, V126, P0, DOI 10.1016/j.eja.2021.126278
   Gomez C, 2008, GEODERMA, V146, P403, DOI 10.1016/j.geoderma.2008.06.011
   Goydaragh MG, 2021, CATENA, V202, P0, DOI 10.1016/j.catena.2021.105280
   Guo L, 2019, GEODERMA, V337, P32, DOI 10.1016/j.geoderma.2018.09.003
   Huang J, 2021, EUR J SOIL SCI, V72, P1831, DOI 10.1111/ejss.13085
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2
   HUETE A R, 1988, REMOTE SENSING OF ENVIRONMENT, V25, P295
   Janik LJ, 2007, AUST J SOIL RES, V45, P73, DOI 10.1071/SR06083
   KENNARD RW, 1969, TECHNOMETRICS, V11, P137, DOI 10.2307/1266770
   Kuang B, 2012, EUR J SOIL SCI, V63, P421, DOI 10.1111/j.1365-2389.2012.01456.x
   Lal R, 2016, FOOD ENERGY SECUR, V5, P212, DOI 10.1002/fes3.96
   Lal R, 2014, J SOIL WATER CONSERV, V69, P186A, DOI 10.2489/jswc.69.6.186A
   Lamichhane S, 2019, GEODERMA, V352, P395, DOI 10.1016/j.geoderma.2019.05.031
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leifeld J, 2006, EUR J SOIL SCI, V57, P846, DOI 10.1111/j.1365-2389.2005.00776.x
   Li XL, 2022, GEODERMA, V425, P0, DOI 10.1016/j.geoderma.2022.116069
   Luca F, 2017, GEODERMA, V288, P175, DOI 10.1016/j.geoderma.2016.11.015
   Luo C, 2022, CATENA, V209, P0, DOI 10.1016/j.catena.2021.105842
   Ma F, 2017, CHEMOMETR INTELL LAB, V171, P9, DOI 10.1016/j.chemolab.2017.09.017
   Madejova J, 2003, VIB SPECTROSC, V31, P1, DOI 10.1016/S0924-2031(02)00065-6
   Marsett RC, 2006, RANGELAND ECOL MANAG, V59, P530, DOI 10.2111/05-201R.1
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   Metternicht GI, 2003, REMOTE SENS ENVIRON, V85, P1, DOI 10.1016/S0034-4257(02)00188-8
   Minhoni RTD, 2021, SCI TOTAL ENVIRON, V784, P0, DOI 10.1016/j.scitotenv.2021.147216
   Moura-Bueno JM, 2021, GEODERMA, V393, P0, DOI 10.1016/j.geoderma.2021.114981
   Movasaghi Z, 2008, APPL SPECTROSC REV, V43, P134, DOI 10.1080/05704920701829043
   Nayak PS, 2007, B MATER SCI, V30, P235, DOI 10.1007/s12034-007-0042-5
   NELLIS M D, 1992, TRANSACTIONS OF THE KANSAS ACADEMY OF SCIENCE, V95, P93, DOI 10.2307/3628024
   Ng W, 2019, GEODERMA, V352, P251, DOI 10.1016/j.geoderma.2019.06.016
   Ni WD, 2014, ANAL CHIM ACTA, V813, P1, DOI 10.1016/j.aca.2013.12.002
   Padarian J, 2019, GEODERMA REG, V16, P0, DOI 10.1016/j.geodrs.2018.e00198
   Pedersen JA, 2011, ORG GEOCHEM, V42, P947, DOI 10.1016/j.orggeochem.2011.04.003
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peltre C, 2014, SOIL BIOL BIOCHEM, V77, P41, DOI 10.1016/j.soilbio.2014.06.022
   Qi J., 1994, P 6 INT S PHYS MEASU, V0, P0
   Ramirez-Lopez L, 2019, EUR J SOIL SCI, V70, P378, DOI 10.1111/ejss.12752
   Rial M, 2016, SCI TOTAL ENVIRON, V539, P26, DOI 10.1016/j.scitotenv.2015.08.088
   Rondeaux G, 1996, REMOTE SENS ENVIRON, V55, P95, DOI 10.1016/0034-4257(95)00186-7
   Rossel RAV, 2010, GEODERMA, V158, P46, DOI 10.1016/j.geoderma.2009.12.025
   Scudiero E., 2014, GEODERMA REG, V2-3, P82, DOI 10.1016/j.geodrs.2014.10.004
   Shetty N, 2011, FIELD CROP RES, V120, P31, DOI 10.1016/j.fcr.2010.08.008
   Shoko C, 2017, ISPRS J PHOTOGRAMM, V129, P32, DOI 10.1016/j.isprsjprs.2017.04.016
   Song XD, 2016, GEODERMA, V261, P11, DOI 10.1016/j.geoderma.2015.06.024
   Soriano-Disla JM, 2014, APPL SPECTROSC REV, V49, P139, DOI 10.1080/05704928.2013.811081
   Srisomkiew S, 2022, GEODERMA, V409, P0, DOI 10.1016/j.geoderma.2021.115597
   Taghizadeh-Mehrjardi R, 2014, GEODERMA, V213, P15, DOI 10.1016/j.geoderma.2013.07.020
   Thaler EA, 2019, SOIL SCI SOC AM J, V83, P1443, DOI 10.2136/sssaj2018.09.0318
   Nguyen TT, 2022, SCI TOTAL ENVIRON, V804, P0, DOI 10.1016/j.scitotenv.2021.150187
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Van Bemmelen J.M., 1890, LANDWIRTHSCHAFTLICHE, V37, P279
   Wadoux AMJC, 2021, GEODERMA, V383, P0, DOI 10.1016/j.geoderma.2020.114725
   Wadoux AMJC, 2019, GEODERMA, V355, P0, DOI 10.1016/j.geoderma.2019.113913
   Walkley A, 1934, SOIL SCI, V37, P29, DOI 10.1097/00010694-193401000-00003
   Wang B, 2018, SCI TOTAL ENVIRON, V630, P367, DOI 10.1016/j.scitotenv.2018.02.204
   Wang F, 2021, SCI TOTAL ENVIRON, V754, P0, DOI 10.1016/j.scitotenv.2020.142030
   Wang F, 2020, GEODERMA, V365, P0, DOI 10.1016/j.geoderma.2020.114211
   Wang N, 2022, GEODERMA, V409, P0, DOI 10.1016/j.geoderma.2021.115656
   Wang SC, 2020, J SOIL SEDIMENT, V20, P1241, DOI 10.1007/s11368-019-02520-2
   Wu WC, 2014, IEEE J-STARS, V7, P4442, DOI 10.1109/JSTARS.2014.2360411
   Xiao XM, 2004, REMOTE SENS ENVIRON, V91, P256, DOI 10.1016/j.rse.2004.03.010
   Xing Z, 2019, GEODERMA, V335, P94, DOI 10.1016/j.geoderma.2018.08.003
   Xing Z, 2016, TALANTA, V158, P262, DOI 10.1016/j.talanta.2016.05.076
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Xu XB, 2020, FORENSIC SCI INT, V310, P0, DOI 10.1016/j.forsciint.2020.110222
   Xu XB, 2019, GEODERMA, V355, P0, DOI 10.1016/j.geoderma.2019.113905
   Yu H, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18041048
   Zhou T, 2021, SCI TOTAL ENVIRON, V755, P0, DOI 10.1016/j.scitotenv.2020.142661
   Zhou T, 2020, SCI TOTAL ENVIRON, V729, P0, DOI 10.1016/j.scitotenv.2020.138244
NR 96
TC 0
Z9 0
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 15
PY 2023
VL 15
IS 4
BP 
EP 
DI 10.3390/rs15041072
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA 9J3II
UT WOS:000940084500001
DA 2023-04-26
ER

PT J
AU Chen, XN
   Han, ZH
   Li, Y
   Ma, MY
   Mei, SH
   Cheng, W
AF Chen, Xiaoning
   Han, Zonghao
   Li, Yong
   Ma, Mingyang
   Mei, Shaohui
   Cheng, Wei
TI Attention-Aware Deep Feature Embedding for Remote Sensing Image Scene Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Attention mechanism; convolutional neural network (CNN); dual attention-aware (DAA); remote sensing (RS); scene classification
ID convolutional neural-networks; thick cloud; removal; bag
AB Due to the wide application of remote sensing (RS) image scene classification, more and more scholars activate great attention to it. With the development of the convolutional neural network (CNN), the CNN-based methods of the RS image scene classification have made impressive progress. In the existing works, most of the architectures just considered the global information of the RS images. However, the global information contains a large number of redundant areas that diminish the classification performance and ignore the local information that reflects more fine spatial details of local objects. Furthermore, most CNN-based methods assign the same weights to each feature vector causing the mode to fail to discriminate the crucial features. In this article, a novel method by Two-branch Deep Feature Embedding (TDFE) with a dual attention-aware (DAA) module for RS image scene classification is proposed. In order to mine more complementary information, we extract global semantic-based features of high level and local object-based features of low level by the TDFE module. Then, to focus selectively on the key global-semantics feature maps as well as the key local regions, we propose a DAA module to attain those key information. We conduct extensive experiments to verify the superiority of our proposed method, and the experimental results obtained on two widely used RS scene classification benchmarks demonstrate the effectiveness of the proposed method.
C1 [Chen, Xiaoning; Han, Zonghao; Li, Yong; Mei, Shaohui; Cheng, Wei] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
   [Ma, Mingyang] Jiaotong Univ, Sch Informat & Commun Engn, Xian 710129, Peoples R China.
C3 Northwestern Polytechnical University
RP Li, Y (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
EM chenxiaoning2018@mail.nwpu.edu.cn; hanzonghao@mail.nwpu.edu.cn; ruikel@nwpu.edu.cn; mamingyang@mail.nwpu.edu.cn; meish@nwpu.edu.cn; pupil_119@nwpu.edu.cn
FU Fundamental Research Funds for the Central Universities [3102019ZX015]
CR [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   Anwer RM, 2018, ISPRS J PHOTOGRAMM, V138, P74, DOI 10.1016/j.isprsjprs.2018.01.023
   Avtar R, 2019, RESOURCES-BASEL, V8, P0, DOI 10.3390/resources8030149
   Bi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1603, DOI 10.1109/LGRS.2019.2949930
   Cao R, 2021, IEEE GEOSCI REMOTE S, V18, P43, DOI 10.1109/LGRS.2020.2968550
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XN, 2021, IEEE J-STARS, V14, P12429, DOI 10.1109/JSTARS.2021.3130073
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Dalal N, 2005, PROC CVPR IEEE, V0, PP886, DOI 10.1109/cvpr.2005.177
   Ding L, 2021, IEEE T GEOSCI REMOTE, V59, P426, DOI 10.1109/TGRS.2020.2994150
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Fan RY, 2019, INT GEOSCI REMOTE SE, V0, PP1346, DOI 10.1109/IGARSS.2019.8900199
   Han XB, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9080848
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu M, 2021, PROC CVPR IEEE, V0, PP15338, DOI 10.1109/CVPR46437.2021.01509
   Ji JS, 2020, IEEE GEOSCI REMOTE S, V17, P1647, DOI 10.1109/LGRS.2019.2949253
   Kingma DP., 2014, P ICLR POSTER, V0, P0
   Komodakis N, 2017, PROC INT C LEARN REP, V0, P0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE INT C COMP VI, V0, PP2169, DOI 10.1109/CVPR.2006.68
   Li FP, 2020, IEEE J-STARS, V13, P3862, DOI 10.1109/JSTARS.2020.3006241
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li WM, 2020, IEEE J-STARS, V13, P1986, DOI 10.1109/JSTARS.2020.2988477
   Lin T.-Y., 2017, FEATURE PYRAMID NETW, V0, P2117
   Liu BD, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050518
   Liu N, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7030095
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P2504, DOI 10.1109/TGRS.2019.2951779
   Lu XQ, 2019, IEEE T GEOSCI REMOTE, V57, P7894, DOI 10.1109/TGRS.2019.2917161
   Luo YH, 2022, MULTIMED TOOLS APPL, V81, P30685, DOI 10.1007/s11042-022-11940-1
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Lv YF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11243006
   Minetto R, 2019, IEEE T GEOSCI REMOTE, V57, P6530, DOI 10.1109/TGRS.2019.2906883
   Obaid K. B., 2020, INT J SCI BUSINESS, V4, P75
   Ren JF, 2015, PATTERN RECOGN, V48, P3180, DOI 10.1016/j.patcog.2015.02.001
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, V0, PP618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, ARXIV, V0, P0
   Sridharan H, 2015, IEEE GEOSCI REMOTE S, V12, P676, DOI 10.1109/LGRS.2014.2357392
   Tang X, 2021, IEEE J-STARS, V14, P2030, DOI 10.1109/JSTARS.2021.3051569
   Tian T, 2021, IEEE J-STARS, V14, P5501, DOI 10.1109/JSTARS.2021.3074508
   Tiwari KC, 2011, INT J APPL EARTH OBS, V13, P730, DOI 10.1016/j.jag.2011.03.007
   Vaswani A, 2017, ADV NEURAL INFORM PR, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Voltersen M., 2015, PROC JOINT URBAN REM, V0, P1
   Wang D, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13245076
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang X, 2021, IEEE T GEOSCI REMOTE, V59, P7918, DOI 10.1109/TGRS.2020.3044655
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111402
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xu C., 2021, IEEE T CYBERNETICS, V60, P1, DOI 10.1109/TGRS.2020.3048024.[7]H
   Xu KJ, 2020, IEEE GEOSCI REMOTE S, V17, P1894, DOI 10.1109/LGRS.2019.2960026
   Yi YN, 2020, CATENA, V195, P0, DOI 10.1016/j.catena.2020.104851
   Zeng D, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050734
   Zhang LF, 2018, IEEE T CYBERNETICS, V48, P16, DOI 10.1109/TCYB.2016.2605044
   Zhang Q, 2022, IEEE T IMAGE PROCESS, V31, P6356, DOI 10.1109/TIP.2022.3211471
   Zhang Q, 2021, ISPRS J PHOTOGRAMM, V177, P161, DOI 10.1016/j.isprsjprs.2021.04.021
   Zhang Q, 2020, ISPRS J PHOTOGRAMM, V162, P148, DOI 10.1016/j.isprsjprs.2020.02.008
   Zhang W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050494
   Zheng XT, 2019, IEEE T GEOSCI REMOTE, V57, P4799, DOI 10.1109/TGRS.2019.2893115
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
   Zhu MH, 2021, IEEE T GEOSCI REMOTE, V59, P449, DOI 10.1109/TGRS.2020.2994057
   Zhu QQ, 2016, IEEE GEOSCI REMOTE S, V13, P747, DOI 10.1109/LGRS.2015.2513443
   Zhu YX, 2019, IEEE INT CON MULTI, V0, PP712, DOI 10.1109/ICME.2019.00128
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 68
TC 0
Z9 0
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2023
VL 16
IS 
BP 1171
EP 1184
DI 10.1109/JSTARS.2022.3229729
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 7U8ZA
UT WOS:000912413700016
DA 2023-04-26
ER
