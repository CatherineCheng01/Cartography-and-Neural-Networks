
PT J
AU Weld, G
   Jang, E
   Li, A
   Zeng, A
   Heimerl, K
   Froehlich, JE
AF Weld, Galen
   Jang, Esther
   Li, Anthony
   Zeng, Aileen
   Heimerl, Kurtis
   Froehlich, Jon E.
TI Deep Learning for Automatically Detecting Sidewalk Accessibility Problems Using Streetscape Imagery
SO ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY
LA English
DT Proceedings Paper
DE Neural networks; computer vision; accessibility; sidewalks; curb ramps; Google Streetview
ID database; view
AB Recent work has applied machine learning methods to automatically find and/or assess pedestrian infrastructure in online map imagery (e.g., satellite photos, streetscape panoramas). While promising, these methods have been limited by two interrelated issues: small training sets and the choice of machine learning model. In this paper, aided by the recently released Project Sidewalk dataset of 300,000+ image-based sidewalk accessibility labels, we present the first examination of deep learning to automatically assess sidewalks in Google Street View (GSV) panoramas. Specifically, we investigate two application areas: automatically validating crowdsourced labels and automatically labeling sidewalk accessibility issues. For both tasks, we introduce and use a residual neural network (ResNet) modified to support both image and non-image (contextual) features (e.g., geography). We present an analysis of performance, the effect of our non-image features and training set size, and cross-city generalizability. Our results significantly improve on prior automated methods and, in some cases, meet or exceed human labeling performance.
C1 [Weld, Galen; Jang, Esther; Zeng, Aileen; Heimerl, Kurtis; Froehlich, Jon E.] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
   [Li, Anthony] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
C3 University of Washington; University of Washington Seattle; University System of Maryland; University of Maryland College Park
RP Weld, G (corresponding author), Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA.
EM gweld@cs.washington.edu; infrared@cs.washington.edu; antli@umd.edu; aileenz@cs.washington.edu; kheimerl@cs.washington.edu; jonf@cs.washington.edu
FU NSF [IIS-1302338]; Sloan Research Fellowship
CR Ahmetovic D, 2017, ACM T ACCESS COMPUT, V9, P0, DOI 10.1145/3046790
   Ahmetovic D, 2015, ASSETS15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, V0, PP251, DOI 10.1145/2700648.2809847
   Ahmetovic D, 2014, INT C PATT RECOG, V0, PP2566, DOI 10.1109/ICPR.2014.443
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Bellei EA, 2018, SYMP VIRTUAL AUGMENT, V0, PP1, DOI 10.1109/SVR.2018.00014
   Bromley J., 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Cardonha Carlos, 2013, P 10 INT CROSS DISCI, V0, P0
   Cheng MM, 2018, IEEE T VEH TECHNOL, V67, P10330, DOI 10.1109/TVT.2018.2865836
   Christensen KM, 2010, PREV CHRONIC DIS, V7, P0
   Cordts M., 2016, CITYSCAPES DATASET S, V0, P0
   De D, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), V0, PP305, DOI 10.1109/IEMECON.2017.8079611
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Ding Chaohai, 2014, WEB ALL C, V0, P0, DOI DOI 10.1145/2596695.2596708
   Felzenszwalb P., 2009, PAMI, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Forsyth David A, 2002, COMPUTER VISION MODE, V0, P0
   Froehlich JE., 2019, INTERACTIONS, V26, P78, DOI 10.1145/3301657
   Gallo Orazio, 2008, 2008 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPR WORKSHOPS), V0, PP1, DOI 10.1109/CVPRW.2008.4563165
   Garcia M., 2016, WORLD POLICY J, V33, P111
   Hajian S, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2125, DOI 10.1145/2939672.2945386
   Hansen W, 2009, J PHYS ACT HEALTH, V6, P374, DOI 10.1123/jpah.6.3.374
   Hara K., 2013, P SIGCHI C HUMAN FAC, V0, PP631, DOI 10.1145/2470654.2470744
   Hara K., 2014, P 27 ANN ACM S US IN, V0, PP189, DOI 10.1145/2642918.2647403
   Hara K., 2012, P 14 INT ACM SIGACCE, V0, PP273, DOI 10.1145/2384916.2384989
   Hara K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P1757, DOI 10.1145/2858036.2858315
   Hara Kotaro, 2013, HCOMP, V0, P0
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Isola P., 2017, PROC IEEE C COMPUT V, V0, P1125
   Iwasawa Y, 2015, PROCEDIA COMPUT SCI, V63, P74, DOI 10.1016/j.procs.2015.08.314
   Janssen I, 2012, BMC MED RES METHODOL, V12, P0, DOI 10.1186/1471-2288-12-39
   Kang B, 2015, INT J GEOGR INF SCI, V29, P440, DOI 10.1080/13658816.2014.981191
   Kirchner CE, 2008, AM J PREV MED, V34, P349, DOI 10.1016/j.amepre.2008.01.005
   Kirkham R, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 17), V0, P0, DOI DOI 10.1145/3098279.3098527
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Law Stephen, 2018, TECHNICAL REPORT, V0, P0, DOI DOI 10.475/123
   Li A, 2018, ASSETS18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, V0, PP444, DOI 10.1145/3234695.3241000
   Li XJ, 2015, URBAN FOR URBAN GREE, V14, P675, DOI 10.1016/j.ufug.2015.06.006
   Li Xiaojiang, 2017, MAPPING URBAN LANDSC, V0, P0
   Lu Y, 2018, INT J ENV RES PUB HE, V15, P0, DOI 10.3390/ijerph15081576
   Mahajan Dhruv, 2018, CORR, V0, P0
   May A, 2014, TRANSPORT RES C-EMER, V49, P103, DOI 10.1016/j.trc.2014.10.007
   Mirri S, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), V0, PP6, DOI 10.1109/ISCC.2016.7543705
   Mitchell C, 2006, TOP GERIATR REHABIL, V22, P45
   Mollahosseini A., 2016, PROC IEEE WINTER C A, V0, PP1, DOI 10.1109/WACV.2016.7477450
   Okatani T., 2015, P PROCEDINGS BRIT MA, V61, P1, DOI 10.5244/c.29.61
   Olivas E. S., 2009, HDB RES MACHINE LEAR, V0, P0, DOI DOI 10.4018/978-1-6056-6766-9&BUYLINK=TRUE
   Prandi Catia, 2014, 2014 IEEE 11TH CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), V0, PP591, DOI 10.1109/CCNC.2014.6940491
   Russell SJ, 2010, ARTIFCIAL INTELLIGEN, V0, P0
   Saha Manaswi, 2019, PROJECT SIDEWALK WEB, V0, P0, DOI DOI 10.1145/XXXXXX.XXXXXX
   Sinkonde D, 2018, URBAN SCI, V2, P0, DOI 10.3390/urbansci2030052
   Sobek AD, 2006, J GEOGR SYST, V8, P269, DOI 10.1007/s10109-006-0021-1
   Soltani AA, 2017, PROC CVPR IEEE, V0, PP2511, DOI 10.1109/CVPR.2017.269
   Sun J, 2017, PROC CVPR IEEE, V0, PP1234, DOI 10.1109/CVPR.2017.136
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
NR 53
TC 18
Z9 18
U1 2
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
SN 
EI 
J9 
PD JUN 15
PY 2019
VL 0
IS 
BP 196
EP 209
DI 10.1145/3308561.3353798
PG 14
WC Computer Science, Theory & Methods
SC Computer Science
GA BO6WR
UT WOS:000522450600018
DA 2023-04-26
ER

PT J
AU Feng, QL
   Zhu, DH
   Yang, JY
   Li, BG
AF Feng, Quanlong
   Zhu, Dehai
   Yang, Jianyu
   Li, Baoguo
TI Multisource Hyperspectral and LiDAR Data Fusion for Urban Land-Use Mapping based on a Modified Two-Branch Convolutional Neural Network
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE convolutional neural networks; multisource data; feature fusion; urban land-use mapping
ID remote-sensing data; cover classification; pixel
AB Accurate urban land-use mapping is a challenging task in the remote-sensing field. With the availability of diverse remote sensors, synthetic use and integration of multisource data provides an opportunity for improving urban land-use classification accuracy. Neural networks for Deep Learning have achieved very promising results in computer-vision tasks, such as image classification and object detection. However, the problem of designing an effective deep-learning model for the fusion of multisource remote-sensing data still remains. To tackle this issue, this paper proposes a modified two-branch convolutional neural network for the adaptive fusion of hyperspectral imagery (HSI) and Light Detection and Ranging (LiDAR) data. Specifically, the proposed model consists of a HSI branch and a LiDAR branch, sharing the same network structure to reduce the time cost of network design. A residual block is utilized in each branch to extract hierarchical, parallel, and multiscale features. An adaptive-feature fusion module is proposed to integrate HSI and LiDAR features in a more reasonable and natural way (based on "Squeeze-and-Excitation Networks"). Experiments indicate that the proposed two-branch network shows good performance, with an overall accuracy of almost 92%. Compared with single-source data, the introduction of multisource data improves accuracy by at least 8%. The adaptive fusion model can also increase classification accuracy by more than 3% when compared with the feature-stacking method (simple concatenation). The results demonstrate that the proposed network can effectively extract and fuse features for a better urban land-use mapping accuracy.
C1 [Feng, Quanlong] China Agr Univ, Coll Resources & Environm Sci, Beijing 100094, Peoples R China.
   [Feng, Quanlong; Zhu, Dehai; Yang, Jianyu; Li, Baoguo] China Agr Univ, Coll Land Sci & Technol, Beijing 100083, Peoples R China.
C3 China Agricultural University; China Agricultural University
RP Zhu, DH (corresponding author), China Agr Univ, Coll Land Sci & Technol, Beijing 100083, Peoples R China.
EM fengql@cau.edu.cn; zhudehai@263.net; ycjyyang@126.com; libg@cau.edu.cn
FU China Postdoctoral Science Foundation [2018M641529]; Ministry of Land and Resources Industry Public Welfare projects [201511010-06]
CR Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Bulat A, 2017, IEEE I CONF COMP VIS, V0, PP1021, DOI 10.1109/ICCV.2017.116
   Bulat A, 2017, IEEE I CONF COMP VIS, V0, PP3726, DOI 10.1109/ICCV.2017.400
   Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387
   Chen XL, 2006, REMOTE SENS ENVIRON, V104, P133, DOI 10.1016/j.rse.2005.11.016
   Chen Y, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7050181
   Dalponte M, 2008, IEEE T GEOSCI REMOTE, V46, P1416, DOI 10.1109/TGRS.2008.916480
   Debes C, 2014, IEEE J-STARS, V7, P2405, DOI 10.1109/JSTARS.2014.2305441
   Demarchi L, 2014, ISPRS J PHOTOGRAMM, V87, P166, DOI 10.1016/j.isprsjprs.2013.10.012
   Gonzalez RS, 2018, INT J REMOTE SENS, V39, P8859, DOI 10.1080/01431161.2018.1500071
   Hu J, 2018, 2017 IEEE C COMP VIS, V0, P0
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Hughes LH, 2018, IEEE GEOSCI REMOTE S, V15, P784, DOI 10.1109/LGRS.2018.2799232
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Kereszturi G, 2018, INT J APPL EARTH OBS, V73, P323, DOI 10.1016/j.jag.2018.07.006
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2015, IEEE I CONF COMP VIS, V0, PP1449, DOI 10.1109/ICCV.2015.170
   Liu XL, 2015, REMOTE SENS-BASEL, V7, P922, DOI 10.3390/rs70100922
   Lu DS, 2010, PHOTOGRAMM ENG REM S, V76, P1159, DOI 10.14358/PERS.76.10.1159
   Man QX, 2015, INT J REMOTE SENS, V36, P1618, DOI 10.1080/01431161.2015.1015657
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Powell RL, 2007, REMOTE SENS ENVIRON, V106, P253, DOI 10.1016/j.rse.2006.09.005
   Pu RL, 2011, INT J REMOTE SENS, V32, P3285, DOI 10.1080/01431161003745657
   Rezaee M, 2018, IEEE J-STARS, V11, P3030, DOI 10.1109/JSTARS.2018.2846178
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russwurm M, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7040129
   Sankey T, 2017, REMOTE SENS ENVIRON, V195, P30, DOI 10.1016/j.rse.2017.04.007
   Sasaki T, 2012, LANDSC ECOL ENG, V8, P157, DOI 10.1007/s11355-011-0158-z
   Sturari M, 2017, EUR J REMOTE SENS, V50, P1, DOI 10.1080/22797254.2017.1274572
   Tong XH, 2014, IEEE J-STARS, V7, P3998, DOI 10.1109/JSTARS.2013.2272212
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 35
TC 53
Z9 54
U1 5
U2 42
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD JAN 15
PY 2019
VL 8
IS 1
BP 
EP 
DI 10.3390/ijgi8010028
PG 16
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA HL3AN
UT WOS:000458582700027
DA 2023-04-26
ER

PT J
AU Wan, LM
   Zhang, HS
   Lin, GH
   Lin, H
AF Wan, Luoma
   Zhang, Hongsheng
   Lin, Guanghui
   Lin, Hui
TI A small-patched convolutional neural network for mangrove mapping at species level using high-resolution remote-sensing image
SO ANNALS OF GIS
LA English
DT Article
DE Small patch; mangrove species; CNNs
ID vehicle detection; classification; ensemble; dynamics; ikonos
AB The understanding of mangrove forest structure and dynamics at species level is essential for mangrove conservation and management. To classify mangrove species, remote-sensing technologies provide a better way with high spatial resolution image. The spatial structure is usually viewed as effective complementary information for classification. However, it is still a challenge to design handcrafted features for mangrove species due to their non-structure texture. To leverage the advantage of convolutional neural networks (CNNs) in abstract feature exploration, a small patch-based CNN is proposed to overcome the requirement of fixed and large input which limits the applicability of CNNs to fringe mangrove forests. The function of down-sampling technology was substantially reduced to make deeper network for small input in our work. Meanwhile, the inception structure is used to exploit the multi-scale features of mangrove forests. Furthermore, the network is optimized with lesser convolution kernels and a single fully connected layer to reduce overfitting via reducing the training parameters. Compared to the features of grey level co-occurrence matrix with support vector machine, our proposed CNN shows better performance in classification accuracy. Moreover, the differences between mangrove species can be perceptive via CNN visualization, which offers better understanding of mangrove forests.
C1 [Wan, Luoma; Zhang, Hongsheng; Lin, Hui] Chinese Univ Hong Kong, Inst Space & Earth Informat Sci, Shatin, Hong Kong, Peoples R China.
   [Zhang, Hongsheng; Lin, Hui] Chinese Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
   [Lin, Guanghui] Tsinghua Univ, Dept Earth Syst Sci, Minist Educ, Key Lab Earth Syst Modeling, Beijing, Peoples R China.
   [Lin, Hui] Chinese Univ Hong Kong, Dept Geog & Resource Management, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Chinese University of Hong Kong, Shenzhen; Tsinghua University; Chinese University of Hong Kong
RP Zhang, HS (corresponding author), Chinese Univ Hong Kong, Inst Space & Earth Informat Sci, Shatin, Hong Kong, Peoples R China.; Zhang, HS (corresponding author), Chinese Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
EM stevenzhang@cuhk.edu.hk
FU National Natural Science Foundation of China [41401370]; Research Grants Council (RGC) General Research Fund [CUHK 14601515, CUHK 14635916, CUHK 14605917]
CR [Anonymous], 2015, LOC MANGR SPEC, V0, P0
   Basaeed E, 2016, KNOWL-BASED SYST, V99, P19, DOI 10.1016/j.knosys.2016.01.028
   Blasco F, 1998, MAR FRESHWATER RES, V49, P287, DOI 10.1071/MF97153
   Cai BW, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111198
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Chollet F., 2016, CONVOLUTIONAL NEURAL, V0, P0
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Claridge D, 1993, MANGROVES FOCUS, V0, P0
   Ellison AM, 2005, FRONT ECOL ENVIRON, V3, P479, DOI 10.2307/3868635
   Giri C, 2008, J BIOGEOGR, V35, P519, DOI 10.1111/j.1365-2699.2007.01806.x
   Giri C, 2011, GLOBAL ECOL BIOGEOGR, V20, P154, DOI 10.1111/j.1466-8238.2010.00584.x
   Guo ZL, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8040271
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Heumann BW, 2011, REMOTE SENS-BASEL, V3, P2440, DOI 10.3390/rs3112440
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Ji M. H, 2008, REMOTE SENSING MODEL, V7083, P0
   Jia MM, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080627
   Jia MM, 2014, INT J APPL EARTH OBS, V33, P226, DOI 10.1016/j.jag.2014.06.006
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kuenzer C, 2011, REMOTE SENS-BASEL, V3, P878, DOI 10.3390/rs3050878
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li H, 2017, REMOTE SENS LETT, V8, P262, DOI 10.1080/2150704X.2016.1258127
   Lima E, 2017, IEEE GEOSCI REMOTE S, V14, P354, DOI 10.1109/LGRS.2016.2643000
   Lin HN, 2017, IEEE GEOSCI REMOTE S, V14, P1665, DOI 10.1109/LGRS.2017.2727515
   Liu Y, 2017, COMPUT ELECTR ENG, V62, P538, DOI 10.1016/j.compeleceng.2016.12.026
   Liu Y, 2017, J ENERGY STORAGE, V9, P25, DOI 10.1016/j.est.2016.11.004
   Liu Z. G, 2007, GEOINFORMATICS 200 C, V0, P0
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Marmanis D, 2016, ISPRS ANN PHOTO REM, V3, P473, DOI 10.5194/isprsannals-III-3-473-2016
   Myint SW, 2008, GISCI REMOTE SENS, V45, P188, DOI 10.2747/1548-1603.45.2.188
   Neukermans G, 2008, J SPAT SCI, V53, P75, DOI 10.1080/14498596.2008.9635137
   Pan B, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/1796728
   Peng Cong-jiao, 2016, YINGYONG SHENGTAI XUEBAO, V27, P2059, DOI 10.13287/j.1001-9332.201607.029
   Peng L, 2003, ENG SCI, V6, P4
   Polidoro BA, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0010095
   Qu T, 2017, MULTIMED TOOLS APPL, V76, P21651, DOI 10.1007/s11042-016-4043-5
   Ren H, 2009, ECOL ENG, V35, P1243, DOI 10.1016/j.ecoleng.2009.05.008
   Tian S, 2017, IEEE GEOSCI REMOTE S, V14, P2127, DOI 10.1109/LGRS.2017.2753821
   Vaiphasa C, 2006, ISPRS J PHOTOGRAMM, V61, P1, DOI 10.1016/j.isprsjprs.2006.05.005
   Valderrama-Landeros L, 2018, ENVIRON MONIT ASSESS, V190, P0, DOI 10.1007/s10661-017-6399-z
   Wan H., 2014, SCI WORLD J, V2014, P7
   Wan LM, 2018, WETLANDS, V38, P861, DOI 10.1007/s13157-017-0925-1
   Wang HZ, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042606
   Wang L, 2004, INT J REMOTE SENS, V25, P5655, DOI 10.1080/014311602331291215
   Wang L, 2004, REMOTE SENS ENVIRON, V91, P432, DOI 10.1016/j.rse.2004.04.005
   Wang T, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010024
   Wong FKK, 2014, INT J REMOTE SENS, V35, P7828, DOI 10.1080/01431161.2014.978034
   Xiao ZF, 2017, IEEE GEOSCI REMOTE S, V14, P1469, DOI 10.1109/LGRS.2017.2712638
   Yao Y, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042611
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P5553, DOI 10.1109/TGRS.2016.2569141
   Zhang HS, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030467
   Zhang P, 2017, IEEE GEOSCI REMOTE S, V14, P1183, DOI 10.1109/LGRS.2017.2673118
   Zhang YH, 2018, REMOTE SENS LETT, V9, P11, DOI 10.1080/2150704X.2017.1378452
   Zhong YF, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.025006
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P5832, DOI 10.1109/TGRS.2016.2572736
NR 58
TC 27
Z9 29
U1 2
U2 20
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1947-5683
EI 1947-5691
J9 ANN GIS
JI Ann. GIS
PD JUN 15
PY 2019
VL 25
IS 1
BP 45
EP 55
DI 10.1080/19475683.2018.1564791
PG 11
WC Geography; Geography, Physical; Remote Sensing
SC Geography; Physical Geography; Remote Sensing
GA JL7KL
UT WOS:000495707200005
DA 2023-04-26
ER

PT J
AU Kikin, PM
   Kolesnikov, AA
   Portnov, AM
AF Kikin, P. M.
   Kolesnikov, A. A.
   Portnov, A. M.
TI USE OF MACHINE LEARNING TECHNIQUES FOR RAPID DETECTION, ASSESSMENT AND MAPPING THE IMPACT OF DISASTERS ON TRANSPORT INFRASTRUCTURE
SO ISPRS ICWG III/IVA GI4DM 2019 - GEOINFORMATION FOR DISASTER MANAGEMENT
LA English
DT Proceedings Paper
DE Road Network; Machine Learning; Artificial Neural Networks; Unet; UAV; Rapid Mapping
ID earthquake; extraction; framework
AB Road traffic infrastructure plays a key role in emergency management. It allows to evacuate people from the affected area in the shortest possible time, as well as to organize rapid emergency response. However, disasters often cause the destruction of roads, railways and pedestrian routes, which can significantly affect the evacuation plan and availability of facilities for emergency services, which increases the response time and thereby increases the losses. Therefore, it is very important to quickly provide emergency services with necessary post-disaster maps, created on the principles of rapid mapping. Change detection based on geospatial data before and after damage can make rapid and automatic assessment possible with reasonable accuracy and speed. This research proposes a new approach for detecting damage and detecting the state and availability of the road network based on the satellite imagery data, unmanned aerial vehicles (UAVs) and SAR using various methods of image analysis. We also provided an assessment of the resulting combined mathematical model based on neural networks and spatial analysis approaches.
C1 [Kikin, P. M.] Peter Great St Petersburg Polytech Univ SPbPU, St Petersburg, Russia.
   [Kolesnikov, A. A.] Siberian State Univ Geo Syst & Technol, Novosibirsk, Russia.
   [Portnov, A. M.] Moscow State Univ Geodesy & Cartog, Moscow, Russia.
C3 Peter the Great St. Petersburg Polytechnic University
RP Kikin, PM (corresponding author), Peter Great St Petersburg Polytech Univ SPbPU, St Petersburg, Russia.
EM it-technologies@yandex.ru; alexeykw@yandex.ru; portnov@miigaik.ru
CR Adriano B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070886
   Alemohammad, 2019, IEEE C COMP VIS PATT, V0, P83
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP), V0, P0
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Deledalle CA, 2015, IEEE T GEOSCI REMOTE, V53, P2021, DOI 10.1109/TGRS.2014.2352555
   García Herrera Arístides Lázaro, 2017, REV.MED.ELECTRÓN., V0, P1
   Gokon H, 2015, IEEE GEOSCI REMOTE S, V12, P1277, DOI 10.1109/LGRS.2015.2392792
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Henry C, 2018, IEEE GEOSCI REMOTE S, V15, P1867, DOI 10.1109/LGRS.2018.2864342
   Karimzadeh S, 2018, IEEE J-STARS, V11, P2668, DOI 10.1109/JSTARS.2018.2825399
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Liang D, 2017, REMOTE SENS LETT, V8, P126, DOI 10.1080/2150704X.2016.1235807
   Linlin Ge, 2015, ANNALS OF GIS, V21, P175, DOI 10.1080/19475683.2015.1068221
   Liu W, 2013, EARTHQ SPECTRA, V29, PS183, DOI 10.1193/1.4000120
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Schmitt M, 2019, ISPRS J PHOTOGRAMM, V148, P130, DOI 10.1016/j.isprsjprs.2018.12.007
   Van Etten, 2017, SPACENET ROAD DETE 1, V0, P0
   Wang J, 2015, INT J REMOTE SENS, V36, P3144, DOI 10.1080/01431161.2015.1054049
   Wang SL, 2017, IEEE I CONF COMP VIS, V0, PP3028, DOI 10.1109/ICCV.2017.327
   Zeiler MD, 2010, PROC CVPR IEEE, V0, PP2528, DOI 10.1109/CVPR.2010.5539957
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou LC, 2018, IEEE COMPUT SOC CONF, V0, PP192, DOI 10.1109/CVPRW.2018.00034
NR 24
TC 1
Z9 1
U1 0
U2 4
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 1682-1750
EI 2194-9034
J9 INT ARCH PHOTOGRAMM
PD JUN 15
PY 2019
VL 42-3
IS W8
BP 195
EP 200
DI 10.5194/isprs-archives-XLII-3-W8-195-2019
PG 6
WC Geography, Physical; Management; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Business & Economics; Remote Sensing; Imaging Science & Photographic Technology
GA BS0WA
UT WOS:000684596600032
DA 2023-04-26
ER

PT J
AU Azeez, OS
   Pradhan, B
   Shafri, HZM
   Shukla, N
   Lee, CW
   Rizeei, HM
AF Azeez, Omer Saud
   Pradhan, Biswajeet
   Shafri, Helmi Z. M.
   Shukla, Nagesh
   Lee, Chang-Wook
   Rizeei, Hossein Mojaddadi
TI Modeling of CO Emissions from Traffic Vehicles Using Artificial Neural Networks
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE traffic CO; traffic CO prediction; neural networks; GIS; land use/land cover (LULC)
ID land-use regression; air-pollution; noise-levels; pm10 concentrations; urban air; prediction; quality; road; complex; gis
AB Traffic emissions are considered one of the leading causes of environmental impact in megacities and their dangerous effects on human health. This paper presents a hybrid model based on data mining and GIS models designed to predict vehicular Carbon Monoxide (CO) emitted from traffic on the New Klang Valley Expressway, Malaysia. The hybrid model was developed based on the integration of GIS and the optimized Artificial Neural Network algorithm that combined with the Correlation based Feature Selection (CFS) algorithm to predict the daily vehicular CO emissions and generate prediction maps at a microscale level in a small urban area by using a field survey and open source data, which are the main contributions to this paper. The other contribution is related to the case study, which represents the spatial and quantitative variations in the vehicular CO emissions between toll plaza areas and road networks. The proposed hybrid model consists of three steps: the first step is the implementation of the correlation-based Feature Selection model to select the best model's predictors; the second step is the prediction of vehicular CO by using a multilayer perceptron neural network model; and the third step is the creation of micro scale prediction maps. The model was developed using six traffic CO predictors: number of vehicles, number of heavy vehicles, number of motorbikes, temperature, wind speed and a digital surface model. The network architecture and its hyperparameters were optimized through a grid search approach. The traffic CO concentrations were observed at 15-min intervals on weekends and weekdays, four times per day. The results showed that the developed model had achieved validation accuracy of 80.6 %. Overall, the developed models are found to be promising tools for vehicular CO simulations in highly congested areas.
C1 [Azeez, Omer Saud; Shafri, Helmi Z. M.] Univ Putra Malaysia, Dept Civil Engn, Fac Engn, Serdang 43400, Malaysia.
   [Pradhan, Biswajeet; Shukla, Nagesh; Rizeei, Hossein Mojaddadi] Univ Technol Sydney, Fac Engn & Informat Technol, CAMGIS, Sydney, NSW 2007, Australia.
   [Lee, Chang-Wook] Kangwon Natl Univ, Div Sci Educ, 1 Kangwondaehak Gil, Chuncheon Si 24341, Gangwon Do, South Korea.
C3 Universiti Putra Malaysia; University of Technology Sydney; Kangwon National University
RP Pradhan, B (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, CAMGIS, Sydney, NSW 2007, Australia.; Lee, CW (corresponding author), Kangwon Natl Univ, Div Sci Educ, 1 Kangwondaehak Gil, Chuncheon Si 24341, Gangwon Do, South Korea.
EM baghdad.eagle2016@gmail.com; Biswajet.Pradhan@uts.edu.au; helmi@upm.edu.my; nagesh.shukla@uts.edu.au; cwlee@kangwon.ac.kr; h.mojaddadi@gmail.com
FU UTS [321740.2232335, 321740.2232357]
CR Ancona C, 2017, J TRANSP HEALTH, V5, PS42, DOI 10.1016/j.jth.2017.05.331
   [Anonymous], 1999, CORRELATION BASED FE, V0, P0
   Bastien LAJ, 2015, ENVIRON SCI TECHNOL, V49, P7276, DOI 10.1021/acs.est.5b00686
   Behera SN, 2015, URBAN CLIM, V14, P396, DOI 10.1016/j.uclim.2014.12.003
   Borge R, 2016, ATMOS ENVIRON, V140, P432, DOI 10.1016/j.atmosenv.2016.06.020
   BOZNAR M, 1993, ATMOS ENVIRON B-URB, V27, P221, DOI 10.1016/0957-1272(93)90007-S
   Cai M, 2009, TRANSPORT RES D-TR E, V14, P32, DOI 10.1016/j.trd.2008.10.004
   Chaloulakou A, 2003, SCI TOTAL ENVIRON, V313, P1, DOI 10.1016/S0048-9697(03)00335-8
   Chen KS, 2003, SCI TOTAL ENVIRON, V312, P113, DOI 10.1016/S0048-9697(03)00196-7
   Crouse DL, 2010, ENVIRON HEALTH PERSP, V118, P1578, DOI 10.1289/ehp.1002221
   Juez FJD, 2010, MATH COMPUT MODEL, V52, P1177, DOI 10.1016/j.mcm.2010.03.017
   Delfino RJ, 2010, EPIDEMIOLOGY, V21, P396, DOI 10.1097/EDE.0b013e3181d5e19b
   Di Mascio P, 2012, PROCD SOC BEHV, V53, P1203, DOI 10.1016/j.sbspro.2012.09.969
   Domene E, 2017, J TRANSP HEALTH, V5, PS60, DOI 10.1016/j.jth.2017.05.355
   Fameli KM, 2015, SCI TOTAL ENVIRON, V505, P770, DOI 10.1016/j.scitotenv.2014.10.015
   Friedman J., 2001, ELEMENTS STAT LEARNI, V1, P0
   Nieto PJG, 2018, SCI TOTAL ENVIRON, V621, P753, DOI 10.1016/j.scitotenv.2017.11.291
   Gardner MW, 1999, ATMOS ENVIRON, V33, P709, DOI 10.1016/S1352-2310(98)00230-1
   Garshick E, 2003, EPIDEMIOLOGY, V14, P728, DOI 10.1097/01.ede.0000082045.50073.66
   Goyal P, 2003, ATMOS ENVIRON, V37, P5423, DOI 10.1016/j.atmosenv.2003.09.005
   Hamad K, 2017, TRANSPORT RES D-TR E, V53, P161, DOI 10.1016/j.trd.2017.04.014
   Henderson SB, 2007, ENVIRON SCI TECHNOL, V41, P2422, DOI 10.1021/es0606780
   Hooyberghs J, 2005, ATMOS ENVIRON, V39, P3279, DOI 10.1016/j.atmosenv.2005.01.050
   Hulsmann F, 2014, URBAN CLIM, V10, P732, DOI 10.1016/j.uclim.2014.01.001
   Johnson M, 2010, ATMOS ENVIRON, V44, P3660, DOI 10.1016/j.atmosenv.2010.06.041
   Kanaroglou PS, 2013, ATMOS ENVIRON, V79, P421, DOI 10.1016/j.atmosenv.2013.07.014
   Kho FWL, 2007, INT J ENVIRON SCI TE, V4, P27, DOI 10.1007/BF03325958
   Kim Y, 2015, ATMOS ENVIRON, V107, P364, DOI 10.1016/j.atmosenv.2015.02.053
   Kirchstetter TW, 1996, ENVIRON SCI TECHNOL, V30, P661, DOI 10.1021/es950406p
   Kukkonen J, 2003, ATMOS ENVIRON, V37, P4539, DOI 10.1016/S1352-2310(03)00583-1
   Kwok LK, 2017, ATMOS POLLUT RES, V8, P114, DOI 10.1016/j.apr.2016.08.001
   Li F, 2016, TRANSPORT RES D-TR E, V49, P313, DOI 10.1016/j.trd.2016.10.019
   Mousavi SZ, 2011, GEOMAT NAT HAZ RISK, V2, P33, DOI 10.1080/19475705.2010.532975
   Namdeo A, 2002, ENVIRON MODELL SOFTW, V17, P179, DOI 10.1016/S1364-8152(01)00063-9
   Oftedal B, 2015, ENVIRON RES, V138, P144, DOI 10.1016/j.envres.2015.01.011
   Pao HT, 2012, ENERGY, V40, P400, DOI 10.1016/j.energy.2012.01.037
   PAO YH, 1992, INT J CONTROL, V56, P263, DOI 10.1080/00207179208934315
   Quaassdorff C, 2016, SCI TOTAL ENVIRON, V566, P416, DOI 10.1016/j.scitotenv.2016.05.051
   Ragettli MS, 2016, J EXPO SCI ENV EPID, V26, P597, DOI 10.1038/jes.2015.82
   Ranjbar H.R., 2012, J GEOGR INF SYST, V4, P322, DOI 10.4236/jgis.2012.44037
   Righini G, 2014, ATMOS ENVIRON, V97, P121, DOI 10.1016/j.atmosenv.2014.08.015
   Rojek I, 2017, AI EDAM, V31, P1, DOI 10.1017/S0890060416000147
   Shakerkhatibi M, 2015, ENV HEALTH ENG MANAG, V2, P117
   Sharma N, 2013, J SCI IND RES INDIA, V72, P521
   Shi Y, 2016, ENVIRON SCI TECHNOL, V50, P8178, DOI 10.1021/acs.est.6b01807
   Singh D, 2016, SCI TOTAL ENVIRON, V572, P586, DOI 10.1016/j.scitotenv.2016.08.086
   Tomic J, 2016, J ACOUST SOC AM, V140, PEL340, DOI 10.1121/1.4964786
   Vandaele N, 2000, TRANSPORT RES D-TR E, V5, P121, DOI 10.1016/S1361-9209(99)00028-0
   Zarandi MHF, 2012, APPL SOFT COMPUT, V12, P291, DOI 10.1016/j.asoc.2011.08.043
   Zheng Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD13), V0, PP1436, DOI 10.1145/2487575.2488188
NR 50
TC 30
Z9 31
U1 3
U2 37
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2076-3417
EI 
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD JAN 2
PY 2019
VL 9
IS 2
BP 
EP 
DI 10.3390/app9020313
PG 23
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA HM4IG
UT WOS:000459436300103
DA 2023-04-26
ER
