
PT J
AU Saeedimoghaddam, M
   Stepinski, TF
AF Saeedimoghaddam, Mahmoud
   Stepinski, T. F.
TI Automatic extraction of road intersection points from USGS historical map series using deep convolutional neural networks
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Road network data; object detection; GIS; Faster RCNN; deep learning
ID scene classification; data augmentation; object detection; recognition; images
AB Road intersection data have been used across a range of geospatial analyses. However, many datasets dating from before the advent of GIS are only available as historical printed maps. To be analyzed by GIS software, they need to be scanned and transformed into a usable (vector-based) format. Because the number of scanned historical maps is voluminous, automated methods of digitization and transformation are needed. Frequently, these processes are based on computer vision algorithms. However, the key challenges to this are (1) the low conversion accuracy for low quality and visually complex maps, and (2) the selection of optimal parameters. In this paper, we used a region-based deep convolutional neural network-based framework (RCNN) for object detection, in order to automatically identify road intersections in historical maps of several cities in the United States of America. We found that the RCNN approach is more accurate than traditional computer vision algorithms for double-line cartographic representation of the roads, though its accuracy does not surpass all traditional methods used for single-line symbols. The results suggest that the number of errors in the outputs is sensitive to complexity and blurriness of the maps, and to the number of distinct red-green-blue (RGB) combinations within them.
C1 [Saeedimoghaddam, Mahmoud; Stepinski, T. F.] Univ Cincinnati, Geog & GIS Dept, Cincinnati, OH 45220 USA.
   [Stepinski, T. F.] Univ Cincinnati, Space Informat Lab, Cincinnati, OH 45220 USA.
C3 University System of Ohio; University of Cincinnati; University System of Ohio; University of Cincinnati
RP Saeedimoghaddam, M; Stepinski, TF (corresponding author), Univ Cincinnati, Geog & GIS Dept, Cincinnati, OH 45220 USA.; Stepinski, TF (corresponding author), Univ Cincinnati, Space Informat Lab, Cincinnati, OH 45220 USA.
EM saeedimd@mail.uc.edu; stepintz@uc.edu
CR Abrishami H., 2018, 2018 IEEE EMBS INT C, V0, PP210, DOI 10.1109/BHI.2018.8333406
   Akcay S, 2018, IEEE T INF FOREN SEC, V13, P2203, DOI 10.1109/TIFS.2018.2812196
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Allord G.J., 2014, STANDARD US GEOLOGIC, V3, P11
   Amit SNKB, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), V0, P239
   [Anonymous], 2016, 8 INT C QUALITY MULT, V0, P0
   [Anonymous], 2014, PROC IEEE C COMPUT V, V0, P0
   Ayrey E, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040649
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772
   Cetinic E, 2018, EXPERT SYST APPL, V114, P107, DOI 10.1016/j.eswa.2018.07.026
   Chen CC, 2008, GEOINFORMATICA, V12, P377, DOI 10.1007/s10707-007-0033-0
   Chen SQ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060820
   Chew RF, 2018, INT J HEALTH GEOGR, V17, P0, DOI 10.1186/s12942-018-0132-1
   Chiang Y.-Y, 2013, GRAPHICS RECOGNITION, V0, PP25, DOI 10.1007/978-3-642-36824-0
   Chiang Y.Y., 2005, P 13 ANN ACM INT WOR, V0, PP267, DOI 10.1145/1097064.1097102
   Chiang YY, 2009, GEOINFORMATICA, V13, P121, DOI 10.1007/s10707-008-0046-3
   Chollet F., 2017, DEEP LEARNING PYTHON, V0, P0
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZP, 2017, IEEE J-STARS, V10, P3652, DOI 10.1109/JSTARS.2017.2694890
   Dickerson N.L., 2017, THESIS, V0, P0
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao WS, 2010, INT CONF COMP SCI, V0, PP67, DOI 10.1109/ICCSIT.2010.5563693
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Henderson Thomas C., 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP376, DOI 10.1109/ICDAR.2009.31
   Henderson T.C., 2014, ROAD ROAD INTERSECTI, V0, P141
   Henry C., 2018, ABS180201445 CORR, V0, P0
   Huang J, 2017, IEEE INT C INT ROBOT, V0, P3296
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, V0, PP650, DOI 10.1109/MWSYM.2017.8058653
   Jo H, 2017, INT C CONTR AUTOMAT, V0, P1035
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   Karahan S., 2016, 2016 INT C BIOMETRIC, V0, P1
   Khan Salman, 2018, GUIDE CONVOLUTIONAL, V0, P0, DOI DOI 10.2200/S00822ED1V01Y201712COV015
   Krahenbuhl P, 2015, PROC CVPR IEEE, V0, PP1574, DOI 10.1109/CVPR.2015.7298765
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long Y, 2016, APPL GEOGR, V75, P36, DOI 10.1016/j.apgeog.2016.08.002
   Lu KY, 2018, COMPUT VIS IMAGE UND, V172, P77, DOI 10.1016/j.cviu.2018.02.008
   Lv JJ, 2017, NEUROCOMPUTING, V230, P184, DOI 10.1016/j.neucom.2016.12.025
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Masucci A, 2015, PREPRINT, V0, P0
   Murcio R, 2015, PHYS REV E, V92, P0, DOI 10.1103/PhysRevE.92.062130
   Naik Z.K., 2018, INT J COMPUTER APPL, V180, P46
   OShea K, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Pech-Pacheco JL, 2000, INT C PATT RECOG, V0, PP314, DOI 10.1109/ICPR.2000.903548
   Peters R.A., 1990, IMAGE COMPLEXITY MET, V0, P0, DOI DOI 10.1099/00221287-136-2-327
   Pezeshk A, 2011, IEEE T GEOSCI REMOTE, V49, P5047, DOI 10.1109/TGRS.2011.2157697
   Phung SL, 2007, INT CONF ACOUST SPEE, V0, P1229
   Rahnemoonfar M, 2017, PROC SPIE, V10218, P0, DOI 10.1117/12.2263097
   Redmon J., 2016, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Shojaee Ali, 2019, CONNECTOMICS IN NEUROIMAGING. THIRD INTERNATIONAL WORKSHOP, V0, P83, DOI 10.1007/978-3-030-32391-2_9
   Simonyan K, 2015, ARXIV, V0, P0
   Tao YM, 2016, IEEE C EVOL COMPUTAT, V0, PP1349, DOI 10.1109/CEC.2016.7743945
   Uhl J., 2017, P 8 INT C PATTERN RE, V0, P0, DOI DOI 10.1049/CP.2017.0144
   Uhl JH, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7040148
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   USGS, 2005, TOP MAP SYMB, V0, P0
   Volokitin A., 2017, ABS170608616 CORR, V0, P0
   Wang J, 2015, INT J REMOTE SENS, V36, P3144, DOI 10.1080/01431161.2015.1054049
   Wang YC, 2016, INT J COMPUT SCI NET, V16, P21
   Weiwei Duan, 2017, SIGSPATIAL SPECIAL, V9, P6, DOI 10.1145/3178392.3178396
   Wu CH, 2017, IEEE WINT CONF APPL, V0, PP540, DOI 10.1109/WACV.2017.66
   Xi Y, 2018, COGN SYST RES, V52, P144, DOI 10.1016/j.cogsys.2018.06.014
   Xia G., 2017, ABS171110398 CORR, V0, P0
   Yang Z, 2018, OPTIK, V171, P287, DOI 10.1016/j.ijleo.2018.06.024
   Zarbaf SEHAM, 2018, ENG STRUCT, V177, P291, DOI 10.1016/j.engstruct.2018.09.060
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 77
TC 31
Z9 32
U1 7
U2 24
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD MAY 3
PY 2020
VL 34
IS 5
BP 947
EP 968
DI 10.1080/13658816.2019.1696968
EA NOV 2019
PG 22
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA KZ0PC
UT WOS:000499070400001
DA 2023-04-26
ER

PT J
AU Ye, XH
   Xiong, FC
   Lu, JF
   Zhao, HF
   Zhou, J
AF Ye, Xinhai
   Xiong, Fengchao
   Lu, Jianfeng
   Zhao, Haifeng
   Zhou, Jun
TI M-2-Net: A Multi-scale Multi-level Feature Enhanced Network for Object Detection in Optical Remote Sensing Images
SO 2020 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA)
LA English
DT Proceedings Paper
DE Convolutional neural network (CNN); object detection; feature fusion; remote sensing image; multi-scale analysis
AB Object detection in remote sensing images is a challenging task due to diversified orientation, complex background, dense distribution and scale variation of objects. In this paper, we tackle this problem by proposing a novel multi-scale multi-level feature enhanced network (M-2-Net) that integrates a Feature Map Enhancement (FME) module and a Feature Fusion Block (FFB) into Rotational RetinaNet. The FME module aims to enhance the weak features by factorizing the convolutional operation into two similar branches instead of one single branch, which helps to broaden receptive field with less parameters. This module is embedded into different layers in the backbone network to capture multi-scale semantics and location information for detection. The FFB module is used to shorten the information propagation path between low-level high-resolution features in shallow layers and high-level semantic features in deep layers, facilitating more effective feature fusion and object detection especially those with small sizes. Experimental results on three benchmark datasets show that our method not only outperforms many one-stage detectors but also achieves competitive accuracy with lower time cost than two-stage detectors.
C1 [Ye, Xinhai; Xiong, Fengchao; Lu, Jianfeng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Zhao, Haifeng] Jinling Inst Technol, Sch Software Engn, Nanjing, Peoples R China.
   [Zhou, Jun] Griffith Univ, Sch Informat & Commun, Nathan, Qld, Australia.
RP Xiong, FC; Lu, JF (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
EM yyxxhh@njust.edu.cn; fcxiong@njust.edu.cn; zhf@jit.edu.cn; jun.zhou@griffith.edu.au
FU National Natural Science Foundation of China [62002169]; National Key Research and Development Program of China [2017YFB1300205]; Research Foundation for Advanced Talents and Incubation Foundation of Jingling Institute of Technology [JIT-B-201717, JIT-FHXM-201808]; Major Program of University Natural Science Research of Jiangsu Province [16KJA520003]
CR Azimi SM, 2019, LECT NOTES COMPUT SC, V11363, P150, DOI 10.1007/978-3-030-20893-6_10
   Chen J, 2020, IEEE GEOSCI REMOTE S, V17, P681, DOI 10.1109/LGRS.2019.2930462
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Dai JF, 2016, ADV NEUR IN, V29, P0
   Ding J, 2019, PROC CVPR IEEE, V0, PP2844, DOI 10.1109/CVPR.2019.00296
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Ding XH, 2019, IEEE I CONF COMP VIS, V0, PP1911, DOI 10.1109/ICCV.2019.00200
   Girshick R., 2014, P IEEE C COMP VIS PA, V0, P580
   Girshick R., 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He K, 2017, IEEE INT WORKSH MULT, V0, P0
   Hendrycks D, 2020, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1606.08415
   Jiang YY, 2017, ARXIV, V0, P0
   Li CZ, 2019, IEEE IMAGE PROC, V0, PP3886, DOI 10.1109/ICIP.2019.8803521
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Lin YT, 2021, ARXIV, V0, P0
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WC, 2019, IEEE GEOSCI REMOTE S, V16, P791, DOI 10.1109/LGRS.2018.2882778
   Pang JM, 2019, IEEE T GEOSCI REMOTE, V57, P5512, DOI 10.1109/TGRS.2019.2899955
   Qin H., 2020, IEEE GEOSCI REMOTE S, V0, P0
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Szegedy C., 2015, P 2015 IEEE C COMPUT, V0, P0
   Tayara H, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18103341
   Wang C, 2019, IEEE GEOSCI REMOTE S, V16, P310, DOI 10.1109/LGRS.2018.2872355
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Xiao ZF, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060908
   Yang X, 2020, ARXIV, V0, P0
   Yang X, 2019, IEEE I CONF COMP VIS, V0, PP8231, DOI 10.1109/ICCV.2019.00832
   Yang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010132
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang XD, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070755
   Zhu H., 2015, PROC IEEE INT C IMAG, V0, P0
NR 40
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2020
VL 0
IS 
BP 
EP 
DI 10.1109/DICTA51227.2020.9363420
PG 8
WC Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology
SC Computer Science; Imaging Science & Photographic Technology
GA BU7CC
UT WOS:000935148000053
DA 2023-04-26
ER

PT J
AU Hakim, WL
   Lee, CW
AF Hakim, Wahyu Luqmanul
   Lee, Chang-Wook
TI A Review on Remote Sensing and GIS Applications to Monitor Natural Disasters in Indonesia
SO KOREAN JOURNAL OF REMOTE SENSING
LA English
DT Review
DE Remote Sensing; GIS; Natural Disaster; Review; Indonesia
ID persistent scatterer interferometry; central java; land subsidence; logistic-regression; surface deformation; frequency ratio; high-resolution; merapi volcano; mount sinabung; neural-network
AB Indonesia is more prone to natural disasters due to its geological condition under the three main plates, making Indonesia experience frequent seismic activity, causing earthquakes, volcanic eruption, and tsunami. Those disasters could lead to other disasters such as landslides, floods, land subsidence, and coastal inundation. Monitoring those disasters could be essential to predict and prevent damage to the environment. We reviewed the application of remote sensing and Geographic Information System (GIS) for detecting natural disasters in the case of Indonesia, based on 43 articles. The remote sensing and GIS method will be focused on InSAR techniques, image classification, and susceptibility mapping. InSAR method has been used to monitor natural disasters affecting the deformation of the earth's surface in Indonesia, such as earthquakes, volcanic activity, and land subsidence. Monitoring landslides in Indonesia using InSAR techniques has not been found in many studies; hence it is crucial to monitor the unstable slope that leads to a landslide. Image classification techniques have been used to monitor pre-and post-natural disasters in Indonesia, such as earthquakes, tsunami, forest fires, and volcano eruptions. It has a lack of studies about the classification of flood damage in Indonesia. However, flood mapping was found in susceptibility maps, as many studies about the landslide susceptibility map in Indonesia have been conducted. However, a land subsidence susceptibility map was the one subject to be studied more to decrease land subsidence damage, considering many reported cases found about land subsidence frequently occur in several cities in Indonesia.
C1 [Hakim, Wahyu Luqmanul] Kangwon Natl Univ, Dept Smart Reg Innovat, Chunchon, South Korea.
   [Lee, Chang-Wook] Kangwon Natl Univ, Dept Sci Educ, Chunchon, South Korea.
C3 Kangwon National University; Kangwon National University
RP Lee, CW (corresponding author), Kangwon Natl Univ, Dept Sci Educ, Chunchon, South Korea.
EM cwlee@kangwon.ac.kr
FU National Research Foundation of Korea; government of Korea [2019R1A2C1085686]
CR Abidin HZ, 2011, NAT HAZARDS, V59, P1753, DOI 10.1007/s11069-011-9866-9
   Achmad A.R., 2020, REMOTE SENSING, V12, P1
   Achmad A.R., 2020, REMOTE SENSING, V12, P1
   Achmad AR, 2019, J COASTAL RES, V0, PP214, DOI 10.2112/SI90-026.1
   Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   Agustin F., 2017, GIS LANDSLIDE, V0, P183
   Aitkenhead MJ, 2007, DISASTERS, V31, P217, DOI 10.1111/j.1467-7717.2007.01005.x
   Albino F, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-08564-9
   [Anonymous], 2015, P 4 IND JAP C KNOWL, V0, P1
   Aoki Y., 2018, P IOP C SERIES MAT S, V344, P1
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172833
   Arifianti Y., 2018, P 2018 IOP C SER EAR, V0, P20
   Babu A., 2019, MULTIDISCIPLINARY DI, V24, P21
   Berardino P, 2002, IEEE T GEOSCI REMOTE, V40, P2375, DOI 10.1109/TGRS.2002.803792
   BNPB(Badan Nasional Penanggulangan Bencana), 2020, DAT INF DIS IND, V0, P0
   Booysen R., 2021, ENCY GEOLOGY, Vsecond, P301, DOI 10.1016/B978-0-12-409548-9.12127-X.9780081029091
   Budiyono Y, 2016, NAT HAZARD EARTH SYS, V16, P757, DOI 10.5194/nhess-16-757-2016
   Chaussard E, 2013, J GEOPHYS RES-SOL EA, V118, P3957, DOI 10.1002/jgrb.50288
   Chaussard E, 2013, REMOTE SENS ENVIRON, V128, P150, DOI 10.1016/j.rse.2012.10.015
   Chaussard E, 2012, GEOPHYS RES LETT, V39, P0, DOI 10.1029/2012GL053817
   Cho M, 2013, KOREAN J REMOTE SENS, V29, P443, DOI 10.7780/kjrs.2013.29.5.1
   Crosetto M, 2016, ISPRS J PHOTOGRAMM, V115, P78, DOI 10.1016/j.isprsjprs.2015.10.011
   Dewi RS, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030190
   Dong J, 2018, REMOTE SENS ENVIRON, V205, P180, DOI 10.1016/j.rse.2017.11.022
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gaillard JC, 2008, NAT HAZARDS, V47, P17, DOI 10.1007/s11069-007-9193-3
   Gonzalez PJ, 2015, PURE APPL GEOPHYS, V172, P3229, DOI 10.1007/s00024-014-0915-7
   Guyon D, 2016, LAND SURFACE REMOTE SENSING IN AGRICULTURE AND FOREST, V0, P249
   Hadmoko DS, 2017, NAT HAZARDS, V87, P437, DOI 10.1007/s11069-017-2772-z
   Hooper A, 2012, TECTONOPHYSICS, V514, P1, DOI 10.1016/j.tecto.2011.10.013
   Jensen J.R., 2000, UPPER SADDLE RIVER N, V1, P1
   Ji LY, 2013, GEOD GEODYN, V4, P65, DOI 10.3724/SP.J.1246.2013.03065
   Kadavi P.R., 2020, ARABIAN J GEOSCIENCE, V13, P1
   Kadavi PR, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7090935
   Kerle N, 2010, INT J APPL EARTH OBS, V12, P466, DOI 10.1016/j.jag.2010.07.004
   Kusumastuti RD, 2014, INT J DISAST RISK RE, V10, P327, DOI 10.1016/j.ijdrr.2014.10.007
   Lee CW, 2017, KOREAN J REMOTE SENS, V33, P37, DOI 10.7780/kjrs.2017.33.1.4
   Lee CW, 2015, INT GEOSCI REMOTE SE, V0, PP4793, DOI 10.1109/IGARSS.2015.7326902
   Lee S, 2019, KOREAN J REMOTE SENS, V35, P179, DOI 10.7780/kjrs.2019.35.1.12
   Lee S, 2013, J ENVIRON MANAGE, V127, P166, DOI 10.1016/j.jenvman.2013.04.010
   Lee SK, 2015, B VOLCANOL, V77, P0, DOI 10.1007/s00445-015-0920-4
   Li M, 2014, EUR J REMOTE SENS, V47, P389, DOI 10.5721/EuJRS20144723
   Li ZW, 2019, EARTH-SCI REV, V192, P258, DOI 10.1016/j.earscirev.2019.03.008
   Maghsoudi Y, 2018, INT J APPL EARTH OBS, V64, P386, DOI 10.1016/j.jag.2017.04.001
   Maguire, 1991, GEOGRAPHICAL INFORMA, V1, P9
   Marfai MA, 2008, ENVIRON GEOL, V56, P335, DOI 10.1007/s00254-007-1169-9
   Marfai MA, 2008, ENVIRON GEOL, V55, P1507, DOI 10.1007/s00254-007-1101-3
   Meilianda E, 2019, INT J DISAST RISK RE, V41, P0, DOI 10.1016/j.ijdrr.2019.101292
   Moya L, 2020, REMOTE SENS ENVIRON, V242, P0, DOI 10.1016/j.rse.2020.111743
   Ng AHM, 2012, INT J APPL EARTH OBS, V18, P232, DOI 10.1016/j.jag.2012.01.018
   Niemeier W., 2019, REMOTE SENSING SPATI, V42, P623
   Oh HJ, 2010, ENVIRON EARTH SCI, V60, P1317, DOI 10.1007/s12665-009-0272-5
   Osmanoglu B, 2016, ISPRS J PHOTOGRAMM, V115, P90, DOI 10.1016/j.isprsjprs.2015.10.003
   Pepe A, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7121264
   Pradhan B, 2010, GEOMAT NAT HAZ RISK, V1, P199, DOI 10.1080/19475705.2010.498151
   Prasetyo LB, 2016, PROCEDIA ENVIRON SCI, V33, P450, DOI 10.1016/j.proenv.2016.03.096
   Qu CY, 2017, ACTA GEOL SIN-ENGL, V91, P93, DOI 10.1111/1755-6724.13065
   Rasyid AR., 2016, GEOENVIRONMENTAL DIS, V3, P1, DOI 10.1186/S40677-016-0053-X
   Rofi A, 2006, DISASTERS, V30, P340, DOI 10.1111/j.0361-3666.2005.00324.x
   Rosen PA, 2000, P IEEE, V88, P333, DOI 10.1109/5.838084
   Schindler S., 2016, VISUALIZATION ENG, V4, P1
   Siegert F, 2000, REMOTE SENS ENVIRON, V72, P64, DOI 10.1016/S0034-4257(99)00092-9
   Silalahi FES, 2019, GEOSCI LETT, V6, P0, DOI 10.1186/s40562-019-0140-4
   Soldato M.D., 2019, REMOTE SENSING, V11, P1
   Syifa M, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19030542
   Takagi H, 2016, URBAN CLIM, V17, P135, DOI 10.1016/j.uclim.2016.05.003
   Tambunan MP, 2017, IOP C SER EARTH ENV, V56, P0, DOI 10.1088/1755-1315/56/1/012014
   Tang J., 2014, CH CRC DATA MIN KNOW, V0, P37
   Tanioka Y., 2010, J GEOPHYS RES, V115, P1
   Thouret JC, 2015, REMOTE SENS ENVIRON, V170, P350, DOI 10.1016/j.rse.2015.09.028
   Tolomei C, 2019, INT GEOSCI REMOTE SE, V0, PP9674, DOI 10.1109/IGARSS.2019.8899102
   Umar Z, 2014, CATENA, V118, P124, DOI 10.1016/j.catena.2014.02.005
   Vetrita Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010005
   Voight B, 2000, J VOLCANOL GEOTH RES, V100, P69, DOI 10.1016/S0377-0273(00)00134-7
   Wang CS, 2020, SEISMOL RES LETT, V91, P733, DOI 10.1785/0220190002
   Wang DL, 2012, GEOPHYS RES LETT, V39, P0, DOI 10.1029/2012GL053081
   Warlina L, 2019, J ENG SCI TECHNOL, V14, P3481
   Wati SE, 2010, INT ARCH PHOTOGRAMM, V38, P248
   Yastika PE, 2019, ADV SPACE RES, V63, P1719, DOI 10.1016/j.asr.2018.11.008
   Yu C., 2020, J GEOPHYS RES SOLID, V125, P1
   Yulianto F, 2013, NAT HAZARDS, V66, P229, DOI 10.1007/s11069-012-0438-4
NR 81
TC 6
Z9 6
U1 14
U2 60
PU KOREAN SOC REMOTE SENSING
PI SEOUL
PA KOREAN SOC REMOTE SENSING, SEOUL, 00000, SOUTH KOREA
SN 1225-6161
EI 2287-9307
J9 KOREAN J REMOTE SENS
JI Korean J. Remote Sensing
PD DEC 15
PY 2020
VL 36
IS 6
BP 1303
EP 1322
DI 10.7780/kjrs.2020.36.6.1.3
PG 20
WC Remote Sensing
SC Remote Sensing
GA PW1EJ
UT WOS:000610419200003
DA 2023-04-26
ER

PT J
AU Li, AS
   Chirayath, V
   Segal-Rozenhaimer, M
   Torres-Perez, JL
   van den Bergh, J
AF Li, Alan S.
   Chirayath, Ved
   Segal-Rozenhaimer, Michal
   Torres-Perez, Juan L.
   van den Bergh, Jarrett
TI NASA NeMO-Net's Convolutional Neural Network: Mapping Marine Habitats with Spectrally Heterogeneous Remote Sensing Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Machine learning; NASA; Spatial resolution; Satellites; Image segmentation; Convolutional neural network (CNN); deep learning; image segmentation; multispectral imaging
ID coral-reef; satellite; classification; resolution; environments; sensors; cover
AB Recent advances in machine learning and computer vision have enabled increased automation in benthic habitat mapping through airborne and satellite remote sensing. Here, we applied deep learning and neural network architectures in NASA NeMO-Net, a novel neural multimodal observation and training network for global habitat mapping of shallow benthic tropical marine systems. These ecosystems, particularly coral reefs, are undergoing rapid changes as a result of increasing ocean temperatures, acidification, and pollution, among other stressors. Remote sensing from air and space has been the primary method in which changes are assessed within these important, often remote, ecosystems at a global scale. However, such global datasets often suffer from large spectral variances due to the time of observation, atmospheric effects, water column properties, and heterogeneous instruments and calibrations. To address these challenges, we developed an object-based fully convolutional network (FCN) to improve upon the spatial-spectral classification problem inherent in multimodal datasets. We showed that with training upon augmented data in conjunction with classical methods, such as K-nearest neighbors, we were able to achieve better overall classification and segmentation results. This suggests FCNs are able to effectively identify the relative applicable spectral and spatial spaces within an image, whereas pixel-based classical methods excel at classification within those identified spaces. Our spectrally invariant results, based on minimally preprocessed WorldView-2 and Planet satellite imagery, show a total accuracy of approximately 85% and 80%, respectively, over nine classes when trained and tested upon a chain of Fijian islands imaged under highly variable day-to-day spectral inputs.
C1 [Li, Alan S.; Chirayath, Ved; Segal-Rozenhaimer, Michal; Torres-Perez, Juan L.; van den Bergh, Jarrett] NASA, Earth Sci Div Code SG, Ames Res Ctr, Mountain View, CA 94035 USA.
C3 National Aeronautics & Space Administration (NASA); NASA Ames Research Center
RP Li, AS (corresponding author), NASA, Earth Sci Div Code SG, Ames Res Ctr, Mountain View, CA 94035 USA.
EM alan.s.li@nasa.gov; ved.c@nasa.gov; michal.segalrozenhaimer@nasa.gov; juan.l.torresperez@nasa.gov; jarrett.s.vandenbergh@nasa.gov
FU National Aeronautics and Space Administration (NASA) Earth Science Technology Office (ESTO), under the Advanced Information Systems Technology (AIST) Program [AIST-16-0046]; National Aeronautics and Space Administration (NASA) Earth Science Technology Office (ESTO), under the Biodiversity and Ecological Forecasting Program [AIST-16-0046]
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI 10.1145/3022670.2976746
   Ainsworth TD, 2016, SCIENCE, V352, P338, DOI 10.1126/science.aac7125
   Alonso I, 2017, IEEE INT CONF COMP V, V0, PP2874, DOI 10.1109/ICCVW.2017.339
   Alonso K, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19204471
   Andrefouet S, 2003, REMOTE SENS ENVIRON, V88, P128, DOI 10.1016/j.rse.2003.04.005
   Andrefouet S, 2001, REMOTE SENS ENVIRON, V78, P150, DOI 10.1016/S0034-4257(01)00256-5
   Andrefouet S, 2001, INT J REMOTE SENS, V22, P987, DOI 10.1080/014311601300074522
   [Anonymous], 2001, 18 INT C MACHINE LEA, V0, P0
   [Anonymous], 2015, P IEEE C COMP VIS PA, V0, P0
   [Anonymous], 2015, SENTINEL 2 USER HDB, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0
   [Anonymous], 2009, WORLDVIEW 2, V0, P0
   Bachmann CM, 2006, IEEE T GEOSCI REMOTE, V44, P2786, DOI 10.1109/TGRS.2006.881801
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benfield SL, 2007, INT J REMOTE SENS, V28, P5047, DOI 10.1080/01431160701258062
   Berman M, 2018, PROC CVPR IEEE, V0, PP4413, DOI 10.1109/CVPR.2018.00464
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Call KA, 2003, INT J REMOTE SENS, V24, P2627, DOI 10.1080/0143116031000066990
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chirayath V, 2019, REMOTE SENS ENVIRON, V235, P0, DOI 10.1016/j.rse.2019.111475
   Chirayath V, 2019, FRONT MAR SCI, V6, P0, DOI 10.3389/fmars.2019.00521
   Chirayath V, 2016, AQUAT CONSERV, V26, P237, DOI 10.1002/aqc.2654
   Chollet F, 2015, KERAS, V0, P0
   Clark ML, 2016, ISPRS J PHOTOGRAMM, V119, P228, DOI 10.1016/j.isprsjprs.2016.06.007
   Collin A, 2012, REMOTE SENS-BASEL, V4, P1425, DOI 10.3390/rs4051425
   Cooley T, 2002, INT GEOSCI REMOTE SE, V0, PP1414, DOI 10.1109/IGARSS.2002.1026134
   Davis C. O., 2008, P IEEE INT GEOSC REM, V0, PP101, DOI 10.1109/IGARSS.2008.4779666
   Dial G, 2003, REMOTE SENS ENVIRON, V88, P23, DOI 10.1016/j.rse.2003.08.014
   Dill J, 2019, ADV INFORM KNOWL PRO, V0, PP11, DOI 10.1007/978-3-030-24367-8_2
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Guild L., 2007, PROC 32 INT S REMOTE, V0, P616
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hedley JD, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020118
   Heron SF, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep38402
   Hochberg EJ, 2003, REMOTE SENS ENVIRON, V85, P174, DOI 10.1016/S0034-4257(02)00202-X
   Hochberg EJ, 2003, REMOTE SENS ENVIRON, V85, P159, DOI 10.1016/S0034-4257(02)00201-8
   Hughes TP, 2018, NATURE, V556, P492, DOI 10.1038/s41586-018-0041-2
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   King A, 2018, IEEE COMPUT SOC CONF, V0, PP1475, DOI 10.1109/CVPRW.2018.00188
   King DB, 2015, ACS SYM SER, V1214, P1
   Kleypas JA, 2007, B MAR SCI, V80, P419
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Li JW, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121445
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   LYZENGA DR, 1978, APPL OPTICS, V17, P379, DOI 10.1364/AO.17.000379
   Maggiori E, 2016, INT GEOSCI REMOTE SE, V0, PP5071, DOI 10.1109/IGARSS.2016.7730322
   Mahmood A, 2016, OCEANS 2016 MTS/IEEE MONTEREY, V0, P0, DOI DOI 10.1109/OCEANS.2016.7761105
   Matsunaga T, 2019, INT GEOSCI REMOTE SE, V0, PP4495, DOI 10.1109/IGARSS.2019.8899179
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mouroulis P, 2014, APPL OPTICS, V53, P1363, DOI 10.1364/AO.53.001363
   Mumby PJ, 2002, REMOTE SENS ENVIRON, V82, P248, DOI 10.1016/S0034-4257(02)00041-X
   Nair V, 2010, ICML, V0, P807
   National Academies of Sciences Engineering and Medicine, 2018, THRIV OUR CHANG PLAN, V0, P0
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   P. Team, 2017, PLAN APPL PROGR INT, V0, P0
   Phinn SR, 2012, INT J REMOTE SENS, V33, P3768, DOI 10.1080/01431161.2011.633122
   Purkis S, 2002, INT J REMOTE SENS, V23, P1677, DOI 10.1080/01431160110047722
   Purkis SJ, 2019, CORAL REEFS, V38, P467, DOI 10.1007/s00338-019-01802-y
   Purkis SJ, 2018, ANNU REV MAR SCI, V10, P149, DOI 10.1146/annurev-marine-121916-063249
   Purkis SJ, 2005, IEEE T GEOSCI REMOTE, V43, P1375, DOI 10.1109/TGRS.2005.845646
   Roelfsema C, 2018, REMOTE SENS ENVIRON, V208, P27, DOI 10.1016/j.rse.2018.02.005
   Roelfsema C, 2013, INT J REMOTE SENS, V34, P6367, DOI 10.1080/01431161.2013.800660
   Roelfsema CM, 2014, REMOTE SENS ENVIRON, V150, P172, DOI 10.1016/j.rse.2014.05.001
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Segal-Rozenhaimer M, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111446
   Siegel DA, 2000, APPL OPTICS, V39, P3582, DOI 10.1364/AO.39.003582
   Silver A, 2019, NATURE, V570, P545, DOI 10.1038/d41586-019-01988-9
   Simonyan K, 2015, ARXIV, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Theriault C, 2006, CAN J REMOTE SENS, V32, P315, DOI 10.5589/m06-027
   Topping M, 2002, P SOC PHOTO-OPT INS, V4816, P1, DOI 10.1117/12.453794
   Tuia D, 2015, ISPRS J PHOTOGRAMM, V105, P272, DOI 10.1016/j.isprsjprs.2015.01.006
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   Wang ZW, 2014, IEEE T GEOSCI REMOTE, V52, P4808, DOI 10.1109/TGRS.2013.2285049
   Zhang CY, 2015, ISPRS J PHOTOGRAMM, V104, P213, DOI 10.1016/j.isprsjprs.2014.06.005
   Zoffoli ML, 2014, SENSORS-BASEL, V14, P16881, DOI 10.3390/s140916881
NR 82
TC 10
Z9 10
U1 6
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2020
VL 13
IS 
BP 5115
EP 5133
DI 10.1109/JSTARS.2020.3018719
PG 19
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA NR7UM
UT WOS:000571765800006
DA 2023-04-26
ER

PT J
AU Tao, RZ
   Zhang, YH
   Wang, LH
   Cai, PY
   Tan, HW
AF Tao, Runzhe
   Zhang, Yonghong
   Wang, Lihua
   Cai, Pengyan
   Tan, Haowen
TI Detection of Precipitation Cloud over the Tibet Based on the Improved U-Net
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE U-net; fy-4a; precipitation cloud; dense skip connections; residual network
AB Aiming at the problem of radar base and ground observation stations on the Tibet is sparsely distributed and cannot achieve large-scale precipitation monitoring. UNet, an advanced machine learning (ML) method, is used to develop a robust and rapid algorithm for precipitating cloud detection based on the new-generation geostationary satellite of FengYun-4A (FY-4A). First, in this algorithm, the real-time multi-band infrared brightness temperature from FY-4A combined with the data of Digital Elevation Model (DEM) has been used as predictor variables for our model. Second, the efficiency of the feature was improved by changing the traditional convolution layer serial connection method of U-Net to residual mapping. Then, in order to solve the problem of the network that would produce semantic differences when directly concentrated with low-level and high-level features, we use dense skip pathways to reuse feature maps of different layers as inputs for concatenate neural networks feature layers from different depths. Finally, according to the characteristics of precipitation clouds, the pooling layer of U-Net was replaced by a convolution operation to realize the detection of small precipitation clouds. It was experimentally concluded that the Pixel Accuracy (PA) and Mean Intersection over Union (MIoU) of the improved U-Net on the test set could reach 0.916 and 0.928, the detection of precipitation clouds over Tibet were well actualized.
C1 [Tao, Runzhe; Zhang, Yonghong; Wang, Lihua; Cai, Pengyan] Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
   [Tan, Haowen] Chosun Univ, Dept Comp Engn, Gwangju 501759, South Korea.
C3 Nanjing University of Information Science & Technology; Chosun University
RP Tao, RZ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
EM taorunzhe@sina.com
FU National Science Foundation of China [41875027]
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen BY, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP90, DOI 10.1145/3219819.3219926
   Dronner J., 2018, REMOTE SENSING, V1782, P1
   Forbes R., 2015, ECMWF NEWSLETTER, V144, P21, DOI 10.21957/JXT0NKY0
   Han B, 2018, ADV NEUR IN, V31, P0, DOI 10.5555/3327757.3327944
   [何钰 He Yu], 2013, 大气科学 CHINESE JOURNAL OF ATMOSPHERIC SCIENCES, V37, P933
   Huang GQ, 2019, NEUROCOMPUTING, V332, P215, DOI 10.1016/j.neucom.2018.12.050
   Kan X, 2018, CMC-COMPUT MATER CON, V57, P49, DOI 10.32604/cmc.2018.02376
   Liu J., 2019, J AMB INTEL HUM COMP, V0, PP1, DOI 10.1007/ S12652-019-01344-9
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Otsuka S, 2016, WEATHER FORECAST, V31, P329, DOI 10.1175/WAF-D-15-0063.1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi En, 2018, JOURNAL OF COMPUTER APPLICATIONS, V38, P661, DOI 10.11772/j.issn.1001-9081.2017082098
   Wang W, 2019, INT J COMPUT INT SYS, V12, P1592, DOI 10.2991/ijcis.d.191209.001
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zeng DJ, 2019, J INTELL FUZZY SYST, V36, P3971, DOI 10.3233/JIFS-169958
   Zhang XR, 2019, INT J SENS NETW, V31, P24, DOI 10.1504/IJSNET.2019.101567
   Zhou YS, 2019, ATMOS RES, V225, P131, DOI 10.1016/j.atmosres.2019.03.037
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zsoter E, 2015, METEOROL APPL, V22, P236, DOI 10.1002/met.1447
NR 20
TC 6
Z9 6
U1 6
U2 15
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PD JUN 15
PY 2020
VL 65
IS 3
BP 2455
EP 2474
DI 10.32604/cmc.2020.011526
PG 20
WC Computer Science, Information Systems; Materials Science, Multidisciplinary
SC Computer Science; Materials Science
GA PA0YB
UT WOS:000595341400005
DA 2023-04-26
ER
