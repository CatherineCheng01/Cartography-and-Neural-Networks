
PT J
AU Bono, J
   Zannone, S
   Pedrosa, V
   Clopath, C
AF Bono, Jacopo
   Zannone, Sara
   Pedrosa, Victor
   Clopath, Claudia
TI Learning predictive cognitive maps with spiking neurons during behavior and replays
SO ELIFE
LA English
DT Article
DE predictive; successor representation; hippocampus; modelling; Mouse
ID continuous-time; spatial memory; place cells; representations; hippocampus; ca1; reactivation; information; plasticity; retrieval
AB The hippocampus has been proposed to encode environments using a representation that contains predictive information about likely future states, called the successor representation. However, it is not clear how such a representation could be learned in the hippocampal circuit. Here, we propose a plasticity rule that can learn this predictive map of the environment using a spiking neural network. We connect this biologically plausible plasticity rule to reinforcement learning, mathematically and numerically showing that it implements the TD-lambda algorithm. By spanning these different levels, we show how our framework naturally encompasses behavioral activity and replays, smoothly moving from rate to temporal coding, and allows learning over behavioral timescales with a plasticity rule acting on a timescale of milliseconds. We discuss how biological parameters such as dwelling times at states, neuronal firing rates and neuromodulation relate to the delay discounting parameter of the TD algorithm, and how they influence the learned representation. We also find that, in agreement with psychological studies and contrary to reinforcement learning theory, the discount factor decreases hyperbolically with time. Finally, our framework suggests a role for replays, in both aiding learning in novel environments and finding shortcut trajectories that were not experienced during behavior, in agreement with experimental data.
C1 [Bono, Jacopo; Zannone, Sara; Pedrosa, Victor; Clopath, Claudia] Imperial Coll London, Dept Bioengn, London, England.
C3 Imperial College London
RP Clopath, C (corresponding author), Imperial Coll London, Dept Bioengn, London, England.
EM c.clopath@imperial.ac.uk
FU Wellcome Trust [200790/Z/16/Z]; Engineering and Physical Sciences Research Council [EP/R035806/1]; Simons Foundation [564408]
CR Aggleton JP, 1999, BEHAV BRAIN SCI, V22, P425
   Ainslie G, 2012, THEOR DECIS, V73, P3, DOI 10.1007/s11238-011-9272-5
   Ambrose RE, 2016, NEURON, V91, P1124, DOI 10.1016/j.neuron.2016.07.047
   Bittner KC, 2017, SCIENCE, V357, P1033, DOI 10.1126/science.aan3846
   Brea J, 2016, PLOS COMPUT BIOL, V12, P0, DOI 10.1371/journal.pcbi.1005003
   Brun VH, 2008, NEURON, V57, P290, DOI 10.1016/j.neuron.2007.11.034
   Cheng S, 2008, NEURON, V57, P303, DOI 10.1016/j.neuron.2007.11.035
   Daw ND, 2002, NEURAL NETWORKS, V15, P603, DOI 10.1016/S0893-6080(02)00052-7
   DAYAN P, 1993, NEURAL COMPUT, V5, P613, DOI 10.1162/neco.1993.5.4.613
   Doya K, 1996, ADV NEUR IN, V8, P1073
   Doya K, 2000, NEURAL COMPUT, V12, P219, DOI 10.1162/089976600300015961
   Drew PJ, 2006, P NATL ACAD SCI USA, V103, P8876, DOI 10.1073/pnas.0600676103
   Eichenbaum H, 1999, NEURON, V23, P209, DOI 10.1016/S0896-6273(00)80773-4
   Erdem UM, 2012, EUR J NEUROSCI, V35, P916, DOI 10.1111/j.1460-9568.2012.08015.x
   Fang C, 2023, ELIFE, V12, P0, DOI 10.7554/eLife.80680
   Fuchsberger T, 2022, CURR OPIN NEUROBIOL, V75, P0, DOI 10.1016/j.conb.2022.102558
   Gardner MPH, 2018, P ROY SOC B-BIOL SCI, V285, P0, DOI 10.1098/rspb.2018.1645
   George TM, 2023, ELIFE, V12, P0, DOI 10.7554/eLife.80663
   Gershman SJ, 2018, J NEUROSCI, V38, P7193, DOI 10.1523/JNEUROSCI.0151-18.2018
   Glimcher PW, 2011, P NATL ACAD SCI USA, V108, P15647, DOI 10.1073/pnas.1014269108
   Hales JB, 2014, CELL REP, V9, P893, DOI 10.1016/j.celrep.2014.10.009
   HASSELMO ME, 1994, J NEUROSCI, V14, P3898
   Hasselmo ME, 2002, NEURAL COMPUT, V14, P793, DOI 10.1162/089976602317318965
   Hasselmo ME, 2005, NEURAL NETWORKS, V18, P1172, DOI 10.1016/j.neunet.2005.08.007
   Hasselmo ME, 2011, NEUROPSYCHOPHARMACOL, V36, P52, DOI 10.1038/npp.2010.104
   Igata H, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2011266118
   Jackson JC, 2006, J NEUROSCI, V26, P12415, DOI 10.1523/JNEUROSCI.4118-06.2006
   Jacopo B., 2023, LEARNING COGNITIVE M, V0, P0
   Johnson A, 2007, J NEUROSCI, V27, P12176, DOI 10.1523/JNEUROSCI.3761-07.2007
   Kay K, 2020, CELL, V180, P552, DOI 10.1016/j.cell.2020.01.014
   Kempter R, 1999, PHYS REV E, V59, P4498, DOI 10.1103/PhysRevE.59.4498
   Kraus BJ, 2013, NEURON, V78, P1090, DOI 10.1016/j.neuron.2013.04.015
   Kubie JL, 2012, FRONT NEURAL CIRCUIT, V6, P0, DOI 10.3389/fncir.2012.00020
   Kurth-Nelson Z, 2016, NEURON, V91, P194, DOI 10.1016/j.neuron.2016.05.028
   Laibson D, 1997, Q J ECON, V112, P443, DOI 10.1162/003355397555253
   Marr D., 2010, VISION, V0, P0, DOI DOI 10.7551/mitpress/9780262514620.001.0001
   Matsumoto M, 2007, NATURE, V447, P1111, DOI 10.1038/nature05860
   Mattar MG., 2017, RATIONAL MODEL PRIOR, V0, P0
   MCNAUGHTON BL, 1987, TRENDS NEUROSCI, V10, P408, DOI 10.1016/0166-2236(87)90011-7
   Mehta MR, 2000, NEURON, V25, P707, DOI 10.1016/S0896-6273(00)81072-7
   Micheau J, 2011, BEHAV BRAIN RES, V221, P424, DOI 10.1016/j.bbr.2010.11.052
   Momennejad I, 2017, NAT HUM BEHAV, V1, P680, DOI 10.1038/s41562-017-0180-8
   Momennejad I, 2020, CURR OPIN BEHAV SCI, V32, P155, DOI 10.1016/j.cobeha.2020.02.017
   MORRIS RGM, 1982, NATURE, V297, P681, DOI 10.1038/297681a0
   MORRIS RGM, 1981, LEARN MOTIV, V12, P239, DOI 10.1016/0023-9690(81)90020-5
   OKeefe J., 1978, BEHAV BRAIN SCI, V0, P0, DOI DOI 10.1016/j.neuron.2015.06.013
   OReilly KC, 2014, FRONT BEHAV NEUROSCI, V8, P0, DOI 10.3389/fnbeh.2014.00292
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   Olafsdottir HF, 2015, ELIFE, V4, P0, DOI 10.7554/eLife.06063
   OLTON DS, 1979, NEUROPSYCHOLOGIA, V17, P669, DOI 10.1016/0028-3932(79)90042-3
   Palacios-Filardo J, 2021, NAT COMMUN, V12, P0, DOI 10.1038/s41467-021-25280-5
   Pfeiffer BE, 2020, HIPPOCAMPUS, V30, P6, DOI 10.1002/hipo.22824
   Pfeiffer BE, 2013, NATURE, V497, P74, DOI 10.1038/nature12112
   Robbins TW, 1997, BIOL PSYCHOL, V45, P57, DOI 10.1016/S0301-0511(96)05222-2
   Roscow EL, 2021, TRENDS NEUROSCI, V44, P808, DOI 10.1016/j.tins.2021.07.007
   Russek EM, 2017, PLOS COMPUT BIOL, V13, P0, DOI 10.1371/journal.pcbi.1005768
   Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593
   Shouval HZ, 2002, P NATL ACAD SCI USA, V99, P10831, DOI 10.1073/pnas.152343099
   Stachenfeld KL, 2014, ADV NEUR IN, V27, P0
   Stachenfeld KL, 2017, NAT NEUROSCI, V20, P1643, DOI 10.1038/nn.4650
   Staresina BP, 2013, P NATL ACAD SCI USA, V110, P21159, DOI 10.1073/pnas.1311989110
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Teles-Grilo Ruivo Leonor M, 2013, FRONT SYNAPTIC NEUROSCI, V5, P2, DOI 10.3389/fnsyn.2013.00002
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   van Rossum MCW, 2012, PLOS COMPUT BIOL, V8, P0, DOI 10.1371/journal.pcbi.1002836
   Waddington A, 2012, FRONT COMPUT NEUROSC, V6, P1, DOI 10.3389/fncom.2012.00088
   Wood ER, 2000, NEURON, V27, P623, DOI 10.1016/S0896-6273(00)00071-4
   Wood ER, 1999, NATURE, V397, P613, DOI 10.1038/17605
   Wu CT, 2017, NAT NEUROSCI, V20, P571, DOI 10.1038/nn.4507
NR 69
TC 2
Z9 2
U1 2
U2 2
PU eLIFE SCIENCES PUBL LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
EI 
J9 ELIFE
JI eLife
PD MAR 16
PY 2023
VL 12
IS 
BP 
EP 
DI 10.7554/eLife.80671
PG 29
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA A1YR8
UT WOS:000953162100001
PM 36927625
DA 2023-04-26
ER

PT J
AU Liu, Q
   Yin, CC
   Su, Y
   Liu, YH
   Wang, LY
   Liang, H
   Wang, H
AF Liu, Qiang
   Yin, Changchun
   Su, Yang
   Liu, Yunhe
   Wang, Luyuan
   Liang, Hao
   Wang, Han
TI Two-dimensional fast imaging of airborne EM data based on U-net
SO FRONTIERS IN EARTH SCIENCE
LA English
DT Article
DE airborne EM; frequency-domain; neural networks; U-net; full convolution
ID electromagnetic data; bayesian inversion
AB As an efficient geophysical exploration tool, the airborne electromagnetic (AEM) method has been widely used in mineral exploration, geological mapping, environmental and engineering investigation, etc. Currently, the imaging and 1D inversions are the mainstream means for AEM interpretation as the amount of AEM data is huge and 2D and 3D inversions are not efficient. In this paper, we propose a 2D fast imaging method for frequency-domain AEM data based on U-net network. The U-net is a symmetric full-convolution neural network, in which the partial pooling operation between the convolution layers is replaced by the up-sampling operation, while the target location is achieved by skipping connection. This method does not need to consider the complex coupling between the EM responses and underground structures, but instead it establishes a mapping relationship between EM responses and the resistivity model and can quickly achieve accurate imaging of AEM data. We use this network to image both synthetic and field survey data and compare the results with the traditional inversion algorithms. The results show that the U-net imaging have high resolution at high speed that provides a new way for interpreting large amounts of AEM data.
C1 [Liu, Qiang; Yin, Changchun; Su, Yang; Liu, Yunhe; Wang, Luyuan; Liang, Hao; Wang, Han] Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun, Peoples R China.
C3 Jilin University
RP Yin, CC (corresponding author), Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun, Peoples R China.
EM yinchangchun@jlu.edu.cn
FU National Natural Science Foundation of China [42030806]; National Key R&D Program of China [2021YFB3202104]
CR Abadi M, 2016, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1603.04467
   [Anonymous], 1998, EXPLOR GEOPHYS, V0, P0, DOI DOI 10.1071/EG998163
   Auken E, 2004, GEOPHYSICS, V69, P752, DOI 10.1190/1.1759461
   Brodie R., 2004, ASEG EXTENDED ABSTRA, V2004, P1, DOI 10.1071/ASEG2004ab014
   Cai J, 2014, CHINESE J GEOPHYS-CH, V57, P953, DOI 10.6038/cjg20140324
   Chen J., 1998, EXPLOR GEOPHYS, V29, P128, DOI 10.1071/EG998128
   Clevert DA, 2016, ARXIV, V0, P0
   CONSTABLE SC, 1987, GEOPHYSICS, V52, P289, DOI 10.1190/1.1442303
   Farquharson CG, 2003, GEOPHYSICS, V68, P1857, DOI 10.1190/1.1635038
   Gao ZH, 2018, APPL GEOPHYS, V15, P318, DOI 10.1007/s11770-018-0684-7
   Haber E., 2019, ASEG EXTENDED ABSTRA, V2019, P1, DOI 10.1080/22020586.2019.12072978
   Huang HP, 2008, GEOPHYSICS, V73, PF115, DOI 10.1190/1.2904984
   Huang HP, 1996, GEOPHYSICS, V61, P100, DOI 10.1190/1.1574674
   Huang HM, 2020, INT CONF ACOUST SPEE, V0, PP1055, DOI 10.1109/ICASSP40776.2020.9053405
   Iturraran-Viveros U, 2021, PURE APPL GEOPHYS, V178, P423, DOI 10.1007/s00024-021-02655-9
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kobayashi T, 2002, EARTH PLANETS SPACE, V54, P973, DOI 10.1186/BF03352445
   Li JF, 2020, GEOPHYSICS, V85, PE163, DOI 10.1190/GEO2019-0015.1
   Liu B, 2020, IEEE T GEOSCI REMOTE, V58, P5715, DOI 10.1109/TGRS.2020.2969040
   Liu YH, 2018, GEOPHYS J INT, V213, P1, DOI 10.1093/gji/ggx545
   Long J., 2015, P IEEE C COMPUTER VI, V0, PP3431, DOI 10.48550/ARXIV.1411.4038
   MACNAE J, 1987, GEOPHYSICS, V52, P545, DOI 10.1190/1.1442323
   Meju MA, 1998, GEOPHYSICS, V63, P405, DOI 10.1190/1.1444340
   Minsley BJ, 2012, GEOPHYS RES LETT, V39, P0, DOI 10.1029/2011GL050079
   Noh K, 2020, EXPLOR GEOPHYS, V51, P214, DOI 10.1080/08123985.2019.1668240
   Puzyrev V, 2019, GEOPHYS J INT, V218, P817, DOI 10.1093/gji/ggz204
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ronning J. S., 2020, NGU REPORT 2019031, V0, P0, DOI DOI 10.13140/RG.2.2.31573.17126
   Smith RS, 2004, NEAR SURF GEOPHYS, V2, P123, DOI 10.3997/1873-0604.2004009
   Supper R., 2008, ADV GEOSCIENCES, V14, P195, DOI 10.5194/ADGE0-14-195-2008
   Tan K., 2009, ASEG EXTENDED ABSTRA, V2009, P1, DOI 10.1071/ASEG2009ab135
   Vallee Marc A., 2009, LEADING EDGE, V28, P284, DOI 10.1190/1.3104071
   Vallee MA, 2009, NEAR SURF GEOPHYS, V7, P63, DOI 10.3997/1873-0604.2008035
   van der Baan M, 2000, GEOPHYSICS, V65, P1032, DOI 10.1190/1.1444797
   Wang J, 2021, APPL GEOPHYS, V18, P199, DOI 10.1007/s11770-021-0894-2
   Wolfgram P., 1995, EXPLOR GEOPHYS, V26, P179, DOI 10.1071/EG995179
   Yang FS, 2019, GEOPHYSICS, V84, PR585, DOI 10.1190/GEO2018-0249.1
   Yin CC, 2015, CHINESE J GEOPHYS-CH, V58, P2637, DOI 10.6038/cjg20150804
   Yin CC, 2014, CHINESE J GEOPHYS-CH, V57, P2971, DOI 10.6038/cjg20140922
   Yin CC, 2007, GEOPHYSICS, V72, PF189, DOI 10.1190/1.2736195
   [殷长春 Yin Changchun], 2016, 吉林大学学报. 地球科学版 JOURNAL OF JILIN UNIVERSITY. EARTH SCIENCE EDITION, V46, P254
   Yu SW, 2021, REV GEOPHYS, V59, P0, DOI 10.1029/2021RG000742
   Zhu WQ, 2019, GEOPHYS J INT, V216, P261, DOI 10.1093/gji/ggy423
NR 43
TC 0
Z9 0
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 2296-6463
J9 FRONT EARTH SC-SWITZ
JI Front. Earth Sci.
PD JAN 10
PY 2023
VL 10
IS 
BP 
EP 
DI 10.3389/feart.2022.1082876
PG 13
WC Geosciences, Multidisciplinary
SC Geology
GA 8F0ZM
UT WOS:000919396100001
DA 2023-04-26
ER

PT J
AU Toro, JV
   Wiberg, A
   Tarkian, M
AF Villena Toro, Javier
   Wiberg, Anton
   Tarkian, Mehdi
TI Application of optimized convolutional neural network to fixture layout in automotive parts
SO INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY
LA English
DT Article; Early Access
DE Design automation; Machine learning; Fixtures; CNN; Hyperparameter tuning; EfficientNet
ID design; system
AB Fixture layout is a complex task that significantly impacts manufacturing costs and requires the expertise of well-trained engineers. While most research approaches to automating the fixture layout process use optimization or rule-based frameworks, this paper presents a novel approach using supervised learning. The proposed framework replicates the 3-2-1 locating principle to layout fixtures for sheet metal designs. This principle ensures the correct fixing of an object by restricting its degrees of freedom. One main novelty of the proposed framework is the use of topographic maps generated from sheet metal design data as input for a convolutional neural network (CNN). These maps are created by projecting the geometry onto a plane and converting the Z coordinate into gray-scale pixel values. The framework is also novel in its ability to reuse knowledge about fixturing to lay out new workpieces and in its integration with a CAD environment as an add-in. The results of the hyperparameter-tuned CNN for regression show high accuracy and fast convergence, demonstrating the usability of the model for industrial applications. The framework was first tested using automotive b-pillar designs and was found to have high accuracy (approximate to 100%) in classifying these designs. The proposed framework offers a promising approach for automating the complex task of fixture layout in sheet metal design.
C1 [Villena Toro, Javier; Wiberg, Anton; Tarkian, Mehdi] Linkoping Univ, Dept Management & Engn, SE-58183 Linkoping, Sweden.
RP Toro, JV (corresponding author), Linkoping Univ, Dept Management & Engn, SE-58183 Linkoping, Sweden.
EM javier.villena.toro@liu.se; anton.wiberg@liu.se; mehdi.tarkian@liu.se
FU Linkping University; Vinnova-FFI (Fordonsstrategisk forskning ochinnovation) [2020-02974]
CR Ahmad Z, 2018, J MECH SCI TECHNOL, V32, P1749, DOI 10.1007/s12206-018-0331-5
   Ahmed Wafaa Shihab, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND SOFTWARE ENGINEERING (CSASE). PROCEEDINGS, V0, PP88, DOI 10.1109/CSASE48920.2020.9142089
   Bakker OJ, 2013, INT J PROD RES, V51, P3171, DOI 10.1080/00207543.2012.695893
   Bi ZM, 2001, INT J PROD RES, V39, P2867, DOI 10.1080/00207540110054579
   Boyle I, 2011, ROBOT CIM-INT MANUF, V27, P1, DOI 10.1016/j.rcim.2010.05.008
   Chen C, 2018, INT J ADV MANUF TECH, V96, P4303, DOI 10.1007/s00170-018-1907-z
   Chollet F, 2015, KERAS, V0, P0
   Gameros A, 2017, INT J MACH TOOL MANU, V123, P1, DOI 10.1016/j.ijmachtools.2017.07.004
   Hashemi H, 2014, INT J ADV MANUF TECH, V74, P113, DOI 10.1007/s00170-014-5930-4
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Ivanov V, 2020, LECT N MECH ENG, V0, PP114, DOI 10.1007/978-3-030-22365-6_12
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kumar AS, 2000, INT J ADV MANUF TECH, V16, P176, DOI 10.1007/s001700050024
   Kumawat S, 2019, PROC CVPR IEEE, V0, PP4898, DOI 10.1109/CVPR.2019.00504
   Li Cheng, 2022, JOURNAL OF PHYSICS: CONFERENCE SERIES, V2174, P0, DOI 10.1088/1742-6596/2174/1/012013
   LIN ZC, 1995, INT J ADV MANUF TECH, V10, P379, DOI 10.1007/BF01179401
   Low DWW, 2020, INT J ADV MANUF TECH, V107, P2303, DOI 10.1007/s00170-020-05156-6
   Ma Z., 2019, P 2019 INT C ARTIFIC, V0, P0, DOI DOI 10.1145/3358331.3358358
   Manafi D, 2021, INT J PROD RES, V59, P2647, DOI 10.1080/00207543.2020.1736357
   Michael Thomas Rex F., 2020, PROCEEDINGS OF ICDMC 2019. DESIGN, V0, P0
   Mihaylov O., 2019, P INT SCI PRACTICAL, V3, P160
   Nambiar S., 2022, CHI 2019 P 2019 CHI, V2, P543, DOI 10.1017/pds.2022.56
   Nee AYC., 2012, ADV FIXTURE DESIGN F, V0, P0
   Nixon F., 1971, MANAGING ACHIEVE QUA, V0, P0
   OMalley T., 2019, KERASTUNER, V0, P0
   Parvaz H, 2018, COMPUT AIDED DESIGN, V104, P1, DOI 10.1016/j.cad.2018.04.004
   PHAM DT, 1990, INT J MACH TOOL MANU, V30, P403, DOI 10.1016/0890-6955(90)90184-K
   Qin GH, 2014, INT J PROD RES, V52, P1351, DOI 10.1080/00207543.2013.842020
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Snoek J., 2012, ADV NEURAL INFORM PR, V0, P0
   Sun SH, 1996, ENG APPL ARTIF INTEL, V9, P533, DOI 10.1016/0952-1976(96)00048-6
   Sundararaman KA, 2014, INT J ADV MANUF TECH, V73, P669, DOI 10.1007/s00170-014-5848-x
   Tan MX, 2020, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.1905.11946
   TRAPPEY AJC, 1993, J MANUF SYST, V12, P486, DOI 10.1016/0278-6125(93)90345-T
   Trappey J. C., 1990, INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY, V5, P240, DOI 10.1007/BF02601534
   Wu HB, 2015, NEURAL NETWORKS, V71, P1, DOI 10.1016/j.neunet.2015.07.007
   Yu T., 2020, ARXIV, V0, P0
NR 38
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0268-3768
EI 1433-3015
J9 INT J ADV MANUF TECH
JI Int. J. Adv. Manuf. Technol.
PD JUN 15
PY 2023
VL 0
IS 
BP 
EP 
DI 10.1007/s00170-023-10995-0
PG 15
WC Automation & Control Systems; Engineering, Manufacturing
SC Automation & Control Systems; Engineering
GA 9G6LO
UT WOS:000938262100003
DA 2023-04-26
ER

PT J
AU Hao, M
   Dou, GM
   Zhang, XT
   Lin, HJ
   Huo, WQ
AF Hao, Ming
   Dou, Guimiao
   Zhang, Xiaotong
   Lin, Huijing
   Huo, Wenqi
TI A Subpixel Mapping Method for Urban Land Use by Reducing Shadow Effects
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Abundance optimization; multi-index feature fusion; shadow; subpixel mapping; super-resolution reconstruction
ID spectral mixture analysis; water index ndwi; cloud removal; cover; algorithm; features
AB Urban land use classification is significant for urban development planning. Considering complex environments of urban surface features, traditional semantic segmentation methods are difficult to solve the problems of mixed pixels and limited spatial resolution of images. The subpixel mapping technology is an effective method to solve the above problems in urban land use classification. However, traditional subpixel mapping methods are sensitive to mountain shadow, high-rise building shadow and impermeable surface heterogeneity, resulting in false classification. Therefore, we propose a subpixel mapping method that can reduce the shadow effect. This method uses a multi-index feature fusion strategy to optimize the abundance of the shadow errors in the abundance image, and uses a super-resolution reconstruction neural network model to reconstruct the optimized abundance image for the subpixel mapping of urban land use. Experiments were conducted on sentinel-2 images obtained over Yuelu District of Changsha City, Hunan Province, China. The experimental results show that the method proposed in this article can effectively overcome the influence of building shadows and mountain shadows in urban land cover classification and is superior to traditional subpixel/pixel spatial attraction model, radial basis function, super-resolution subpixel mapping, and other methods in the effect and accuracy of urban land use subpixel mapping.
C1 [Hao, Ming; Dou, Guimiao; Zhang, Xiaotong; Lin, Huijing; Huo, Wenqi] China Univ Ming & Technol, Jiangsu Key Lab Resource & Environm Informat Engn, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Dou, GM (corresponding author), China Univ Ming & Technol, Jiangsu Key Lab Resource & Environm Informat Engn, Xuzhou 221116, Peoples R China.
EM haomingcumt@gmail.com; douguimiao1127@163.com; z2965397155@163.com; linhuijing@cumt.edu.cn; huowenqi@cumt.edu.cn
FU Fundamental Research Funds for the Central Universities [2021YCPY0113]; National Natural Science Foundation of China [42271368]; Priority Academic Program Development of Jiangsu Higher Education Institutions
CR Arevalo V, 2008, INT J REMOTE SENS, V29, P1945, DOI 10.1080/01431160701395302
   Arun PV, 2018, NEUROCOMPUTING, V311, P51, DOI 10.1016/j.neucom.2018.05.051
   Atkinson PM, 2005, PHOTOGRAMM ENG REM S, V71, P839, DOI 10.14358/PERS.71.7.839
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P917, DOI 10.1080/014311697217224
   Boucher A, 2006, REMOTE SENS ENVIRON, V104, P264, DOI 10.1016/j.rse.2006.04.020
   He D, 2022, INT J APPL EARTH OBS, V106, P0, DOI 10.1016/j.jag.2021.102667
   He D, 2021, IEEE T GEOSCI REMOTE, V59, P10628, DOI 10.1109/TGRS.2021.3050824
   He D, 2019, IEEE T GEOSCI REMOTE, V57, P2198, DOI 10.1109/TGRS.2018.2872081
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Jin HR, 2012, INT J REMOTE SENS, V33, P7747, DOI 10.1080/01431161.2012.702234
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Lim B, 2017, IEEE COMPUT SOC CONF, V0, PP1132, DOI 10.1109/CVPRW.2017.151
   Lin CH, 2013, IEEE T GEOSCI REMOTE, V51, P232, DOI 10.1109/TGRS.2012.2197682
   Liu XP, 2018, REMOTE SENS ENVIRON, V209, P227, DOI 10.1016/j.rse.2018.02.055
   Lu DS, 2006, REMOTE SENS ENVIRON, V102, P146, DOI 10.1016/j.rse.2006.02.010
   Ma XF, 2019, IEEE J-STARS, V12, P4930, DOI 10.1109/JSTARS.2019.2941089
   Makido Y., 2006, THESIS MICHIGAN STAT, V0, P0
   Makido Y, 2007, PHOTOGRAMM ENG REM S, V73, P1233, DOI 10.14358/PERS.73.11.1233
   Makido YK, 2008, GISCI REMOTE SENS, V45, P471, DOI 10.2747/1548-1603.45.4.471
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS
   Maus V, 2016, IEEE J-STARS, V9, P3729, DOI 10.1109/JSTARS.2016.2517118
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Mertens KC, 2006, INT J REMOTE SENS, V27, P3293, DOI 10.1080/01431160500497127
   Mu L, 2019, IEEE J-STARS, V12, P5233, DOI 10.1109/JSTARS.2019.2956318
   NEMANI RR, 1989, J APPL METEOROL, V28, P276, DOI 10.1175/1520-0450(1989)028<0276:EORSRT>2.0.CO;2
   Powell RL, 2007, REMOTE SENS ENVIRON, V106, P253, DOI 10.1016/j.rse.2006.09.005
   Shen ZQ, 2009, PHOTOGRAMM ENG REM S, V75, P557, DOI 10.14358/PERS.75.5.557
   Su N, 2016, IEEE J-STARS, V9, P2568, DOI 10.1109/JSTARS.2016.2570234
   Thornton MW, 2007, COMPUT GEOSCI-UK, V33, P1261, DOI 10.1016/j.cageo.2007.05.010
   Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5
   Wang QJ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050469
   Wang QM, 2017, REMOTE SENS ENVIRON, V193, P127, DOI 10.1016/j.rse.2017.03.002
   Wang QM, 2014, ISPRS J PHOTOGRAMM, V92, P1, DOI 10.1016/j.isprsjprs.2014.02.012
   Wang QM, 2014, IEEE T GEOSCI REMOTE, V52, P2940, DOI 10.1109/TGRS.2013.2267802
   Wang QM, 2012, J SYST ENG ELECTRON, V23, P293, DOI 10.1109/JSEE.2012.00037
   Wu W, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111704
   Xie C, 2016, INT J DIGIT EARTH, V9, P925, DOI 10.1080/17538947.2016.1170215
   Xie H, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070584
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Yang H, 2012, IEEE J-STARS, V5, P544, DOI 10.1109/JSTARS.2012.2185822
   Zhang LP, 2008, NEUROCOMPUTING, V71, P2046, DOI 10.1016/j.neucom.2007.08.033
   Zhang Q, 2021, ISPRS J PHOTOGRAMM, V177, P161, DOI 10.1016/j.isprsjprs.2021.04.021
   Zhao Y., 2013, PRINCIPLES METHODS R, V2nd, P0
   Zhong YF, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111838
NR 45
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2023
VL 16
IS 
BP 2163
EP 2177
DI 10.1109/JSTARS.2023.3243895
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 9M7JJ
UT WOS:000942401000005
DA 2023-04-26
ER

PT J
AU Bergamasco, L
   Bovolo, F
   Bruzzone, L
AF Bergamasco, Luca
   Bovolo, Francesca
   Bruzzone, Lorenzo
TI A Dual-Branch Deep Learning Architecture for Multisensor and Multitemporal Remote Sensing Semantic Segmentation
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Deep learning (DL) classification; multiresolution; multisensor data; multitemporal images; remote sensing (RS); very-high-resolution (VHR) images
ID image time-series; land-cover; combining sentinel-1; classification; settlements; networks
AB Multisensor data analysis allows exploiting heterogeneous data regularly acquired by the many available remote sensing (RS) systems. Machine- and deep-learning methods use the information of heterogeneous sources to improve the results obtained by using single-source data. However, the state-of-the-art methods analyze either the multiscale information of multisensor multiresolution images or the time component of image time series. We propose a supervised deep-learning classification method that jointly performs a multiscale and multitemporal analysis of RS multitemporal images acquired by different sensors. The proposed method processes very-high-resolution (VHR) images using a residual network with a wide receptive field that handles geometrical details and multitemporal high-resolution (HR) image using a 3-D convolutional neural network that analyzes both the spatial and temporal information. The multiscale and multitemporal features are processed together in a decoder to retrieve a land-cover map. We tested the proposed method on two multisensor and multitemporal datasets. One is composed of VHR orthophotos and Sentinel-2 multitemporal images for pasture classification, and another is composed of VHR orthophotos and Sentinel-1 multitemporal images. Results proved the effectiveness of the proposed classification method.
C1 [Bergamasco, Luca; Bovolo, Francesca] Fdn Bruno Kessler, Ctr Digital Soc, I-38123 Trento, Italy.
   [Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38050 Trento, Italy.
C3 Fondazione Bruno Kessler; University of Trento
RP Bovolo, F (corresponding author), Fdn Bruno Kessler, Ctr Digital Soc, I-38123 Trento, Italy.
EM lbergamasco@fbk.eu; bovolo@fbk.eu; lorenzo.bruzzone@ing.unitn.it
CR Lopez JA, 2011, ISPRS J PHOTOGRAMM, V66, P115, DOI 10.1016/j.isprsjprs.2010.09.008
   Benedetti P, 2018, IEEE J-STARS, V11, P4939, DOI 10.1109/JSTARS.2018.2876357
   Bergado JR, 2018, IEEE T GEOSCI REMOTE, V56, P6361, DOI 10.1109/TGRS.2018.2837357
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Martinez JAC, 2021, ISPRS J PHOTOGRAMM, V171, P188, DOI 10.1016/j.isprsjprs.2020.11.007
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YY, 2019, EARTH SCI INFORM, V12, P341, DOI 10.1007/s12145-019-00383-2
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Coates A., 2011, ADV NEURAL INF PROCE, V0, PP2528, DOI 10.1016/J.PSYCHRES.2009.03.008
   de Castro HC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162655
   Gaetano R, 2018, ARXIV, V0, P0
   Garnot VS, 2022, ISPRS J PHOTOGRAMM, V187, P294, DOI 10.1016/j.isprsjprs.2022.03.012
   Gbodjo YJE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172814
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   HORN BKP, 1981, P IEEE, V69, P14, DOI 10.1109/PROC.1981.11918
   Ienco D, 2017, IEEE GEOSCI REMOTE S, V14, P1685, DOI 10.1109/LGRS.2017.2728698
   Ienco D, 2020, IEEE ACCESS, V8, P179547, DOI 10.1109/ACCESS.2020.3024133
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Ienco D, 2019, INT GEOSCI REMOTE SE, V0, PP4881, DOI 10.1109/IGARSS.2019.8898458
   Inglada J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010095
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, V0, PP680, DOI 10.1109/CVPRW.2016.90
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kong YL, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030452
   KROGH A, 1992, ADV NEUR IN, V4, P950
   Kuffer M, 2011, PROCEDIA ENVIRON SCI, V7, P152, DOI 10.1016/j.proenv.2011.07.027
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Liu X, 2018, IEEE T GEOSCI REMOTE, V56, P461, DOI 10.1109/TGRS.2017.2750220
   Luo WJ, 2016, ADV NEUR IN, V29, P0
   Maggiori E, 2016, INT GEOSCI REMOTE SE, V0, PP5071, DOI 10.1109/IGARSS.2016.7730322
   Martino T. D., 2021, PROC IEEE INT GEOSCI, V0, PP1847, DOI 10.1109/IGARSS47720.2021.9554286
   Maus V, 2016, IEEE J-STARS, V9, P3729, DOI 10.1109/JSTARS.2016.2517118
   Moser G, 2013, P IEEE, V101, P631, DOI 10.1109/JPROC.2012.2211551
   Nichol J, 2005, INT J REMOTE SENS, V26, P903, DOI 10.1080/01431160412331291198
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050523
   Pelletier C, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9020173
   Pelletier C, 2016, REMOTE SENS ENVIRON, V187, P156, DOI 10.1016/j.rse.2016.10.010
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Reddy DS, 2018, MODEL EARTH SYST ENV, V4, P409, DOI 10.1007/s40808-018-0431-3
   Robinson C, 2019, PROC CVPR IEEE, V0, PP12718, DOI 10.1109/CVPR.2019.01301
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rustowicz Rose M, 2019, P IEEE CVF C COMP VI, V0, P75
   Saha S, 2019, INT GEOSCI REMOTE SE, V0, PP5033, DOI 10.1109/IGARSS.2019.8900173
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8040189
   Zhang PB, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113717
   Zhang XY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020281
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2023
VL 16
IS 
BP 2147
EP 2162
DI 10.1109/JSTARS.2023.3243396
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA 9M7JJ
UT WOS:000942401000004
DA 2023-04-26
ER
