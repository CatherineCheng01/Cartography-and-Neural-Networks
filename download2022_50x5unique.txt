
PT J
AU Duarte, D
   Fonte, CC
   Patriarca, J
   Jesus, I
AF Duarte, D.
   Fonte, C. C.
   Patriarca, J.
   Jesus, I
TI GEOGRAPHICAL TRANSFERABILITY OF LULC IMAGE-BASED SEGMENTATION MODELS USING TRAINING DATA AUTOMATICALLY GENERATED FROM OPENSTREETMAP - CASE STUDY IN PORTUGAL
SO XXIV ISPRS CONGRESS: IMAGING TODAY, FORESEEING TOMORROW, COMMISSION III
LA English
DT Proceedings Paper
DE Volunteered Geographical Information; OSM; Remote Sensing; Satellite; Convolutional Neural Networks; Deep Learning
ID land-cover; algorithms
AB Synoptic remote sensing systems have been broadly used within supervised classification methods to map land use and land cover (LULC). Such methods rely on high quality sets of training data that are able to characterize the target classes. Often, training data is manually generated, either by field campaigns and/or by photointerpretation of ancillary remote sensing imagery. Several authors already proposed methodologies to attenuate such labour-intensive task of generating training data. One of the preferred datasets that are used as input training data is OpenStreetMap (OSM), which aims at creating a publicly available vector map of the world with the input of volunteers. However, OSM data is spatially heterogenous (e.g., capital cities and highly populated areas often have high degrees of completion while unpopulated regions often have a lower degree of completion), where there are still large areas without OSM coverage. In this paper we present a set of experiments that aim at assessing the geographical transferability of satellite imagebased segmentation models trained with OSM derived data. To this end, we chose two locations with different OSM coverage and disparate landscape (metropolitan region vs natural park region, in different landscape units), and assess how these models behave when trained in a region and applied in the other. The results show that the mapping of some classes is improved when considering a model trained in a different location.
C1 [Duarte, D.; Fonte, C. C.; Patriarca, J.; Jesus, I] Inst Syst Engn & Comp Coimbra INESC Coimbra, Coimbra, Portugal.
   [Fonte, C. C.] Univ Coimbra, Dept Math, Coimbra, Portugal.
   [Patriarca, J.; Jesus, I] Univ Coimbra, Dept Informat Engn, Coimbra, Portugal.
C3 INESC Coimbra; Universidade de Coimbra; Universidade de Coimbra; Universidade de Coimbra
RP Duarte, D (corresponding author), Inst Syst Engn & Comp Coimbra INESC Coimbra, Coimbra, Portugal.
EM diogovad@inescc.pt; cfonte@mat.uc.pt; jpatriarca@mat.uc.pt; ismaeljesus@student.uc.pt
FU Portuguese Foundation for Science and Technology (FCT) [UIDB/00308/2020]
CR Abdi AM, 2020, GISCI REMOTE SENS, V57, P1, DOI 10.1080/15481603.2019.1650447
   Arsanjani JJ, 2013, INT ARCH PHOTOGRAMM, V40-4-W1, P51
   Arsanjani JJ, 2015, INT J APPL EARTH OBS, V35, P329, DOI 10.1016/j.jag.2014.09.009
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Chen Y, 2021, GISCI REMOTE SENS, V58, P624, DOI 10.1080/15481603.2021.1933367
   Clark ML, 2017, REMOTE SENS ENVIRON, V200, P311, DOI 10.1016/j.rse.2017.08.028
   DGT-Direcao-Geral do Territorio, 2019, ESP TECN CART US OC, V0, P0
   European Commission Directorate-General for Communication, 2020, EUR GREEN DEAL, V0, P0
   Fonte CC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203428
   Fonte CC, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6040125
   Friedl MA, 2002, REMOTE SENS ENVIRON, V83, P287, DOI 10.1016/S0034-4257(02)00078-0
   Haufel G, 2018, INT GEOSCI REMOTE SE, V0, P7263
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Li ZP, 2017, ECOL MODEL, V365, P68, DOI 10.1016/j.ecolmodel.2017.09.017
   Patriarca J., 2019, OPEN GEOSPATIAL DATA, V0, P0, DOI 10.1186/s40965-019-0070-2
   Patriarca J., 2020, GLASS V0 01, V0, P0
   Rajib A, 2017, HYDROL PROCESS, V31, P3645, DOI 10.1002/hyp.11282
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Schultz M, 2017, INT J APPL EARTH OBS, V63, P206, DOI 10.1016/j.jag.2017.07.014
NR 21
TC 0
Z9 0
U1 1
U2 1
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 2194-9042
EI 2194-9050
J9 ISPRS ANN PHOTO REM
PD JUN 15
PY 2022
VL 5-3
IS 
BP 25
EP 31
DI 10.5194/isprs-annals-V-3-2022-25-2022
PG 7
WC Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA BT8SD
UT WOS:000855203200005
DA 2023-04-26
ER

PT J
AU Han, J
   Lee, S
AF Han, J.
   Lee, S.
TI RESIDENT'S SATISFACTION IN STREET LANDSCAPE USING THE IMMERSIVE VIRTUAL ENVIRONMENT-BASED EYE-TRACKING TECHNIQUE AND DEEP LEARNING MODEL
SO 17TH 3D GEOINFO CONFERENCE
LA English
DT Proceedings Paper
DE Street Landscape; Visual Attention; Immersive Virtual Reality; Eye-tracking; Deep-learning
ID urban green; fear; spaces; preferences; perception; behavior; design; safety; parks; view
AB Virtual reality technology provides a significant clue to understanding the human visual perception process by enabling the interaction between humans and computers. In addition, deep learning techniques in the visual field provide analysis methods for image classification, processing, and segmentation. This study reviewed the applicability of gaze movement and deep learning-based satisfaction evaluation on the landscape using an immersive virtual reality-based eye-tracking device. To this end, the following research procedures were established and analysed. First, the gaze movement of the test taker is measured using an immersive virtual environment-based eye tracker. The relationship between the gaze movement pattern of the test taker and the satisfaction evaluation result for the landscape image is analysed. Second, using the Convolutional Neural Networks (CNN)-based Class Activation Map (CAM) technique, a model for estimating the satisfaction evaluation result is constructed, and the gaze pattern of the test taker is derived. Third, we compare and analyse the similarity between the gaze heat map derived through the immersive virtual environment-based gaze tracker and the heat map generated by CAM. This study suggests the applicability of urban environment technology and deep learning methods to understand landscape planning factors that affect urban landscape satisfaction, resulting from the three-dimensional and immediate visual cognitive activity.
C1 [Han, J.; Lee, S.] Hanyang Univ, Dept Urban Planning & Engn, Seoul, South Korea.
C3 Hanyang University
RP Han, J (corresponding author), Hanyang Univ, Dept Urban Planning & Engn, Seoul, South Korea.
EM tommorello@hanmail.net; sugielee@hanmail.net
CR Alexander C., 1977, PATTERN LANGUAGE TOW, V0, P0
   Balcetis E, 2006, J PERS SOC PSYCHOL, V91, P612, DOI 10.1037/0022-3514.91.4.612
   Baran PK, 2018, URBAN FOR URBAN GREE, V35, P72, DOI 10.1016/j.ufug.2018.08.009
   BURGESS J, 1988, URBAN STUD, V25, P455, DOI 10.1080/00420988820080631
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Cazzato D, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20133739
   Chen B., 2022, J ENVIRONMENTA PSYCH, V80, P1
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Ebenberger M, 2019, URBAN FOR URBAN GREE, V41, P272, DOI 10.1016/j.ufug.2019.04.011
   Ewing R, 2009, J URBAN DES, V14, P65, DOI 10.1080/13574800802451155
   Gamberini L, 2003, ERGONOMICS, V46, P842, DOI 10.1080/0014013031000111266
   Gehl J., 2013, STUDY PUBLIC LIFE, V0, P0, DOI DOI 10.5822/978-1-61091-525-0
   Guo YQ, 2021, LANDSCAPE URBAN PLAN, V209, P0, DOI 10.1016/j.landurbplan.2021.104058
   Han J., 2021, APPL VERIFICATION ST, V0, P198
   Harvey C. W., 2014, MEASURING STREETSCAP, V0, P0
   Harvey C, 2015, LANDSCAPE URBAN PLAN, V142, P18, DOI 10.1016/j.landurbplan.2015.05.007
   Heath Gregory W, 2006, J PHYS ACT HEALTH, V3, PS55, DOI 10.1123/jpah.3.s1.s55
   Hidalgo MC, 2001, J ENVIRON PSYCHOL, V21, P273, DOI 10.1006/jevp.2001.0221
   Im S., 1988, J KOREAN I LANDSCAPE, V16, P43
   Jiang B, 2015, LANDSCAPE URBAN PLAN, V139, P16, DOI 10.1016/j.landurbplan.2015.02.018
   Jorgensen A, 2007, LANDSCAPE URBAN PLAN, V79, P273, DOI 10.1016/j.landurbplan.2006.02.015
   Kaplan R, 2001, ENVIRON BEHAV, V33, P507, DOI 10.1177/00139160121973115
   Kinateder M, 2015, FIRE SAFETY J, V78, P24, DOI 10.1016/j.firesaf.2015.07.002
   Li J, 2020, URBAN FOR URBAN GREE, V56, P0, DOI 10.1016/j.ufug.2020.126903
   Li XJ, 2015, URBAN FOR URBAN GREE, V14, P675, DOI 10.1016/j.ufug.2015.06.006
   Li XJ, 2015, ISPRS INT J GEO-INF, V4, P1166, DOI 10.3390/ijgi4031166
   Liao H, 2022, COMPUT ENVIRON URBAN, V93, P0, DOI 10.1016/j.compenvurbsys.2022.101758
   Low S.M., 1992, PLACE ATTACHMENT, V12, P0, DOI 10.1007/978-1-4684-8753-4_1
   Lund K, 2007, LANG RESOUR EVAL, V41, P289, DOI 10.1007/s10579-007-9058-0
   Lynch K., 2008, IMAGE CITY, V33rd ed., P0
   Madge C, 1997, TIJDSCHR ECON SOC GE, V88, P237, DOI 10.1111/j.1467-9663.1997.tb01601.x
   Maruthaveeran S, 2014, URBAN FOR URBAN GREE, V13, P1, DOI 10.1016/j.ufug.2013.11.006
   Mele ML, 2012, COGN PROCESS, V13, PS261, DOI 10.1007/s10339-012-0499-z
   Muhlberger A., 2015, J VIRTUAL REALITY BR, V12, P1
   NASAR JL, 1993, LANDSCAPE URBAN PLAN, V26, P161, DOI 10.1016/0169-2046(93)90014-5
   OWENS PM, 1993, LANDSCAPE URBAN PLAN, V26, P115, DOI 10.1016/0169-2046(93)90011-2
   Paes D, 2017, AUTOMAT CONSTR, V84, P292, DOI 10.1016/j.autcon.2017.09.016
   Peperkorn HM, 2015, COMPUT HUM BEHAV, V48, P542, DOI 10.1016/j.chb.2015.02.028
   Portman ME, 2015, COMPUT ENVIRON URBAN, V54, P376, DOI 10.1016/j.compenvurbsys.2015.05.001
   Rapoport A, 2016, HUMAN ASPECTS URBAN, V0, P0
   Rossetti T, 2019, LANDSCAPE URBAN PLAN, V181, P169, DOI 10.1016/j.landurbplan.2018.09.020
   Salesses P, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0068400
   Schroeder R., 2008, J VIRTUAL WORLDS RES, V1, P1, DOI 10.4101/jvwr.v1i1.294
   Sklenicka P, 2010, ENVIRON MANAGE, V46, P424, DOI 10.1007/s00267-010-9513-3
   Tress B, 2001, LANDSCAPE URBAN PLAN, V57, P143, DOI 10.1016/S0169-2046(01)00200-6
   Tveit MS, 2009, J ENVIRON MANAGE, V90, P2882, DOI 10.1016/j.jenvman.2007.12.021
   Wei J., 2022, INT J APPL EARTH OBS, V112, P1
   Westerink J, 2017, LAND USE POLICY, V60, P408, DOI 10.1016/j.landusepol.2016.11.006
   Xi CF, 2022, REMOTE SENS-BASEL, V14, P0, DOI 10.3390/rs14010203
   Zaalberg R, 2013, RISK ANAL, V33, P866, DOI 10.1111/j.1539-6924.2012.01868.x
   Zhang Z, 2022, FRONT MICROBIOL, V13, P0, DOI 10.3389/fmicb.2022.888266
   Zhou B, 2016, PROC CVPR IEEE, V0, PP2921, DOI 10.1109/CVPR.2016.319
   Zhou ST, 2022, FORESTS, V13, P0, DOI 10.3390/f13010047
NR 54
TC 0
Z9 0
U1 8
U2 8
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 1682-1750
EI 2194-9034
J9 INT ARCH PHOTOGRAMM
PD JUN 15
PY 2022
VL 48-4
IS W4
BP 45
EP 52
DI 10.5194/isprs-archives-XLVIII-4-W4-2022-45-2022
PG 8
WC Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA BU2JR
UT WOS:000885095700007
DA 2023-04-26
ER

PT J
AU Zhao, DY
   Zhang, Z
   Lu, H
   Cheng, S
   Si, BL
   Feng, XS
AF Zhao, Dongye
   Zhang, Zheng
   Lu, Hong
   Cheng, Sen
   Si, Bailu
   Feng, Xisheng
TI Learning Cognitive Map Representations for Navigation by Sensory-Motor Integration
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article
DE Visualization; Navigation; Robot sensing systems; Brain modeling; Hippocampus; Biological system modeling; Cognitive map; hippocampus; navigation; path integration; place cells; self-motion cues; sensorimotor integration; sensory-motor integration network model (SeMINet); visual cues
ID hippocampal place cells; path-integration; grid cells; cortex; perception; networks; dynamics; neurons; system; fields
AB How to transform a mixed flow of sensory and motor information into memory state of self-location and to build map representations of the environment are central questions in the navigation research. Studies in neuroscience have shown that place cells in the hippocampus of the rodent brains form dynamic cognitive representations of locations in the environment. We propose a neural-network model called sensory-motor integration network model (SeMINet) to learn cognitive map representations by integrating sensory and motor information while an agent is exploring a virtual environment. This biologically inspired model consists of a deep neural network representing visual features of the environment, a recurrent network of place units encoding spatial information by sensorimotor integration, and a secondary network to decode the locations of the agent from spatial representations. The recurrent connections between the place units sustain an activity bump in the network without the need of sensory inputs, and the asymmetry in the connections propagates the activity bump in the network, forming a dynamic memory state which matches the motion of the agent. A competitive learning process establishes the association between the sensory representations and the memory state of the place units, and is able to correct the cumulative path-integration errors. The simulation results demonstrate that the network forms neural codes that convey location information of the agent independent of its head direction. The decoding network reliably predicts the location even when the movement is subject to noise. The proposed SeMINet thus provides a brain-inspired neural-network model for cognitive map updated by both self-motion cues and visual cues.
C1 [Zhao, Dongye; Feng, Xisheng] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang 110016, Peoples R China.
   [Zhao, Dongye; Feng, Xisheng] Chinese Acad Sci, Inst Robot, Shenyang 110169, Peoples R China.
   [Zhao, Dongye; Feng, Xisheng] Chinese Acad Sci, Inst Intelligent Mfg, Shenyang 110169, Peoples R China.
   [Zhao, Dongye; Feng, Xisheng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Zhang, Zheng] New York Univ Shanghai, Dept Comp Sci, Shanghai 316021, Peoples R China.
   [Lu, Hong] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
   [Cheng, Sen] Ruhr Univ Bochum, Inst Neuroinformat, D-44801 Bochum, Germany.
   [Si, Bailu] Beijing Normal Univ, Sch Syst Sci, Beijing 100875, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; NYU Shanghai; Fudan University; Ruhr University Bochum; Beijing Normal University
RP Si, BL (corresponding author), Beijing Normal Univ, Sch Syst Sci, Beijing 100875, Peoples R China.
EM zhaodongye@sia.cn; zz@nyu.edu; honglu@fudan.edu.cn; sen.cheng@rub.de; bailusi@bnu.edu.cn; fxs@sia.cn
FU National Key Research and Development Program of China [2016YFC0801808]; German Research Foundation [SFB 1280]
CR Aggelopoulos NC, 2005, J NEUROPHYSIOL, V93, P1342, DOI 10.1152/jn.00553.2004
   AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259
   Arleo A, 2000, BIOL CYBERN, V83, P287, DOI 10.1007/s004220000171
   Banino A, 2018, NATURE, V557, P429, DOI 10.1038/s41586-018-0102-6
   Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10
   Bjerknes TL, 2018, P NATL ACAD SCI USA, V115, PE1637, DOI 10.1073/pnas.1719054115
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Cheng S, 2011, NEUROSCIENCE, V197, P293, DOI 10.1016/j.neuroscience.2011.09.002
   Conklin J, 2005, J COMPUT NEUROSCI, V18, P183, DOI 10.1007/s10827-005-6558-z
   Cover T.M.., 2017, ELEMENTS INFORM THEO, V0, P0
   Deshmukh SS, 2011, FRONT BEHAV NEUROSCI, V5, P0, DOI 10.3389/fnbeh.2011.00069
   Dudes G., 2010, COMPUTATIONAL PRINCI, V0, P0
   ENGELSON SP, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P2555, DOI 10.1109/ROBOT.1992.220057
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   Franzius M, 2007, PLOS COMPUT BIOL, V3, P1605, DOI 10.1371/journal.pcbi.0030166
   Gagliardo A, 1999, J NEUROSCI, V19, P311, DOI 10.1523/JNEUROSCI.19-01-00311.1999
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2
   Golledge R, 2003, COLONIZATION UNFAMIL, V0, PP25, DOI 10.4324/9780203422908-13
   Guazzelli A, 2001, HIPPOCAMPUS, V11, P216, DOI 10.1002/hipo.1039
   Gustafson NJ, 2011, PLOS COMPUT BIOL, V7, P0, DOI 10.1371/journal.pcbi.1002235
   HASSELMO ME, 1989, EXP BRAIN RES, V75, P417
   JUNG MW, 1994, J NEUROSCI, V14, P7347
   Knierim JJ, 2015, HIPPOCAMPUS, V25, P719, DOI 10.1002/hipo.22453
   Langston RF, 2010, SCIENCE, V328, P1576, DOI 10.1126/science.1188210
   Leutgeb S, 2005, CURR OPIN NEUROBIOL, V15, P738, DOI 10.1016/j.conb.2005.10.002
   Leutgeb S, 2005, SCIENCE, V309, P619, DOI 10.1126/science.1114037
   Lipton P. A., 2008, NEURAL PLASTICITY, V2008, P1, DOI 10.1155/2008/258467
   Liu S, 2015, IEEE IJCNN, V0, P0
   MARKUS EJ, 1994, HIPPOCAMPUS, V4, P410, DOI 10.1002/hipo.450040404
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932
   Milford MJ, 2008, IEEE T ROBOT, V24, P1038, DOI 10.1109/TRO.2008.2004520
   Muller RU, 1996, J GEN PHYSIOL, V107, P663, DOI 10.1085/jgp.107.6.663
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKeefe J, 1996, NATURE, V381, P425, DOI 10.1038/381425a0
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   OKEEFE J, 1976, EXP NEUROL, V51, P78, DOI 10.1016/0014-4886(76)90055-8
   Petres C, 2007, IEEE T ROBOT, V23, P331, DOI 10.1109/TRO.2007.895057
   QUIRK GJ, 1990, J NEUROSCI, V10, P2008
   Rao RPN, 2004, NEURAL COMPUT, V16, P1, DOI 10.1162/08997660460733976
   Robinson L, 2015, BIOL CYBERN, V109, P505, DOI 10.1007/s00422-015-0658-2
   Rolls ET, 2006, NETWORK-COMP NEURAL, V17, P447, DOI 10.1080/09548980601064846
   Rolls ET, 2012, FRONT COMPUT NEUROSC, V6, P0, DOI 10.3389/fncom.2012.00035
   Samsonovich A, 1997, J NEUROSCI, V17, P5900
   Schonfeld F, 2013, FRONT COMPUT NEUROSC, V7, P0, DOI 10.3389/fncom.2013.00104
   Sheynikhovich D, 2009, PSYCHOL REV, V116, P540, DOI 10.1037/a0016170
   Si B, 2009, COGN NEURODYNAMICS, V3, P177, DOI 10.1007/s11571-009-9079-z
   Skaggs W, 1992, ADV NEURAL INFORM PR, V5, P0, DOI 10.5555/2987061.2987188
   Solstad T, 2006, HIPPOCAMPUS, V16, P1026, DOI 10.1002/hipo.20244
   Stella F, 2012, NEUROSCI BIOBEHAV R, V36, P1609, DOI 10.1016/j.neubiorev.2011.12.002
   Tang HJ, 2017, NEURAL NETWORKS, V87, P27, DOI 10.1016/j.neunet.2016.08.015
   Thrun S., 2005, PROBABILISTIC ROBOTI, V0, P0, DOI DOI 10.1108/03684920610675292
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Tsodyks M, 1995, INTERNATIONAL JOURNAL OF NEURAL SYSTEMS, V0, P0
   Wills TJ, 2010, SCIENCE, V328, P1573, DOI 10.1126/science.1188224
   WILSON MA, 1993, SCIENCE, V261, P1055, DOI 10.1126/science.8351520
   Zeng TP, 2017, FRONT NEUROROBOTICS, V11, P0, DOI 10.3389/fnbot.2017.00061
   Zhang J., 2017, ARXIV170609520, V0, P0
   Zhang SJ, 2013, SCIENCE, V340, P44, DOI 10.1126/science.1232627
   Zhang Wen- Hao, 2013, ADV NEURAL INFOR PRO, V0, P19
NR 59
TC 1
Z9 1
U1 11
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD JAN 15
PY 2022
VL 52
IS 1
BP 508
EP 521
DI 10.1109/TCYB.2020.2977999
PG 14
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Automation & Control Systems; Computer Science
GA YG0IU
UT WOS:000742182700046
PM 32275629
DA 2023-04-26
ER

PT J
AU Cheng, H
   Lei, HR
   Zourlidou, S
   Sester, M
AF Cheng, Hao
   Lei, Haoran
   Zourlidou, Stefania
   Sester, Monika
TI TRAFFIC CONTROL RECOGNITION WITH AN ATTENTION MECHANISM USING SPEED-PROFILE AND SATELLITE IMAGERY DATA
SO XXIV ISPRS CONGRESS IMAGING TODAY, FORESEEING TOMORROW, COMMISSION IV
LA English
DT Proceedings Paper
DE Traffic Regulation; Deep Learning; Generative Model; Attention Mechanism; Classification
AB Traffic regulators at intersections act as an essential factor that influences traffic flow and, subsequently, the route choices of commuters. A digital map that provides up-to-date traffic control information is beneficial not only for facilitating the commuters' trips, but also for energy-saving and environmental protection. In this paper, instead of using expensive surveying methods, we propose an automatic way based on a Conditional Variational Autoencoder (CVAE) to recognize traffic regulators, i.e., arm rules at intersections, by leveraging the GPS data collected from vehicles and the satellite imagery retrieved from digital maps, i.e., Google Maps. We apply a Long Short-Term Memory to extract the motion dynamics over a GPS sequence traversed through the intersection. Simultaneously, we build a Convolutional Neural Network (CNN) to extract the grid-based local imagery information associated with each step of the GPS positions. Moreover, a self-attention mechanism is adopted to extract the spatial and temporal features over both the GPS and grid sequences. The extracted temporal and spatial features are then combined for detecting the traffic arm rules. To analyze the performance of our method, we tested it on a GPS dataset collected by driving vehicles in Hannover, a medium-sized German city. Compared to a Random Forest model and an Encoder-Decoder model, our proposed model achieved better results with both accuracy and F1-score of 0.90 for the three-class (arm rules of uncontrolled, traffic light, and priority sign) task. We also carried out ablation studies to further investigate the effectiveness of the GPS input branch, the image input branch, and the self-attention mechanism in our model.
C1 [Cheng, Hao; Zourlidou, Stefania; Sester, Monika] Leibniz Univ Hannover, Inst Kartog & Geoinformat, Hannover, Germany.
   [Lei, Haoran] Leibniz Univ Hannover, Inst Kommunikat Tech, Hannover, Germany.
C3 Leibniz University Hannover; Leibniz University Hannover
RP Cheng, H (corresponding author), Leibniz Univ Hannover, Inst Kartog & Geoinformat, Hannover, Germany.
EM cheng@ikg.uni-hannover.de; haoran.lei@stud.uni-hannover.de; zourlidou@ikg.uni-hannover.de; sester@ikg.uni-hannover.de
FU German Research Foundation (DFG) [GRK2159 i.c.sens]
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Cheng H, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9110652
   Chollet F, 2015, KERAS, V0, P0
   Golze J., 2020, J CARTOGR GEOGR INF, V70, P95, DOI 10.1007/s42489-020-00048-x
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Houben S, 2013, IEEE IJCNN, V0, P0
   Hu SH, 2015, ACM T SENSOR NETWORK, V11, P0, DOI 10.1145/2770876
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   John V, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), V0, PP2286, DOI 10.1109/ITSC.2014.6958056
   Kingma D. P., 2013, AUTOENCODING VARIATI, V0, P0
   Kingma DP, 2014, ADV NEUR IN, V27, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Liao ZH, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10110769
   Meneroux Y, 2020, INT J DATA SCI ANAL, V10, P101, DOI 10.1007/s41060-019-00197-x
   Meneroux Y., 2018, DETECTION LOCALIZATI, V114, P0
   Munoz-Organero M, 2018, COMPUT ENVIRON URBAN, V68, P1, DOI 10.1016/j.compenvurbsys.2017.09.005
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   Pribe C., 1999, J TRANSP RES BOARD, V1679, P95, DOI 10.3141/1679-13
   Protschky V, 2015, IEEE INT C INTELL TR, V0, PP2438, DOI 10.1109/ITSC.2015.393
   Saremi F, 2015, IEEE INT CONF MOB, V0, PP145, DOI 10.1109/MASS.2015.18
   Sohn K, 2015, ADV NEUR IN, V28, P0
   Tian Y, 2019, IEEE T INTELL TRANSP, V20, P4466, DOI 10.1109/TITS.2018.2886283
   Tin Kam Ho, 1995, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, V0, PP278, DOI 10.1109/ICDAR.1995.598994
   van Rossum G., 1995, PYTHON REFERENCE MAN, V0, P0
   Vaswani A., 2017, ADV NEURAL INFORM PR, V30, P5998
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Zourlidou S, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8110491
NR 27
TC 0
Z9 0
U1 2
U2 2
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 1682-1750
EI 2194-9034
J9 INT ARCH PHOTOGRAMM
PD JUN 15
PY 2022
VL 43-B4
IS 
BP 288
EP 294
DI 10.5194/isprs-archives-XLIII-B4-2022-287-2022
PG 7
WC Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA BT8WE
UT WOS:000855689800040
DA 2023-04-26
ER

PT J
AU Oyewola, OM
   Ismail, OS
   Olasinde, MO
   Ajide, OO
AF Oyewola, Olanrewaju M.
   Ismail, Olawale S.
   Olasinde, Malik O.
   Ajide, Olusegun O.
TI Mapping of solar energy potential in Fiji using an artificial neural network approach
SO HELIYON
LA English
DT Article
DE Artificial neural network; ANN learning algorithms; Activation function; Solar radiation mapping; Coefficient of correlation
ID radiation
AB The concerned stakeholders have been pursuing renewable energy seriously due to its overwhelming benefits. Countries that receive less solar radiation are not lagging behind as they are working to optimize the available radiation let alone of countries that receive sufficient solar radiation over long durations such as Fiji. In view of the abundancy of this energy in Fiji, the country has been working intensely on tapping the full potential of this energy, thus proposed that by 2030; more than 50% of its energy will come from renewable energy. The accurate estimation of global solar radiation determines the reliability of performance evaluation of solar energy systems. Therefore, the key interest of this study is in respect of accurate mapping of solar radiation to aid reliable solar energy design especially in siting and sizing of photovoltaic power systems. In the light of this, this work modelled solar radiation on the earth of Fiji from common meteorological and geographical data in all locations in Fiji using Artificial Neural Networks (ANN). There are different configurations of ANN but in this study, Levenberg-Marquardt (LM) and Scaled Conjugate Gradient (SCG) were selected as the learning algorithms due to the data size, speed of computation and the success of these algorithms in solar radiation modelling. Similarly, a tangent sigmoid transfer function was used in the network. In total, twelve different configurations of ANN were considered and the best configuration was selected to predict the solar radiation potential in Fiji. Since ANN requires input data to train the network, meteorological data covering 36 years (1984-2019) and geographical data from NASA database were supplied to the network. All the locations considered were distributed evenly throughout Fiji and thus covered all the four regions and 14 provinces in Fiji. The geographical and meteoro-logical data used to train the network are month, latitude, longitude, altitude, mean temperature, relative hu-midity, precipitation and solar radiation. The mean squared error of 0.118838 and correlation coefficient of 0.9402 were obtained between the ANN predicted and measured solar radiation for the entire dataset. These correlation coefficients and mean squared error showed that ANN model of solar radiation in Fiji is satisfactory and thus can be used as an alternative where solar radiation data are not available. Similarly, the network pro-duced satisfactory solar radiation result for the locations where there are no solar radiation data. To ease solar radiation assessment of all places in Fiji, the iso-lines of the solar radiation were presented in the form of monthly maps. It is believed that this prediction will aid energy stakeholders in making best decision concerning solar energy potential in Fiji thus boosting optimal utilization of the scarce resource.
C1 [Oyewola, Olanrewaju M.] Fiji Natl Univ, Sch Mech Engn, Suva, Fiji.
   [Oyewola, Olanrewaju M.; Ismail, Olawale S.; Olasinde, Malik O.; Ajide, Olusegun O.] Univ Ibadan, Dept Mech Engn, Ibadan, Oyo State, Nigeria.
C3 Fiji National University (FNU); University of Ibadan
RP Oyewola, OM (corresponding author), Fiji Natl Univ, Sch Mech Engn, Suva, Fiji.; Oyewola, OM (corresponding author), Univ Ibadan, Dept Mech Engn, Ibadan, Oyo State, Nigeria.
EM oooyewola001@gmail.com
CR Adaramola MS, 2012, RENEW ENERG, V47, P38, DOI 10.1016/j.renene.2012.04.005
   Agrawala S., 2003, DEV CLIMATE CHANGE F, V0, P0
   Beale M. H., 2010, NEURAL NETWORK TOOLB, V0, P0
   Benali L., 2018, RENEW ENERG, V0, P0
   Benkaciali S., 2016, REV ENERGIES RENOUVE, V19, P617
   Bhikabhai Y, 2005, 406 SOPAC, V0, P0
   BLACK J. N., 1956, ARCH METEOROL GEOPHYS BIOKLIMATOL SER B, V7, P165, DOI 10.1007/BF02243320
   Chen Y., 2015, FIJI RENEWABLE READI, V0, P0
   COOPER PI, 1969, SOL ENERGY, V12, P333, DOI 10.1016/0038-092X(69)90047-4
   Dornan M., 2011, AUSTR AGR RES EC SOC, V0, P0
   Fadare D., 2010, AM J SCI IND RES, V1, P144, DOI 10.5251/AJSIR.2010.1.2.144.157
   Fadare DA, 2009, APPL ENERG, V86, P1410, DOI 10.1016/j.apenergy.2008.12.005
   Fiji Renewable Energy Power Project (FREPP), 2014, WAST EN RES ASS FIJ, V0, P0
   Ghimire S, 2019, J CLEAN PROD, V216, P288, DOI 10.1016/j.jclepro.2019.01.158
   Hargreaves GH, 2003, J IRRIG DRAIN ENG, V129, P53, DOI 10.1061/(ASCE)0733-9437(2003)129:1(53)
   Hassan G.E., 2017, ENV SCI SUSTAINABLE, V0, P1
   Hontoria L, 2002, SOL ENERGY, V72, P441, DOI 10.1016/S0038-092X(02)00010-5
   Kalogirou SA, 2001, RENEW SUST ENERG REV, V5, P373, DOI 10.1016/S1364-0321(01)00006-5
   Krishnaiah T., 2007, J APPL SCI RES, V3, P1105
   LOF GOG, 1966, SOL ENERGY, V10, P27, DOI 10.1016/0038-092X(66)90069-7
   Barrera JM, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12176915
   Mellit A, 2006, APPL ENERG, V83, P705, DOI 10.1016/j.apenergy.2005.06.003
   National aeronautics and space administration (NASA), 2021, US, V0, P0
   Notton G, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9010209
   Oyewola OM, 2022, ALEX ENG J, V61, P8555, DOI 10.1016/j.aej.2022.01.065
   Podder Shuvankar, 2015, JOURNAL OF RENEWABLE ENERGY, V0, P0, DOI DOI 10.1155/2015/482543
   Prasad S.B, 1991, RERIC INT ENERG J, V13, P131
   Shboul B, 2021, SUSTAIN ENERGY TECHN, V46, P0, DOI 10.1016/j.seta.2021.101248
   Siwratibau S, 1982, AGR WASTES, V4, P159
   Sofiu V, 2011, J ENG STUD RES, V17, P109
   Sozen A, 2004, APPL ENERG, V77, P273, DOI 10.1016/S0306-2619(03)00137-5
   SPC (Secretariat of the Pacific Community), 2020, US, V0, P0
   Svantesson J., 2012, THESIS ROYAL I TECHN, V0, P31
   Woodruff A, 2007, 397 SOPAC, V0, P0
   World Bank Group, 2017, REP FIJ SYST COUNTR, V0, P0
NR 35
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 
EI 2405-8440
J9 HELIYON
JI Heliyon
PD JUL 15
PY 2022
VL 8
IS 7
BP 
EP 
DI 10.1016/j.heliyon.2022.e09961
EA JUL 2022
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA 3Y1TD
UT WOS:000843511300011
PM 35874079
DA 2023-04-26
ER
