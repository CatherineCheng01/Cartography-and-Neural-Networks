
PT J
AU Christodoulou, V
   Filgueira, R
   Bee, E
   MacDonald, E
   Kosar, B
AF Christodoulou, Vyron
   Filgueira, Rosa
   Bee, Emma
   MacDonald, Elizabeth
   Kosar, Burcu
TI Automatic classification of Aurora-related tweets using machine learning methods
SO 2019 2ND INTERNATIONAL CONFERENCE ON GEOINFORMATICS AND DATA ANALYSIS (ICGDA 2019)
LA English
DT Proceedings Paper
DE Twitter; text classification; Deep neural networks; Aurora detection
AB The constant flow of information by social media provides valuable information about all sorts of events at a high temporal and spatial resolution. Over the past few years we have been analyzing in real-time geological hazards/phenomena, such as earthquakes, volcanic eruptions, landslides, floods or the aurora, as part of the GeoSocial project, by geo-locating tweets filtered by keywords in a web-map. However, up to this date only a keyword-based filtering was applied that does not always filter out tweets that are unrelated to hazard-events. Therefore, this work explores five learning-based classification techniques: a Linear SVM and four Deep Neural Networks (DNNs): a Convolutional Neural Network (CNN), a Recurrent Neural Network (RNN), a RNN-Long-short-term memory (RNN-LSTM) and a RNN-Gated Recurrent Unit (GRU) for automatic hazard-event classification based on tweets about Aurora sightings. In addition, for the DNNS we also trained the algorithms using pre-trained word2vec word-embeddings. We finally evaluate the algorithms using two datasets, one from the Aurorasaurus application and one manually labeled in the BGS. We show that DNNs and especially the CNN perform better for both datasets and that there is potential for improvement. Our code is also available online(1).
C1 [Christodoulou, Vyron; Bee, Emma] British Geol Survey, Edinburgh, Midlothian, Scotland.
   [Filgueira, Rosa] EPCC, Edinburgh, Midlothian, Scotland.
   [MacDonald, Elizabeth; Kosar, Burcu] NASA, Goddard Space Flight Ctr, Greenbelt, MD USA.
C3 UK Research & Innovation (UKRI); Natural Environment Research Council (NERC); NERC British Geological Survey; National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center
RP Christodoulou, V (corresponding author), British Geol Survey, Edinburgh, Midlothian, Scotland.
EM vyronc@bgs.ac.uk; r.filgueira@epcc.ed.ac.uk; ebee@bgs.ac.uk; elizabeth.a.macdonald@nasa.gov; burcu.kosar@nasa.gov
FU NERC [bgs05014] Funding Source: UKRI
CR Ashktorab Z., 2014, ISCRAM, V0, P354
   Avvenuti M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP1749, DOI 10.1145/2623330.2623358
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Blair SJ, 2016, FRONT ARTIF INTEL AP, V284, P155, DOI 10.3233/978-1-61499-682-8-155
   Case Nathan Anthony, 2016, CITIZEN SCI THEORY P, V2016, P0
   Cho K., 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/v1/d14-1179
   Earle PS, 2011, ANN GEOPHYS-ITALY, V54, P708, DOI 10.4401/ag-5364
   Godin F., 2015, P WORKSH NOIS US GEN, V0, PP146, DOI 10.18653/V1/W15-4322
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Guzman TD, 2013, FIRST PEOPLE NEW DIR, V0, P31
   Khan FH, 2014, DECIS SUPPORT SYST, V57, P245, DOI 10.1016/j.dss.2013.09.004
   Kim Y., 2014, P 2014 EMP METH NAT, V0, P1746
   MacDonald EA, 2015, SPACE WEATHER, V13, P548, DOI 10.1002/2015SW001214
   Mikolov T., 2017, ADV PRETRAINING DIST, V0, P0
   Sakaki T, 2010, P 19 INT C WORLD WID, V0, PP851, DOI 10.1145/1772690.1772777
   To H, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), V0, PP330, DOI 10.1109/BigMM.2017.82
NR 17
TC 0
Z9 0
U1 1
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
SN 
EI 
J9 
PD JUN 15
PY 2019
VL 0
IS 
BP 115
EP 119
DI 10.1145/3318236.3318242
PG 5
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Geosciences, Multidisciplinary
SC Computer Science; Engineering; Geology
GA BN3FI
UT WOS:000478860700022
DA 2023-04-26
ER

PT J
AU Pershina, JS
   Kazdorf, SY
   Lopota, AV
AF Pershina, J. S.
   Kazdorf, S. Ya.
   Lopota, A. V.
TI Methods of Mobile Robot Visual Navigation and Environment Mapping
SO OPTOELECTRONICS INSTRUMENTATION AND DATA PROCESSING
LA English
DT Article
DE visual navigation; convolutional neural networks; semantic segmentation; cognitive map
ID cognitive maps
AB State-of-the-art methods of visual navigation for mobile robots are considered. A hierarchical representation structure of the environment corresponding to the hierarchical organization of the mobile robot control system is proposed. State-of-the-art approaches to constructing map models are presented. Their development will bring the navigation system closer to that formed by the human intellect and combines vision and a semantic view of the world within cognitive maps.
C1 [Pershina, J. S.; Kazdorf, S. Ya.] Novosibirsk State Tech Univ, Pr Karla Marksa 20, Novosibirsk 630070, Russia.
   [Lopota, A. V.] Cent Res Inst Robot & Tech Cybernet, Tikhoretskii Pr 21, St Petersburg 194064, Russia.
C3 Novosibirsk State Technical University
RP Pershina, JS (corresponding author), Novosibirsk State Tech Univ, Pr Karla Marksa 20, Novosibirsk 630070, Russia.
EM pershina@tiger.cs.nstu.ru; alopota@rtc.ru
FU Russian Foundation for Basic Research [18-58-76003]
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   [Барамия Денис Александрович Baramiya D.A.], 2017, АВТОМЕТРИЯ OPTOELECTRONICS INSTRUMENTATION AND DATA PROCESSING AVTOMETRIYA, V53, P77, DOI 10.15372/AUT20170609
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bingxi Jia, 2015, CONTROL THEORY AND TECHNOLOGY, V13, P311, DOI 10.1007/s11768-015-4068-8
   Hua BS, 2018, PROC CVPR IEEE, V0, PP984, DOI 10.1109/CVPR.2018.00109
   Bowman Sean L., 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP1722, DOI 10.1109/ICRA.2017.7989203
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chaumette F, 2006, IEEE ROBOT AUTOM MAG, V13, P82, DOI 10.1109/MRA.2006.250573
   Cherabier I, 2018, LECT NOTES COMPUT SC, V11216, P325, DOI 10.1007/978-3-030-01258-8_20
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Civera J, 2011, IEEE INT C INT ROBOT, V0, PP1277, DOI 10.1109/IROS.2011.6048293
   Dai A., 2018, COMP VIS PATTERN REC, V0, P0
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, V0, PP2432, DOI 10.1109/CVPR.2017.261
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Garcia-Garcia A., 2017, COMP VIS PATTERN REC, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Kirilchenko A A, 2002, THEORETICAL ASPECTS, V0, P0
   Klein George, 2007, P1, V0, P0
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lopota A V, 2013, ISSLEDOVANIYA NAUKOG, V4, P49
   Lowe D. G., 1999, INT C COMP VIS, V0, P0
   Makarov I M, 2006, IZV YUFU TEKHNICHESK, V58, P3
   McCormac John, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP4628, DOI 10.1109/ICRA.2017.7989538
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Newcombe RA, 2011, IEEE I CONF COMP VIS, V0, PP2320, DOI 10.1109/ICCV.2011.6126513
   Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103
   Pham Q. H., 2017, COMP VIS PATTERN REC, V0, P0
   Pinheiro P. H. O., 2015, NIPS, V0, P1990
   [Половко С.А. Polovko S.A.], 2014, РОБОТОТЕХНИКА И ТЕХНИЧЕСКАЯ КИБЕРНЕТИКА ROBOTICS AND TECHNICAL CYBERNETICS ROBOTOTEKHNIKA I TEKHNICHESKAYA KIBERNETIKA, V0, P30
   Qi C. R., 2017, ADV NEURAL INFORM PR, V0, P5099
   REDMON J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rublee E, 2011, IEEE I CONF COMP VIS, V0, PP2564, DOI 10.1109/ICCV.2011.6126544
   Simonyan K., 2015, COMP VIS PATTERN REC, V0, P0
   Song SR, 2017, PROC CVPR IEEE, V0, PP190, DOI 10.1109/CVPR.2017.28
   Thrun S, 1998, AUTON ROBOT, V5, P253, DOI 10.1023/A:1008806205438
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Vasudevan S, 2007, ROBOT AUTON SYST, V55, P359, DOI 10.1016/j.robot.2006.12.008
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   [Яковлев К.С. Yakovlev K.S.], 2014, РОБОТОТЕХНИКА И ТЕХНИЧЕСКАЯ КИБЕРНЕТИКА ROBOTICS AND TECHNICAL CYBERNETICS ROBOTOTEKHNIKA I TEKHNICHESKAYA KIBERNETIKA, V0, P44
   [Юдин Д.А. Yudin D.A.], 2014, РОБОТОТЕХНИКА И ТЕХНИЧЕСКАЯ КИБЕРНЕТИКА ROBOTICS AND TECHNICAL CYBERNETICS ROBOTOTEKHNIKA I TEKHNICHESKAYA KIBERNETIKA, V0, P70
   Yushchenko A. S., 2004, MEKHATRONIKA AVTOMAT, V0, P31
NR 48
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 8756-6990
EI 1934-7944
J9 OPTOELECTRON INSTRUM
JI Optoelectron. Instrum. Data Proc.
PD MAR 15
PY 2019
VL 55
IS 2
BP 181
EP 188
DI 10.3103/S8756699019020109
PG 8
WC Physics, Multidisciplinary
SC Physics
GA ID4PI
UT WOS:000471658400010
DA 2023-04-26
ER

PT J
AU Peng, YP
   Zhao, L
   Hu, YM
   Wang, GX
   Wang, L
   Liu, ZH
AF Peng, Yiping
   Zhao, Li
   Hu, Yueming
   Wang, Guangxing
   Wang, Lu
   Liu, Zhenhua
TI Prediction of Soil Nutrient Contents Using Visible and Near-Infrared Reflectance Spectroscopy
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE soil nutrient contents; hyperspectral; accuracy improvement; BPNN; GA-BPNN
ID nir spectroscopy; organic-matter; total nitrogen; heavy-metals; regression; phosphorus; inversion; accuracy; plsr
AB Quickly and efficiently monitoring soil nutrient contents using remote sensing technology is of great significance for farmland soil productivity, food security and sustainable agricultural development. Current research has been conducted to estimate and map soil nutrient contents in large areas using hyper-spectral techniques, however, it is difficult to obtain accurate estimates. In order to improve the estimation accuracy of soil nutrient contents, we introduced a GA-BPNN method, which combined a back propagation neural network (BPNN) with the genetic algorithm optimization (GA). This study was conducted in Guangdong, China, based on soil nutrient contents and hyperspectral data. The prediction accuracies from a partial least squares regression (PLSR), BPNN and GA-BPNN were compared using field observations. The results showed that (1) Among three methods, the GA-BPNN provided the most accurate estimates of soil total nitrogen (TN), total phosphorus (TP) and total potassium (TK) contents; (2) Compared with the BPNN models, the GA-BPNN models significantly improved the estimation accuracies of the soil nutrient contents by decreasing the relative root mean square error (RRMSE) values by 15.9%, 5.6% and 20.2% at the sample point level, and 20.1%, 16.5% and 47.1% at the regional scale for TN, TP and TK, respectively. This indicated that by optimizing the parameters of BPNN, the GA-BPNN provided greater potential to improving the estimation; and (3) Soil TK content could be more accurately mapped by the GA-BPNN method using HuanJing-1A Hyperspectral Imager (HJ-1A HSI) (manufacturer: China Aerospace Science and Technology Corporation; Beijing, China) data with a RRMSE value of 20.37% than the soil TN and TP with the RRMSE values of 40.41% and 34.71%, respectively. This implied that the GA-BPNN model provided the potential to map the soil TK content for the large area. The research results provided an important reference for high-accuracy prediction of soil nutrient contents.
C1 [Peng, Yiping; Zhao, Li; Hu, Yueming; Wang, Guangxing; Wang, Lu; Liu, Zhenhua] South China Agr Univ, Coll Nat Resources & Environm, Guangzhou 510642, Guangdong, Peoples R China.
   [Hu, Yueming] South China Agr Univ, Guangdong Prov Key Lab Land Use & Consolidat, Guangzhou 510642, Guangdong, Peoples R China.
   [Hu, Yueming] South China Agr Univ, Guangdong Prov Engn Res Ctr Land Informat Technol, Guangzhou 510642, Guangdong, Peoples R China.
   [Hu, Yueming] South China Agr Univ, Key Lab Construct Land Transformat, Minist Land & Resources, Guangzhou 510642, Guangdong, Peoples R China.
   [Hu, Yueming] Qinghai Univ, Coll Agr & Anim Husb, Xining 810016, Qinghai, Peoples R China.
   [Wang, Guangxing] SIUC, Coll Liberal Arts, Dept Geog & Environm Resources, Carbondale, IL 62901 USA.
C3 South China Agricultural University; South China Agricultural University; South China Agricultural University; Ministry of Natural Resources of the People's Republic of China; South China Agricultural University; Qinghai University; Southern Illinois University System; Southern Illinois University
RP Hu, YM; Liu, ZH (corresponding author), South China Agr Univ, Coll Nat Resources & Environm, Guangzhou 510642, Guangdong, Peoples R China.; Hu, YM (corresponding author), South China Agr Univ, Guangdong Prov Key Lab Land Use & Consolidat, Guangzhou 510642, Guangdong, Peoples R China.; Hu, YM (corresponding author), South China Agr Univ, Guangdong Prov Engn Res Ctr Land Informat Technol, Guangzhou 510642, Guangdong, Peoples R China.; Hu, YM (corresponding author), South China Agr Univ, Key Lab Construct Land Transformat, Minist Land & Resources, Guangzhou 510642, Guangdong, Peoples R China.; Hu, YM (corresponding author), Qinghai Univ, Coll Agr & Anim Husb, Xining 810016, Qinghai, Peoples R China.
EM pyppyp@stu.scau.edu.cn; zhaoli@stu.scau.edu.cn; ymhu@scau.edu.cn; gxwang@siu.edu; selinapple@scau.edu.cn; zhenhua@scau.edu.cn
FU National Key Research and Development Program of China [2016YFC0501801, 2018YFD1100801-01]; Qinghai Province Science and Technology Planning Project [2017-ZJ-730]; Guangzhou Science and Technology Project, China [201804020034]
CR Adeline KRM, 2017, GEODERMA, V288, P143, DOI 10.1016/j.geoderma.2016.11.010
   An X.F., 2015, COMPUTER COMPUTING T, V0, P117
   Balabin RM, 2011, ANALYST, V136, P1703, DOI 10.1039/c0an00387e
   Cao FX, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17112603
   Casa R, 2013, VADOSE ZONE J, V12, P0, DOI 10.2136/vzj2012.0201
   Chen T, 2016, SCI TOTAL ENVIRON, V565, P155, DOI 10.1016/j.scitotenv.2016.04.163
   Dong X, 2017, SPECTROSC SPECT ANAL, V37, P557, DOI 10.3964/j.issn.1000-0593(2017)02-0557-09
   Fabre S, 2015, SENSORS-BASEL, V15, P3262, DOI 10.3390/s150203262
   Falahatkar S, 2016, ARCH AGRON SOIL SCI, V62, P375, DOI 10.1080/03650340.2015.1051472
   Gao HZ, 2011, SPECTROSC SPECT ANAL, V31, P1245, DOI 10.3964/j.issn.1000-0593(2011)05-1245-05
   Gomez C, 2008, GEODERMA, V148, P141, DOI 10.1016/j.geoderma.2008.09.016
   Haque ME, 2002, INT J FATIGUE, V24, P1003, DOI 10.1016/S0142-1123(01)00207-9
   Hively W. D., 2011, APPLIED AND ENVIRONMENTAL SOIL SCIENCE, V2011, P358193, DOI 10.1155/2011/358193
   Hu G, 2016, T ASABE, V59, P97
   Kang J, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020192
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Khosravi V, 2018, GEODERMA, V318, P29, DOI 10.1016/j.geoderma.2017.12.025
   Leone AP, 2012, CURR ANAL CHEM, V8, P283
   Lin LX, 2015, SENSORS-BASEL, V15, P17990, DOI 10.3390/s150817990
   Liu HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010029
   LIU P, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11020419
   Liu ZH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121464
   Lu P, 2013, J GEOCHEM EXPLOR, V132, P26, DOI 10.1016/j.gexplo.2013.04.003
   Ma L, 2014, ECOL RES, V29, P69, DOI 10.1007/s11284-013-1100-7
   Ma Wei-bo, 2016, JOURNAL OF ECOLOGY AND RURAL ENVIRONMENT, V32, P213
   Mouazen AM, 2007, SOIL TILL RES, V93, P13, DOI 10.1016/j.still.2006.03.009
   Mouazen AM, 2010, GEODERMA, V158, P23, DOI 10.1016/j.geoderma.2010.03.001
   Panda SS, 2010, REMOTE SENS-BASEL, V2, P673, DOI 10.3390/rs2030673
   Pirie A, 2005, AUST J SOIL RES, V43, P713, DOI 10.1071/SR04182
   Ramoelo A, 2013, ISPRS J PHOTOGRAMM, V82, P27, DOI 10.1016/j.isprsjprs.2013.04.012
   Razakamanarivo RH, 2011, GEODERMA, V162, P335, DOI 10.1016/j.geoderma.2011.03.006
   Saleh SM, 2016, APPL SOFT COMPUT, V48, P535, DOI 10.1016/j.asoc.2016.07.043
   Gomez RS, 2016, J APPL STAT, V43, P1831, DOI 10.1080/02664763.2015.1120712
   ShuMin Duan, 2014, ADVANCED MATERIALS RESEARCH, V1022, P292, DOI 10.4028/www.scientific.net/AMR.1022.292
   Song YQ, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18093086
   Tang Faming, 2006, JOURNAL OF SYSTEMS ENGINEERING AND ELECTRONICS, V17, P200, DOI 10.1016/S1004-4132(06)60035-2
   Walkley A, 1934, SOIL SCI, V37, P29, DOI 10.1097/00010694-193401000-00003
   Wang FH, 2018, ISPRS J PHOTOGRAMM, V136, P73, DOI 10.1016/j.isprsjprs.2017.12.003
   Wang JJ, 2014, GEODERMA, V216, P1, DOI 10.1016/j.geoderma.2013.10.024
   Wang QA, 2010, SCI CHINA EARTH SCI, V53, P51, DOI 10.1007/s11430-010-4139-0
   WOLD H, 1966, RES PAPERS STAT, V0, P441
   Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1
   Xu J, 2015, INSECT MOL BIOL, V24, P183, DOI 10.1111/imb.12144
   Xu SX, 2018, GEODERMA, V310, P29, DOI 10.1016/j.geoderma.2017.09.013
   Xu YM, 2018, GEODERMA, V320, P52, DOI 10.1016/j.geoderma.2018.01.017
   Yu L, 2016, SPECTROSC SPECT ANAL, V36, P1428, DOI 10.3964/j.issn.1000-0593(2016)05-1428-06
   Zhao L, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10072474
NR 47
TC 28
Z9 28
U1 13
U2 93
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. Geo-Inf.
PD OCT 15
PY 2019
VL 8
IS 10
BP 
EP 
DI 10.3390/ijgi8100437
PG 18
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA JP6UM
UT WOS:000498398300012
DA 2023-04-26
ER

PT J
AU Carvajal-Ramirez, F
   da Silva, JRM
   Aguera-Vega, F
   Martinez-Carricondo, P
   Serrano, J
   Moral, FJ
AF Carvajal-Ramirez, Fernando
   Marques da Silva, Jose Rafael
   Aguera-Vega, Francisco
   Martinez-Carricondo, Patricio
   Serrano, Joao
   Jesus Moral, Francisco
TI Evaluation of Fire Severity Indices Based on Pre- and Post-Fire Multispectral Imagery Sensed from UAV
SO REMOTE SENSING
LA English
DT Article
DE Fire Severity; UAV; Multispectral Imagery
ID structure-from-motion; burn severity; vegetation recovery; classification; ndvi
AB Fire severity is a key factor for management of post-fire vegetation regeneration strategies because it quantifies the impact of fire, describing the amount of damage. Several indices have been developed for estimation of fire severity based on terrestrial observation by satellite imagery. In order to avoid the implicit limitations of this kind of data, this work employed an Unmanned Aerial Vehicle (UAV) carrying a high-resolution multispectral sensor including green, red, near-infrared, and red edge bands. Flights were carried out pre- and post-controlled fire in a Mediterranean forest. The products obtained from the UAV-photogrammetric projects based on the Structure from Motion (SfM) algorithm were a Digital Surface Model (DSM) and multispectral images orthorectified in both periods and co-registered in the same absolute coordinate system to find the temporal differences (d) between pre- and post-fire values of the Excess Green Index (EGI), Normalized Difference Vegetation Index (NDVI), and Normalized Difference Red Edge (NDRE) index. The differences of indices (dEGI, dNDVI, and dNDRE) were reclassified into fire severity classes, which were compared with the reference data identified through the in situ fire damage location and Artificial Neural Network classification. Applying an error matrix analysis to the three difference of indices, the overall Kappa accuracies of the severity maps were 0.411, 0.563, and 0.211 and the Cramer's Value statistics were 0.411, 0.582, and 0.269 for dEGI, dNDVI, and dNDRE, respectively. The chi-square test, used to compare the average of each severity class, determined that there were no significant differences between the three severity maps, with a 95% confidence level. It was concluded that dNDVI was the index that best estimated the fire severity according to the UAV flight conditions and sensor specifications.
C1 [Carvajal-Ramirez, Fernando; Aguera-Vega, Francisco; Martinez-Carricondo, Patricio] Univ Almeria, Dept Engn, Mediterranean Res Ctr Econ & Sustainable Dev CIME, ceiA3, Agrifood Campus Int Excellence, Almeria 04120, Spain.
   [Marques da Silva, Jose Rafael; Serrano, Joao] Univ Evora, ICAAM, Rural Engn Dept, Apartado 94, P-7002554 Evora, Portugal.
   [Marques da Silva, Jose Rafael] Agroinsider PITE R Circular Norte, NERE Sala 12-10, P-7005841 Evora, Portugal.
   [Martinez-Carricondo, Patricio] Univ Almeria, Peripheral Serv Res & Dev Based Drones, Canada San Urbano S-N, Almeria 04120, Spain.
   [Jesus Moral, Francisco] Univ Extremadura, Escuela Ingn Ind, Dept Expres Graf, Avda Elvas S-N, Badajoz 06006, Spain.
C3 Universidad de Almeria; University of Evora; Universidad de Almeria; Universidad de Extremadura
RP Carvajal-Ramirez, F (corresponding author), Univ Almeria, Dept Engn, Mediterranean Res Ctr Econ & Sustainable Dev CIME, ceiA3, Agrifood Campus Int Excellence, Almeria 04120, Spain.
EM carvajal@ual.es; jmsilva@uevora.pt; faguera@ual.es; pmc824@ual.es; jmrs@uevora.pt; fjmoral@unex.es
CR ACOCK AC, 1979, SOC FORCES, V57, P1381, DOI 10.2307/2577276
   Aguera-Vega F, 2018, MEASUREMENT, V121, P127, DOI 10.1016/j.measurement.2018.02.062
   Aguera-Vega F, 2017, J SURV ENG, V143, P0, DOI 10.1061/(ASCE)SU.1943-5428.0000206
   Aguilar FJ, 2005, PHOTOGRAMM ENG REM S, V71, P805, DOI 10.14358/PERS.71.7.805
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Tran BN, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111680
   Certini G, 2005, OECOLOGIA, V143, P1, DOI 10.1007/s00442-004-1788-8
   Chen X, 2018, INT J REMOTE SENS, V39, P6479, DOI 10.1080/01431161.2018.1460507
   Chuvieco E, 2006, J GEOPHYS RES-BIOGEO, V111, P0, DOI 10.1029/2005JG000143
   Diaz-Delgado R, 2003, INT J REMOTE SENS, V24, P1751, DOI 10.1080/01431160210144732
   Dillon GK, 2011, ECOSPHERE, V2, P0, DOI 10.1890/ES11-00271.1
   Escuin S, 2008, INT J REMOTE SENS, V29, P1053, DOI 10.1080/01431160701281072
   Fonstad MA, 2013, EARTH SURF PROC LAND, V38, P421, DOI 10.1002/esp.3366
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Fornacca D, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081196
   Fraser RH, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030279
   French NHF, 2008, INT J WILDLAND FIRE, V17, P443, DOI 10.1071/WF08007
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Glocker M., 2012, 2012 6 ESA WORKSH GN, V0, PP1, DOI 10.1109/NAVITEC.2012.6423060
   Gonzalez-Alonso F, 2007, INT J REMOTE SENS, V28, P797, DOI 10.1080/01431160600979115
   Hassan MA, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060809
   Huang YB, 2010, COMPUT ELECTRON AGR, V71, P107, DOI 10.1016/j.compag.2010.01.001
   Huesca M, 2013, INT J REMOTE SENS, V34, P4025, DOI 10.1080/01431161.2013.772313
   Keeley JE, 2008, ECOL APPL, V18, P1530, DOI 10.1890/07-0836.1
   Leon JRR, 2012, REMOTE SENS-BASEL, V4, P598, DOI 10.3390/rs4030598
   Montealegre AL, 2014, REMOTE SENS-BASEL, V6, P4240, DOI 10.3390/rs6054240
   Fernandez-Guisuraga JM, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18020586
   Martinez-Carricondo P, 2018, INT J APPL EARTH OBS, V72, P1, DOI 10.1016/j.jag.2018.05.015
   McKenna P, 2017, INT J REMOTE SENS, V38, P4244, DOI 10.1080/01431161.2017.1317942
   Parks SA, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060879
   Pla M, 2017, REV TELEDETEC, V0, PP91, DOI 10.4995/raet.2017.7140
   Poblete T, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17112488
   Polychronaki A, 2013, REMOTE SENS-BASEL, V5, P5680, DOI 10.3390/rs5115680
   Richards JA, 2013, REMOTE SENSING DIGIT, V5th, P0
   Silveira EMO, 2019, INT J APPL EARTH OBS, V78, P175, DOI 10.1016/j.jag.2019.02.004
   Tits L, 2015, IEEE GEOSCI REMOTE S, V12, P82, DOI 10.1109/LGRS.2014.2326555
   van Leeuwen WJD, 2008, SENSORS-BASEL, V8, P2017, DOI 10.3390/s8032017
   Veraverbeke S, 2011, INT J REMOTE SENS, V32, P3521, DOI 10.1080/01431161003752430
   Verhegghen A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8120986
   Vlassova L, 2014, REMOTE SENS-BASEL, V6, P6136, DOI 10.3390/rs6076136
   Wallace L, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080679
   Warner TA, 2017, INT J REMOTE SENS, V38, P598, DOI 10.1080/01431161.2016.1268739
NR 42
TC 37
Z9 38
U1 4
U2 30
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY 1
PY 2019
VL 11
IS 9
BP 
EP 
DI 10.3390/rs11090993
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA IA7US
UT WOS:000469763600001
DA 2023-04-26
ER

PT J
AU Zheng, LN
   Zhang, T
   Yu, XG
AF Zheng, Lina
   Zhang, Ting
   Yu, Xinguo
TI Recognition of Handwritten Chemical Organic Ring Structure Symbols Using Convolutional Neural Networks
SO 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION WORKSHOPS (ICDARW), VOL 5
LA English
DT Proceedings Paper
DE Handwritten symbol recognition; Chemical organic ring structure symbols; convolutional neural networks
AB Many types of data exhibit characteristic of rotational symmetry. Chemical Organic Ring Structure(ORS) Symbol is such a case. In this paper, we focus on offline handwritten chemical ORS Symbols recognition using convolutional neural networks(CNNs), from application point of view, in order to relax the inconvenience and ineffectiveness of the traditional click-and-drag style of interaction when input chemical notations into electronic devices; from scientific point of view, to explore the capacity of rotation invariance of CNNs using data augmentation. We propose a VGGNet-based classifier for offline handwritten chemical ORS Symbols. To evaluate it, a new dataset of 3600 samples are collected of which 90% is for training while 10% is for test. The recognition accuracy is 84.3% with VGGNet-16 and 92.4% with VGGNet-19.
C1 [Zheng, Lina] Cent China Normal Univ, Cent China Normal Univ Wollongong Joint Inst, Wuhan, Hubei, Peoples R China.
   [Zhang, Ting; Yu, Xinguo] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
C3 Central China Normal University; Central China Normal University
RP Zhang, T (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
EM zhenglinawawdj@gmail.com; ting.zhang@mail.ccnu.edu.cn; xgyu@mail.ccnu.edu.cn
FU China Postdoctoral Science Foundation [2019M652678]; Fundamental Research Funds for the Central Universities [CCNU18XJ046]
CR Cousins KR, 2011, J AM CHEM SOC, V133, P8388, DOI 10.1021/ja204075s
   Dan B., 2014, DRUGBANK, V0, P0
   Fleischner H., 2000, THEORETICAL COMPUTER, V289, P503
   Hussain M., 2018, UK WORKSH COMP INT, V0, P0
   Krizhevsky A., 2012, INT C NEURAL INFORM, V0, P0
   Liwicki M, 2011, PROC INT CONF DOC, V0, PP1480, DOI 10.1109/ICDAR.2011.294
   Ouyang T. Y., 2011, CHEMINK NATURAL REAL, V0, P0
   Ouyang T. Y., 2007, NAT C ART INT, V0, P0
   Peng T., 2013, IEEE ACIS INT C COMP, V0, P0
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI 10.1162/NECO_a_00990
   Sadawi N. M., 2012, P SOC PHOTO-OPT INS, V8297, P32
   Simonyan K., 2014, INF SOFTW TECHNOL, V0, P0
   Sun P., 2018, IAPR INT WORKSH DOC, V0, P0
   Willighagen EL, 2013, J CHEMINFORMATICS, V5, P0, DOI 10.1186/1758-2946-5-23
   Xin W., 2009, INT C DOC AN REC, V0, P0
   Yang J., 2008, 2008 19 INT C PATT R, V0, P0
   Yang Z., 2010, INT C PATT REC, V0, P0
   Yang Z., 2009, INT C DOC AN REC, V0, P0
NR 18
TC 6
Z9 6
U1 1
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1520-5363
EI 
J9 PROC INT CONF DOC
PD JUN 15
PY 2019
VL 0
IS 
BP 165
EP 168
DI 10.1109/ICDARW.2019.40099
PG 4
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA BO5ST
UT WOS:000518786800028
DA 2023-04-26
ER
