PT J
AU Sakellariou, S
   Sfougaris, A
   Christopoulou, O
AF Sakellariou, Stavros
   Sfougaris, Athanassios
   Christopoulou, Olga
TI Review of Geoinformatics-Based Forest Fire Management Tools for Integrated Fire Analysis
SO POLISH JOURNAL OF ENVIRONMENTAL STUDIES
LA English
DT Review
DE wildfires; fire prevention; fire risk/probability; fire effects; visibility analysis; network analysis; land use change; geographical information systems (GIS); remote sensing
ID initial attack resources; burn probability; neural-network; wildfire; risk; model; location; gis; suppression; simulation
AB Wildfires of high severity can have profound implications on natural and human environment affecting the quality of life; the health of living beings; and the prosperity of any society. Consequently, specific strategies, tactics and techniques should always be adopted for the alleviation of this critical phenomenon. Hence, the aim of the paper is the review of the most common geoinformatics-based techniques contributing to an integrated fire analysis through four pillars. The first one is related with the fire exposure on the ground, primarily analyzing the fire susceptibility in terms of fire risk and burn probability maps; The second one examines the fire effects on the most critical ecological and anthropogenic resources and infrastructures. The third pillar combines two effective geospatial tools supporting the wildfire prevention and suppression, such as the visibility analysis for early detection of fire hotspots and the network analysis for strategic and operational planning of fire events. Last, the Earth-Observation module, through the spatiotemporal monitoring and prediction of land use changes, permits the planners to evaluate the underlying pressures (fires, urbanization) against forests developing the appropriate planning guidelines. In the meantime, new perspectives emerge. Novel machine learning algorithms and remote sensing data techniques are expected to improve the fire risk/probability credibility enhancing the more precise identification of fire effects to any resource. The integration of specific geographic criteria (e.g. topography, accessibility) and programming techniques (e.g. maximizing the visible area) to visibility analysis would empower the immediate fire detection. New technologies such as the adoption of drones would be a cost-effective tool for quick retrieval of vital geo-data. Network analysis could propose financially and environmentally efficient location schemes of fire agencies and resources.
C1 [Sakellariou, Stavros; Sfougaris, Athanassios] Univ Thessaly, Dept Agr Crop Prod & Rural Environm, Volos 38446, Greece.
   [Sakellariou, Stavros; Christopoulou, Olga] Univ Thessaly, Dept Planning & Reg Dev, Volos 38334, Greece.
C3 University of Thessaly; University of Thessaly
RP Sakellariou, S (corresponding author), Univ Thessaly, Dept Agr Crop Prod & Rural Environm, Volos 38446, Greece.; Sakellariou, S (corresponding author), Univ Thessaly, Dept Planning & Reg Dev, Volos 38334, Greece.
EM stasakel@gmail.com
FU Stavros Niarchos Foundation
CR Abbate A, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9100417
   Adetona O., 2016, INHAL TOXICOL, V0, P0
   Akinola OV, 2019, INT J SUST DEV WORLD, V26, P251, DOI 10.1080/13504509.2018.1551815
   Amalina P, 2016, PROCEDIA ENVIRON SCI, V33, P239, DOI 10.1016/j.proenv.2016.03.075
   [Anonymous], 2012, SOCIO-ECON PLAN SCI, V0, P0, DOI DOI 10.1016/J.SEPS.2012.02.003
   Arca B., 2007, P 7 S FIR FOR MET, V0, P0
   Arrubla JAG, 2014, INT J WILDLAND FIRE, V23, P825, DOI 10.1071/WF13204
   Atun R., 2020, TURKISH J GEOSCIENCE, V1, P0
   Badia A, 2019, SCI TOTAL ENVIRON, V673, P184, DOI 10.1016/j.scitotenv.2019.04.012
   Banu Tiberiu Paul, 2016, J ENV SCI ENG B, V5, P0
   Bao ST, 2015, FIRE SAFETY J, V71, P100, DOI 10.1016/j.firesaf.2014.11.016
   Bar Massada A, 2009, FOREST ECOL MANAG, V258, P1990, DOI 10.1016/j.foreco.2009.07.051
   Barros AMG, 2019, FOREST ECOL MANAG, V433, P514, DOI 10.1016/j.foreco.2018.10.041
   Berberoglu S, 2009, INT J APPL EARTH OBS, V11, P46, DOI 10.1016/j.jag.2008.06.002
   Bernier PY, 2016, FORESTS, V7, P0, DOI 10.3390/f7080157
   Braun W. J., 2010, J PROBAB STAT, V0, P0
   Bufacchi P, 2016, FIRE SAFETY J, V79, P44, DOI 10.1016/j.firesaf.2015.11.014
   Carmel Y, 2009, FOREST ECOL MANAG, V257, P370, DOI 10.1016/j.foreco.2008.09.039
   Carvalho F, 2019, SCI TOTAL ENVIRON, V692, P691, DOI 10.1016/j.scitotenv.2019.07.265
   Chung W, 2015, CURR FOR REP, V1, P44, DOI 10.1007/s40725-015-0005-9
   Cru H., 2016, SENSORS SWITZERLAND, V16, P0
   Cunillera-Montcusi D, 2019, FRESHWATER BIOL, V64, P323, DOI 10.1111/fwb.13219
   de Bem PP, 2019, INT J WILDLAND FIRE, V28, P35, DOI 10.1071/WF18018
   Deng JS, 2009, LANDSCAPE URBAN PLAN, V92, P187, DOI 10.1016/j.landurbplan.2009.05.001
   Dijkstra E. W., 1959, NUMER MATH, V0, P0
   Eugenio FC, 2016, SCI TOTAL ENVIRON, V562, P542, DOI 10.1016/j.scitotenv.2016.03.231
   Eugenio FC, 2016, J ENVIRON MANAGE, V173, P65, DOI 10.1016/j.jenvman.2016.02.021
   Fairbrother A, 2005, FOREST ECOL MANAG, V211, P28, DOI 10.1016/j.foreco.2005.01.026
   Finney MA, 2005, FOREST ECOL MANAG, V211, P97, DOI 10.1016/j.foreco.2005.02.010
   Gabban A, 2006, INT J REMOTE SENS, V27, P1725, DOI 10.1080/01431160500183107
   Gheshlaghi HA, 2020, J ENVIRON PLANN MAN, V63, P481, DOI 10.1080/09640568.2019.1594726
   Haider W, 2019, CAN J FOREST RES, V49, P1242, DOI 10.1139/cjfr-2018-0309
   Halmy MWA, 2015, APPL GEOGR, V63, P101, DOI 10.1016/j.apgeog.2015.06.015
   Hegazy Ibrahim Rizk, 2015, INTERNATIONAL JOURNAL OF SUSTAINABLE BUILT ENVIRONMENT, V4, P117, DOI 10.1016/j.ijsbe.2015.02.005
   Hua LZ, 2017, J FORESTRY RES, V28, P215, DOI 10.1007/s11676-016-0361-8
   Indriasari V, 2010, INT J GEOGR INF SCI, V24, P213, DOI 10.1080/13658810802549162
   Jaffe D.A., 2012, ATMOS ENVIRON, V0, P0
   Kai N., 2014, TELKOMNIKA INDONESIA, V12, P0
   Kalabokidis K, 2013, ECOL INFORM, V16, P62, DOI 10.1016/j.ecoinf.2013.04.007
   Karimi A., 2019, J GEOGRAPHY CARTOGRA, V2, P0
   Kim YH, 2004, COMPUT GEOSCI-UK, V30, P1019, DOI 10.1016/j.cageo.2004.07.008
   Kucuk O, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-6008-1
   Laszlo B., 2018, PROCEDIA ENG, V211, P8, DOI 10.1016j.proeng.2017.12.132
   Lee Y, 2013, CAN J FOREST RES, V43, P56, DOI 10.1139/cjfr-2011-0433
   Li W., 2020, REMOTE SENS ENVIRON, V237, P0
   Loomis J., 2019, GENERAL TECHNICAL REPORT - PACIFIC SOUTHWEST RESEARCH STATION, V0, P70
   Magalhaes Salles V. G., 2010, 2010 10TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS 2010), V0, PP135, DOI 10.1109/HIS.2010.5600013
   Moreira F, 2011, J ENVIRON MANAGE, V92, P2389, DOI 10.1016/j.jenvman.2011.06.028
   Murray AT, 2013, FIRE SAFETY J, V62, P64, DOI 10.1016/j.firesaf.2013.03.002
   Ntaimo L, 2012, CAN J FOREST RES, V42, P987, DOI 10.1139/X2012-032
   Paneque-Galvez J, 2014, FORESTS, V5, P1481, DOI 10.3390/f5061481
   Parisien MA, 2016, NATURE, V534, P297, DOI 10.1038/534297a
   Parisien MA, 2013, NAT HAZARDS, V66, P439, DOI 10.1007/s11069-012-0495-8
   Parks SA, 2012, ECOSPHERE, V3, P0, DOI 10.1890/ES11-00298.1
   Pausas JC, 2008, INT J WILDLAND FIRE, V17, P713, DOI 10.1071/WF07151
   Pechony O, 2010, P NATL ACAD SCI USA, V107, P19167, DOI 10.1073/pnas.1003669107
   Pimont F, 2016, ENVIRON MODELL SOFTW, V80, P225, DOI 10.1016/j.envsoft.2016.03.003
   Pompa-Garcia M., 2012, JOURNAL OF ENVIRONMENTAL PROTECTION, V3, P1034
   Bui QT, 2019, GEOMAT NAT HAZ RISK, V10, P136, DOI 10.1080/19475705.2018.1509902
   Richardson LA, 2012, J FOREST ECON, V18, P14, DOI 10.1016/j.jfe.2011.05.002
   Running SW, 2006, SCIENCE, V313, P927, DOI 10.1126/science.1130370
   Ryan K.C., 2012, ROCKY MOUNTAIN RES S, V0, P0
   Sakellariou S., 2020, SENSORS SWITZERLAND, V20, P1
   Sakellariou S., 2020, LOCATION PLANNING FI, V16, P643
   Sakellariou S, 2020, SCI TOTAL ENVIRON, V729, P0, DOI 10.1016/j.scitotenv.2020.139004
   Sakellariou S, 2020, ENVIRON HAZARDS-UK, V19, P131, DOI 10.1080/17477891.2019.1628696
   Sakellariou S, 2017, INT J AGRIC ENVIRON, V8, P1, DOI 10.4018/ijaeis.2017100101
   Sakellariou S, 2017, J FORESTRY RES, V28, P1107, DOI 10.1007/s11676-017-0452-1
   Salis M, 2016, FOREST ECOL MANAG, V368, P207, DOI 10.1016/j.foreco.2016.03.009
   Sant C., 2016, FIRE EFFECTS SOILS H, V0, P0
   Scott JH, 2012, FIRE ECOL, V8, P125, DOI 10.4996/fireecology.0802125
   Sharma LK, 2012, DISASTER PREV MANAG, V21, P160, DOI 10.1108/09653561211219964
   Shi X, 2016, INT J DIGIT EARTH, V9, P1153, DOI 10.1080/17538947.2016.1207718
   Sivrikaya F, 2014, POL J ENVIRON STUD, V23, P187
   Skorput P, 2016, ELMAR PROC, V0, PP93, DOI 10.1109/ELMAR.2016.7731762
   Srivastava PK, 2012, ADV SPACE RES, V50, P1250, DOI 10.1016/j.asr.2012.06.032
   Stockdale C, 2019, J ENVIRON MANAGE, V233, P238, DOI 10.1016/j.jenvman.2018.12.035
   Thompson M. P., 2011, J ENVIRON MANAGE, V0, P0
   Thompson MP, 2013, INTEGR ENVIRON ASSES, V9, P329, DOI 10.1002/ieam.1365
   Thompson MP, 2011, ENVIRON MONIT ASSESS, V179, P217, DOI 10.1007/s10661-010-1731-x
   Tubbesing CL, 2019, FOREST ECOL MANAG, V436, P45, DOI 10.1016/j.foreco.2019.01.010
   Vadrevu KP, 2010, ENVIRON MONIT ASSESS, V166, P223, DOI 10.1007/s10661-009-0997-3
   Varol T., 2015, POL J ENVIRON STUD, V0, P0
   Veeraswamy A, 2018, SAFETY SCI, V102, P178, DOI 10.1016/j.ssci.2017.07.015
   Wang S.W., 2020, SUSTAINABILITY SWITZ, V12, P0
   Wang YW, 2020, INT J GEOGR INF SCI, V34, P448, DOI 10.1080/13658816.2019.1664743
   Wei Y, 2015, FOREST SCI, V61, P278, DOI 10.5849/forsci.14-112
   Westerling AL, 2006, SCIENCE, V313, P940, DOI 10.1126/science.1128834
   Wezyk P, 2016, QUAEST GEOGR, V35, P93, DOI 10.1515/quageo-2016-0009
   Woo H, 2017, INT J WILDLAND FIRE, V26, P789, DOI 10.1071/WF17021
   Yu TX, 2016, INT J GEOGR INF SCI, V30, P2171, DOI 10.1080/13658816.2016.1163571
   Zhang FQ, 2019, SCI TOTAL ENVIRON, V654, P164, DOI 10.1016/j.scitotenv.2018.11.038
   Zhang GL, 2019, INT J DISAST RISK SC, V10, P386, DOI 10.1007/s13753-019-00233-1
   Zheng Z, 2017, ECOL MODEL, V348, P33, DOI 10.1016/j.ecolmodel.2016.12.022
NR 94
TC 1
Z9 1
U1 10
U2 24
PU HARD
PI OLSZTYN 5
PA POST-OFFICE BOX, 10-718 OLSZTYN 5, POLAND
SN 1230-1485
EI 2083-5906
J9 POL J ENVIRON STUD
JI Pol. J. Environ. Stud.
PD JUN 15
PY 2021
VL 30
IS 6
BP 5423
EP 5434
DI 10.15244/pjoes/135614
PG 12
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA ZH0CW
UT WOS:000760618000002
DA 2023-04-26
ER

PT J
AU Ahadit, AB
   Jatoth, RK
AF Ahadit, Alagesan Bhuvaneswari
   Jatoth, Ravi Kumar
TI A Novel Dual CNN Architecture with LogicMax for Facial Expression Recognition
SO JOURNAL OF INFORMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE convolutional neural networks; transfer learning; facial action coding system; action units; Pearson correlation; data augmentation; dlib facial landmark predictor; vgg16; logicMax
AB Facial expressions convey important features for recognizing human emotions. It is a challenging task to classify accurate facial expressions due to high intra-class correlation. Conventional methods depend on the classification of handcrafted features like scale-invariant feature transform and local binary patterns to predict the emotion. In recent years, deep learning techniques are used to boost the accuracy of FER models. Although it has improved the accuracy in standard datasets, FER models have to consider problems like face occlusion and intra-class variance. In this paper, we have used two convolutional neural networks which have vgg16 architecture as a base network using transfer learning. This paper explains the method to tackle issues on classifying high intra-class correlated facial expressions through an in-depth investigation of the Facial Action Coding System (FACS) action units. We have used a novel LogicMax layer at the end of the model to boost the accuracy of the FER model. Classification metrics like Accuracy, Precision, Recall, and Fl score are calculated for evaluating the model performance on CK+ and JAFFE datasets. The model is tested using 10-fold cross-validation and the obtained classification accuracy rate of 98.62% and 94.86% on CK+ and JAFFE datasets respectively. The experimental results also include a feature map visualization of 64 convolutional filters of the two convolutional neural networks.
C1 [Ahadit, Alagesan Bhuvaneswari; Jatoth, Ravi Kumar] Natl Inst Technol, Dept Elect & Commun, Warangal 506004, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Warangal
RP Ahadit, AB (corresponding author), Natl Inst Technol, Dept Elect & Commun, Warangal 506004, Telangana, India.
EM ahadit.ab.ml@gmail.com; ravikumar@nitw.ac.in
CR Alisa, 2018, P S EL MECH APPL SCI, V0, P73
   Alphonse AS, 2018, MULTIMED TOOLS APPL, V77, P9455, DOI 10.1007/s11042-017-5141-8
   Bradski G., 2008, LEARNING OPENCV COMP, V0, P0
   Cai J, 2018, IEEE INT CONF AUTOMA, V0, PP302, DOI 10.1109/FG.2018.00051
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   CORRADO G, 2011, J MACHINE LEARNING R, V12, P2825
   Darwin C., 1872, P374, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman R., 1997, WHAT FACE REVEALS BA, V0, P0
   Huang J, 2017, IEEE INT C INT ROBOT, V0, P3296
   Iwasaki M, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep22049
   Jung H, 2015, IEEE I CONF COMP VIS, V0, PP2983, DOI 10.1109/ICCV.2015.341
   Kahou SE, 2013, ICMI13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, V0, PP543, DOI 10.1145/2522848.2531745
   KAZEMI V, 2014, PROC CVPR IEEE, V0, PP1867, DOI 10.1109/CVPR.2014.241
   Kim BK, 2016, IEEE COMPUT SOC CONF, V0, PP1499, DOI 10.1109/CVPRW.2016.187
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lucey P., 2010, PROC IEEE C COMPUT V, V0, PP94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M.J., 1998, PROC IEEE INT C AUTO, V0, PP14, DOI 10.5281/ZENODO.3451524
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Petrantonakis PC, 2010, IEEE T INF TECHNOL B, V14, P186, DOI 10.1109/TITB.2009.2034649
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simonyan K, 2015, ARXIV, V0, P0
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.8
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   XIE S, 2017, ELECTRON LETT, V53, P235, DOI 10.1049/el.2016.4328
   Yadan Lv, 2014, 2014 INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), V0, PP303, DOI 10.1109/SMARTCOMP.2014.7043872
   Yang HY, 2018, PROC CVPR IEEE, V0, PP2168, DOI 10.1109/CVPR.2018.00231
   Zhang FF, 2018, PROC CVPR IEEE, V0, PP3359, DOI 10.1109/CVPR.2018.00354
   Zhang ZL, 2018, ADV NEUR IN, V31, P0
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhi RC, 2011, IEEE T SYST MAN CY B, V41, P38, DOI 10.1109/TSMCB.2010.2044788
NR 35
TC 0
Z9 0
U1 2
U2 12
PU INST INFORMATION SCIENCE
PI TAIPEI
PA ACADEMIA SINICA, TAIPEI 115, TAIWAN
SN 1016-2364
EI 
J9 J INF SCI ENG
JI J. Inf. Sci. Eng.
PD JAN 15
PY 2021
VL 37
IS 1
BP 15
EP 39
DI 10.6688/JISE.202101_37(1).0002
PG 25
WC Computer Science, Information Systems
SC Computer Science
GA PS6PS
UT WOS:000608049100002
DA 2023-04-26
ER

PT J
AU Chen, F
   Zhou, R
   Van de Voorde, T
   Chen, XZ
   Bourgeois, J
   Gheyle, W
   Goossens, R
   Yang, J
   Xu, WB
AF Chen, Fen
   Zhou, Rui
   Van de Voorde, Tim
   Chen, Xingzhuang
   Bourgeois, Jean
   Gheyle, Wouter
   Goossens, Rudi
   Yang, Jian
   Xu, Wenbo
TI Automatic detection of burial mounds (kurgans) in the Altai Mountains
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Kurgans; Stone mounds; Altai Mountains; Remote sensing archaeology; Object detection
ID archaeological features; imagery; identification; classification; extraction; ikonos-2; valley; marks; tombs
AB The Altai Mountains are one of the most impressive and valuable archaeological areas in the world. Kurgans (burial mounds) of ancient civilizations, which are scattered across the vast Altai area, are an exceptionally valuable source of information for archaeology. These precious archaeological resources, which sometimes have been preserved intact in the permafrost underground for over two millennia, are now under various threats, such as natural disasters, farmland expansion, touristic development, and most notably global warming. A detailed map or inventory of the mounds is essential but is still not available. In this study, we test the deep convolutional neural network (CNN) technique for automatic detection of stone mounds from high-resolution satellite images in four regions in the Altai Mountains. We propose three improvement techniques to increase the performance of off-the-shelf object detection methods that are originally proposed for daily-life objects. Our results demonstrate that it is feasible to apply CNN to detect stone mounds, and the detection results are good enough to capture their spatial distribution. CNN-based object detection can largely narrow down the search area for archaeologists in yet un-surveyed regions, and is therefore useful for preparing field survey campaigns and directing archaeological fieldwork. We also applied the method to an un-surveyed Altai Mountain area and successfully discovered stone mounds that are yet undocumented. Our method can potentially be applied to construct an inventory for all stone mounds present in the whole Altai Mountain region.
C1 [Chen, Fen; Zhou, Rui; Chen, Xingzhuang; Xu, Wenbo] Univ Elect Sci & Technol China, Sch Resources & Environm, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
   [Van de Voorde, Tim; Goossens, Rudi] Univ Ghent, Dept Geog, Krijgslaan 281,S8, B-9000 Ghent, Belgium.
   [Bourgeois, Jean; Gheyle, Wouter] Univ Ghent, Dept Archaeol, Sint Pieternieuwstr 35, B-9000 Ghent, Belgium.
   [Bourgeois, Jean] Fellow Presidents Int Fellowship Initiat, Beijing, Peoples R China.
   [Yang, Jian] Chinese Acad Sci, Aerosp Informat Res Inst, 9 Dengzhuang South Rd, Beijing 100094, Peoples R China.
C3 University of Electronic Science & Technology of China; Ghent University; Ghent University; Chinese Academy of Sciences
RP Chen, F (corresponding author), Univ Elect Sci & Technol China, Sch Resources & Environm, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
EM chenfen@uestc.edu.cn
FU National Key Research and Development Program of China [2017YFC0821900]; Chinese Academy of Sciences President's International Fellowship Initiative [2020VCA0015]
CR Baumer C., 2012, HIST CENTRAL ASIA AG, V0, P0
   Belongie S., 2016, ARXIV PREPRINT ARXIV, V0, P0
   Bourgeois J, 2014, ARCHAEOL ETHNOL ANTH, V42, P106, DOI 10.1016/j.aeae.2015.06.011
   Bourgeois J., 2009, REPORT BELGIAN RUSSI, V1, P0
   Bourgeois J., 2007, UNESCO WORKSH COMP C, V0, P0
   Bourgeois J, 2007, WORLD ARCHAEOL, V39, P458, DOI 10.1080/00438240701504585
   Bourgeois J, 2017, ARCHAEOL RES ASIA, V10, P17, DOI 10.1016/j.ara.2017.02.003
   Byeon W, 2019, J COMPUT SCI-NETH, V32, P36, DOI 10.1016/j.jocs.2019.02.005
   Cai ZW, 2018, PROC CVPR IEEE, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Caspari G, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050773
   Caspari G, 2019, J ARCHAEOL SCI, V110, P0, DOI 10.1016/j.jas.2019.104998
   Chen F, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030443
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Z, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010139
   Chetouani A, 2018, IEEE IMAGE PROC, V0, PP1038, DOI 10.1109/ICIP.2018.8451728
   Cugunov K.V., 2006, GOLDSCHATZ ARZAN FUR, V0, P0
   Cunliffe BW., 2015, STEPPE DESERT OCEAN, V0, P0
   De Laet V, 2007, J ARCHAEOL SCI, V34, P830, DOI 10.1016/j.jas.2006.09.013
   De Laet V, 2009, INT J REMOTE SENS, V30, P5655, DOI 10.1080/01431160802705821
   Figorito B, 2014, INT J APPL EARTH OBS, V26, P458, DOI 10.1016/j.jag.2013.04.005
   Gheyle W., 2009, HIGHLANDS STEPPES AN, V0, P0
   Gheyle W., 2016, TOPOI BERLIN STUDIES, V0, P0
   Gheyle W., 2007, DIGITAL DISCOVERY EX, V0, P67
   Goossens R, 2006, J ARCHAEOL SCI, V33, P745, DOI 10.1016/j.jas.2005.10.010
   Han Junhi, 2008, PRESERVATION FROZEN, V0, P0
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Kong T., 2019, ARXIV PREPRINT ARXIV, V0, P0
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kubarev V.D., 1991, KURGANY ULANDRYKA HA, V0, P0
   Laben C. A., 2000, US PATENT, V0, Patent No. 6011875
   Lasaponara R, 2007, J ARCHAEOL SCI, V34, P214, DOI 10.1016/j.jas.2006.04.014
   Li HX, 2015, PROC CVPR IEEE, V0, PP5325, DOI 10.1109/CVPR.2015.7299170
   Li Q., 2018, SCI CHINA INFORM SCI, V61, P1, DOI 10.1007/S11432-017-9235-7
   Lin T., 2017, P IEEE INT C COMP VI, V0, P0
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Molodin V.I., 2004, ARCHEOLOGICHESKIE PA, V0, P0
   Nawroth M., 2007, VERNISSAGE Z AUSSTEL, V15, P0
   Orengo HA, 2020, P NATL ACAD SCI USA, V117, P18240, DOI 10.1073/pnas.2005583117
   Pang JM, 2019, PROC CVPR IEEE, V0, PP821, DOI 10.1109/CVPR.2019.00091
   Parzinger H., 2006, FRUHEN SPACING DIAER, V0, P0
   Plets G, 2011, MT RES DEV, V31, P372, DOI 10.1659/MRD-JOURNAL-D-11-00065.1
   Polosmak N.V., 1994, SCYTHIA SIBERIA, V1, P346
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rudenko S. I., 1970, FROZEN TOMBS SIBERIA, V0, P0
   Schuetter J, 2013, INT J REMOTE SENS, V34, P6611, DOI 10.1080/01431161.2013.802054
   Silverman B. W., 1986, DENSITY ESTIMATION S, V0, P0
   Simpson St J., 2017, SCYTHIANS WARRIORS A, V0, P0
   Singh B, 2018, PROC CVPR IEEE, V0, PP3578, DOI 10.1109/CVPR.2018.00377
   Tian Z, 2019, IEEE I CONF COMP VIS, V0, PP9626, DOI 10.1109/ICCV.2019.00972
   Wang HY, 2017, J CULT HERIT, V27, P60, DOI 10.1016/j.culher.2017.03.006
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P1745, DOI 10.1109/LGRS.2018.2856921
   Zhou Y, 2016, LECT NOTES COMPUT SC, V9906, P278, DOI 10.1007/978-3-319-46475-6_18
   Zingman I, 2016, IEEE T GEOSCI REMOTE, V54, P4580, DOI 10.1109/TGRS.2016.2545919
NR 60
TC 7
Z9 7
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG 15
PY 2021
VL 177
IS 
BP 217
EP 237
DI 10.1016/j.isprsjprs.2021.05.010
EA MAY 2021
PG 21
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SR3ZD
UT WOS:000660980400015
DA 2023-04-26
ER

PT J
AU Liu, C
   Hu, YH
   Li, Z
   Xu, JK
   Han, ZG
   Guo, JZ
AF Liu, Chun
   Hu, Yaohui
   Li, Zheng
   Xu, Junkui
   Han, Zhigang
   Guo, Jianzhong
TI TriangleConv: A Deep Point Convolutional Network for Recognizing Building Shapes in Map Space
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE map space; shape recognition; shape classification; point convolution; TriangleConv
ID classification
AB The classification and recognition of the shapes of buildings in map space play an important role in spatial cognition, cartographic generalization, and map updating. As buildings in map space are often represented as the vector data, research was conducted to learn the feature representations of the buildings and recognize their shapes based on graph neural networks. Due to the principles of graph neural networks, it is necessary to construct a graph to represent the adjacency relationships between the points (i.e., the vertices of the polygons shaping the buildings), and extract a list of geometric features for each point. This paper proposes a deep point convolutional network to recognize building shapes, which executes the convolution directly on the points of the buildings without constructing the graphs and extracting the geometric features of the points. A new convolution operator named TriangleConv was designed to learn the feature representations of each point by aggregating the features of the point and the local triangle constructed by the point and its two adjacency points. The proposed method was evaluated and compared with related methods based on a dataset consisting of 5010 vector buildings. In terms of accuracy, macro-precision, macro-recall, and macro-F1, the results show that the proposed method has comparable performance with typical graph neural networks of GCN, GAT, and GraphSAGE, and point cloud neural networks of PointNet, PointNet++, and DGCNN in the task of recognizing and classifying building shapes in map space.
C1 [Liu, Chun; Hu, Yaohui; Li, Zheng] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475000, Peoples R China.
   [Liu, Chun; Xu, Junkui; Han, Zhigang; Guo, Jianzhong] Henan Univ, Henan Ind Technol Acad Spatiotemporal Big Data, Zhengzhou 450046, Peoples R China.
   [Xu, Junkui; Han, Zhigang; Guo, Jianzhong] Henan Univ, Coll Geog & Environm Sci, Kaifeng 475000, Peoples R China.
C3 Henan University; Henan University; Henan University
RP Xu, JK (corresponding author), Henan Univ, Henan Ind Technol Acad Spatiotemporal Big Data, Zhengzhou 450046, Peoples R China.; Xu, JK (corresponding author), Henan Univ, Coll Geog & Environm Sci, Kaifeng 475000, Peoples R China.
EM liuchun@henu.edu.cn; 104753190624@henu.edu.cn; lizheng@henu.edu.cn; 10130153@vip.henu.edu.cn; zghan@henu.edu.cn; jianzhong420@sohu.com
FU National Natural Science Foundation of China [41871316]
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Basaraner M, 2017, INT J GEOGR INF SCI, V31, P1952, DOI 10.1080/13658816.2017.1346257
   Bruna J., 2014, P INT C LEARN REPR, V0, P0
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   DGL Development Team, 2018, DEEP GRAPH LIB, V0, P0
   Douglas D. H., 1973, CARTOGRAPHICA INT J, V10, P112, DOI 10.3138/FM57-6770-U75U-7727
   Du SH, 2015, ISPRS J PHOTOGRAMM, V105, P107, DOI 10.1016/j.isprsjprs.2015.03.011
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim Y, 2016, AAAI CONF ARTIF INTE, V0, P2741
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P0, DOI 10.5555/303568.303704
   Li XL, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13152910
   Mark DM, 1999, INT J GEOGR INF SCI, V13, P747, DOI 10.1080/136588199241003
   Matikainen L, 2010, REMOTE SENS-BASEL, V2, P1217, DOI 10.3390/rs2051217
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Rainsford D, 2002, ADVANCES IN SPATIAL DATA HANDLING, V0, P137
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SHEA KS, 1989, AUTO CARTO 9 : NINTH INTERNATIONAL SYMPOSIUM ON COMPUTER-ASSISTED CARTOGRAPHY, V0, P56
   Simonyan K, 2015, ARXIV, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Touya G, 2019, INT J CARTOGRAPHY, V5, P142, DOI 10.1080/23729333.2019.1613071
   [王辉连 Wang Huilian], 2005, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V34, P269
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   [徐冰冰 Xu Bingbing], 2020, 计算机学报 CHINESE JOURNAL OF COMPUTERS, V43, P755
   Yan XF, 2021, INT J GEOGR INF SCI, V35, P490, DOI 10.1080/13658816.2020.1768260
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Yan XF, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6080250
   Yang CZ, 2018, NEUROCOMPUTING, V275, P1160, DOI 10.1016/j.neucom.2017.09.067
   Zhang CZ, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13122285
   Zhou XD, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7100406
NR 36
TC 4
Z9 4
U1 3
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD OCT 15
PY 2021
VL 10
IS 10
BP 
EP 
DI 10.3390/ijgi10100687
PG 14
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA WR5TD
UT WOS:000714560700001
DA 2023-04-26
ER

PT J
AU Gao, X
   Chen, T
   Niu, RQ
   Plaza, A
AF Gao, Xiao
   Chen, Tao
   Niu, Ruiqing
   Plaza, Antonio
TI Recognition and Mapping of Landslide Using a Fully Convolutional DenseNet and Influencing Factors
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Terrain factors; Remote sensing; Geology; Feature extraction; Image segmentation; Semantics; Earthquakes; Fully convolutional DenseNet (FC-DenseNet); influencing factors; landslide recognition and mapping; remote sensing
ID 3 gorges reservoir; jiuzhaigou earthquake; neural-networks; susceptibility; inventory; basin; maps
AB The recognition and mapping of landslide (RML) is an important task in hazard and risk research and can provide a scientific basis for the prevention and control of landslide disasters. However, traditional RML methods are inefficient, costly, and not intuitive. With the rapid development of computer vision, methods based on convolutional neural networks have attracted great attention due to their numerous advantages. However, problems such as insufficient feature extraction, excessive parameters, and slow model testing have restricted the development of this technology. This research proposes a new RML framework based on a new semantic segmentation network termed the fully convolutional DenseNet (FC-DenseNet). In this network, the features extracted from each layer are repeatedly used in a dense connection, and the parameters are controlled by a bottle-neck structure. Meanwhile, the structure of the encoder-decoder solves the problem of the slowness of model testing. Finally, the landslide influencing factors are added, which enriches the training data. To verify the effectiveness of the proposed method, we focused on several deep networks for comparison and analysis. The results show that FC-DenseNet can better recognize the boundary and interior of landslides, and there are fewer missing and excessive recognition results. The kappa value of the new method is 94.72% in Site 1, which is 6% and 4% higher than that of U-Net and ResU-Net, respectively, and 94.56% in Site 2, which is 6% and 3% higher than that of U-Net and ResU-Net, respectively, indicating that FC-DenseNet has great potential in RML applications.
C1 [Gao, Xiao; Chen, Tao; Niu, Ruiqing] China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
   [Chen, Tao] Beijing Key Lab Urban Spatial Informat Engn, Beijing 100038, Peoples R China.
   [Plaza, Antonio] Univ Extremadura, Escuela Politecn, Dept Technol Comp & Commun, Hyperspectral Comp Lab, Caceres 10071, Spain.
C3 China University of Geosciences; Universidad de Extremadura
RP Chen, T (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
EM gaoxiao@cug.edu.cn; taochen@cug.edu.cn; niuruiqing@cug.edu.cn; aplaza@unex.es
FU National Natural Science Foundation of China [62071439, 61871259]; Opening Foundation of Qilian Mountain National Park Research Center (Qinghai) [GKQ2019-01]; Opening Foundation of Beijing Key Laboratory of Urban Spatial Information Engineering [20210209]; Opening Foundation of Geomatics Technology and Application Key Laboratory of Qinghai Province [QHDX-2019-01]
CR Ahmed MF, 2016, B ENG GEOL ENVIRON, V75, P563, DOI 10.1007/s10064-015-0773-2
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bengio Y., 1996, HDB BRAIN THEORY NEU, V0, P0
   Cai HJ, 2021, IEEE J-STARS, V14, P5235, DOI 10.1109/JSTARS.2021.3079196
   Chang M, 2021, ENVIRON SCI POLLUT R, V28, P20549, DOI 10.1007/s11356-020-11826-5
   Chen S, 2020, IEEE J-STARS, V13, P1649, DOI 10.1109/JSTARS.2020.2985088
   Chen T, 2020, J MT SCI-ENGL, V17, P670, DOI 10.1007/s11629-019-5839-3
   Chen T, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040333
   Chen T, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5317-y
   Chen T, 2015, ENVIRON EARTH SCI, V73, P5571, DOI 10.1007/s12665-014-3811-7
   Chen Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172767
   Cubuk ED, 2019, PROC CVPR IEEE, V0, PP113, DOI 10.1109/CVPR.2019.00020
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), V0, PP444, DOI 10.1109/YAC.2016.7804935
   Galli M, 2008, GEOMORPHOLOGY, V94, P268, DOI 10.1016/j.geomorph.2006.09.023
   Ge J., 2019, 2019 IEEE 13 INT C A, V0, PP1, DOI 10.1109/ASICON47005.2019.8983577
   Ghorbanzadeh O, 2021, IEEE J-STARS, V14, P452, DOI 10.1109/JSTARS.2020.3043836
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Gribbon KT, 2004, INT SYM ELECT DES TE, V0, P126
   Guzzetti F, 2000, ENVIRON MANAGE, V25, P247, DOI 10.1007/s002679910020
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Hackl J, 2018, NAT HAZARD EARTH SYS, V18, P2273, DOI 10.5194/nhess-18-2273-2018
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   [黄汀 Huang Ting], 2018, 测绘通报 BULLETIN OF SURVEYING AND MAPPING, V0, P67
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsson G., 2016, ARXIV16050748, V0, P0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2015, LENET 5 CONVOLUTIONA, V20, P14
   Lee S, 2005, ENVIRON GEOL, V48, P778, DOI 10.1007/s00254-005-0019-x
   [李强 Li Qiang], 2019, 遥感学报 JOURNAL OF REMOTE SENSING, V23, P785
   Lissak C, 2020, SURV GEOPHYS, V41, P1391, DOI 10.1007/s10712-020-09609-1
   Liu LW, 2012, J EARTH SCI-CHINA, V23, P207, DOI 10.1007/s12583-012-0247-4
   Liu P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050894
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Luo X., 2017, J QUANZHOU NORMAL U, V35, P40
   Lv ZY, 2021, IEEE GEOSCI REMOTE S, V18, P1284, DOI 10.1109/LGRS.2020.2998684
   Marjanovic M, 2011, ACTA GEOTECH SLOV, V8, P45
   Martha TR, 2013, GEOMORPHOLOGY, V184, P139, DOI 10.1016/j.geomorph.2012.12.001
   Mohan A, 2021, T EMERG TELECOMMUN T, V32, P0, DOI 10.1002/ett.3998
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Oyedotun OK, 2018, IEEE COMPUT SOC CONF, V0, PP1739, DOI 10.1109/CVPRW.2018.00217
   Ozturk U, 2021, LANDSLIDES, V18, P681, DOI 10.1007/s10346-020-01485-5
   Ngo PTT, 2021, GEOSCI FRONT, V12, P505, DOI 10.1016/j.gsf.2020.06.013
   [乔建平 QIAO Jianping], 2006, 山地学报 JOURNAL OF MOUNTAIN SCIENCE, V24, P569
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Simonyan K, 2015, ARXIV, V0, P0
   Soares L. P., 2020, ARXIV200706672, V0, P0
   Su ZY, 2021, LANDSLIDES, V18, P1421, DOI 10.1007/s10346-020-01557-6
   Sun P, 2018, J HUBEI U NATURAL SC, V40, P29
   Sun XH, 2020, B ENG GEOL ENVIRON, V79, P4657, DOI 10.1007/s10064-020-01849-0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tang Wan, 2015, SHANGHAI ARCH PSYCHIATRY, V27, P62, DOI 10.11919/j.issn.1002-0829.215010
   Tian YY, 2019, J EARTH SCI-CHINA, V30, P206, DOI 10.1007/s12583-018-0869-2
   Ullo SL, 2021, IEEE J-STARS, V14, P3799, DOI 10.1109/JSTARS.2021.3064981
   Wang J, 2018, J MT SCI-ENGL, V15, P1412, DOI 10.1007/s11629-018-4823-7
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang SH, 2020, NEURAL COMPUT APPL, V32, P665, DOI 10.1007/s00521-018-3924-0
   Wang Y. Q, 2012, J CHANGCHUN I TECHNO, V13, P79
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Wu Caiyan, 2006, WUHAN UNIVERSITY JOURNAL OF NATURAL SCIENCES, V11, P773, DOI 10.1007/BF02830163
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), V0, PP327, DOI 10.1109/ITME.2018.00080
   Xu C, 2015, GEOSCI FRONT, V6, P825, DOI 10.1016/j.gsf.2014.03.004
   Ye CM, 2019, IEEE J-STARS, V12, P5047, DOI 10.1109/JSTARS.2019.2951725
   Yi YN, 2020, IEEE J-STARS, V13, P6166, DOI 10.1109/JSTARS.2020.3028855
   Yilmaz I, 2010, ENVIRON EARTH SCI, V61, P821, DOI 10.1007/s12665-009-0394-9
   [于欢 YU Huan], 2010, 中国图象图形学报 JOURNAL OF IMAGE AND GRAPHICS, V15, P352
   [余伟健 YU Weijian], 2008, 北京科技大学学报 JOURNAL OF UNIVERSITY SCIENCE AND TECHNOLOGY BEIJING, V30, P227
   Zhao CY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020279
   ZhiYong L, 2022, IEEE GEOSC REM SEN M, V10, P44, DOI 10.1109/MGRS.2021.3088865
NR 71
TC 22
Z9 22
U1 19
U2 71
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7881
EP 7894
DI 10.1109/JSTARS.2021.3101203
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UC8FJ
UT WOS:000686757500008
DA 2023-04-26
ER

PT J
AU Baudoux, L
   Inglada, J
   Mallet, C
AF Baudoux, Luc
   Inglada, Jordi
   Mallet, Clement
TI Toward a Yearly Country-Scale CORINE Land-Cover Map without Using Images: A Map Translation Approach
SO REMOTE SENSING
LA English
DT Article
DE land cover; mapping; translation; nomenclature; Convolutional Neural Network; geographical encoding; CORINE Land Cover; operational
ID harmonization; category; cropland
AB CORINE Land-Cover (CLC) and its by-products are considered as a reference baseline for land-cover mapping over Europe and subsequent applications. CLC is currently tediously produced each six years from both the visual interpretation and the automatic analysis of a large amount of remote sensing images. Observing that various European countries regularly produce in parallel their own land-cover country-scaled maps with their own specifications, we propose to directly infer CORINE Land-Cover from an existing map, therefore steadily decreasing the updating time-frame. No additional remote sensing image is required. In this paper, we focus more specifically on translating a country-scale remote sensed map, OSO (France), into CORINE Land Cover, in a supervised way. OSO and CLC not only differ in nomenclature but also in spatial resolution. We jointly harmonize both dimensions using a contextual and asymmetrical Convolution Neural Network with positional encoding. We show for various use cases that our method achieves a superior performance than the traditional semantic-based translation approach, achieving an 81% accuracy over all of France, close to the targeted 85% accuracy of CLC.
C1 [Baudoux, Luc; Mallet, Clement] Univ Gustave Eiffel, IGN, ENSG, LaSTIG, 73 Ave Paris, F-94160 St Mande, France.
   [Inglada, Jordi] Univ Toulouse, CNRS, CNES, Ctr Etud Spatiales Biosphere,IRD,INRAE,UPS, 18 Av Edouard Belin,Bpi 2801, F-31401 Toulouse, France.
C3 Universite Gustave-Eiffel; INRAE; Universite de Toulouse; Universite Toulouse III - Paul Sabatier; Centre National de la Recherche Scientifique (CNRS); Institut de Recherche pour le Developpement (IRD)
RP Baudoux, L (corresponding author), Univ Gustave Eiffel, IGN, ENSG, LaSTIG, 73 Ave Paris, F-94160 St Mande, France.
EM luc.baudoux@ign.fr; jordi.inglada@cesbio.eu; clement.mallet@ign.fr
FU AI4GEO project; French National Research agency as a part of the MAESTRIA project [ANR-18-CE23-0023]
CR Adamo M, 2014, LANDSCAPE ECOL, V29, P1045, DOI 10.1007/s10980-014-0028-9
   Ahlqvist O, 2005, INT J GEOGR INF SCI, V19, P831, DOI 10.1080/13658810500106729
   Al-Mubaid H, 2009, IEEE T SYST MAN CY C, V39, P389, DOI 10.1109/TSMCC.2009.2020689
   Anderson J.R., 1976, LAND USE LAND COVER, V964, P0
   Ardeshir S, 2014, LECT NOTES COMPUT SC, V8694, P602, DOI 10.1007/978-3-319-10599-4_39
   Arnold S., 2015, EAGLE CONCEPT PARADI, V0, PP107, DOI 10.1201/b18746-7
   Arsanjani JJ, 2016, INT J DIGIT EARTH, V9, P873, DOI 10.1080/17538947.2016.1151956
   Bechtel B, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111769
   Berg T, 2014, PROC CVPR IEEE, V0, PP2019, DOI 10.1109/CVPR.2014.259
   Buchhorn M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12061044
   Chen J, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6080230
   Chu G, 2019, IEEE INT CONF COMP V, V0, PP247, DOI 10.1109/ICCVW.2019.00033
   Comber A, 2004, INT J GEOGR INF SCI, V18, P691, DOI 10.1080/13658810410001705316
   Courtial A, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9050338
   Di Gregorio A., 2005, LAND COVER CLASSIFIC, V2-3, P0
   Feng C.-C., 2004, COMPUTERS, V0, P0
   Feng M, 2019, BIG EARTH DATA, V3, P191, DOI 10.1080/20964471.2019.1663627
   Fritz S, 2005, INT J GEOGR INF SCI, V19, P787, DOI 10.1080/13658810500072020
   Fritz S, 2015, GLOBAL CHANGE BIOL, V21, P1980, DOI 10.1111/gcb.12838
   Grekousis G, 2015, INT J REMOTE SENS, V36, P5309, DOI 10.1080/01431161.2015.1093195
   Herold M, 2008, REMOTE SENS ENVIRON, V112, P2538, DOI 10.1016/j.rse.2007.11.013
   Herold M, 2006, IEEE T GEOSCI REMOTE, V44, P1719, DOI 10.1109/TGRS.2006.871219
   HEYMANN Y, 1994, CORINE LAND COVER TE, V0, P0
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Homer C, 2020, ISPRS J PHOTOGRAMM, V162, P184, DOI 10.1016/j.isprsjprs.2020.02.019
   Hu JL, 2015, IEEE J-STARS, V8, P2031, DOI 10.1109/JSTARS.2015.2399509
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Inglada J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010095
   Isensee F., 2019, INFORM AKTUELL, V0, P0, DOI DOI 10.1007/978-3-658-25326-47
   Jansen LJM, 2008, J LAND USE SCI, V3, P131, DOI 10.1080/17474230802332076
   Jiang WM, 2017, FRONT MAR SCI, V4, P0, DOI 10.3389/fmars.2017.00151
   Kavouras M, 2005, COMPUT GEOSCI-UK, V31, P145, DOI 10.1016/j.cageo.2004.07.010
   Kavouras M, 2002, INT J GEOGR INF SCI, V16, P439, DOI 10.1080/13658810210129120
   Khened M, 2019, MED IMAGE ANAL, V51, P21, DOI 10.1016/j.media.2018.10.004
   Kilpelainen T., 2000, CARTOGR GEOGR INF SC, V27, P41, DOI 10.1559/152304000783547993
   Kohl M, 2000, ENVIRON MONIT ASSESS, V63, P361, DOI 10.1023/A:1006257630216
   Kosmidou V, 2014, ECOL INDIC, V36, P290, DOI 10.1016/j.ecolind.2013.07.025
   Li XD, 2019, IEEE T GEOSCI REMOTE, V57, P4951, DOI 10.1109/TGRS.2019.2894773
   Li Z, 2021, INT J GEOGR INF SCI, V35, P348, DOI 10.1080/13658816.2020.1796131
   Liao S, 2015, IEEE T MULTIMEDIA, V17, P1058, DOI 10.1109/TMM.2015.2436057
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lu M, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17071613
   Mac Aodha O, 2019, IEEE I CONF COMP VIS, V0, PP9595, DOI 10.1109/ICCV.2019.00969
   Malkin K., 2019, LABEL SUPER RESOLUTI, V0, P0
   Marcos D, 2018, ISPRS J PHOTOGRAMM, V145, P96, DOI 10.1016/j.isprsjprs.2018.01.021
   Milletari F, 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Moiret-Guigand A., 2021, CLC2018 CLCC1218 VAL, V0, P0
   Neumann K, 2007, INT J APPL EARTH OBS, V9, P425, DOI 10.1016/j.jag.2007.02.004
   Paris C, 2019, IEEE T GEOSCI REMOTE, V57, P4259, DOI 10.1109/TGRS.2018.2890404
   PARMAR N, 2018, PR MACH LEARN RES, V80, P0
   Pashaei M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060959
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Perez-Hoyos A, 2020, INT J APPL EARTH OBS, V88, P0, DOI 10.1016/j.jag.2020.102064
   Qiu JJ, 2016, DESTECH TRANS ENG, V0, P0
   Reinhart V, 2021, INT J APPL EARTH OBS, V94, P0, DOI 10.1016/j.jag.2020.102221
   Rodriguez MA, 1999, LECT NOTES COMPUT SC, V1580, P189
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Ruas A., 2008, MAP GEN, V0, PP631, DOI 10.1007/978-0-387-35973-1743
   Russo F, 2010, IEEE SIGNAL PROC LET, V17, P417, DOI 10.1109/LSP.2010.2042516
   Sakai M, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL, V0, PP434, DOI 10.1109/ISIC.2002.1157802
   Salehi SSM, 2017, LECT NOTES COMPUT SC, V10541, P379, DOI 10.1007/978-3-319-67389-9_44
   Sattar F, 1997, IEEE T IMAGE PROCESS, V6, P888, DOI 10.1109/83.585239
   Tang K, 2015, IEEE I CONF COMP VIS, V0, PP1008, DOI 10.1109/ICCV.2015.121
   Tomaselli V, 2013, LANDSCAPE ECOL, V28, P905, DOI 10.1007/s10980-013-9863-3
   Topfer F, 1966, CARTOGR J, V3, P10, DOI 10.1179/CAJ.1966.3.1.10
   Vancutsem C, 2013, REMOTE SENS-BASEL, V5, P19, DOI 10.3390/rs5010019
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vilar L, 2019, INT J APPL EARTH OBS, V78, P102, DOI 10.1016/j.jag.2019.01.019
   Waser LT, 2006, INT J APPL EARTH OBS, V8, P196, DOI 10.1016/j.jag.2005.10.001
   Wong K.C.L., 2018, COMPUTING COMPUTER A, V0, P0, DOI DOI 10.1007/978-3-030-00931-170
   Xu Q., 2016, THESIS, V0, P0
   Yang H, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6050154
   Yang LM, 2018, ISPRS J PHOTOGRAMM, V146, P108, DOI 10.1016/j.isprsjprs.2018.09.006
   Yu QZ, 2021, ISPRS J PHOTOGRAMM, V171, P1, DOI 10.1016/j.isprsjprs.2020.10.019
   Zazkis R., 1996, J MATH BEHAV, V15, P207, DOI 10.1016/S0732-3123(96)90017-6
NR 77
TC 5
Z9 5
U1 3
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR 15
PY 2021
VL 13
IS 6
BP 
EP 
DI 10.3390/rs13061060
PG 32
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SE3PD
UT WOS:000651981800001
DA 2023-04-26
ER

PT J
AU Ou, DP
   Tan, K
   Lai, J
   Jia, XP
   Wang, X
   Chen, Y
   Li, J
AF Ou, Depin
   Tan, Kun
   Lai, Jian
   Jia, Xiuping
   Wang, Xue
   Chen, Yu
   Li, Jie
TI Semi-supervised DNN regression on airborne hyperspectral imagery for improved spatial soil properties prediction
SO GEODERMA
LA English
DT Article
DE Hyperspectral imagery; Soil organic matter; Heavy metals; Semi-supervised deep neural network regression; Spatial transportation and aggregation; VNIR-SWIR spectroscopy
ID spectral band selection; natural organic-matter; heavy-metals; reflectance spectroscopy; mining area; pollution; field; mobilization; calibration; sediments
AB A number of algorithms have been developed for soil organic matter (SOM) or soil heavy metal detection in airborne hyperspectral imagery with high spatial and spectral resolutions. However, to achieve improved land management, the problems of the inconsistent features and low accuracy still need to be solved. In this paper, we propose a novel regression model to estimate the concentrations of SOM, arsenic (As), and chromium (Cr) in soil. Firstly, a hyperspectral unmixing technique is utilized to extract the bare soil pixels. We then combine the absorption depth feature after continuum removal, the original absorption feature, the band ratio feature, and the first-order differential feature, to form a set of features for parameter inversion. To solve the over-fitting problem caused by the small number of samples and the weak expression problem, the semi-supervised deep neural network regression (Semi-DNNR) model is introduced. The experimental were conducted using several datasets collected by HyMap, which is an airborne hyperspectral imaging sensor in VNIR-SWIR spectral range in Yitong county, Jilin province, China. The proposed Semi-DNNR model shows a good performance in this study, with the prediction R-p(2) values for SOM, As, and Cr being 0.71, 0.82, and 0.63, respectively. After the spatial distribution map of the soil components of the study area was overlaid with the stream network, which was obtained from the digital elevation model (DEM). It was found that snowmelt, the melting of frozen soil, and surface rainfall can transport SOM to low-lying areas. A similar phenomenon was also observed for As, due to SOM adsorption and dissolved organic matter (DOM) complexation. A comparison of the proposed method with both feature selection methods (competitive adaptive reweighted sampling (CARS), genetic algorithm (GA)) and regression methods (partial least squares regression (PLSR), support vector regression (SVR)) shows that the proposed feature selection method is more robust than the CARS and GA methods. The proposed Semi-DNNR model was found to be at least 18.80% higher in prediction accuracy for As than the SVR or PLSR methods, at least 25.71% higher for Cr, and at least 19.73% higher for SOM.
C1 [Ou, Depin; Tan, Kun; Chen, Yu] China Univ Min & Technol, MNR Key Lab Land Environm & Disaster Monitoring, Xuzhou 221116, Jiangsu, Peoples R China.
   [Tan, Kun; Wang, Xue] East China Normal Univ, Minist Educ, Key Lab Geog Informat Sci, Shanghai 200241, Peoples R China.
   [Lai, Jian] Shanghai Inst Satellite Engn, Shanghai 200240, Peoples R China.
   [Jia, Xiuping] Univ New South Wales, Sch Engn & Informat Technol, Canberra, ACT 2600, Australia.
   [Li, Jie] Nantong Acad Intelligent Sensing, Nantong 226000, Peoples R China.
C3 China University of Mining & Technology; East China Normal University; University of New South Wales Sydney
RP Tan, K (corresponding author), East China Normal Univ, Minist Educ, Key Lab Geog Informat Sci, Shanghai 200241, Peoples R China.
EM tankuncu@gmail.com
FU Natural Science Foundation of China [41871337]; Priority Academic Program Development of Jiangsu Higher Education Institutions
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amigo JM, 2015, ANAL CHIM ACTA, V896, P34, DOI 10.1016/j.aca.2015.09.030
   [Anonymous], 2017, NIPS WORKSH, V0, P0
   Bajcsy P, 2004, PHOTOGRAMM ENG REM S, V70, P793, DOI 10.14358/PERS.70.7.793
   Bajcsy P, 2009, ENVIRON RES, V0, P154
   Bajcsy P, 2008, SOIL POLLUTION, V0, P0
   Bal M, 2017, 2017 16TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), V0, PP281, DOI 10.1145/3055031.3055046
   Bauer M, 2006, SCI TOTAL ENVIRON, V354, P179, DOI 10.1016/j.scitotenv.2005.01.027
   BenDor E, 1997, REMOTE SENS ENVIRON, V61, P1, DOI 10.1016/S0034-4257(96)00120-4
   BERK A, 1999, INT SOC OPT PHOTON, V3756, P348
   Brefeld U., 2006, INT C MACH LEARN, V0, P0
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Cecillon L, 2008, SOIL BIOL BIOCHEM, V40, P1975, DOI 10.1016/j.soilbio.2008.03.016
   Chabrillat S, 2019, SURV GEOPHYS, V40, P361, DOI 10.1007/s10712-019-09524-0
   Chakraborty S, 2017, GEODERMA, V296, P30, DOI 10.1016/j.geoderma.2017.02.015
   Chakraborty S, 2017, GEODERMA, V289, P72, DOI 10.1016/j.geoderma.2016.11.024
   Chi G, 2017, SMALL AREA POPULATIO, V0, P0
   Choe E, 2008, REMOTE SENS ENVIRON, V112, P3222, DOI 10.1016/j.rse.2008.03.017
   COLEMAN TL, 1991, SOIL SCI, V151, P355, DOI 10.1097/00010694-199105000-00005
   CSILLAG F, 1993, REMOTE SENS ENVIRON, V43, P231, DOI 10.1016/0034-4257(93)90068-9
   Du PJ, 2020, J GEOVIS SPAT ANAL, V4, P0, DOI 10.1007/s41651-020-00048-5
   Farifteh J, 2007, REMOTE SENS ENVIRON, V110, P59, DOI 10.1016/j.rse.2007.02.005
   Fichot CG, 2016, ENVIRON SCI TECHNOL, V50, P573, DOI 10.1021/acs.est.5b03518
   Galvao LS, 1998, REMOTE SENS ENVIRON, V63, P166, DOI 10.1016/S0034-4257(97)00135-1
   Gannouni S., 2012, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V4, P242, DOI 10.4236/jgis.2012.43029
   Gholizadeh A, 2015, SOIL WATER RES, V10, P218, DOI 10.17221/113/2015-SWR
   Granitto PM, 2006, CHEMOMETR INTELL LAB, V83, P83, DOI 10.1016/j.chemolab.2006.01.007
   Groves P., 2003, IEEE WORKSH ADV TECH, V0, P0
   Guanter L, 2006, APPL OPTICS, V45, P2360, DOI 10.1364/AO.45.002360
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   HENDERSON TL, 1989, SOIL SCI SOC AM J, V53, P1778, DOI 10.2136/sssaj1989.03615995005300060028x
   JENSON SK, 1988, PHOTOGRAMM ENG REM S, V54, P1593
   Kalbitz K, 1998, SCI TOTAL ENVIRON, V209, P27, DOI 10.1016/S0048-9697(97)00302-1
   Khajehsharifi H., 2017, ARAB J CHEM, V10, P0
   Khan TM, 2017, IEEE T IMAGE PROCESS, V26, P2116, DOI 10.1109/TIP.2017.2671781
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kleijnen JPC, 2009, EUR J OPER RES, V192, P707, DOI 10.1016/j.ejor.2007.10.013
   Klembaiim D., 2013, APPL REGRESSION ANAL, V0, P0
   Kukreja S. L., 2006, IFAC P, V39, P814
   Leardi R, 2000, J CHEMOMETR, V14, P643, DOI 10.1002/1099-128X(200009/12)14:5/6<643::AID-CEM621>3.0.CO;2-E
   Lei M.A., 2011, COMPUT ENG APPL, V25, P0
   Li HD, 2009, ANAL CHIM ACTA, V648, P77, DOI 10.1016/j.aca.2009.06.046
   Liu WD, 2002, REMOTE SENS ENVIRON, V81, P238, DOI 10.1016/S0034-4257(01)00347-9
   McArthur JM, 2004, APPL GEOCHEM, V19, P1255, DOI 10.1016/j.apgeochem.2004.02.001
   Dematte JAM, 2018, REMOTE SENS ENVIRON, V212, P161, DOI 10.1016/j.rse.2018.04.047
   Nascimento J.M., 2005, IEEE T GEOSCI REMOTE, V13, P0
   OCALLAGHAN JF, 1984, COMPUT VISION GRAPH, V28, P323, DOI 10.1016/S0734-189X(84)80011-0
   Ou DP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060654
   Padarian J, 2019, GEODERMA REG, V16, P0, DOI 10.1016/j.geodrs.2018.e00198
   Padarian J, 2019, GEODERMA, V340, P279, DOI 10.1016/j.geoderma.2019.01.009
   Pyo J, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111350
   Redman AD, 2002, ENVIRON SCI TECHNOL, V36, P2889, DOI 10.1021/es0112801
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS
   Rezaei Y., 2008, INT ARCH PHOTOGRAMME, V37, P383
   Rinnan A, 2009, TRAC-TREND ANAL CHEM, V28, P1201, DOI 10.1016/j.trac.2009.07.007
   Rossel RAV, 2010, GEODERMA, V158, P46, DOI 10.1016/j.geoderma.2009.12.025
   Sarathjith MC, 2016, GEODERMA, V267, P1, DOI 10.1016/j.geoderma.2015.12.031
   Selige T, 2006, GEODERMA, V136, P235, DOI 10.1016/j.geoderma.2006.03.050
   Shi TZ, 2016, INT J APPL EARTH OBS, V52, P95, DOI 10.1016/j.jag.2016.06.002
   Shi TZ, 2014, J HAZARD MATER, V265, P166, DOI 10.1016/j.jhazmat.2013.11.059
   Singh S, 2019, GEODERMA REG, V18, P0, DOI 10.1016/j.geodrs.2019.e00233
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Soriano-Disla JM, 2014, APPL SPECTROSC REV, V49, P139, DOI 10.1080/05704928.2013.811081
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stamatis G, 2001, WATER AIR SOIL POLL, V128, P61, DOI 10.1023/A:1010337718104
   Stevens A, 2008, GEODERMA, V144, P395, DOI 10.1016/j.geoderma.2007.12.009
   Tachikawa T., 2011, ASTER GLOBAL DIGITAL, V0, P0
   Tan K, 2018, J SOIL SEDIMENT, V18, P2008, DOI 10.1007/s11368-018-1930-6
   Thompson B., 1995, STEPWISE REGRESSION, V0, P0
   thou Z., 2006, PRICAI 2006 TRENDS A, V0, P0
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Tsakiridis NL, 2020, NEUROCOMPUTING, V389, P27, DOI 10.1016/j.neucom.2020.01.008
   Tsakiridis NL, 2020, GEODERMA, V367, P0, DOI 10.1016/j.geoderma.2020.114208
   Tsakiridis NL, 2019, APPL SOFT COMPUT, V81, P0, DOI 10.1016/j.asoc.2019.105504
   Underwood E, 2003, REMOTE SENS ENVIRON, V86, P150, DOI 10.1016/S0034-4257(03)00096-8
   Wang FH, 2018, ISPRS J PHOTOGRAMM, V136, P73, DOI 10.1016/j.isprsjprs.2017.12.003
   Wang L, 2009, PADDY WATER ENVIRON, V7, P259, DOI 10.1007/s10333-009-0166-x
   Wang M., 2006, P 6 IEEE INT C DAT M, V0, P0
   Wang SL, 2006, ENVIRON GEOCHEM HLTH, V28, P197, DOI 10.1007/s10653-005-9032-y
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P7232, DOI 10.1109/TGRS.2019.2912468
   Zhou ZH, 2007, IEEE T KNOWL DATA EN, V19, P1479, DOI 10.1109/TKDE.2007.190644
   Zou XB, 2010, ANAL CHIM ACTA, V667, P14, DOI 10.1016/j.aca.2010.03.048
NR 82
TC 25
Z9 26
U1 7
U2 72
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0016-7061
EI 1872-6259
J9 GEODERMA
JI Geoderma
PD MAR 1
PY 2021
VL 385
IS 
BP 
EP 
DI 10.1016/j.geoderma.2020.114875
PG 17
WC Soil Science
SC Agriculture
GA PV5AB
UT WOS:000609999200025
DA 2023-04-26
ER

PT J
AU Abdollahi, A
   Pradhan, B
   Alamri, A
AF Abdollahi, Abolfazl
   Pradhan, Biswajeet
   Alamri, Abdullah
TI RoadVecNet: a new approach for simultaneous road network segmentation and vectorization from aerial and google earth imagery in a complex urban set-up
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Deep learning; RoadVecNet; remote sensing; road segmentation; GIS; road vectorization
ID convolutional neural-network; centerline extraction; satellite images; classification; cnn
AB In this study, we present a new automatic deep learning-based network named Road Vectorization Network (RoadVecNet), which comprises interlinked UNet networks to simultaneously perform road segmentation and road vectorization. Particularly, RoadVecNet contains two UNet networks. The first network with powerful representation capability can obtain more coherent and satisfactory road segmentation maps even under a complex urban set-up. The second network is linked to the first network to vectorize road networks by utilizing all of the previously generated feature maps. We utilize a loss function called focal loss weighted by median frequency balancing (MFB_FL) to focus on the hard samples, fix the training data imbalance problem, and improve the road extraction and vectorization performance. A new module named dense dilated spatial pyramid pooling, which combines the benefit of cascaded modules with atrous convolution and atrous spatial pyramid pooling, is designed to produce more scale features over a broader range. Two types of high-resolution remote sensing datasets, namely, aerial and Google Earth imagery, were used for road segmentation and road vectorization tasks. Classification results indicate that the RoadVecNet outperforms the state-of-the-art deep learning-based networks with 92.51% and 93.40% F1 score for road surface segmentation and 89.24% and 92.41% F1 score for road vectorization from the aerial and Google Earth road datasets, respectively. In addition, the proposed method outperforms the other comparative methods in terms of qualitative results and produces high-resolution road segmentation and vectorization maps. As a conclusion, the presented method demonstrates that considering topological quality may result in improvement of the final road network, which is essential in various applications, such as GIS database updating.
C1 [Abdollahi, Abolfazl; Pradhan, Biswajeet] Univ Technol Sydney UTS, CAMGIS, Sydney, NSW, Australia.
   [Pradhan, Biswajeet] Univ Kebangsaan Malaysia, Earth Observat Ctr, Inst Climate Change, Bangi, Sekangor, Malaysia.
   [Alamri, Abdullah] King Saud Univ, Coll Sci, Dept Geol & Geophys, Riyadh, Saudi Arabia.
C3 University of Technology Sydney; Universiti Kebangsaan Malaysia; King Saud University
RP Pradhan, B (corresponding author), Univ Technol Sydney UTS, CAMGIS, Sydney, NSW, Australia.; Pradhan, B (corresponding author), Univ Kebangsaan Malaysia, Earth Observat Ctr, Inst Climate Change, Bangi, Sekangor, Malaysia.
EM biswajeet24@gmail.com
FU King Saud University, Riyadh, Saudi Arabia [RSP-2021/14]; Centre for Advanced Modelling and Geospatial Information Systems, Faculty of Engineering and IT, University of Technology Sydney
CR Abdollahi A, 2021, EXPERT SYST APPL, V176, P0, DOI 10.1016/j.eswa.2021.114908
   Abdollahi A, 2020, IEEE ACCESS, V8, P179424, DOI 10.1109/ACCESS.2020.3026658
   Abdollahi A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091444
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Buslaev A, 2018, IEEE COMPUT SOC CONF, V0, PP197, DOI 10.1109/CVPRW.2018.00035
   Chaudhuri D, 2012, IEEE J-STARS, V5, P1538, DOI 10.1109/JSTARS.2012.2199085
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Diakogiannis F, 2019, RESUNET A DEEP LEARN, V0, P1
   Eigen D, 2012, PROC CVPR IEEE, V0, PP2799, DOI 10.1109/CVPR.2012.6248004
   Gao X, 2018, IEEE ACCESS, V6, P39401, DOI 10.1109/ACCESS.2018.2856088
   Hong ZL, 2018, IEEE ACCESS, V6, P46988, DOI 10.1109/ACCESS.2018.2867210
   Hormese J, 2016, PROC TECH, V24, P1460, DOI 10.1016/j.protcy.2016.05.180
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kaur A., 2015, INT J RES, V2, P1025
   Li PK, 2016, INT GEOSCI REMOTE SE, V0, PP1599, DOI 10.1109/IGARSS.2016.7729408
   Li Y, 2019, REMOTE SENS LETT, V10, P381, DOI 10.1080/2150704X.2018.1557791
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Liu RY, 2019, NEUROCOMPUTING, V329, P384, DOI 10.1016/j.neucom.2018.10.036
   Liu YH, 2019, IEEE T GEOSCI REMOTE, V57, P2043, DOI 10.1109/TGRS.2018.2870871
   Long J., 2015, PROC CVPR IEEE, V0, PP6810, DOI 10.1109/CVPR.2015.7298965
   Luo YR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091026
   Maboudi M, 2017, INT J REMOTE SENS, V38, P179, DOI 10.1080/01431161.2016.1264026
   Miao ZL, 2013, IEEE GEOSCI REMOTE S, V10, P583, DOI 10.1109/LGRS.2012.2214761
   Mnih V., 2013, PHD DISSERTATION, V0, P0
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Movaghati S, 2010, IEEE T GEOSCI REMOTE, V48, P2807, DOI 10.1109/TGRS.2010.2041783
   Qiaoping Z., 2004, GEOSPATIAL INFORM SC, V7, P89, DOI 10.1007/BF02826642
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saito S, 2015, PROC SPIE, V9405, P0, DOI 10.1117/12.2083273
   Sarhan E., 2011, 2011 INT C IM INF PR, VIn, P1
   Sevo I, 2016, IEEE GEOSCI REMOTE S, V13, P740, DOI 10.1109/LGRS.2016.2542358
   Shao ZF, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13020239
   Shen ZF, 2010, INT GEOSCI REMOTE SE, V0, PP453, DOI 10.1109/IGARSS.2010.5649912
   Simonyan K., 2014, VERY DEEP CONVOLUTIO, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Unsalan C, 2012, IEEE T GEOSCI REMOTE, V50, P4441, DOI 10.1109/TGRS.2012.2190078
   Vincent O.R., 2009, INF SCI IT ED C, V2009, P97
   Wei YN, 2017, IEEE GEOSCI REMOTE S, V14, P709, DOI 10.1109/LGRS.2017.2672734
   Wei Y, 2020, IEEE T GEOSCI REMOTE, V58, P8919, DOI 10.1109/TGRS.2020.2991733
   Xie Y, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8120571
   Xu YY, 2018, INT CONF GEOINFORM, V0, P0
   Yang MK, 2018, PROC CVPR IEEE, V0, PP3684, DOI 10.1109/CVPR.2018.00388
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yi WB, 2010, INT GEOSCI REMOTE SE, V0, PP445, DOI 10.1109/IGARSS.2010.5650966
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhao WZ, 2017, IEEE J-STARS, V10, P3386, DOI 10.1109/JSTARS.2017.2680324
   Zhong YF, 2017, REMOTE SENS LETT, V8, P136, DOI 10.1080/2150704X.2016.1235299
   Zhong ZL, 2016, INT GEOSCI REMOTE SE, V0, PP1591, DOI 10.1109/IGARSS.2016.7729406
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050489
NR 53
TC 20
Z9 20
U1 9
U2 38
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD OCT 3
PY 2021
VL 58
IS 7
BP 1151
EP 1174
DI 10.1080/15481603.2021.1972713
EA AUG 2021
PG 24
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA XC0VF
UT WOS:000691150000001
DA 2023-04-26
ER

PT J
AU Schnurer, R
   Sieber, R
   Schmid-Lanter, J
   Oztireli, AC
   Hurni, L
AF Schnurer, Raimund
   Sieber, Rene
   Schmid-Lanter, Jost
   Oztireli, A. Cengiz
   Hurni, Lorenz
TI Detection of Pictorial Map Objects with Convolutional Neural Networks
SO CARTOGRAPHIC JOURNAL
LA English
DT Article
DE Artificial intelligence; convolutional neural networks; pictorial maps; map libraries; classification; object detection
ID cartography
AB In this work, realistically drawn objects are identified on digital maps by convolutional neural networks. For the first two experiments, 6200 images were retrieved from Pinterest. While alternating image input options, two binary classifiers based on Xception and InceptionResNetV2 were trained to separate maps and pictorial maps. Results showed that the accuracy is 95-97% to distinguish maps from other images, whereas maps with pictorial objects are correctly classified at rates of 87-92%. For a third experiment, bounding boxes of 3200 sailing ships were annotated in historic maps from different digital libraries. Faster R-CNN and RetinaNet were compared to determine the box coordinates, while adjusting anchor scales and examining configurations for small objects. A resulting average precision of 32% was obtained for Faster R-CNN and of 36% for RetinaNet. Research outcomes are relevant for trawling map images on the Internet and for enhancing the advanced search of digital map catalogues.
C1 [Schnurer, Raimund; Sieber, Rene; Hurni, Lorenz] Swiss Fed Inst Technol, Inst Cartog & Geoinformat, Zurich, Switzerland.
   [Schmid-Lanter, Jost] Zentralbibliothek Zurich, Abt Karten & Panoramen, Zurich, Switzerland.
   [Oztireli, A. Cengiz] Univ Cambridge, Dept Comp Sci & Technol, Cambridge, England.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Cambridge
RP Schnurer, R (corresponding author), Swiss Fed Inst Technol, Inst Cartog & Geoinformat, Zurich, Switzerland.
EM schnuerer@ethz.ch
FU ETH Research Grant [ETH-11 17-1]
CR Agarwal A, 2019, TOP 40 CARTOGRAPHY B, V0, P0
   Alloa E, 2016, CULT THEORY CRIT, V57, P228, DOI 10.1080/14735784.2015.1068127
   [Anonymous], 2015, ARXIV150408083CS, V0, P0
   [Anonymous], 2020, SHIP 1, V0, P0
   [Anonymous], 2016, ARXIV160207261CS, V0, P0
   [Anonymous], 2020, BOAT 1, V0, P0
   Antoniou A., 2015, MIND MAP ILLUSTRATED, V0, P0
   Bandrova T., 2003, INT RES GEOGRAPHICAL, V12, P0, DOI 10.1080/10382040308667547
   Barron R., 1990, DECORATIVE MAPS, V0, P0
   Baumgartner Ingrid., 2019, MAPS TRAVEL MIDDLE A, V0, P0
   Bengio Y., 2007, LARGE SCALE KERNEL M, V0, P0
   Berann H., 1989, PANORAMIC DRAWING YO, V0, P0
   Block A., 1614, FIGURATIVE MAP ADRIA, V0, P0
   Bodum L., 2005, EXPLORING GEOVISUALI, V0, P389
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Brueghel the Elder P., 1565, 16 BOATS DIFFERENT S, V0, P0
   Campbell T., 2019, MAP HIST HIST CARTOG, V0, P0
   Caquard S, 2014, CARTOGR J, V51, P101, DOI 10.1179/0008704114Z.000000000130
   Cartwright W, 2015, INT J DIGIT EARTH, V8, P522, DOI 10.1080/17538947.2014.923942
   Chen L.-C., 2016, ARXIV160600915CS, V0, P0
   Child H, 1956, DECORATIVE MAPS DO I, V0, P0
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Clarke V, 2015, MAP EXPLORING WORLD, V0, P0
   COCO Consortium, 2015, COMM OBJ CONT COCO, V0, P0
   Coronelli V.M, 1690, MAP ETHIOPIA ABYSSIN, V0, P0
   Cresques A, 1375, CATALAN ATLAS, V0, P0
   Dai JF, 2017, IEEE I CONF COMP VIS, V0, PP764, DOI 10.1109/ICCV.2017.89
   Dodge S, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, V0, PP358, DOI 10.23919/MVA.2017.7986875
   Duan W., 2018, P AUTOCARTO, V0, P0
   Duzer C.V., 2014, SEA MONSTERS MEDIEVA, V0, P0
   Eggert C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR17), V0, PP172, DOI 10.1145/3078971.3078990
   Eytzinger M., 1583, LEO BELGICUS, V0, P0
   Feng Y, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8060258
   Fuchs R, 2015, APPL GEOGR, V59, P43, DOI 10.1016/j.apgeog.2015.02.013
   Gaiser H, 2018, KERAS RETINANET, V0, P0
   Girshick R., 2013, P IEEE C COMP VIS PA, V0, P0
   Goel A, 2011, INT J DOC ANAL RECOG, V14, P349, DOI 10.1007/s10032-010-0136-2
   Gonthier N., 2018, P EUR C COMP VIS, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Goodman M.B., 1930, MAP BERKELEY OAKLAND, V0, P0
   Google Developers, 2019, CUSTOM SEARCH JSON A, V0, P0
   Graca A.J.S., 2015, REV BRASILEIRA CARTO, V67, P0
   Hamaguchi R, 2018, IEEE WINT CONF APPL, V0, PP1442, DOI 10.1109/WACV.2018.00162
   He K., 2015, PROC CVPR IEEE, V5, P6
   He K., 2017, ARXIV170306870CS, V0, P0
   Holmes N., 1991, PICTORIAL MAPS HIST, V0, P0
   Hornsby S., 2017, PICTURING AM GOLDEN, V0, P0
   Huang J., 2019, TENSORFLOW OBJECT DE, V0, P0
   Jordan P., 2009, GEOGRAPHICAL NAMES P, V18, P0
   Kang YH, 2019, INT J CARTOGRAPHY, V5, P115, DOI 10.1080/23729333.2019.1615729
   Kent A., 2012, CARTOGRAPHIC PERSPEC, V73, P39
   Kraak M. J., 2017, INT J CARTOGRAPHY, V3, P9, DOI https://doi.org/10.1080/23729333.2017.1288535
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lamb A., 2014, TEACHER LIB, V42, P0
   Lin T.-Y., 2017, ARXIV170802002CS, V0, P0
   Liu C, 2017, IEEE I CONF COMP VIS, V0, PP2214, DOI 10.1109/ICCV.2017.241
   Mason B, 2016, THESE COLORFUL PROPA, V0, P0
   Merwin D, 2009, CARTOGR GEOGR INF SC, V36, P347, DOI 10.1559/152304009789786335
   Minard C.J., 1869, CARTE FIGURATIVE PER, V0, P0
   Nguyen HTH, 2017, LECT NOTES ARTIF INT, V10535, P705, DOI 10.1007/978-3-319-71246-8_43
   OShea K., 2015, ARXIV151108458CS, V0, P0
   Olszewski R, 2018, GEOD CARTOGR, V67, P255, DOI 10.24425/118708
   Ortelius A, 1589, MARIS PACIFICI, V0, P0
   Ortelius A, 1585, ISLANDIA, V0, P0
   Redmon J., 2018, YOLOV3 J INCREMENTAL, V0, P6
   REES R, 1980, GEOGR REV, V70, P60, DOI 10.2307/214368
   Reinhartz D., 2012, ART MAP ILLUSTRATED, V0, P0
   Ren S., 2016, ARXIV, V0, P0, DOI DOI 10.1109/TPAMI.2016.2577031
   Roman J., 2015, ART ILLUSTRATED MAPS, V0, P0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarjakoski L. T., 2009, LECT NOTES GEOINFORM, V0, PP107, DOI 10.1007/978-3-540-68569-2_10
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P82, DOI 10.1007/978-3-642-15825-4_9
   Sen A, 2014, CARTOGR GEOGR INF SC, V41, P151, DOI 10.1080/15230406.2013.877231
   Siam M, 2017, IEEE INT C INTELL TR, V0, P0
   Simonyan K, 2015, ARXIV, V0, P0
   Skelton R. A, 1966, DECORATIVE PRINTED M, V0, P0
   Stanford Vision Lab, 2016, STANF VIS LAB, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Turconi C, 1997, RUP ARCH C 1997, V0, P0
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Unger RW, 2010, EARLY MOD HIST-SOC C, V0, PP1, DOI 10.1057/9780230282162
   Virrantaus K, 2009, CARTOGR GEOGR INF SC, V36, P209, DOI 10.1559/152304009788188772
   Wallis Wallis Helen M. Helen M., 1987, CARTOGRAPHICAL INNOV, V0, P0
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7774, DOI 10.1109/CVPR.2018.00811
   Wang YX, 2015, LECT NOTES GEOINF CA, V0, PP189, DOI 10.1007/978-3-319-17738-0_14
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Yanagisawa H, 2018, PROC INT WORKSH ADV, V0, P0
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Ziran Z, 2018, LECT NOTES ARTIF INT, V11081, P383, DOI 10.1007/978-3-319-99978-4_30
NR 94
TC 4
Z9 4
U1 5
U2 10
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0008-7041
EI 1743-2774
J9 CARTOGR J
JI Cartogr. J.
PD JAN 2
PY 2021
VL 58
IS 1
BP 50
EP 68
DI 10.1080/00087041.2020.1738112
EA JUN 2020
PG 19
WC Geography
SC Geography
GA TY2FT
UT WOS:000570645000001
DA 2023-04-26
ER

PT J
AU Khadka, S
   Gyawali, BR
   Shrestha, TB
   Cristan, R
   Banerjee, S
   Antonious, G
   Poudel, HP
AF Khadka, Saaruj
   Gyawali, Buddhi R.
   Shrestha, Tilak B.
   Cristan, Richard
   Banerjee, Swagata ''Ban''
   Antonious, George
   Poudel, Hari P.
TI Exploring relationships among landownership, landscape diversity, and ecological productivity in Kentucky
SO LAND USE POLICY
LA English
DT Article
DE Agroecosystem; Ecological productivity; Landsat; NDVI; Ownership structure
ID land-use; forest fragmentation; texture analysis; neural-network; cover; classification; ownership; vegetation; population; climate
AB Kentucky has varied landscapes favorable for different land use land cover and agroecosystem management. The changes in land use land cover concerning a change in landownership structure can potentially alter landscape diversity and ecological productivity. This research examined the relationship among land cover, ownership structure (small, medium, and large parcel), and ecological productivity in Scott, Morgan, and Graves counties of Kentucky. Landsat 4-5 TM and 8 OLI (30-meter) imagery were used for supervised classification, accuracy assessment, and change detection at the pixel level in the years 2001, 2011, and 2016 for major land cover classes. The correlations in landscape diversity were analyzed using parcel data and thematic maps. Ecological productivity was estimated using the MODIS-NDVI 250 m, 16-day mean composite data along with parcel data. The change in land cover was primarily noticed in the cultivated crops and water, cultivated crops, and forest and pasture in Scott, Morgan, and Graves Counties, respectively. There was a strong negative correlation among agriculture, forest, and developed lands. The parcel size was significant (p < 0.05) for most of the land cover classes, but the relationships were not consistent in all combinations of year and counties. The ecological productivity was significantly different (p < 0.05) between small, medium, and large parcels. Further research is needed on other driving factors so that appropriate policy and decisions can be set for sustainable agroecosystem management.
C1 [Khadka, Saaruj] Univ Missouri, Sch Nat Resources, Columbia, MO 65211 USA.
   [Gyawali, Buddhi R.; Shrestha, Tilak B.; Antonious, George] Kentucky State Univ, Sch Agr Communities & Environm, Frankfort, KY 40601 USA.
   [Cristan, Richard] Auburn Univ, Sch Forestry & Wildlife Sci, Auburn, AL 36849 USA.
   [Banerjee, Swagata ''Ban''] Kentucky State Univ, Sch Business, Frankfort, KY USA.
   [Poudel, Hari P.] Agr & Agri Food Canada, Lethbridge Res & Dev Ctr, Lethbridge, AB, Canada.
C3 University of Missouri System; University of Missouri Columbia; Kentucky State University; Auburn University System; Auburn University; Kentucky State University; Agriculture & Agri Food Canada
RP Gyawali, BR (corresponding author), Kentucky State Univ, Sch Agr Communities & Environm, Frankfort, KY 40601 USA.
EM Buddhi.gyawali@kysu.edu
FU USDA/Evans Allen Fund "Developing Decision Support Systems (DSS) for Agroecosystems Management and Sustainability" [KYX-10-17-59P, 1014433]
CR Ahlqvist O., 2000, CONTEXT SENSITIVE TR, V0, P0
   Ali DA, 2015, LAND ECON, V91, P317, DOI 10.3368/le.91.2.317
   Altieri MA, 1999, AGR ECOSYST ENVIRON, V74, P19, DOI 10.1016/S0167-8809(99)00028-6
   Anderson J.R., 1976, LAND USE LAND COVER, V964, P0
   [Anonymous], 2002, SURV LAND INF SYST, V0, P0
   [Anonymous], 1994, REMOTE SENSING IMAGE, V0, P0
   [Anonymous], 2014, INT J FOR RES, V0, P0, DOI DOI 10.1155/2014/614249
   Assuncao JJ, 2007, AM J AGR ECON, V89, P980, DOI 10.1111/j.1467-8276.2007.01032.x
   Bai Y, 2019, ECOL INDIC, V102, P51, DOI 10.1016/j.ecolind.2019.01.079
   Barrett CB, 2010, WORLD DEV, V38, P88, DOI 10.1016/j.worlddev.2009.06.002
   Belanger L, 2002, LANDSCAPE ECOL, V17, P495, DOI 10.1023/A:1021443929548
   Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191
   Berry W, 1987, PUB TYPE, V1, P8
   Bhattacharjee S, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, V0, PP177, DOI 10.5194/isprsannals-II-4-W2-177-2015
   BOLSTAD PV, 1991, PHOTOGRAMM ENG REM S, V57, P67
   Braun E.L., 1937, RHODORA, V39, P193
   Burton ML, 2008, PLANT ECOL, V195, P99, DOI 10.1007/s11258-007-9305-x
   Butaye J, 2001, ECOGRAPHY, V24, P369, DOI 10.1034/j.1600-0587.2001.d01-193.x
   Chakraborty M., 2006, J INDIAN SOC REMOTE, V34, P13
   Chase TN, 2000, CLIM DYNAM, V16, P93, DOI 10.1007/s003820050007
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   CRIST EP, 1984, PHOTOGRAMM ENG REM S, V50, P343
   Crist Eric P., 1986, DIGEST INT GEOSCIENC, V0, P1465
   DeGrove JohnM, 1984, LAND GROWTH POLITICS, V0, P0
   Desiere S, 2018, J DEV ECON, V130, P84, DOI 10.1016/j.jdeveco.2017.10.002
   Dijk T, 2003, DEAL CENT EUR LAND F, V0, P0
   Dijk Terry, 2004, S VOLVIC, V0, P31
   Dobrowski SZ, 2008, APPL VEG SCI, V11, P499, DOI 10.3170/2008-7-18560
   Drohan PJ, 2012, ENVIRON MANAGE, V49, P1061, DOI 10.1007/s00267-012-9841-6
   Dumortier J, 2013, ENVIRON RES LETT, V8, P0, DOI 10.1088/1748-9326/8/4/044020
   Elliott NC, 1999, LANDSCAPE ECOL, V14, P239, DOI 10.1023/A:1008002528345
   Erbek FS, 2004, INT J REMOTE SENS, V25, P1733, DOI 10.1080/0143116031000150077
   Ferranto S, 2013, SOC NATUR RESOUR, V26, P1082, DOI 10.1080/08941920.2013.779343
   Foody GM, 1996, ECOL MODEL, V85, P3, DOI 10.1016/0304-3800(95)00012-7
   FOODY GM, 1992, PHOTOGRAMM ENG REM S, V58, P1335
   Futamura T, 2007, JAPANESE J AM STUDIE, V18, P209
   Gao J, 2010, INT J APPL EARTH OBS, V12, P9, DOI 10.1016/j.jag.2009.08.003
   Gardiner MM, 2009, ECOL APPL, V19, P143, DOI 10.1890/07-1265.1
   Ge SK, 2006, ENVIRON MONIT ASSESS, V114, P65, DOI 10.1007/s10661-006-1071-z
   Gill N, 2010, J ENVIRON PLANN MAN, V53, P317, DOI 10.1080/09640561003612890
   Gonzalez R.C., 1992, DIGITAL IMAGE PROCES, V0, P2
   Google Earth, 2019, FREE GOOGL EARTH, V0, P0
   Gosnell H, 2006, SOC NATUR RESOUR, V19, P743, DOI 10.1080/08941920600801181
   GrashofBokdam C, 1997, J VEG SCI, V8, P21, DOI 10.2307/3237238
   Gustafson EJ, 1998, ECOSYSTEMS, V1, P143, DOI 10.1007/s100219900011
   Halich G., 2018, KENTUCKY ANR AGENT L, V0, P90
   Hart J.F., 2020, TOTAL FARM LAND 1900, V4, P1
   Healy R.G., 2013, LAND USE STATES, V0, P0
   Homewood K, 2001, P NATL ACAD SCI USA, V98, P12544, DOI 10.1073/pnas.221053998
   Honnay O, 1999, BIOL CONSERV, V87, P73, DOI 10.1016/S0006-3207(98)00038-X
   Honnay O, 2003, LANDSCAPE URBAN PLAN, V63, P241, DOI 10.1016/S0169-2046(02)00194-9
   Hooks P.J., 2016, KENTUCKY RURAL DEV, V0, P0
   Houghton RA, 1999, SCIENCE, V285, P574, DOI 10.1126/science.285.5427.574
   Imaging G., 2005, IMAGINE 12, V0, P0
   Jenkins C.L, 2016, PERCEPTION OPPORTUNI, V0, P0, DOI DOI 10.13023/ETD.2016.236
   Jensen J. R., 1996, INTRODUCTORY DIGITAL IMAGE PROCESSING: A REMOTE SENSING PERSPECTIVE., V0, P0
   Johnston K., 2001, GIS ESRI, V0, P0
   Kadigi R. M. J., 2017, JOURNAL OF DEVELOPMENT AND AGRICULTURAL ECONOMICS, V9, P26, DOI 10.5897/jdae2016.0797
   Kasperson J, 1995, REGIONS RISK, V0, P0
   KGS, 2012, PHYS MAP KENT, V0, P0
   Kuplich TM, 2005, INT J REMOTE SENS, V26, P4829, DOI 10.1080/01431160500239107
   Laba M, 2002, REMOTE SENS ENVIRON, V81, P443, DOI 10.1016/S0034-4257(02)00020-2
   Lambin EF, 2001, GLOBAL ENVIRON CHANG, V11, P261, DOI 10.1016/S0959-3780(01)00007-3
   Larkin JL, 2008, SOUTHEAST NAT, V7, P401, DOI 10.1656/1528-7092-7.3.401
   Li J, 2015, ENVIRON MONIT ASSESS, V187, P0, DOI 10.1007/s10661-015-4766-1
   Li XJ, 2021, SCI TOTAL ENVIRON, V786, P0, DOI 10.1016/j.scitotenv.2021.147488
   Liu DS, 2008, REMOTE SENS ENVIRON, V112, P2222, DOI 10.1016/j.rse.2007.10.002
   Lopez AD, 2006, LANCET, V367, P1747, DOI 10.1016/S0140-6736(06)68770-9
   Lowrey A., 2014, N Y MAG, V0, P0
   Lu Dengsheng, 2005, ACTA AMAZ., V35, P249, DOI 10.1590/S0044-59672005000200015
   Lucas R, 2007, ISPRS J PHOTOGRAMM, V62, P165, DOI 10.1016/j.isprsjprs.2007.03.003
   Macaulay L, 2017, CALIF AGR, V71, P221, DOI 10.3733/ca.2017a0041
   Macaulay L, 2016, LAND USE POLICY, V58, P218, DOI 10.1016/j.landusepol.2016.06.024
   Mendham E, 2010, SOC NATUR RESOUR, V23, P653, DOI 10.1080/08941920801998893
   Mitchley J, 2004, P PET REM SENS WORKS, V0, P9
   Multi-Resolution Land Characteristics (MRLC) Consortium, 2011, MULT LAND CHAR MRLC, V0, P0
   NASS, 2012, CENS AGR, V0, P0
   NASS, 2016, CROPL DAT LAYER, V0, P0
   NASS-USDA, 2017, CENS AGR, V0, P0
   Natural Resources Conservation Service, 2012, AGR STAT KENT, V0, P0
   Niroula GS, 2007, LAND DEGRAD DEV, V18, P237, DOI 10.1002/ldr.771
   OHara JK, 2019, J AGRIC FOOD SYST CO, V9, P31, DOI 10.5304/jafscd.2019.091.046
   Ormsbee L.E., 2003, KENTUCKY RIVER BASIN, V0, P0
   OTTO JS, 1989, P AM PHILOS SOC, V133, P51
   Paola J. D., 1994, THESIS U ARIZONA TUC, V0, P0
   PAOLA JD, 1995, IEEE T GEOSCI REMOTE, V33, P981, DOI 10.1109/36.406684
   Parola A.C., 2007, KY DIV, V319, P0
   Patton J.W., 2014, KY JPN BLUEGRASS, V123, P0
   Peters D.P.C., 2013, ENCY BIODIVERSITY, V0, PP476, DOI 10.1016/B978-0-12-384719-5.00084-8
   Pond GJ, 2010, HYDROBIOLOGIA, V641, P185, DOI 10.1007/s10750-009-0081-6
   Popper F., 1982, ENVIRONMENT, V24, P0
   Porter E. E., 2001, URBAN ECOSYST, V5, P131, DOI 10.1023/A:1022391721622
   Rahman S, 2009, LAND USE POLICY, V26, P95, DOI 10.1016/j.landusepol.2008.01.003
   Ramankutty N, 1999, GLOBAL BIOGEOCHEM CY, V13, P997, DOI 10.1029/1999GB900046
   Reilly J, 2007, ENERG POLICY, V35, P5370, DOI 10.1016/j.enpol.2006.01.040
   Rosenzweig Michael L., 1995, DOI 10.1017/CBO9780511623387.002, V0, P0
   Sala OE, 2000, SCIENCE, V287, P1770, DOI 10.1126/science.287.5459.1770
   Sauer C.O., 1927, GEOGRAPHY PENNYROYAL, V25, P0
   Schmidt MH, 2005, J BIOGEOGR, V32, P467, DOI 10.1111/j.1365-2699.2004.01244.x
   Sen S, 2012, PHOTOGRAMM ENG REM S, V78, P223, DOI 10.14358/PERS.78.3.223
   SHAFFER ML, 1981, BIOSCIENCE, V31, P131, DOI 10.2307/1308256
   Shen QP, 2009, HABITAT INT, V33, P15, DOI 10.1016/j.habitatint.2008.02.004
   Sorice MG, 2012, J ARID ENVIRON, V80, P56, DOI 10.1016/j.jaridenv.2012.01.004
   South S, 2004, REMOTE SENS ENVIRON, V91, P90, DOI 10.1016/j.rse.2004.03.001
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Tang BS, 1999, LAND USE POLICY, V16, P33, DOI 10.1016/S0264-8377(98)00035-0
   Tarnavsky E, 2008, REMOTE SENS ENVIRON, V112, P535, DOI 10.1016/j.rse.2007.05.008
   Thies C, 2003, OIKOS, V101, P18, DOI 10.1034/j.1600-0706.2003.12567.x
   Tilahun A, 2015, AM J ENV PROT, V4, P193, DOI 10.4236/IJG.2017.84033
   Tolba M.K., 1992, WORLD ENV 1972 1992, V0, P801
   Townsend PA, 2009, REMOTE SENS ENVIRON, V113, P62, DOI 10.1016/j.rse.2008.08.012
   TUCKER CJ, 1985, REMOTE SENS ENVIRON, V17, P233, DOI 10.1016/0034-4257(85)90097-5
   U.S. Bureau of Labor Statistics, 2015, WOM LAB FORC DAT, V0, P0
   Unger DE, 2013, NORTHEAST NAT, V20, P289, DOI 10.1656/045.020.0206
   US Census Bureau, 2017, AM COMMUNITY SURVEY, V0, P0
   USGS, 2001, USGS GEODATA DIG ORT, V0, P0
   Veldkamp A, 2001, AGR ECOSYST ENVIRON, V85, P1, DOI 10.1016/S0167-8809(01)00199-2
   Vitousek PM, 1997, SCIENCE, V277, P494, DOI 10.1126/science.277.5325.494
   Waisanen PJ, 2002, GLOBAL BIOGEOCHEM CY, V16, P0, DOI 10.1029/2001GB001843
   Wang JZ, 2018, EUR J REMOTE SENS, V51, P251, DOI 10.1080/22797254.2017.1419831
   Whitcomb R.F., 1981, ECOLOGICAL STUDIES, V41, P125
   WILCOVE DS, 1985, ECOLOGY, V66, P1211, DOI 10.2307/1939174
   Williams C, 2011, EFFECTS MULTISPECIES, V0, P0
   Wynne F., 2002, OVERVIEW RAINBOW TRO, V0, P2
   Yaslioglu E, 2009, EUR PLAN STUD, V17, P327, DOI 10.1080/09654310802553639
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zawacki T.M, 2016, J ANIM ENV LAW, V8, P38
NR 128
TC 1
Z9 1
U1 6
U2 15
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0264-8377
EI 1873-5754
J9 LAND USE POLICY
JI Land Use Pol.
PD DEC 15
PY 2021
VL 111
IS 
BP 
EP 
DI 10.1016/j.landusepol.2021.105723
PG 15
WC Environmental Studies
SC Environmental Sciences & Ecology
GA XH7XN
UT WOS:000725642800009
DA 2023-04-26
ER

PT J
AU Adedeji, PA
   Akinlabi, SA
   Madushele, N
   Olatunji, OO
AF Adedeji, Paul A.
   Akinlabi, Stephen A.
   Madushele, Nkosinathi
   Olatunji, Obafemi O.
TI Beyond site suitability: Investigating temporal variability for utility-scale solar-PV using soft computing techniques
SO RENEWABLE ENERGY FOCUS
LA English
DT Article
ID multicriteria decision-making; analytic hierarchy process; photovoltaic power-plants; clearness index; forecasting methods; genetic algorithm; farms locations; neural-networks; energy system; wind turbine
AB Site suitability is highly essential for utility-scale solar-PV exploration, however, beyond this phase, the need to investigate solar resource variability in suitable site is very vital to strategic planning and grid-ntegration. This study investigates solar resource variability in a suitable site obtained from geographical information system (GIS)-based site suitability analysis using soft computing techniques. The Western Cape Province, South Africa was used as a case study and climatological, topographic, and location factors were considered for the site suitability analysis for solar-PV in the province. Five soft computing techniques were applied on a candidate site chosen from the final suitability map. These are: gradient descent with adaptive learning rate neural network (GDALRNN), resilient backpropagation neural network (RBNN), adaptive neurofuzzy inference system (ANFIS), genetic algorithm-based ANFIS (GA-ANFIS) and particle swarm optimization based ANFIS (PSO-ANFIS). Each model was trained and tested with 70% and 30% of the data obtained from the representative site respectively. The GDALRNN model outperforms all other models with a root mean square error (RMSE) of 0.0316, coefficient of variation of RMSE (CV(RMSE)) of 4.7590%, relative mean bias error of -0.2951%, mean absolute percentage error of 4.0998, robust coefficient of variation of 0.0403, skill score of 10.7345 and computational time of 9.71 s. Finally, the possibility of integrating resource variability investigation into site suitability and the relevance of simple intelligent models over complex hybrid ones in solar resource variability modelling were established.
C1 [Adedeji, Paul A.; Madushele, Nkosinathi; Olatunji, Obafemi O.] Univ Johannesburg, Dept Mech Engn Sci, Johannesburg, South Africa.
   [Adedeji, Paul A.; Olatunji, Obafemi O.] Univ Johannesburg, Proc Energy & Environm Technol Stn PEETS, Johannesburg, South Africa.
   [Akinlabi, Stephen A.] Walter Sisulu Univ, Dept Mech Engn, Mthatha, South Africa.
C3 University of Johannesburg; University of Johannesburg; Walter Sisulu University
RP Adedeji, PA (corresponding author), Univ Johannesburg, Dept Mech Engn Sci, Johannesburg, South Africa.; Adedeji, PA (corresponding author), Univ Johannesburg, Proc Energy & Environm Technol Stn PEETS, Johannesburg, South Africa.
EM padedeji@uj.ac.za
FU University of Johannesburg
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Adedeji PA, 2020, SCI TECHNOL MANAG, V0, P117
   Adedeji P.A., 1900, P1055, V0, P0
   Adedeji PA, 2021, NEURAL COMPUT APPL, V33, P13049, DOI 10.1007/s00521-021-06001-x
   Adedeji PA, 2020, J CLEAN PROD, V269, P0, DOI 10.1016/j.jclepro.2020.122104
   Adedeji PA, 2020, J CLEAN PROD, V254, P0, DOI 10.1016/j.jclepro.2020.120135
   Adedeji PA, 2020, INT J AMBIENT ENERGY, V0, P0, DOI DOI 10.1080/01430750.2020.1719885
   Adedeji PA, 2019, PROCEDIA MANUF, V33, P176, DOI 10.1016/j.promfg.2019.04.022
   Al Garni HZ, 2017, APPL ENERG, V206, P1225, DOI 10.1016/j.apenergy.2017.10.024
   Alba E, 2004, LECT NOTES COMPUT SC, V3102, P852
   Ali S, 2019, RENEW ENERG, V132, P1360, DOI 10.1016/j.renene.2018.09.035
   Aly A, 2017, RENEW ENERG, V113, P159, DOI 10.1016/j.renene.2017.05.077
   Silva RAE, 2018, SOL ENERGY, V163, P329, DOI 10.1016/j.solener.2018.01.095
   Anoune K, 2018, RENEW SUST ENERG REV, V93, P652, DOI 10.1016/j.rser.2018.05.032
   Arnette AN, 2011, RENEW ENERG, V36, P2785, DOI 10.1016/j.renene.2011.04.024
   Ayodele TR, 2021, RENEW ENERG FOCUS, V38, P57, DOI 10.1016/j.ref.2021.06.001
   Ayodele T. R., 2019, RENEWABLE ENERGY FOCUS, V29, P78, DOI 10.1016/j.ref.2019.03.003
   Ayodele TR, 2018, APPL ENERG, V228, P1853, DOI 10.1016/j.apenergy.2018.07.051
   Badosa J, 2013, SOL ENERGY, V88, P42, DOI 10.1016/j.solener.2012.11.007
   Baharin KA, 2016, ENRGY PROCED, V103, P400, DOI 10.1016/j.egypro.2016.11.306
   Beale M. H., 2010, NEURAL NETWORK TOOLB, V0, P0
   Canada J, 2000, J GEOPHYS RES-ATMOS, V105, P4759, DOI 10.1029/1999JD901106
   Charabi Y, 2011, RENEW ENERG, V36, P2554, DOI 10.1016/j.renene.2010.10.037
   Choudhury B., 2016, SOFT COMPUTING ELECT, V0, P0
   Demuth H., 2004, MATH WORKS USERS GUI, V0, P0
   Department of Environmental Affairs, 2015, EIA GUID REN EN PROJ, V0, P0
   Diabate L, 2004, SOL ENERGY, V76, P733, DOI 10.1016/j.solener.2004.01.002
   Diagne M, 2013, RENEW SUST ENERG REV, V27, P65, DOI 10.1016/j.rser.2013.06.042
   DoE, 2018, REIPPPP GLANCE FOCUS, V0, P0
   Doljak D, 2017, ENERGY, V127, P291, DOI 10.1016/j.energy.2017.03.140
   Doorga JRS, 2019, RENEW ENERG, V133, P1201, DOI 10.1016/j.renene.2018.08.105
   Dorvlo ASS, 2002, APPL ENERG, V71, P307, DOI 10.1016/S0306-2619(02)00016-8
   GARNAUT R, 1992, ECONOMIC REFORM AND INTERNATIONALISATION: CHINA AND THE PACIFIC REGION, V0, P1
   Gibson L, 2017, TRENDS ECOL EVOL, V32, P922, DOI 10.1016/j.tree.2017.09.007
   Gothwal Suman, 2015, INTERNATIONAL JOURNAL OF SERVICES AND OPERATIONS MANAGEMENT, V22, P235
   Halabi LM, 2018, APPL ENERG, V213, P247, DOI 10.1016/j.apenergy.2018.01.035
   Hong T, 2016, ENRGY PROCED, V88, P265, DOI 10.1016/j.egypro.2016.06.157
   Hummon M.R., 2012, P 2 INT WORKSH INT S, V16560, P1
   Icer S., 2006, EXPERT SYST APPL, V31, P406, DOI 10.1016/j.eswa.2005.09.037
   Inman RH, 2013, PROG ENERG COMBUST, V39, P535, DOI 10.1016/j.pecs.2013.06.002
   J.199-R.S.235, 2014, SOLAR ENERGY CONVERS, V0, P0
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Jiaqin Yang, 1997, FACILITIES, V15, P241, DOI 10.1108/02632779710178785
   Jimenez-Perez PF, 2016, SOL ENERGY, V135, P682, DOI 10.1016/j.solener.2016.06.039
   Kaldellis JK, 2014, RENEW ENERG, V66, P612, DOI 10.1016/j.renene.2013.12.041
   Kennedy J., 1998, EVOLUTIONARY PROGRAMMING VII. 7TH INTERNATIONAL CONFERENCE, V0, P581
   Khatib T, 2012, INT J PHOTOENERGY, V2012, P0, DOI 10.1155/2012/419504
   Kheradmand S, 2016, RENEW SUST ENERG REV, V58, P1357, DOI 10.1016/j.rser.2015.12.240
   Khorasanizadeh H, 2016, INT J HYDROGEN ENERG, V41, P21888, DOI 10.1016/j.ijhydene.2016.09.198
   Khosravi A, 2018, J CLEAN PROD, V194, P342, DOI 10.1016/j.jclepro.2018.05.147
   Kumar A, 2017, RENEW SUST ENERG REV, V69, P596, DOI 10.1016/j.rser.2016.11.191
   Lara-Fanego V, 2012, SOL ENERGY, V86, P2200, DOI 10.1016/j.solener.2011.02.014
   Lawrance M., 2018, FAA TECHNICAL GUIDAN, V0, P0
   Lee HC, 2018, RENEW SUST ENERG REV, V92, P883, DOI 10.1016/j.rser.2018.05.007
   Lynn N, 2018, SWARM EVOL COMPUT, V39, P24, DOI 10.1016/j.swevo.2017.11.002
   Majumdar D, 2019, RENEW ENERG, V134, P1213, DOI 10.1016/j.renene.2018.08.064
   Makhloufi S., 2019, 2018 INT C WIND EN A, V0, PP1, DOI 10.1109/ICWEAA.2018.8605102.
   Makridakis S, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0194889
   Mu E, 2018, SPRINGER OPER RES, V0, PP7, DOI 10.1007/978-3-319-68369-0_2
   Mensour ON, 2019, ENERGY, V182, P900, DOI 10.1016/j.energy.2019.06.063
   Nematollahi O, 2017, RENEW SUST ENERG REV, V77, P566, DOI 10.1016/j.rser.2017.03.132
   Noorollahi E, 2016, ENERGIES, V9, P0, DOI 10.3390/en9080643
   Obafemi Olatunji, 2019, EAI ENDORSED T ENERG, V19, P1, DOI 10.4108/EAI.11-6-2019.159119
   Olatunji OO, 2020, J CLEAN PROD, V267, P0, DOI 10.1016/j.jclepro.2020.122013
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pan WT, 2009, NEURAL COMPUT APPL, V18, P1005, DOI 10.1007/s00521-009-0243-5
   Paulescu M, 1900, V2021, V0, P249
   Pereira RM, 2019, SOL ENERGY, V188, P339, DOI 10.1016/j.solener.2019.06.020
   Perez MJR, 2015, SOL ENERGY, V117, P46, DOI 10.1016/j.solener.2015.04.020
   PEREZ R, 1994, SOL ENERGY, V53, P491, DOI 10.1016/0038-092X(94)90128-O
   Perez R., 1900, V1, V0, PP1, DOI 10.1561/2700000006no.1
   Petkovic D, 2014, ENERGY, V64, P868, DOI 10.1016/j.energy.2013.10.094
   Petkovic D, 2013, RENEW SUST ENERG REV, V28, P191, DOI 10.1016/j.rser.2013.07.049
   Pohekar SD, 2004, RENEW SUST ENERG REV, V8, P365, DOI 10.1016/j.rser.2003.12.007
   Prasad AA, 2017, APPL ENERG, V190, P354, DOI 10.1016/j.apenergy.2016.12.135
   Quej VH, 2017, J ATMOS SOL-TERR PHY, V155, P62, DOI 10.1016/j.jastp.2017.02.002
   Raju P.L.N., 2006, SATELLITE REMOTE SEN, V0, P103
   Rakhshani E, 2019, ENERGIES, V12, P0, DOI 10.3390/en12081425
   Rix A., 2015, POTENTIAL DISTRIBUTE, V0, P0
   Rodrigues S, 2017, INT J RENEW ENERGY R, V7, P243
   Saaty Th. L., 2008, DECISION MAKING LEAD, V0, P0
   Sabo ML, 2016, RENEW SUST ENERG REV, V66, P79, DOI 10.1016/j.rser.2016.07.045
   Saeidian B, 2016, INT J DISAST RISK RE, V15, P94, DOI 10.1016/j.ijdrr.2016.01.002
   Salazar G, 2014, RENEW ENERG, V64, P197, DOI 10.1016/j.renene.2013.11.003
   Sanchez-Lozano JM, 2013, RENEW SUST ENERG REV, V24, P544, DOI 10.1016/j.rser.2013.03.019
   Semero YK, 2018, CSEE J POWER ENERGY, V4, P210, DOI 10.17775/CSEEJPES.2016.01920
   Semero YK, 2018, ELECTR POW COMPO SYS, V46, P95, DOI 10.1080/15325008.2018.1433733
   Sindhu S, 2017, RENEW SUST ENERG REV, V73, P496, DOI 10.1016/j.rser.2017.01.135
   Skoplaki E, 2008, SOL ENERG MAT SOL C, V92, P1393, DOI 10.1016/j.solmat.2008.05.016
   Soubdhan T, 2014, ENRGY PROCED, V57, P1309, DOI 10.1016/j.egypro.2014.10.121
   Soubdhan T, 2009, SOL ENERGY, V83, P1056, DOI 10.1016/j.solener.2009.01.010
   Suh J, 2016, ENERGIES, V9, P0, DOI 10.3390/en9080648
   Sun YW, 2013, ENERG POLICY, V58, P248, DOI 10.1016/j.enpol.2013.03.002
   Takase T, 2018, NEURAL NETWORKS, V101, P68, DOI 10.1016/j.neunet.2018.01.016
   Thirugnanasambandam M, 2010, RENEW SUST ENERG REV, V14, P312, DOI 10.1016/j.rser.2009.07.014
   Uyan M, 2013, RENEW SUST ENERG REV, V28, P11, DOI 10.1016/j.rser.2013.07.042
   Vignola F, 2012, WORLD RENEWABLE ENER, V1, P621
   Voyant C, 2017, RENEW ENERG, V105, P569, DOI 10.1016/j.renene.2016.12.095
   Voyant C, 2014, SOL ENERGY, V102, P131, DOI 10.1016/j.solener.2014.01.017
   Wang SH, 2016, SOL ENERGY, V133, P85, DOI 10.1016/j.solener.2016.03.069
   Watson S, 2014, WIRES ENERGY ENVIRON, V3, P330, DOI 10.1002/wene.95
   Woyte A, 2007, SOL ENERGY, V81, P195, DOI 10.1016/j.solener.2006.03.001
   Xu Y, 2020, ENERGY, V207, P0, DOI 10.1016/j.energy.2020.118222
   Yang D, 2020, J ASTHMA, V57, P79, DOI 10.1080/02770903.2018.1545857
   Yavari S, 2012, INT ARCH PHOTOGRAMM, V39-B1, P281
   Yousefi H, 2018, ENERGIES, V11, P0, DOI 10.3390/en11071648
   Yushchenko A, 2018, RENEW SUST ENERG REV, V81, P2088, DOI 10.1016/j.rser.2017.06.021
   ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255
   Zyoud SH, 2017, EXPERT SYST APPL, V78, P158, DOI 10.1016/j.eswa.2017.02.016
NR 110
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1755-0084
EI 1878-0229
J9 RENEW ENERG FOCUS
JI Renew. Energ. Focus
PD DEC 15
PY 2021
VL 39
IS 
BP 72
EP 89
DI 10.1016/j.ref.2021.07.008
EA AUG 2021
PG 18
WC Energy & Fuels
SC Energy & Fuels
GA WB6EK
UT WOS:000703663000007
DA 2023-04-26
ER

PT J
AU Costache, R
   Arabameri, A
   Blaschke, T
   Pham, QB
   Pham, BT
   Pandey, M
   Arora, A
   Linh, NTT
   Costache, I
AF Costache, Romulus
   Arabameri, Alireza
   Blaschke, Thomas
   Pham, Quoc Bao
   Pham, Binh Thai
   Pandey, Manish
   Arora, Aman
   Linh, Nguyen Thi Thuy
   Costache, Iulia
TI Flash-Flood Potential Mapping Using Deep Learning, Alternating Decision Trees and Data Provided by Remote Sensing Sensors
SO SENSORS
LA English
DT Article
DE flash-flood potential index; remote sensing sensors; bivariate statistics; deep learning neural network; alternating decision trees; ensemble models
ID support vector machine; weights-of-evidence; spatial prediction; frequency ratio; logistic-regression; landslide hazard; soil-moisture; models; gis; classification
AB There is an evident increase in the importance that remote sensing sensors play in the monitoring and evaluation of natural hazards susceptibility and risk. The present study aims to assess the flash-flood potential values, in a small catchment from Romania, using information provided remote sensing sensors and Geographic Informational Systems (GIS) databases which were involved as input data into a number of four ensemble models. In a first phase, with the help of high-resolution satellite images from the Google Earth application, 481 points affected by torrential processes were acquired, another 481 points being randomly positioned in areas without torrential processes. Seventy percent of the dataset was kept as training data, while the other 30% was assigned to validating sample. Further, in order to train the machine learning models, information regarding the 10 flash-flood predictors was extracted in the training sample locations. Finally, the following four ensembles were used to calculate the Flash-Flood Potential Index across the Basca Chiojdului river basin: Deep Learning Neural Network-Frequency Ratio (DLNN-FR), Deep Learning Neural Network-Weights of Evidence (DLNN-WOE), Alternating Decision Trees-Frequency Ratio (ADT-FR) and Alternating Decision Trees-Weights of Evidence (ADT-WOE). The model's performances were assessed using several statistical metrics. Thus, in terms of Sensitivity, the highest value of 0.985 was achieved by the DLNN-FR model, meanwhile the lowest one (0.866) was assigned to ADT-FR ensemble. Moreover, the specificity analysis shows that the highest value (0.991) was attributed to DLNN-WOE algorithm, while the lowest value (0.892) was achieved by ADT-FR. During the training procedure, the models achieved overall accuracies between 0.878 (ADT-FR) and 0.985 (DLNN-WOE). K-index shows again that the most performant model was DLNN-WOE (0.97). The Flash-Flood Potential Index (FFPI) values revealed that the surfaces with high and very high flash-flood susceptibility cover between 46.57% (DLNN-FR) and 59.38% (ADT-FR) of the study zone. The use of the Receiver Operating Characteristic (ROC) curve for results validation highlights the fact that FFPIDLNN-WOE is characterized by the most precise results with an Area Under Curve of 0.96.
C1 [Costache, Romulus] Univ Bucharest, Res Inst, 90-92 Sos Panduri,5th Dist, Bucharest 050663, Romania.
   [Costache, Romulus] Natl Inst Hydrol & Water Management, Bucuresti Ploiesti Rd,97E,1st Dist, Bucharest 013686, Romania.
   [Arabameri, Alireza] Tarbiat Modares Univ, Dept Geomorphol, Tehran 3658117994, Iran.
   [Blaschke, Thomas] Univ Salzburg, Dept Geoinformat Z GIS, A-5020 Salzburg, Austria.
   [Pham, Quoc Bao] Ton Duc Thang Univ, Environm Qual Atmospher Sci & Climate Change Res, Ho Chi Minh City 700000, Vietnam.
   [Pham, Quoc Bao] Ton Duc Thang Univ, Fac Environm & Labour Safety, Ho Chi Minh City 700000, Vietnam.
   [Pham, Binh Thai] Univ Transport Technol, Geotech Engn Deparment, Hanoi 100000, Vietnam.
   [Pandey, Manish] Chandigarh Univ, Univ Ctr Res & Dev UCRD, Chandigarh 140413, Punjab, India.
   [Pandey, Manish] Chandigarh Univ, Univ Inst Engn, Dept Civil Engn, Chandigarh 140413, Punjab, India.
   [Arora, Aman] Jamia Millia Islamia, Fac Nat Sci, Dept Geog, New Delhi 110025, India.
   [Linh, Nguyen Thi Thuy] Duy Tan Univ, Inst Res & Dev, Danang 550000, Vietnam.
   [Linh, Nguyen Thi Thuy] Duy Tan Univ, Fac Environm & Chem Engn, Danang 550000, Vietnam.
   [Costache, Iulia] Univ Bucharest, Fac Geog, Bd Nicolae Balcescu 1,1st Dist, Bucharest 010041, Romania.
C3 University of Bucharest; Tarbiat Modares University; Salzburg University; Ton Duc Thang University; Ton Duc Thang University; Chandigarh University; Chandigarh University; Jamia Millia Islamia; Duy Tan University; Duy Tan University; University of Bucharest
RP Arabameri, A (corresponding author), Tarbiat Modares Univ, Dept Geomorphol, Tehran 3658117994, Iran.; Pham, QB (corresponding author), Ton Duc Thang Univ, Environm Qual Atmospher Sci & Climate Change Res, Ho Chi Minh City 700000, Vietnam.; Pham, QB (corresponding author), Ton Duc Thang Univ, Fac Environm & Labour Safety, Ho Chi Minh City 700000, Vietnam.
EM romulus.costache@icub.unibuc.ro; a.arabameri@modares.ac.ir; Thomas.Blaschke@sbg.ac.at; phambaoquoc@tdtu.edu.vn; binhpt@utt.edu.vn; manish07sep@gmail.com; aman.jmi01@gmail.com; nguyentthuylinh58@duytan.edu.vn; iulia.elena.costache@gmail.com
FU Austrian Science Fund (FWF) through the Doctoral College GIScience at the University of Salzburg [DKW 1237-N23]
CR Agarap A. F., 2018, ARXIV, V0, P0
   Ali SA, 2020, ECOL INDIC, V117, P0, DOI 10.1016/j.ecolind.2020.106620
   Arabameri A, 2020, J HYDROL, V587, P0, DOI 10.1016/j.jhydrol.2020.125007
   Avand M, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11102076
   Bezak N, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11102167
   Pham BT, 2018, GEOMORPHOLOGY, V303, P256, DOI 10.1016/j.geomorph.2017.12.008
   Cao C, 2016, SUSTAINABILITY-BASEL, V8, P0, DOI 10.3390/su8090948
   Chao LJ, 2018, J HYDROL, V558, P275, DOI 10.1016/j.jhydrol.2018.01.042
   Chapi K, 2017, ENVIRON MODELL SOFTW, V95, P229, DOI 10.1016/j.envsoft.2017.06.012
   Chen HZ, 2020, AGR WATER MANAGE, V240, P0, DOI 10.1016/j.agwat.2020.106303
   Chen HZ, 2019, IEEE T IND INFORM, V15, P5971, DOI 10.1109/TII.2019.2933582
   Chen W, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134979
   Chen W, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4795-7
   Choubin B, 2019, SCI TOTAL ENVIRON, V651, P2087, DOI 10.1016/j.scitotenv.2018.10.064
   Corrao MV, 2017, EARTH SURF PROC LAND, V42, P1560, DOI 10.1002/esp.4114
   Costache R, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010106
   Costache R, 2020, SCI TOTAL ENVIRON, V712, P0, DOI 10.1016/j.scitotenv.2019.136492
   Costache R, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.134514
   Costache R, 2019, STOCH ENV RES RISK A, V33, P1375, DOI 10.1007/s00477-019-01689-9
   Costache R, 2019, SCI TOTAL ENVIRON, V659, P1115, DOI 10.1016/j.scitotenv.2018.12.397
   Costache R, 2017, J EARTH SYST SCI, V126, P0, DOI 10.1007/s12040-017-0828-9
   Dano UL, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11030615
   De Rosa P, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11061145
   Bui DT, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134413
   Bui DT, 2019, SCI TOTAL ENVIRON, V668, P1038, DOI 10.1016/j.scitotenv.2019.02.422
   Bui DT, 2014, SOC EARTH SCI SER, V0, PP87, DOI 10.1007/978-3-319-05906-8_6
   Bui DT, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131589
   Elkhrachy I, 2015, EGYPT J REMOTE SENS, V18, P261, DOI 10.1016/j.ejrs.2015.06.007
   Freund Y, 1999, MACHINE LEARNING, V0, P124
   Fu XW, 2020, COMPUT NETW, V177, P0, DOI 10.1016/j.comnet.2020.107327
   Fu XW, 2020, RELIAB ENG SYST SAFE, V197, P0, DOI 10.1016/j.ress.2020.106815
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Halkos G, 2020, CLIM DEV, V12, P57, DOI 10.1080/17565529.2019.1596782
   Hong HY, 2015, CATENA, V133, P266, DOI 10.1016/j.catena.2015.05.019
   Hosseini FS, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.135161
   Huang Z., 2014, P INTERSPEECH 15 ANN, V0, P0
   Janizadeh S, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11195426
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Khosravi K, 2018, SCI TOTAL ENVIRON, V627, P744, DOI 10.1016/j.scitotenv.2018.01.266
   Khosravi K, 2016, NAT HAZARDS, V83, P947, DOI 10.1007/s11069-016-2357-2
   Lee S, 2007, LANDSLIDES, V4, P33, DOI 10.1007/s10346-006-0047-y
   Lee S, 2012, J ENVIRON MANAGE, V96, P91, DOI 10.1016/j.jenvman.2011.09.016
   Lin SW, 2008, APPL SOFT COMPUT, V8, P1505, DOI 10.1016/j.asoc.2007.10.012
   Liu YX, 2019, SIGNAL PROCESS-IMAGE, V78, P216, DOI 10.1016/j.image.2019.07.013
   Long Q, 2015, APPL MATH COMPUT, V251, P284, DOI 10.1016/j.amc.2014.11.064
   Lv ZH, 2020, IEEE INTERNET THINGS, V7, P5706, DOI 10.1109/JIOT.2019.2942719
   Lv ZH, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106300
   Nielsen M., 2015, NEURAL NETWORKS DEEP, V0, P0
   Pravalie R., 2014, FORUM GEOGR, VXIII, P39, DOI 10.5775/FG.2067-4635.2014.071.I
   Prvlie R., 2014, ROM REV REG STUD, V10, P2
   Qian JM, 2020, APL PHOTONICS, V5, P0, DOI 10.1063/5.0003217
   Qian JM, 2020, OPT LETT, V45, P1842, DOI 10.1364/OL.388994
   Bui QT, 2020, J HYDROL, V581, P0, DOI 10.1016/j.jhydrol.2019.124379
   Razandi Y, 2015, EARTH SCI INFORM, V8, P867, DOI 10.1007/s12145-015-0220-8
   Razavi Termeh S.V., 2018, J WATERSHED MANAG RE, V9, P67
   Sahana M, 2022, GEOCARTO INT, V37, P2747, DOI 10.1080/10106049.2020.1837262
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shi KB, 2020, FUZZY SET SYST, V394, P40, DOI 10.1016/j.fss.2019.09.001
   Shi KB, 2020, FUZZY SET SYST, V381, P1, DOI 10.1016/j.fss.2018.11.017
   Siahkamari S, 2018, GEOCARTO INT, V33, P927, DOI 10.1080/10106049.2017.1316780
   Singh C, 2018, OPTIK, V158, P127, DOI 10.1016/j.ijleo.2017.11.202
   Skentos A., 2018, ACTA GEOBALCANICA, V4, P7, DOI 10.18509/AGB.2018.01
   Tehrany MS, 2014, J HYDROL, V512, P332, DOI 10.1016/j.jhydrol.2014.03.008
   Tsai YH, 2019, AUTOMAT CONSTR, V107, P0, DOI 10.1016/j.autcon.2019.102923
   vanWesten C., 1997, ILWIS, V2, P1
   Wang S, 2020, ENVIRON MODELL SOFTW, V124, P0, DOI 10.1016/j.envsoft.2019.104607
   Wang Y, 2019, J ENVIRON MANAGE, V247, P712, DOI 10.1016/j.jenvman.2019.06.102
   Wu T, 2020, INFORM SCIENCES, V521, P231, DOI 10.1016/j.ins.2020.02.051
   Wu T, 2019, COMPLEXITY, V2019, P0, DOI 10.1155/2019/7875305
   Wu YL, 2020, CATENA, V187, P0, DOI 10.1016/j.catena.2019.104396
   Xiong LL, 2016, NONLINEAR ANAL-HYBRI, V19, P13, DOI 10.1016/j.nahs.2015.07.005
   Xiong Q, 2020, COMPUT MATH METHOD M, V2020, P0, DOI 10.1155/2020/9812019
   Xiong ZG, 2021, J SIGNAL PROCESS SYS, V93, P139, DOI 10.1007/s11265-019-01508-y
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang WC, 2018, ECOL INDIC, V89, P269, DOI 10.1016/j.ecolind.2018.02.015
   Zarea R., 2010, BULETINUL I POLITEHN, V0, P37
   Zhang K, 2020, ENVIRON MODELL SOFTW, V128, P0, DOI 10.1016/j.envsoft.2020.104704
   Zhang K, 2019, J HYDROL, V574, P903, DOI 10.1016/j.jhydrol.2019.04.087
   Zhang SP, 2021, ACTA GEOTECH, V16, P911, DOI 10.1007/s11440-020-01067-8
   Zhao CH, 2020, SYMMETRY-BASEL, V12, P0, DOI 10.3390/sym12050739
   Zhu JB, 2018, COMPLEXITY, V0, P0, DOI DOI 10.1155/2018/5928235
   Zhu Q, 2020, IEEE INTELL SYST, V35, P18, DOI 10.1109/MIS.2019.2942836
   Zuo C, 2020, OPT LASER ENG, V128, P0, DOI 10.1016/j.optlaseng.2020.106003
NR 84
TC 26
Z9 26
U1 7
U2 34
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD JAN 15
PY 2021
VL 21
IS 1
BP 
EP 
DI 10.3390/s21010280
PG 21
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA PP9UO
UT WOS:000606198700001
PM 33406613
DA 2023-04-26
ER

PT J
AU Shi, YJ
   Guo, EL
   Zhu, S
   Gu, J
   Bai, LF
   Han, J
AF Shi, Yingjie
   Guo, Enlai
   Zhu, Shuo
   Gu, Jie
   Bai, Lianfa
   Han, Jing
TI Research on optimal skip connection scale in learning-based scattering imaging
SO SEVENTH SYMPOSIUM ON NOVEL PHOTOELECTRONIC DETECTION TECHNOLOGY AND APPLICATIONS
LA English
DT Proceedings Paper
DE Scattering imaging; speckle correlation; deep learning; skip connections
ID phase retrieval
AB Strong scattering media bring difficulties to imaging in many fields such as medicine and astronomy. The deep learning method has a powerful fitting ability, which can be better applied in reconstructing the target behind the scattering medium. But the detail of the reconstructed target is often inaccurate. In this paper, the skip connection is added in the neural network to improve the accuracy of the reconstructed detail. This network can combine pixel-level information with high-level semantic information, and the information missed during the encoding process can be more involved in the final reconstruction process. 1100 handwritten characters are used as the targets hidden behind the ground glass. It is found that the quality of the reconstructed target is different when the skip connection is added to the network at different scales. The feature map visualization method is used to help us analyze the role of the skip connection. Meanwhile, PSNR (Peak Signal to Noise Ratio) is also used as an objective evaluation standard to evaluate the quality of reconstructed targets. According to subjective and objective evaluation criteria, conclusions can be drawn that the detail of targets can be better retained when the skip connection is added between the convolutional layer corresponding to the feature map of the size 64*64, and the average PSNR can be enhanced 1 dB compared with the network without skip connections. This work provides a reference for the fusion methods of different scale features in the computational optical imaging.
C1 [Shi, Yingjie; Guo, Enlai; Zhu, Shuo; Gu, Jie; Bai, Lianfa; Han, Jing] Nanjing Univ Sci & Technol, Sch Elect Engn & Optoelect, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Han, J (corresponding author), Nanjing Univ Sci & Technol, Sch Elect Engn & Optoelect, Nanjing 210094, Peoples R China.
FU National Natural Science Foundation of China [62031018, 61971227]; Jiangsu Provincial Key Research and Development Program [BE2018126]
CR Ando T, 2015, OPT EXPRESS, V23, P33902, DOI 10.1364/OE.23.033902
   Bertolotti J, 2012, NATURE, V491, P232, DOI 10.1038/nature11578
   FIENUP JR, 1982, APPL OPTICS, V21, P2758, DOI 10.1364/AO.21.002758
   Guo EL, 2020, OPT EXPRESS, V28, P2433, DOI 10.1364/OE.383911
   Horisaki R, 2016, OPT EXPRESS, V24, P13738, DOI 10.1364/OE.24.013738
   Katz O, 2014, NAT PHOTONICS, V8, P784, DOI 10.1038/nphoton.2014.189
   Kim M, 2015, OPT EXPRESS, V23, P12648, DOI 10.1364/OE.23.012648
   Li S, 2018, OPTICA, V5, P803, DOI 10.1364/OPTICA.5.000803
   Li YZ, 2018, OPTICA, V5, P1181, DOI 10.1364/OPTICA.5.001181
   Lu D, 2018, SPECKLE 2018 SPECKLE 2018, V10834, P578
   Schniter P, 2015, IEEE T SIGNAL PROCES, V63, P1043, DOI 10.1109/TSP.2014.2386294
   Wang K, 2015, NAT COMMUN, V6, P0, DOI 10.1038/ncomms8276
   Xie JP, 2019, J OPTICS-UK, V21, P0, DOI 10.1088/2040-8986/ab2972
   Xu XQ, 2018, OPT EXPRESS, V26, P15073, DOI 10.1364/OE.26.015073
NR 14
TC 1
Z9 1
U1 1
U2 7
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
J9 PROC SPIE
PD JUN 15
PY 2021
VL 11763
IS 
BP 
EP 
DI 10.1117/12.2586177
PG 7
WC Optics
SC Optics
GA BR8DM
UT WOS:000671015900033
DA 2023-04-26
ER

PT J
AU Alshaikhli, T
   Liu, W
   Maruyama, Y
AF Alshaikhli, Tamara
   Liu, Wen
   Maruyama, Yoshihisa
TI Simultaneous Extraction of Road and Centerline from Aerial Images Using a Deep Convolutional Neural Network
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE multitask learning; deep convolutional neural network; attention gates; aerial images; extraction of road and centerline; simultaneous extraction process; residual blocks
ID multiscale
AB The extraction of roads and centerlines from aerial imagery is considered an important topic because it contributes to different fields, such as urban planning, transportation engineering, and disaster mitigation. Many researchers have studied this topic as a two-separated task that affects the quality of extracted roads and centerlines because of the correlation between these two tasks. Accurate road extraction enhances accurate centerline extraction if these two tasks are processed simultaneously. This study proposes a multitask learning scheme using a gated deep convolutional neural network (DCNN) to extract roads and centerlines simultaneously. The DCNN is composed of one encoder and two decoders implemented on the U-Net backbone. The decoders are assigned to extract roads and centerlines from low-resolution feature maps. Before extraction, the images are processed within an encoder to extract the spatial information from a complex, high-resolution image. The encoder consists of the residual blocks (Res-Block) connected to a bridge represented by a Res-Block, and the bridge connects the two identical decoders, which consists of stacking convolutional layers (Conv.layer). Attention gates (AGs) are added to our model to enhance the selection process for the true pixels that represent road or centerline classes. Our model is trained on a dataset of high-resolution aerial images, which is open to the public. The model succeeds in efficiently extracting roads and centerlines compared with other multitask learning models.
C1 [Alshaikhli, Tamara; Liu, Wen; Maruyama, Yoshihisa] Chiba Univ, Grad Sch Engn, Chiba 2638522, Japan.
C3 Chiba University
RP Alshaikhli, T (corresponding author), Chiba Univ, Grad Sch Engn, Chiba 2638522, Japan.
EM tamara_alshaikhli@chiba-u.jp; wen.liu@chiba-u.jp; ymaruyam@tu.chiba-u.ac.jp
CR Alshaikhli T, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9224825
   Bastani F, 2018, PROC CVPR IEEE, V0, PP4720, DOI 10.1109/CVPR.2018.00496
   Baumgartner A, 1999, PHOTOGRAMM ENG REM S, V65, P777
   Bicego M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS
   Buslaev A, 2018, IEEE COMPUT SOC CONF, V0, PP197, DOI 10.1109/CVPRW.2018.00035
   Caruana R., 1993, ICML, V0, PP41, DOI 10.1016/b978-1-55860-307-3.50012-5
   Chen Chen, 2019, STATISTICAL ATLASES AND COMPUTATIONAL MODELS OF THE HEART. ATRIAL SEGMENTATION AND LV QUANTIFICATION CHALLENGES. 9TH INTERNATIONAL WORKSHOP, V0, P292, DOI 10.1007/978-3-030-12029-0_32
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Dal Poz A. P., 2006, PATTERN RECOGNITION AND IMAGE ANALYSIS, V16, P239, DOI 10.1134/S1054661806020118
   Goncalves GR, 2019, LECT NOTES COMPUT SC, V11896, P251, DOI 10.1007/978-3-030-33904-3_23
   Guo B., 2009, P 17 INT C GEOINF FA, V0, P1
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   HEIPKE C, 1995, P SOC PHOTO-OPT INS, V2486, P222, DOI 10.1117/12.213122
   Hu X., 2004, INT ARCH PHOTOGRAMME, V35 Pt B3, P288
   Huang X, 2009, INT J REMOTE SENS, V30, P1977, DOI 10.1080/01431160802546837
   Kendall A, 2018, PROC CVPR IEEE, V0, PP7482, DOI 10.1109/CVPR.2018.00781
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001
   Liu SC, 2019, AAAI CONF ARTIF INTE, V0, P9977
   Liu YH, 2019, IEEE T GEOSCI REMOTE, V57, P2043, DOI 10.1109/TGRS.2018.2870871
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Mattyus G, 2017, IEEE I CONF COMP VIS, V0, PP3458, DOI 10.1109/ICCV.2017.372
   Miao ZL, 2014, IEEE J-STARS, V7, P4762, DOI 10.1109/JSTARS.2014.2309613
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Oktay O, 2018, ARXIV180403999, V0, P0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saito S, 2016, J IMAGING SCI TECHN, V60, P0, DOI 10.2352/J.ImagingSci.Technol.2016.60.1.010402
   Shao ZF, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13020239
   Shen W, 2017, IEEE T IMAGE PROCESS, V26, P5298, DOI 10.1109/TIP.2017.2735182
   Shi WZ, 2014, IEEE T GEOSCI REMOTE, V52, P3359, DOI 10.1109/TGRS.2013.2272593
   Simonyan K, 2015, ARXIV, V0, P0
   Song MJ, 2004, PHOTOGRAMM ENG REM S, V70, P1365, DOI 10.14358/PERS.70.12.1365
   Sujatha C, 2015, EURASIP J IMAGE VIDE, V0, P0, DOI DOI 10.1186/s13640-015-0062-9
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Trinder JC, 1998, DIGIT SIGNAL PROCESS, V8, P215, DOI 10.1006/dspr.1998.0322
   Wang HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050446
   Wang WX, 2016, J TRAFFIC TRANSP ENG, V3, P271, DOI 10.1016/j.jtte.2016.05.005
   Wellmann T, 2020, LANDSCAPE URBAN PLAN, V204, P0, DOI 10.1016/j.landurbplan.2020.103921
   Xiao YQ, 2019, IEEE ACCESS, V7, P171272, DOI 10.1109/ACCESS.2019.2949269
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091461
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yao H, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121443
   Zhang MR, 2019, ARXIV, V0, P0
   Zhang XR, 2020, IEEE GEOSCI REMOTE S, V17, P1777, DOI 10.1109/LGRS.2019.2953523
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
NR 47
TC 1
Z9 1
U1 2
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD MAR 15
PY 2021
VL 10
IS 3
BP 
EP 
DI 10.3390/ijgi10030147
PG 15
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RD8JB
UT WOS:000633715800001
DA 2023-04-26
ER

PT J
AU Gadasin, DV
   Shvedov, AV
   Kuzin, IA
AF Gadasin, D., V
   Shvedov, A., V
   Kuzin, I. A.
TI Reconstruction of a Three-Dimensional Scene from its Projections in Computer Vision Systems
SO 2021 INTELLIGENT TECHNOLOGIES AND ELECTRONIC DEVICES IN VEHICLE AND ROAD TRANSPORT COMPLEX (TIRVED)
LA English
DT Proceedings Paper
DE Three-dimensional reconstruction; computer vision; depth map; scene reconstruction; three-dimensional images; stereo mapping; CNN
AB The problem of reconstructing a three-dimensional scene from its projections is one of the most urgent and studied among the problems solved by computer vision methods. Most often, such systems are implemented by creating geographically distributed complexes that require the transfer of a large amount of data between their components, which creates a large load on the transmission lines. Scene reconstruction using projections obtained from several observation points is a special case and is not always possible, especially when used in unmanned aerial vehicles or autonomous vehicles. To resolve these limitations, the possibility of using a computer stereoscopic vision system and a three-dimensional convolutional neural network capable of reconstructing a complete scene from a single image containing subjective characteristics of scene objects, such as color and depth, is considered in this work, creating its three-dimensional representation. The article describes the architecture and principle of operation of a neural network, and also builds a model of a computer stereo vision stand for image registration. An image formation algorithm is proposed for this model.
C1 [Gadasin, D., V; Shvedov, A., V; Kuzin, I. A.] Moscow Tech Univ Commun & Informat, Moscow, Russia.
C3 Moscow Technical University of Communications & Informatics
RP Gadasin, DV (corresponding author), Moscow Tech Univ Commun & Informat, Moscow, Russia.
EM dengadiplom@mail.ru; a.v.shvedov@mtuci.ru; IvanKuzin-forwork@yandex.ru
CR Davies ER, 2004, MACHINE VISION THEOR, V0, P0
   Fusiello A., 1997, IMAGE ANAL PROCESSIN, V1310, P0, DOI 10.1007/3-540-63507-6_259
   Gadasin DV, 2021, 2021 SYSTEMS OF SIGNAL SYNCHRONIZATION, V0, P0, DOI 10.1109/SYNCHROINFO51390.2021.9488349
   Gadasin DV, 2019, 2019 SYSTEMS OF SIGNALS GENERATING AND PROCESSING IN THE FIELD OF ON BOARD COMMUNICATIONS, V0, P0
   Gadasin D.V., 2021, 2021 WAVE ELECT ITS, V0, PP1, DOI 10.1109/WECONF51603.2021.9470710
   Gadasin D. V., 2020, 2020 INT C ENG MAN C, V0, PP1, DOI 10.1109/EMCTECH49634.2020.9261538
   Gadasin DV, 2018, 2018 SYSTEMS OF SIGNALS GENERATING AND PROCESSING IN THE FIELD OF ON BOARD COMMUNICATIONS, V0, P0
   Kotov A.P., 2016, MAT 2 INT C YOUTH SC, V0, P988
   Lucas B. D., 1981, P 7 INT JOINT C ART, V0, P0
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, V0, PP492, DOI 10.1109/ICCV.1998.710763
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Seitz Steven M, 2006, IEEE C COMP VIS PATT, V0, P0, DOI DOI 10.1109/CVPR.2006.19
   Shvedov A. V., 1900, V2021, V0, PP1, DOI 10.1109/IEEECONF51389.2021.9416072
   Shvedov A.V., 2020, P 2020 INT C ENG MAN, V0, P1
   Zbontar J, 2015, PROC CVPR IEEE, V0, PP1592, DOI 10.1109/CVPR.2015.7298767
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 16
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/TIRVED53476.2021.9639161
PG 8
WC Automation & Control Systems; Transportation Science & Technology
SC Automation & Control Systems; Transportation
GA BS8EE
UT WOS:000771713900040
DA 2023-04-26
ER

PT J
AU Zhang, YK
   Chen, MY
   Tian, DH
   Ding, LM
AF Zhang, Yukun
   Chen, Mengyuan
   Tian, Dehong
   Ding, Lingmei
TI Biomimetic SLAM Algorithm Based on Growing Self-Organizing Map
SO IEEE ACCESS
LA English
DT Article
DE Simultaneous localization and mapping; Navigation; Firing; Location awareness; Mobile robots; Real-time systems; Self-organizing feature maps; Cognitive maps; place cells; grid cells; SLAM; GSOM
ID grid cells; model; interference; ratslam
AB A Biomimetic SLAM Algorithm Based on Growing Self-Organizing Map (GSOM-BSLAM), inspired by spatial cognitive mechanism of mammalian hippocampus, is proposed to resolve uncertainty problems in location identification and lack of real-time performance in simultaneous localization and mapping. The algorithm connects activation characteristics of the place cell and neurons in the output layer of the neural network to construct a topological map of space using a self-organizing growable mapping neural network. It utilizes self-motion-aware information to obtain activation response of the place cell to estimate the robot position information, improving the localization accuracy and real-time performance of the system. Meanwhile, an accurate environmental cognitive map is finally created by incorporating color-depth images for closed-loop detection and error correction for spatial cell path integration. The proposed algorithm is validated using publicly available KITTI and St. Lucia datasets. The experimental results demonstrate that the proposed algorithm outperforms RatSALM by 37.8% and 36.5% in terms of localization accuracy and real-time performance, respectively, indicating good mapping capabilities.
C1 [Chen, Mengyuan] Anhui Polytech Univ, Sch Elect Engn, Wuhu 241000, Peoples R China.
   Anhui Polytech Univ, Key Lab Adv Percept & Intelligent Control High En, Wuhu 241000, Peoples R China.
C3 Anhui Polytechnic University; Anhui Polytechnic University
RP Chen, MY (corresponding author), Anhui Polytech Univ, Sch Elect Engn, Wuhu 241000, Peoples R China.
EM mychen@ahpu.edu.cn
FU National Natural Science Foundation of China [61903002]; University Synergy Innovation Project of Anhui Province [GXXT-2021-050]; Anhui Polytechnic University-Jiujiang District Industry Collaborative Innovation Special Foundation [2021cyxtb8]; Middle-Aged and Top-Notch Talent Project of Anhui Polytechnic University
CR Ai YB, 2020, IEEE ACCESS, V8, P162335, DOI 10.1109/ACCESS.2020.2991441
   Barry C, 2014, CURR BIOL, V24, PR330, DOI 10.1016/j.cub.2014.02.049
   Bavle H, 2020, IEEE ACCESS, V8, P60704, DOI 10.1109/ACCESS.2020.2983121
   Burgess N, 2007, HIPPOCAMPUS, V17, P801, DOI 10.1002/hipo.20327
   Bush D, 2015, NEURON, V87, P507, DOI 10.1016/j.neuron.2015.07.006
   [陈孟元 Chen Mengyuan], 2021, 计算机辅助设计与图形学学报 JOURNAL OF COMPUTER-AIDED DESIGN & COMPUTER GRAPHICS, V33, P712
   Chen MY, 2021, J ELECTRON INF TECHN, V43, P1003, DOI 10.11999/JEIT200025
   Couey JJ, 2013, NAT NEUROSCI, V16, P318, DOI 10.1038/nn.3310
   Cui LY, 2020, IEEE ACCESS, V8, P95301, DOI 10.1109/ACCESS.2020.2994348
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Erdem UM, 2012, EUR J NEUROSCI, V35, P916, DOI 10.1111/j.1460-9568.2012.08015.x
   Fuhs MC, 2006, J NEUROSCI, V26, P4266, DOI 10.1523/JNEUROSCI.4353-05.2006
   Grieves R. M., 2021, NATURE NEUROSCI, V4, P11
   Hasselmo ME, 2007, HIPPOCAMPUS, V17, P1252, DOI 10.1002/hipo.20374
   Juavinett AL, 2015, CURR BIOL, V25, P1759, DOI 10.1016/j.cub.2015.05.028
   Keinath AT, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.38169
   Knudsen EB, 2021, CELL, V184, P4640, DOI 10.1016/j.cell.2021.07.010
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Krupic J, 2012, SCIENCE, V337, P853, DOI 10.1126/science.1222403
   Milford M, 2007, ROBOT AUTON SYST, V55, P403, DOI 10.1016/j.robot.2006.12.006
   Milford MJ, 2004, IEEE INT CONF ROBOT, V0, PP403, DOI 10.1109/ROBOT.2004.1307183
   Montazeri H, 2011, NEUROCOMPUTING, V74, P1069, DOI 10.1016/j.neucom.2010.11.012
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723
   Moser EI, 2014, NAT REV NEUROSCI, V15, P466, DOI 10.1038/nrn3766
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   Soman K, 2018, EUR J NEUROSCI, V47, P1266, DOI 10.1111/ejn.13918
   Tian B, 2013, IEEE INT C INT ROBOT, V0, PP1562, DOI 10.1109/IROS.2013.6696557
   Wang WJ, 2021, HELIYON, V7, P0, DOI 10.1016/j.heliyon.2021.e06087
   Yuan ML, 2015, AAAI CONF ARTIF INTE, V0, P586
   Yuntian L., 2012, CONTROL DECIS, V36, P513
NR 31
TC 2
Z9 2
U1 1
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2021
VL 9
IS 
BP 134660
EP 134671
DI 10.1109/ACCESS.2021.3113311
PG 12
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA WC2PO
UT WOS:000704104000001
DA 2023-04-26
ER

PT J
AU Boughariou, E
   Allouche, N
   Ben Brahim, F
   Nasri, G
   Bouri, S
AF Boughariou, Emna
   Allouche, Nabila
   Ben Brahim, Fatma
   Nasri, Ghada
   Bouri, Salem
TI Delineation of groundwater potentials of Sfax region, Tunisia, using fuzzy analytical hierarchy process, frequency ratio, and weights of evidence models
SO ENVIRONMENT DEVELOPMENT AND SUSTAINABILITY
LA English
DT Article
DE Groundwater potential; Fuzzy analytical hierarchy process; Frequency ratio; Weights of evidence; Water management; Tunisia
ID geographical information-system; of-evidence; logistic-regression; multicriteria evaluation; aquifer vulnerability; spatial-analysis; coastal aquifer; neural-networks; drastic model; random forest
AB Groundwater in semiarid regions is of extreme importance due to limited water resources and increasing population demand. Hence, a better knowledge of aquifer potentialities is required for better management of this precious resource. This study aims to assess the groundwater potential map (GPM) by both statistical methods and geographical information system (GIS) in Sfax region, Tunisia. A number of 11,868 wells in the region were mapped in GIS and divided into two data sets: 8308 wells (70%) were selected in a random way and defined as training, wells while the remaining ones (3560 as 30%) were considered as testing wells for model validation. First, the groundwater conditioning factors, namely altitude, slope, lithology, drainage density, lineament density and land use maps, were evaluated and then processed by the fuzzy analytical hierarchy process (FAHP), frequency ratio (FR), and weights of evidence (WOE) statistical models. Then, the groundwater potential index (GWPI) was generated from an overlap of the weighted and rated of all the conditioning factors for the three methods. The groundwater potential maps were produced in ArcGIS 10.3 for the three models and classified by means of the quantile classification method. As a final step, the receiver operating characteristics (ROC) curves validated these maps. The validation results show from the areas under the curves (AUC) that the WOE model (AUC = 71.4%) performs similarly to the FR model (AUC = 71.1%), and both are slightly better than the FAHP (AUC = 65.1%) model. Thus, the delineation of groundwater potential zones supports the decision makers for the management of the aquifer exploitation. The appropriate groundwater potential map is established for a suitable management and a better planning of the water resources. Preventive works in low potential coastal areas should be conducted in the present and considered for a long-term management. Given the close results of the three adopted methods, it is possible to apply them in other regions with a consideration of their specific characteristics.
C1 [Boughariou, Emna; Allouche, Nabila; Ben Brahim, Fatma; Nasri, Ghada; Bouri, Salem] ENI Sfax, LR3E, Sfax, Tunisia.
   [Ben Brahim, Fatma] Univ Gabes, Fac Sci Gabes, Gabes, Tunisia.
   [Bouri, Salem] Univ Sfax, Fac Sci Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Universite de Gabes; Universite de Sfax; Faculty of Sciences Sfax
RP Boughariou, E (corresponding author), ENI Sfax, LR3E, Sfax, Tunisia.
EM boughariouemna@live.fr
CR Abd Manap M, 2014, ARAB J GEOSCI, V7, P711, DOI 10.1007/s12517-012-0795-z
   Al-Abadi AM, 2015, ENVIRON EARTH SCI, V74, P1109, DOI 10.1007/s12665-015-4097-0
   Allouche N, 2015, J WATER SUPPLY RES T, V64, P719, DOI 10.2166/aqua.2015.105
   Antonakos AK, 2007, J HYDROL, V333, P288, DOI 10.1016/j.jhydrol.2006.08.014
   Aryafar A, 2013, ENVIRON EARTH SCI, V68, P2313, DOI 10.1007/s12665-012-1910-x
   Ayadi R, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5445-4
   Ben Brahim F, 2013, ARAB J GEOSCI, V6, P2089, DOI 10.1007/s12517-011-0481-6
   Bonham-Carter GF., 1994, COMPUT METHODS GEOSC, V13, P398
   Bouaziz S, 2002, TECTONOPHYSICS, V357, P227, DOI 10.1016/S0040-1951(02)00370-0
   Boughariou E, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3408-7
   Boughariou E, 2015, ARAB J GEOSCI, V8, P5203, DOI 10.1007/s12517-014-1512-x
   Bouri S, 2008, ENVIRON GEOL, V53, P1421, DOI 10.1007/s00254-007-0751-5
   BUCKLEY JJ, 1985, FUZZY SET SYST, V17, P233, DOI 10.1016/0165-0114(85)90090-9
   Chang D.Y., 1992, EXTENT ANAL SYNTHETI, VVolume 1, P352
   Chen W, 2018, SCI TOTAL ENVIRON, V634, P853, DOI 10.1016/j.scitotenv.2018.04.055
   Cheng CH, 1999, EUR J OPER RES, V116, P423, DOI 10.1016/S0377-2217(98)00156-8
   Chenini I, 2010, WATER RESOUR MANAG, V24, P921, DOI 10.1007/s11269-009-9479-1
   Corsini A, 2009, GEOMORPHOLOGY, V111, P79, DOI 10.1016/j.geomorph.2008.03.015
   Daneshfar M., 2015, J APPL HYDROL, V2, P45
   DGRE, 2005, REPORT CO SGF INC SU, V0, P460
   Douglas SH, 2018, PHYS GEOGR, V39, P487, DOI 10.1080/02723646.2017.1406300
   Ebrahimi S. H., 2019, MODIFICATION DRASTIC, V0, P0
   Elmahdy SI, 2015, ARAB J GEOSCI, V8, P2405, DOI 10.1007/s12517-014-1327-9
   Fenta AA, 2015, HYDROGEOL J, V23, P195, DOI 10.1007/s10040-014-1198-x
   Ghribi R., 2010, THESIS U SFAX, V0, P256
   Gontara M., 2016, TUNISIA ARAB J GEOSC, V9, P1
   Hagedorn B, 2018, SCI TOTAL ENVIRON, V624, P1550, DOI 10.1016/j.scitotenv.2017.12.115
   Hua SS, 2015, WATER RES, V85, P31, DOI 10.1016/j.watres.2015.08.007
   Jha MK, 2010, HYDROGEOL J, V18, P1713, DOI 10.1007/s10040-010-0631-z
   Jmal I, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-3143-5
   Kahraman C, 2004, INT J PROD ECON, V87, P171, DOI 10.1016/S0925-5273(03)00099-9
   Kahraman C, 2008, SPRINGER SER OPTIM A, V16, P1, DOI 10.1007/978-0-387-76813-7
   Karan SK, 2018, LAND DEGRAD DEV, V29, P2351, DOI 10.1002/ldr.2990
   Kishore P, 2016, J MANUF SCI PROD, V16, P51, DOI 10.1515/jmsp-2015-0017
   Kordestani MD, 2019, HYDROGEOL J, V27, P211, DOI 10.1007/s10040-018-1848-5
   Kumar T, 2014, WATER RESOUR MANAG, V28, P4449, DOI 10.1007/s11269-014-0663-6
   Kura NU, 2015, ENVIRON SCI POLLUT R, V22, P1512, DOI 10.1007/s11356-014-3444-0
   Lee S, 2012, J ENVIRON MANAGE, V96, P91, DOI 10.1016/j.jenvman.2011.09.016
   Machiwal D, 2011, WATER RESOUR MANAG, V25, P1359, DOI 10.1007/s11269-010-9749-y
   Masetti M., 2007, NAT RESOUR RES, V16, P109, DOI 10.1007/s11053-007-9045-6
   Miraki S, 2019, WATER RESOUR MANAG, V33, P281, DOI 10.1007/s11269-018-2102-6
   Moghaddam DD, 2015, ARAB J GEOSCI, V8, P913, DOI 10.1007/s12517-013-1161-5
   Mohammadi-Behzad HR, 2019, CARBONATE EVAPORITE, V34, P1307, DOI 10.1007/s13146-018-0420-7
   Mokadem N, 2018, J AFR EARTH SCI, V141, P107, DOI 10.1016/j.jafrearsci.2018.02.007
   Msaddek MH, 2019, GEOL Q, V63, P3, DOI 10.7306/gq.1451
   Nampak H, 2014, J HYDROL, V513, P283, DOI 10.1016/j.jhydrol.2014.02.053
   Nejad SG, 2017, GEOCARTO INT, V32, P167, DOI 10.1080/10106049.2015.1132481
   NIM, 2018, ANN HYDROLOGICAL REP, V0, P0
   Oh HJ, 2011, J HYDROL, V399, P158, DOI 10.1016/j.jhydrol.2010.12.027
   Ozdagoglu A., 2007, COMP AHP FUZZY AHP M, V0, P0
   Ozdemir A, 2011, J HYDROL, V411, P290, DOI 10.1016/j.jhydrol.2011.10.010
   Rahmati O, 2016, CATENA, V137, P360, DOI 10.1016/j.catena.2015.10.010
   Rahmati O, 2015, ARAB J GEOSCI, V8, P7059, DOI 10.1007/s12517-014-1668-4
   Razandi Y, 2015, EARTH SCI INFORM, V8, P867, DOI 10.1007/s12145-015-0220-8
   RCAD : Sfax, 2014, RAPPORT ANNUEL LANNE, V0, P0
   Reis AP, 2004, APPL GEOCHEM, V19, P623, DOI 10.1016/j.apgeochem.2003.09.003
   Saaty T, 1980, ANAL HIERARCHY PROCE, V0, P287
   Sener E, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3510-x
   Sener E, 2015, ENVIRON EARTH SCI, V73, P8405, DOI 10.1007/s12665-014-4001-3
   Shekhar S, 2015, GEOCARTO INT, V30, P402, DOI 10.1080/10106049.2014.894584
   Smida Habib, 2010, SECHERESSE (MONTROUGE), V21, P131, DOI 10.1684/sec.2010.0246
   Tahmassebipoor N, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2166-z
   Tehrany MS, 2014, J HYDROL, V512, P332, DOI 10.1016/j.jhydrol.2014.03.008
   Trabelsi R., 2005, TUNISIE GEOSCI, V337, P515, DOI 10.1016/J.CRTE.2005.01.010
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Zabihi M, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5424-9
   Zeinivand H, 2018, GEOCARTO INT, V33, P651, DOI 10.1080/10106049.2017.1289560
NR 67
TC 12
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1387-585X
EI 1573-2975
J9 ENVIRON DEV SUSTAIN
JI Environ. Dev. Sustain.
PD OCT 15
PY 2021
VL 23
IS 10
BP 14749
EP 14774
DI 10.1007/s10668-021-01270-x
EA FEB 2021
PG 26
WC Green & Sustainable Science & Technology; Environmental Sciences
SC Science & Technology - Other Topics; Environmental Sciences & Ecology
GA UE1ZX
UT WOS:000616877200001
DA 2023-04-26
ER

PT J
AU Mohd, MRS
   Ruslan, FA
   Johari, J
AF Mohd, Mohd Rizman Sultan
   Ruslan, Fazlina Ahmat
   Johari, Juliana
TI GIS-AIDED GEOGRAPHICAL AND METEOROLOGICAL DATA OVERVIEW OF SOLAR RADIATION MAPPING FOR MALAYSIA - AN EXPLANATORY STUDY BASED ON SOLAR RADIATION PREDICTION MODELING USING NEURAL NETWORK APPROACH
SO JURNAL TEKNOLOGI-SCIENCES & ENGINEERING
LA English
DT Article
DE GIS; Spatial; Solar Radiation; Prediction Modeling; Neural Network
ID climate-change
AB Solar radiation mapping has used geographical and meteorological data. To obtain geographical and meteorological data, a Geographic Information System (GIS) is required. GIS is defined as an integrated geographic resource that presents data in terms of spatial information. This data is important for Neural Networks as it will be used as input parameters for the development of solar radiation prediction models. Solar radiation prediction is one way to map the sun's rays in certain places where there are insufficient resources or space to build a complete solar radiation measurement station. Since predictions about solar radiation require meteorological and geographical data, this paper will give an overview of GIS-assisted geographical and meteorological data to be used as input parameters for solar radiation mapping which will eventually be used as input for prediction models developed for the whole country of Malaysia using Neural Networks. Based on the results, the prediction model developed managed to obtain a coefficient of determination, R-2 value of 0.9329.
C1 [Mohd, Mohd Rizman Sultan; Ruslan, Fazlina Ahmat; Johari, Juliana] Univ Teknol MARA UiTM Shah Alam, Fac Elect Engn, Shah Alam 40450, Selangor, Malaysia.
C3 Universiti Teknologi MARA
RP Mohd, MRS (corresponding author), Univ Teknol MARA UiTM Shah Alam, Fac Elect Engn, Shah Alam 40450, Selangor, Malaysia.
EM engr_rizman@outlook.com
FU Research Management Institute (RMI); Innovative Electromobility Research Laboratory (ITEM); School of Electrical Engineering, College of Engineering, Universiti Teknologi MARA Shah Alam
CR Abdullah WSW, 2019, ENERGIES, V12, P0, DOI 10.3390/en12122437
   Abdurrahman M, 2019, DUTSE J PURE APPL SC, V5, P123
   Abdurrahman M., 2019, FUDMA J SCI, V3, P301
   Acquah P. C., 2017, REV INT GEOGRAPHICAL, V0, P0
   Andreev DV, 2020, IOP C SER EARTH ENV, V421, P0, DOI 10.1088/1755-1315/421/4/042001
   [Anonymous], 2020, ASIAN J BASIC SCI RE, V2, P86, DOI 10.38177/AJBSR.2020.2209, 10.38177/AJBSR.2020.2209
   Babatunde D.E., 2020, INT J ENERGY EC POLI, V10, P250, DOI 10.32479/ijeep.8691
   Belmahdi B, 2020, OPTIK, V219, P0, DOI 10.1016/j.ijleo.2020.165207
   Blal M, 2020, MEASUREMENT, V152, P0, DOI 10.1016/j.measurement.2019.107348
   Brewer J, 2015, RENEW ENERG, V81, P825, DOI 10.1016/j.renene.2015.04.017
   Chakchak J, 2021, MEASUREMENT, V176, P0, DOI 10.1016/j.measurement.2021.109159
   Cheng CH, 2020, ENERGIES, V13, P0, DOI 10.3390/en13195164
   Chun Y. F., 2019, CIGRE IEC 2019 C EHV, V0, P0
   Davis RE, 2016, ENVIRON RES, V144, P106, DOI 10.1016/j.envres.2015.10.014
   Diez FJ, 2021, AGRONOMY-BASEL, V11, P0, DOI 10.3390/agronomy11030495
   Dymkova SS, 2020, 2020 SYSTEMS OF SIGNAL SYNCHRONIZATION, V0, P0
   Enriquez-Velasquez EA, 2020, ENERGIES, V13, P0, DOI 10.3390/en13246501
   Fan JL, 2020, J CLEAN PROD, V248, P0, DOI 10.1016/j.jclepro.2019.119264
   Fan JL, 2020, RENEW ENERG, V145, P2034, DOI 10.1016/j.renene.2019.07.104
   Feng Y, 2020, ENERG CONVERS MANAGE, V203, P0, DOI 10.1016/j.enconman.2019.112236
   Grandi C, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17041357
   Guijo-Rubio D, 2020, ENERGY, V210, P0, DOI 10.1016/j.energy.2020.118374
   Guo M, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7101028
   Gurel AE, 2020, J CLEAN PROD, V277, P0, DOI 10.1016/j.jclepro.2020.122353
   Guzman R, 2017, J GEOPHYS RES-ATMOS, V122, P1066, DOI 10.1002/2016JD025946
   Huibin L., 2016, CHIN INT C EL DISTR, V0, P0, DOI DOI 10.1109/CICED.2016.7576037
   Izhari Fahmi, 2020, IOP CONFERENCE SERIES: MATERIALS SCIENCE AND ENGINEERING, V725, P0, DOI 10.1088/1757-899X/725/1/012103
   Jeong JS, 2017, ENERGIES, V10, P0, DOI 10.3390/en10122095
   Kabir HMD, 2021, APPL SOFT COMPUT, V99, P0, DOI 10.1016/j.asoc.2020.106878
   Kaplan AG, 2020, RENEW ENERG, V146, P2462, DOI 10.1016/j.renene.2019.08.095
   Kisi O, 2019, APPL ENERG, V241, P184, DOI 10.1016/j.apenergy.2019.03.089
   Kumar N, 2021, J HYDROL, V594, P0, DOI 10.1016/j.jhydrol.2020.125642
   Kumar N, 2020, AGR WATER MANAGE, V239, P0, DOI 10.1016/j.agwat.2020.106259
   Kweku D., 2018, J SCI RES REP, V0, P0, DOI DOI 10.9734/JSRR/2017/39630
   Lacour A, 2018, J CLIMATE, V31, P9293, DOI 10.1175/JCLI-D-18-0023.1
   Lee HJ, 2017, ENERGIES, V10, P0, DOI 10.3390/en10050594
   Lee J, 2020, ENERG CONVERS MANAGE, V208, P0, DOI 10.1016/j.enconman.2020.112582
   Linhua W., 2021, APPL SCI, V11, P0
   Liu ZL, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, V0, P0
   Maleki SAM, 2017, ENERGIES, V10, P0, DOI 10.3390/en10010134
   Barrera JM, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12176915
   Masuda R, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171962
   Mensour ON, 2017, ENRGY PROCED, V139, P778, DOI 10.1016/j.egypro.2017.11.287
   Mierzejowska A., 2018, J WATER LAND DEV, V39, P101, DOI 10.2478/jwld-2018-0064
   Mikhaylov A, 2020, ENTREP SUSTAIN ISS, V7, P2897, DOI 10.9770/jesi.2020.7.4(21)
   Moffatt JE, 2020, APPL SPECTROSC REV, V55, P327, DOI 10.1080/05704928.2019.1672712
   Mohd M. R. S., 2020, 2020 IEEE 8 C SYST P, V0, P0
   Mousavi SM, 2017, ENERG CONVERS MANAGE, V153, P671, DOI 10.1016/j.enconman.2017.09.040
   Nnabuenyi H.O., 2017, AM J RENEWABLE SUSTA, V3, P8
   Obukhov SG, 2018, IOP CONF SER-MAT SCI, V363, P0, DOI 10.1088/1757-899X/363/1/012021
   Ojo O. S., 2020, J ADV SCI ENG, V3, P0
   Olubayo M.B., 2020, ENERGIES, V13, P0, DOI 10/3390/en13102488
   Pang ZH, 2020, RENEW ENERG, V156, P279, DOI 10.1016/j.renene.2020.04.042
   Qin Y, 2021, SOL ENERGY, V220, P119, DOI 10.1016/j.solener.2021.03.029
   Ramadhan RAA, 2021, RENEW ENERG, V178, P1006, DOI 10.1016/j.renene.2021.06.079
   Razmjoo A, 2016, J FUNDAM RENEWABLE E, V6, P214, DOI 10.4172/2090-4541.1000214
   Richardson MI, 2018, PLANET SPACE SCI, V164, P132, DOI 10.1016/j.pss.2018.07.003
   Saklani N, 2019, INT J ENG MANAG RES, V09, P24
   Selvakumar AI, 2017, 2017 2 INT C COMMUNI, V0, PP302, DOI 10.1109/CESYS.2017.8321285
   Sharma S. K., 2019, INT J COMPUTER NETWO, V9, P0
   Shin Y, 2020, J CLEAN PROD, V277, P0, DOI 10.1016/j.jclepro.2020.124124
   Shrestha AK, 2019, INT J PHOTOENERGY, V2019, P0, DOI 10.1155/2019/8369231
   Siecker J, 2017, RENEW SUST ENERG REV, V79, P192, DOI 10.1016/j.rser.2017.05.053
   Souza PVD, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106275
   Spiridonov V., 2021, FUNDAMENTALS METEORO, V0, P0, DOI DOI 10.1007/978-3-030-52655-9_9
   Tang KHD, 2019, SCI TOTAL ENVIRON, V650, P1858, DOI 10.1016/j.scitotenv.2018.09.316
   Traore S, 2017, WATER RESOUR MANAG, V31, P4891, DOI 10.1007/s11269-017-1784-5
   Tukimat N. N. A., 2021, IOP CONFERENCE SERIES: EARTH AND ENVIRONMENTAL SCIENCE, V682, P0, DOI 10.1088/1755-1315/682/1/012044
   Varnai T, 2018, ATMOSPHERE-BASEL, V9, P0, DOI 10.3390/atmos9110430
   Wang X, 2018, CHIN AUTOM CONGR, V0, PP2265, DOI 10.1109/CAC.2018.8623195
   Wong CL, 2016, WATER-SUI, V8, P0, DOI 10.3390/w8110500
   Zhang QW, 2018, ADV METEOROL, V2018, P0, DOI 10.1155/2018/3894831
NR 72
TC 0
Z9 0
U1 0
U2 1
PU PENERBIT UTM PRESS
PI JOHOR
PA PENERBIT UTM PRESS, SKUDAI, JOHOR, 81310, MALAYSIA
SN 0127-9696
EI 2180-3722
J9 J TEKNOL
JI J. Teknol.-Sci Eng.
PD NOV 15
PY 2021
VL 83
IS 6
BP 19
EP 33
DI 10.11113/jurnalteknologi.v83.16634
PG 15
WC Engineering, Multidisciplinary
SC Engineering
GA YO2CD
UT WOS:000747752000002
DA 2023-04-26
ER

PT J
AU Zhang, WW
   Li, JJ
   Hua, Z
AF Zhang, Wanwan
   Li, Jinjiang
   Hua, Zhen
TI Attention-Based Tri-UNet for Remote Sensing Image Pan-Sharpening
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Spatial resolution; Feature extraction; Image reconstruction; Image fusion; Sensors; Superresolution; Attention mechanism; convolutional neural networks (CNNs); multispectral (MS) images; pan-sharpening; panchromatic (PAN) images
ID fusion
AB Pan-sharpening of remote sensing images is a significant method for integrating remote sensing information in the field of computer vision, where complementary and redundant information between multispectral (MS) images and panchromatic (PAN) images is used to generate high-resolution MS (HRMS) images. Inspired by the remarkable achievements of convolutional neural networks in a variety of computer-vision tasks, we incorporate domain-specific knowledge to design our attention-based triangle UNet (Tri-UNet) architecture to generate high-quality HRMS images. The attention-based Tri-UNet is mainly divided into the following three modules: 1) feature extraction; 2) feature fusion; and 3) image reconstruction. In the feature extraction step, the feature extraction module simultaneously extracts spectral and spatial information from the MS and PAN images. The feature maps are then fused in the feature fusion module, which makes the final feature image contain rich spectral and spatial information. Finally, the image reconstruction module generates a high-resolution MS image that uses the fused image as input. The attention mechanism is introduced into the image reconstruction module to make the network focus more on key information in the feature image. The experimental results demonstrate that the proposed method can generate high-quality HRMS images. A quantitative comparison and qualitative analysis of the experimental results indicate that our method is superior to the existing methods.
C1 [Zhang, Wanwan; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology & Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
EM wwwanzhang@163.com; lijinjiang@gmail.com; huazhen66@foxmail.com
FU National Natural Science Foundation of China [61772319, 62002200, 61976125, 61976124]; Shandong Natural Science Foundation of China [ZR2017MF049]
CR Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Eismann MT, 2004, IEEE T GEOSCI REMOTE, V42, P1924, DOI 10.1109/TGRS.2004.830644
   Fauvel M, 2009, EURASIP J ADV SIG PR, V0, P0, DOI DOI 10.1155/2009/783194
   Feng XX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12061009
   Gao LR, 2021, IEEE T GEOSCI REMOTE, V59, P2269, DOI 10.1109/TGRS.2020.3000684
   GILLESPIE AR, 1987, REMOTE SENS ENVIRON, V22, P343, DOI 10.1016/0034-4257(87)90088-5
   Han C, 2016, IEEE J-STARS, V9, P439, DOI 10.1109/JSTARS.2015.2507859
   Hong DF, 2019, IEEE T GEOSCI REMOTE, V57, P4349, DOI 10.1109/TGRS.2018.2890705
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V147, P193, DOI 10.1016/j.isprsjprs.2018.10.006
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Hu XC, 2019, PROC CVPR IEEE, V0, PP1575, DOI 10.1109/CVPR.2019.00167
   Kwan C, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091416
   Li G, 2019, IEEE T GEOSCI REMOTE, V57, P8506, DOI 10.1109/TGRS.2019.2921342
   Li P., 2020, P IEEE CVF C COMP VI, V0, P11534
   Li ST, 2011, IEEE T GEOSCI REMOTE, V49, P738, DOI 10.1109/TGRS.2010.2067219
   Liu D, 2020, J APPL REMOTE SENS, V14, P0, DOI 10.1117/1.JRS.14.016518
   Liu J, 2020, PROC CVPR IEEE, V0, PP2356, DOI 10.1109/CVPR42600.2020.00243
   Liu XY, 2020, INFORM FUSION, V55, P1, DOI 10.1016/j.inffus.2019.07.010
   Liu XY, 2018, IEEE IMAGE PROC, V0, PP873, DOI 10.1109/ICIP.2018.8451049
   Liu ZS, 2019, IEEE INT CONF COMP V, V0, PP3517, DOI 10.1109/ICCVW.2019.00436
   Ma JY, 2020, INFORM FUSION, V62, P110, DOI 10.1016/j.inffus.2020.04.006
   Masi G, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070594
   Rao YZ, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017), V0, P0
   Rush A.M., 2015, C EMPIRICAL METHODS, V0, P379
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Shandoosti HR, 2016, INFORM FUSION, V27, P150, DOI 10.1016/j.inffus.2015.06.006
   Shao ZM, 2020, IEEE GEOSCI REMOTE S, V17, P1573, DOI 10.1109/LGRS.2019.2949745
   Shen HF, 2016, IEEE T GEOSCI REMOTE, V54, P7135, DOI 10.1109/TGRS.2016.2596290
   Tai Y, 2017, IEEE I CONF COMP VIS, V0, PP4549, DOI 10.1109/ICCV.2017.486
   Tan W, 2020, IEEE ACCESS, V8, P42540, DOI 10.1109/ACCESS.2020.2977299
   Tian Z, 2019, PROC CVPR IEEE, V0, PP3121, DOI 10.1109/CVPR.2019.00324
   Upla KP, 2015, IEEE T GEOSCI REMOTE, V53, P3210, DOI 10.1109/TGRS.2014.2371812
   Valizadeh SA, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), V0, PP1184, DOI 10.1109/ISTEL.2012.6483168
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wei Q, 2015, IEEE T IMAGE PROCESS, V24, P4109, DOI 10.1109/TIP.2015.2458572
   Wei YC, 2017, IEEE GEOSCI REMOTE S, V14, P1795, DOI 10.1109/LGRS.2017.2736020
   Wu HL, 2019, IEEE ACCESS, V7, P46562, DOI 10.1109/ACCESS.2019.2908968
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y, 2018, IEEE GEOSCI REMOTE S, V15, P734, DOI 10.1109/LGRS.2018.2810219
   Ye FJ, 2019, MULTIMED TOOLS APPL, V78, P14683, DOI 10.1007/s11042-018-6850-3
   Yin Wenpeng, 2016, T ASSOC COMPUT LING, V4, P259, DOI 10.1162/TACL_A_00097
   Yokoya N, 2012, IEEE T GEOSCI REMOTE, V50, P528, DOI 10.1109/TGRS.2011.2161320
   Yuan QQ, 2018, IEEE J-STARS, V11, P978, DOI 10.1109/JSTARS.2018.2794888
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zheng K, 2021, IEEE T GEOSCI REMOTE, V59, P2487, DOI 10.1109/TGRS.2020.3006534
   Zhong JY, 2016, SENS IMAGING, V17, P0, DOI 10.1007/s11220-016-0135-6
   Zhu XX, 2016, IEEE T GEOSCI REMOTE, V54, P2664, DOI 10.1109/TGRS.2015.2504261
NR 54
TC 13
Z9 13
U1 5
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3719
EP 3732
DI 10.1109/JSTARS.2021.3068274
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RO0RM
UT WOS:000640757900009
DA 2023-04-26
ER

PT J
AU Feng, JF
   Liang, YK
   Li, L
AF Feng, Jiangfan
   Liang, Yukun
   Li, Lin
TI Anomaly Detection in Videos Using Two-Stream Autoencoder with Post Hoc Interpretability
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
LA English
DT Article
ID abnormal event detection
AB The growing interest in deep learning approaches to video surveillance raises concerns about the accuracy and efficiency of neural networks. However, fast and reliable detection of abnormal events is still a challenging work. Here, we introduce a two-stream approach that offers an autoencoder-based structure for fast and efficient detection to facilitate anomaly detection from surveillance video without labeled abnormal events. Furthermore, we present post hoc interpretability of feature map visualization to show the process of feature learning, revealing uncertain and ambiguous decision boundaries in the video sequence. Experimental results on Avenue, UCSD Ped2, and Subway datasets show that our method can detect abnormal events well and explain the internal logic of the model at the object level.
C1 [Feng, Jiangfan; Liang, Yukun] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing, Peoples R China.
   [Li, Lin] Chongqing Geomat & Remote Sensing Ctr, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Feng, JF (corresponding author), Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing, Peoples R China.
EM fengjf@cqupt.edu.cn
FU National Nature Science Foundation of China [41971365]; Chongqing Research Program of Basic Science and Frontier Technology [cstc2019jcyj-msxmX0131]
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Dosovitskiy A, 2016, PROC CVPR IEEE, V0, PP4829, DOI 10.1109/CVPR.2016.522
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, P0, DOI 10.1016/j.cviu.2020.102920
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, V0, PP6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, V0, PP1933, DOI 10.1109/CVPR.2016.213
   Guo X., 2021, IEEE T GEOSCI ELECT, V0, PP1, DOI 10.1109/TGRS.2021.3077062
   Hasan M, 2016, PROC CVPR IEEE, V0, PP733, DOI 10.1109/CVPR.2016.86
   Vu H, 2019, AAAI CONF ARTIF INTE, V0, P5216
   Vu H, 2017, LECT NOTES ARTIF INT, V10234, P641, DOI 10.1007/978-3-319-57454-7_50
   Ionescu RT, 2019, IEEE WINT CONF APPL, V0, PP1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, V0, PP2914, DOI 10.1109/ICCV.2017.315
   Jeon YS, 2021, IEEE J BIOMED HEALTH, V25, P2388, DOI 10.1109/JBHI.2021.3081355
   Kingma D. P., 2013, ARXIV13126114, V0, P0
   Kiran BR, 2018, J IMAGING, V4, P0, DOI 10.3390/jimaging4020036
   Kwon YH, 2019, PROC CVPR IEEE, V0, PP1811, DOI 10.1109/CVPR.2019.00191
   Liu W, 2018, PROC CVPR IEEE, V0, PP6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, V0, PP2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, V0, PP341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, V0, PP439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, V0, PP1975, DOI 10.1109/CVPR.2010.5539872
   Mahendran A, 2015, PROC CVPR IEEE, V0, PP5188, DOI 10.1109/CVPR.2015.7299155
   Oliva A., 2014, OBJECT DETECTORS EME, V0, P0
   Patraucean V., 2016, ICLR WORKSH, V0, P0
   Pianpanit T., 2021, IEEE SENS J, V0, P0, DOI DOI 10.1109/JSEN.2021.3077949
   Qiang Y, 2021, IEEE ACCESS, V9, P68108, DOI 10.1109/ACCESS.2021.3077577
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, V0, PP1689, DOI 10.1109/WACV.2018.00188
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Schlegl T, 2019, MED IMAGE ANAL, V54, P30, DOI 10.1016/j.media.2019.01.010
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, V0, PP618, DOI 10.1109/ICCV.2017.74
   Shi X., 2015, ADV NEURAL INFORM PR, V28, P802, DOI 10.5555/2969239.2969329
   Simonyan K, 2014, ADV NEUR IN, V27, P0
   Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70
   Springenberg JT, 2015, ICLR, V0, P0, DOI DOI 10.1163/_q3_SIM_00374
   Wang H., 2020, IEEE COMPUT SOC CONF, V0, PP24, DOI 10.1109/CVPRW50498.2020.00020
   Wu Tianfu, 2017, INTERPRETABLE R CNN, V0, P0
   Xu D., 2015, LEARNING DEEP REPRES, V0, P0
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yan SY, 2020, IEEE T COGN DEV SYST, V12, P30, DOI 10.1109/TCDS.2018.2883368
   Yu J, 2022, IEEE T NEUR NET LEAR, V33, P3572, DOI 10.1109/TNNLS.2021.3053563
   Yuan Y, 2017, IEEE T CYBERNETICS, V47, P3597, DOI 10.1109/TCYB.2016.2572609
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang QS, 2019, PROC CVPR IEEE, V0, PP6254, DOI 10.1109/CVPR.2019.00642
   Zhang QS, 2017, AAAI CONF ARTIF INTE, V0, P2898
   Zhang QS, 2018, AAAI CONF ARTIF INTE, V0, P4454
   Zhang QS, 2018, PROC CVPR IEEE, V0, PP8827, DOI 10.1109/CVPR.2018.00920
NR 48
TC 3
Z9 3
U1 3
U2 13
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-5265
EI 1687-5273
J9 COMPUT INTEL NEUROSC
JI Comput. Intell. Neurosci.
PD JUL 27
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/7367870
PG 15
WC Mathematical & Computational Biology; Neurosciences
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA TY8FR
UT WOS:000684015900003
PM 34354745
DA 2023-04-26
ER

PT J
AU Zheng, Z
   Wan, Y
   Zhang, YJ
   Xiang, SZ
   Peng, DF
   Zhang, B
AF Zheng, Zhi
   Wan, Yi
   Zhang, Yongjun
   Xiang, Sizhe
   Peng, Daifeng
   Zhang, Bin
TI CLNet: Cross-layer convolutional neural network for change detection in optical remote sensing imagery
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Optical remote sensing image; Deep convolutional neural networks; Cross-Layer Block (CLB); Cross-Layer Network (CLNet); UNet
ID unsupervised change detection
AB Change detection plays a crucial role in observing earth surface transition and has been widely investigated using deep learning methods. However, the current deep learning methods for pixel-wise change detection still suffer from limited accuracy, mainly due to their insufficient feature extraction and context aggregation. To address this limitation, we propose a novel Cross Layer convolutional neural Network (CLNet) in this paper, where the UNet structure is used as the backbone and newly designed Cross Layer Blocks (CLBs) are embedded to incorporate the multi-scale features and multi-level context information. The designed CLB starts with one input and then split into two parallel but asymmetric branches, which are leveraged to extract the multi-scale features by using different strides; and the feature maps, which come from the opposite branches but have the same size, are concatenated to incorporate multi-level context information. The designed CLBs aggregate the multi-scale features and multi-level context information so that the proposed CLNet can reuse extracted feature information and capture accurate pixel-wise change in complex scenes. Quantitative and qualitative experiments were conducted on a public very-high-resolution satellite image dataset (VHR-Dataset), a newly released building change detection dataset (LEVIR-CD Dataset) and an aerial building change detection dataset (WHU Building Dataset). The CLNet reached an F1-score of 0.921 and an overall accuracy of 98.1% with the VHR-Dataset, an F1-score of 0.900 and an overall accuracy of 98.9% with the LEVIR-CD Dataset, and an F1-score of 0.963 and an overall accuracy of 99.7% with the WHU Building Dataset. The experimental results with all the selected datasets showed that the proposed CLNet outperformed several state-of-the-art (SOTA) methods and achieved competitive accuracy and efficiency trade-offs. The code of CLNet will be released soon at: https://skyearth.org/publication/project/CLNet.
C1 [Zheng, Zhi; Wan, Yi; Zhang, Yongjun; Xiang, Sizhe; Zhang, Bin] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Peng, Daifeng] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
   [Peng, Daifeng] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
C3 Wuhan University; Nanjing University of Information Science & Technology; University of Trento
RP Wan, Y; Zhang, YJ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM zhengzhi@whu.edu.cn; yi.wan@whu.edu.cn; zhangyj@whu.edu.cn; xiangsizhe@whu.edu.cn; daifeng@nuist.edu.cn; bin.zhang@whu.edu.cn
FU National Natural Science Foundation of China [42030102, 42001406, 41801386]; Fund for Innovative Research Groups of the Hubei Natural Science Foundation [2020CFA003]; China Postdoctoral Science Foundation [2020M672416]
CR Akcay HG, 2010, INT GEOSCI REMOTE SE, V0, PP1932, DOI 10.1109/IGARSS.2010.5652842
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Chen H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101662
   Chen H, 2019, I-PERCEPTION, V10, P0, DOI 10.1177/2041669519864971
   Chen J, 2013, ISPRS J PHOTOGRAMM, V85, P1, DOI 10.1016/j.isprsjprs.2013.07.009
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Daudt Caye, 2018, ARXIV181008462V1, V0, P0
   Daudt R.C., 2018, CORR, V0, P0
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Gevaert CM, 2020, INT J APPL EARTH OBS, V90, P0, DOI 10.1016/j.jag.2020.102117
   Ghosh S, 2009, INT J APPROX REASON, V50, P37, DOI 10.1016/j.ijar.2008.01.008
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Hulley G, 2014, REMOTE SENS ENVIRON, V140, P755, DOI 10.1016/j.rse.2013.10.014
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji S., 2019, IEEE T GEOSCI REMOTE, V0, P0
   Lebedev M., 2018, INT ARCH PHOTOGRAM R, V42, P0
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Liang B., 2010, IEEE J SEL TOP QUANT, V4, P43
   Liu RY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232844
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060506
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Peng DF, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.024512
   Peng DF, 2017, INT J REMOTE SENS, V38, P3886, DOI 10.1080/01431161.2017.1308033
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), V0, PP1, DOI 10.1109/ICPHM.2017.7998297
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wiratama W, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8101785
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Xie SN, 2015, IEEE I CONF COMP VIS, V0, PP1395, DOI 10.1109/ICCV.2015.164
   Yang J, 2012, REMOTE SENS ENVIRON, V119, P62, DOI 10.1016/j.rse.2011.12.004
   Yang K., 2020, ARXIV201005687, V0, P0
   Yu F., 2015, 1511 ARXIV, V0, P0
   Yu WJ, 2016, REMOTE SENS ENVIRON, V177, P37, DOI 10.1016/j.rse.2016.02.030
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8040189
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhou Zongwei, 2018, DEEP LEARN MED IMAGE ANAL MULTIMODAL LEARN CLIN DECIS SUPPORT (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 55
TC 46
Z9 47
U1 19
U2 91
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY 15
PY 2021
VL 175
IS 
BP 247
EP 267
DI 10.1016/j.isprsjprs.2021.03.005
EA MAR 2021
PG 21
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT8HA
UT WOS:000644695700018
DA 2023-04-26
ER

PT J
AU Imam, A
   Faisal, K
   Majrashi, A
   Hegazy, I
AF Imam, Ayman
   Faisal, Kamil
   Majrashi, Abdulrahman
   Hegazy, Ibrahim
TI An automatic approach for detecting building fences from high-resolution images: the case study of Makkah, Saudi Arabia
SO INTERNATIONAL JOURNAL OF LOW-CARBON TECHNOLOGIES
LA English
DT Article
DE machine learning; extract building fences; convolutional neural networks; high-resolution images; Makkah
ID road network; extraction
AB In the light of the constantly expanding technological advancements concerning high-resolution satellites and imaging techniques for investigative and information uses it is important to look at how these algorithms progress to acquire more reliable data in a much efficient manner. This study aims to (1) investigate the ability to use remote sensing and geographic information system techniques to extract the detecting building edges in the City of Makkah and (2) investigate new machine learning techniques to derive the illegal building fences in the study area. Two WorldView-3 images will be the first obtained for the City of Makkah in 2016 and 2018. Convolutional neural networks algorithm will be investigated to detect all the fences within the two images. These traits have been utilized to create automated object detection techniques, which are a core requirement of information extraction and large frame analysis of images covering large expanses of land. In high-resolution images, object detection identifies objects belonging to a class, locating them using a bounding box. Based on satellite images time series, the outputs will detect the changes that occurred during 2016 and 2018. A web map application will be designed as the primary tool to make it easier, illustrating the differences between the main changes. Evaluation of binary classifiers approach will be used to evaluate the outcomes of building fences based on several performances that measure data interpretation. Preliminary findings will illustrate the precision and accuracy of the used machine learning algorithm. The research findings can contribute to the federal/municipal authorities and act as a generic indicator for targeting building fences for urban areas and/or suburban areas.
C1 [Imam, Ayman; Hegazy, Ibrahim] King Abdulaziz Univ, Fac Architecture & Planning, Dept Urban & Reg Planning, Jeddah 80200, Saudi Arabia.
   [Faisal, Kamil] King Abdulaziz Univ, Fac Architecture & Planning, Dept Geomat, Jeddah 80200, Saudi Arabia.
   [Majrashi, Abdulrahman] Umm Al Qura Univ, Fac Engn & Islamic Architecture, Dept Islamic Architecture, Mecca 715, Saudi Arabia.
   [Hegazy, Ibrahim] Mansoura Univ, Fac Engn, Dept Architecture, Mansoura 35516, Egypt.
C3 King Abdulaziz University; King Abdulaziz University; Umm Al Qura University; Egyptian Knowledge Bank (EKB); Mansoura University
RP Hegazy, I (corresponding author), King Abdulaziz Univ, Fac Architecture & Planning, Dept Urban & Reg Planning, Jeddah 80200, Saudi Arabia.; Hegazy, I (corresponding author), Mansoura Univ, Fac Engn, Dept Architecture, Mansoura 35516, Egypt.
EM ibmrizk@yahoo.com
FU Umm Al-Qura University [DSRUQU.PKC-41-2]
CR Al-Gendy M, 2017, J AL AZHAR U ENG SEC, V12, P489
   Britz D., 2015, UNDERSTANDING CONVOL, V0, P0
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Exelis Inc, 2009, ATMOSPHERIC CORRECTI, V0, P0
   Guo W, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010131
   Pham HM, 2011, LANDSCAPE URBAN PLAN, V100, P223, DOI 10.1016/j.landurbplan.2010.12.009
   Khan SU, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-27515-w
   Ko K. T., 1995, THESIS MISSISSIPPI S, V0, P0
   Li PL, 2019, IEEE ACCESS, V7, P122784, DOI 10.1109/ACCESS.2019.2938215
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P5157
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Miao ZL, 2014, IEEE GEOSCI REMOTE S, V11, P1856, DOI 10.1109/LGRS.2014.2312000
   Mokhtarzade M, 2007, INT J APPL EARTH OBS, V9, P32, DOI 10.1016/j.jag.2006.05.001
   Ottichilo W, 2002, INT ARCH PHOTOGRAMM, V34, P89
   Palubinskas G., 2008, P IGARSS 2008 2008 I, V2, P0
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Saha S., 2018, DATA SCI, V0, P0
   Sewak M., 2018, PRACTICAL CONVOLUTIO, V0, P0
   Shaker A, 2010, GISCI REMOTE SENS, V47, P321, DOI 10.2747/1548-1603.47.3.321
   Sharma V, 2020, COMPUT SCI REV, V38, P0, DOI 10.1016/j.cosrev.2020.100301
   Sun Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091459
   Unsalan C, 2012, IEEE T GEOSCI REMOTE, V50, P4441, DOI 10.1109/TGRS.2012.2190078
   Valero S, 2010, PATTERN RECOGN LETT, V31, P1120, DOI 10.1016/j.patrec.2009.12.018
   Wang HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050446
   Wang WX, 2016, J TRAFFIC TRANSP ENG, V3, P271, DOI 10.1016/j.jtte.2016.05.005
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zhou J, 2006, ISPRS J PHOTOGRAMM, V61, P108, DOI 10.1016/j.isprsjprs.2006.09.002
   Zhu D.-M., 2011, INT S IMAGE DATA FUS, V0, PP1, DOI 10.1007/978-1-4419-7566-9_1
NR 28
TC 0
Z9 0
U1 2
U2 8
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1748-1317
EI 1748-1325
J9 INT J LOW-CARBON TEC
JI Int. J. Low-Carbon Technol.
PD SEP 15
PY 2021
VL 16
IS 3
BP 1087
EP 1097
DI 10.1093/ijlct/ctab039
EA MAY 2021
PG 11
WC Thermodynamics; Energy & Fuels
SC Thermodynamics; Energy & Fuels
GA WK2GZ
UT WOS:000709550600039
DA 2023-04-26
ER

PT J
AU Lin, Y
   Tong, Y
   Zhong, QK
   Gao, RP
   Yin, BY
   Liu, L
   Ma, L
   Chai, H
AF Lin, Yu
   Tong, Yao
   Zhong, Qinkun
   Gao, Ruipeng
   Yin, Buyi
   Liu, Lei
   Ma, Li
   Chai, Hua
TI DCCP: Deep Convolutional Neural Networks for Cellular Network Positioning
SO 2021 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM)
LA English
DT Proceedings Paper
DE cellular network positioning; user query; multidimensional feature map; CNN
AB Although location awareness is prevalent outdoors due to the GPS, we get confused and disoriented in many blocked environments such as in urban canyons and under multi-level flyovers. A straightforward solution is to employ cellular signals for positioning, but the cellular signatures are always sparse and uneven in vast region, and vary among different devices and postures. In this paper, we propose DCCP, a novel cellular network positioning approach that transforms the localization problem into a corresponding object recognition task in geographic space. Specially, we elicit the receptive region of each cellular station via crowdsourced user queries, and exploit neighbour base stations to derive a multi-dimensional feature map. We also devise a CNN model to learn local correlations among nearby map grids, and employ it for cellular positioning. Extensive experiments on two real-world traffic datasets from the DiDi platform have demonstrated our effectiveness compared with the state-of-the-art. This is the lirst approach to use only user queries instead of RF signatures for cellular network positioning, and our system meets requirements of the E911.
C1 [Lin, Yu; Yin, Buyi; Liu, Lei; Ma, Li; Chai, Hua] Didi Chuxing, Beijing, Peoples R China.
   [Tong, Yao; Zhong, Qinkun; Gao, Ruipeng] Beijing Jiaotong Univ, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Gao, RP (corresponding author), Beijing Jiaotong Univ, Beijing, Peoples R China.
EM whulinyu@didiglobal.com; tongyao@bjtu.edu.cn; qkzhong@bjtu.edu.cn; rpgao@bjtu.edu.cn; yinbuyi@didiglobal.com; liuleifrey@didiglobal.com; malimarey@didiglobal.com; chaihua@didiglobal.com
FU Beijing NSF [L192004]; NSFC [62072029]; DiDi Research Collaboration Plan; CCF-Tencent Open Fund
CR Alimpertis E, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP2536, DOI 10.1145/3308558.3313726
   [Anonymous], 2014, PROC IEEE C COMPUT V, V0, P0
   Chakraborty Ayon, 2015, 2015 IEEE CONFERENCE ON COMPUTER COMMUNICATIONS (INFOCOM). PROCEEDINGS, V0, PP2767, DOI 10.1109/INFOCOM.2015.7218669
   del Peral-Rosado JA, 2018, IEEE COMMUN SURV TUT, V20, P1124, DOI 10.1109/COMST.2017.2785181
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Ibrahim M, 2012, IEEE T VEH TECHNOL, V61, P286, DOI 10.1109/TVT.2011.2173771
   Kos T, 2006, PROCEEDINGS ELMAR-2006, V0, PP185, DOI 10.1109/ELMAR.2006.329545
   LeCun Y, 2010, IEEE INT SYMP CIRC S, V0, PP253, DOI 10.1109/ISCAS.2010.5537907
   Margolies R, 2017, IEEE INFOCOM SER, V0, P0
   Niculescu D, 2003, IEEE INFOCOM SER, V0, P1734
   Vo QD, 2016, IEEE COMMUN SURV TUT, V18, P491, DOI 10.1109/COMST.2015.2448632
   Ray A, 2016, IEEE INFOCOM SER, V0, P0
   Simsim MT, 2006, IEEE VTS VEH TECHNOL, V0, P2666
   Tian XH, 2020, IEEE T MOBILE COMPUT, V19, P450, DOI 10.1109/TMC.2019.2893278
   Trevisani E, 2004, SIXTH IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, V0, P51, DOI 10.1109/MCSA.2004.9
   Zhang W., 2010, P IEEE INT C GEOINF, V0, P0
NR 16
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2334-0983
EI 2576-6813
J9 IEEE GLOB COMM CONF
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/GLOBECOM46510.2021.9685658
PG 6
WC Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA BT0PJ
UT WOS:000790747203078
DA 2023-04-26
ER

PT J
AU Alvarez, K
   Urenda, JC
   Csiszar, O
   Csiszar, G
   Dombi, J
   Eigner, G
   Kreinovich, V
AF Alvarez, Kevin
   Urenda, Julio C.
   Csiszar, Orsolya
   Csiszar, Gabor
   Dombi, Jozsef
   Eigner, Gyorgy
   Kreinovich, Vladik
TI Towards Fast and Understandable Computations: Which "And"- and "Or"-Operations Can Be Represented by the Fastest (i.e., 1-Layer) Neural Networks? Which Activations Functions Allow Such Representations?
SO ACTA POLYTECHNICA HUNGARICA
LA English
DT Article
DE neural networks; fuzzy logic; "and"- and "or"-operations; rectified linear neurons; explainable Al
ID fuzzy cognitive maps; universal approximation; systems; controllers; theorem; logic
AB We want computations to be fast, and we want them to be understandable. As we show, the need for computations to be fast naturally leads to neural networks, with 1-layer networks being the fastest, and the need to be understandable naturally leads to fuzzy logic and to the corresponding "and"- and "or"-operations. Since we want our computations to be both fast and understandable, a natural question is: which "and"- and "or"-operations of fuzzy logic can be represented by the fastest (i.e., 1-layer) neural network? And a related question is: which activation functions allow such a representation? In this paper, we provide an answer to both questions: the only "and"- and "or"-operations that can be thus represented are max(0, a + b - 1) and min(a + b,1), and the only activations functions allowing such a representation are equivalent to the rectified linear function - the one used in deep learning. This result provides an additional explanation of why rectified linear neurons are so successful. With also show that with full 2-layer networks, we can compute practically any "and"- and "or"-operation.
C1 [Alvarez, Kevin; Urenda, Julio C.; Kreinovich, Vladik] Univ Texas El Paso, Dept Comp Sci, El Paso, TX 79968 USA.
   [Urenda, Julio C.] Univ Texas El Paso, Dept Math Sci, El Paso, TX 79968 USA.
   [Csiszar, Orsolya] Univ Appl Sci Esslingen, Fac Basic Sci, Esslingen, Germany.
   [Csiszar, Orsolya] Obuda Univ, Inst Appl Math, Budapest, Hungary.
   [Eigner, Gyorgy] Obuda Univ, Inst Biomat & Appl Artificial Intelligence, Budapest, Hungary.
   [Csiszar, Gabor] Univ Stuttgart, Inst Mat Phys, Stuttgart, Germany.
   [Dombi, Jozsef] Univ Szeged, Inst Informat, Szeged, Hungary.
C3 University of Texas System; University of Texas El Paso; University of Texas System; University of Texas El Paso; Obuda University; Obuda University; University of Stuttgart; Szeged University
RP Alvarez, K (corresponding author), Univ Texas El Paso, Dept Comp Sci, El Paso, TX 79968 USA.
EM kalvarez9@miners.utep.edu; jcurenda@utep.edu; orsolya.csiszar@nik.uni-obuda.hu; gabor.csiszar@mp.imw.uni-stuttgart.de; dombi@inf.u-szeged.hu; eigner.gyorgy@nik.uni-obuda.hu; vladik@utep.edu
FU Ministry of Technology and Innovation, Hungary [TUDFO/47138-1/2019-ITM]; US National Science Foundation [1623190, HRD-1242122]
CR Adam N, 2018, ACTA POLYTECH HUNG, V15, P69, DOI 10.12700/APH.15.1.2018.2.4
   Afravi M, 2020, DECISION MAKING CONS, V0, P1
   Afravi M. M., 2017, P JOINT 17 C INT FUZ, V0, P0
   [Anonymous], 2006, MACH LEARN, V0, P0
   [Anonymous], 1995, FUZZY SETS FUZZY LOG, V0, P0
   Baral C, 2018, STUD SYST DECIS CONT, V100, P1, DOI 10.1007/978-3-319-61753-4_1
   Belohlavek R., 2017, FUZZY LOGIC MATH HIS, V0, P0
   BLUM EK, 1991, NEURAL NETWORKS, V4, P511, DOI 10.1016/0893-6080(91)90047-9
   CASTRO JL, 1995, IEEE T SYST MAN CYB, V25, P629, DOI 10.1109/21.370193
   Chen CH, 2015, ACTA POLYTECH HUNG, V12, P7
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Goodfellow I., 2016, DEEP LEANING, V0, P0
   Hilbert D., 1902, B AM MATH SOC, V8, P437
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Klement EP, 1999, INT J GEN SYST, V28, P259, DOI 10.1080/03081079908935238
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   KOLMOGOROV AN, 1957, DOKL AKAD NAUK SSSR+, V114, P953
   KOSKO B, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, V0, PP1153, DOI 10.1109/FUZZY.1992.258720
   Kreinovich V, 2000, INT J INTELL SYST, V15, P565, DOI 10.1002/(SICI)1098-111X(200006)15:6<565::AID-INT6>3.0.CO;2-0
   Kreinovich V, 2015, INT J COMPUT COMMUN, V10, P825
   Kreinovich V, 1998, HDB FUZZ SET SER, V2, P135
   Kreinovich V, 1996, INT J UNCERTAIN FUZZ, V4, P331, DOI 10.1142/S0218488596000196
   Kreinovich V., 1993, NEURAL, V0, P0
   Kreinovich V., 2020, P 4 INT C INT SYST M, V0, P0
   Kreinovich V., 2018, P WORLD C SOFT COMP, V0, P0
   KREINOVICH VY, 1991, NEURAL NETWORKS, V4, P381, DOI 10.1016/0893-6080(91)90074-F
   KURKOVA V, 1992, NEURAL NETWORKS, V5, P501, DOI 10.1016/0893-6080(92)90012-8
   Lemos A., 2011, P 30 ANN C N AM FUZZ, V0, P0
   Lorentz G. G., 1976, MATH DEV ARISING HIL, V2, P419
   Lorentz G. G., 1965, APPROXIMATION FUNCTI, V0, P0
   Lovassy R, 2010, ACTA POLYTECH HUNG, V7, P25
   Mandelbrot B. B., 1983, FRACTAL GEOMETRY NAT, V51, P286, DOI 10.1119/1.13295
   Mendel J., 2017, UNCERTAIN RULE BASED, V0, P0, DOI DOI 10.1007/978-3-319-51370-6
   Moser B, 1999, FUZZY SET SYST, V104, P269, DOI 10.1016/S0165-0114(97)00220-0
   Nakamura M., 1993, INTERVAL COMPUTATION, V3, P183
   Nguyen H. T., 2019, 1 COURSE FUZZY LOGIC, V0, P0
   Nguyen HT, 1996, FUZZY SET SYST, V80, P71, DOI 10.1016/0165-0114(95)00263-4
   Nguyen HT, 1997, ORDERED WEIGHTED AVERAGING OPERATORS, V0, P3
   Nguyen HT, 1998, INT J APPROX REASON, V18, P239, DOI 10.1016/S0888-613X(98)00009-7
   NGUYEN HT, 1993, P 5 INT FUZZ SYST AS, V0, P1414
   Novak V., 1999, MATH PRINCIPLES FUZZ, V0, P0
   Perfilieva I, 2002, INT J INTELL SYST, V17, P1121, DOI 10.1002/int.10063
   SPRECHER DA, 1965, T AM MATH SOC, V115, P340, DOI 10.2307/1994273
   Stone M., 1948, MATH MAG, V0, PP237, DOI 10.2307/3029337
   Tikk D., 1999, TATRA MOUNTAINS MATHEMATICAL PUBLICATIONS, V16, P369
   Trejo R., 1998, INTERVAL COMPUTATION, V0, P0
   Vascak J, 2010, ACTA POLYTECH HUNG, V7, P109
   WANG LX, 1992, IEEE T NEURAL NETWOR, V3, P807, DOI 10.1109/72.159070
   Weierstrass K, 1895, MATH WERKE, V2, P71
   Weierstrass K., 1885, SITZUNGSBERICHTE KON, V0, P[633, 789]
   Yager RR, 2003, FUZZY SET SYST, V140, P331, DOI 10.1016/S0165-0114(02)00521-3
   Yeung Yam, 1999, PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL INTELLIGENT SYSTEMS AND SEMIOTICS (CAT. NO.99CH37014), V0, PP213, DOI 10.1109/ISIC.1999.796657
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 55
TC 5
Z9 5
U1 0
U2 2
PU BUDAPEST TECH
PI BUDAPEST
PA BECSI UT 96-B, BUDAPEST, H-1034, HUNGARY
SN 1785-8860
EI 
J9 ACTA POLYTECH HUNG
JI Acta Polytech. Hung.
PD JUN 15
PY 2021
VL 18
IS 2
BP 27
EP 45
DI 10.12700/APH.18.2.2021.2.2
PG 19
WC Engineering, Multidisciplinary
SC Engineering
GA QA7TR
UT WOS:000613644800002
DA 2023-04-26
ER

PT J
AU Tran, TH
   Dam, ND
   Jalal, FE
   Al-Ansari, N
   Ho, LS
   Phong, TV
   Iqbal, M
   Le, HV
   Nguyen, HBT
   Prakash, I
   Pham, BT
AF Trung-Hieu Tran
   Nguyen Duc Dam
   Jalal, Fazal E.
   Al-Ansari, Nadhir
   Ho, Lanh Si
   Tran Van Phong
   Iqbal, Mudassir
   Hiep Van Le
   Hanh Bich Thi Nguyen
   Prakash, Indra
   Binh Thai Pham
TI GIS-Based Soft Computing Models for Landslide Susceptibility Mapping: A Case Study of Pithoragarh District, Uttarakhand State, India
SO MATHEMATICAL PROBLEMS IN ENGINEERING
LA English
DT Article
ID alternating decision trees; logistic-regression model; support vector machines; weights-of-evidence; spatial prediction; information value; neural-networks; random forest; multivariate regression; multilayer perceptron
AB The main objective of the study was to investigate performance of three soft computing models: Naive Bayes (NB), Multilayer Perceptron (MLP) neural network classifier, and Alternating Decision Tree (ADT) in landslide susceptibility mapping of Pithoragarh District of Uttarakhand State, India. For this purpose, data of 91 past landslide locations and ten landslide influencing factors, namely, slope degree, curvature, aspect, land cover, slope forming materials (SFM), elevation, distance to rivers, geomorphology, overburden depth, and distance to roads were considered in the models study. Thematic maps of the Geological Survey of India (GSI), Google Earth images, and Aster Digital Elevation Model (DEM) were used for the development of landslide susceptibility maps in the Geographic Information System (GIS) environment. Landslide locations data was divided into a 70 : 30 ratio for the training (70%) and testing/validation (30%) of the three models. Standard statistical measures, namely, Positive Predicted Values (PPV), Negative Predicted Values (NPV), Sensitivity, Specificity, Mean Absolute Error (MAE), Root Mean Squire Error (RMSE), and Area under the ROC Curve (AUC) were used for the evaluation of the models. All the three soft computing models used in this study have shown good performance in the accurate development of landslide susceptibility maps, but performance of the ADT and MLP is better than NB. Therefore, these models can be used for the construction of accurate landslide susceptibility maps in other landslide-prone areas also.
C1 [Trung-Hieu Tran; Nguyen Duc Dam; Ho, Lanh Si; Hiep Van Le; Hanh Bich Thi Nguyen; Binh Thai Pham] Univ Transport Technol, Hanoi 100000, Vietnam.
   [Jalal, Fazal E.; Iqbal, Mudassir] Shanghai Jiao Tong Univ, Dept Civil Engn, State Key Lab Ocean Engn, Shanghai 200240, Peoples R China.
   [Al-Ansari, Nadhir] Lulea Univ Technol, Dept Civil Environm & Nat Resources Engn, S-97187 Lulea, Sweden.
   [Ho, Lanh Si] Hiroshima Univ, Grad Sch Adv Sci & Engn, Civil & Environm Engn Program, 1-4-1 Kagamiyama, Higashihiroshima, Hiroshima 7398527, Japan.
   [Tran Van Phong] Vietnam Acad Sci & Technol, Inst Geol Sci, 84 Chua Lang St, Hanoi 100000, Vietnam.
   [Iqbal, Mudassir] Univ Engn & Technol, Dept Civil Engn, Peshawar, Pakistan.
   [Prakash, Indra] DDG R Geol Survey India, Gandhinagar 382010, India.
C3 Shanghai Jiao Tong University; Lulea University of Technology; Hiroshima University; Vietnam Academy of Science & Technology (VAST); University of Engineering & Technology Peshawar
RP Pham, BT (corresponding author), Univ Transport Technol, Hanoi 100000, Vietnam.; Al-Ansari, N (corresponding author), Lulea Univ Technol, Dept Civil Environm & Nat Resources Engn, S-97187 Lulea, Sweden.
EM nadhir.alansari@ltu.se; binhpt@utt.edu.vn
FU University of Transport Technology
CR Achour Y, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2980-6
   Ahmed B, 2015, LANDSLIDES, V12, P1077, DOI 10.1007/s10346-014-0521-x
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203389
   Arabameri A, 2019, J MT SCI-ENGL, V16, P595, DOI 10.1007/s11629-018-5168-y
   Begueria S, 2006, GEOMORPHOLOGY, V74, P196, DOI 10.1016/j.geomorph.2005.07.018
   Begueria S, 2006, NAT HAZARDS, V37, P315, DOI 10.1007/s11069-005-5182-6
   Pham BT, 2021, J HYDROL, V592, P0, DOI 10.1016/j.jhydrol.2020.125815
   Pham BT, 2016, GEOTECH GEOL ENG, V34, P1807, DOI 10.1007/s10706-016-9990-0
   Pham BT, 2018, CIV ENG ENVIRON SYST, V35, P139, DOI 10.1080/10286608.2019.1568418
   Pham BT, 2019, GEOCARTO INT, V34, P316, DOI 10.1080/10106049.2017.1404141
   Pham BT, 2017, CATENA, V149, P52, DOI 10.1016/j.catena.2016.09.007
   Pham BT, 2017, THEOR APPL CLIMATOL, V128, P255, DOI 10.1007/s00704-015-1702-9
   Borgelt C., 2009, GRAPHICAL MODELS REP, V0, P0
   Camilo DC, 2017, ENVIRON MODELL SOFTW, V97, P145, DOI 10.1016/j.envsoft.2017.08.003
   Carranza E.J.M., 2000, NAT RESOUR RES, V9, P237, DOI 10.1023/A:1010147818806
   Catal C, 2011, EXPERT SYST APPL, V38, P2347, DOI 10.1016/j.eswa.2010.08.022
   Chen T, 2020, J MT SCI-ENGL, V17, P670, DOI 10.1007/s11629-019-5839-3
   Chen W, 2017, GEOMAT NAT HAZ RISK, V8, P950, DOI 10.1080/19475705.2017.1289250
   Chen ZH, 2007, NAT HAZARDS, V42, P75, DOI 10.1007/s11069-006-9061-6
   Chu L, 2019, GEOSCI J, V23, P341, DOI 10.1007/s12303-018-0038-8
   CHUNG CJF, 1995, ADV NAT TECHNOL HAZ, V5, P107
   Corominas J, 2008, ENG GEOL, V102, P193, DOI 10.1016/j.enggeo.2008.03.018
   Dahoua L, 2018, ADV SCI TECHNOL INN, V0, PP1837, DOI 10.1007/978-3-319-70548-4_532
   Das I, 2010, GEOMORPHOLOGY, V114, P627, DOI 10.1016/j.geomorph.2009.09.023
   De Vita P, 1998, ENVIRON GEOL, V35, P219, DOI 10.1007/s002540050308
   Bui DT, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5919-4
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Bui DT, 2015, GEOMAT NAT HAZ RISK, V6, P243, DOI 10.1080/19475705.2013.843206
   Bui DT, 2012, MATH PROBL ENG, V2012, P0, DOI 10.1155/2012/974638
   Dikshit A, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10072466
   Fang ZC, 2021, INT J GEOGR INF SCI, V35, P321, DOI 10.1080/13658816.2020.1808897
   Felicisimo A, 2013, LANDSLIDES, V10, P175, DOI 10.1007/s10346-012-0320-1
   Fell R, 2008, ENG GEOL, V102, P99, DOI 10.1016/j.enggeo.2008.03.014
   Freund Y, 1999, MACHINE LEARNING, V0, P124
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Gariano SL, 2016, EARTH-SCI REV, V162, P227, DOI 10.1016/j.earscirev.2016.08.011
   Guy RT, 2012, GENET EPIDEMIOL, V36, P99, DOI 10.1002/gepi.21608
   Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007
   Hong HY, 2019, CATENA, V176, P45, DOI 10.1016/j.catena.2018.12.035
   Hong HY, 2018, CATENA, V163, P399, DOI 10.1016/j.catena.2018.01.005
   Hong HY, 2017, GEOMAT NAT HAZ RISK, V8, P1997, DOI 10.1080/19475705.2017.1403974
   Hong HY, 2015, CATENA, V133, P266, DOI 10.1016/j.catena.2015.05.019
   Huang Y, 2018, CATENA, V165, P520, DOI 10.1016/j.catena.2018.03.003
   Jayas DS, 2000, J AGR ENG RES, V77, P119, DOI 10.1006/jaer.2000.0559
   Kadavi PR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081252
   Kanungo D, 2008, LANDSLIDES, V5, P407, DOI 10.1007/s10346-008-0134-3
   Kasai M, 2009, GEOMORPHOLOGY, V113, P57, DOI 10.1016/j.geomorph.2009.06.004
   Kavoura K, 2020, LANDSLIDES, V17, P127, DOI 10.1007/s10346-019-01271-y
   Kazakis N, 2015, J HYDROL, V525, P13, DOI 10.1016/j.jhydrol.2015.03.035
   Kornejady A, 2017, CATENA, V152, P144, DOI 10.1016/j.catena.2017.01.010
   Lee DH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071194
   Lee JH, 2018, GEOMORPHOLOGY, V303, P284, DOI 10.1016/j.geomorph.2017.12.007
   Lee S, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9010048
   Li T, 1990, LANDSLIDE MANAGEMENT, V0, P0
   Liu KY, 2005, BMC GENET, V6, P0, DOI 10.1186/1471-2156-6-S1-S132
   Liu ZQ, 2021, GEOSCI FRONT, V12, P385, DOI 10.1016/j.gsf.2020.04.014
   Maalouf M, 2011, COMPUT STAT DATA AN, V55, P168, DOI 10.1016/j.csda.2010.06.014
   Manzo G, 2013, INT J GEOGR INF SCI, V27, P1433, DOI 10.1080/13658816.2012.693614
   Mitra SK, 2013, J GEOL SOC INDIA, V82, P443
   Moayedi H, 2019, ENG COMPUT-GERMANY, V35, P967, DOI 10.1007/s00366-018-0644-0
   Neuhauser B, 2007, GEOMORPHOLOGY, V86, P12, DOI 10.1016/j.geomorph.2006.08.002
   Ooi MPL, 2017, HANDBOOK OF NEURAL COMPUTATION, V0, PP345, DOI 10.1016/B978-0-12-811318-9.00019-3
   Ozer BC, 2020, B ENG GEOL ENVIRON, V79, P551, DOI 10.1007/s10064-019-01548-5
   Panchal G., 2011, INT J COMPUT THEORY, V3, P332, DOI 10.7763/IJCTE.2011.V3.328
   Park S, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9050942
   Pourghasemi HR, 2013, ARAB J GEOSCI, V6, P2351, DOI 10.1007/s12517-012-0532-7
   Pradhan AMS, 2017, B ENG GEOL ENVIRON, V76, P1263, DOI 10.1007/s10064-016-0919-x
   Pradhan B, 2012, ENVIRON MONIT ASSESS, V184, P715, DOI 10.1007/s10661-011-1996-8
   Razavi-Termeh SV, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101689
   Roslee R., 2017, MALAYSIAN J GEOSCIEN, V1, P13
   Roy J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232866
   Saha AK, 2005, LANDSLIDES, V2, P61, DOI 10.1007/s10346-004-0039-8
   Sahana M, 2022, GEOCARTO INT, V37, P2747, DOI 10.1080/10106049.2020.1837262
   Sameen MI, 2020, COMPUT GEOSCI-UK, V134, P0, DOI 10.1016/j.cageo.2019.104336
   Sarkar S, 2013, J GEOL SOC INDIA, V82, P351, DOI 10.1007/s12594-013-0162-z
   Senouci R, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su13020630
   Shatovskaya T., 2006, P 2006 INT C MOD PRO, V0, P0, DOI DOI 10.1109/tcset.2006.4404462
   Shirani K, 2018, NAT HAZARDS, V93, P1379, DOI 10.1007/s11069-018-3356-2
   Tangestani MH, 2009, J ASIAN EARTH SCI, V35, P66, DOI 10.1016/j.jseaes.2009.01.002
   Tsangaratos P, 2017, LANDSLIDES, V14, P1091, DOI 10.1007/s10346-016-0769-4
   Van Gestel T, 2003, IEEE C COMP INTEL FI, V0, PP1, DOI 10.1109/CIFER.2003.1196234
   Viet-Ha Nhu, 2020, FORESTS, V11, P0, DOI 10.3390/f11080830
   Nhu VH, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17082749
   Wan SA, 2014, ARAB J GEOSCI, V7, P2059, DOI 10.1007/s12517-013-0952-z
   Wang GR, 2020, SYMMETRY-BASEL, V12, P0, DOI 10.3390/sym12030325
   Wang GR, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9030144
   Wang QQ, 2019, GEOMAT NAT HAZ RISK, V10, P820, DOI 10.1080/19475705.2018.1549111
   Witten IH., 2002, ACM SIGMOD RECORD, V31, P76, DOI 10.1145/507338.507355
   Wongsasuluk P, 2018, ENVIRON RES, V162, P106, DOI 10.1016/j.envres.2017.11.024
   Xu C, 2013, NAT HAZARDS, V68, P883, DOI 10.1007/s11069-013-0661-7
   Yariyan P, 2020, WATER RESOUR MANAG, V34, P3037, DOI 10.1007/s11269-020-02603-7
   Youssef AM, 2021, GEOSCI FRONT, V12, P639, DOI 10.1016/j.gsf.2020.05.010
   Yu XY, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0229818
   Zare M, 2013, ARAB J GEOSCI, V6, P2873, DOI 10.1007/s12517-012-0610-x
   Zhang C, 2018, ISPRS J PHOTOGRAMM, V140, P133, DOI 10.1016/j.isprsjprs.2017.07.014
NR 95
TC 12
Z9 12
U1 4
U2 15
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1024-123X
EI 1563-5147
J9 MATH PROBL ENG
JI Math. Probl. Eng.
PD AUG 29
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/9914650
PG 19
WC Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications
SC Engineering; Mathematics
GA UP7GR
UT WOS:000695545300004
DA 2023-04-26
ER

PT J
AU Liu, F
   Lv, YJ
   Li, BH
   Gao, S
   Qin, YC
AF Liu, Feng
   Lv, Yanjie
   Li, Buhang
   Gao, Shuai
   Qin, Yuchu
TI A Semiphysical Approach of Haze Removal for Landsat Image
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Earth; Artificial satellites; Atmospheric modeling; Satellites; Image color analysis; Cloud computing; Dark object; guided-filter; haze removal; Landsat; light transmission
ID neural-network; vision; classification; shadows; weather; cloud; scale; tm
AB The presence of haze could seriously contaminate the observations of optical satellite imagery. Haze not only significantly affects the visual interpretation but also reduces the accuracy of map products. In this article, a semiphysical approach is proposed to reduce the haze effects for Landsat image. The proposed approach is based on the physical model of radiative transfer theory and the presence of dark objects. As the depth map of satellite remotely sensed image is almost a constant value, the coarse transmission map of atmosphere is estimated by the haze thickness, other than the scene depth map. The derived coarse transmission is utilized to correct the color shift induced by airlight. For haze veiled textural information, the guided-filter based approach is adopted to refine the coarse transmission map to restore the textural information. Experiments are conducted upon the images acquired by Landsat at different dates and spatial locations. The visual interpretation upon the dehazed results suggests that the proposed approach could generate visually promising results and preserve spectral properties of land surfaces. Moreover, it also performs favorably against several state-of-the-art deep learning based methods and a classic algorithm. The results of quantitative assessments demonstrate that the developed approach could enhance the information of Landsat scene with minimum spectrum changes. With the visual and quantitative assessments, we can conclude that the proposed approach is a promising solution for Landsat image dehazing. It is expected to improve the data quality of hazy scene and expand the usability of Landsat data.
C1 [Liu, Feng; Lv, Yanjie; Gao, Shuai; Qin, Yuchu] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.
   [Liu, Feng; Lv, Yanjie; Gao, Shuai; Qin, Yuchu] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Li, Buhang] Sun Yat Sen Univ, Sch Life Sci, Guangzhou 510275, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Sun Yat Sen University
RP Qin, YC (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.
EM liufeng@radi.ac.cn; yjlv@mail.ie.ac.cn; libuhang@mail.sysu.edu.cn; gaoshuai@radi.ac.cn; qinyc@radi.ac.cn
FU National Key R&D Program of China [2018YFC0506901]; Hundred Talents Program of Chinese Academy of Sciences
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Bodart C, 2011, ISPRS J PHOTOGRAMM, V66, P555, DOI 10.1016/j.isprsjprs.2011.03.003
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chander G, 2009, REMOTE SENS ENVIRON, V113, P893, DOI 10.1016/j.rse.2009.01.007
   CHAVEZ PS, 1988, REMOTE SENS ENVIRON, V24, P459, DOI 10.1016/0034-4257(88)90019-3
   Chen F, 2018, LANDSLIDES, V15, P453, DOI 10.1007/s10346-017-0884-x
   Cohen WB, 2004, BIOSCIENCE, V54, P535, DOI 10.1641/0006-3568(2004)054[0535:LRIEAO]2.0.CO;2
   Fattal R, 2008, ACM T GRAPHIC, V27, P0, DOI 10.1145/1360612.1360671
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Friedl MA, 2010, REMOTE SENS ENVIRON, V114, P168, DOI 10.1016/j.rse.2009.08.016
   Giri C, 2011, GLOBAL ECOL BIOGEOGR, V20, P154, DOI 10.1111/j.1466-8238.2010.00584.x
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Israel H., 1959, VS VERLAG SOZIALWISS, V0, PP7, DOI 10.1007/978-3-663-04661-5_2
   Jiang H, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060945
   Jiang H, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100844
   Ju JC, 2005, REMOTE SENS ENVIRON, V96, P62, DOI 10.1016/j.rse.2005.01.016
   KAUFMAN YJ, 1990, J GEOPHYS RES-ATMOS, V95, P9895, DOI 10.1029/JD095iD07p09895
   Kaufman YJ, 1997, IEEE T GEOSCI REMOTE, V35, P1286, DOI 10.1109/36.628795
   Li BY, 2017, IEEE I CONF COMP VIS, V0, PP4780, DOI 10.1109/ICCV.2017.511
   Li RD, 2018, PROC CVPR IEEE, V0, PP8202, DOI 10.1109/CVPR.2018.00856
   Li XH, 2014, IEEE T GEOSCI REMOTE, V52, P7086, DOI 10.1109/TGRS.2014.2307354
   Liu Q, 2017, SIGNAL PROCESS, V137, P33, DOI 10.1016/j.sigpro.2017.01.036
   Liu XH, 2019, IEEE I CONF COMP VIS, V0, PP7313, DOI 10.1109/ICCV.2019.00741
   Long J, 2014, IEEE GEOSCI REMOTE S, V11, P59, DOI 10.1109/LGRS.2013.2245857
   Long J, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, V0, P132
   Lu D, 2007, INT J REMOTE SENS, V28, P4027, DOI 10.1080/01431160701227703
   Mas JF, 1999, INT J REMOTE SENS, V20, P139, DOI 10.1080/014311699213659
   McCartney E. J, 1976, WILEY SER PURE APPL, V30, P0
   Narasimhan SG, 2001, PROC CVPR IEEE, V0, P186
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, V0, PP598, DOI 10.1109/CVPR.2000.855874
   Pan XX, 2015, IEEE SIGNAL PROC LET, V22, P1806, DOI 10.1109/LSP.2015.2432466
   Qin MJ, 2018, IEEE J-STARS, V11, P1645, DOI 10.1109/JSTARS.2018.2812726
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren WQ, 2018, PROC CVPR IEEE, V0, PP3253, DOI 10.1109/CVPR.2018.00343
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Song C, 2001, REMOTE SENS ENVIRON, V75, P230, DOI 10.1016/S0034-4257(00)00169-3
   Sun LX, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9100972
   Tan RT, 2008, PROC CVPR IEEE, V0, PP2347, DOI 10.1109/cvpr.2008.4587643
   Wang N, 2020, ISPRS J PHOTOGRAMM, V162, P137, DOI 10.1016/j.isprsjprs.2020.02.012
   Wulder MA, 2008, REMOTE SENS ENVIRON, V112, P955, DOI 10.1016/j.rse.2007.07.004
   Xie FY, 2018, IEEE ACCESS, V6, P67982, DOI 10.1109/ACCESS.2018.2879893
   Xueyang Fu, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P1190, DOI 10.1109/ICASSP.2014.6853785
   Yang XT, 2018, AAAI CONF ARTIF INTE, V0, P7485
   Yu B, 2018, IEEE J-STARS, V11, P3252, DOI 10.1109/JSTARS.2018.2860989
   Zhang H, 2018, PROC CVPR IEEE, V0, PP3194, DOI 10.1109/CVPR.2018.00337
   Zhang Y, 2002, REMOTE SENS ENVIRON, V82, P173, DOI 10.1016/S0034-4257(02)00034-2
   Zhang YC, 2004, J GEOPHYS RES-ATMOS, V109, P0, DOI 10.1029/2003JD004457
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
NR 51
TC 0
Z9 0
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7410
EP 7421
DI 10.1109/JSTARS.2021.3096651
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TW0SJ
UT WOS:000682121200002
DA 2023-04-26
ER

PT J
AU Chen, CF
   Hu, BJ
   Li, YY
AF Chen, Chuanfa
   Hu, Baojian
   Li, Yanyan
TI Easy-to-use spatial random-forest-based downscaling-calibration method for producing precipitation data with high resolution and high accuracy
SO HYDROLOGY AND EARTH SYSTEM SCIENCES
LA English
DT Article
ID satellite precipitation; rain-gauge; interpolation; regression; climate; tmpa; bias; algorithm; scales; region
AB Precipitation data with high resolution and high accuracy are significantly important in numerous hydrological applications. To enhance the spatial resolution and accuracy of satellite-based precipitation products, an easy-to-use downscaling-calibration method based on a spatial random forest (SRF-DC) is proposed in this study, where the spatial autocorrelation of precipitation measurements between neighboring locations is considered. SRF-DC consists of two main stages. First, the satellite-based precipitation is downscaled by the SRF with the incorporation of high-resolution variables including latitude, longitude, normalized difference vegetation index (NDVI), digital elevation model (DEM), terrain slope, aspect, relief and land surface temperatures. Then, the downscaled precipitation is calibrated by the SRF with rain gauge observations and the aforementioned high-resolution variables. The monthly Integrated MultisatellitE Retrievals for Global Precipitation Measurement (IMERG) over Sichuan Province, China, from 2015 to 2019 was processed using SRF-DC, and its results were compared with those of classical methods including geographically weighted regression (GWR), artificial neural network (ANN), random forest (RF), kriging interpolation only on gauge measurements, bilinear interpolation-based downscaling and then SRF-based calibration (Bi-SRF), and SRF-based downscaling and then geographical difference analysis (GDA)-based calibration (SRF-GDA). Comparative analyses with respect to root mean square error (RMSE), mean absolute error (MAE) and correlation coefficient (CC) demonstrate that (1) SRF-DC outperforms the classical methods as well as the original IMERG; (2) the monthly based SRF estimation is slightly more accurate than the annually based SRF fraction disaggregation method; (3) SRF-based downscaling and calibration perform better than bilinear downscaling (Bi-SRF) and GDA-based calibration (SRF-GDA); (4) kriging is more accurate than GWR and ANN, whereas its precipitation map loses detailed spatial precipitation patterns; and (5) based on the variable-importance rank of the RF, the precipitation interpolated by kriging on the rain gauge measurements is the most important variable, indicating the significance of incorporating spatial autocorrelation for precipitation estimation.
C1 [Chen, Chuanfa; Hu, Baojian; Li, Yanyan] Shandong Univ Sci & Technol, Coll Geodesy & Geomat, Qingdao 266590, Peoples R China.
   [Chen, Chuanfa; Hu, Baojian; Li, Yanyan] Shandong Univ Sci & Technol, Key Lab Geomat & Digital Technol Shandong Prov, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of Science & Technology
RP Li, YY (corresponding author), Shandong Univ Sci & Technol, Coll Geodesy & Geomat, Qingdao 266590, Peoples R China.; Li, YY (corresponding author), Shandong Univ Sci & Technol, Key Lab Geomat & Digital Technol Shandong Prov, Qingdao 266590, Peoples R China.
EM yylee@whu.edu.cn
FU National Natural Science Foundation of China [41804001]; Shandong Provincial Natural Science Foundation of China [ZR2020YQ26, ZR2019MD007, ZR2019BD006]; Shandong Province Higher Educational Youth Innovation Science and Technology Program [2019KJH007]; Shandong Provincial Key Research and Development Program (Major Scientific and Technological Innovation Project) [2019JZZY010429]; Scientific Research Foundation of Shandong University of Science and Technology for Recruited Talents [2019RCJJ003]
CR [Anonymous], 1900, DOI 10.5066/F7PR7TFT, V0, P0
   [Anonymous], 2021, NASA GLOB PREC MEAS, V0, P0
   [Anonymous], 2021, NASA DATA RES FIND S, V0, P0, DOI DOI 10.5067/MODIS/mod13a3.006
   [Anonymous], 2021, NASA EARTH DATA MOD1, V0, P0
   Ashouri H, 2015, B AM METEOROL SOC, V96, P69, DOI 10.1175/BAMS-D-13-00068.1
   Baez-Villanueva OM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111606
   Beck HE, 2019, B AM METEOROL SOC, V100, P473, DOI 10.1175/BAMS-D-17-0138.1
   Beck HE, 2017, HYDROL EARTH SYST SC, V21, P589, DOI 10.5194/hess-21-589-2017
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Berndt C, 2018, J HYDROL-REG STUD, V15, P184, DOI 10.1016/j.ejrh.2018.02.002
   Berndt C, 2014, J HYDROL, V508, P88, DOI 10.1016/j.jhydrol.2013.10.028
   Bhuiyan MAE, 2018, HYDROL EARTH SYST SC, V22, P1371, DOI 10.5194/hess-22-1371-2018
   Pham BT, 2020, ATMOS RES, V237, P0, DOI 10.1016/j.atmosres.2020.104845
   Brocca L, 2019, EARTH SYST SCI DATA, V11, P1583, DOI 10.5194/essd-11-1583-2019
   Brunsell NA, 2006, REMOTE SENS ENVIRON, V100, P200, DOI 10.1016/j.rse.2005.10.025
   Chao LJ, 2018, J HYDROL, V558, P275, DOI 10.1016/j.jhydrol.2018.01.042
   Cheema MJM, 2012, INT J REMOTE SENS, V33, P2603, DOI 10.1080/01431161.2011.617397
   Chen C, 2015, IEEE J-STARS, V8, P4592, DOI 10.1109/JSTARS.2015.2441734
   Chen CF, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203435
   Chen FR, 2020, J HYDROL, V581, P0, DOI 10.1016/j.jhydrol.2019.124414
   Chen FR, 2014, INT J REMOTE SENS, V35, P3074, DOI 10.1080/01431161.2014.902550
   Chen J, 2013, WATER RESOUR RES, V49, P4187, DOI 10.1002/wrcr.20331
   Chen ST, 2010, J HYDROL, V385, P13, DOI 10.1016/j.jhydrol.2010.01.021
   Chen SL, 2020, J HYDROL, V589, P0, DOI 10.1016/j.jhydrol.2020.125156
   Chen YY, 2018, REMOTE SENS ENVIRON, V214, P154, DOI 10.1016/j.rse.2018.05.021
   Duan Z, 2013, REMOTE SENS ENVIRON, V131, P1, DOI 10.1016/j.rse.2012.12.002
   Elnashar A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12233860
   Fan D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242962
   Funk C, 2015, SCI DATA, V2, P0, DOI 10.1038/sdata.2015.50
   Gebregiorgis AS, 2013, IEEE T GEOSCI REMOTE, V51, P704, DOI 10.1109/TGRS.2012.2196282
   Ghorbanpour AK, 2021, J HYDROL, V596, P0, DOI 10.1016/j.jhydrol.2021.126055
   Goovaerts P, 2000, J HYDROL, V228, P113, DOI 10.1016/S0022-1694(00)00144-X
   Haile AT, 2013, HYDROL PROCESS, V27, P1829, DOI 10.1002/hyp.9330
   Hengl T, 2018, PEERJ, V6, P0, DOI 10.7717/peerj.5518
   Hou AY, 2014, B AM METEOROL SOC, V95, P701, DOI 10.1175/BAMS-D-13-00164.1
   Huffman G. J., 2019, ALGORITHM THEORETICA, V0, P0
   Huffman GJ, 2007, J HYDROMETEOROL, V8, P38, DOI 10.1175/JHM560.1
   Immerzeel WW, 2009, REMOTE SENS ENVIRON, V113, P362, DOI 10.1016/j.rse.2008.10.004
   Jia SF, 2011, REMOTE SENS ENVIRON, V115, P3069, DOI 10.1016/j.rse.2011.06.009
   Jing WL, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080655
   Li M, 2010, J HYDROL, V385, P51, DOI 10.1016/j.jhydrol.2010.01.023
   Li TW, 2017, GEOPHYS RES LETT, V44, P11985, DOI 10.1002/2017GL075710
   Li YG, 2019, CHINESE GEOGR SCI, V29, P446, DOI 10.1007/s11769-019-1033-3
   Lima CHR, 2021, J HYDROL, V597, P0, DOI 10.1016/j.jhydrol.2021.126095
   Lu XY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030398
   Lu XY, 2019, J HYDROL, V575, P1239, DOI 10.1016/j.jhydrol.2019.06.019
   Ma ZQ, 2017, REMOTE SENS ENVIRON, V200, P378, DOI 10.1016/j.rse.2017.08.023
   Mohsenzadeh Karimi S., 2020, J HYDRAUL ENG, V26, P376, DOI 10.1080/09715010.2018.1495583
   Park NW, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030255
   Sharifi E, 2019, J GEOPHYS RES-ATMOS, V124, P789, DOI 10.1029/2018JD028795
   Shi YL, 2015, REMOTE SENS-BASEL, V7, P5849, DOI 10.3390/rs70505849
   Shortridge A, 2011, REMOTE SENS ENVIRON, V115, P1576, DOI 10.1016/j.rse.2011.02.017
   Spracklen DV, 2012, NATURE, V489, P282, DOI 10.1038/nature11390
   Sun L, 2021, INT J CLIMATOL, V41, P1128, DOI 10.1002/joc.6769
   Tao YM, 2016, J HYDROMETEOROL, V17, P931, DOI 10.1175/JHM-D-15-0075.1
   Trenberth KE, 2005, GEOPHYS RES LETT, V32, P0, DOI 10.1029/2005GL022760
   Ullah S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12193162
   Wu HC, 2020, J HYDROL, V584, P0, DOI 10.1016/j.jhydrol.2020.124664
   Wu T, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11091789
   Wu ZY, 2018, SCI TOTAL ENVIRON, V640, P1165, DOI 10.1016/j.scitotenv.2018.05.272
   Xie PP, 2011, J GEOPHYS RES-ATMOS, V116, P0, DOI 10.1029/2011JD016118
   Xu SG, 2015, REMOTE SENS ENVIRON, V162, P119, DOI 10.1016/j.rse.2015.02.024
   Xu Y, 2018, J ANAL TEST, V2, P249, DOI 10.1007/s41664-018-0068-2
   Yan X, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13112040
   Yang YF, 2014, J HYDROMETEOROL, V15, P459, DOI 10.1175/JHM-D-13-041.1
   Yang ZW, 2017, J GEOPHYS RES-ATMOS, V122, P5267, DOI 10.1002/2016JD026177
   Yue T. X., 2011, SURFACE MODELING HIG, V0, P0, DOI DOI 10.1201/b10392
   Yue TX, 2007, GEOMORPHOLOGY, V91, P161, DOI 10.1016/j.geomorph.2007.02.006
   Zhang L, 2021, J HYDROL, V594, P0, DOI 10.1016/j.jhydrol.2021.125969
   Zhang XJ, 2015, J GEOPHYS RES-ATMOS, V120, P6426, DOI 10.1002/2015JD023400
   Zhao N, 2018, INT J CLIMATOL, V38, P3309, DOI 10.1002/joc.5502
   Zhao TB, 2014, INT J CLIMATOL, V34, P2749, DOI 10.1002/joc.3872
NR 74
TC 11
Z9 11
U1 11
U2 48
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1027-5606
EI 1607-7938
J9 HYDROL EARTH SYST SC
JI Hydrol. Earth Syst. Sci.
PD NOV 3
PY 2021
VL 25
IS 11
BP 5667
EP 5682
DI 10.5194/hess-25-5667-2021
PG 16
WC Geosciences, Multidisciplinary; Water Resources
SC Geology; Water Resources
GA WT3DX
UT WOS:000715749100001
DA 2023-04-26
ER

PT J
AU Liu, T
   Yang, LX
   Lunga, D
AF Liu, Tao
   Yang, Lexie
   Lunga, Dalton
TI Change detection using deep learning approach with object-based image analysis
SO REMOTE SENSING OF ENVIRONMENT
LA English
DT Article
DE Change detection; OBIA; Deep learning; Pixel-based; Feature fusion
ID neural-networks; convolutional networks; random forest; classification; misregistration; segmentation; machine
AB In their applications, both deep learning techniques and object-based image analysis (OBIA) have shown better performance separately than conventional methods on change detection tasks. However, efforts to investigate the effect of combining these two techniques for advancing change detection techniques are unexplored in current literature. This study proposes a novel change detection method implementing change feature extraction using convolutional neural networks under an OBIA framework. To demonstrate the effectiveness of our proposed method, we compare the proposed method against benchmark pixel-based counterparts on aerial images for the task of multi-class change detection. To thoroughly assess the performance of our proposed method, this study also for the first time compared three common feature fusion schemes for change detection architecture: concatenation, differencing, and Long Short-Term Memory (LSTM). The proposed method was also tested on simulated misregistered images to evaluate its robustness, a factor that plays an important role in compromising change detection accuracy but has not been investigated for supervised change detection methods in the literature. Finally, the proposed change detection method was also tested using very high resolution (VHR) satellite images for binary class change detection to map an impacted area caused by natural disaster and the result was evaluated using reference data from the Federal Emergency Management Agency (FEMA). With the experimental results from these two sets of experiments, we showed that (1) our proposed method achieved substantially higher accuracy and computational efficiency when compared to pixel-based methods, (2) three feature fusion schemes did not show a significant difference for overall accuracy, (3) our proposed method was robust in image misregistration in both testing and training data, (4) we demonstrate the potential impact of automation to decision making by deploying our method to map a large geographic area affected by a recent natural disaster.
C1 [Liu, Tao; Yang, Lexie; Lunga, Dalton] Oak Ridge Natl Lab, Geospatial Sci & Human Dynam Div, GeoAI, Oak Ridge, TN USA.
   [Liu, Tao] Michigan Technol Univ, Coll Forest Resources & Environm Sci, Houghton, MI 49931 USA.
C3 United States Department of Energy (DOE); Oak Ridge National Laboratory; Michigan Technological University
RP Liu, T (corresponding author), Michigan Technol Univ, Coll Forest Resources & Environm Sci, Houghton, MI 49931 USA.
EM taoliu@mtu.edu
FU US Department of Energy (DOE) [DE-AC05-00OR22725]
CR Abd El-Kawy OR, 2011, APPL GEOGR, V31, P483, DOI 10.1016/j.apgeog.2010.10.012
   Abuelgasim AA, 1999, REMOTE SENS ENVIRON, V70, P208, DOI 10.1016/S0034-4257(99)00039-5
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Boldt M., 2012, EARTH RESOURCES ENV, V0, P85380E
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2014, ISPRS J PHOTOGRAMM, V87, P19, DOI 10.1016/j.isprsjprs.2013.10.007
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Cleve C, 2008, COMPUT ENVIRON URBAN, V32, P317, DOI 10.1016/j.compenvurbsys.2007.10.001
   Comber A, 2004, PHOTOGRAMM ENG REM S, V70, P931, DOI 10.14358/PERS.70.8.931
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Duro DC, 2013, PHOTOGRAMM ENG REM S, V79, P259, DOI 10.14358/PERS.79.3.259
   Ehlers M., 2014, GLOBAL URBAN MONITOR, V0, P346
   FEMA, 2016, DAMAGE ASSESSMENT OP, V0, P0
   FEMA, 2019, HIST DAMAGE ASSESSME, V0, P0
   Fu BL, 2017, ECOL INDIC, V73, P105, DOI 10.1016/j.ecolind.2016.09.029
   Gao P., 2012, GEOINF GEOINFORMATIC, V0, PP1, DOI 10.1109/GEOINFORMATICS.2012.6270319
   Gong JH, 2012, INT J REMOTE SENS, V33, P3907, DOI 10.1080/01431161.2011.636767
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   He K., 2015, PROC CVPR IEEE, V5, P6
   Healey SP, 2018, REMOTE SENS ENVIRON, V204, P717, DOI 10.1016/j.rse.2017.09.029
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Karpatne A, 2016, IEEE GEOSC REM SEN M, V4, P8, DOI 10.1109/MGRS.2016.2528038
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu T., 2020, 2020 IEEE INT GEOSC, V0, P0
   Liu T, 2018, ISPRS J PHOTOGRAMM, V139, P154, DOI 10.1016/j.isprsjprs.2018.03.006
   Liu T, 2018, GISCI REMOTE SENS, V55, P243, DOI 10.1080/15481603.2018.1426091
   Liu X, 2002, INT J REMOTE SENS, V23, P2513, DOI 10.1080/01431160110097240
   Lunga D, 2018, IEEE J-STARS, V11, P962, DOI 10.1109/JSTARS.2018.2795753
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060506
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Microsoft, 2020, COMPUTER GENERATED B, V0, P0
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   NOAA, 2020, US CLIMATE EXTREMES, V0, P0
   Pande-Chhetri R, 2017, EUR J REMOTE SENS, V50, P564, DOI 10.1080/22797254.2017.1373602
   Raj A, 2016, INT CONF IND INF SYS, V0, P54
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   TOWNSHEND JRG, 1992, IEEE T GEOSCI REMOTE, V30, P1054, DOI 10.1109/36.175340
   van der Walt S, 2014, PEERJ, V2, P0, DOI 10.7717/peerj.453
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Vu TT, 2004, INT GEOSCI REMOTE SE, V0, P3413
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Wang FG, 2010, ENVIRON MONIT ASSESS, V162, P311, DOI 10.1007/s10661-009-0798-8
   Wang SM, 2018, RESOUR CONSERV RECY, V128, P526, DOI 10.1016/j.resconrec.2016.05.011
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yang LM, 2003, PHOTOGRAMM ENG REM S, V69, P1003, DOI 10.14358/PERS.69.9.1003
   YUAN J, 2016, INT J HUM RESOUR MAN, V0, P2703
   Yuhas R.H., 1992, PROC SUMMARIES 3 ANN, V1, P147
   ZHAN Y, 2017, 2016 IEEE INT C BIG, V14, P1845
   Zhu Z, 2020, REMOTE SENS ENVIRON, V238, P0, DOI 10.1016/j.rse.2019.03.009
NR 62
TC 36
Z9 36
U1 19
U2 115
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0034-4257
EI 1879-0704
J9 REMOTE SENS ENVIRON
JI Remote Sens. Environ.
PD APR 15
PY 2021
VL 256
IS 
BP 
EP 
DI 10.1016/j.rse.2021.112308
EA JAN 2021
PG 16
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology
GA QT5NB
UT WOS:000626633100001
DA 2023-04-26
ER

PT J
AU Danner, M
   Berger, K
   Wocher, M
   Mauser, W
   Hank, T
AF Danner, Martin
   Berger, Katja
   Wocher, Matthias
   Mauser, Wolfram
   Hank, Tobias
TI Efficient RTM-based training of machine learning regression algorithms to quantify biophysical & biochemical traits of agricultural crops
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Reflectance modelling; Hyperspectral remote sensing; Radiative transfer model; SPARC; Grid search; Machine learning
ID leaf-area index; imaging-spectroscopy; gaussian-processes; surface reflectance; vegetation index; retrieval; canopy; model; lai; sentinel-2
AB With an upcoming unprecedented stream of imaging spectroscopy data, there is a rising need for tools and software applications exploiting the spectral possibilities to extract relevant information on an operational basis. In this study, we investigate the potential of a scientific processor designed to quantify biophysical and biochemical crop traits from spectroscopic imagery of the upcoming Environmental Mapping and Analysis Program (EnMAP) satellite. Said processor relies on a hybrid retrieval workflow executing pre-trained machine learning regression models fast and efficiently based on training data from a lookup table of synthetic vegetation spectra and their associated parameterization of the well-known radiative transfer model (RTM) PROSAIL. The established models provide spatial information about leaf area index (LAI), average leaf inclination angle (ALIA), leaf chlorophyll content (C-ab) and leaf mass per area (C-m). In contrast to using site-specific training data, the approach facilitates a universal application without the need to integrate a priori information into the processor. Four machine learning algorithms, namely artificial neural networks (ANN), random forest regression (RFR), support vector machine regression (SVR), and Gaussian process regression (GPR), were found to estimate biophysical and biochemical variables of unseen targets with high performance (relative error scores < 10%). ANNs excelled in terms of accuracy, model size and execution time when the 242 spectral bands were transformed into 15 principal components, the signals of which were scaled by a z-transformation. Validation using in situ data from the SPARC03 Barrax campaign dataset revealed an overall good estimation of measured functional traits, for instance for LAI with root mean squared error (RMSE) of 0.81 m(2) m(-2), and for C-ab RMSE of 6.2 mu g cm(-2) with the ANN model. Moreover, both crop traits could be successfully mapped using a pseudo-EnMAP scene revealing plausible within-field patterns. Conformity with LAI output of the SNAP biophysical processor was found especially for grassland and maize in the vegetative stages. Based on these findings, ANN models are considered the best choice for implementation of a hybrid retrieval workflow within the context of operational agricultural crop traits monitoring from future satellite imaging spectroscopy.
C1 [Danner, Martin; Berger, Katja; Wocher, Matthias; Mauser, Wolfram; Hank, Tobias] Ludwig Maximilians Univ Munchen, Dept Geog, Luisenstr 37, D-80333 Munich, Germany.
C3 University of Munich
RP Danner, M (corresponding author), Ludwig Maximilians Univ Munchen, Dept Geog, Luisenstr 37, D-80333 Munich, Germany.
EM m.danner@lmu.de; katja.berger@lmu.de; m.wocher@lmu.de; w.mauser@lmu.de; tobias.hank@lmu.de
FU Space Administration of the German Aerospace Center (DLR) - German Ministry of Economics and Technology [50EE1623]; EnMAP scientific preparation program under the DLR Space Administration; German Federal Ministry of Economic Affairs and Energy [50EE1923]
CR Amin E, 2021, REMOTE SENS ENVIRON, V255, P0, DOI 10.1016/j.rse.2020.112168
   [Anonymous], 2003, P 2 CHRIS PROB WORKS, V0, P0
   [Anonymous], 1900, V10, V0, P0
   [Anonymous], 1900, V132, V0, P88
   [Anonymous], 2020, INT J APPL EARTH OBS, V92, P0
   Arenas-Garcia J, 2013, IEEE SIGNAL PROC MAG, V30, P16, DOI 10.1109/MSP.2013.2250591
   Asner GP, 1998, REMOTE SENS ENVIRON, V64, P234, DOI 10.1016/S0034-4257(98)00014-5
   Bacour C, 2006, NEURAL NETWORK ESTIM, V0, P0
   Belda S, 2020, OPTIMIZING GAUSSIAN, V0, P0
   Berger K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10122063
   Berger K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010085
   Brede B, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060915
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Broge NH, 2001, REMOTE SENS ENVIRON, V76, P156, DOI 10.1016/S0034-4257(00)00197-8
   Camps-Valls G, 2018, APPL SOFT COMPUT, V68, P69, DOI 10.1016/j.asoc.2018.03.021
   Camps-Valls G, 2016, IEEE GEOSC REM SEN M, V4, P58, DOI 10.1109/MGRS.2015.2510084
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P339, DOI 10.1109/LGRS.2006.871748
   Camps-Valls G, 2009, IEEE GEOSCI REMOTE S, V6, P248, DOI 10.1109/LGRS.2008.2009077
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Chapman O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11182129
   Danner M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101150
   Darvishzadeh R, 2008, INT J APPL EARTH OBS, V10, P358, DOI 10.1016/j.jag.2008.02.005
   De Grave C, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112101
   Doktor D, 2014, REMOTE SENS-BASEL, V6, P12247, DOI 10.3390/rs61212247
   DUrso G, 2004, RETRIEVAL LEAF AREA, V0, P0
   Estevez J, 2020, ISPRS J PHOTOGRAMM, V167, P289, DOI 10.1016/j.isprsjprs.2020.07.004
   Fang HL, 2003, IEEE T GEOSCI REMOTE, V41, P2052, DOI 10.1109/TGRS.2003.813493
   Feingersh T, 2016, OPTICAL PAYLOADS FOR SPACE MISSIONS, V0, P247
   Feret JB, 2017, REMOTE SENS ENVIRON, V193, P204, DOI 10.1016/j.rse.2017.03.004
   Feret J.B, 2020, PROSPECT PROESTIMATI, V0, P0
   Gandia S, 2004, ESA SP, V578, P40
   Gehler P. V., 2009, KERNEL METHODS REMOT, V0, PP25, DOI 10.1002/9780470748992.ch2
   Gitelson A.A, 2018, BIOPHYSICAL BIOCHEMI, V1, P0
   Glenn EP, 2008, SENSORS-BASEL, V8, P2136, DOI 10.3390/s8042136
   Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9
   Green RO, 2018, INT GEOSCI REMOTE SE, V0, P183
   Guanter L, 2005, IEEE T GEOSCI REMOTE, V43, P2908, DOI 10.1109/TGRS.2005.857915
   Guanter L, 2015, REMOTE SENS-BASEL, V7, P8830, DOI 10.3390/rs70708830
   Hanes JM, 2014, SPRING REMOTE SENS P, V0, PP1, DOI 10.1007/978-3-642-25047-7
   Hank TB, 2015, REMOTE SENS-BASEL, V7, P3934, DOI 10.3390/rs70403934
   Houborg R, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060890
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Izquierdo-Verdiguier E, 2018, INT GEOSCI REMOTE SE, V0, P5776
   JACQUEMOUD S, 1993, REMOTE SENS ENVIRON, V44, P281, DOI 10.1016/0034-4257(93)90022-P
   JACQUEMOUD S, 1990, REMOTE SENS ENVIRON, V34, P75, DOI 10.1016/0034-4257(90)90100-Z
   Jacquemoud S, 2009, REMOTE SENS ENVIRON, V113, PS56, DOI 10.1016/j.rse.2008.01.026
   Janicke C, 2020, REMOTE SENS LETT, V11, P1, DOI 10.1080/2150704X.2019.1670518
   Karlik B, 2011, INT J ARTIFICIAL INT, V4, P111
   Kganyago M, 2018, INT J APPL EARTH OBS, V67, P10, DOI 10.1016/j.jag.2017.12.008
   King DB, 2015, ACS SYM SER, V1214, P1
   Koetz B, 2005, REMOTE SENS ENVIRON, V95, P115, DOI 10.1016/j.rse.2004.11.017
   LAI fAPAR fCover and LAIxCab, 1900, V105, V0, P313
   Lary DJ, 2016, GEOSCI FRONT, V7, P3, DOI 10.1016/j.gsf.2015.07.003
   Lee CM, 2015, REMOTE SENS ENVIRON, V167, P6, DOI 10.1016/j.rse.2015.06.012
   Locherer M, 2015, REMOTE SENS-BASEL, V7, P10321, DOI 10.3390/rs70810321
   Loizzo R, 2018, INT GEOSCI REMOTE SE, V0, P175
   Luoma S.N, 2015, SCIENCE, V13, P0
   Marti J, 2004, SPECTRA BARRAX CAMPA, V0, P0
   Moreno J, 2015, OPTICAL REMOTE SENSI, V0, P0
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Myneni R., 2000, USERS GUIDE FPAR LAI, V0, P0
   NASA EO, 2020, MET DAT, V0, P0
   Nieke J, 2018, INT GEOSCI REMOTE SE, V0, P157
   Norman J. M., 1989, PLANT PHYSIOLOGICAL ECOLOGY: FIELD METHODS AND INSTRUMENTATION., V0, P301
   Pal M, 2005, INT J REMOTE SENS, V26, P1007, DOI 10.1080/01431160512331314083
   Pasqualotto N, 2019, AGRONOMY-BASEL, V9, P0, DOI 10.3390/agronomy9100663
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939
   Rabe A, 2018, INT GEOSCI REMOTE SE, V0, P7764
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Richter K, 2009, CAN J REMOTE SENS, V35, P230, DOI 10.5589/m09-010
   Rodriguez-Fernandez NJ, 2017, INT GEOSCI REMOTE SE, V0, PP1581, DOI 10.1109/IGARSS.2017.8127273
   Segl K, 2012, IEEE J-STARS, V5, P522, DOI 10.1109/JSTARS.2012.2188994
   Smola AJ, 2001, ADV NEUR IN, V13, P619
   Snoek J., 2012, ADV NEURAL INFORM PR, V0, P0
   Sohl-Dickstein J, 2014, PR MACH LEARN RES, V32, P604
   Thenkabail P, 2017, HYPERSPECTRAL REMOTE, V0, P0
   Thompson DR, 2015, REMOTE SENS ENVIRON, V167, P64, DOI 10.1016/j.rse.2015.02.010
   Tripathi R, 2012, J INDIAN SOC REMOTE, V40, P19, DOI 10.1007/s12524-011-0129-8
   Upreti D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050481
   van der Maaten L.J.P., 2007, DIMENSIONALITY REDUC, V0, P0
   Verger A, 2008, REMOTE SENS ENVIRON, V112, P2789, DOI 10.1016/j.rse.2008.01.006
   Verger A, 2014, REMOTE SENS ENVIRON, V152, P654, DOI 10.1016/j.rse.2014.06.006
   VERHOEF W, 1984, REMOTE SENS ENVIRON, V16, P125, DOI 10.1016/0034-4257(84)90057-9
   Verhoef W, 2007, REMOTE SENS ENVIRON, V109, P166, DOI 10.1016/j.rse.2006.12.013
   Verrelst J, 2021, IEEE GEOSCI REMOTE S, V18, P2038, DOI 10.1109/lgrs.2020.3014676
   Verrelst J, 2019, SURV GEOPHYS, V40, P589, DOI 10.1007/s10712-018-9478-y
   Verrelst J, 2016, INT J APPL EARTH OBS, V52, P554, DOI 10.1016/j.jag.2016.07.016
   Verrelst J, 2014, IEEE T GEOSCI REMOTE, V52, P257, DOI 10.1109/TGRS.2013.2238242
   Verrelst J, 2012, REMOTE SENS ENVIRON, V118, P127, DOI 10.1016/j.rse.2011.11.002
   Vuolo F, 2008, INT J REMOTE SENS, V29, P5063, DOI 10.1080/01431160802036490
   Wang L, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0207624
   Wang TT, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17010081
   Wang WM, 2007, AGR FOREST METEOROL, V143, P106, DOI 10.1016/j.agrformet.2006.12.003
   Waske B., 2009, KERNEL METHODS REMOT, V0, PP1, DOI 10.1002/9780470748992.CH1
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111402
   Weiss M, 2000, AGRONOMIE, V20, P3, DOI 10.1051/agro:2000105
   Weiss M., 2016, S2TOOLBOX LEVEL 2 PR, V0, P0
   White H., 1992, ARTIFICIAL NEURAL NE, V0, P0
   Wocher M, 2020, INT J APPL EARTH OBS, V93, P0, DOI 10.1016/j.jag.2020.102219
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Yang XH, 2011, SCI CHINA LIFE SCI, V54, P272, DOI 10.1007/s11427-011-4135-4
   YODER BJ, 1995, REMOTE SENS ENVIRON, V53, P199, DOI 10.1016/0034-4257(95)00135-N
   Zabel F, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0107522
   Ziliani M., 2018, AGU FALL M, V0, P0
NR 108
TC 43
Z9 44
U1 16
U2 62
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAR 15
PY 2021
VL 173
IS 
BP 278
EP 296
DI 10.1016/j.isprsjprs.2021.01.017
EA FEB 2021
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO3ZZ
UT WOS:000640986100018
DA 2023-04-26
ER

PT J
AU Pan, F
   Wu, ZB
   Liu, Q
   Xu, Y
   Wei, ZH
AF Pan, Fei
   Wu, Zebin
   Liu, Qian
   Xu, Yang
   Wei, Zhihui
TI DCFF-Net: A Densely Connected Feature Fusion Network for Change Detection in High-Resolution Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Remote sensing; Semantics; Image resolution; Image segmentation; Network architecture; Data mining; Change detection (CD); deep learning; feature fusion; remote sensing images
AB Change detection is one of the main applications of remote sensing image analysis. Due to the strong capabilities of neural networks in other fields, a growing number of research works of automatic remote sensing change detection focus on deep learning algorithms. The network architectures of change detection are mostly based on the encoder-decoder architecture. Although the encoder-decoder architecture can acquire high-level semantic information for change detection, it still exists some problems in high-resolution remote sensing images, such as the loss of high-resolution location information during the down-sampling process, insufficient high-resolution information during the up-sampling reconstruction process, and small changes are challenging to detect. To address these issues, we propose a densely connected feature fusion network (DCFF-Net) for change detection. First, we extract the multiscale raw image features by two-stream network architecture with the same weights. At the same time, bitemporal images are concatenated as one input with six channels to generate the change map by a difference extraction network based on encoder-decoder architecture. In order to better reconstruct the edge details of the change map and the changes with the small region, an attention mechanism is employed in each up-sampling process to fuse the previously extracted raw image features with difference features. The deep supervision strategy is adopted to alleviate the problem of gradient vanishing. In addition, a novel weighted loss is proposed by combining self-adjusting dice loss and binary cross-entropy loss to alleviate the data imbalance issue. We perform extensive experiments on two public change detection datasets. The visual comparison and quantitative evaluation confirm that our proposed method outperformsother state-of-the-art methods.
C1 [Pan, Fei; Wu, Zebin; Liu, Qian; Xu, Yang; Wei, Zhihui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Wu, ZB (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM 120106022643@njust.edu.cn; zebin.wu@gmail.com; liuqianahu@163.com; xuyangth90@njust.edu.cn; gswei@njust.edu.cn
FU National Natural Science Foundation of China [61772274, 62071233, 61671243, 61976117]; Jiangsu Provincial Natural Science Foundation of China [BK20211570, BK20180018, BK20191409]; Fundamental Research Funds for the Central Universities [30917015104, 30919011103, 30919011402, 30921011209]; China Postdoctoral Science Foundation [2017M611814, 2018T110502]
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   [Anonymous], 2015, C TRACK P, V0, P0
   [Anonymous], 2015, INT C MED IM COMP CO, V0, P0
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101662
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Chen KQ, 2017, INT GEOSCI REMOTE SE, V0, P1672
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Fang S, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1145/3510858.3510863
   Fu W., 2020, MANUAL DIGITAL EARTH, V0, PP55, DOI 10.1007/978-981-32-9915-3_3
   Guo E., 2018, LEARNING MEASURE CHA, V0, P0
   Guo HN, 2021, IEEE T GEOSCI REMOTE, V59, P4287, DOI 10.1109/TGRS.2020.3014312
   Hanan NP, 2020, NATURE, V587, P42, DOI 10.1038/d41586-020-02830-3
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang ZM, 2016, INT GEOSCI REMOTE SE, V0, PP1835, DOI 10.1109/IGARSS.2016.7729471
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), V0, P115
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lebedev M., 2018, INT ARCH PHOTOGRAM R, V42, P565, DOI 10.5194/isprs-archives-XLII-2-565-2018
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li DR, 2021, GEO-SPAT INF SCI, V24, P85, DOI 10.1080/10095020.2020.1838957
   Li X, 2018, IEEE J-STARS, V11, P3680, DOI 10.1109/JSTARS.2018.2865187
   Li XY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), V0, PP465, DOI 10.1007/978-981-15-3863-6_51
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Ma L, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8090761
   Maltezos E, 2019, IEEE GEOSCI REMOTE S, V16, P155, DOI 10.1109/LGRS.2018.2867736
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Wang FG, 2010, ENVIRON MONIT ASSESS, V162, P311, DOI 10.1007/s10661-009-0798-8
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang CS, 2018, IEEE J-STARS, V11, P2440, DOI 10.1109/JSTARS.2018.2817121
   Zhang XW, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3049370
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 46
TC 5
Z9 5
U1 6
U2 37
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11974
EP 11985
DI 10.1109/JSTARS.2021.3129318
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XL5BR
UT WOS:000728159900002
DA 2023-04-26
ER

PT J
AU Fan, RY
   Feng, RY
   Han, W
   Wang, LZ
AF Fan, Runyu
   Feng, Ruyi
   Han, Wei
   Wang, Lizhe
TI Urban Functional Zone Mapping With a Bibranch Neural Network via Fusing Remote Sensing and Social Sensing Data
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Urban areas; Sensors; Task analysis; Data models; Manuals; Visualization; Deep learning (DL); OpenStreetMap (OSM); remote sensing; social sensing; urban functional zones (UFZ) mapping
ID land-use classification; performance evaluation; mobile phone; points; images
AB Urban functional zones (UFZs) are the urban spaces divided by various functional activities and are the basic units of daily human activities. UFZ mapping, which identifies the UFZ categories in different spatial areas of a city, is of considerable significance to urban management, design, and sustainable development. Various deep learning-based (DL-based) methods, which achieved remarkable results in an end-to-end supervised process, were proposed for UFZ mapping. However, the excellent performance of DL-based models relies heavily on a large number of well-annotated samples, which is impossible to obtain in practical UFZ mapping scenarios. Obtaining these well-annotated samples requires a lot of manual costs, which greatly limits the outcome of these methods in practical UFZ mapping tasks. In this article, we proposed a UFZ mapping method using OpenStreetMap-based (OSM-based) sample generation and the bi-branch neural network (BibNet). By adopting the idea of OSM-based sample generation, the proposed method utilized large-scale crowdsourcing labeled data (source domain) in OSM to generate a UFZ dataset (target domain) from OSM using remote sensing and social sensing data. Considering the inconsistent response of UFZ to various data observations, it is difficult to fully reflect the characteristics of UFZs using only remote sensing or social sensing data. We further proposed the BibNet, which utilizes two different deep neural network branches to comprehensively harness remote sensing images and social sensing data to map the UFZ. Experiments were conducted in Shenzhen City and Hong Kong City (Yau Tsim Mong District, Sham Shui Po District and Kowloon City District). The proposed method achieved an overall accuracy (OA) of 94.46% in the testing set of Shenzhen City and OA of 91.90% in the testing set of Hong Kong City.
C1 [Fan, Runyu; Feng, Ruyi; Han, Wei; Wang, Lizhe] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
   [Fan, Runyu; Feng, Ruyi; Han, Wei; Wang, Lizhe] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.
C3 China University of Geosciences; China University of Geosciences
RP Wang, LZ (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
EM runyufan@cug.edu.cn; fengry@cug.edu.cn; weihan@cug.edu.cn; lizhe.wang@gmail.com
FU National Natural Science Foundation of China [41925007, U1711266]
CR Arsanjani JJ, 2015, INT J APPL EARTH OBS, V35, P329, DOI 10.1016/j.jag.2014.09.009
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3081421
   Cheng G, 2020, IEEE J-STARS, V13, P3735, DOI 10.1109/JSTARS.2020.3005403
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Dalal N, 2005, PROC CVPR IEEE, V0, PP886, DOI 10.1109/cvpr.2005.177
   Du ZH, 2020, T GIS, V24, P123, DOI 10.1111/tgis.12591
   Forget Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071145
   Gao QK, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0215656
   Gao S, 2017, T GIS, V21, P446, DOI 10.1111/tgis.12289
   Hagenauer J, 2012, INT J GEOGR INF SCI, V26, P963, DOI 10.1080/13658816.2011.619501
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Han W, 2021, IEEE GEOSC REM SEN M, V9, P8, DOI 10.1109/MGRS.2020.3041450
   Hartigan J. A., 1979, APPLIED STATISTICS, V28, P100, DOI 10.2307/2346830
   Hu YF, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11051385
   Jiang Guilin, 2016, JOURNAL OF COMPUTER APPLICATIONS, V36, P2046, DOI 10.11772/j.issn.1001-9081.2016.07.2046
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XJ, 2017, GISCI REMOTE SENS, V54, P819, DOI 10.1080/15481603.2017.1338389
   Lindeberg T., 2012, SCALE INVARIANT FEAT, V7, P10491, DOI 10.4249/scholarpedia.10491
   OJALA T, 1994, INT C PATT RECOG, V0, PP582, DOI 10.1109/ICPR.1994.576366
   Pei T, 2014, INT J GEOGR INF SCI, V28, P1988, DOI 10.1080/13658816.2014.913794
   Pershina M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P732
   Purver M., 2012, EACL 2012 13 C EUR C, V0, P0
   Reiplinger M, 2014, LECT NOTES ARTIF INT, V8686, P345, DOI 10.1007/978-3-319-10888-9_35
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahni T, 2017, INT CONF COMMUN SYST, V0, PP548, DOI 10.1109/COMSNETS.2017.7945451
   Shen Y, 2016, CITIES, V55, P9, DOI 10.1016/j.cities.2016.03.013
   Srivastava S, 2019, REMOTE SENS ENVIRON, V228, P129, DOI 10.1016/j.rse.2019.04.014
   Stefanov WL, 2001, REMOTE SENS ENVIRON, V77, P173, DOI 10.1016/S0034-4257(01)00204-8
   Sun T, 2019, PROC CVPR IEEE, V0, PP7501, DOI 10.1109/CVPR.2019.00769
   Tu W, 2017, INT J GEOGR INF SCI, V31, P2331, DOI 10.1080/13658816.2017.1356464
   Van de Voorde T, 2011, LANDSCAPE URBAN PLAN, V102, P143, DOI 10.1016/j.landurbplan.2011.03.017
   Vargas-Munoz JE, 2019, ISPRS J PHOTOGRAMM, V147, P283, DOI 10.1016/j.isprsjprs.2018.11.010
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Xu YH, 2019, IEEE J-STARS, V12, P1709, DOI 10.1109/JSTARS.2019.2911113
   Yang J., 2007, PROC INT WORKSHOP WO, V0, PP197, DOI 10.1145/1290082.1290111
   Yao Y, 2017, INT J GEOGR INF SCI, V31, P825, DOI 10.1080/13658816.2016.1244608
   Zhan XY, 2014, NETW SPAT ECON, V14, P647, DOI 10.1007/s11067-014-9264-4
   Zhang WX, 2017, COMPUT ENVIRON URBAN, V64, P215, DOI 10.1016/j.compenvurbsys.2017.03.001
   Zhang XY, 2020, ISPRS J PHOTOGRAMM, V161, P1, DOI 10.1016/j.isprsjprs.2020.01.005
   Zhang XY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020281
   Zhang XY, 2017, ISPRS J PHOTOGRAMM, V132, P170, DOI 10.1016/j.isprsjprs.2017.09.007
   Zhou W, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111458
   Zhu Z, 2012, REMOTE SENS ENVIRON, V117, P72, DOI 10.1016/j.rse.2011.07.020
NR 52
TC 5
Z9 6
U1 11
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11737
EP 11749
DI 10.1109/JSTARS.2021.3127246
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XG0VV
UT WOS:000724480200007
DA 2023-04-26
ER

PT J
AU Su, JH
   Liao, JJ
   Gu, DJ
   Wang, ZY
   Cai, GR
AF Su, Jinhe
   Liao, JiaJia
   Gu, Dujuan
   Wang, Zongyue
   Cai, Guorong
TI Object Detection in Aerial Images Using a Multiscale Keypoint Detection Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Attention network; convolutional neural networks (CNNs); loss functions; object detection; unmanned aerial vehicles
AB Automatic object detection in aerial imagery is being increasingly adopted in many applications, such as traffic monitoring, smart cities, and disaster assistance. In keypoint-based detectors, the predictionmodules are usually generated froma fixed featuremap scale. This configuration significantly limits the ability to detect multiscale objects in aerial scenes. The corner selection module in these detectors often ignores that a category in an aerial image is relatively unitary. In this article, a novel network, called the multiscale keypoint detection network (MKD-Net), is proposed to address these challenges. MKD-Net fuses multiscale layers to generate multiple feature maps for objects of different sizes. During the inference phase, both feature maps can be exploited for predicting corners. Moreover, a category attention module is designed to reduce the channel noise for a single-category scene. Experiments on benchmarks PASCAL VOC and DOTA show promising performance ofMKD-Net compared with the baseline network. The code is available on https://github.com/jason-su/MKD-NET.
C1 [Su, Jinhe; Liao, JiaJia; Wang, Zongyue; Cai, Guorong] Jimei Univ, Sch Comp Engn, Xiamen 361021, Peoples R China.
   [Gu, Dujuan] NSFOCUS Informat Technol Co Ltd, Beijing 100000, Peoples R China.
C3 Jimei University
RP Cai, GR (corresponding author), Jimei Univ, Sch Comp Engn, Xiamen 361021, Peoples R China.
EM sujh@jmu.edu.cn; jiajialiao@jmu.edu.cn; gudujuan@sina.com; wangzongyue@jmu.edu.cn; guorongcai.jmu@gmail.com
FU Natural Science Foundation of Fujian Province, China [2020J01701]; Scientific Research Foundation of Jimei University, China [ZQ2019013]; Fujian Provincial Science and Technology Program [JAT190318]
CR [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   Bodla N, 2017, IEEE I CONF COMP VIS, V0, PP5562, DOI 10.1109/ICCV.2017.593
   Cheng G, 2016, PROC CVPR IEEE, V0, PP2884, DOI 10.1109/CVPR.2016.315
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Deng ZP, 2017, IEEE J-STARS, V10, P3652, DOI 10.1109/JSTARS.2017.2694890
   Duan KW, 2019, IEEE I CONF COMP VIS, V0, PP6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Jiang YY, 2018, INT C PATT RECOG, V0, P3610
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Law H., 1900, V2019, V0, P0
   Law H., 2018, ARXIV180801244, V0, P0
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Newell A, 2017, ADV NEUR IN, V30, P0
   Newell A, 2017, ADV NEUR IN, V30, P0
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Sommer LW, 2017, IEEE WINT CONF APPL, V0, PP311, DOI 10.1109/WACV.2017.41
   Tian Z, 2019, IEEE I CONF COMP VIS, V0, PP9626, DOI 10.1109/ICCV.2019.00972
   Wang JQ, 2019, PROC CVPR IEEE, V0, PP2960, DOI 10.1109/CVPR.2019.00308
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Yang X, 2019, IEEE I CONF COMP VIS, V0, PP8231, DOI 10.1109/ICCV.2019.00832
   Zhang S, 2019, IEEE GEOSCI REMOTE S, V16, P864, DOI 10.1109/LGRS.2018.2888887
   Zhu CC, 2019, PROC CVPR IEEE, V0, PP840, DOI 10.1109/CVPR.2019.00093
   Zhu P., 2018, ARXIV PREPRINT ARXIV, V0, P0
NR 28
TC 5
Z9 5
U1 6
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1389
EP 1398
DI 10.1109/JSTARS.2020.3044733
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SO6CB
UT WOS:000659056800001
DA 2023-04-26
ER

PT J
AU Qi, KL
   Yang, C
   Hu, CL
   Shen, YL
   Wu, HY
AF Qi, Kunlun
   Yang, Chao
   Hu, Chuli
   Shen, Yonglin
   Wu, Huayi
TI Deep Object-Centric Pooling in Convolutional Neural Network for Remote Sensing Scene Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Training; Location awareness; Feature extraction; Convolutional neural networks; Visualization; Earth; Convolutional neural network (CNN); feature pooling; object-centric pooling; remote sensing (RS) scene classification
AB Remote sensing imagery typically comprises successive background contexts and complex objects. Global average pooling is a popular choice to connect the convolutional and fully connected (FC) layers for the deep convolution network. This article equips the networks with another pooling strategy, namely the deep object-centric pooling (DOCP), to pool convolutional features considering the location of an object within the scene image. The proposed DOCP network structure consists of the following two steps: inferring object's location and separately pooling the foreground and background features to generate an object-level representation. Specifically, a spatial context module is presented to learn the location of the object of interest in the scene image. Then, the convolutional feature maps are pooled separately in the foreground and background of the object. Finally, the FC layer concatenates these pooled features and is followed by a batch normalization layer, a dropout layer, and a softmax layer. Two challenging datasets are employed to validate our approach. The experimental results demonstrate that the proposed DOCP-net can outperform the corresponding pooling methods and achieve a better classification performance than other pretrained convolutional neural network-based scene classification methods.
C1 [Qi, Kunlun; Yang, Chao; Hu, Chuli; Shen, Yonglin] China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
   [Wu, Huayi] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 China University of Geosciences; Wuhan University
RP Yang, C (corresponding author), China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
EM qikunlun@cug.edu.cn; yangchao@cug.edu.cn; huchl@cug.edu.cn; shenyl@cug.edu.cn; wuhuayi@whu.edu.cn
FU Hubei Key Research, and Development Program in China [2020AAA004]; National Key Research and Development Program of China [2019YFB2102903]; National Natural Science Foundation of China [41701410]; Fundamental Research Funds for the Central Universities, China University of Geosciences (Wuhan) [CUG190624]
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   Bi Q, 2020, NEUROCOMPUTING, V377, P345, DOI 10.1016/j.neucom.2019.11.068
   Bilen H, 2016, PROC CVPR IEEE, V0, PP2846, DOI 10.1109/CVPR.2016.311
   Cao R, 2021, IEEE GEOSCI REMOTE S, V18, P43, DOI 10.1109/LGRS.2020.2968550
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2020, IEEE T IMAGE PROCESS, V29, P5794, DOI 10.1109/TIP.2020.2987161
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Choe J, 2019, PROC CVPR IEEE, V0, PP2214, DOI 10.1109/CVPR.2019.00232
   Chollet F, 2015, KERAS, V0, P0
   Christlein Vincent, 2019, 2019 INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR). PROCEEDINGS, V0, PP1090, DOI 10.1109/ICDAR.2019.00177
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   de Lima RP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010086
   Feng XX, 2020, IEEE T GEOSCI REMOTE, V58, P8002, DOI 10.1109/TGRS.2020.2985989
   Ge WF, 2018, PROC CVPR IEEE, V0, PP1277, DOI 10.1109/CVPR.2018.00139
   Grauman K, 2005, IEEE I CONF COMP VIS, V0, P1458
   Han XB, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9080848
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He NJ, 2018, IEEE T GEOSCI REMOTE, V56, P6899, DOI 10.1109/TGRS.2018.2845668
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Jose A, 2018, IEEE IMAGE PROC, V0, PP480, DOI 10.1109/ICIP.2018.8451361
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Laptev D, 2016, PROC CVPR IEEE, V0, PP289, DOI 10.1109/CVPR.2016.38
   Lazebnik S., 2006, PROC IEEE C COMPUT V, V2, P2169, DOI 10.1109/CVPR.2006.68
   Li J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091366
   Li YS, 2020, REMOTE SENS ENVIRON, V250, P0, DOI 10.1016/j.rse.2020.112045
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI 10.1017/S1368980013002176
   Lu XQ, 2019, NEUROCOMPUTING, V328, P135, DOI 10.1016/j.neucom.2018.03.076
   Mahendran A, 2015, PROC CVPR IEEE, V0, PP5188, DOI 10.1109/CVPR.2015.7299155
   Murray N, 2014, PROC CVPR IEEE, V0, PP2473, DOI 10.1109/CVPR.2014.317
   Oquab M, 2015, PROC CVPR IEEE, V0, PP685, DOI 10.1109/CVPR.2015.7298668
   Qi K., 2021, REMOTE SENS-BASEL, V13, P1
   Qi KL, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060934
   Ranzato M., 2007, PROC IEEE C COMPUT V, V0, PP1, DOI 10.1109/CVPR.2007.383157
   Raza A, 2020, IEEE J-STARS, V13, P5297, DOI 10.1109/JSTARS.2020.3021045
   Russakovsky O, 2012, LECT NOTES COMPUT SC, V7573, P1, DOI 10.1007/978-3-642-33709-3_1
   Simonyan K, 2015, ARXIV, V0, P0
   Song M., 2018, REMOTE SENS-BASEL, V10, P1
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Tang P., 2018, ECCV, V0, P352
   Wan YT, 2020, IEEE T GEOSCI REMOTE, V58, P3601, DOI 10.1109/TGRS.2019.2958812
   Wang SD, 2020, IEEE T IMAGE PROCESS, V29, P5396, DOI 10.1109/TIP.2020.2983560
   Wang YH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010020
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xu C., 1900, DOI 10.1109/TGRS.2020.3048024, V0, P0
   Xu KJ, 2020, INFORM SCIENCES, V539, P250, DOI 10.1016/j.ins.2020.06.011
   Yang K, 2019, IEEE I CONF COMP VIS, V0, PP8371, DOI 10.1109/ICCV.2019.00846
   Yao XW, 2021, IEEE T GEOSCI REMOTE, V59, P675, DOI 10.1109/TGRS.2020.2991407
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang BX, 2018, NEUROCOMPUTING, V321, P36, DOI 10.1016/j.neucom.2018.07.079
   Zhang LF, 2019, INFORM SCIENCES, V485, P154, DOI 10.1016/j.ins.2019.02.008
   Zhang W., 2019, REMOTE SENS-BASEL, V11, P1
   Zhao J, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111605
   Zheng XT, 2019, IEEE T GEOSCI REMOTE, V57, P4799, DOI 10.1109/TGRS.2019.2893115
   Zhou B., 2015, ICRL, V0, P0
   Zhou B., 2014, P ADV NEUR INF PROC, V0, PP487, DOI 10.1162/153244303322533223
   Zhou B, 2016, PROC CVPR IEEE, V0, PP2921, DOI 10.1109/CVPR.2016.319
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 63
TC 1
Z9 1
U1 4
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7857
EP 7868
DI 10.1109/JSTARS.2021.3100330
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UC8FJ
UT WOS:000686757500006
DA 2023-04-26
ER

PT J
AU Rubanenko, L
   Perez-Lopez, S
   Schull, J
   Lapotre, MGA
AF Rubanenko, Lior
   Perez-Lopez, Sebastian
   Schull, Joseph
   Lapotre, Mathieu G. A.
TI Automatic Detection and Segmentation of Barchan Dunes on Mars and Earth Using a Convolutional Neural Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Earth; Mars; Training; Object detection; Image segmentation; Image edge detection; Machine learning; neural networks; planets; Mars; geology
ID sand dunes; wind; crater
AB The morphology of isolated barchan dunes on Mars and Earth may shed light on the dynamic conditions that form them, their migration direction and the physical properties of the sediments composing them. Prior to this study, dune fields have been largely analyzed manually from aerial and satellite imagery, as automatic detection techniques are often not sufficiently accurate in outlining dunes. Here, we employ an instance segmentation neural network to detect and outline isolated barchan dunes on Mars and Earth. We train and test the model on martian targets using Mars reconnaissance orbiter (MRO) context camera (CTX) images, and find it sufficiently accurate (mAP=77% on the test dataset) to characterize dune field dynamics. Using our trained model, we detect and map the global distribution of barchan dunes relative to previously mapped dune fields, and find that barchan dunes are more abundant in the northern hemisphere than in the southern hemisphere. These contrasting abundances of barchans may reflect latitudinally dependent wind regimes, sediment supply, or sediment availability.
C1 [Rubanenko, Lior; Perez-Lopez, Sebastian; Schull, Joseph; Lapotre, Mathieu G. A.] Stanford Univ, Dept Geol Sci, Stanford, CA 94305 USA.
C3 Stanford University
RP Rubanenko, L (corresponding author), Stanford Univ, Dept Geol Sci, Stanford, CA 94305 USA.
EM liorr@stanford.edu; sebp101@stanford.edu; jschull@berkeley.edu; mlapotre@stanford.edu
CR Abdulla W., 2017, GITHUB REPOSITORY, V0, P0
   Ali-Dib M, 2020, ICARUS, V345, P0, DOI 10.1016/j.icarus.2020.113749
   Azzaoui M., 2016, REMOTE SENS SPATIAL, V41, P0
   Baird T, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202423
   Bandeira L, 2013, EARTH SURF PROC LAND, V38, P275, DOI 10.1002/esp.3323
   BREED CS, 1979, J GEOPHYS RES, V84, P8183, DOI 10.1029/JB084iB14p08183
   Bridges NT, 2012, NATURE, V485, P339, DOI 10.1038/nature11022
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carrera D, 2019, KNOWL-BASED SYST, V163, P858, DOI 10.1016/j.knosys.2018.10.011
   Dickson J.L., 2018, LUNAR PLANETARY SCI, V49, P0
   Ehlmann BL, 2017, J GEOPHYS RES-PLANET, V122, P2510, DOI 10.1002/2017JE005267
   Fenton LK, 2020, ICARUS, V352, P0, DOI 10.1016/j.icarus.2020.114018
   Forsyth D. A., 2012, COMPUTERVISION MODER, V0, P0
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Greeley R, 2004, SCIENCE, V305, P810, DOI 10.1126/science.1100108
   Hayward RK, 2014, ICARUS, V230, P38, DOI 10.1016/j.icarus.2013.04.011
   Hayward R. K., 2012, US GEOLOGICAL SURVEY, V1259, P0
   Hayward RK, 2007, J GEOPHYS RES-PLANET, V112, P0, DOI 10.1029/2007JE002943
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   King DB, 2015, ACS SYM SER, V1214, P1
   Lapotre MGA, 2018, GEOPHYS RES LETT, V45, P10200, DOI 10.1029/2018GL079032
   Lapotre MGA, 2017, J GEOPHYS RES-PLANET, V122, P2489, DOI 10.1002/2016JE005133
   LEE P, 1995, J GEOPHYS RES-PLANET, V100, P5381, DOI 10.1029/95JE00225
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Malin MC, 2007, J GEOPHYS RES-PLANET, V112, P0, DOI 10.1029/2006JE002808
   Neubeck A, 2006, INT C PATT RECOG, V0, PP850, DOI 10.1109/icpr.2006.479
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Parteli EJR, 2014, AEOLIAN RES, V12, P121, DOI 10.1016/j.aeolia.2013.12.002
   Piqueux S, 2019, GEOPHYS RES LETT, V46, P14290, DOI 10.1029/2019GL083947
   Rasley J, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP3505, DOI 10.1145/3394486.3406703
   Rehman ZU, 2021, IET IMAGE PROCESS, V15, P2157, DOI 10.1049/ipr2.12183
   Robbins SJ, 2012, J GEOPHYS RES-PLANET, V117, P0, DOI 10.1029/2011JE003967
   Rubanenko L, 2021, TRAINED WEIGHTS MASK, V0, P0, DOI DOI 10.21227/mbrx-hp61
   Ruder S., 2016, OVERVIEW GRADIENT DE, V2016, P0
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Silvestro S, 2011, GEOPHYS RES LETT, V38, P0, DOI 10.1029/2011GL048955
   Sullivan R, 2008, J GEOPHYS RES-PLANET, V113, P0, DOI 10.1029/2008JE003101
   Tirsch D, 2011, J GEOPHYS RES-PLANET, V116, P0, DOI 10.1029/2009JE003562
   TSOAR H, 1979, J GEOPHYS RES, V84, P8167, DOI 10.1029/JB084iB14p08167
   Tsoar H, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-6040-4
   Ullo SL, 2021, IEEE J-STARS, V14, P3799, DOI 10.1109/JSTARS.2021.3064981
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/7068349
   WASSON RJ, 1983, NATURE, V304, P337, DOI 10.1038/304337a0
   Zhang ZC, 2018, GEOSCIENCES, V8, P0, DOI 10.3390/geosciences8060204
NR 48
TC 5
Z9 5
U1 5
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9364
EP 9371
DI 10.1109/JSTARS.2021.3109900
PG 8
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UY0RM
UT WOS:000701240700003
DA 2023-04-26
ER

PT J
AU Dusek, B
   Gede, M
AF Dusek, Bence
   Gede, Matyas
TI Automatic mapping of traffic signs
SO 30TH INTERNATIONAL CARTOGRAPHIC CONFERENCE (ICC 2021), VOL 4
LA English
DT Proceedings Paper
DE deep learning; traffic sign detection and recognition; mobile mapping system; computer vision
AB Nowadays, people easily can get into their cars and drive hundreds of kilometers in a few hours, but for that to work efficiently a system of rules must be applied and those rules have to be communicated transparently. This is why traffic signs are an influential part of our lives and every kind of information about each is helping the government, the community, and the drivers. This paper presents a novel and cost-efficient method for acquiring information on traffic signs, such like the category and the 3D position. The former can be gained using camera images and a Convolutional Neural Network model. The latter can be obtained using positioning devices. With the help of a GNSS device the absolute position of the vehicle can be learned and based on that a local coordinate system can be established. From the vehicle's point of view the coordinates and the orientation of the traffic sign can be acquired by applying a stereo camera and an IMU (Inertial Measurement Unit) sensor. Then, with the help of these attributes a large database can be built, maintained, and updated. This project displays that adequately precise data can easily be accessible using a few cheap devices and sensors.
C1 [Dusek, Bence; Gede, Matyas] Eotvos Lorcind Univ, Fac Informat, Inst Cartog & Geoinformat, Budapest, Hungary.
RP Gede, M (corresponding author), Eotvos Lorcind Univ, Fac Informat, Inst Cartog & Geoinformat, Budapest, Hungary.
EM dusekbence@gmail.com; saman@map.elte.hu
FU Hungarian Government [EFOP-3.6.3-VEKOP-16-2017-00001]; European Social Fund
CR Balado J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030442
   Barnes N, 2008, IEEE T INTELL TRANSP, V9, P322, DOI 10.1109/TITS.2008.922935
   Gonzalez A, 2011, IEEE T INTELL TRANSP, V12, P485, DOI 10.1109/TITS.2010.2098029
   Hassan M., 2020, OPENCV PROJECTS TRAF, V0, P0
   Liu LR, 2020, IEEE J-STARS, V13, P2096, DOI 10.1109/JSTARS.2020.2966543
   Madeira S. R., 2005, GIS PLANET 2005 INT, V0, P0
   Ritter W., 1992, PROC INTELL VEHICLES, V0, P12
   Rosebrock A., 2017, DEEP LEARNING COMPUT, V0, P0
   Soilan M, 2016, INT ARCH PHOTOGRAMM, V41, P717, DOI 10.5194/isprsarchives-XLI-B3-717-2016
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
NR 10
TC 0
Z9 0
U1 0
U2 0
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.5194/ica-proc-4-29-2021
PG 6
WC Geography; Geography, Physical
SC Geography; Physical Geography
GA BT8VN
UT WOS:000855572500029
DA 2023-04-26
ER

PT J
AU Thomas, AV
   Saha, S
   Danumah, JH
   Raveendran, S
   Prasad, MK
   Ajin, RS
   Kuriakose, SL
AF Thomas, Anjana V.
   Saha, Sunil
   Danumah, Jean Homian
   Raveendran, S.
   Prasad, Megha K.
   Ajin, R. S.
   Kuriakose, Sekhar L.
TI Landslide Susceptibility Zonation of Idukki District Using GIS in the Aftermath of 2018 Kerala Floods and Landslides: a Comparison of AHP and Frequency Ratio Methods
SO JOURNAL OF GEOVISUALIZATION AND SPATIAL ANALYSIS
LA English
DT Article
DE Analytical hierarchy process; Frequency ratio; GIS; Landslides; Western Ghats
ID analytical hierarchy process; support vector machine; rainfall-induced landslides; evidential belief function; logistic-regression model; gorges reservoir area; land-use changes; hazard evaluation; garhwal-himalaya; neural-network
AB This study aims to demarcate landslide susceptible zones using methods of analytical hierarchy process (AHP) and frequency ratio (FR) to find the most influencing factors and to compare their prediction capability. Ten causative factors (slope angle, elevation, lithology, land use/land cover types, normalized difference moisture index, road buffer, normalized difference built-up index, water ratio index, stream power index, and soil) are used in the study. The area of the landslide susceptibility was grouped into five classes. According to the landslide susceptibility maps prepared using the AHP and FR methods, 11.14% and 6.57% of the area are very highly susceptible to landslides. Finally, the receiver operating characteristic (ROC) curves for the landslide susceptibility maps prepared using both AHP and FR methods were plotted, and the area under the ROC curve (AUC) values were estimated to validate the results. AUC values of 0.69 and 0.81 were estimated for the landslide susceptible zone maps prepared using AHP and FR, respectively. From the AUC values, it is confirmed that the FR method is more effective in predicting the landslide susceptible zones in Idukki district. The landslide susceptibility maps are helpful for land use planners and policy makers in adopting suitable mitigation measures to minimize the impacts of landslides and thereby reduce loss of life and property.
C1 [Thomas, Anjana V.] Univ Coll, Dept Geol, Thiruvananthapuram, Kerala, India.
   [Saha, Sunil] Univ Gour Banga, Dept Geog, Malda, W Bengal, India.
   [Danumah, Jean Homian] Univ Felix Houphouet Boigny, Ctr Univ Rech & Applicat Teledetect CURAT, Abidjan, Cote Ivoire.
   [Raveendran, S.; Ajin, R. S.; Kuriakose, Sekhar L.] Kerala State Disaster Management Author KSDMA, Kerala State Emergency Operat Ctr KSEOC, Thiruvananthapuram, Kerala, India.
   [Prasad, Megha K.] Bharathidasan Univ, Dept Remote Sensing, Tiruchirappalli, Tamil Nadu, India.
C3 University of Gour Banga; Bharathidasan University
RP Ajin, RS (corresponding author), Kerala State Disaster Management Author KSDMA, Kerala State Emergency Operat Ctr KSEOC, Thiruvananthapuram, Kerala, India.
EM ajinares@ieee.org
CR Abraham MT, 2021, GEOMAT NAT HAZ RISK, V12, P540, DOI 10.1080/19475705.2021.1884610
   Abraham MT, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11102113
   Achour Y, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2980-6
   Achu AL, 2021, LANDSLIDES, V18, P1459, DOI 10.1007/s10346-020-01598-x
   Aghda SMF, 2018, GEOTECH GEOL ENG, V36, P915, DOI 10.1007/s10706-017-0365-y
   Aimaiti Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202351
   Ajin R.S., 2016, INT J APPL REMOTE SE, V3, P16
   Althuwaynee OF, 2014, CATENA, V114, P21, DOI 10.1016/j.catena.2013.10.011
   ANBALAGAN R, 1992, ENG GEOL, V32, P269, DOI 10.1016/0013-7952(92)90053-2
   [Anonymous], 2016, GEOENVIRONMENTAL DIS, V0, P0, DOI DOI 10.1186/S40677-016-0044-Y
   [Anonymous], 1996, SOILS FOUND, V0, P0
   Cancela J, 2015, BMC MED INFORM DECIS, V15, P0, DOI 10.1186/1472-6947-15-S3-S7
   Cardinali M, 2006, NAT HAZARD EARTH SYS, V6, P237, DOI 10.5194/nhess-6-237-2006
   Chawla A, 2018, ADV CIV ENG, V2018, P0, DOI 10.1155/2018/6416492
   Chen W, 2018, GEOMAT NAT HAZ RISK, V9, P735, DOI 10.1080/19475705.2018.1472144
   Chen W, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4795-7
   Cruden D., 1991, B INT ASS ENG GEOL, V43, P27, DOI 10.1007/BF02590167
   Dahoua L, 2018, ADV SCI TECHNOL INN, V0, PP1837, DOI 10.1007/978-3-319-70548-4_532
   Dai FC, 2002, GEOMORPHOLOGY, V42, P213, DOI 10.1016/S0169-555X(01)00087-3
   Demir G, 2013, NAT HAZARDS, V65, P1481, DOI 10.1007/s11069-012-0418-8
   Devara M, 2021, GEOMAT NAT HAZ RISK, V12, P675, DOI 10.1080/19475705.2021.1887939
   Ehret D, 2010, J EARTH SCI-CHINA, V21, P824, DOI 10.1007/s12583-010-0134-9
   El Jazouli A, 2019, GEOENVIRONMENTAL DIS, V6, P0, DOI 10.1186/s40677-019-0119-7
   Elmoulat M, 2018, GEOMAT NAT HAZ RISK, V9, P1306, DOI 10.1080/19475705.2018.1505666
   Emrouznejad A, 2017, INT J PROD RES, V55, P6653, DOI 10.1080/00207543.2017.1334976
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Garcia-Rodriguez MJ, 2008, GEOMORPHOLOGY, V95, P172, DOI 10.1016/j.geomorph.2007.06.001
   Geertsema M, 2009, LANDSLIDES - DISASTER RISK REDUCTION, V0, PP589, DOI 10.1007/978-3-540-69970-5_31
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Hamza T, 2017, J KING SAUD UNIV SCI, V29, P151, DOI 10.1016/j.jksus.2016.05.002
   Hemasinghe H, 2018, PROCEDIA ENGINEER, V212, P1046, DOI 10.1016/j.proeng.2018.01.135
   Hong Y., 2007, EOS T AM GEOPHYS UN, V88, P357, DOI 10.1029/2007EO370001
   Huang FM, 2018, GEOMAT NAT HAZ RISK, V9, P919, DOI 10.1080/19475705.2018.1482963
   Ibrahim GRF, 2017, CLIMATE, V5, P0, DOI 10.3390/cli5010013
   Jaafari A, 2014, INT J ENVIRON SCI TE, V11, P909, DOI 10.1007/s13762-013-0464-0
   Kanungo D., 2009, J S ASIA DISASTER ST, V2, P81
   Kanungo DP, 2006, ENG GEOL, V85, P347, DOI 10.1016/j.enggeo.2006.03.004
   Kanungo DP, 2020, CURR SCI INDIA, V119, P1797, DOI 10.18520/cs/v119/i11/1797-1806
   Karsli F, 2009, ENVIRON MONIT ASSESS, V156, P241, DOI 10.1007/s10661-008-0481-5
   Kaur H, 2017, SPAT INF RES, V25, P389, DOI 10.1007/s41324-017-0105-7
   Kayastha P, 2012, NAT HAZARDS, V63, P479, DOI 10.1007/s11069-012-0163-z
   Khan H, 2019, EGYPT J REMOTE SENS, V22, P11, DOI 10.1016/j.ejrs.2018.03.004
   Kouhpeimaa A., 2017, DESERT, V22, P85
   Kumar D, 2017, GEOMORPHOLOGY, V295, P115, DOI 10.1016/j.geomorph.2017.06.013
   Kumar MK., 2015, DISASTER ADV, V8, P46
   Kumar R, 2016, J GEOL SOC INDIA, V87, P271, DOI 10.1007/s12594-016-0395-8
   Lee ML, 2014, NAT HAZARDS, V70, P353, DOI 10.1007/s11069-013-0814-8
   Lee S, 2007, INT J REMOTE SENS, V28, P4763, DOI 10.1080/01431160701264227
   Lee S, 2005, ENVIRON GEOL, V47, P982, DOI 10.1007/s00254-005-1228-z
   Lee S, 2004, INT J REMOTE SENS, V25, P2037, DOI 10.1080/01431160310001618734
   Lee S, 2006, J EARTH SYST SCI, V115, P661, DOI 10.1007/s12040-006-0004-0
   Li Fangyu, 2018, SHANGHAI ARCH PSYCHIATRY, V30, P207, DOI 10.11919/j.issn.1002-0829.218052
   Melo F., 2013, AREA ROC CURVE, V0, P38
   MOORE ID, 1991, HYDROL PROCESS, V5, P3, DOI 10.1002/hyp.3360050103
   Myronidis D, 2016, NAT HAZARDS, V81, P245, DOI 10.1007/s11069-015-2075-1
   Nakamura S, 2014, SOILS FOUND, V54, P544, DOI 10.1016/j.sandf.2014.06.001
   Nakileza BR, 2020, GEOENVIRONMENTAL DIS, V7, P0, DOI 10.1186/s40677-020-00160-0
   Oh HJ, 2018, GEOMAT NAT HAZ RISK, V9, P1053, DOI 10.1080/19475705.2018.1481147
   Oh HJ, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/3730913
   Oh HJ, 2011, COMPUT GEOSCI-UK, V37, P1264, DOI 10.1016/j.cageo.2010.10.012
   Park SJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101545
   Pourghasemi HR, 2013, J EARTH SYST SCI, V122, P349, DOI 10.1007/s12040-013-0282-2
   Pourghasemi HR, 2012, NAT HAZARDS, V63, P965, DOI 10.1007/s11069-012-0217-2
   Pourghasemi HR, 2012, CATENA, V97, P71, DOI 10.1016/j.catena.2012.05.005
   Pradhan B, 2010, IEEE T GEOSCI REMOTE, V48, P4164, DOI 10.1109/TGRS.2010.2050328
   Pradhan B, 2010, ENVIRON MODELL SOFTW, V25, P747, DOI 10.1016/j.envsoft.2009.10.016
   Raghuvanshi TK, 2015, EGYPT J REMOTE SENS, V18, P235, DOI 10.1016/j.ejrs.2015.08.001
   Raghuvanshi TK, 2014, J AFR EARTH SCI, V99, P595, DOI 10.1016/j.jafrearsci.2014.05.004
   Ramachandran RM, 2017, J INDIAN SOC REMOTE, V45, P163, DOI 10.1007/s12524-015-0521-x
   Rasyid A.R., 2016, GEOENVIRONMENTAL DIS, V3, P19, DOI 10.1186/s40677-016-0053-x
   Ray RL, 2007, NAT HAZARDS, V43, P211, DOI 10.1007/s11069-006-9095-9
   Resmi TR, 2016, J EARTH SYST SCI, V125, P1481, DOI 10.1007/s12040-016-0747-1
   Rostami ZA, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-016-2720-3
   Roy J, 2019, GEOENVIRONMENTAL DIS, V6, P0, DOI 10.1186/s40677-019-0126-8
   Russo RDSM, 2015, PROCEDIA COMPUT SCI, V55, P1123, DOI 10.1016/j.procs.2015.07.081
   Saaty T.L., 1980, ANAL HIERARCHY PROCE, V0, P0
   Sar N, 2015, MODEL EARTH SYST ENV, V1, P0, DOI 10.1007/s40808-015-0039-9
   SARKAR S, 1995, MT RES DEV, V15, P301, DOI 10.2307/3673806
   Sartohadi J., 2018, APPLIED AND ENVIRONMENTAL SOIL SCIENCE, V2018, P2648185, DOI 10.1155/2018/2648185
   Semlali I, 2019, CURR SCI INDIA, V116, P773, DOI 10.18520/cs/v116/i5/773-779
   Senthilkumar V, 2018, INT J GEOMECH, V18, P0, DOI 10.1061/(ASCE)GM.1943-5622.0001218
   Shahfahad, 2020, ARAB J GEOSCI, V13, P0, DOI 10.1007/s12517-020-06068-1
   Shahri AA, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104225
   Shano Leulalem, 2021, ARABIAN JOURNAL OF GEOSCIENCES, V14, P0, DOI 10.1007/s12517-021-06995-7
   Sharma S., 2018, GEOENVIRONMENTAL DIS, V5, P1, DOI 10.1186/S40677-018-0097-1
   Shen L, 2010, P 18 INT C GEOINF BE, V0, PP1, DOI 10.1109/GEOINFORMATICS.2010.5567762
   Sifa S.F., 2019, GEOL ECOL LANDSC, V4, P222, DOI 10.1080/24749508.2019.1619222
   Silalahi FES, 2019, GEOSCI LETT, V6, P0, DOI 10.1186/s40562-019-0140-4
   Sujatha ER, 2021, HYDROLOGY-BASEL, V8, P0, DOI 10.3390/hydrology8010041
   Turrini MC, 1998, ENG GEOL, V50, P255, DOI 10.1016/S0013-7952(98)00022-2
   United States Geological Survey, 2004, LANDSL TYP PROC FACT, V0, P0
   Ortiz JAV, 2018, GEOMAT NAT HAZ RISK, V9, P1106, DOI 10.1080/19475705.2018.1513083
   Pham VD, 2020, IEEE ACCESS, V8, P32727, DOI 10.1109/ACCESS.2020.2973415
   Wu YL, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-5194-9
   Xie P, 2018, GEOMAT NAT HAZ RISK, V9, P501, DOI 10.1080/19475705.2018.1451399
   Zha Y, 2003, INT J REMOTE SENS, V24, P583, DOI 10.1080/01431160304987
   Zhang KX, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-017-6731-5
   Zhang KQ, 2016, ECOSPHERE, V7, P0, DOI 10.1002/ecs2.1366
NR 98
TC 17
Z9 17
U1 3
U2 10
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2509-8810
EI 2509-8829
J9 J GEOVIS SPAT ANAL
JI J. Geovis. Spat. Anal.
PD DEC 15
PY 2021
VL 5
IS 2
BP 
EP 
DI 10.1007/s41651-021-00090-x
PG 27
WC Environmental Sciences; Geography; Geography, Physical; Remote Sensing
SC Environmental Sciences & Ecology; Geography; Physical Geography; Remote Sensing
GA WF2ML
UT WOS:000706144900001
DA 2023-04-26
ER

PT J
AU Can, YS
   Gerrits, PJ
   Kabadayi, ME
AF Can, Yekta Said
   Gerrits, Petrus Johannes
   Kabadayi, M. Erdem
TI Automatic Detection of Road Types From the Third Military Mapping Survey of Austria-Hungary Historical Map Series With Deep Convolutional Neural Networks
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Roads; Training; Data mining; Forestry; Europe; Annotations; Convolutional neural networks; digital humanities; digital preservation; document analysis; geospatial analysis; geospatial artificial intelligence; road type detection; image processing
ID classification; population
AB With the increased amount of digitized historical documents, information extraction from them gains pace. Historical maps contain valuable information about historical, geographical and economic aspects of an era. Retrieving information from historical maps is more challenging than processing modern maps due to lower image quality, degradation of documents and the massive amount of non-annotated digital map archives. Convolutional Neural Networks (CNN) solved many image processing challenges with great success, but they require a vast amount of annotated data. For historical maps, this means an unprecedented scale of manual data entry and annotation. In this study, we first manually annotated the Third Military Mapping Survey of Austria-Hungary historical map series conducted between 1884 and 1918 and made them publicly accessible. We recognized different road types and their pixel-wise positions automatically by using a CNN architecture and achieved promising results.
C1 [Can, Yekta Said; Gerrits, Petrus Johannes; Kabadayi, M. Erdem] Koc Univ, Coll Social Sci & Humanities, TR-34450 Istanbul, Turkey.
C3 Koc University
RP Can, YS (corresponding author), Koc Univ, Coll Social Sci & Humanities, TR-34450 Istanbul, Turkey.
EM ycan@ku.edu.tr
FU European Research Council (ERC) Project: Industrialisation and Urban Growth from the mid-nineteenth century Ottoman Empire to Contemporary Turkey in a Comparative Perspective, 1850-2000 under the European Union's Horizon 2020 Research and Innovation Progra [679097]
CR [Anonymous], 2020, DISCOVERY TOOL GEOSP, V0, P0
   [Anonymous], 2021, 3 MILITARY MAPPING S, V0, P0
   Arnaud J.-L., 2014, HIST CARTOGRAPHY, V0, P111
   Budig B., 2016, P 24 ACM SIGSPATIAL, V0, P1
   Budig B, 2015, LECT NOTES ARTIF INT, V9356, P33, DOI 10.1007/978-3-319-24282-8_5
   Can YS, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10165430
   Can YS, 2020, J IMAGING, V6, P0, DOI 10.3390/jimaging6050032
   Chiang Y.-Y., 2020, USING HIST MAPS SCI, V0, PP65, DOI 10.1007/978-3-319-66908-3_4
   Duan W., 2017, P 1 WORKSHOP ARTIFIC, V0, PP45, DOI 10.1145/3149808.3149816
   Duan WW, 2020, INT J GEOGR INF SCI, V34, P824, DOI 10.1080/13658816.2019.1698742
   Esri, 2020, ARCGIS PRO VERSION 2, V0, P0
   Gimmi U., 2016, PRACE GEOGRAFICZNE, V146, P7
   Glorot X., 2010, P 13 INT C ART INT S, V0, P249
   Goderle W., 2018, DYNAMIKEN WISSENSPRO, V0, P9
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Herrault PA, 2013, LECT NOTES GEOINF CA, V0, PP95, DOI 10.1007/978-3-319-00615-4_6
   Jobin K. V., 2018, COMPUTER VISION PATT, V0, P372
   King DB, 2015, ACS SYM SER, V1214, P1
   Koak T., 2021, SPATIAL WEBS MAPPING, V0, P115
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Macias J. Ugarte, 2019, THESIS U SEVILLA SEV, V0, P0
   Najafabadi M.M., 2015, J BIG DATA-GER, V2, P21, DOI 10.1186/S40537-014-0007-7
   Oliveira SA, 2018, INT CONF FRONT HAND, V0, PP7, DOI 10.1109/ICFHR-2018.2018.00011
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saeedimoghaddam M, 2020, INT J GEOGR INF SCI, V34, P947, DOI 10.1080/13658816.2019.1696968
   Timar G., 2010, PRESERVATION DIGITAL, V0, PP273, DOI 10.1007/978-3-642-12733-5_14
   Uhl J., 2017, P 8 INT C PATTERN RE, V0, P0, DOI DOI 10.1049/CP.2017.0144
   Uhl JH, 2020, IEEE ACCESS, V8, P6978, DOI 10.1109/ACCESS.2019.2963213
NR 28
TC 9
Z9 9
U1 2
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2021
VL 9
IS 
BP 62847
EP 62856
DI 10.1109/ACCESS.2021.3074897
PG 10
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA RV5DU
UT WOS:000645853900001
DA 2023-04-26
ER

PT J
AU Sucar, E
   Liu, SK
   Ortiz, J
   Davison, AJ
AF Sucar, Edgar
   Liu, Shikun
   Ortiz, Joseph
   Davison, Andrew J.
TI iMAP: Implicit Mapping and Positioning in Real-Time
SO 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021)
LA English
DT Proceedings Paper
AB We show for the first time that a multilayer perceptron (MLP) can serve as the only scene representation in a real-time SLAM system for a handheld RGB-D camera. Our network is trained in live operation without prior data, building a dense, scene-specific implicit 3D model of occupancy and colour which is also immediately used for tracking. Achieving real-time SLAM via continual training of a neural network against a live image stream requires significant innovation. Our iMAP algorithm uses a keyframe structure and multi-processing computation flow, with dynamic information-guided pixel sampling for speed, with tracking at 10 Hz and global map updating at 2 Hz. The advantages of an implicit MLP over standard dense SLAM techniques include efficient geometry representation with automatic detail control and smooth, plausible filling-in of unobserved regions such as the back surfaces of objects.
C1 [Sucar, Edgar; Liu, Shikun; Davison, Andrew J.] Imperial Coll London, Dyson Robot Lab, London, England.
   [Ortiz, Joseph] Imperial Coll London, Robot Vis Lab, London, England.
C3 Imperial College London; Imperial College London
RP Sucar, E (corresponding author), Imperial Coll London, Dyson Robot Lab, London, England.
EM e.sucar18@imperial.ac.uk; shikun.liu17@imperial.ac.uk; j.ortiz@imperial.ac.uk; a.davison@imperial.ac.uk
FU Dyson Technology Ltd.
CR Bloesch M, 2018, PROC CVPR IEEE, V0, PP2560, DOI 10.1109/CVPR.2018.00271
   Chabra Rohan, 2020, ECCV, V0, P0
   Chibane J., 2020, NEURAL INFORM PROCES, V0, P0
   Curless B., 1996, COMPUTER GRAPHICS PROCEEDINGS. SIGGRAPH 96, V0, PP303, DOI 10.1145/237170.237269
   Dai A, 2020, PROC CVPR IEEE, V0, PP846, DOI 10.1109/CVPR42600.2020.00093
   Dai M, 2020, METHOD PHARMACOL TOX, V0, PP1, DOI 10.1007/978-1-0716-0171-6_1
   GROSSBERG S, 1980, STUDIES MIND BRAIN, V87, P1
   Keller M., 2013, P JOINT 3DIM 3DPVT C, V0, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Klein G., 2007, P INT S MEX AUGM REA, V0, P0
   Kohavi R, 2020, TRUSTWORTHY ONLINE CONTROLLED EXPERIMENTS: A PRACTICAL GUIDE TO A/B TESTING, V0, PP1, DOI 10.1017/9781108653985
   LESORT T, 2019, 2019 INT JOINT C NEU, V0, P0
   Maltoni D, 2019, NEURAL NETWORKS, V116, P56, DOI 10.1016/j.neunet.2019.03.010
   Mescheder L, 2019, PROC CVPR IEEE, V0, PP4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B., 2020, ECCV, V0, PP405, DOI 10.1007/978-3-030-58452-8_24
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Newcombe RA, 2011, IEEE I CONF COMP VIS, V0, PP2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2011, INT SYM MIX AUGMENT, V0, PP127, DOI 10.1109/ISMAR.2011.6092378
   Park JJ, 2019, PROC CVPR IEEE, V0, PP165, DOI 10.1109/CVPR.2019.00025
   Paszke A., 2019, ADV NEURAL INFORM PR, V0, P0, DOI DOI 10.48550/ARXIV.1912.01703
   Peng Songyou, 2020, ECCV, V0, P0, DOI DOI 10.1007/978-3-030-58580-8_31
   Rolnick David, 2019, P ADV NEUR INF PROC, V0, P350
   Rusu Andrei A., 2016, PROGRESSIVE, V0, P0
   Schops Thomas, 2019, P IEEE C COMP VIS PA, V0, P0
   Schwarz J, 2018, PR MACH LEARN RES, V80, P0
   Shin H, 2017, ADV NEUR IN, V30, P0
   Sitzmann Vincent, 2020, NEURAL INFORM PROCES, V0, P0
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404
   Straub Julian, 2019, ARXIV190605797, V0, P0
   Sturm J, 2012, IEEE INT C INT ROBOT, V0, PP573, DOI 10.1109/IROS.2012.6385773
   Sucar E., 2020, P INT C 3D VIS 3DV, V0, P0
   Tancik M., 2020, NEURAL INFORM PROCES, V0, P0
   Vespa E., 2018, IEEE ROBOTICS AUTOMA, V0, P0
   Wang Z., 2021, ARXIV210207064, V0, P0
   Weder Silvan, 2020, P IEEE C COMP VIS PA, V0, P0
   Whelan T., 2012, RSS WORKSH RGB D ADV, V0, P0
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI, V0, P0
   Yen-Chen Lin, 2020, ARXIV201205877, V0, P0
NR 39
TC 1
Z9 1
U1 12
U2 13
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 6209
EP 6218
DI 10.1109/ICCV48922.2021.00617
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA BT1IF
UT WOS:000797698906044
DA 2023-04-26
ER

PT J
AU Lang, N
   Irniger, A
   Rozniak, A
   Hunziker, R
   Wegner, JD
   Schindler, K
AF Lang, Nico
   Irniger, Andrea
   Rozniak, Agnieszka
   Hunziker, Roni
   Wegner, Jan Dirk
   Schindler, Konrad
TI GRAINet: mapping grain size distributions in river beds from UAV images with convolutional neural networks
SO HYDROLOGY AND EARTH SYSTEM SCIENCES
LA English
DT Article
ID digital images; information
AB Grain size analysis is the key to understand the sediment dynamics of river systems. We propose GRAINet, a data-driven approach to analyze grain size distributions of entire gravel bars based on georeferenced UAV images. A convolutional neural network is trained to regress grain size distributions as well as the characteristic mean diameter from raw images. GRAINet allows for the holistic analysis of entire gravel bars, resulting in (i) high-resolution estimates and maps of the spatial grain size distribution at large scale and (ii) robust grading curves for entire gravel bars. To collect an extensive training dataset of 1491 samples, we introduce digital line sampling as a new annotation strategy. Our evaluation on 25 gravel bars along six different rivers in Switzerland yields high accuracy: the resulting maps of mean diameters have a mean absolute error (MAE) of 1.1 cm, with no bias. Robust grading curves for entire gravel bars can be extracted if representative training data are available. At the gravel bar level the MAE of the predicted mean diameter is even reduced to 0.3 cm, for bars with mean diameters ranging from 1.3 to 29.3 cm. Extensive experiments were carried out to study the quality of the digital line samples, the generalization capability of GRAINet to new locations, the model performance with respect to human labeling noise, the limitations of the current model, and the potential of GRAINet to analyze images with low resolutions.
C1 [Lang, Nico; Rozniak, Agnieszka; Wegner, Jan Dirk; Schindler, Konrad] Swiss Fed Inst Technol, EcoVis Lab, Photogrammetry & Remote Sensing, Zurich, Switzerland.
   [Irniger, Andrea; Hunziker, Roni] Hunziker Zarn & Partner, Aarau, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Lang, N (corresponding author), Swiss Fed Inst Technol, EcoVis Lab, Photogrammetry & Remote Sensing, Zurich, Switzerland.; Irniger, A (corresponding author), Hunziker Zarn & Partner, Aarau, Switzerland.
EM nico.lang@geod.baug.ethz.ch; andrea.irniger@hzp.ch
CR ADAMS J, 1979, J HYDR ENG DIV-ASCE, V105, P1247
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Babej J, 2016, GEOGR FIS DIN QUAT, V39, P3, DOI 10.4461/GFDQ.2016.39.1
   Badoux A, 2014, NAT HAZARD EARTH SYS, V14, P279, DOI 10.5194/nhess-14-279-2014
   Black M, 2014, SEDIMENTOLOGY, V61, P691, DOI 10.1111/sed.12072
   Brasington J, 2012, WATER RESOUR RES, V48, P0, DOI 10.1029/2012WR012223
   Bunte K., 2001, SAMPLING SURFACE SUB, V0, P0
   Buscombe D, 2010, J GEOPHYS RES-EARTH, V115, P0, DOI 10.1029/2009JF001477
   Buscombe D, 2020, EARTH SURF PROC LAND, V45, P638, DOI 10.1002/esp.4760
   Buscombe D, 2013, SEDIMENTOLOGY, V60, P1709, DOI 10.1111/sed.12049
   Buscombe D, 2009, SEDIMENTOLOGY, V56, P421, DOI 10.1111/j.1365-3091.2008.00977.x
   Butler JB, 2001, J HYDRAUL RES, V39, P519, DOI 10.1080/00221686.2001.9628276
   Carbonneau PE, 2018, EARTH SURF PROC LAND, V43, P1160, DOI 10.1002/esp.4298
   Carbonneau PE, 2005, WATER RESOUR RES, V41, P0, DOI 10.1029/2005WR003994
   Carbonneau PE, 2005, EARTH SURF PROC LAND, V30, P1687, DOI 10.1002/esp.1288
   Carbonneau PE, 2004, WATER RESOUR RES, V40, P0, DOI 10.1029/2003WR002759
   de Haas T, 2014, GEOMORPHOLOGY, V217, P165, DOI 10.1016/j.geomorph.2014.04.028
   Detert M, 2012, RIVER FLOW 2012, VOLS 1 AND 2, P595
   Fehr R., 1987, SCHWEIZER INGENIEUR, V105, P1104
   Graham DJ, 2010, WATER RESOUR RES, V46, P0, DOI 10.1029/2008WR006940
   Graham DJ, 2005, MATH GEOL, V37, P1, DOI 10.1007/s11004-005-8745-x
   Gregory KJ, 2019, RIVER RES APPL, V35, P1097, DOI 10.1002/rra.3455
   Grill G, 2019, NATURE, V569, P215, DOI 10.1038/s41586-019-1111-9
   Habersack H., 2011, FLIESSGEWASSERMODELL, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang GH, 2018, OPEN GEOSCI, V10, P607, DOI 10.1515/geo-2018-0048
   IBBEKEN H, 1986, EARTH SURF PROCESSES, V11, P59, DOI 10.1002/esp.3290110108
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Irniger A., 2020, UAV GRAIN SIZE DATAS, V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Krumbein W. C., 1939, MANUAL SEDIMENTARY P, VXIV C, P0
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Meyer-Peter E., 1948, PAPER PRESENTED 2 M, V3, P39
   Nelson J. M., 2016, TOOLS FLUV GEOMORPHO, V0, PP412, DOI 10.1002/9781118648551.CH18
   Piegay H, 2020, EARTH SURF PROC LAND, V45, P157, DOI 10.1002/esp.4787
   Poeppl RE, 2017, GEOMORPHOLOGY, V277, P237, DOI 10.1016/j.geomorph.2016.07.033
   Purinton B, 2019, EARTH SURF DYNAM, V7, P859, DOI 10.5194/esurf-7-859-2019
   Ramdas A, 2017, ENTROPY-SWITZ, V19, P0, DOI 10.3390/e19020047
   Rice S, 1998, EARTH SURF PROC LAND, V23, P345, DOI 10.1002/(SICI)1096-9837(199804)23:4<345::AID-ESP850>3.0.CO;2-B
   Rice SP, 2010, SEDIMENTOLOGY, V57, P232, DOI 10.1111/j.1365-3091.2009.01108.x
   Rubin DM, 2004, J SEDIMENT RES, V74, P160, DOI 10.1306/052203740160
   Settles B., 2009, 1648 U WISC, V0, P0
   Sharma K, 2020, IEEE WINT CONF APPL, V0, PP3626, DOI 10.1109/WACV45572.2020.9093484
   Shen CP, 2018, HYDROL EARTH SYST SC, V22, P5639, DOI 10.5194/hess-22-5639-2018
   Sime LC, 2003, J SEDIMENT RES, V73, P630, DOI 10.1306/112102730630
   Simon A, 2006, GEOMORPHOLOGY, V79, P361, DOI 10.1016/j.geomorph.2006.06.037
   Spada D, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7080314
   Surian N, 2003, GEOMORPHOLOGY, V50, P307, DOI 10.1016/S0169-555X(02)00219-2
   Surian N, 2002, GEOMORPHOLOGY, V43, P137, DOI 10.1016/S0169-555X(01)00127-1
   Van Horn G, 2015, PROC CVPR IEEE, V0, PP595, DOI 10.1109/CVPR.2015.7298658
   Vazquez-Tarrio D, 2017, GEOMORPHOLOGY, V285, P94, DOI 10.1016/j.geomorph.2017.01.039
   Verdu JM, 2005, GEOMORPHOLOGY, V72, P73, DOI 10.1016/j.geomorph.2005.04.015
   Wohl EE, 1996, WATER RESOUR RES, V32, P3219, DOI 10.1029/96WR01527
   Wolman M.G., 1954, EOS T AM GEOPHYS UN, V35, P951, DOI 10.1029/TR035I006P00951
   Woodget AS, 2018, EARTH SURF PROC LAND, V43, P857, DOI 10.1002/esp.4285
   Wu FC, 2018, GEOMORPHOLOGY, V308, P161, DOI 10.1016/j.geomorph.2018.02.013
   Zettler-Mann A, 2020, GEOMORPHOLOGY, V350, P0, DOI 10.1016/j.geomorph.2019.106920
NR 57
TC 10
Z9 10
U1 4
U2 8
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1027-5606
EI 1607-7938
J9 HYDROL EARTH SYST SC
JI Hydrol. Earth Syst. Sci.
PD MAY 19
PY 2021
VL 25
IS 5
BP 2567
EP 2597
DI 10.5194/hess-25-2567-2021
PG 31
WC Geosciences, Multidisciplinary; Water Resources
SC Geology; Water Resources
GA SH7UQ
UT WOS:000654339500001
DA 2023-04-26
ER

PT J
AU Zhou, N
   Li, X
   Shen, ZF
   Wu, TJ
   Luo, JC
AF Zhou, Nan
   Li, Xiang
   Shen, Zhanfeng
   Wu, Tianjun
   Luo, Jiancheng
TI Geo-Parcel-Based Change Detection Using Optical and SAR Images in Cloudy and Rainy Areas
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Change detection; cloudy and rainy; geo-parcel; multisource images
ID unsupervised change detection; classification; fusion
AB In this article, we deal with the problem of change detection in cloudy and rainy areas using multisource remote sensing images. While previous methods mostly focus on change detection on pixel or super-pixel levels, in this article, we introduce the concept of geo-parcel and use it as the basic processing unit for our change detection method. Concretely, we first extract geo-parcel from an optical high spatial resolution remote sensing image. Then, we divide each geo-parcel into fine-grained segments with refined boundaries using image segmentation methods. These fine-grained segments are used as the basic processing units for our change detection method. After that, an unsupervised learning-based method is adopted to obtain the difference map by comparing synthetic aperture radar images of two periods. Training samples with labels are automatically generated from the difference map. Finally, a deep neural network is trained using the generated samples and is further used to predict the refined change map. Experiments on the collected images from Gui'an, Guizhou Province, China demonstrate the effectiveness of the proposed method for change detection in a cloudy and rainy area with an overall accuracy surpasses 94%.
C1 [Zhou, Nan] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100049, Peoples R China.
   [Zhou, Nan] Univ Chinese Acad Sci, Beijing 100864, Peoples R China.
   [Li, Xiang] NYU Tandon & Abu Dhabi, NYU Multimedia & Visual Comp Lab, Abu Dhabi 129188, U Arab Emirates.
   [Shen, Zhanfeng; Luo, Jiancheng] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100049, Peoples R China.
   [Wu, Tianjun] Changan Univ, Sch Sci, Xian 710064, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Chang'an University
RP Shen, ZF (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100049, Peoples R China.
EM zhounan@aircas.ac.cn; xl1845@nyu.edu; shenzf@aircas.ac.cn; tjwu@chd.edu.cn; luojc@radi.ac.cn
FU National Key Research and Development Program of China [2017YFB0504204, 2018YFB0505000]; National Natural Science Foundation of China [41971375, 41631179]; Xinjiang Uygur Autonomous Region Flexible Talent Award
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP), V0, P0
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Iglovikov V, 2018, IEEE COMPUT SOC CONF, V0, PP228, DOI 10.1109/CVPRW.2018.00042
   Li L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091091
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), V0, P0, DOI DOI 10.1145/3173574.3173703
   Liu Y, 2017, PROC CVPR IEEE, V0, PP5872, DOI 10.1109/CVPR.2017.622
   Mnih V., 2013, PHD DISSERTATION, V0, P0
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Renu U., 1900, V2, V0, P1726
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Tong X.-Y., 2018, ARXIV180705713, V0, P0
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wan L, 2019, IEEE GEOSCI REMOTE S, V16, P1026, DOI 10.1109/LGRS.2019.2892432
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Yokoya N, 2018, IEEE J-STARS, V11, P1363, DOI 10.1109/JSTARS.2018.2799698
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhou LC, 2018, IEEE COMPUT SOC CONF, V0, PP192, DOI 10.1109/CVPRW.2018.00034
NR 24
TC 3
Z9 3
U1 3
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1326
EP 1332
DI 10.1109/JSTARS.2020.3038169
PG 7
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900043
DA 2023-04-26
ER

PT J
AU Thiyagarajan, A
   Gunasekar, K
AF Thiyagarajan, Akila
   Gunasekar, Kumaragurubaran
TI An improved feature selection based classifier for prediction of different regions in sar images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic aperture radar (SAR); Satellite image processing; Pyramid histogram of oriented gradients; Principal component analysis; Random forest classifier
ID superpixel segmentation; neural-network
AB Satellite images play an essential role in various applications like geographical information systems, remote sensing, ecology, and oceanography. Synthetic Aperture Radar (SAR) imaging is used to achieve high-resolution images on earth. However, these images are positively affected by unnecessary noises by compression and transmission errors. The noise removal process is a challenging task that it had artefacts and blurring of images. Existing researches and studies proposed various de-noising techniques to improve the accuracy of these images, and that attains specific application. These techniques had not yet attained the high performances due to the inaccurate prediction of objects. The primary aim of this research is to enhance the classification accuracy of different regions like water region, residential area, land region, and forest region from SAR images. From input SAR images, the features are extracted by using proposed hybrid saliency mapping and pyramid histogram of oriented gradients. The most important features are selected by using the Improved Principal Component Analysis (IPCA) technique. Further, the classification of regions is achieved by using a novel forest classifier. The performance of the proposed framework ha analyzed with the measures of accuracy, specificity, sensitivity, precision, recall, and f-score. In the result analysis, the proposed method had achieved 98% of accuracy compared than the state-of-the-art algorithms. From the estimation results, it is concluded that the proposed approach offers better results with increased accuracy for the prediction of different objects in SAR images.
C1 [Thiyagarajan, Akila] King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
   [Gunasekar, Kumaragurubaran] Univ Strathclyde, Dept Engn, Glasgow, Lanark, Scotland.
C3 King Khalid University; University of Strathclyde
RP Thiyagarajan, A (corresponding author), King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
EM ajan@kku.edu.sa
CR Abburu S., 2015, INT J COMPUT APPL, V119, P20, DOI 10.5120/21088-3779
   Adelabu S, 2015, GEOCARTO INT, V30, P457, DOI 10.1080/10106049.2014.885589
   Arisoy S, 2016, IEEE GEOSCI REMOTE S, V13, P1721, DOI 10.1109/LGRS.2016.2605583
   Baghi A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), V0, PP229, DOI 10.1109/PRIA.2017.7983052
   Buono A, 2016, IEEE T GEOSCI REMOTE, V54, P5862, DOI 10.1109/TGRS.2016.2574561
   Chen JW, 2016, IEEE GEOSCI REMOTE S, V13, P1467, DOI 10.1109/LGRS.2016.2592503
   Chen L, 2020, REMOTE SENS LETT, V11, P807, DOI 10.1080/2150704X.2020.1773564
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, P0, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-020-02066-z
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, P0, DOI 10.1002/cpe.5533
   Chen YT, 2019, CLUSTER COMPUT, V22, PS7665, DOI 10.1007/s10586-018-2368-8
   Dellinger F, 2015, IEEE T GEOSCI REMOTE, V53, P453, DOI 10.1109/TGRS.2014.2323552
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Gao F, 2019, IEEE ACCESS, V7, P108617, DOI 10.1109/ACCESS.2019.2933459
   Gu J, 2016, IEEE J-STARS, V9, P1265, DOI 10.1109/JSTARS.2015.2502991
   Guan DD, 2018, IEEE GEOSCI REMOTE S, V15, P1035, DOI 10.1109/LGRS.2018.2821711
   Hou B, 2016, IEEE GEOSCI REMOTE S, V13, P33, DOI 10.1109/LGRS.2015.2493242
   Javed U, 2016, IEEE T AERO ELEC SYS, V52, P181, DOI 10.1109/TAES.2015.120817
   Kavzoglu T, 2017, HANDBOOK OF NEURAL COMPUTATION, V0, PP607, DOI 10.1016/B978-0-12-811318-9.00033-8
   Kohli D, 2016, J SPAT SCI, V61, P405, DOI 10.1080/14498596.2016.1138247
   Kumar RP, 2020, MACHINE LEARNING ML, V29, P231
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li HG, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010156
   Li MQ, 2018, MATH PROBL ENG, V2018, P0, DOI 10.1155/2018/4576015
   Li WJ, 2017, INT GEOSCI REMOTE SE, V0, PP846, DOI 10.1109/IGARSS.2017.8127085
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   Liu FQ, 2016, IEEE GEOSCI REMOTE S, V13, P242, DOI 10.1109/LGRS.2015.2507982
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Qin FC, 2015, IEEE GEOSCI REMOTE S, V12, P13, DOI 10.1109/LGRS.2014.2322960
   Quickbird, 2020, QUICKBIRD SATELLITE, V0, P0
   Rostami O, 2021, COMPUTAT GEOSCI, V25, P911, DOI 10.1007/s10596-020-10030-1
   Santi F, 2016, IEEE T GEOSCI REMOTE, V54, P6217, DOI 10.1109/TGRS.2016.2583784
   Shang RH, 2016, IEEE J-STARS, V9, P1640, DOI 10.1109/JSTARS.2016.2516014
   Traore BB, 2017, EXPERT SYST APPL, V72, P443, DOI 10.1016/j.eswa.2016.10.010
   Wang F, 2017, IEEE T GEOSCI REMOTE, V55, P537, DOI 10.1109/TGRS.2016.2611060
   Wang S.P., 2021, J LEATHER SCI ENG, V3, P1, DOI 10.1186/s42825-020-00042-z
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
NR 40
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT 15
PY 2021
VL 80
IS 25
BP 33641
EP 33662
DI 10.1007/s11042-021-11416-8
EA AUG 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687012300003
DA 2023-04-26
ER

PT J
AU Ye, N
   Morgenroth, J
   Xu, C
   Chen, N
AF Ye, Ning
   Morgenroth, Justin
   Xu, Cong
   Chen, Na
TI Indigenous forest classification in New Zealand-A comparison of classifiers and sensors
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Image fusion; Vegetation classification; Artificial neural network; Pixel-based classification; Land cover; Land use
ID tree species classification; red edge position; chlorophyll content; global vegetation; spatial-resolution; accuracy; index; algorithms; images; area
AB Understanding the composition and the changes of New Zealand's woody vegetation communities is important for effective management. However, past national-scale mapped classifications emphasised mature rather than seral vegetation communities and forests were mapped in relative coarse spatial resolution. The integration of Sentinel-2 and PlanetScope imagery provides an opportunity for forest mapping with low cost and high accuracy. This study aims to investigate the feasibility of the integrated image for detailed forest mapping. Free satellite data (Sentinel-2, PlanetScope, fused data) were compared with commercial data (WorldView-2, and WorldView-2 resampled to Sentinel-2 and PlanetScope spatial resolutions) by conducting pixel-based classification with three machine learning classifiers (Support Vector Machine radial basis function kernel, Random Forest, Artificial Neural Network). The combinations of imagery type and classifier were assessed on their potential for mapping nine land cover classes in podocarp forest in New Zealand's central north island, including: conifer, low layer vegetation, broadleaf evergreen, highland softwood, wetland vegetation, water, dead tree, lowland softwood, and low-density vegetation and bare soil. Spectral features (single bands and indices), textural features, and an 8 m resolution digital terrain model (DTM) were used in classifications; the relative importance of these input features was also assessed. In this study, it was found that the overall classification accuracy was dependent on the combination of classifier and imagery, with different combinations resulting in a range of accuracies between 0.669 and 0.956. The best overall accuracy was achieved by integrating Sentinel-2 and PlanetScope imagery (0.956) which was even greater than that of WorldView-2 (0.951). The digital terrain model was the most important feature for all scenarios; Gray-Level Co-Occurrence Matrix-Mean was the most important texture variable for WorldView-2 and integrated images. Original bands, as well as GI, Norm-G, and SR-NIRR, were also crucial for vegetation classification.
C1 [Ye, Ning; Morgenroth, Justin; Xu, Cong] Univ Canterbury, New Zealand Sch Forestry, Private Bag 4800, Christchurch 8041, New Zealand.
   [Chen, Na] Wageningen Univ & Res, Lab Geoinformat Sci & Remote Sensing, Droevendaalsesteeg 3,POB 47, NL-6700 AA Wageningen, Netherlands.
C3 University of Canterbury; Wageningen University & Research
RP Ye, N (corresponding author), Univ Canterbury, New Zealand Sch Forestry, Private Bag 4800, Christchurch 8041, New Zealand.
EM ning.ye@pg.canterbury.ac.nz; justin.morgenroth@canterbury.ac.nz; cong.xu@canterbury.ac.nz; na.chen@wur.nl
FU School of Forestry and College of Engineering at the University of Canterbury
CR Adelabu S, 2013, J APPL REMOTE SENS, V7, P0, DOI 10.1117/1.JRS.7.073480
   Afwani MZ, 2019, PROC SPIE, V11311, P0, DOI 10.1117/12.2548423
   Ansari A.A., 2016, PLANT BIODIVERSITY M, V0, P0
   Blackburn GA, 1998, REMOTE SENS ENVIRON, V66, P273, DOI 10.1016/S0034-4257(98)00059-5
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Chen PF, 2010, SPECTROSC SPECT ANAL, V30, P512, DOI 10.3964/j.issn.1000-0593(2010)02-0512-06
   Congalton RG, 2001, INT J WILDLAND FIRE, V10, P321, DOI 10.1071/WF01031
   Dalponte M, 2012, REMOTE SENS ENVIRON, V123, P258, DOI 10.1016/j.rse.2012.03.013
   Datt B, 1999, J PLANT PHYSIOL, V154, P30, DOI 10.1016/S0176-1617(99)80314-9
   ENVI, 2019, EXELIS VISUAL INFORM, V0, P0
   ESRI, 2019, ARCGIS DESKTOP 1071, V0, P0
   FILELLA I, 1994, INT J REMOTE SENS, V15, P1459, DOI 10.1080/01431169408954177
   Garson DG., 1991, AI EXPERT, V6, P47, DOI 10.5555/129449.129452
   Gasparovic M, 2018, INT J REMOTE SENS, V39, P822, DOI 10.1080/01431161.2017.1392640
   Ghosh A, 2014, INT J APPL EARTH OBS, V26, P298, DOI 10.1016/j.jag.2013.08.011
   Gitelson AA, 1996, REMOTE SENS ENVIRON, V58, P289, DOI 10.1016/S0034-4257(96)00072-7
   Gitelson AA, 1996, J PLANT PHYSIOL, V148, P501, DOI 10.1016/S0176-1617(96)80285-9
   Gong P, 1997, REMOTE SENS ENVIRON, V62, P189, DOI 10.1016/S0034-4257(97)00094-1
   Grabska E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101197
   Hennessy A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010113
   Herbert J.W, 1978, FOREST PATTERN REGEN, V0, P0
   HUETE AR, 1988, REMOTE SENS ENVIRON, V25, P295, DOI 10.1016/0034-4257(88)90106-X
   Immitzer M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222599
   Immitzer M, 2012, REMOTE SENS-BASEL, V4, P2661, DOI 10.3390/rs4092661
   Ke Y., 2007, P ASPRS 2007 ANN C, V0, P0
   Kupidura P, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101233
   Land Information New Zealand (LINZ), 2020, NZ 8M DIG EL MOD 201, V0, P0
   Landcare Research, 2020, ECOSAT LCDB WHAT IS, V0, P0
   Laurin GV, 2016, REMOTE SENS ENVIRON, V176, P163, DOI 10.1016/j.rse.2016.01.017
   le Maire G, 2004, REMOTE SENS ENVIRON, V89, P1, DOI 10.1016/j.rse.2003.09.004
   Lichtenthaler HK, 1996, J PLANT PHYSIOL, V148, P599, DOI 10.1016/S0176-1617(96)80081-2
   Lissens G, 2000, INT GEOSCI REMOTE SE, V0, PP834, DOI 10.1109/IGARSS.2000.861719
   Liu M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010146
   Lottering R, 2016, ISPRS J PHOTOGRAMM, V112, P13, DOI 10.1016/j.isprsjprs.2015.11.010
   Lu DS, 2014, INT J REMOTE SENS, V35, P8188, DOI 10.1080/01431161.2014.980920
   Marden M, 2018, NZ J FORESTRY SCI, V48, P0, DOI 10.1186/s40490-018-0113-y
   Mason NWH, 2013, FOREST ECOL MANAG, V305, P177, DOI 10.1016/j.foreco.2013.05.028
   Meyer David, 2021, CRAN, V0, P0
   Ministry for the Environment (MfE), 2020, ENV AOTEAROA 2019 SU, V0, P0
   MONSERUD RA, 1992, ECOL MODEL, V62, P275, DOI 10.1016/0304-3800(92)90003-W
   NICHOLLS J L, 1976, NEW ZEALAND JOURNAL OF FORESTRY, V21, P105
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
   Palmer MW, 2002, ENVIRONMETRICS, V13, P121, DOI 10.1002/env.516
   Park G., 2000, NZ ECOSYSTEMS ECOSYS, V0, P0
   Persson M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111794
   PINTY B, 1992, VEGETATIO, V101, P15, DOI 10.1007/BF00031911
   Radoux J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060488
   Roffey M., 2019, VEGETATION TREE SPEC, V0, P0
   SCBD, 2020, NZ MAIN DETAILS, V0, P0
   Sesnie SE, 2008, REMOTE SENS ENVIRON, V112, P2145, DOI 10.1016/j.rse.2007.08.025
   Shahi K, 2015, EGYPT J REMOTE SENS, V18, P27, DOI 10.1016/j.ejrs.2014.12.003
   Sheil D, 2018, FOR ECOSYST, V5, P0, DOI 10.1186/s40663-018-0138-y
   Sripada RP, 2006, AGRON J, V98, P968, DOI 10.2134/agronj2005.0200
   The Ministry for Primary Industries (MPI), 2020, NZS FOR, V0, P0
   Trier OD, 2018, EUR J REMOTE SENS, V51, P336, DOI 10.1080/22797254.2018.1434424
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Venables W.N., 2002, MODERN APPL STAT S, V0, P0
   Wolf AF, 2012, PROC SPIE, V8390, P0, DOI 10.1117/12.917717
   Wulf H., 2015, P SENT 2A EXP US TEC, V0, P0
   Yao W, 2012, REMOTE SENS ENVIRON, V123, P368, DOI 10.1016/j.rse.2012.03.027
   Zhang F, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112105
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
NR 65
TC 4
Z9 4
U1 6
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD OCT 15
PY 2021
VL 102
IS 
BP 
EP 
DI 10.1016/j.jag.2021.102395
PG 10
WC Remote Sensing
SC Remote Sensing
GA UX4ZW
UT WOS:000700853200003
DA 2023-04-26
ER

PT J
AU Yahya, BM
   Yahya, FS
   Thannoun, RG
AF Yahya, Bashar Moneer
   Yahya, Farah Samier
   Thannoun, Rayan Ghazi
TI COVID-19 prediction analysis using artificial intelligence procedures and GIS spatial analyst: a case study for Iraq
SO APPLIED GEOMATICS
LA English
DT Article
DE COVID-19; Prediction; Artificial neural networks; Geographic Information System; Geospatial analysis
ID neural-networks; model
AB The prediction of diseases caused by viral infections is a complex medical task where many real data that consists of different variables must be employed. As known, COVID-19 is the most dangerous disease worldwide; nowhere, an effective drug has been found yet. To limit its spread, it is essential to find a rational method that shows the spread of this virus by relying on many infected people's data. A model consisting of three artificial neural networks' (ANN) functions was developed to predict COVID-19 separation in Iraq based on real infection data supplied by the public health department at the Iraqi Ministry of Health. The performance efficiency of this model was evaluated, where its performance efficiency reached 81.6% when employed four statistical error criteria as mean absolute percentage error (MAPE), root mean square error (RMSE), coefficient of determination (R-2), and Nash-Sutcliffe coefficient (NC). The severity of the virus's spread across Iraq was assessed in a short term (in the next 6 months), where the results show that the spread severity will intensify in this short term by 17.1%, and the average death cases will increase by 8.3%. These results clarified by creating spatial distribution maps for virus spread are simulated by employing a Geographic Information System (GIS) environment to be used as a useful database for developing plans for combating viruses in Iraq.
C1 [Yahya, Bashar Moneer; Thannoun, Rayan Ghazi] Univ Mosul, Ctr Remote Sensing, Mosul, Iraq.
   [Yahya, Farah Samier] Univ Mosul, Coll Med, Mosul, Iraq.
C3 University of Mosul; University of Mosul
RP Yahya, BM (corresponding author), Univ Mosul, Ctr Remote Sensing, Mosul, Iraq.
EM bashar1974@uomosul.edu.iq; fsy@uomousul.edu.iq; rayan.ghazi@uomosul.edu.iq
CR Abebe AJ, 2000, HYDROLOG SCI J, V45, P425, DOI 10.1080/02626660009492339
   Ahmad A., 2020, TRENDS RENEW ENERGY, V6, P12, DOI 10.17737/tre.2020.6.1.00110
   Alamo T, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9050827
   [Anonymous], 2020, RADIOLOGY, V0, P0, DOI DOI 10.1148/radiol.2020200490
   [Anonymous], 1981, PATTERN RECOGN, V0, P0
   Astakhova N. N., 2015, CONT ENG SCI, V8, P1659, DOI 10.12988/CES.2015.510286
   Ruiz LGB, 2016, ENERGIES, V9, P0, DOI 10.3390/en9090684
   Baskir MB, 2013, EXPERT SYST APPL, V40, P929, DOI 10.1016/j.eswa.2012.05.049
   BELLO MG, 1992, IEEE T NEURAL NETWOR, V3, P864, DOI 10.1109/72.165589
   Cadenas E, 2016, ENERGIES, V9, P0, DOI 10.3390/en9020109
   Fitzpatrick F, 2020, CURR TREAT OPT INFEC, V12, P135, DOI 10.1007/s40506-020-00216-7
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   Kandwal R, 2009, J BIOMED INFORM, V42, P748, DOI 10.1016/j.jbi.2009.04.008
   Lai CC, 2020, INT J ANTIMICROB AG, V55, P0, DOI 10.1016/j.ijantimicag.2020.105924
   Lauer SA, 2020, ANN INTERN MED, V172, P577, DOI 10.7326/M20-0504
   Liao PH, 2015, HEALTH INFORM J, V21, P137, DOI 10.1177/1460458213509806
   Lin TN, 1996, IEEE T NEURAL NETWOR, V7, P1329, DOI 10.1109/72.548162
   Lyseen A K, 2014, YEARB MED INFORM, V9, P110, DOI 10.15265/IY-2014-0008
   Mirmozaffari M., 2019, EUROPEAN J ENG RES S, V4, P1, DOI 10.24018/EJERS.2019.4.3.1168
   Murad A, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9050328
   Murugesan B, 2020, J GEOGR STUD, V4, P1, DOI 10.21523/gcj5.20040101
   Naude W, 2020, AI SOC, V35, P761, DOI 10.1007/s00146-020-00978-0
   Peiffer-Smadja N, 2020, CLIN MICROBIOL INFEC, V26, P584, DOI 10.1016/j.cmi.2019.09.009
   Rahmani F, 2021, ENVIRON RES LETT, V16, P0, DOI 10.1088/1748-9326/abd501
   Rahmati AS, 2019, OIL GAS SCI TECHNOL, V74, P0, DOI 10.2516/ogst/2019021
   Scardoni A, 2020, J INFECT PUBLIC HEAL, V13, P1061, DOI 10.1016/j.jiph.2020.06.006
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Stebbing J., 2020, EMBO MOL MED, V12, P0, DOI 10.15252/emmm.202012697
   Steiner MC, 2020, VIRUSES-BASEL, V12, P0, DOI 10.3390/v12050560
   Uysal G, 2016, PROCEDIA ENGINEER, V154, P1185, DOI 10.1016/j.proeng.2016.07.526
   Wang PZ, 2019, SCI TOTAL ENVIRON, V693, P0, DOI 10.1016/j.scitotenv.2019.07.246
   Yahya BM, 2019, APPL ARTIF INTELL, V33, P137, DOI 10.1080/08839514.2018.1530858
   Yalur T, 2020, AI SOC, V35, P737, DOI 10.1007/s00146-019-00910-1
   Yang ZF, 2020, J THORAC DIS, V12, P165, DOI 10.21037/jtd.2020.02.64
   Yokoi S, 2011, J APPL METEOROL CLIM, V50, P1666, DOI 10.1175/2011JAMC2643.1
   Zhang SC, 2003, APPL ARTIF INTELL, V17, P375, DOI 10.1080/713827180
   Zhou XZ, 2010, ARTIF INTELL MED, V48, P139, DOI 10.1016/j.artmed.2009.07.012
NR 37
TC 14
Z9 15
U1 3
U2 10
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1866-9298
EI 1866-928X
J9 APPL GEOMAT
JI Appl. Geomat.
PD SEP 15
PY 2021
VL 13
IS 3
BP 481
EP 491
DI 10.1007/s12518-021-00365-4
EA MAR 2021
PG 11
WC Remote Sensing
SC Remote Sensing
GA UC8JK
UT WOS:000625070900001
DA 2023-04-26
ER

PT J
AU Dinh, TC
   Dinh, TC
   Anh, TT
   Xuan, BM
   Manh, LN
   Thanh, DV
   Van, DL
   Thanh, HD
   Quang, TN
AF Trong Cao Dinh
   Trieu Cao Dinh
   Tuan Thai Anh
   Bach Mai Xuan
   Luc Nguyen Manh
   Duong Van Thanh
   Dung Le Van
   Hai Dang Thanh
   Toan Ngo Quang
TI Mapping Seismic Zones Based on the Geomorphic Indices and the Analytic Hierarchy Process (AHP): A Case Study in Cao Bang Province and Adjacent Areas (Vietnam)
SO JOURNAL OF THE GEOLOGICAL SOCIETY OF INDIA
LA English
DT Article
ID artificial neural-networks; structural evolution; active fault; hazard; basin
AB This paper presents the application of Digital Elevation Model (DEM) for mapping seismic zones in Cao Bang province and adjacent areas. The application of the Analytic Hierarchy Process (AHP) in this study consists of four analytical steps namely: (1) Determination of the geomorphic indices' sensitivity with respect to the earthquake activity using the MLP (Multi-layer Perceptron) neural network; (2) Calculation of the weight coefficients of all indices according to principle Eigenvector (AHP method); (3) Estimation of the ranking sensitivity of each geomorphic indices to the earthquake activity using their value distribution and (4) Identification of the Seismic Susceptibility Index (SSI). The results show that there are 6 seismic zones in the study area, including Na Hang, where the largest earthquake occurred with M4.6 (November 1, 1943); Ha Giang M5.0 (August 18, 1975); Bao Lac M5.2 (June 13, 1968); Cao Bang-Tien Yen M5.0 (November 1, 1933); Quang Yen-Song Bang M4.6 (April 6, 1979) and Quay Son River M5.0 (November 25, 2019).
C1 [Trong Cao Dinh; Tuan Thai Anh; Bach Mai Xuan; Luc Nguyen Manh; Duong Van Thanh; Dung Le Van; Hai Dang Thanh] VAST, Inst Geophys, A8-18 Hoang Quoc Viet Rd, Hanoi, Vietnam.
   [Trong Cao Dinh; Trieu Cao Dinh; Tuan Thai Anh; Hai Dang Thanh] Univ Sci & Technol, VAST, A28-18 Hoang Quoc Viet Rd, Hanoi, Vietnam.
   [Trieu Cao Dinh] VUSTA, Inst Appl Geophys, 210 Doi Can Rd, Hanoi, Vietnam.
   [Trieu Cao Dinh] Vietnam Natl Univ Ho Chi Minh City, 227 Nguyen Van Cu Rd, Ho Chi Minh City, Vietnam.
   [Toan Ngo Quang] Vietnam Union Geol Sci, 6 Pham Ngu Lao Rd, Hanoi, Vietnam.
C3 Vietnam Academy of Science & Technology (VAST); Vietnam Academy of Science & Technology (VAST); Vietnam National University Hochiminh City
RP Dinh, TC (corresponding author), Univ Sci & Technol, VAST, A28-18 Hoang Quoc Viet Rd, Hanoi, Vietnam.; Dinh, TC (corresponding author), VUSTA, Inst Appl Geophys, 210 Doi Can Rd, Hanoi, Vietnam.; Dinh, TC (corresponding author), Vietnam Natl Univ Ho Chi Minh City, 227 Nguyen Van Cu Rd, Ho Chi Minh City, Vietnam.
EM cdtrieu@gmail.com
FU Vietnam Academy of Science and Technology (VAST) [VAST05.06/21-22]
CR Alaei M, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-3025-x
   [Anonymous], 2009, US GEOL SURV OPEN FI, V0, P0
   ARIAN M, 2015, OPEN J GEOL, V5, P291, DOI 10.4236/ojg.2015.55026
   Beck MW, 2018, J STAT SOFTW, V85, P0, DOI 10.18637/jss.v085.i11
   BLAKELY RJ, 1986, GEOPHYSICS, V51, P1494, DOI 10.1190/1.1442197
   Bruce AB., 1999, EARTHQUAKE, V0, P0
   Cao D.T., 2007, P 5 VIETN SCI TECHN, V0, PP159, DOI 10.1093/EJIL/CHAB022
   Cao DT., 2009, VIETNAM J GEOL, V314, P27
   Cao DT., 2019, TECTONIC DEFORMATION, V0, P0
   Cao DT., 2005, GEOPHYSICAL FIELD LI, V0, P0
   Dang T.H, 2003, PHDTHESIS, V0, P0
   Dao V.T., 2011, TNMT0304 CTR INF DOC, V0, P0
   Dehbozorgi M, 2010, GEOMORPHOLOGY, V121, P329, DOI 10.1016/j.geomorph.2010.05.002
   DIMOPOULOS Y, 1995, NEURAL PROCESS LETT, V2, P1, DOI 10.1007/BF02309007
   Dubey RK, 2017, J ASIAN EARTH SCI, V148, P153, DOI 10.1016/j.jseaes.2017.08.032
   Eusden JD, 2000, NEW ZEAL J GEOL GEOP, V43, P391, DOI 10.1080/00288306.2000.9514896
   Fiedler B, 2018, B SEISMOL SOC AM, V108, P2778, DOI 10.1785/0120180091
   Garson DG., 1991, AI EXPERT, V6, P47, DOI 10.5555/129449.129452
   Geological map scale 1/200.000, 2000, F4811 DEP GEOL MIN V, V0, P0
   Geophysical Division Vietnam, 2011, BOUG GRAV AN MAP MAI, V0, P0
   Giaconia F, 2012, GEOMORPHOLOGY, V145, P90, DOI 10.1016/j.geomorph.2011.12.043
   GOH ATC, 1995, ARTIF INTELL ENG, V9, P143, DOI 10.1016/0954-1810(94)00011-S
   Howes P, 1999, NEUROCOMPUTING, V24, P191, DOI 10.1016/S0925-2312(98)00102-7
   Ihaka R., 1996, J COMPUTNL GRAPH STA, V5, P299, DOI 10.2307/1390807
   Institute of Geophysics, 2020, NOT EARTHQ LIST EART, V0, P0
   Jackson J, 1996, J STRUCT GEOL, V18, P217, DOI 10.1016/S0191-8141(96)80046-0
   Jaime P., 2021, JOUR STAT SOFTWARE, V5, P0, DOI 10.18637/jss.v000.i00
   Jayappa KS, 2012, INT ARCH PHOTOGRAMM, V39-B8, P215
   Keller A.E., 1996, ACTIVE TECTONICS EAR, V0, P0
   Keller EA., 1986, ACTIVE TECTONICS, V1, P136
   Keller EA., 2002, ACTIVE TECTONICS EAR, V0, P0
   Le DA., 2012, GEOMORPHOLOGY VIETNA, V0, P0
   Le T.V, 2004, SUPPLEMENT JOUR EART, V25, P0
   LETTIS WR, 1991, GEOLOGY, V19, P559, DOI 10.1130/0091-7613(1991)019<0559:CSPIFS>2.3.CO;2
   Manuel P., 2003, ADV NATURAL SCI, V4, P347
   Ngo VL., 2016, J EARTH SCI, V38, P1
   Ngo VL., 2006, J EARTH SCI, V2, P110
   Nguyen D.X., 2004, INJECTION MOLDING SC, V0, P0
   Nguyen V.N., 2015, THESIS NATL LIB HANO, V0, P0
   Olden JD, 2004, ECOL MODEL, V178, P389, DOI 10.1016/j.ecolmodel.2004.03.013
   Ozdemir H, 2009, ENVIRON GEOL, V56, P1405, DOI 10.1007/s00254-008-1235-y
   Pareta Kuldeep, 2011, INTERNATIONAL JOURNAL OF GEOMATICS AND GEOSCIENCES, V2, P248
   Trinh PT, 2013, CENT EUR J GEOSCI, V5, P223, DOI 10.2478/s13533-012-0128-5
   Phung TTH, 2011, COMP STUDY LEVEL MOD, V0, P0
   Phung VP., 1996, MODERN TERRITORY VIE, V1, P101
   Robert SY., 1997, GEOLOGY EARTHQUAKES, V0, P0
   Saaty T.L., 1980, ANAL HIERARCHY PROCE, V0, P0
   Saaty TL, 1994, DECISION MAKING EC P, V0, P0
   Sarp G, 2014, J ASIAN EARTH SCI, V88, P168, DOI 10.1016/j.jseaes.2014.03.018
   Srivastava OS., 2014, INT J ENG SCI, V3, P71
   Sujatha ER, 2015, GEOMAT NAT HAZ RISK, V6, P326, DOI 10.1080/19475705.2013.845114
   Temitope D., 2020, GEOL ECOL LANDSCAPES, V0, P0, DOI DOI 10.1080/24749508.2020.1812147
   Trong Cao Dinh, 2021, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INNOVATIONS FOR SUSTAINABLE AND RESPONSIBLE MINING. ISRM 2020. LECTURE NOTES IN CIVIL ENGINEERING (LNCE 108), V0, PP167, DOI 10.1007/978-3-030-60269-7_9
   Van Kha T, 2018, J APPL GEOPHYS, V152, P161, DOI 10.1016/j.jappgeo.2018.03.023
   Vasilakos C, 2009, NAT HAZARDS, V50, P125, DOI 10.1007/s11069-008-9326-3
   Vu VC., 2000, J EARTH SCI, V22, P181
   William B.B., 2007, TECTONIC GEOMORPHOLO, V0, P0
   YOON Y, 1994, DECIS SUPPORT SYST, V11, P497, DOI 10.1016/0167-9236(94)90021-3
NR 58
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA
SN 0016-7622
EI 0974-6889
J9 J GEOL SOC INDIA
JI J. Geol. Soc. India
PD DEC 15
PY 2021
VL 97
IS 12
BP 1565
EP 1573
DI 10.1007/s12594-021-1914-9
PG 9
WC Geosciences, Multidisciplinary
SC Geology
GA XQ4GV
UT WOS:000731505200015
DA 2023-04-26
ER

PT J
AU Peng, B
   Huang, QY
   Vongkusolkit, J
   Gao, S
   Wright, DB
   Fang, ZN
   Qiang, Y
AF Peng, Bo
   Huang, Qunying
   Vongkusolkit, Jamp
   Gao, Song
   Wright, Daniel B.
   Fang, Zheng N.
   Qiang, Yi
TI Urban Flood Mapping With Bitemporal Multispectral Imagery Via a Self-Supervised Learning Framework
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Urban areas; Spatial resolution; Optical sensors; Optical imaging; Hurricanes; Labeling; Image registration; Flood mapping; multispectral (MS) imagery; self-supervised learning; urban
ID convolutional neural-network; change-vector analysis
AB Near realtime flood mapping in densely populated urban areas is critical for emergency response. The strong heterogeneity of urban areas poses a big challenge for accurate near realtime flood mapping. However, previous studies on automatic methods for urban flood mapping perform infeasible in near realtime or fail to generalize well to other floods, for several reasons. First, multitemporal pixel-wise flood mapping requires accurate image registration, hindering the efficiency of large-scale processing. Although automatic image registration has been investigated, precisely coregistered multitemporal image sequence requires time-consuming fine tuning. Additionally, the floods may lead to the loss of many corresponding image points across multitemporal images for accurate coregistration. Second, existing unsupervised methods generally rely on hand-crafted features for floodwater detection. Such features may not well represent the patterns of floodwaters in different areas due to inconsistent weather conditions, illumination, and floodwater spectra. This article proposes a self-supervised learning framework for patch-wise urban flood mapping using bitemporal multispectral satellite imagery. Patch-wise change vector analysis is used with patch features learned through a self-supervised autoencoder to produce patch-wise change maps showing potentially flood-affected areas. Postprocessing including spectral and spatial filtering is applied to these patch-wise change maps to remove nonflood related changes. Final flood maps and parameter sensitivities were evaluated using several performance metrics. Two flood events from areas with differing degrees of urbanization were considered: Hurricane Harvey flood (2017) in Houston, Texas, and Hurricane Florence flood (2018) in Lumberton, North Carolina. The proposed method shows strong performance for self-supervised urban flood mapping.
C1 [Peng, Bo] Univ Wisconsin, Dept Elect & Comp Engn, Dept Geog, 1415 Johnson Dr, Madison, WI 53706 USA.
   [Huang, Qunying; Vongkusolkit, Jamp; Gao, Song] Univ Wisconsin, Dept Geog, Madison, WI 53706 USA.
   [Wright, Daniel B.] Univ Wisconsin, Dept Civil & Environm Engn, Madison, WI 53706 USA.
   [Fang, Zheng N.] Univ Texas Arlington, Dept Civil Engn, Arlington, TX 76019 USA.
   [Qiang, Yi] Univ S Florida, Sch Geosci, Tampa, FL 33620 USA.
C3 University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; University of Texas System; University of Texas Arlington; State University System of Florida; University of South Florida
RP Huang, QY (corresponding author), Univ Wisconsin, Dept Geog, Madison, WI 53706 USA.
EM bo.peng@wisc.edu; qhuang46@wisc.edu; vongkusolkit@wisc.edu; song.gao@wisc.edu; danielb.wright@wisc.edu; nickfang@uta.edu; qiangy@usf.edu
FU National Science Foundation [1940091]; Microsoft AI for Earth Grant; Vilas Associates Competition Award from University ofWisconsin-Madison (UW-Madison); Trewartha Graduate Research Award from Department of Geography at UW-Madison; ICER; Directorate For Geosciences [1940091] Funding Source: National Science Foundation
CR Adam P., 2017, NIPS, V0, P0
   Amitrano D, 2018, IEEE T GEOSCI REMOTE, V56, P3290, DOI 10.1109/TGRS.2018.2797536
   Bruzzone L, 2003, IEEE T GEOSCI REMOTE, V41, P2455, DOI 10.1109/TGRS.2003.817268
   Byun Y, 2015, REMOTE SENS-BASEL, V7, P10347, DOI 10.3390/rs70810347
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Dhakal AS, 2002, PHOTOGRAMM ENG REM S, V68, P233
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P6003, DOI 10.1109/TGRS.2019.2903875
   Feng QL, 2015, WATER-SUI, V7, P1437, DOI 10.3390/w7041437
   Gebrehiwot A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071486
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Greifeneder F, 2014, INT J REMOTE SENS, V35, P2857, DOI 10.1080/01431161.2014.890299
   Huang Q., 2019, P 3 ACM SIGSPATIAL I, V0, P40
   Insom P, 2015, IEEE GEOSCI REMOTE S, V12, P1943, DOI 10.1109/LGRS.2015.2439575
   Jing LL, 2022, INT J OCCUP SAF ERGO, V28, P842, DOI 10.1080/10803548.2020.1835234
   Kingma D. P, 2015, PROC INT C LEARN REP, V0, P0
   KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kolesnikov A, 2019, PROC CVPR IEEE, V0, PP1920, DOI 10.1109/CVPR.2019.00202
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   LEVANDOWSKY M, 1971, NATURE, V234, P34, DOI 10.1038/234034a0
   Li LY, 2015, ISPRS J PHOTOGRAMM, V101, P10, DOI 10.1016/j.isprsjprs.2014.11.006
   Li Y, 2019, ISPRS J PHOTOGRAMM, V152, P178, DOI 10.1016/j.isprsjprs.2019.04.014
   Liu T, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), V0, PP420, DOI 10.1145/3347146.3359068
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Malila W. A., 1980, SIXTH ANNUAL SYMPOSIUM ON MACHINE PROCESSING OF REMOTELY SENSED DATA AND SOIL INFORMATION SYSTEMS AND REMOTE SENSING AND SOIL SURVEY, V0, P326
   Malinowski R, 2015, REMOTE SENS-BASEL, V7, P14853, DOI 10.3390/rs71114853
   Microsoft Bing Maps Team, 2018, MICROSOFT BUILDING F, V0, P0
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212492
   Peng B, 2016, INT GEOSCI REMOTE SE, V0, PP5868, DOI 10.1109/IGARSS.2016.7730533
   Pilon P. J., 2002, TECH REP, V0, P0
   Planet Team, 2018, PLANET APPL PROGRAM, V0, P0
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   Rosin PL, 2002, COMPUT VIS IMAGE UND, V86, P79, DOI 10.1006/cviu.2002.0960
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Schlaffer S, 2015, INT J APPL EARTH OBS, V38, P15, DOI 10.1016/j.jag.2014.12.001
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Skakun S, 2010, COMPUT INFORM, V29, P1013
   Song H, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020114
   Tong LY, 2019, IEEE T GEOSCI REMOTE, V57, P7872, DOI 10.1109/TGRS.2019.2917001
   UN, 2019, UN SUST DEV GOALS, V0, P0
   USGS, 2019, FLOOD INUNDATION MAP, V0, P0
   Wang P, 2019, IEEE GEOSCI REMOTE S, V16, P771, DOI 10.1109/LGRS.2018.2882516
   Wieland M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192330
   Xie M, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2545, DOI 10.1145/3219819.3220053
   Zhang LF, 2017, IEEE J-STARS, V10, P4614, DOI 10.1109/JSTARS.2017.2725382
NR 51
TC 9
Z9 9
U1 9
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2001
EP 2016
DI 10.1109/JSTARS.2020.3047677
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QC7WE
UT WOS:000615042800002
DA 2023-04-26
ER

PT J
AU Hoodbhoy, Z
   Jeelani, SM
   Aziz, A
   Habib, MI
   Iqbal, B
   Akmal, W
   Siddiqui, K
   Hasan, B
   Leeflang, M
   Das, JK
AF Hoodbhoy, Zahra
   Jeelani, Sarah Masroor
   Aziz, Abeer
   Habib, Muhammad Ibrahim
   Iqbal, Bilal
   Akmal, Waqaas
   Siddiqui, Khan
   Hasan, Babar
   Leeflang, Mariska
   Das, Jai K.
TI Machine Learning for Child and Adolescent Health: A Systematic Review
SO PEDIATRICS
LA English
DT Review
ID care
AB CONTEXT: In the last few decades, data acquisition and processing has seen tremendous amount of growth, thus sparking interest in machine learning (ML) within the health care system. OBJECTIVE: Our aim for this review is to provide an evidence map of the current available evidence on ML in pediatrics and adolescent medicine and provide insight for future research. DATA SOURCES: A literature search was conducted by using Medline, the Cochrane Library, the Cumulative Index to Nursing and Allied Health Literature Plus, Web of Science Library, and EBSCO Dentistry & Oral Science Source. STUDY SELECTION: Articles in which an ML model was assessed for the diagnosis, prediction, or management of any condition in children and adolescents (0-18 years) were included. DATA EXTRACTION: Data were extracted for year of publication, geographical location, age range, number of participants, disease or condition under investigation, study methodology, reference standard, type, category, and performance of ML algorithms. RESULTS: The review included 363 studies, with subspecialties such as psychiatry, neonatology, and neurology having the most literature. A majority of the studies were from high-income (82%; n = 296) and upper middle-income countries (15%; n = 56), whereas only 3% (n = 11) were from low middle-income countries. Neural networks and ensemble methods were most commonly tested in the 1990s, whereas deep learning and clustering emerged rapidly in the current decade. LIMITATIONS: Only studies conducted in the English language could be used in this review. CONCLUSIONS: The interest in ML has been growing across various subspecialties and countries, suggesting a potential role in health service delivery for children and adolescents in the years to come.
C1 [Hoodbhoy, Zahra; Jeelani, Sarah Masroor; Aziz, Abeer; Hasan, Babar; Das, Jai K.] Aga Khan Univ, Dept Pediat & Child Hlth, POB 3500,Stadium Rd, Karachi 74800, Pakistan.
   [Habib, Muhammad Ibrahim; Iqbal, Bilal; Akmal, Waqaas] Aga Khan Univ, Karachi, Pakistan.
   [Siddiqui, Khan] Johns Hopkins Univ, Sch Med, Russell H Morgan Dept Radiol & Radiol Sci, Baltimore, MD USA.
   [Leeflang, Mariska] Univ Amsterdam, Dept Clin Epidemiol & Biostat, Amsterdam, Netherlands.
C3 Aga Khan University; Aga Khan University; Johns Hopkins University; University of Amsterdam
RP Hasan, B (corresponding author), Aga Khan Univ, Dept Pediat & Child Hlth, POB 3500,Stadium Rd, Karachi 74800, Pakistan.
EM babar.hasan@aku.edu
CR [Anonymous], 2013, DEF KEY TERMS, V0, P0
   [Anonymous], 2018, BRIEF BIOINFORM, V0, P0, DOI DOI 10.1093/bib/bbx044
   Browlee J, 2019, TOUR MACHINE LEARNIN, V0, P0
   Cox J L, 2001, CAN J CLIN PHARMACOL, V8 Suppl A, P0
   Das S., 2015, INT J COMPUTER APPL, V115, P31, DOI 10.5120/20182-2402
   Dreyer K, 2018, J AM COLL RADIOL, V15, P655, DOI 10.1016/j.jacr.2018.01.010
   Fraser Hamish S F, 2005, INFORM PRIM CARE, V13, P83
   Glymour C., 2014, DISCOVERING CAUSAL S, V0, P0
   Grapov D, 2018, OMICS, V22, P630, DOI 10.1089/omi.2018.0097
   Harerimana G, 2019, IEEE ACCESS, V7, P101245, DOI 10.1109/ACCESS.2019.2928363
   Iroju Olaronke G., 2015, INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, V7, P44, DOI 10.5815/ijitcs.2015.08.07
   Kelly CJ, 2019, BMC MED, V17, P0, DOI 10.1186/s12916-019-1426-2
   Khazaei H, 2015, IEEE J TRANSL ENG HE, V3, P0
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Langerhuizen DWG, 2019, CLIN ORTHOP RELAT R, V477, P2482, DOI 10.1097/CORR.0000000000000848
   Levy S, 2017, MOL AUTISM, V8, P0, DOI 10.1186/s13229-017-0180-6
   Liang HY, 2019, NAT MED, V25, P433, DOI 10.1038/s41591-018-0335-9
   LINDSAY RK, 1993, ARTIF INTELL, V61, P209, DOI 10.1016/0004-3702(93)90068-M
   Lovejoy CA, 2019, EUR PSYCHIAT, V55, P1, DOI 10.1016/j.eurpsy.2018.08.004
   Moher D., 2009, ANN INTERN MED, V6, P0, DOI 10.7326/0003-4819-151-10-200911170-00008
   Neves J, 2018, MOBILE NETW APPL, V23, P1123, DOI 10.1007/s11036-018-1071-6
   Niu JQ, 2016, ISPRS INT J GEO-INF, V5, P0, DOI 10.3390/ijgi5050066
   Piette JD, 2011, AM J PREV MED, V40, P629, DOI 10.1016/j.amepre.2011.02.014
   Poushter Jacob, 2016, SMARTPHONE OWNERSHIP, V22, P1
   Randall M, 2018, COCHRANE DB SYST REV, V0, PP1, DOI 10.1002/14651858.CD009044.pub2
   Sanchez-Martinez S, 2018, CIRC-CARDIOVASC IMAG, V11, P0, DOI 10.1161/CIRCIMAGING.117.007138
   SHONO H, 1992, INT J BIOMED COMPUT, V30, P113, DOI 10.1016/0020-7101(92)90074-3
   SHORTLIFFE EH, 1975, COMPUT BIOMED RES, V8, P303, DOI 10.1016/0010-4809(75)90009-9
   Sugiyama K., 1984, JPN J MED ELECT BIOL, V22, P942
   The Rockefeller Foundation; US Agency for International Development, 2019, ART INT GLOB HLTH DE, V0, P0
   Vidyasagar D, 2006, J PERINATOL, V26, P55, DOI 10.1038/sj.jp.7211402
   Wang YC, 2018, TECHNOL FORECAST SOC, V126, P3, DOI 10.1016/j.techfore.2015.12.019
   Wiens J, 2018, CLIN INFECT DIS, V66, P149, DOI 10.1093/cid/cix731
   World Bank Data Team, 2019, NEW COUNTR CLASS INC, V0, P0
   World Health Organization, 2007, TASK SHIFT RAT RED T, V0, P0
   World Health Organization, 2017, ANNEX C WHO REG GROU, V0, P0
   Zhang L, 2017, DRUG DISCOV TODAY, V22, P1680, DOI 10.1016/j.drudis.2017.08.010
NR 39
TC 12
Z9 13
U1 2
U2 8
PU AMER ACAD PEDIATRICS
PI ELK GROVE VILLAGE
PA 141 NORTH-WEST POINT BLVD,, ELK GROVE VILLAGE, IL 60007-1098 USA
SN 0031-4005
EI 1098-4275
J9 PEDIATRICS
JI Pediatrics
PD JAN 15
PY 2021
VL 147
IS 1
BP 
EP 
DI 10.1542/peds.2020-011833
PG 12
WC Pediatrics
SC Pediatrics
GA PQ4OE
UT WOS:000606524000005
PM 33323492
DA 2023-04-26
ER

PT J
AU Xiao, AR
   Yang, XF
   Lu, SJ
   Guan, DY
   Huang, JX
AF Xiao, Aoran
   Yang, Xiaofei
   Lu, Shijian
   Guan, Dayan
   Huang, Jiaxing
TI FPS-Net: A convolutional fusion network for large-scale LiDAR point cloud segmentation
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE LiDAR; Point cloud; Semantic segmentation; Spherical projection; Autonomous driving; Scene understanding
ID deep neural-networks; semantic segmentation; classification
AB Scene understanding based on LiDAR point cloud is an essential task for autonomous cars to drive safely, which often employs spherical projection to map 3D point cloud into multi-channel 2D images for semantic segmentation. Most existing methods simply stack different point attributes/modalities (e.g. coordinates, intensity, depth, etc.) as image channels to increase information capacity, but ignore distinct characteristics of point attributes in different image channels. We design FPS-Net, a convolutional fusion network that exploits the uniqueness and discrepancy among the projected image channels for optimal point cloud segmentation. FPS-Net adopts an encoder-decoder structure. Instead of simply stacking multiple channel images as a single input, we group them into different modalities to first learn modality-specific features separately and then map the learnt features into a common high-dimensional feature space for pixel-level fusion and learning. Specifically, we design a residual dense block with multiple receptive fields as a building block in encoder which preserves detailed information in each modality and learns hierarchical modality-specific and fused features effectively. In the FPS-Net decoder, we use a recurrent convolution block likewise to hierarchically decode fused features into output space for pixel-level classification. Extensive experiments conducted on two widely adopted point cloud datasets show that FPS-Net achieves superior semantic segmentation as compared with state-of-the-art projection-based methods. Specifically, FPS-Net outperforms the state-of-the-art in both accuracy (4.9% higher than RangeNet++ and 2.8% higher than PolarNet in mIoU) and computation speed (15.0 FPS faster than Squeeze-SegV3) for SemanticKITTI benchmark. For KITTI benchmark, FPS-Net achieves significant accuracy improvement (12.6% higher than RangeNet++ in mIoU) with comparable computation speed. In addition, the proposed modality fusion idea is compatible with typical projection-based methods and can be incorporated into them with consistent performance improvement.
C1 [Xiao, Aoran; Lu, Shijian; Guan, Dayan; Huang, Jiaxing] Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab Ente, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Yang, Xiaofei] Univ Macau, Ave Univ, Taipa 999078, Macau, Peoples R China.
C3 Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Macau
RP Lu, SJ (corresponding author), Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab Ente, 50 Nanyang Ave, Singapore 639798, Singapore.
EM aoran.xiao@ntu.edu.sg; yangxiaofei@um.edu.mo; Shijian.Lu@ntu.edu.sg; dayan.guan@ntu.edu.sg; jiaxing.huang@ntu.edu.sg
FU Singapore Government through the Industry Alignment Fund -Industry Collaboration Projects Grant
CR [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Behley J, 2019, IEEE I CONF COMP VIS, V0, PP9296, DOI 10.1109/ICCV.2019.00939
   Bendjebbour A, 2001, IEEE T GEOSCI REMOTE, V39, P1789, DOI 10.1109/36.942557
   Berman M, 2018, PROC CVPR IEEE, V0, PP4413, DOI 10.1109/CVPR.2018.00464
   Hua BS, 2018, PROC CVPR IEEE, V0, PP984, DOI 10.1109/CVPR.2018.00109
   Bugeau A, 2019, P IEEE INT C COMP VI, V0, P0
   Cao YP, 2019, ISPRS J PHOTOGRAMM, V150, P70, DOI 10.1016/j.isprsjprs.2019.02.005
   Cao YP, 2019, INFORM FUSION, V46, P206, DOI 10.1016/j.inffus.2018.06.005
   Choy C, 2019, PROC CVPR IEEE, V0, PP3070, DOI 10.1109/CVPR.2019.00319
   Dechesne C, 2017, ISPRS J PHOTOGRAMM, V126, P129, DOI 10.1016/j.isprsjprs.2017.02.011
   Geiger A, 2012, PROC CVPR IEEE, V0, PP3354, DOI 10.1109/CVPR.2012.6248074
   Ghamisi P, 2015, INT J IMAGE DATA FUS, V6, P189, DOI 10.1080/19479832.2015.1055833
   Guan DY, 2021, PATTERN RECOGN, V112, P0, DOI 10.1016/j.patcog.2020.107764
   Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017
   Gunes H, 2005, IEEE SYS MAN CYBERN, V0, P3437
   Guo B, 2015, ISPRS J PHOTOGRAMM, V100, P71, DOI 10.1016/j.isprsjprs.2014.04.015
   Guo L, 2011, ISPRS J PHOTOGRAMM, V66, P56, DOI 10.1016/j.isprsjprs.2010.08.007
   Hackel T, 2016, ISPRS ANN PHOTO REM, V3, P177, DOI 10.5194/isprsannals-III-3-177-2016
   Hu Q., 2020, P IEEECVF C COMPUTER, V0, PP11108, DOI 10.48550/ARXIV.1911.11236
   Huang J, 2016, INT C PATT RECOG, V0, PP2670, DOI 10.1109/ICPR.2016.7900038
   Iandola F.N., 2016, SQUEEZENET ALEXNET L, V0, P0
   Jiaxing Huang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12360), V0, PP705, DOI 10.1007/978-3-030-58555-6_42
   Kumar A., 1900, V4, V0, P0
   Landrieu L, 2018, PROC CVPR IEEE, V0, PP4558, DOI 10.1109/CVPR.2018.00479
   Landrieu L, 2017, ISPRS J PHOTOGRAMM, V132, P102, DOI 10.1016/j.isprsjprs.2017.08.010
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Lehtomaki M, 2016, IEEE T GEOSCI REMOTE, V54, P1226, DOI 10.1109/TGRS.2015.2476502
   Liao WZ, 2015, IEEE GEOSCI REMOTE S, V12, P552, DOI 10.1109/LGRS.2014.2350263
   Liu ZJ, 2019, ADV NEUR IN, V32, P0
   Meng HY, 2019, IEEE I CONF COMP VIS, V0, PP8499, DOI 10.1109/ICCV.2019.00859
   Milioto A, 2019, IEEE INT C INT ROBOT, V0, PP4213, DOI 10.1109/IROS40897.2019.8967762
   Ngiam J, 2011, ICML, V0, P0
   Niemeyer J, 2013, 2013 JOINT URBAN REMOTE SENSING EVENT (JURSE), V0, PP139, DOI 10.1109/JURSE#.2013.6550685
   Qi C.R., 2017, ADV NEUR IN, V0, P5099
   Qi CR, 2017, PROC CVPR IEEE, V0, PP77, DOI 10.1109/CVPR.2017.16
   Qi XJ, 2017, IEEE I CONF COMP VIS, V0, PP5209, DOI 10.1109/ICCV.2017.556
   Rasti B, 2017, IEEE T GEOSCI REMOTE, V55, P6354, DOI 10.1109/TGRS.2017.2726901
   Rasti B, 2017, IEEE T GEOSCI REMOTE, V55, P3997, DOI 10.1109/TGRS.2017.2686450
   Rethage D., 2018, ECCV, V0, P596
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi HY, 2020, PROC CVPR IEEE, V0, PP4573, DOI 10.1109/CVPR42600.2020.00463
   Simonovsky M, 2017, PROC CVPR IEEE, V0, PP29, DOI 10.1109/CVPR.2017.11
   Snoek C. G. M., 2005, 13TH ANNUAL ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP399, DOI 10.1145/1101149.1101236
   Su H, 2018, PROC CVPR IEEE, V0, PP2530, DOI 10.1109/CVPR.2018.00268
   Sun RQ, 2019, PROC CVPR IEEE, V0, PP4355, DOI 10.1109/CVPR.2019.00449
   Sun Y, 2018, ISPRS J PHOTOGRAMM, V143, P3, DOI 10.1016/j.isprsjprs.2018.06.005
   Tatarchenko M, 2018, PROC CVPR IEEE, V0, PP3887, DOI 10.1109/CVPR.2018.00409
   Tchapmi LP, 2017, INT CONF 3D VISION, V0, PP537, DOI 10.1109/3DV.2017.00067
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Weinmann M., 2014, ISPRS ANN PHOTOGRAMM, VII-3, P181, DOI 10.5194/ISPRSANNALS-II-3-181-2014
   Wu BC, 2019, IEEE INT CONF ROBOT, V0, PP4376, DOI 10.1109/ICRA.2019.8793495
   Wu BC, 2018, IEEE INT CONF ROBOT, V0, P1887
   Xiang BB, 2019, IEEE T GEOSCI REMOTE, V57, P7799, DOI 10.1109/TGRS.2019.2916625
   Xu H, 2006, ACM T MULTIM COMPUT, V2, P44, DOI 10.1145/1126004.1126007
   Xu S, 2014, ISPRS J PHOTOGRAMM, V88, P1, DOI 10.1016/j.isprsjprs.2013.11.008
   Yang JC, 2019, PROC CVPR IEEE, V0, PP3318, DOI 10.1109/CVPR.2019.00344
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Zhang JX, 2013, REMOTE SENS-BASEL, V5, P3749, DOI 10.3390/rs5083749
   Zhang Y., 2020, P IEEE C COMP VIS PA, V0, P9601
   Zhang YL, 2018, PROC CVPR IEEE, V0, PP2472, DOI 10.1109/CVPR.2018.00262
   Zhang ZY, 2019, IEEE I CONF COMP VIS, V0, PP1607, DOI 10.1109/ICCV.2019.00169
   Zhao CX, 2019, IEEE IMAGE PROC, V0, PP1475, DOI 10.1109/ICIP.2019.8803048
   Zhao HS, 2019, PROC CVPR IEEE, V0, PP5550, DOI 10.1109/CVPR.2019.00571
   Zhou Y, 2012, INT J ADV ROBOT SYST, V9, P0, DOI 10.5772/54715
NR 77
TC 12
Z9 12
U1 12
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUN 15
PY 2021
VL 176
IS 
BP 237
EP 249
DI 10.1016/j.isprsjprs.2021.04.011
EA MAY 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SJ4AV
UT WOS:000655474600018
DA 2023-04-26
ER

PT J
AU Owen-Smith, TM
   Trumbull, RB
   Bauer, K
   Keiding, JK
   Will, TM
AF Owen-Smith, T. M.
   Trumbull, R. B.
   Bauer, K.
   Keiding, J. K.
   Will, T. M.
TI A neural network application to assess magma diversity in the Etendeka igneous province, Namibia
SO SOUTH AFRICAN JOURNAL OF GEOLOGY
LA English
DT Article
ID plume-lithosphere interactions; continental flood volcanism; tristan mantle plume; self-organizing maps; south-atlantic; dyke swarm; 40ar/39ar geochronology; chemical classification; crustal contamination; geochemical patterns
AB The geochemical discrimination of different magma types in Large Igneous Provinces is conventionally based on a few, pre-selected variables that are regarded to have petrological meaning. An alternative approach explored in this study is to apply the neural network technique of self-organising maps (SOM) to identify inherent groupings in data without knowledge or assumptions (unsupervised learning). The dataset used in this study comprises whole-rock analyses from extrusive (lava) and intrusive (dykes, sills) mafic suites in the Etendeka province, Namibia, taken from published sources and augmented by 103 new chemical analyses of dykes. Six SOM-classified groups are identified, which are unevenly distributed among the extrusive and the intrusive rock suites. The lava samples are dominated by just three of the six SOM groups (95% of all samples) and one group is absent entirely, whereas all six groups are present in the intrusive suite and five of them each comprise more than 5% of the samples. The geographic distribution of SOM-grouped dykes is heterogeneous and groups that are under-represented in the lava suite occur preferentially in a region of the pre-Etendeka basement where few lavas are preserved. Thus, the difference in magma diversity between intrusive and extrusive suites may be partly an artefact of erosion, which implies that a proper assessment of magma diversity in this and other LIPs must include the intrusive components. The correspondence of our SOM groupings with magma types in the Etendeka province that were established from petrologically defined variables is reasonably good for most trace-element abundances and ratios. However, some of the SOM groups have a wide range of initial Sr-Nd isotope ratios and a poor correspondence with the established magma types. We conclude that the SOM approach is useful for sorting out large and complex geochemical datasets but the method gives all input variables equal weight, which may be problematic if they have different responses to processes in the system under study (e.g., partial melting, fractional crystallisation, degassing, alteration). It is no substitute for expert petrological knowledge in discriminating genetically distinct magma types in an application like the present one. The geochemical discrimination of different magma types in Large Igneous Provinces is conventionally based on a few, pre-selected variables that are regarded to have petrological meaning. An alternative approach explored in this study is to apply the neural network technique of self-organising maps (SOM) to identify inherent groupings in data without knowledge or assumptions (unsupervised learning). The dataset used in this study comprises whole-rock analyses from extrusive (lava) and intrusive (dykes, sills) mafic suites in the Etendeka province, Namibia, taken from published sources and augmented by 103 new chemical analyses of dykes. Six SOM-classified groups are identified, which are unevenly distributed among the extrusive and the intrusive rock suites. The lava samples are dominated by just three of the six SOM groups (95% of all samples) and one group is absent entirely, whereas all six groups are present in the intrusive suite and five of them each comprise more than 5% of the samples. The geographic distribution of SOM-grouped dykes is heterogeneous and groups that are under-represented in the lava suite occur preferentially in a region of the pre-Etendeka basement where few lavas are preserved. Thus, the difference in magma diversity between intrusive and extrusive suites may be partly an artefact of erosion, which implies that a proper assessment of magma diversity in this and other LIPs must include the intrusive components. The correspondence of our SOM groupings with magma types in the Etendeka province that were established from petrologically defined variables is reasonably good for most trace-element abundances and ratios. However, some of the SOM groups have a wide range of initial Sr-Nd isotope ratios and a poor correspondence with the established magma types. We conclude that the SOM approach is useful for sorting out large and complex geochemical datasets but the method gives all input variables equal weight, which may be problematic if they have different responses to processes in the system under study (e.g., partial melting, fractional crystallisation, degassing, alteration). It is no substitute for expert petrological knowledge in discriminating genetically distinct magma types in an application like the present one.
C1 [Owen-Smith, T. M.; Trumbull, R. B.; Bauer, K.] GFZ German Res Ctr Geosci, Potsdam, Germany.
   [Owen-Smith, T. M.] Univ Johannesburg, Dept Geol, Johannesburg, South Africa.
   [Keiding, J. K.] Geol Survey Denmark & Greenland GEUS, Copenhagen, Denmark.
   [Will, T. M.] Univ Wurzburg, Inst Geog & Geol, Wurzburg, Germany.
C3 Helmholtz Association; Helmholtz-Center Potsdam GFZ German Research Center for Geosciences; University of Johannesburg; Geological Survey Of Denmark & Greenland; University of Wurzburg
RP Owen-Smith, TM (corresponding author), GFZ German Res Ctr Geosci, Potsdam, Germany.; Owen-Smith, TM (corresponding author), Univ Johannesburg, Dept Geol, Johannesburg, South Africa.
EM trishyaos@uj.ac.za; bobby@gfz-potsdam.de; klaus@gfz-potsdam.de; jkk@geus.dk; thomas.will@uni-wuerzburg.de
FU Deutsche Forschungsgemeinschaft (DFG) [SPP 1375]
CR Ashwal LD, 2021, GEOCHEM GEOPHY GEOSY, V22, P0, DOI 10.1029/2020GC009561
   Bauer K, 2012, GEOPHYS J INT, V189, P984, DOI 10.1111/j.1365-246X.2012.05402.x
   Bauer K, 2008, GEOPHYS RES LETT, V35, P0, DOI 10.1029/2008GL035263
   Bauer K, 2020, GEOPHYS PROSPECT, V68, P466, DOI 10.1111/1365-2478.12853
   Beccaluva L, 2020, LITHOS, V362, P0, DOI 10.1016/j.lithos.2020.105484
   Becker K, 2014, SOLID EARTH, V5, P1011, DOI 10.5194/se-5-1011-2014
   Belissont R, 2014, GEOCHIM COSMOCHIM AC, V126, P518, DOI 10.1016/j.gca.2013.10.052
   Brehme M, 2017, J VOLCANOL GEOTH RES, V336, P19, DOI 10.1016/j.jvolgeores.2017.01.013
   Canon-Tapia E, 2018, J VOLCANOL GEOTH RES, V355, P287, DOI 10.1016/j.jvolgeores.2017.11.011
   CLIFF RA, 1991, CHEM GEOL, V92, P251, DOI 10.1016/0009-2541(91)90073-Z
   Codeco MS, 2021, MINER DEPOSITA, V56, P481, DOI 10.1007/s00126-020-00984-8
   COHEN RS, 1982, EARTH PLANET SC LETT, V61, P73, DOI 10.1016/0012-821X(82)90040-1
   Cracknell MJ, 2017, GEOCHEM-EXPLOR ENV A, V17, P204, DOI 10.1144/geochem2016-012
   Dalla Libera N, 2020, WATER RESOUR RES, V56, P0, DOI 10.1029/2019WR026234
   Dodd SC, 2015, EARTH PLANET SC LETT, V414, P16, DOI 10.1016/j.epsl.2015.01.009
   Duncan A. R., 1989, COMMUN GEOL SURV NAM, V5, P5
   Erlank A., 1984, SPEC PUBL GEOL SOC S, V13, P195
   Ewart A, 2004, J PETROL, V45, P59, DOI 10.1093/petrology/egg083
   Ewart A, 1998, J PETROL, V39, P191, DOI 10.1093/petrology/39.2.191
   Ewart A, 2004, J PETROL, V45, P107, DOI 10.1093/petrology/egg082
   Ewart A, 1998, J PETROL, V39, P227, DOI 10.1093/petrology/39.2.227
   Gibson SA, 2006, EARTH PLANET SC LETT, V251, P1, DOI 10.1016/j.epsl.2006.08.004
   Gibson SA, 2005, EARTH PLANET SC LETT, V237, P744, DOI 10.1016/j.epsl.2005.06.015
   Gibson SA, 1995, EARTH PLANET SC LETT, V136, P149, DOI 10.1016/0012-821X(95)00179-G
   Glen JMG, 1997, GEOLOGY, V25, P1131, DOI 10.1130/0091-7613(1997)025<1131:MFIFAO>2.3.CO;2
   IRVINE TN, 1971, CAN J EARTH SCI, V8, P523, DOI 10.1139/e71-055
   Jerram D, 1999, J GEODYN, V28, P393, DOI 10.1016/S0264-3707(99)00018-6
   Keiding JK, 2013, LITHOS, V179, P16, DOI 10.1016/j.lithos.2013.07.018
   Kirstein LA, 2001, J GEOL SOC LONDON, V158, P583, DOI 10.1144/jgs.158.4.583
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kohonen T., 2001, SELF ORG MAPS, V0, P245
   Lacassie JP, 2006, J GEOCHEM EXPLOR, V91, P81, DOI 10.1016/j.gexplo.2006.03.004
   Lacassie JP, 2004, SEDIMENT GEOL, V165, P175, DOI 10.1016/j.sedgeo.2003.12.001
   LEBAS MJ, 1986, J PETROL, V27, P745, DOI 10.1093/petrology/27.3.745
   Lehmann J, 2016, TECTONICS, V35, P103, DOI 10.1002/2015TC003899
   Lehtonen M., 1995, WALVIS BAY GEOLOGICA, V0, P0
   LEROEX AP, 1990, J PETROL, V31, P779, DOI 10.1093/petrology/31.4.779
   Lohr SC, 2010, GEODERMA, V156, P253, DOI 10.1016/j.geoderma.2010.02.025
   Lord J, 1996, INT J REMOTE SENS, V17, P2945, DOI 10.1080/01431169608949120
   Marques LS, 1999, J GEODYN, V28, P439, DOI 10.1016/S0264-3707(99)00020-4
   Marsh JS, 2007, J AFR EARTH SCI, V48, P329, DOI 10.1016/j.jafrearsci.2007.04.004
   Marsh JS, 2018, J VOLCANOL GEOTH RES, V355, P21, DOI 10.1016/j.jvolgeores.2016.10.011
   Marsh JS, 2001, B VOLCANOL, V62, P464, DOI 10.1007/s004450000115
   Marzoli A, 1999, J GEODYN, V28, P341, DOI 10.1016/S0264-3707(99)00014-9
   Matthews KA, 2006, GEOCHEM GEOPHY GEOSY, V7, P0, DOI 10.1029/2006GC001352
   MCDERMOTT F, 1990, CHEM GEOL, V83, P263, DOI 10.1016/0009-2541(90)90284-E
   McMaster M, 2019, J AFR EARTH SCI, V150, P319, DOI 10.1016/j.jafrearsci.2018.11.010
   Miller R.M., 1988, GEOLOGICAL MAP DAMAR, V0, P0
   Miller R.M., 2008, GEOLOGY NAMIBIA, V3, P17
   Miller R.M., 2008, GEOLOGY NAMIBIA, V18-1, P18
   Milner S.C., 1997, MINISTRY MINES ENERG, V0, P0
   Milner SC, 1995, J VOLCANOL GEOTH RES, V69, P137, DOI 10.1016/0377-0273(95)00040-2
   Murphy DT, 2002, J PETROL, V43, P981, DOI 10.1093/petrology/43.6.981
   Natali C, 2018, LITHOS, V296, P54, DOI 10.1016/j.lithos.2017.11.001
   NEWSOM HE, 1986, EARTH PLANET SC LETT, V80, P299, DOI 10.1016/0012-821X(86)90112-3
   Owen-Smith TM, 2017, J PETROL, V58, P423, DOI 10.1093/petrology/egx021
   Passchier C, 2016, GEOLOGY, V44, P843, DOI 10.1130/G38015.1
   Pearce JA, 2008, LITHOS, V100, P14, DOI 10.1016/j.lithos.2007.06.016
   Peate D. W., 1997, GEOPH MONOG SERIES, V100, P217
   PEATE DW, 1992, B VOLCANOL, V55, P119, DOI 10.1007/BF00301125
   PEATE DW, 1990, GEOLOGY, V18, P1223, DOI 10.1130/0091-7613(1990)018<1223:MPAFBS>2.3.CO;2
   Penn BS, 2005, COMPUT GEOSCI-UK, V31, P531, DOI 10.1016/j.cageo.2004.10.009
   PETRINI R, 1987, J PETROL, V28, P701, DOI 10.1093/petrology/28.4.701
   Piccirillo E.M., 1988, CONTINENTAL FLOOD BA, V0, P195
   PICCIRILLO EM, 1989, CHEM GEOL, V75, P103, DOI 10.1016/0009-2541(89)90023-5
   Pirajno F., 2000, COMMUN GEOL SURV NAM, V12, P301
   Plank T, 1998, CHEM GEOL, V145, P325, DOI 10.1016/S0009-2541(97)00150-2
   Raab MJ, 2005, TECTONICS, V24, P0, DOI 10.1029/2004TC001688,
   Renne PR, 1996, GEOLOGY, V24, P659, DOI 10.1130/0091-7613(1996)024<0659:AOEFVA>2.3.CO;2
   Schmitt AK, 2000, J PETROL, V41, P1207, DOI 10.1093/petrology/41.8.1207
   Stewart K, 1996, EARTH PLANET SC LETT, V143, P95, DOI 10.1016/0012-821X(96)00132-X
   Stroncik NA, 2017, GEOLOGY, V45, P827, DOI 10.1130/G39151.1
   Sun S.S., 1989, GEOLOGICAL SOC, V42, P313, DOI 10.1144/GSL.SP.1989.042.01.19
   TAYLOR SR, 1995, REV GEOPHYS, V33, P241, DOI 10.1029/95RG00262
   Teklay M, 2020, LITHOS, V354, P0, DOI 10.1016/j.lithos.2019.105283
   Thompson RN, 2007, J PETROL, V48, P1119, DOI 10.1093/petrology/egm012
   Thompson RN, 2000, NATURE, V407, P502, DOI 10.1038/35035058
   Thompson RN, 2001, J PETROL, V42, P2049, DOI 10.1093/petrology/42.11.2049
   Trumbull RB, 2004, J AFR EARTH SCI, V40, P17, DOI 10.1016/j.jafrearsci.2004.07.006
   Trumbull RB, 2004, LITHOS, V73, P21, DOI 10.1016/j.lithos.2003.10.006
   Trumbull RB, 2007, S AFR J GEOL, V110, P477, DOI 10.2113/gssajg.110.2-3.477
   Ueki K, 2017, LITHOS, V290, P60, DOI 10.1016/j.lithos.2017.08.001
   Wigand M, 2004, J VOLCANOL GEOTH RES, V130, P285, DOI 10.1016/S0377-0273(03)00310-X
   Will TM, 2016, CHEM GEOL, V444, P141, DOI 10.1016/j.chemgeo.2016.08.040
   Will TM, 2013, J GEOL, V121, P455, DOI 10.1086/671398
   WINCHESTER JA, 1977, CHEM GEOL, V20, P325, DOI 10.1016/0009-2541(77)90057-2
   Workman RK, 2005, EARTH PLANET SC LETT, V231, P53, DOI 10.1016/j.epsl.2004.12.005
   Zhou H, 2020, EARTH PLANET SC LETT, V535, P0, DOI 10.1016/j.epsl.2020.116123
NR 88
TC 2
Z9 2
U1 0
U2 1
PU GEOLOGICAL SOC SOUTH AFRICA
PI MARSHALLTOWN
PA PO BOX 61809, MARSHALLTOWN 2107, SOUTH AFRICA
SN 1012-0750
EI 1996-8590
J9 S AFR J GEOL
JI S. Afr. J. Geol.
PD JUN 15
PY 2021
VL 124
IS 2
BP 481
EP 498
DI 10.25131/sajg.124.0034
PG 18
WC Geology
SC Geology
GA TY1LE
UT WOS:000683544500011
DA 2023-04-26
ER

PT J
AU Carter-McAuslan, A
   Farquharson, C
AF Carter-McAuslan, Angela
   Farquharson, Colin
TI Predictive geologic mapping from geophysical data using self-organizing maps: A case study from Baie Verte, Newfoundland, Canada
SO GEOPHYSICS
LA English
DT Article
AB Self-organizing maps (SOMs) are a type of unsupervised ar-tificial neural networks clustering tool. SOMs are used to cluster large multivariate data sets. They can identify patterns and trends in the geophysical maps of an area and generate proxy geology maps, known as remote predictive mapping. We have applied SOMs to magnetic, radiometric, and gravity data sets compiled from multiple modern and legacy data sources over the Baie Verte Peninsula, Newfoundland, Canada. The regional and local geologic maps available for this area and knowledge from numerous geologic studies has enabled the accuracy of SOM-based predictive mapping to be assessed. Proxy geology maps generated by primary clustering directly from the SOMs and secondary clustering using a k-means approach reproduced many geologic units identified by previous traditional geologic mapping. Of the combinations of data sets tested, the combina-tion of magnetic data, primary radiometric data and their ratios, and Bouguer gravity data gave the best results. We found that using reduced-to-the-pole residual intensity or using the analytic signal as the magnetic data were equally useful. The SOM process was unaffected by gaps in the coverage of some of the data sets. The SOM results could be used as input into k-means clus-tering because this method requires no gaps in the data. The subsequent k-means clustering resulted in more meaningful proxy geology maps than were created by the SOM alone. In regions where the geology is poorly known, these proxy maps can be useful in targeting where traditional, on-the-ground geo-logic mapping would be most beneficial, which can be especially useful in parts of the world where access is difficult and expensive.
C1 [Carter-McAuslan, Angela; Farquharson, Colin] Mem Univ Newfoundland, Dept Earth Sci, St John, NF A1B 3X5, Canada.
C3 Memorial University Newfoundland
RP Farquharson, C (corresponding author), Mem Univ Newfoundland, Dept Earth Sci, St John, NF A1B 3X5, Canada.
EM acartermcauslan@mun.ca; cgfarquh@mun.ca
FU NALCOR
CR Abedi M, 2013, ARAB J GEOSCI, V6, P3601, DOI 10.1007/s12517-012-0615-5
   Barlow M., 2019, PREVIEW, V2019, P11, DOI 10.1080/14432471.2019.1647607
   Bauer K, 2012, GEOPHYS J INT, V189, P984, DOI 10.1111/j.1365-246X.2012.05402.x
   Bedini E, 2012, INT J REMOTE SENS, V33, P939, DOI 10.1080/01431161.2010.542202
   Boyd D., 2007, P EXPLORATION 07 5 D, V0, P491
   Breard G., 2017, THESIS U RHODE ISLAN, V0, P0
   Carneiro CD, 2012, GEOPHYSICS, V77, PK17, DOI 10.1190/geo2011-0302.1
   Cereghino R, 2009, ENVIRON MODELL SOFTW, V24, P945, DOI 10.1016/j.envsoft.2009.01.008
   Chon TS, 1996, ECOL MODEL, V90, P69, DOI 10.1016/0304-3800(95)00148-4
   Coyle M., 1990, THESIS MEMORIAL U NE, V0, P0
   Coyle M., 2007, GOPHYSICAL SERIES 1, V0, P0
   Cracknell M. J., 2014, UNSUPERVISED CLUSTER, V0, P0
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   El Hourany R, 2019, J GEOPHYS RES-OCEANS, V124, P1357, DOI 10.1029/2018JC014450
   Franceschini S, 2019, MAR POLLUT BULL, V149, P0, DOI 10.1016/j.marpolbul.2019.110580
   Fraser S.J., 2007, P EXPLORATION 07 5 D, V0, P907
   Geological Survey of Newfoundland and Labrador, 1990, N00154 GEOL SURV NEW, V0, P0
   Geological Survey of Newfoundland and Labrador, 2007, DN09902 GEOL SURV NE, V0, P0
   Harris JR, 2015, COMPUT GEOSCI-UK, V80, P9, DOI 10.1016/j.cageo.2015.03.013
   Harris J. R., 2008, 5643 GEOL SURV CAN, V0, P0
   Harris J. R., 2012, EARTH SCI, V0, P495
   Hayes J. P., 2004, GEN INTERPRETIVE MAP, V0, P0
   Kean B. F., 1995, 952 DEP NATL R ES GE, V0, P0
   Kirby F., 2011, VANDERVER 2011 SURF, V0, P0
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kuhn S, 2019, ORE GEOL REV, V112, P0, DOI 10.1016/j.oregeorev.2019.103015
   MacQueen J.B., 1967, PROC 5 BERKELEY S MA, V0, P281
   Metsaranta R. T., 2011, 6270 ONT GEOL SURV, V0, P0
   Mosusu N., 2016, ASEG PESA AIG 2016 2, V0, P0
   Mount NJ, 2011, PATTERN ANAL APPL, V14, P139, DOI 10.1007/s10044-011-0210-5
   Natural Resources Canada, 2018, GRAV AN POINT DAT CA, V0, P0
   Ouedraogo A., 2016, 86 ANN INT M SEG EXP, V0, PP2223, DOI 10.1190/segam2016-13779128.1
   Skulski T., 2009, NEWFOUNDLAND LABRADO, V0, P0
   Skupin A., 2008, SELF ORG MAPS APPL G, V0, PP1, DOI 10.1002/9780470021699.CH1
   Slavinski H, 2010, CAN J REMOTE SENS, V36, P99, DOI 10.5589/m10-031
   Steel M., 2011, THESIS CURTIN U, V0, P0
   VERHOEF J, 1989, PHYS EARTH PLANET IN, V54, P332, DOI 10.1016/0031-9201(89)90250-1
   Zamani A., 2009, JOURNAL OF APPLIED SCIENCES, V9, P4099, DOI 10.3923/jas.2009.4099.4114
NR 39
TC 1
Z9 1
U1 0
U2 4
PU SOC EXPLORATION GEOPHYSICISTS - SEG
PI TULSA
PA 8801 S YALE ST, TULSA, OK 74137 USA
SN 0016-8033
EI 1942-2156
J9 GEOPHYSICS
JI Geophysics
PD JUL-AUG 15
PY 2021
VL 86
IS 4
BP B249
EP B264
DI 10.1190/GEO-2020-0756.1
PG 16
WC Geochemistry & Geophysics
SC Geochemistry & Geophysics
GA UA1XL
UT WOS:000684958600003
DA 2023-04-26
ER

PT J
AU Xu, LL
   Liu, YJ
   Yang, P
   Chen, H
   Zhang, HY
   Wang, D
   Zhang, X
AF Xu, Leilei
   Liu, Yujun
   Yang, Peng
   Chen, Hao
   Zhang, Hanyue
   Wang, Dan
   Zhang, Xin
TI HA U-Net: Improved Model for Building Extraction From High Resolution Remote Sensing Imagery
SO IEEE ACCESS
LA English
DT Article
DE Buildings; Feature extraction; Image segmentation; Remote sensing; Predictive models; Training; Task analysis; Deep learning; building extraction; holistically-nested neural network; attention mechanism; weight mapping; watershed algorithm
ID segmentation; framework; network
AB Automatic extraction of buildings from high-resolution remote sensing images becomes an important research. Since the convolutional neural network can perform pixel-level segmentation, this technology has been applied in this field. But the increase in resolution prone to blurry segmentation because the model needs more edge detail and multi-scale detail learning. To solve this problem, a method is proposed in this paper, which consists of three parts: (1) an improved model named Holistically-Nested Attention U-Net (HA U-Net) is designed, which integrates the attention mechanism and multi-scale nested modules to supervise prediction; (2) During model training, an improved weighted loss function is proposed to make the designed model more focused on learning boundary features; (3) watershed algorithm is exploited for image post-processing to optimize segmentation results. The designed HA U-Net performs well on WHU Building Dataset and Urban3d Challenge dataset, and achieves 9.31%, 2.17% better F1-score and 10.78%, 1.77% better IOU than the standard U-Net respectively. The experimental results indicate that the proposed method can well solve the building adhesion problem. The research can serve as updating geographic databases.
C1 [Xu, Leilei] Hohai Univ, Sch Earth Sci & Engn, Nanjing 211100, Peoples R China.
   [Liu, Yujun] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, Beijing 100101, Peoples R China.
   [Liu, Yujun; Wang, Dan] Prov Geomat Ctr Jiangsu, Nanjing 210013, Peoples R China.
   [Yang, Peng] Chinese Acad Sci, Aerosp Informat Res Inst, Qilu Res Inst, Jinan 250100, Peoples R China.
   [Yang, Peng] Suzhou Zhe Xin Informat Technol Co Ltd, Suzhou 215000, Peoples R China.
   [Chen, Hao] Tech Univ Berlin, Inst Geodesy & Geoinformat Sci, D-10553 Berlin, Germany.
   [Zhang, Hanyue] Beijing Forestry Univ, Precis Forestry Key Lab Beijing, Beijing 100083, Peoples R China.
   [Zhang, Xin] Tongji Univ, Coll Surveying & Geoinformat, Shanghai 200092, Peoples R China.
C3 Hohai University; Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS; Chinese Academy of Sciences; Technical University of Berlin; Beijing Forestry University; Tongji University
RP Liu, YJ (corresponding author), Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, Beijing 100101, Peoples R China.; Liu, YJ (corresponding author), Prov Geomat Ctr Jiangsu, Nanjing 210013, Peoples R China.; Chen, H (corresponding author), Tech Univ Berlin, Inst Geodesy & Geoinformat Sci, D-10553 Berlin, Germany.
EM liuyj.20b@igsnrr.ac.cn; 1145871257@qq.com
CR Aamir M, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11010003
   Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   [Anonymous], 2015, ICLR, V0, P0
   [Anonymous], 2018, PREPRINT, V0, P0
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bieniek A, 2000, PATTERN RECOGN, V33, P907, DOI 10.1016/S0031-3203(99)00154-5
   Chen K, 2019, PROC CVPR IEEE, V0, PP4969, DOI 10.1109/CVPR.2019.00511
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Q, 2019, ISPRS J PHOTOGRAMM, V147, P42, DOI 10.1016/j.isprsjprs.2018.11.011
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Goldberg H., 2017, P IEEE APPL IM PATT, V0, P1
   Guerrero-Pena FA, 2018, IEEE IMAGE PROC, V0, PP2451, DOI 10.1109/ICIP.2018.8451187
   Hamaguchi R, 2018, IEEE WINT CONF APPL, V0, PP1442, DOI 10.1109/WACV.2018.00162
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2017, IEEE J-STARS, V10, P654, DOI 10.1109/JSTARS.2016.2587324
   Huang ZM, 2016, INT GEOSCI REMOTE SE, V0, PP1835, DOI 10.1109/IGARSS.2016.7729471
   Ji SP, 2019, INT J REMOTE SENS, V40, P3308, DOI 10.1080/01431161.2018.1528024
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Khoshboresh-Masouleh M, 2020, J APPL REMOTE SENS, V14, P0, DOI 10.1117/1.JRS.14.034503
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Li L, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091350
   Lin JB, 2019, IEEE ACCESS, V7, P54285, DOI 10.1109/ACCESS.2019.2912822
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Masouleh MK, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.046018
   [孟庆祥 Meng Qingxiang], 2019, 华中师范大学学报. 自然科学版 JOURNAL OF CENTRAL CHINA NORMAL UNIVERSITY. NATURAL SCIENCES EDITION, V53, P568
   Mnih V., 2013, CITESEER, V0, P0
   Pan XR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050743
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schuegraf P, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8040191
   Sun GY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030227
   Sun K, 2019, PROC CVPR IEEE, V0, PP5686, DOI 10.1109/CVPR.2019.00584
   Xu Y, 2017, IEEE T BIO-MED ENG, V64, P2901, DOI 10.1109/TBME.2017.2686418
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010144
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yang H, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111768
   Ying ZG, 2017, MED PHYS, V44, P5234, DOI 10.1002/mp.12481
   Yu LT, 2020, J DIGIT IMAGING, V33, P341, DOI 10.1007/s10278-019-00277-1
   [余烨 Yu Ye], 2016, 中国图象图形学报 JOURNAL OF IMAGE AND GRAPHICS, V21, P145
   Yuan JY, 2018, IEEE T PATTERN ANAL, V40, P2793, DOI 10.1109/TPAMI.2017.2750680
   Zhang ZX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060696
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhou LC, 2018, IEEE COMPUT SOC CONF, V0, PP192, DOI 10.1109/CVPRW.2018.00034
NR 47
TC 11
Z9 11
U1 4
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2021
VL 9
IS 
BP 101972
EP 101984
DI 10.1109/ACCESS.2021.3097630
PG 13
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA TQ5ER
UT WOS:000678303900001
DA 2023-04-26
ER

PT J
AU Mazzuto, G
   Antomarioni, S
   Ciarapica, FE
   Bevilacqua, M
AF Mazzuto, G.
   Antomarioni, S.
   Ciarapica, F. E.
   Bevilacqua, M.
TI Health Indicator for Predictive Maintenance Based on Fuzzy Cognitive Maps, Grey Wolf, and K-Nearest Neighbors Algorithms
SO MATHEMATICAL PROBLEMS IN ENGINEERING
LA English
DT Article
ID remaining useful life; support-system; big data; optimization; machine; risk; identification; uncertainty; reliability; diagnostics
AB An essential step in the implementation of predictive maintenance involves the health state analysis of productive equipment in order to provide company managers with performance and degradation indicators which help to predict component condition. In this paper, a supervised approach for health indicator calculation is provided combining the Grey Wolf Optimisation method, Swarm Intelligence algorithm, and Fuzzy Cognitive Maps. The k-neighbors algorithms is used to predict the Remaining Useful Life of an item, since, in addition to its simplicity, they produce good results in a large number of domains. The approach aims to solve the problem that frequently occurs in interpolation procedures: the approximation of functions belonging to a chosen class of functions of which we have no knowledge. The proposed algorithm allows maintenance managers to distinguish different degradation profiles in depth with a consequently more precise estimate of the Remaining Useful Life of an item and, in addition, an in-depth understanding of the degradation process. Specifically, in order to show its suitability for predictive maintenance, a dataset on NASA aircraft engines has been used and results have been compared to those obtained with a neural network approach. Results highlight how all of the degradation profiles, obtained using the proposed approach, are modelled in a more detailed manner, allowing one to significantly distinguish different situations. Moreover, the physical core speed and the corrected fan speed have been identified as the main critical factors to the engine degradation.
C1 [Mazzuto, G.; Antomarioni, S.; Ciarapica, F. E.; Bevilacqua, M.] Univ Politecn Marche, Dipartimento Ingn Ind & Sci Matemat, Via Brecce Bianche, I-60131 Ancona, Italy.
C3 Marche Polytechnic University
RP Mazzuto, G (corresponding author), Univ Politecn Marche, Dipartimento Ingn Ind & Sci Matemat, Via Brecce Bianche, I-60131 Ancona, Italy.
EM g.mazzuto@univpm.it; s.antomarioni@univpm.it; f.e.ciarapica@univpm.it; m.bevilacqua@univpm.it
FU INAIL (Istituto Nazionale per l'Assicurazione Contro gli Infortuni sul Lavoro); Italian National Institute for Insurance against Accidents at Work, under the BRIC 2018 project titled "Sviluppo di soluzioni smart attraverso metodologie Digital Twin per aumentare la sicurezza degli operatori durante i processi di manutenzione degli impi [BRIC ID12]
CR Abdelghafar S, 2019, ADV INTELL SYST COMP, V845, P664, DOI 10.1007/978-3-319-99010-1_61
   Abichou B., 2012, IFAC P VOLUMES, V45, P193, DOI 10.3182/20121122-2-es-4026.00019
   Aguilar J., 2005, INT J COMPUT COGN, V3, P27
   Ali MM, 2013, COMPUT OPTIM APPL, V54, P707, DOI 10.1007/s10589-012-9498-3
   Amihai I, 2018, IEEE INTL CONF IND I, V0, P212
   Arunraj NS, 2013, ACCIDENT ANAL PREV, V55, P242, DOI 10.1016/j.aap.2013.03.007
   Azadeh A, 2017, INT J ADV MANUF TECH, V90, P499, DOI 10.1007/s00170-016-9208-x
   Azevedo D, 2020, PHM SOC EUR C, V5, P10, DOI 10.36001/PHME.2020.V5I1.1226
   Baraldi P, 2018, MECH SYST SIGNAL PR, V102, P382, DOI 10.1016/j.ymssp.2017.09.013
   Bevilacqua M, 2018, SAFETY SCI, V102, P194, DOI 10.1016/j.ssci.2017.10.022
   Bevilacqua M, 2016, QUAL RELIAB ENG INT, V32, P373, DOI 10.1002/qre.1756
   Bevilacqua M, 2012, J LOSS PREVENT PROC, V25, P677, DOI 10.1016/j.jlp.2012.02.004
   Bueno S, 2009, EXPERT SYST APPL, V36, P5221, DOI 10.1016/j.eswa.2008.06.072
   Calabrese F, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10124120
   Carvalho JP, 2013, FUZZY SET SYST, V214, P6, DOI 10.1016/j.fss.2011.12.009
   Ciarapica F, 2019, PROCESS SAF ENVIRON, V128, P50, DOI 10.1016/j.psep.2019.05.037
   Dalla Vedova M.D., 2019, P 29 EUROPEAN SAFETY, V0, P0, DOI DOI 10.3850/978-981-11-2724-3_0476-cd
   Das Kaushik Ranjan, 2015, 2015 INTERNATIONAL CONFERENCE ON SOFT COMPUTING TECHNIQUES AND IMPLEMENTATIONS (ICSCTI), V0, PP108, DOI 10.1109/ICSCTI.2015.7489575
   Deng R., 2019, SURVEY PREDICTIVE MA, V0, P0
   DUDANI SA, 1976, IEEE T SYST MAN CYB, V6, P327
   Fang JM, 2006, FUZZY SET SYST, V157, P739, DOI 10.1016/j.fss.2005.10.013
   Georgopoulos V.C., 1900, P1, V0, P0, DOI DOI 10.1109/FUZZ-IEEE.2018.8491657
   Gerber T, 2015, IEEE T IND ELECTRON, V62, P6616, DOI 10.1109/TIE.2015.2458781
   Gonzalez A, 1999, INT J APPROX REASON, V21, P233, DOI 10.1016/S0888-613X(99)00024-9
   Guha D, 2016, ENG SCI TECHNOL, V19, P1693, DOI 10.1016/j.jestch.2016.07.004
   Guo L, 2018, NEUROCOMPUTING, V292, P142, DOI 10.1016/j.neucom.2018.02.083
   Guo L, 2017, NEUROCOMPUTING, V240, P98, DOI 10.1016/j.neucom.2017.02.045
   Gupta P, 2014, INT J SYST ASSUR ENG, V5, P21, DOI 10.1007/s13198-013-0214-1
   Hawkins P., 1900, DOI 10.1109/ASMC.2013.6552784, V0, P0
   Hu WF, 2019, APPL SOFT COMPUT, V82, P0, DOI 10.1016/j.asoc.2019.105556
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   James AT, 2017, INT J SYST ASSUR ENG, V8, P719, DOI 10.1007/s13198-017-0589-5
   Jamshidi A, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND SYSTEMS MANAGEMENT (IESM), V0, PP209, DOI 10.1109/IESM.2015.7380159
   Jing L., 2020, 2020 ASIA ENERGY ELE, V0, P0, DOI DOI 10.1109/AEEES48850.2020.9121416
   Komaki GM, 2015, J COMPUT SCI-NETH, V8, P109, DOI 10.1016/j.jocs.2015.03.011
   Kordon AK, 2010, APPLYING COMPUTATIONAL INTELLIGENCE, V0, PP1, DOI 10.1007/978-3-540-69913-2
   Kougias IP, 2013, WATER RESOUR MANAG, V27, P1249, DOI 10.1007/s11269-012-0236-5
   Kumar A, 2019, INT J SYST ASSUR ENG, V10, P276, DOI 10.1007/s13198-019-00781-1
   Kumar VNA, 2015, QUAL RELIAB ENG INT, V31, P169, DOI 10.1002/qre.1569
   Lakshminarayanan S, 2018, SWARM EVOL COMPUT, V42, P89, DOI 10.1016/j.swevo.2018.02.016
   Laloix T, 2019, CIRP ANN-MANUF TECHN, V68, P483, DOI 10.1016/j.cirp.2019.03.020
   Lee S, 2015, QUAL RELIAB ENG INT, V31, P811, DOI 10.1002/qre.1639
   Lei YG, 2016, IEEE T INSTRUM MEAS, V65, P2671, DOI 10.1109/TIM.2016.2601004
   Lei YG, 2016, IEEE T RELIAB, V65, P1314, DOI 10.1109/TR.2016.2570568
   Lera G, 2002, IEEE T NEURAL NETWOR, V13, P1200, DOI 10.1109/TNN.2002.1031951
   Li ZX, 2018, STRUCT HEALTH MONIT, V17, P1503, DOI 10.1177/1475921717746735
   Lockett A.J., 2020, GEN PURPOSE OPTIMIZA, V0, P0
   Long W, 2017, NEURAL COMPUT APPL, V28, PS421, DOI 10.1007/s00521-016-2357-x
   Lopez C, 2014, INFORM SCIENCES, V256, P25, DOI 10.1016/j.ins.2012.05.026
   Luo M, 2013, IEEE IND ELEC, V0, PP3662, DOI 10.1109/IECON.2013.6699718
   Mahian O, 2020, ENERG CONVERS MANAGE, V211, P0, DOI 10.1016/j.enconman.2020.112751
   de Salazar EM, 2019, J BUILD PERFORM SIMU, V12, P420, DOI 10.1080/19401493.2018.1543351
   Mazza GCC., 2018, 2018 IEEE INT C FUZZ, V0, PP1, DOI 10.1007/s11136-018-1946-9
   Mazzuto G, 2019, IEEE SYS MAN CYBERN, V0, PP2602, DOI 10.1109/SMC.2019.8914456
   Mazzuto G, 2018, IFAC PAPERSONLINE, V51, P1636, DOI 10.1016/j.ifacol.2018.08.222
   Miller A.J., 1976, STRUCTURE DECISION C, V0, PPXVI, DOI 10.1017/s0008423900042797
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mousavipour S., 2019, INT J IND ENG PROD R, V0, P0
   Niu PF, 2019, KNOWL-BASED SYST, V171, P37, DOI 10.1016/j.knosys.2019.01.018
   Osoba OA, 2017, J DEF MODEL SIMUL-AP, V14, P17, DOI 10.1177/1548512916680779
   Pamshetti VB, 2020, INT T ELECTR ENERGY, V30, P0, DOI 10.1002/2050-7038.12147
   Patel P, 2018, IEEE INTELL SYST, V33, P79, DOI 10.1109/MIS.2018.043741325
   Puzis R, 2016, ENTERP INF SYST-UK, V10, P349, DOI 10.1080/17517575.2014.928954
   Qian W., 1900, P661, V0, P0, DOI DOI 10.1109/IAEAC.2017.8054099
   Saadatfar H, 2020, MATHEMATICS-BASEL, V8, P0, DOI 10.3390/math8020286
   Sahal R, 2020, J MANUF SYST, V54, P138, DOI 10.1016/j.jmsy.2019.11.004
   Saremi S, 2015, NEURAL COMPUT APPL, V26, P1257, DOI 10.1007/s00521-014-1806-7
   Saxena A, 2008, 2008 INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (PHM), V0, P1
   Selcuk S, 2017, P I MECH ENG B-J ENG, V231, P1670, DOI 10.1177/0954405415601640
   Senniappan V, 2017, NEURAL COMPUT APPL, V28, PS107, DOI 10.1007/s00521-016-2313-9
   Song XH, 2015, SOIL DYN EARTHQ ENG, V75, P147, DOI 10.1016/j.soildyn.2015.04.004
   Sotiris VA, 2010, IEEE T RELIAB, V59, P277, DOI 10.1109/TR.2010.2048740
   Stylios C. D., 1998, IFAC P VOLUMES, V31, P93
   Stylios CD, 2000, J INTELL FUZZY SYST, V8, P83
   Stylios CD, 2004, IEEE T SYST MAN CY A, V34, P155, DOI 10.1109/TSMCA.2003.818878
   Sutharssan T, 2015, J ENG-JOE, V0, P0, DOI DOI 10.1049/joe.2014.0303
   Taber R, 2007, INT J INTELL SYST, V22, P181, DOI 10.1002/int.20185
   Nguyen TT, 2017, ADV INTELL SYST, V538, P228, DOI 10.1007/978-3-319-49073-1_25
   Tsoukalas LH, 1996, FUZZY NEURAL APPROAC, V0, P0
   Wu L, 2020, SEDIMENT GEOL, V398, P0, DOI 10.1016/j.sedgeo.2020.105590
   Xu JP, 2014, IEEE SENS J, V14, P1124, DOI 10.1109/JSEN.2013.2293517
   Yang H., 2020, MEASUREMENT, V163, P0, DOI 10.1016/j.measurement.2020.108035
   Yang Z, 2018, ADV MECH ENG, V10, P0, DOI 10.1177/1687814018765535
   Zhang R, 2013, INT T OPER RES, V20, P533, DOI 10.1111/itor.12011
   Zhang Y, 2017, CHIN AUTOM CONGR, V0, P882
   Zhao FQ, 2013, INT J MODEL IDENTIF, V18, P261, DOI 10.1504/IJMIC.2013.052820
   Zhao MH, 2016, MEASUREMENT, V86, P41, DOI 10.1016/j.measurement.2015.11.047
   Zheng B, 2020, INT J TURBO JET ENG, V37, P17, DOI 10.1515/tjj-2017-0003
   Zhou L., 1900, P210, V0, P0
   Zidane TEK, 2020, ENERGIES, V13, P0, DOI 10.3390/en13112776
NR 90
TC 3
Z9 3
U1 2
U2 8
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1024-123X
EI 1563-5147
J9 MATH PROBL ENG
JI Math. Probl. Eng.
PD FEB 17
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/8832011
PG 21
WC Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications
SC Engineering; Mathematics
GA QR7CW
UT WOS:000625373800010
DA 2023-04-26
ER

PT J
AU Fang, ZC
   Wang, Y
   Peng, L
   Hong, HY
AF Fang, Zhice
   Wang, Yi
   Peng, Ling
   Hong, Haoyuan
TI A comparative study of heterogeneous ensemble-learning techniques for landslide susceptibility mapping
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Landslide susceptibility mapping; heterogeneous ensemble; stacking; blending; deep neural networks
ID fuzzy inference system; multicriteria decision-analysis; biogeography-based optimization; weighted linear combination; support vector machine; logistic-regression; frequency ratio; area; prediction; models
AB This study introduces four heterogeneous ensemble-learning techniques, that is, stacking, blending, simple averaging, and weighted averaging, to predict landslide susceptibility in Yanshan County, China. These techniques combine several state-of-the-art classifiers of convolutional neural network, recurrent neural network, support vector machine, and logistic regression in specific ways to produce reliable results and avoid problems with the model selection. The study consists of three main steps. The first step establishes a spatial database consisting of 16 landslide conditioning factors and 380 historical landslide locations. The second step randomly selects training (70% of the total) and test (30%) datasets out of grid cells corresponding to landslide and non-slide locations in the study area. The final step constructs the proposed heterogeneous ensemble-learning methods for landslide susceptibility mapping. The proposed ensemble-learning methods show higher prediction accuracy than the individual classifiers mentioned above based on statistical measures. The blending ensemble-learning method achieves the highest overall accuracy of 80.70% compared to the other ensemble-learning methods.
C1 [Fang, Zhice; Wang, Yi] China Univ Geosci, Inst Geophys & Geomat, Wuhan, Peoples R China.
   [Peng, Ling] China Inst Geoenvironm Monitoring, Beijing, Peoples R China.
   [Hong, Haoyuan] Univ Vienna, Dept Geog & Reg Res, Vienna, Austria.
   [Hong, Haoyuan] Nanjing Normal Univ, Minist Educ, Key Lab Virtual Geog Environm, Nanjing, Peoples R China.
C3 China University of Geosciences; University of Vienna; Nanjing Normal University
RP Wang, Y (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Wuhan, Peoples R China.; Hong, HY (corresponding author), Univ Vienna, Dept Geog & Reg Res, Vienna, Austria.
EM cug.yi.wang@gmail.com; hong_haoyuan@outlook.com
FU National Natural Science Foundation of China [61271408, 41602362]; China Scholarship Council [201906860029]
CR Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   Akgun A, 2008, ENVIRON GEOL, V54, P1127, DOI 10.1007/s00254-007-0882-8
   Alizadeh M, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10103376
   Althuwaynee OF, 2014, CATENA, V114, P21, DOI 10.1016/j.catena.2013.10.011
   Alvioli M, 2016, ENVIRON MODELL SOFTW, V81, P122, DOI 10.1016/j.envsoft.2016.04.002
   Anagnostopoulos GG, 2015, WATER RESOUR RES, V51, P7501, DOI 10.1002/2015WR016909
   [Anonymous], 2015, EM DAT INT DISASTER, V0, P0
   Ayalew L, 2005, GEOMORPHOLOGY, V65, P15, DOI 10.1016/j.geomorph.2004.06.010
   Ayalew L, 2004, LANDSLIDES, V1, P73, DOI 10.1007/s10346-003-0006-9
   Pham BT, 2019, CATENA, V175, P203, DOI 10.1016/j.catena.2018.12.018
   Pham BT, 2020, GEOCARTO INT, V35, P1267, DOI 10.1080/10106049.2018.1559885
   Pham BT, 2018, INT J SEDIMENT RES, V33, P157, DOI 10.1016/j.ijsrc.2017.09.008
   Pham BT, 2017, CATENA, V149, P52, DOI 10.1016/j.catena.2016.09.007
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Bueechi E, 2019, LANDSLIDES, V16, P395, DOI 10.1007/s10346-018-1090-1
   Chen W, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9183755
   Chen W, 2017, CATENA, V157, P310, DOI 10.1016/j.catena.2017.05.034
   Choubin B, 2019, SCI TOTAL ENVIRON, V651, P2087, DOI 10.1016/j.scitotenv.2018.10.064
   Ciurleo M, 2017, ENG GEOL, V223, P71, DOI 10.1016/j.enggeo.2017.04.023
   Collobert Ronan, 2008, P 25 INT C MACH LEAR, V0, P0, DOI DOI 10.1145/1390156.1390177
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dietterich TG, 1997, AI MAG, V18, P97
   Bui DT, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5919-4
   Dormann CF, 2013, ECOGRAPHY, V36, P27, DOI 10.1111/j.1600-0587.2012.07348.x
   Dou J, 2020, LANDSLIDES, V17, P641, DOI 10.1007/s10346-019-01286-5
   Eker AM, 2015, INT J GEOGR INF SCI, V29, P132, DOI 10.1080/13658816.2014.953164
   Erener A, 2016, ENG GEOL, V203, P45, DOI 10.1016/j.enggeo.2015.09.007
   Fang ZC, 2020, COMPUT GEOSCI-UK, V139, P0, DOI 10.1016/j.cageo.2020.104470
   Feizizadeh B, 2013, NAT HAZARDS, V65, P2105, DOI 10.1007/s11069-012-0463-3
   Galli M, 2008, GEOMORPHOLOGY, V94, P268, DOI 10.1016/j.geomorph.2006.09.023
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Guzzetti F, 1999, GEOMORPHOLOGY, V31, P181, DOI 10.1016/S0169-555X(99)00078-1
   Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007
   Hajimoradlou A., 2019, THESIS, V0, P0
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Hong HY, 2018, CATENA, V163, P399, DOI 10.1016/j.catena.2018.01.005
   Huang FM, 2020, LANDSLIDES, V17, P217, DOI 10.1007/s10346-019-01274-9
   Jaafari A, 2019, CATENA, V175, P430, DOI 10.1016/j.catena.2018.12.033
   Kavzoglu T, 2014, LANDSLIDES, V11, P425, DOI 10.1007/s10346-013-0391-7
   KIRA K, 1992, MACHINE LEARNING /, V0, P249
   Ko FWY, 2018, ENG GEOL, V242, P12, DOI 10.1016/j.enggeo.2018.05.001
   Kornejady A, 2017, CATENA, V152, P144, DOI 10.1016/j.catena.2017.01.010
   Korzh O, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), V0, P599
   Kumar D, 2017, GEOMORPHOLOGY, V295, P115, DOI 10.1016/j.geomorph.2017.06.013
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9061231
   Lee S, 2007, LANDSLIDES, V4, P33, DOI 10.1007/s10346-006-0047-y
   Lee S, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9173495
   Li, 2010, ADV NEURAL INFORM PR, V0, P0, DOI DOI 10.1184/R1/6475985.V1
   Lombardo L, 2018, ENG GEOL, V244, P14, DOI 10.1016/j.enggeo.2018.07.019
   Mandal S, 2018, MODEL EARTH SYST ENV, V4, P69, DOI 10.1007/s40808-018-0426-0
   Manzo G, 2013, INT J GEOGR INF SCI, V27, P1433, DOI 10.1080/13658816.2012.693614
   Mutlu B, 2019, ISPRS INT GEO-INF, V8, P0, DOI 10.3390/ijgi8120578
   Oh HJ, 2011, COMPUT GEOSCI-UK, V37, P1264, DOI 10.1016/j.cageo.2010.10.012
   Othman AA, 2018, GEOMORPHOLOGY, V319, P147, DOI 10.1016/j.geomorph.2018.07.018
   Sesmero MP, 2015, WIRES DATA MIN KNOWL, V5, P21, DOI 10.1002/widm.1143
   Pham BT., 2018, INDIAN J SCI TECHNOL, V11, P1, DOI 10.17485/ijst/2018/v11i12/99745
   Pourghasemi HR, 2019, SCI TOTAL ENVIRON, V692, P556, DOI 10.1016/j.scitotenv.2019.07.203
   Pourghasemi HR, 2018, CATENA, V162, P177, DOI 10.1016/j.catena.2017.11.022
   Pourghasemi HR, 2012, NAT HAZARDS, V63, P965, DOI 10.1007/s11069-012-0217-2
   Pradhan B, 2013, COMPUT GEOSCI-UK, V51, P350, DOI 10.1016/j.cageo.2012.08.023
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   Sameen MI, 2020, CATENA, V186, P0, DOI 10.1016/j.catena.2019.104249
   Shafizadeh-Moghadam H, 2018, J ENVIRON MANAGE, V217, P1, DOI 10.1016/j.jenvman.2018.03.089
   Shahri AA, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104225
   Shirzadi A, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-016-6374-y
   Sorensen R, 2006, HYDROL EARTH SYST SC, V10, P101, DOI 10.5194/hess-10-101-2006
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Termeh SVR, 2018, SCI TOTAL ENVIRON, V615, P438, DOI 10.1016/j.scitotenv.2017.09.262
   Toscher Andreas, 2009, BIGCHAOS SOLUTION NE, V0, P1
   Tsangaratos P, 2017, LANDSLIDES, V14, P1091, DOI 10.1007/s10346-016-0769-4
   Tsangaratos P, 2016, CATENA, V145, P164, DOI 10.1016/j.catena.2016.06.004
   Ullo S.L., 2019, IGARSS 2019, V0, P0
   Wang G, 2011, EXPERT SYST APPL, V38, P223, DOI 10.1016/j.eswa.2010.06.048
   Wang Q, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090938
   Wang Y, 2020, COMPUT GEOSCI-UK, V138, P0, DOI 10.1016/j.cageo.2020.104445
   Wang Y, 2020, J HYDROL, V582, P0, DOI 10.1016/j.jhydrol.2019.124482
   Wang Y, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104217
   Wang Y, 2019, J ENVIRON MANAGE, V247, P712, DOI 10.1016/j.jenvman.2019.06.102
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Wang YY, 2019, APPL SOFT COMPUT, V77, P188, DOI 10.1016/j.asoc.2019.01.015
   Witten IH, 2011, MOR KAUF D, V0, P1
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xiao LM, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18124436
   Truong XL, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8071046
   Yalcin A, 2008, CATENA, V72, P1, DOI 10.1016/j.catena.2007.01.003
   Yang L, 2019, SOFT COMPUT, V23, P13393, DOI 10.1007/s00500-019-03878-8
   Yu XY, 2016, INT J ENV RES PUB HE, V13, P0, DOI 10.3390/ijerph13050487
   Zeng L., 2001, POLIT ANAL, V9, P137, DOI 10.1093/OXFORDJOURNALS.PAN.A004868
NR 91
TC 66
Z9 67
U1 24
U2 86
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD FEB 1
PY 2021
VL 35
IS 2
BP 321
EP 347
DI 10.1080/13658816.2020.1808897
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA PM8QV
UT WOS:000569836500001
DA 2023-04-26
ER

PT J
AU Sahitya, KS
   Prasad, CSRK
AF Sahitya, K. Sai
   Prasad, C. S. R. K.
TI GIS-BASED URBAN ROAD NETWORK ACCESSIBILITY MODELING USING MLR, ANN AND ANFIS METHODS
SO TRANSPORT AND TELECOMMUNICATION JOURNAL
LA English
DT Article
DE accessibility; GIS; road network; ANN; ANFIS
ID system
AB A sustainable transportation system is possible only through an efficient evaluation of transportation network performance. The efficiency of the transport network structure is analyzed in terms of its connectivity, accessibility, network development, and spatial pattern. This study primarily aims to propose a methodology for modeling the accessibility based on the structural parameters of the urban road network. Accessibility depends on the arrangement of the urban road network structure. The influence of the structural parameters on the accessibility is modeled using Multiple Linear Regression (MLR) analysis. The study attempts to introduce two methods of Artificial Intelligence (AI) namely Artificial Neural Networks (ANN) and Adaptive network-based neuro-fuzzy inference system (ANFIS) in modeling the urban road network accessibility. The study also focuses on comparing the results obtained from MLR, ANN and ANFIS modeling techniques in predicting the accessibility. The results of the study present that the structural parameters of the road network have a considerable impact on accessibility. ANFIS method has shown the best performance in modeling the road network accessibility with a MAPE value of 0.287%. The present study adopted Geographical Information Systems (GIS) to quantify, extract and analyze different features of the urban transportation network structure. The combination of GIS, ANN, and ANFIS help in improved decision-making. The results of the study may be used by transportation planning authorities to implement better planning practices in order to improve accessibility.
C1 [Sahitya, K. Sai; Prasad, C. S. R. K.] Natl Inst Technol, Transportat Div, Dept Civil Engn, Warangal, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Warangal
RP Sahitya, KS (corresponding author), Natl Inst Technol, Transportat Div, Dept Civil Engn, Warangal, Telangana, India.
EM ksspvpcivil@gmail.com; csrk_prasad@yahoo.com
CR Abdulhai B., 1999, PRESENTED 78TH ANN M, V0, P0
   Ahmed Geneidy M.E.I., 2006, ACCESS DESTINATIONS, V0, P0
   Arora A., 2011, 12TH ESRI INDIA USER, V0, P0
   Ben-Akiva M., 1977, BEHAV TRAVEL MODELLI, V0, P654
   Bento A.M., 2003, RES PAPER 3007, V0, P0
   Bhat C., 2002, RES REPORT TX 01 7 4, V0, P0
   Bugday E, 2018, FRESEN ENVIRON BULL, V27, P1656
   Burns L. D., 1979, TRANSPORTATION TEMPO, V0, P0
   Chauhan B., 2013, INT J COMPUTER SCI M, V2, P153
   Chen BP, 2009, I C COMM SOFTW NET, V0, PP791, DOI 10.1109/ICCSN.2009.140
   DALVI MQ, 1976, TRANSPORTATION, V5, P17, DOI 10.1007/BF00165245
   De Cola L., 1993, FRACTALS GEOGRAPHY, V0, P3
   Falconer K., 1986, CAMBRIDGE TRACTS MAT, V0, P0
   Falconer K., 2003, FRACTAL GEOMETRY MAT, V0, P0
   Fu LP, 2000, TRANSPORT PLAN TECHN, V24, P25, DOI 10.1080/03081060008717659
   Gopal S., 2016, INT ENCY GEOGRAPHY P, V0, P1
   HANSEN WG, 1959, J AM I PLANNERS, V25, P73, DOI 10.1080/01944365908978307
   Hastings H.M., 1993, FRACTALS USERS GUIDE, V1993, P1
   Holt A, 1999, INT J GEOGR INF SCI, V13, P9, DOI 10.1080/136588199241436
   Hosseinpour M, 2013, KSCE J CIV ENG, V17, P1761, DOI 10.1007/s12205-013-0036-3
   Kansky K., 1963, RES PAPER 84, V0, P0
   Khodayari A., 2010, 13TH INT IEEE ANN C, V0, P0
   Krishnamurthy K., 2017, EUROPEAN TRANSPORT, V65, P1
   Krol A, 2016, TRANSP RES PROC, V14, P4532, DOI 10.1016/j.trpro.2016.05.376
   Levinson D, 2012, PLOS ONE, V7, P0, DOI 10.1371/journal.pone.0029721
   Mackiewicz A, 1996, TRANSPORT RES B-METH, V30, P47, DOI 10.1016/0191-2615(95)00020-8
   Mandelbrot BB., 1982, FRACTAL GEOMETRY NAT, V0, P0
   McCulloch W., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Modinpuroju A, 2016, INNOV INFRASTRUCT SO, V1, P0, DOI 10.1007/s41062-016-0041-8
   Mohammadi A., 2013, INT J EARTH SCI ENG, V6, P0
   Mohammady S., 2016, CITY TERRIT ARCHIT, V3, P10, DOI 10.1186/S40410-016-0039-8
   Morris D, 2017, IEEE IJCNN, V0, PP4416, DOI 10.1109/IJCNN.2017.7966415
   Murat YS, 2006, TRANSPORT RES C-EMER, V14, P316, DOI 10.1016/j.trc.2006.08.003
   Nijagunappa R., 2007, J INDIAN SOC REMOTE, V35, P267
   Obafemi A.A., 2011, INT J TRAFFIC TRANSP, V1, P257
   Sahitya KS, 2020, SPAT INF RES, V28, P487, DOI 10.1007/s41324-019-00309-6
   Sahitya KS, 2020, SPAT INF RES, V28, P327, DOI 10.1007/s41324-019-00295-9
   Stojcic M., 2018, OPER RES ENG SCI THE, V1, P40
   Sun Z., 2007, J E ASIA SOC TRANSPO, V7, P0
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Thaseepetch T., 2012, INT J MODERN ENG RES, V2, P4153
   Transportation Research Board of the National Academies, 2012, CIRCULAR NUMBER C168, V0, P0
   Transportation Research Board of the National Academies, 2007, CIRCULAR NUMBER C113, V0, P0
   vanderVoort M, 1996, TRANSPORT RES C-EMER, V4, P307, DOI 10.1016/S0968-090X(97)82903-8
   Vozenilek V, 2009, 2009 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS 2009), V0, PP279, DOI 10.1109/INCOS.2009.83
   WU YH, 2002, J TRANSPORTATION STA, V4, P1
NR 46
TC 0
Z9 0
U1 4
U2 18
PU SCIENDO
PI WARSAW
PA BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND
SN 1407-6160
EI 1407-6179
J9 TRANSP TELECOMMUN J
JI Transp. Telecommun. J.
PD FEB 15
PY 2021
VL 22
IS 1
BP 15
EP 28
DI 10.2478/ttj-2021-0002
PG 14
WC Transportation Science & Technology
SC Transportation
GA QR6VW
UT WOS:000625355100002
DA 2023-04-26
ER

PT J
AU Shi, XZ
   Fu, SL
   Chen, J
   Wang, F
   Xu, F
AF Shi, Xianzheng
   Fu, Shilei
   Chen, Jin
   Wang, Feng
   Xu, Feng
TI Object-Level Semantic Segmentation on the High-Resolution Gaofen-3 FUSAR-Map Dataset
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Image segmentation; Radar polarimetry; Semantics; Synthetic aperture radar; Earth; Buildings; Image resolution; 2020 GaoFen challenge; encoder&#8211; decoder network; FUSAR; map dataset; GaoFen-3 (GF-3) single -polarization SAR images; object-level semantic segmentation
ID convolutional neural-network; land-cover classification; sar; imagery
AB Land cover classification with SAR images mainly focuses on the utilization of fully polarimetric SAR (PolSAR) images. The conventional task of PolSAR classification is single-pixel-based region-level classification using polarimetric target decomposition. In recent years, a large number of high-resolution SAR images have become available, most of which are single-polarization. This article explores the potential of object-level semantic segmentation of high-resolution single-pol SAR images, in particular tailored for the Gaofen-3 (GF-3) sensor. First, a well-annotated GF-3 segmentation dataset "FUSAR-Map" is presented for SAR semantic segmentation. It is based on four data sources: GF-3 single-pol SAR images, Google Earth optical remote sensing images, Google Earth digital maps, and building footprint vector data. It consists of 610 high-resolution GF-3 single-pol SAR images with the size of 1024 x 1024. Second, an encoder-decoder network based on transfer learning is employed to implement semantic segmentation of GF-3 SAR images. For the FUSAR-Map dataset, an optical image pretrained deep convolution neural network (DCNN) is fine-tuned with the SAR training dataset. Experiments on the FUSAR-Map dataset demonstrate the feasibility of object-level semantic segmentation with high-resolution GF-3 single-pol SAR images. Also, our algorithm obtains fourth place about the PolSAR image semantic segmentation on the "2020 Gaofen Challenge on Automated High-Resolution Earth Observation Image Interpretation." The new dataset and the encoder-decoder network are intended as the benchmark data and baseline algorithm for further development of semantic segmentation with high-resolution SAR images. The FUSAR-Map and our algorithm are available at github.com/fudanxu/FUSAR-Map/.
C1 [Shi, Xianzheng; Fu, Shilei; Wang, Feng; Xu, Feng] Fudan Univ, Key Lab Informat Sci Electromagnet Waves MoE, Shanghai 200433, Peoples R China.
   [Chen, Jin] Beijing Inst Remote Sensing Informat, Beijing, Peoples R China.
C3 Fudan University
RP Wang, F; Xu, F (corresponding author), Fudan Univ, Key Lab Informat Sci Electromagnet Waves MoE, Shanghai 200433, Peoples R China.
EM xzshi19@fudan.edu.cn; fusl17@fudan.edu.cn; chenjin_wonder@hotmail.com; fengwang@fudan.edu.cn; fengxu@fudan.edu.cn
FU Natural Science Foundation of China [61991422, 61822107]
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   [Anonymous], 2020, GAOFEN CHALLENGE AUT, V0, P0
   Arisoy S, 2016, IEEE GEOSCI REMOTE S, V13, P1721, DOI 10.1109/LGRS.2016.2605583
   Badrinarayanan V, 2015, ARXIV150507293, V0, P0, DOI DOI 10.1109/TPAMI.2016.2644615
   Cantorna D, 2019, APPL SOFT COMPUT, V84, P0, DOI 10.1016/j.asoc.2019.105716
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, PP801, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Q, 2013, IEEE T GEOSCI REMOTE, V51, P1817, DOI 10.1109/TGRS.2012.2205389
   Chollet F, 2016, PROC CVPR IEEE, V0, P0, DOI DOI 10.48550/arXiv.1610.02357
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Dumitru CO, 2015, IEEE J-STARS, V8, P1635, DOI 10.1109/JSTARS.2014.2363595
   HE N, 2020, IEEE J-STARS, V63, P0
   Henry C, 2018, IEEE GEOSCI REMOTE S, V15, P1867, DOI 10.1109/LGRS.2018.2864342
   Hou XY, 2020, SCI CHINA INFORM SCI, V63, P0, DOI 10.1007/s11432-019-2772-5
   Jafari M, 2015, IEEE J-STARS, V8, P3595, DOI 10.1109/JSTARS.2014.2387374
   Jain A, 2019, ADV SPACE RES, V63, P813, DOI 10.1016/j.asr.2018.09.027
   Jiao LC, 2015, IEEE J-STARS, V8, P3876, DOI 10.1109/JSTARS.2015.2429137
   Kang J, 2020, IEEE T GEOSCI REMOTE, V58, P8905, DOI 10.1109/TGRS.2020.2991657
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE INT C COMP VI, V0, PP2169, DOI 10.1109/CVPR.2006.68
   Li GY, 2012, ISPRS J PHOTOGRAMM, V70, P26, DOI 10.1016/j.isprsjprs.2012.03.010
   Li YC, 2017, SCI CHINA INFORM SCI, V60, P0, DOI 10.1007/s11432-016-0572-3
   Liu CX, 2019, PROC CVPR IEEE, V0, PP82, DOI 10.1109/CVPR.2019.00017
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Mohammadimanesh F, 2019, ISPRS J PHOTOGRAMM, V151, P223, DOI 10.1016/j.isprsjprs.2019.03.015
   Negri RG, 2016, IEEE J-STARS, V9, P5369, DOI 10.1109/JSTARS.2016.2594133
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), V0, PP1, DOI 10.1109/ICPHM.2017.7998297
   Ren YX, 2019, IEEE T GEOSCI REMOTE, V57, P5923, DOI 10.1109/TGRS.2019.2903096
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rossi C, 2015, IEEE T GEOSCI REMOTE, V53, P900, DOI 10.1109/TGRS.2014.2330377
   Salehi M, 2014, IEEE J-STARS, V7, P1394, DOI 10.1109/JSTARS.2013.2273074
   Shahzad M, 2019, IEEE T GEOSCI REMOTE, V57, P1100, DOI 10.1109/TGRS.2018.2864716
   Simonyan K, 2015, ARXIV, V0, P0
   Tao ML, 2015, IEEE T GEOSCI REMOTE, V53, P2481, DOI 10.1109/TGRS.2014.2360943
   Uhlmann S, 2014, IEEE T GEOSCI REMOTE, V52, P2197, DOI 10.1109/TGRS.2013.2258675
   WU W, 2019, SCI CHINA INFORM SCI, V16, P977
   Xu F, 2020, SCI CHINA INFORM SCI, V63, P0, DOI 10.1007/s11432-020-2810-x
   Yang ZY, 2020, IEEE T SYST MAN CY-S, V50, P2524, DOI 10.1109/TSMC.2018.2820084
   Yosinski J., 2015, ARXIV150606579, V0, P0
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zou B, 2020, IEEE J-STARS, V13, P609, DOI 10.1109/JSTARS.2020.2968966
NR 43
TC 14
Z9 16
U1 8
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3107
EP 3119
DI 10.1109/JSTARS.2021.3063797
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RE9UV
UT WOS:000634496000003
DA 2023-04-26
ER

PT J
AU Park, SH
   Jung, HS
   Lee, S
   Kim, ES
AF Park, Sung-Hwan
   Jung, Hyung-Sup
   Lee, Sunmin
   Kim, Eun-Sook
TI Mapping Forest Vertical Structure in Sogwang-ri Forest from Full-Waveform Lidar Point Clouds Using Deep Neural Network
SO REMOTE SENSING
LA English
DT Article
DE forest vertical structure; full-waveform LiDAR; deep neural network; deep learning; forest genetic resource reserve
ID small-footprint discrete; airborne lidar; aboveground biomass; diversity; management; height; return; cover; urban
AB The role of forests is increasing because of rapid land use changes worldwide that have implications on ecosystems and the carbon cycle. Therefore, it is necessary to obtain accurate information about forests and build forest inventories. However, it is difficult to assess the internal structure of the forest through 2D remote sensing techniques and fieldwork. In this aspect, we proposed a method for estimating the vertical structure of forests based on full-waveform light detection and ranging (FW LiDAR) data in this study. Voxel-based tree point density maps were generated by estimating the number of canopy height points in each voxel grid from the raster digital terrain model (DTM) and canopy height points after pre-processing the LiDAR point clouds. We applied an unsupervised classification algorithm to the voxel-based tree point density maps and identified seven classes by profile pattern analysis for the forest vertical types. The classification accuracy was found to be 72.73% from the validation from 11 field investigation sites, which was additionally confirmed through comparative analysis with aerial images. Based on this pre-classification reference map, which is assumed to be ground truths, the deep neural network (DNN) model was finally applied to perform the final classification. As a result of accuracy assessment, it showed accuracy of 92.72% with a good performance. These results demonstrate the potential of vertical structure estimation for extensive forests using FW LiDAR data and that the distinction between one-storied and two-storied forests can be clearly represented. This technique is expected to contribute to efficient and effective management of forests based on accurate information derived from the proposed method.
C1 [Park, Sung-Hwan] Korea Inst Ocean Sci & Technol, Marine Disaster Res Ctr, Busan 49111, South Korea.
   [Park, Sung-Hwan; Jung, Hyung-Sup; Lee, Sunmin] Univ Seoul, Dept Geoinformat, Seoul 02504, South Korea.
   [Jung, Hyung-Sup] Univ Seoul, Dept Smart Cities, Seoul 02504, South Korea.
   [Lee, Sunmin] Korea Environm Inst KEI, Ctr Environm Assessment Monitoring, Sejong Si 30147, South Korea.
   [Kim, Eun-Sook] Natl Inst Forest Sci, Div Forest Ecol, Seoul 02455, South Korea.
C3 Korea Institute of Ocean Science & Technology (KIOST); University of Seoul; University of Seoul; Korea Environment Institute (KEI); Korea Forest Research Institute (KFRI); National Institute of Forest Science (NIFOS), Republic of South Korea
RP Lee, S (corresponding author), Univ Seoul, Dept Geoinformat, Seoul 02504, South Korea.; Lee, S (corresponding author), Korea Environm Inst KEI, Ctr Environm Assessment Monitoring, Sejong Si 30147, South Korea.
EM spark@kiost.ac.kr; hsjung@uos.ac.kr; smilee@kei.re.kr; drummer12@korea.kr
FU National Research Foundation of Korea - Korea government [NRF-2018M1A3A3A02066008]; National Research Foundation of Korea [2021-027(R), NRF-2018R1D1A1B07041203]; National Institute of Forest Science, Republic of Korea [FE0100-2019-05]
CR Anderson H.W., 1976, FORESTS WATER EFFECT, VVolume 18, P0
   [Anonymous], 2006, REMOTE SENSING DIGIT, V0, P0
   Bergen KM, 2009, J GEOPHYS RES-BIOGEO, V114, P0, DOI 10.1029/2008JG000883
   Bonan GB, 2008, SCIENCE, V320, P1444, DOI 10.1126/science.1155121
   Cao L, 2014, REMOTE SENS-BASEL, V6, P7110, DOI 10.3390/rs6087110
   DENNISON WC, 1993, BIOSCIENCE, V43, P86, DOI 10.2307/1311969
   Dieler J, 2017, EUR J FOREST RES, V136, P739, DOI 10.1007/s10342-017-1056-1
   Dubayah RO, 2000, J FOREST, V98, P44
   Garden JG, 2007, AUSTRAL ECOL, V32, P669, DOI 10.1111/j.1442-9993.2007.01750.x
   Gardner TA, 2009, ECOL LETT, V12, P561, DOI 10.1111/j.1461-0248.2009.01294.x
   Gaulton R, 2010, INT J REMOTE SENS, V31, P1193, DOI 10.1080/01431160903380565
   Gibbs HK, 2007, ENVIRON RES LETT, V2, P0, DOI 10.1088/1748-9326/2/4/045023
   Goodwin NR, 2006, REMOTE SENS ENVIRON, V103, P140, DOI 10.1016/j.rse.2006.03.003
   Hamdi ZM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171976
   Heinzel J, 2011, INT J APPL EARTH OBS, V13, P152, DOI 10.1016/j.jag.2010.09.010
   HOEN HF, 1994, FOREST SCI, V40, P429
   Kim HakYun, 2017, KOREAN JOURNAL OF ENVIRONMENT AND ECOLOGY, V31, P188, DOI 10.13047/kjee.2017.31.2.188
   Kim Jaebeom, 2017, KOREAN JOURNAL OF AGRICULTURAL AND FOREST METEOROLOGY 한국농림기상학회지, V19, P10, DOI 10.5532/KJAFM.2017.19.1.10
   Korea Forest Service, 2015, FOR BAS STAT, V0, P0
   Lee YS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050797
   Lee YS, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10051666
   Leitold Veronika, 2015, CARBON BALANCE MANAG, V10, P3
   Liao WZ, 2018, IEEE ACCESS, V6, P68716, DOI 10.1109/ACCESS.2018.2880083
   Lillicrap TP, 2020, NAT REV NEUROSCI, V21, P335, DOI 10.1038/s41583-020-0277-3
   Lim K, 2003, PROG PHYS GEOG, V27, P88, DOI 10.1191/0309133303pp360ra
   Lu DS, 2016, INT J DIGIT EARTH, V9, P63, DOI 10.1080/17538947.2014.990526
   Lv Q, 2014, INT GEOSCI REMOTE SE, V0, P0, DOI DOI 10.1109/IGARSS.2014.6947537
   Narine LL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121503
   Nie S, 2017, ECOL INDIC, V78, P221, DOI 10.1016/j.ecolind.2017.02.045
   Popescu SC, 2008, REMOTE SENS ENVIRON, V112, P767, DOI 10.1016/j.rse.2007.06.011
   Referowska-Chodak E, 2019, FORESTS, V10, P0, DOI 10.3390/f10090765
   Ruiz-Jaen MC, 2005, RESTOR ECOL, V13, P569, DOI 10.1111/j.1526-100X.2005.00072.x
   Saldana A, 2014, PLANT SPEC BIOL, V29, P253, DOI 10.1111/1442-1984.12020
   Segura M, 2005, BIOTROPICA, V37, P2, DOI 10.1111/j.1744-7429.2005.02027.x
   Seidel D, 2011, ANN FOREST SCI, V68, P225, DOI 10.1007/s13595-011-0040-z
   Sumnall MJ, 2016, REMOTE SENS ENVIRON, V173, P214, DOI 10.1016/j.rse.2015.07.027
   Sun JM, 2018, J HYDROL, V561, P187, DOI 10.1016/j.jhydrol.2018.04.003
   Terrasolid, 2004, TERRASCAN USERS GUID, V0, P0
   Tews J, 2004, J BIOGEOGR, V31, P79, DOI 10.1046/j.0305-0270.2003.00994.x
   Wagner FH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142225
   Wang YS, 2008, SENSORS-BASEL, V8, P3938, DOI 10.3390/s8063938
   Wing BM, 2012, REMOTE SENS ENVIRON, V124, P730, DOI 10.1016/j.rse.2012.06.024
   Wulder MA, 2012, REMOTE SENS ENVIRON, V121, P196, DOI 10.1016/j.rse.2012.02.001
   Zimble DA, 2003, REMOTE SENS ENVIRON, V87, P171, DOI 10.1016/S0034-4257(03)00139-1
NR 44
TC 1
Z9 1
U1 2
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2021
VL 13
IS 18
BP 
EP 
DI 10.3390/rs13183736
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UY4ER
UT WOS:000701479400001
DA 2023-04-26
ER

PT J
AU Jamali, A
   Mahdianpari, M
   Brisco, B
   Granger, J
   Mohammadimanesh, F
   Salehi, B
AF Jamali, Ali
   Mahdianpari, Masoud
   Brisco, Brian
   Granger, Jean
   Mohammadimanesh, Fariba
   Salehi, Bahram
TI Deep Forest classifier for wetland mapping using the combination of Sentinel-1 and Sentinel-2 data
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Deep Forest; wetland mapping; Sentinel-1; Sentinel-2; random forest; extreme gradient boosting; newfoundland
ID convolutional neural-networks
AB Wetlands are among the most important, yet in danger ecosystems and play a vital role for the well-being of humans as well as flora and fauna. Over the past few years, state-of-the-art deep learning (DL) tools have gained attention for wetland classification within the remote sensing community. However, the DL methods could have complex structure and their efficiency greatly depends on the availability of a large number of training data. Inspired by DL methods, yet with less complexity, the Deep Forest (DF) classifier is an advanced tree-based deep learning tool with a great capability for several remote sensing applications. Despite the effectiveness of DF classifiers, few research studies have investigated the potential of such a powerful technique for classification of remote sensing, with no documented research for wetland classification. Accordingly, the potential of the DF algorithm for the classification of wetland complexes has been investigated in this study. In particular, three well-known classifiers, namely Extreme Gradient Boosting (XGB), Random Forest (RF), and Extra Tree (ET), were used as the tree-based classifier to build DF, for which the hyper parameter tuning is carried out to ensure the optimum classification accuracy. Three well-known tree-based classification algorithms, namely Decision Tree (DT), Conventional Random Forest (CRF), and Conventional Extreme Gradient Boosting (CXGB), as well as a Convolutional Neural Network (CNN) are used as benchmark tools to compare the results obtained from the DF classifiers for wetland mapping. The results demonstrated that the DF-XGB classifier outperforms both DF-RF and DF-ET in terms of classification accuracy albeit with a longer training time. The results also confirmed the superiority of all three DF-based classifiers compared to the CRF and DT classifiers. For example, the DF-XGB improved the F1-score by 14%, 13%, 7%, 3%, and 1% for fen, swamp, marsh, bog, and shallow water, respectively, compared to the optimized CRF. The results indicated that the DF algorithm has great capability to be applied over large areas to support regional and national wetland mapping and monitoring.
C1 [Jamali, Ali] Univ Karabuk, Civil Engn Dept, Fac Engn, Karabuk, Turkey.
   [Mahdianpari, Masoud] Mem Univ Newfoundland, Dept Elect & Comp Engn, St John, NF, Canada.
   [Mahdianpari, Masoud; Granger, Jean] C Core, St John, NF, Canada.
   [Brisco, Brian; Mohammadimanesh, Fariba] Canada Ctr Mapping & Earth Observat, Ottawa, ON, Canada.
   [Salehi, Bahram] SUNY Coll Environm Sci & Forestry Suny Esf, Dept Environm Resources Engn, Syracuse, NY USA.
C3 Karabuk University; Memorial University Newfoundland; Natural Resources Canada; Strategic Policy & Results Sector - Natural Resources Canada; Canada Centre for Mapping & Earth Observation (CCMEO); State University of New York (SUNY) System; State University of New York (SUNY) College of Environmental Science & Forestry
RP Mahdianpari, M (corresponding author), Mem Univ Newfoundland, Dept Elect & Comp Engn, St John, NF, Canada.; Mahdianpari, M (corresponding author), C Core, St John, NF, Canada.
EM m.mahdianpari@mun.ca
CR Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   Amani M, 2018, ISPRS J PHOTOGRAMM, V144, P119, DOI 10.1016/j.isprsjprs.2018.07.005
   [Anonymous], 2015, REMOTE SENSING WETLA, V0, P0
   Berhane TM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040580
   Board M.A, 2005, MILLENNIUM ECOSYSTEM, V0, P0
   Davis P, 2021, AUTOMAT CONSTR, V122, P0, DOI 10.1016/j.autcon.2020.103481
   Friedman J., 2001, ELEMENTS STAT LEARNI, V0, P0, DOI DOI 10.1007/978-0-387-84858-7
   Gardner RC, 2011, WETLANDS: INTEGRATING MULTIDISCIPLINARY CONCEPTS, V0, PP189, DOI 10.1007/978-94-007-0551-7_11
   Jamali A, 2021, EGYPT J REMOTE SENS, V24, P373, DOI 10.1016/j.ejrs.2020.07.001
   Jamali A, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13112046
   Jamali A, 2021, CAN J REMOTE SENS, V47, P243, DOI 10.1080/07038992.2021.1901562
   Jamali A, 2020, EARTH SCI INFORM, V13, P1015, DOI 10.1007/s12145-020-00475-4
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Liu KZ, 2021, MATH PROBL ENG, V2021, P0, DOI 10.1155/2021/6610338
   Louis J., 2016, SENTINEL 2 SEN2COR L, V0, P1
   Ma WP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020142
   Mahdianpari M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010043
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   Mandianpari M, 2017, ISPRS J PHOTOGRAMM, V130, P13, DOI 10.1016/j.isprsjprs.2017.05.010
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   National Wetlands Working Group, 2018, WETLAND BOOK STRUCTU, V0, P0, DOI DOI 10.1007/978-90-481-9659-3_340
   Appiah JO, 2021, EARTH SYST ENVIRON, V5, P253, DOI 10.1007/s41748-021-00207-8
   Slagter B, 2020, INT J APPL EARTH OBS, V86, P0, DOI 10.1016/j.jag.2019.102009
   Song HS, 2021, J AMB INTEL HUM COMP, V12, P3399, DOI 10.1007/s12652-020-02560-4
   Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015
   Sun Zhiyuan, 2021, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1914, P0, DOI 10.1088/1742-6596/1914/1/012025
   Yu B, 2021, EXPERT SYST APPL, V176, P0, DOI 10.1016/j.eswa.2021.114876
   Zhang JH, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13040812
   Zhang JH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010128
   Zhang YH, 2018, REMOTE SENS LETT, V9, P11, DOI 10.1080/2150704X.2017.1378452
   Zhou Z. H., 2017, DEEP FOREST ALTERNAT, V0, P0
NR 31
TC 11
Z9 11
U1 10
U2 35
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD OCT 3
PY 2021
VL 58
IS 7
BP 1072
EP 1089
DI 10.1080/15481603.2021.1965399
EA SEP 2021
PG 18
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA XC0VF
UT WOS:000698334200001
DA 2023-04-26
ER

PT J
AU Hasan, MA
   Hossain, Z
AF Hasan, Md Ariful
   Hossain, Zahid
TI Life Cycle Cost Analysis of Corrugated Metal Pipes in Arkansas
SO TRAN-SET 2020: PROCEEDINGS OF THE TRAN-SET CONFERENCE 2020
LA English
DT Proceedings Paper
AB Metal culverts are being used by the Arkansas Department of Transportation (ArDOT) on a frequent basis. The service life of these culverts mainly depends on the properties of culvert materials and surrounding environments. The selection of pipe material at any location is mostly controlled by its life cycle costs (LCC), which include construction, operation, and maintenance costs. In this study, life cycle costs of different metal pipes are evaluated based on the existing unit costs data and other construction, maintenance, and user associated costs of a culvert. Laboratory investigations were carried out to assess the properties of the soils collected from different parts of the state. The secondary soil and water quality data were collected from secondary sources. Using neural network models developed based on secondary and primary data from state agencies, the electrical resistivity of soils has been predicted for different locations within the state. Then, the service lives of three different metal pipes were estimated. Finally, based on the service life of different metal pipes, their life cycle costs were estimated, and the geographical information system (GIS) based maps were developed for all 75 counties in Arkansas. The maps show the most feasible locations of different metal pipe culverts based on the associated life cycle costs. This study will help the ArDOT engineers to select cost-effective metal culverts for any location within the state.
C1 [Hasan, Md Ariful] Arkansas State Univ, Engn, Jonesboro, AR 72401 USA.
   [Hossain, Zahid] Arkansas State Univ, Dept Civil Engn, Jonesboro, AR USA.
C3 Arkansas State University; Arkansas State University
RP Hasan, MA (corresponding author), Arkansas State Univ, Engn, Jonesboro, AR 72401 USA.
EM mdariful.hasan@smail.astate.edu; mhossain@astate.edu
FU Transportation Consortium of South Central States (TranSET)
CR [Anonymous], 2009, A93099 ASTM, V0, P0
   Arkansas Department of Environmental Quality (ADEQ), 2018, WATER QUALITY MONITO, V0, P0
   Arkansas Department of Transportation (ARDOT), 2014, STANDARD SPECIFICATI, V0, P0
   Arkansas Department of Transportation (ARDOT), 2019, UN PRIC PROJ AW CONT, V0, P0
   California Department of Transportation (Caltrans), 1999, METH EST SERV LIF ST, V0, P0
   Florida Department of Transportation (FDOT), 2012, DRAIN MAN OPT PIP MA, V0, P0
   Fuggle A, 2015, SERVICE LIFE CULVERT, V0, P0, DOI DOI 10.17226/22140
   Hasan M., 2019, INT J GEOMECH, V0, P0
   Hawk H, 2003, BRIDGE LIFE CYCLE CO, V483, P0
   Hossain Z., 2019, DEV METALS CORROSION, V0, P0
   NRCS, 2018, WEB SOIL SURV, V0, P0
   Ozbay K., 2003, FHWANJ2003012, V0, P0
   Perrin J., 2004, TRANSP RES BOARD 200, V0, P0
   Tewari S., 2018, 1803467 TRANSP RES B, V0, P0
   U.S. Department of Agriculture (USDA), 2018, NAT SOIL SURV HDB, V0, P0
NR 15
TC 0
Z9 0
U1 0
U2 0
PU AMER SOC CIVIL ENGINEERS
PI NEW YORK
PA UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 324
EP 334
DI 
PG 11
WC Construction & Building Technology; Engineering, Civil; Transportation Science & Technology
SC Construction & Building Technology; Engineering; Transportation
GA BS2AQ
UT WOS:000698603300033
DA 2023-04-26
ER

PT J
AU Karatzinis, GD
   Boutalis, YS
AF Karatzinis, Georgios D.
   Boutalis, Yiannis S.
TI Fuzzy cognitive networks with functional weights for time series and pattern recognition applications
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Fuzzy cognitive maps; Fuzzy cognitive networks; Classification; Time series prediction; Functional weights
ID adaptive estimation; neural-network; maps; algorithm; regularization; prediction; system; model
AB Over the last decades, a number of remarkable pattern recognition algorithms have been proposed, as a result of the continuous raising of pattern classification in one of the major application areas of artificial intelligence. Many real world problems require the use of efficient classification models pointing out the need for continuous research and study of new techniques. Such a proposal is to use Fuzzy Cognitive Maps (FCMs) and their extensions to solve distinct classification tasks. The extension named Fuzzy Cognitive Network (FCN) has the clear advantage of guaranteed convergence to equilibrium points, which in turn makes it more suitable for pattern recognition applications. However, in order to store the broad range of associations using FCN, large fuzzy rule databases have to be built. In this work, the FCNs with functional weights are introduced and their use in pattern recognition and time series prediction is proposed. The new scheme keeps the nice convergence properties of FCN but is alleviated from the memory and computational requirements of using large fuzzy rule databases, as well as from the inevitable human intervention. The training of the classifier is performed by using a combination of a gradient descent like procedure which uses either a linear or a bilinear parametric model of the network and a least squares method for the estimation of the functional weights. The efficiency and reliability of the proposed classifier is supported by its high overall performance on a set of publicly available time series and pattern recognition datasets outperforming other well-known machine learning models, as well as the most efficient FCM based classifiers. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Karatzinis, Georgios D.; Boutalis, Yiannis S.] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi 67100, Greece.
C3 Democritus University of Thrace
RP Karatzinis, GD (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi 67100, Greece.
EM gkaratzi@ee.duth.gr; ybout@ee.duth.gr
FU Hellenic Foundation for Research and Innovation (HFRI), Greece under the HFRI PhD Fellowship grant [706]
CR Acampora G, 2015, IEEE T FUZZY SYST, V23, P2397, DOI 10.1109/TFUZZ.2015.2426311
   Acampora G, 2011, IEEE T FUZZY SYST, V19, P1040, DOI 10.1109/TFUZZ.2011.2159799
   Azar A, 2019, EXPERT SYST APPL, V115, P607, DOI 10.1016/j.eswa.2018.08.043
   Boutalis Y, 2014, ADV IND CONTROL, V0, PP1, DOI 10.1007/978-3-319-06364-5
   Boutalis Y, 2009, IEEE T FUZZY SYST, V17, P874, DOI 10.1109/TFUZZ.2009.2017519
   Chi YX, 2016, IEEE T FUZZY SYST, V24, P71, DOI 10.1109/TFUZZ.2015.2426314
   de Souza L.B., 2018, 2018 IEEE INT C FUZZ, V0, P1
   Dickerson J.A., 1994, PRESENCE, V3, P173, DOI 10.1162/pres.1994.3.2.173
   Engl H. W., 1996, REGULARIZATION INVER, V0, P0
   Feng G., 2019, IEEE T CYBERN, V0, P0
   Froelich W, 2017, NEUROCOMPUTING, V232, P83, DOI 10.1016/j.neucom.2016.11.059
   Froelich W, 2009, STUD COMPUT INTELL, V252, P153
   Geva AB, 1998, IEEE T NEURAL NETWOR, V9, P1471, DOI 10.1109/72.728396
   GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751
   Hadavandi E, 2010, KNOWL-BASED SYST, V23, P800, DOI 10.1016/j.knosys.2010.05.004
   Hajek P., 2018, P 2018 IEEE INT C FU, V0, P1
   Hajek P, 2019, INFORM SCIENCES, V485, P394, DOI 10.1016/j.ins.2019.02.035
   HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086
   Hassan MR, 2007, EXPERT SYST APPL, V33, P171, DOI 10.1016/j.eswa.2006.04.007
   Hassan MR, 2009, NEUROCOMPUTING, V72, P3439, DOI 10.1016/j.neucom.2008.09.029
   Homenda W., 2019, IEEE T FUZZY SYST, V0, P0
   Homenda W, 2014, LECT NOTES COMPUT SC, V8838, P409, DOI 10.1007/978-3-662-45237-0_38
   Huerga AV, 2002, P 16 INT WORKSH QUAL, V2002, P0
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Karatzinis G, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON SYSTEMS AND CONTROL (ICSC), V0, PP384, DOI 10.1109/ICoSC.2018.8587780
   Karatzinis G, 2018, 2018 EUROPEAN CONTROL CONFERENCE (ECC), V0, PP2069, DOI 10.23919/ECC.2018.8550376
   Karatzinis G, 2018, MED C CONTR AUTOMAT, V0, P709
   Kitagawa T, 2001, BIT, V41, P1049, DOI 10.1023/A:1021949530676
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kottas T, 2015, 2015 IEEE EINDHOVEN POWERTECH, V0, P0
   Kottas T., 2006, 2006 14 MED C CONTR, V0, P1
   Kottas TL, 2006, IEEE T ENERGY CONVER, V21, P793, DOI 10.1109/TEC.2006.875430
   Kottas TL, 2007, INTELL DECIS TECHNOL, V1, P183, DOI 10.3233/IDT-2007-1402
   Kottas T, 2012, APPL SOFT COMPUT, V12, P3736, DOI 10.1016/j.asoc.2012.01.025
   Kottas TL, 2018, IEEE ACCESS, V6, P24866, DOI 10.1109/ACCESS.2018.2822051
   Koulouriotis DE, 2001, IEEE C EVOL COMPUTAT, V0, PP364, DOI 10.1109/CEC.2001.934413
   Li SJ, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2301
   Mei S, 2014, IEEE T FUZZY SYST, V22, P264, DOI 10.1109/TFUZZ.2013.2251638
   Nair A, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106309
   Nair A, 2019, APPL SOFT COMPUT, V84, P0, DOI 10.1016/j.asoc.2019.105754
   Napoles G, 2018, STUD FUZZ SOFT COMP, V360, P83, DOI 10.1007/978-3-319-64286-4_5
   Napoles G, 2014, EXPERT SYST APPL, V41, P821, DOI 10.1016/j.eswa.2013.08.012
   Natarajan R, 2016, COMPUT ELECTRON AGR, V127, P147, DOI 10.1016/j.compag.2016.05.016
   Papageorgiou E, 2003, LECT NOTES ARTIF INT, V2903, P256
   Papageorgiou EI, 2008, APPL SOFT COMPUT, V8, P820, DOI 10.1016/j.asoc.2007.06.006
   Papageorgiou EI, 2005, APPL SOFT COMPUT, V5, P409, DOI 10.1016/j.asoc.2004.08.008
   Papageorgiou EI, 2004, INT J APPROX REASON, V37, P219, DOI 10.1016/j.ijar.2004.01.001
   Papageorgiou EI, 2003, IEEE T BIO-MED ENG, V50, P1326, DOI 10.1109/TBME.2003.819845
   Papageorgiou EI, 2013, IEEE T FUZZY SYST, V21, P342, DOI 10.1109/TFUZZ.2012.2214224
   Papageorgiou EI, 2012, APPL SOFT COMPUT, V12, P3798, DOI 10.1016/j.asoc.2012.03.064
   Papageorgiou EI, 2012, IEEE T SYST MAN CY C, V42, P150, DOI 10.1109/TSMCC.2011.2138694
   Papakostas GA, 2012, EXPERT SYST APPL, V39, P10620, DOI 10.1016/j.eswa.2012.02.148
   Papakostas GA, 2010, STUD FUZZ SOFT COMP, V247, P291
   Papakostas GA, 2008, INT J PATTERN RECOGN, V22, P1461, DOI 10.1142/S0218001408006910
   Parsopoulos KE, 2003, IEEE C EVOL COMPUTAT, V0, P1440
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Pedrycz W, 2014, IEEE T FUZZY SYST, V22, P859, DOI 10.1109/TFUZZ.2013.2277730
   Puerto E, 2019, APPL SOFT COMPUT, V75, P58, DOI 10.1016/j.asoc.2018.10.034
   Renaud O, 2005, IEEE T SYST MAN CY B, V35, P1241, DOI 10.1109/TSMCB.2005.850182
   Salmeron JL, 2019, KNOWL-BASED SYST, V163, P723, DOI 10.1016/j.knosys.2018.09.034
   Salmeron JL, 2019, IEEE T CYBERNETICS, V49, P211, DOI 10.1109/TCYB.2017.2771387
   Salmeron JL, 2016, CONTRIB STAT, V0, PP329, DOI 10.1007/978-3-319-28725-6_24
   Setnes M, 2000, NINTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2000), VOLS 1 AND 2, P700, DOI 10.1109/FUZZY.2000.839117
   Shen F, 2020, KNOWL-BASED SYST, V192, P0, DOI 10.1016/j.knosys.2019.105294
   Song HJJ, 2011, IEEE T FUZZY SYST, V19, P116, DOI 10.1109/TFUZZ.2010.2087383
   Stach W, 2005, FUZZY SET SYST, V153, P371, DOI 10.1016/j.fss.2005.01.009
   Stach W, 2008, IEEE T FUZZY SYST, V16, P61, DOI 10.1109/TFUZZ.2007.902020
   Stach W, 2008, IEEE INT CONF FUZZY, V0, P1977
   Stylios CD, 2000, J INTELL FUZZY SYST, V8, P83
   Ticknor JL, 2013, EXPERT SYST APPL, V40, P5501, DOI 10.1016/j.eswa.2013.04.013
   Tikhonov A.N., 1977, SOLUTIONS ILL POSED, V0, P0
   Vanhoenshoven F, 2020, APPL SOFT COMPUT, V95, P0, DOI 10.1016/j.asoc.2020.106461
   Wang L.-X., 1996, COURSE FUZZY SYSTEMS, V0, P0, DOI DOI 10.5555/248374
   WANG LX, 1992, IEEE T NEURAL NETWOR, V3, P807, DOI 10.1109/72.159070
   Wu K, 2019, IEEE T FUZZY SYST, V0, P0
   Yang SC, 2018, IEEE T FUZZY SYST, V26, P3391, DOI 10.1109/TFUZZ.2018.2831640
   Yang Z, 2019, APPL SOFT COMPUT, V74, P356, DOI 10.1016/j.asoc.2018.10.038
   Yuan KX, 2020, KNOWL-BASED SYST, V206, P0, DOI 10.1016/j.knosys.2020.106359
   Zhang YJ, 2019, IEEE T FUZZY SYST, V27, P16, DOI 10.1109/TFUZZ.2018.2853727
   Zheng G., 1999, J COMPUT INTELL FINA, V7, P0
   Zhou SM, 2009, IEEE T FUZZY SYST, V17, P654, DOI 10.1109/TFUZZ.2008.928597
   Zou XM, 2018, IEEE T FUZZY SYST, V26, P2120, DOI 10.1109/TFUZZ.2017.2764445
NR 82
TC 2
Z9 2
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUL 15
PY 2021
VL 106
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107415
EA APR 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SG9CP
UT WOS:000653738000012
DA 2023-04-26
ER

PT J
AU Zhao, ZY
   Yang, Q
   Ding, XG
   Xing, ZS
AF Zhao, Zhengyong
   Yang, Qi
   Ding, Xiaogang
   Xing, Zisheng
TI Impacts of coarse-resolution soil maps and high-resolution digital-elevation-model-generated attributes on modelling forest soil zinc and copper
SO CANADIAN JOURNAL OF SOIL SCIENCE
LA English
DT Article
DE zinc; copper; soil depth; digital elevation model; artificial neural network
ID artificial neural-networks; heavy-metals; land-use; gis; cu; contamination; solubility; mobility; plants; birch
AB The depth-specific zinc (Zn) and copper (Cu) maps with high resolution (i.e., = 10 m) are important for soil and forest management and conservation. The objective of this study was to assess the effects of easily accessible model inputs, i.e., existing coarse-resolution parent material, pH, and soil texture maps with 1: 1 800 000-2 800 000 scale and nine digital elevation model (DEM)-generated terrain attributes with 10 m resolution, on modelling Zn and Cu distributions of forest soil over a large area (e.g., thousands of km(2)). A total of 511 artificial neural network (ANN) models for each depth (20 cm increments to 100 cm) were built and evaluated by a 10-fold cross-validation with 385 soil profiles from the Yunfu forest, South China, about 4915 km(2) areas. The results indicated that the optimal models for five depths engaged five to seven DEM-generated attributes together with three coarse-resolution soil attributes as inputs, respectively, and accuracies for estimating Zn and Cu varied with R-2 of 0.76-0.85 and relative overall accuracy +/- 10% of 74%-86%. The produced maps showed that DEM-generated sediment delivery ratio, topographic position index (TPI), and aspect were the most important attributes for predicting Cu, but flow length, TPI, and slope were for Zn, which heavily affected Zn and Cu distributions in detail. Boundaries of three coarse-resolution maps were still visible in the generated maps indicated that the maps affected the distributions of Zn and Cu in large scales. Thus, the modelling method, i.e., developing ANN models with k-fold cross-validation, can be used to map high-resolution Zn and Cu over a large area.
C1 [Zhao, Zhengyong; Yang, Qi] Guangxi Univ, Coll Forestry, Guangxi Key Lab Forest Ecol & Conservat, Nanning 530004, Peoples R China.
   [Ding, Xiaogang] Guangdong Acad Forestry, Guangzhou 510520, Guangdong, Peoples R China.
   [Xing, Zisheng] Brandon Res & Dev Ctr, Portage, MB R1N 3V6, Canada.
C3 Guangxi University
RP Ding, XG (corresponding author), Guangdong Acad Forestry, Guangzhou 510520, Guangdong, Peoples R China.
EM 27267152@qq.com
FU Guangxi Natural Science Foundation of China [2018GXNSFAA050135, 2018GXNSFBA138035]; Guangdong Forestry Science and Technology Plan of China [2019-07]
CR Akhtar MK, 2009, HYDROL EARTH SYST SC, V13, P1607, DOI 10.5194/hess-13-1607-2009
   Akhtyrtsev B. P., 1999, POCHVOVEDENIE, V0, P435
   Ambroise B, 1996, WATER RESOUR RES, V32, P2135, DOI 10.1029/95WR03716
   [Anonymous], 2006, P IUFRO PREC FOR S S, V0, P0
   [Anonymous], 2005, SOILS PLANT GROWTH F, V0, P0
   [Anonymous], 1998, CHIN SOIL, V0, P0
   [Anonymous], 2018, FOREST SOIL SURVEY Y, V0, P0
   [Anonymous], 2000, TERRAIN ANAL PRINCIP, V0, P0
   Barak P., 1993, ZINC SOILS PLANTS, V0, P0, DOI DOI 10.1007/978-94-011-0878-2
   Borah P, 2020, CHEMOSPHERE, V254, P0, DOI 10.1016/j.chemosphere.2020.126852
   Boyce MS, 2002, ECOL MODEL, V157, P281, DOI 10.1016/S0304-3800(02)00200-4
   Brady N.C., 2008, NATURE PROPERTIES SO, V14th, P112
   China Soil Survey Office, 1998, CHINESE SOIL, V0, P0
   De Reu J, 2013, GEOMORPHOLOGY, V186, P39, DOI 10.1016/j.geomorph.2012.12.015
   Delen D, 2005, ARTIF INTELL MED, V34, P113, DOI 10.1016/j.artmed.2004.07.002
   Di Baccio D, 2005, NEW PHYTOL, V167, P73, DOI 10.1111/j.1469-8137.2005.01462.x
   Ding XG, 2020, COMPUT ELECTRON AGR, V169, P0, DOI 10.1016/j.compag.2020.105217
   ESRI Inc, 1999, ARCGIS 10 2 HELP, V0, P0
   [方元 FANG Yuan], 2008, 土壤通报 JOURNAL OF SOIL SCIENCE, V39, P647
   Fernandez C, 2003, J SOIL WATER CONSERV, V58, P128
   FERRO V, 1995, HYDROLOG SCI J, V40, P703, DOI 10.1080/02626669509491460
   FIS (Forestry Industry Standard), 1999, 12391999 FIS LYT, V0, P0
   FIS (Forestry Industry Standard), 2019, 31292019 FIS LYT, V0, P0
   Fokin AD, 1999, EURASIAN SOIL SCI+, V32, P109
   Fun M.H., 1996, THESIS OKLAHOMA STAT, V0, P0
   Geron A., 2017, HANDS ON MACHINE LEA, V0, P251
   Guangdong Forestry Survey and Planning Institute, 2014, REP 2014 FOR RES INV, V0, P0
   Guangdong Geological Bureau, 1988, ATL GUANGD GEOL STRU, V0, P0
   Guangdong Soil Survey Team, 1993, ATL GUANGD SOIL, V0, P0
   Hafeez B., 2013, AMERICAN JOURNAL OF EXPERIMENTAL AGRICULTURE, V3, P374
   Hengl T, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0105992
   HEUVELINK GBM, 1992, GEODERMA, V55, P1, DOI 10.1016/0016-7061(92)90002-O
   Hou DY, 2017, ENVIRON POLLUT, V231, P1188, DOI 10.1016/j.envpol.2017.07.021
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   JENSON SK, 1988, PHOTOGRAMM ENG REM S, V54, P1593
   Jiang Y, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-33745-9
   Kaur H, 2019, J PLANT NUTR, V42, P2824, DOI 10.1080/01904167.2019.1659323
   Keller C, 1996, GEODERMA, V71, P263, DOI 10.1016/0016-7061(96)00009-2
   Kopponen P, 2001, ENVIRON POLLUT, V112, P89, DOI 10.1016/S0269-7491(00)00096-8
   Li Q, 2018, HYDROL EARTH SYST SC, V22, P1947, DOI 10.5194/hess-22-1947-2018
   Liu Z., 2013, HUBEI AGR SCI, V52, P65
   Liu Zheng, 1994, SCIENTIA AGRICULTURA SINICA, V27, P30
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   McBratney AB, 2000, GEODERMA, V97, P293, DOI 10.1016/S0016-7061(00)00043-4
   Mico C, 2006, CHEMOSPHERE, V65, P863, DOI 10.1016/j.chemosphere.2006.03.016
   Mikkonen HG, 2018, CHEMOSPHERE, V210, P193, DOI 10.1016/j.chemosphere.2018.06.138
   Murphy PNC, 2007, WETLANDS, V27, P846, DOI 10.1672/0277-5212(2007)27[846:MWACOT]2.0.CO;2
   Naderi A, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-5821-x
   NRIAGU JO, 1988, NATURE, V333, P134, DOI 10.1038/333134a0
   Odor L, 1998, J GEOCHEM EXPLOR, V65, P47, DOI 10.1016/S0375-6742(98)00056-9
   Pajak M, 2017, CHEMOSPHERE, V168, P851, DOI 10.1016/j.chemosphere.2016.10.125
   Pendias A. K., 1992, TRACE ELEMENTS SOIL, V0, P0
   Plouffe G, 2015, INT J LIFE CYCLE ASS, V20, P527, DOI 10.1007/s11367-014-0841-z
   Prasad M. N. V., 1999, HEAVY METAL STRESS P, V0, P207
   Pyo J, 2020, SCI TOTAL ENVIRON, V741, P0, DOI 10.1016/j.scitotenv.2020.140162
   Raisanen ML, 1997, J GEOCHEM EXPLOR, V59, P175, DOI 10.1016/S0375-6742(97)00014-9
   Richardson JB, 2015, SOIL BIOL BIOCHEM, V85, P190, DOI 10.1016/j.soilbio.2015.03.001
   Romkens PFAM, 1998, SOIL SCI, V163, P859, DOI 10.1097/00010694-199811000-00003
   Rousseva SS, 1997, EUR J SOIL SCI, V48, P749, DOI 10.1046/j.1365-2389.1997.00113.x
   SAEED M, 1977, SOIL SCI, V124, P199, DOI 10.1097/00010694-197710000-00002
   Shi X. Z., 2004, SOIL SURVEY HORIZONS, V45, P129
   Sigillito V.G., 1990, NEURAL NETWORK PC TO, V0, P235
   Tang ZH, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7523-z
   The MathWorks Inc, 1984, HELP DOC, V0, P0
   Tsonev T., 2012, EMIR J FOOD AGR, V24, P322, DOI 10.9755/EJFA.V24I6.502509
   Wang J., 1987, SCI GEOGR SIN, V7, P19
   Wang XL, 2015, ENVIRON SCI POLLUT R, V22, P264, DOI 10.1007/s11356-014-3340-7
   White JG, 1997, SOIL SCI SOC AM J, V61, P185, DOI 10.2136/sssaj1997.03615995006100010027x
   Wu L., 2002, PLANT PHYSIOL, V0, P102
   [杨娇 Yang Jiao], 2018, 建筑科学 BUILDING SCIENCE, V34, P112
   Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7
   Zhang L., 2010, ISPRS TC 7 S 100 YEA, V0, P0
   Zhang Xiao-min, 2014, HUANJING KEXUE, V35, P692
   Zhang XY, 2011, ENVIRON EARTH SCI, V64, P1697, DOI 10.1007/s12665-011-0973-4
   Zhang XY, 2008, ENVIRON POLLUT, V156, P1260, DOI 10.1016/j.envpol.2008.03.009
   Zhao ZY, 2020, COMPUT ELECTRON AGR, V169, P0, DOI 10.1016/j.compag.2019.105172
   Zhao ZY, 2013, CAN J SOIL SCI, V93, P193, DOI 10.4141/CJSS2012-016
   Zhao ZY, 2009, COMPUT ELECTRON AGR, V65, P36, DOI 10.1016/j.compag.2008.07.008
   Zinn YL, 2020, CATENA, V185, P0, DOI 10.1016/j.catena.2019.104319
NR 79
TC 2
Z9 2
U1 0
U2 17
PU CANADIAN SCIENCE PUBLISHING
PI OTTAWA
PA 65 AURIGA DR, SUITE 203, OTTAWA, ON K2E 7W6, CANADA
SN 0008-4271
EI 1918-1841
J9 CAN J SOIL SCI
JI Can. J. Soil Sci.
PD JUN 15
PY 2021
VL 101
IS 2
BP 261
EP 276
DI 10.1139/cjss-2020-0103
PG 16
WC Soil Science
SC Agriculture
GA SI6JR
UT WOS:000654934200007
DA 2023-04-26
ER

PT J
AU Kusuma, SS
   Arjasakusuma, S
   Rafif, R
   Saringatin, S
   Wicaksono, P
   Aziz, AA
AF Kusuma, Sandiaga Swahyu
   Arjasakusuma, Sanjiwana
   Rafif, Raihan
   Saringatin, Siti
   Wicaksono, Pramaditya
   Aziz, Ammar Abdul
TI Assessment of Image Segmentation and Deep Learning for Mapping Paddy Fields Using Worldview-3 in Magelang, Central Java Provinces, Indonesia
SO SEVENTH GEOINFORMATION SCIENCE SYMPOSIUM 2021
LA English
DT Proceedings Paper
DE Random Forests; Extreme Gradient Boosting; Convolutional Neural Network; Mean-Shift
AB Paddy fields are complex land-use entities with various surface covers depending on the timing of the planting stages. Therefore, the best practice to map paddy fields using remote sensing has benefited from the availability of multi-temporal data which were used to characterize the phenology related to the paddy fields. However, this practice may require more RS data to be obtained and processed. Other mapping methods by capitalizing the spatial configuration, such as image segmentation in Object-Based Image Analysis (OBIA) and object recognition in Deep Learning using ConvolutionalNeural Network (CNN) architecture has been used in the mapping application. This study aims to assess the accuracy from using mean-shift image segmentation and Random Forests and Extreme Gradient Boosting as the classifiers, with the accuracy from simple CNN architecture, by using Worldview-3 (WV3) full-spectrum image (16 bands). The image segmentation and deep learning analysis were conducted by using 16-bands from the WV3 image and classified by using RF and XGB, and CNN. The results showed that RF was able to identify the paddy fields with an accuracy of 88.09 % (User's accuracy (UA)) and 81.61 % (Producer's accuracy(PA)), while XGB produced an accuracy of 85.71 % (User's accuracy (UA)) and 82.44 % (Producer's accuracy (PA)), respectively. While CNN produced the accuracies of 49.5 % (PA), 96.3 % (UA) and 82.9 % (OA). The lower producer's accuracy indicated the higher omission error where more paddy fields were classified as non-paddy fields. CNN produced promising accuracy results for identifying paddy field tiles with 82.9 % accuracy without using data augmentation, although it will be needed to increase the accuracy and more complex CNN architecture such as U-net is needed to determine the boundary of the mapped objects.
C1 [Kusuma, Sandiaga Swahyu; Arjasakusuma, Sanjiwana; Rafif, Raihan; Saringatin, Siti; Wicaksono, Pramaditya] Univ Gadjah Mada, Dept Geog Informat Sci, Fac Geog, Yogyakarta, Indonesia.
   [Aziz, Ammar Abdul] Univ Queensland, Brisbane, Qld, Australia.
C3 Gadjah Mada University; University of Queensland
RP Kusuma, SS (corresponding author), Univ Gadjah Mada, Dept Geog Informat Sci, Fac Geog, Yogyakarta, Indonesia.
FU [PTNBH/2021];  [1637/UN1/DITLIT/DIT-LIT/PT/2021]
CR Arjasakusuma S, 2021, IOP C SER EARTH ENV, V686, P0, DOI 10.1088/1755-1315/686/1/012053
   Arjasakusuma S., 1900, V17, V0, P0
   Arjasakusuma S., 2017, GEOPLANNING J GEOMAT, V4, P187
   Arjasakusuma S, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9110663
   Bashir A., 2019, JURNAL EKONOMI PEMBA, V19, P172, DOI 10.23917/jep.v19i2.5939
   Bian F., 2013, GEO INF RES MAN SUST, V0, P0
   Breiman L., 2001, MACH LEARN, V45, P5
   Chen T., 2019, PACKAGE XGBOOST R VE, V0, P90
   Ding H, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13051021
   Gong H, 2019, MED PHYS, V46, P2052, DOI 10.1002/mp.13500
   Grizonnet M., 2017, OPEN GEOSPATIAL DATA, V2, P15, DOI 10.1186/S40965-017-0031-6
   Hijmans R.J., 2015, R PACKAGE, V734, P0
   Kattenborn T, 2021, ISPRS J PHOTOGRAMM, V173, P24, DOI 10.1016/j.isprsjprs.2020.12.010
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Panuju D. R., 2013, JOURNAL OF THE SAUDI SOCIETY OF AGRICULTURAL SCIENCES, V12, P27, DOI 10.1016/j.jssas.2012.05.002
   Saptomo SK, 2009, PADDY WATER ENVIRON, V7, P341, DOI 10.1007/s10333-009-0184-8
   Widyantia A., 2014, JOURNAL OF ISSAAS (INTERNATIONAL SOCIETY FOR SOUTHEAST ASIAN AGRICULTURAL SCIENCES), V20, P93
   Zhao RK, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su13020503
NR 18
TC 0
Z9 0
U1 1
U2 1
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
J9 PROC SPIE
PD JUN 15
PY 2021
VL 12082
IS 
BP 
EP 
DI 10.1117/12.2619502
PG 9
WC Environmental Sciences; Geography, Physical; Optics
SC Environmental Sciences & Ecology; Physical Geography; Optics
GA BT1FN
UT WOS:000797356000006
DA 2023-04-26
ER

PT J
AU Zhang, Z
   Song, XY
AF Zhang, Zhe
   Song, Xiaoyu
TI Characterizing the Impact of Temperature on Clay-Water Contact Angle in Geomaterials during Extreme Events by Deep Learning Enhanced Method
SO GEO-EXTREME 2021: INFRASTRUCTURE RESILIENCE, BIG DATA, AND RISK
LA English
DT Proceedings Paper
ID robust normal estimation; unsaturated soils
AB For unsaturated soils, the reduction of matric suction caused by climate change (global warming) or extreme events (rainfall and wildfire) can potentially trigger landslides. It is well known that temperature can impact the strength of unsaturated soils by changing capillary pressure. A key parameter to determine capillary pressure in unsaturated soils is the contact angle between clay and water (e.g., through the Young-Laplace equation). In this paper, we conduct a series of molecular dynamics simulations of a clay-water model to investigate the impact of temperature on the clay-water contact angle. The spatial location of individual water molecular is derived from the coordinate of the molecule's center-of-mass. A numerical approach is adopted to determine the contact angle by treating the water droplet as a three-dimensional point cloud. For each molecule, we fit a tangent plane to the surface spanned by its k-nearest neighbors using the covariance matrix method. The normal vector of the planar surface is used to derive the contact angle. For implementation, we enhance the covariance matrix method by a deep learning algorithm based on the Hough transform, a shape feature extraction technique by a voting procedure. Through the Hough transform, all the normal vectors are mapped into a spherical accumulator space (Hough space) divided by many bins of nearly the same area. Each bin corresponds to a small range of normal. The voted sphere accumulator is then transformed to a square image-accumulator, as the input of a convolutional neural network. The output of the convolutional neural network is two angles representing the normal direction in spherical coordinate system. The numerical results have demonstrated that the deep learning enhanced method is robust in characterizing variations of the contact angle between clay water at elevated temperature. It is expected the results can shed some light on interpreting unsaturated soil slope failures triggered by environmental temperature increase during extreme events.
C1 [Zhang, Zhe; Song, Xiaoyu] Univ Florida, Engn Sch Sustainable Infrastruct & Environm, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Zhang, Z (corresponding author), Univ Florida, Engn Sch Sustainable Infrastruct & Environm, Gainesville, FL 32611 USA.
EM xysong@ufl.edu
CR Blake TD, 1997, LANGMUIR, V13, P2164, DOI 10.1021/la962004g
   Borrmann D, 2011, 3D RES, V2, P0, DOI 10.1007/3DRes.02(2011)3
   Boulch A, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12983
   Boulch A, 2012, COMPUT GRAPH FORUM, V31, P1765, DOI 10.1111/j.1467-8659.2012.03181.x
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Liang LX, 2016, J NAT GAS SCI ENG, V33, P1107, DOI 10.1016/j.jngse.2016.05.024
   Likos WJ, 2004, J ENG MECH-ASCE, V130, P646, DOI 10.1061/(ASCE)0733-9399(2004)130:6(646)
   Likos WJ., 2019, GEOTECHNICAL FUNDAME, V0, PP209, DOI 10.1007/978
   Liu HL, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep23936
   Lu N., 2013, HILLSLOPE HYDROLOGY, V0, P0
   Lu N, 2004, UNSATURATED SOIL MEC, V0, P0
   Lu N., 2019, GEOTECHNICAL FUNDAME, V0, P357
   Santiso EE, 2013, ENTROPY-SWITZ, V15, P3734, DOI 10.3390/e15093734
   Song X., 2018, 7 INT C UNS SOILS 20, V0, P0
   Song XY, 2019, INT J NUMER ANAL MET, V43, P2129, DOI 10.1002/nag.2944
   Song XY, 2018, INT J NUMER ANAL MET, V42, P1785, DOI 10.1002/nag.2811
   Song XY, 2018, ACTA GEOTECH, V13, P73, DOI 10.1007/s11440-017-0534-4
   Wang KQ, 2020, COMPUT METHOD APPL M, V359, P0, DOI 10.1016/j.cma.2019.112770
NR 18
TC 3
Z9 3
U1 3
U2 5
PU AMER SOC CIVIL ENGINEERS
PI NEW YORK
PA UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA
SN 0895-0563
EI 
J9 GEOTECH SP
PD JUN 15
PY 2021
VL 330
IS 
BP 160
EP 168
DI 
PG 9
WC Engineering, Geological; Geography, Physical; Geosciences, Multidisciplinary
SC Engineering; Physical Geography; Geology
GA BS8SM
UT WOS:000776447900016
DA 2023-04-26
ER

PT J
AU van den Bergh, J
   Chirayath, V
   Li, AL
   Torres-Perez, JL
   Segal-Rozenhaimer, M
AF van den Bergh, Jarrett
   Chirayath, Ved
   Li, Alan
   Torres-Perez, Juan L.
   Segal-Rozenhaimer, Michal
TI NeMO-Net - Gamifying 3D Labeling of Multi-Modal Reference Datasets to Support Automated Marine Habitat Mapping
SO FRONTIERS IN MARINE SCIENCE
LA English
DT Article
DE coral reefs; remote sensing; machine learning; citizen science; fluid lensing; video game; active learning; 3D classification
ID coral-reefs
AB NASA NeMO-Net, The Neural Multimodal Observation and Training Network for global coral reef assessment, is a convolutional neural network (CNN) that generates benthic habitat maps of coral reefs and other shallow marine ecosystems. To segment and classify imagery accurately, CNNs require curated training datasets of considerable volume and accuracy. Here, we present a citizen science approach to create these training datasets through a novel 3D classification game for mobile and desktop devices. Leveraging citizen science, the NeMO-Net video game generates high-resolution 3D benthic habitat labels at the subcentimeter to meter scales. The video game trains users to accurately identify benthic categories and semantically segment 3D scenes captured using NASA airborne fluid lensing, the first remote sensing technology capable of mitigating ocean wave distortions, as well as in situ 3D photogrammetry and 2D satellite remote sensing. An active learning framework is used in the game to allow users to rate and edit other user classifications, dynamically improving segmentation accuracy. Refined and aggregated data labels from the game are used to train NeMO-Net's supercomputer-based CNN to autonomously map shallow marine systems and augment satellite habitat mapping accuracy in these regions. We share the NeMO-Net game approach to user training and retention, outline the 3D labeling technique developed to accurately label complex coral reef imagery, and present preliminary results from over 70,000 user classifications. To overcome the inherent variability of citizen science, we analyze criteria and metrics for evaluating and filtering user data. Finally, we examine how future citizen science and machine learning approaches might benefit from label training in 3D space using an active learning framework. Within 7 months of launch, NeMO-Net has reached over 300 million people globally and directly engaged communities in coral reef mapping and conservation through ongoing scientific field campaigns, uninhibited by geography, language, or physical ability. As more user data are fed into NeMO-Net's CNN, it will produce the first shallow-marine habitat mapping products trained on 3D subcm-scale label data and merged with m-scale satellite data that could be applied globally when data sets are available.
C1 [van den Bergh, Jarrett; Chirayath, Ved; Li, Alan; Torres-Perez, Juan L.; Segal-Rozenhaimer, Michal] NASA Silicon Valley Ames Res Ctr, NASA Lab Adv Sensing Earth Sci Div, Mountain View, CA 94035 USA.
   [Segal-Rozenhaimer, Michal] Tel Aviv Univ, Potter Sch Environm & Earth Sci, Dept Geophys, Tel Aviv, Israel.
C3 Tel Aviv University
RP van den Bergh, J (corresponding author), NASA Silicon Valley Ames Res Ctr, NASA Lab Adv Sensing Earth Sci Div, Mountain View, CA 94035 USA.
EM jarrett.s.vandenbergh@nasa.gov
FU NASA Earth Science Technology Office (ESTO) grant [ATI-QRS-140010]; NASA 2015 Center Innovation Fund (CIF) grant; NASA 2016 Center Innovation Fund (CIF) grant; NASA 2017 Center Innovation Fund (CIF) grant; NASA ESTO Advanced Information Systems Technology (AIST) grant [AISTQRS-16-0004, AIST-16-0031]; NASA's Biodiversity & Ecological Forecasting [AIST-16-0046]; 2018 NASA Reimbursable Space Act; 2019 NASA Reimbursable Space Act; University of Guam
CR Allen Coral Atlas, 2020, IM MAPS MON WORLDS T, V0, P0
   [Anonymous], 2007, WATER AIR SOIL POLL, V0, P0, DOI DOI 10.1007/s11270-007-9372-6
   Beijbom O, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0130312
   Bellwood DR, 2004, NATURE, V429, P827, DOI 10.1038/nature02691
   Burns JHR, 2015, PEERJ, V3, P0, DOI 10.7717/peerj.1077
   Chirayath V., 2020, P IEEE IGARSS AN CTR, V0, P0
   Chirayath V., 2019, SYSTEM METHOD IMAGIN, V0, P0
   Chirayath V., 2016, FLUID LENSING APPL R, V0, P0
   Chirayath V, 2019, REMOTE SENS ENVIRON, V235, P0, DOI 10.1016/j.rse.2019.111475
   Chirayath V, 2019, FRONT MAR SCI, V6, P0, DOI 10.3389/fmars.2019.00521
   Chirayath V, 2016, AQUAT CONSERV, V26, P237, DOI 10.1002/aqc.2654
   Cox J., 2014, P 15 INT C INT GAM S, V0, P0
   Gierach M., 2020, P AGU OC SCI M WASH, V0, P0
   Goatley CHR, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0027307
   Hanrahan P., 1990, COMPUTER GRAPHICS, V24, P215, DOI 10.1145/97880.97903
   Hart J.C., 2004, ACM SIGGRAPH 2004 PA, V0, P0
   Hillaire S., 2018, REAL TIME RENDERING, V4th, P0
   HUGHES TP, 1994, SCIENCE, V265, P1547, DOI 10.1126/science.265.5178.1547
   King A, 2018, IEEE COMPUT SOC CONF, V0, PP1475, DOI 10.1109/CVPRW.2018.00188
   Kleffner R, 2017, BIOINFORMATICS, V33, P2765, DOI 10.1093/bioinformatics/btx283
   Kohler KE, 2006, COMPUT GEOSCI-UK, V32, P1259, DOI 10.1016/j.cageo.2005.11.009
   Kuchner MJ, 2016, ASTROPHYS J, V830, P0, DOI 10.3847/0004-637X/830/2/84
   Lintott CJ, 2008, MON NOT R ASTRON SOC, V389, P1179, DOI 10.1111/j.1365-2966.2008.13689.x
   Lozada-Misa P., 2017, ANAL BENTH SURV IM V, V0, P0, DOI DOI 10.7289/v5/ar-pifsc-h-17-02
   Lyons MB, 2020, REMOTE SENS ECOL CON, V6, P557, DOI 10.1002/rse2.157
   Maynard JA, 2015, BIOL CONSERV, V192, P109, DOI 10.1016/j.biocon.2015.09.001
   Oliver T., 2019, PROCESSING PHOTOMOSA, V0, P0
   Purkis SJ, 2019, CORAL REEFS, V38, P467, DOI 10.1007/s00338-019-01802-y
   Purkis SJ, 2018, ANNU REV MAR SCI, V10, P149, DOI 10.1146/annurev-marine-121916-063249
   Roelfsema CM, 2021, FRONT MAR SCI, V8, P0, DOI 10.3389/fmars.2021.643381
   Silver A, 2019, NATURE, V570, P545, DOI 10.1038/d41586-019-01988-9
   Sorooshian S., 2020, P ACM SIGKDD INT C K, V0, P0
   Swanson A, 2015, SCI DATA, V2, P0, DOI 10.1038/sdata.2015.26
   Tavares F., 2020, WHAT IS FLUID LENSIN, V0, P0
NR 36
TC 6
Z9 6
U1 3
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 2296-7745
J9 FRONT MAR SCI
JI Front. Mar. Sci.
PD APR 21
PY 2021
VL 8
IS 
BP 
EP 
DI 10.3389/fmars.2021.645408
PG 17
WC Environmental Sciences; Marine & Freshwater Biology
SC Environmental Sciences & Ecology; Marine & Freshwater Biology
GA RW9VL
UT WOS:000646867800001
DA 2023-04-26
ER

PT J
AU Zhou, L
AF Zhou, Lin
TI Analysis of Psychological and Emotional Tendency Based on Brain Functional Imaging and Deep Learning
SO DISCRETE DYNAMICS IN NATURE AND SOCIETY
LA English
DT Article
ID eeg signal; recognition
AB When facing various pressures, human beings will have different degrees of bad psychological emotions, especially depression and anxiety. How to effectively obtain psychological data signals and use advanced intelligent technology to identify and make decisions is a research hotspot in psychology and computer science. Therefore, a personal emotional tendency analysis method based on brain functional imaging and deep learning is proposed. Firstly, the EEG forward model is established according to functional magnetic resonance imaging (fMRI), and the transfer matrix from the signal source at the cerebral cortex to the head surface electrode is obtained. Therefore, the activation results of fMRI emotional experiment can be mapped to the three-layer head model to obtain the EEG topographic map reflecting the degree of emotional correlation. Then, combining data enhancement (Mixup) with three-dimensional convolutional neural network (3D-CNN), an emotion-related EEG topographic map classification method based on M-3DCNN is proposed. Mixup is used to generate virtual data, the original data and virtual data are used to train the network together, the number of training samples is expanded, the overfitting phenomenon of 3D-CNN is alleviated, and 3D-CNN is used for feature extraction and classification. Experimental data analysis shows that, compared with traditional methods, the proposed method can retain emotion related EEG signals to a greater extent and obtain a higher accuracy of emotion five classifications under the same feature dimension.
C1 [Zhou, Lin] Shenyang Sport Univ, Students Affairs Div, Shenyang 110102, Peoples R China.
C3 Shenyang Sport University
RP Zhou, L (corresponding author), Shenyang Sport Univ, Students Affairs Div, Shenyang 110102, Peoples R China.
EM zhoul@syty.edu.cn
CR Albornoz EM, 2017, IEEE T AFFECT COMPUT, V8, P43, DOI 10.1109/TAFFC.2015.2503757
   Antipov G, 2017, PATTERN RECOGN, V72, P15, DOI 10.1016/j.patcog.2017.06.031
   Bao S, 2020, OPT REV, V27, P475, DOI 10.1007/s10043-020-00614-8
   Berggren S, 2018, DEV NEUROREHABIL, V21, P141, DOI 10.1080/17518423.2017.1305004
   Cai JH, 2020, IET COMPUT VIS, V14, P634, DOI 10.1049/iet-cvi.2020.0023
   Castillo JC, 2016, COGN COMPUT, V8, P357, DOI 10.1007/s12559-016-9383-y
   Chandra BS, 2019, IEEE T BIO-MED ENG, V66, P710, DOI 10.1109/TBME.2018.2854899
   Elngar AA, 2020, OPEN COMPUT SCI, V10, P17, DOI 10.1515/comp-2020-0003
   Guo WQ, 2016, CHIN CONT DECIS CONF, V0, PP131, DOI 10.1109/CCDC.2016.7530968
   Jenke R., 2017, IEEE T AFFECT COMPUT, V5, P339
   Kavakiotis I, 2017, COMPUT STRUCT BIOTEC, V15, P104, DOI 10.1016/j.csbj.2016.12.005
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kaya H, 2016, J MULTIMODAL USER IN, V10, P139, DOI 10.1007/s12193-015-0175-6
   Kim T, 2020, HUM-CENT COMPUT INFO, V10, P0, DOI 10.1186/s13673-020-00244-8
   Kohli M, 2017, AM J ROENTGENOL, V208, P754, DOI 10.2214/AJR.16.17224
   Lin XK, 2020, APPL INTELL, V50, P2105, DOI 10.1007/s10489-020-01641-3
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Ludi Bai, 2020, PROCEDIA COMPUTER SCIENCE, V174, P364, DOI 10.1016/j.procs.2020.06.100
   Masruroh AH, 2019, PROCEDIA COMPUT SCI, V157, P552, DOI 10.1016/j.procs.2019.09.013
   Mitsukura Y., 2016, J SIGNAL PROCESSING, V20, P1, DOI 10.2299/jsp.20.1
   Pound MP, 2017, GIGASCIENCE, V6, P0, DOI 10.1093/gigascience/gix083
   Raissi M, 2018, J COMPUT PHYS, V357, P125, DOI 10.1016/j.jcp.2017.11.039
   Ravikumar S, 2021, J FIELD ROBOT, V38, P967, DOI 10.1002/rob.22020
   Schlegel K, 2016, BEHAV RES METHODS, V48, P1383, DOI 10.3758/s13428-015-0646-4
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Voyant C, 2017, RENEW ENERG, V105, P569, DOI 10.1016/j.renene.2016.12.095
   Wankhade SB, 2020, INT J UNCERTAIN FUZZ, V28, P153, DOI 10.1142/S0218488520500075
   Xu BH, 2018, IEEE T AFFECT COMPUT, V9, P255, DOI 10.1109/TAFFC.2016.2622690
   Yang RP, 2021, NEURAL NETWORKS, V142, P564, DOI 10.1016/j.neunet.2021.07.018
   Zhao L, 2020, MULTIMED TOOLS APPL, V79, P26683, DOI 10.1007/s11042-020-09259-w
NR 30
TC 1
Z9 1
U1 2
U2 8
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1026-0226
EI 1607-887X
J9 DISCRETE DYN NAT SOC
JI Discrete Dyn. Nat. Soc.
PD NOV 16
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/1272502
PG 9
WC Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences
SC Mathematics; Science & Technology - Other Topics
GA XH4QT
UT WOS:000725421800005
DA 2023-04-26
ER

PT J
AU Silva-Perez, C
   Marino, A
   Lopez-Sanchez, JM
   Cameron, I
AF Silva-Perez, Cristian
   Marino, Armando
   Lopez-Sanchez, Juan M.
   Cameron, Iain
TI Multitemporal Polarimetric SAR Change Detection for Crop Monitoring and Crop Type Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Crops; Covariance matrices; Scattering; Monitoring; Time series analysis; Synthetic aperture radar; Satellites; Agricultural fields; change detection; change matrix (CM); image classification; SAR polarimetry; target dynamics and evolution; time series encoding
ID time-series; rice fields; coherence; images
AB The interpretation of multidimensional synthetic aperture radar (SAR) data often requires expert knowledge. In fact, it requires to simultaneously consider several time series of polarimetric features to understand the physical changes of a target and its temporal evolution. In an effort to characterize the changes over time, multitemporal polarimetric SAR (MTPolSAR) change detection was introduced in the literature. However, existing methods either only exploit intensity of changes or the resulting changed scattering mechanisms are not guaranteed to represent physical changes of the target. This article presents a variation in a previously published change detector based on the difference of covariance matrices that characterize the polarimetric information, allowing for an intuitive representation and characterization of physical changes of a target and its dynamics. We show the results of this method for monitoring growth stages of rice crops and present a novel application of the method for crop type mapping from MT-PolSAR data. We compare its performance with a neural network based classifier that uses time series of PolSAR features derived from a target covariance matrix decomposition as input. Experimental results show that the classification performance of the proposed method and the baseline method are comparable with differences between the two methods in the overall balanced accuracy and the F1-macro metrics of around 2% and 3%, respectively. The method presented here achieves similar classification performances of a traditional PolSAR data classifier while providing additional advantages in terms of interpretability and insights about the physical changes of a target over time.
C1 [Silva-Perez, Cristian; Marino, Armando] Univ Stirling, Dept Nat Sci, Stirling FK9 4LA, Scotland.
   [Lopez-Sanchez, Juan M.] Univ Alicante, Inst Comp Res IUII, Alacant 03690, Spain.
   [Cameron, Iain] Environm Syst Ltd, Aberystwyth SY23 3AH, Dyfed, Wales.
C3 University of Stirling; Universitat d'Alacant
RP Silva-Perez, C (corresponding author), Univ Stirling, Dept Nat Sci, Stirling FK9 4LA, Scotland.
EM c.j.silva.perez@stir.ac.uk; armando.marino@stir.ac.uk; juanma.lopez@ua.es; iain.cameron@envsys.co.uk
FU Project EO4cultivar; U.K. Space Agency; Spanish Ministry of Science and Innovation (State Agency of Research, AEI); European Funds for Regional Development (EFRD) [TEC2017-85244-C2-1-P, PID2020-117303GB-C22]
CR Akbari V, 2016, IEEE T GEOSCI REMOTE, V54, P3953, DOI 10.1109/TGRS.2016.2532320
   Akbari V, 2014, IEEE T GEOSCI REMOTE, V52, P3729, DOI 10.1109/TGRS.2013.2275203
   Alonso A, 2016, METHODS MOL BIOL, V1447, P1, DOI 10.1007/978-1-4939-3746-2_1
   Alonso-Gonzalez A, 2020, IEEE T GEOSCI REMOTE, V58, P7317, DOI 10.1109/TGRS.2020.2981929
   Alonso-Gonzalez A, 2016, INT GEOSCI REMOTE SE, V0, PP325, DOI 10.1109/IGARSS.2016.7729077
   [Anonymous], 2004, UNDERSTANDING SYNTHE, V0, P0
   Antropov O, 2011, IEEE T GEOSCI REMOTE, V49, P3838, DOI 10.1109/TGRS.2011.2138146
   Bauer-Marschallingere B, 2019, IEEE T GEOSCI REMOTE, V57, P520, DOI 10.1109/TGRS.2018.2858004
   Cloude S.R., 2009, POLARISATION APPL RE, V0, P0
   Cloude SR, 1997, IEEE T GEOSCI REMOTE, V35, P68, DOI 10.1109/36.551935
   Cloude SR, 1996, IEEE T GEOSCI REMOTE, V34, P498, DOI 10.1109/36.485127
   Conradsen K, 2003, IEEE T GEOSCI REMOTE, V41, P4, DOI 10.1109/TGRS.2002.808066
   Conradsen K, 2016, IEEE T GEOSCI REMOTE, V54, P3007, DOI 10.1109/TGRS.2015.2510160
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jacob AW, 2020, IEEE J-STARS, V13, P535, DOI 10.1109/JSTARS.2019.2958847
   Jong-Sen Lee E.P., 2017, POLARIMETRIC RADAR I, V0, P0
   Kersten P., 2005, COMP CHANGE DETECTIO, V0, P0
   Liu M, 2014, IEEE T GEOSCI REMOTE, V52, P7483, DOI 10.1109/TGRS.2014.2310451
   Lopez-Sanchez JM, 2017, REMOTE SENS ENVIRON, V192, P30, DOI 10.1016/j.rse.2017.02.004
   Lopez-Sanchez JM, 2014, IEEE T GEOSCI REMOTE, V52, P2977, DOI 10.1109/TGRS.2013.2268319
   Marino A, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3113182
   Marino A, 2017, INT GEOSCI REMOTE SE, V0, P5315
   Marino A, 2014, IEEE T GEOSCI REMOTE, V52, P4781, DOI 10.1109/TGRS.2013.2284510
   Marino A, 2012, IEEE T GEOSCI REMOTE, V50, P3787, DOI 10.1109/TGRS.2012.2185703
   McNairn H, 2016, REMOTE SENS DIGIT IM, V20, P317, DOI 10.1007/978-3-319-47037-5_15
   McNairn H, 2009, IEEE T GEOSCI REMOTE, V47, P3981, DOI 10.1109/TGRS.2009.2026052
   Mestre-Quereda A, 2020, IEEE J-STARS, V13, P4070, DOI 10.1109/JSTARS.2020.3008096
   Nascimento ADC, 2019, IEEE T GEOSCI REMOTE, V57, P1380, DOI 10.1109/TGRS.2018.2866367
   Nielsen AA, 2020, IEEE GEOSCI REMOTE S, V17, P242, DOI 10.1109/LGRS.2019.2918636
   Nielsen AA, 2017, CAN J REMOTE SENS, V43, P582, DOI 10.1080/07038992.2017.1394182
   Nielsen AA, 2020, IEEE GEOSCI REMOTE S, V17, P1727, DOI 10.1109/LGRS.2019.2952202
   NOVAK LM, 1989, IEEE T AERO ELEC SYS, V25, P150, DOI 10.1109/7.18677
   Santos MS, 2018, IEEE COMPUT INTELL M, V13, P59, DOI 10.1109/MCI.2018.2866730
   Silva C, 2018, INT GEOSCI REMOTE SE, V0, P6619
   Skriver H, 2011, IEEE J-STARS, V4, P423, DOI 10.1109/JSTARS.2011.2106198
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Le TT, 2015, ISPRS J PHOTOGRAMM, V107, P64, DOI 10.1016/j.isprsjprs.2015.02.008
   Le TT, 2014, IEEE GEOSCI REMOTE S, V11, P1826, DOI 10.1109/LGRS.2014.2311663
NR 38
TC 7
Z9 7
U1 4
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 12361
EP 12374
DI 10.1109/JSTARS.2021.3130186
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XO8GN
UT WOS:000730417100007
DA 2023-04-26
ER

PT J
AU Yoshimori, A
AF Yoshimori, Atsushi
TI Prediction of Molecular Properties Using Molecular Topographic Map
SO MOLECULES
LA English
DT Article
DE generative topographic mapping; convolutional neural network; property prediction; data augmentation
ID feature-selection; adme property; classification; descriptors; regression
AB Prediction of molecular properties plays a critical role towards rational drug design. In this study, the Molecular Topographic Map (MTM) is proposed, which is a two-dimensional (2D) map that can be used to represent a molecule. An MTM is generated from the atomic features set of a molecule using generative topographic mapping and is then used as input data for analyzing structure-property/activity relationships. In the visualization and classification of 20 amino acids, differences of the amino acids can be visually confirmed from and revealed by hierarchical clustering with a similarity matrix of their MTMs. The prediction of molecular properties was performed on the basis of convolutional neural networks using MTMs as input data. The performance of the predictive models using MTM was found to be equal to or better than that using Morgan fingerprint or MACCS keys. Furthermore, data augmentation of MTMs using mixup has improved the prediction performance. Since molecules converted to MTMs can be treated like 2D images, they can be easily used with existing neural networks for image recognition and related technologies. MTM can be effectively utilized to predict molecular properties of small molecules to aid drug discovery research.
C1 [Yoshimori, Atsushi] Inst Theoret Med Inc, 26-1,Muraoka Higashi 2 Chome, Fujisawa, Kanagawa 2510012, Japan.
RP Yoshimori, A (corresponding author), Inst Theoret Med Inc, 26-1,Muraoka Higashi 2 Chome, Fujisawa, Kanagawa 2510012, Japan.
EM yoshimori@itmol.com
CR Abadi M., 2016, TENSORFLOW LARGE SCA, V0, P0
   [Anonymous], 2016, INT J ADV RES BIOL S, V0, P0
   Awale M, 2020, J CHEM INF MODEL, V60, P2903, DOI 10.1021/acs.jcim.0c00269
   Bajorath J, 2021, FUTUR SCI OA, V7, P0, DOI 10.2144/fsoa-2021-0030
   Bento AP, 2014, NUCLEIC ACIDS RES, V42, PD1083, DOI 10.1093/nar/gkt1031
   Bhhatarai B, 2019, NAT MATER, V18, P418, DOI 10.1038/s41563-019-0332-5
   Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5
   Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953
   Chen HM, 2018, DRUG DISCOV TODAY, V23, P1241, DOI 10.1016/j.drudis.2018.01.039
   Chithrananda S., 2020, ARXIV, V0, P0
   Devlin J., 2018, P N AM CHAPT ASS COM, V1, P0
   Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r
   Gawehn E, 2016, MOL INFORM, V35, P3, DOI 10.1002/minf.201501008
   Glen RC, 2006, IDRUGS, V9, P199
   Goh G. B., 2017, CHEMCEPTION DEEP NEU, V0, P0
   Gomez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572
   Heikamp K, 2011, J CHEM INF MODEL, V51, P1831, DOI 10.1021/ci200199u
   Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Kearnes S, 2016, J COMPUT AID MOL DES, V30, P595, DOI 10.1007/s10822-016-9938-8
   KIREEV DB, 1995, J CHEM INF COMP SCI, V35, P175, DOI 10.1021/ci00024a001
   Lavecchia A, 2019, DRUG DISCOV TODAY, V24, P2017, DOI 10.1016/j.drudis.2019.07.006
   Lombardo F, 2017, J MED CHEM, V60, P9097, DOI 10.1021/acs.jmedchem.7b00487
   Ma JS, 2015, J CHEM INF MODEL, V55, P263, DOI 10.1021/ci500747n
   Matsuzaka Y, 2020, MOLECULES, V25, P0, DOI 10.3390/molecules25122764
   Ren YY, 2016, SAR QSAR ENVIRON RES, V27, P721, DOI 10.1080/1062936X.2016.1229691
   Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, V0, PP618, DOI 10.1109/ICCV.2017.74
   Setiawan W., 2020, COMPUT ELECT CONTROL, V18, P1382
   Shen Jie, 2019, DRUG DISCOV TODAY TECHNOL, V32-33, P29, DOI 10.1016/j.ddtec.2020.05.001
   Shen J, 2010, J CHEM INF MODEL, V50, P1034, DOI 10.1021/ci100104j
   Sheridan RP, 2016, J CHEM INF MODEL, V56, P2353, DOI 10.1021/acs.jcim.6b00591
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Stahura FL, 2002, J CHEM INF COMP SCI, V42, P550, DOI 10.1021/ci010243q
   Sun MY, 2020, BRIEF BIOINFORM, V21, P919, DOI 10.1093/bib/bbz042
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Taherkhani A, 2018, NEUROCOMPUTING, V322, P22, DOI 10.1016/j.neucom.2018.09.040
   Uesawa Y, 2018, BIOORG MED CHEM LETT, V28, P3400, DOI 10.1016/j.bmcl.2018.08.032
   van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032
   Wang NN, 2016, J CHEM INF MODEL, V56, P763, DOI 10.1021/acs.jcim.5b00642
   Wang S, 2019, ACM-BCB19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, V0, P429, DOI 10.1145/3307339.3342186
   Wang XF, 2019, J CHEM INF MODEL, V59, P3817, DOI 10.1021/acs.jcim.9b00410
   WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005
   Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a
   Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195
   Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h
   Yang K, 2019, J CHEM INF MODEL, V59, P3370, DOI 10.1021/acs.jcim.9b00237
   Zhang H., 2018, 6 INT C LEARNING REP, V0, P0
   Zhang J, 2019, J CHEM INF MODEL, V59, P4150, DOI 10.1021/acs.jcim.9b00633
   Zhong SF, 2021, CHEM ENG J, V408, P0, DOI 10.1016/j.cej.2020.127998
NR 50
TC 3
Z9 3
U1 7
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1420-3049
J9 MOLECULES
JI Molecules
PD AUG 15
PY 2021
VL 26
IS 15
BP 
EP 
DI 10.3390/molecules26154475
PG 15
WC Biochemistry & Molecular Biology; Chemistry, Multidisciplinary
SC Biochemistry & Molecular Biology; Chemistry
GA TW1HO
UT WOS:000682160700001
PM 34361624
DA 2023-04-26
ER

PT J
AU Zhang, WY
   Chen, ZJ
   Zhang, H
   Su, GN
   Chang, R
   Chen, L
   Zhu, Y
   Cao, QF
   Zhou, CJ
   Wang, Y
   Yang, PZ
AF Zhang, Wanyun
   Chen, Zhijun
   Zhang, Han
   Su, Guannan
   Chang, Rui
   Chen, Lin
   Zhu, Ying
   Cao, Qingfeng
   Zhou, Chunjiang
   Wang, Yao
   Yang, Peizeng
TI Detection of Fuchs' Uveitis Syndrome From Slit-Lamp Images Using Deep Convolutional Neural Networks in a Chinese Population
SO FRONTIERS IN CELL AND DEVELOPMENTAL BIOLOGY
LA English
DT Article
DE Fuchs' uveitis syndrome; diffuse iris depigmentation; slit-lamp images; deep convolutional neural model; deep learning
ID heterochromic iridocyclitis; macular degeneration; automated detection; clinical-features
AB Fuchs' uveitis syndrome (FUS) is one of the most under- or misdiagnosed uveitis entities. Many undiagnosed FUS patients are unnecessarily overtreated with anti-inflammatory drugs, which may lead to serious complications. To offer assistance for ophthalmologists in the screening and diagnosis of FUS, we developed seven deep convolutional neural networks (DCNNs) to detect FUS using slit-lamp images. We also proposed a new optimized model with a mixed "attention" module to improve test accuracy. In the same independent set, we compared the performance between these DCNNs and ophthalmologists in detecting FUS. Seven different network models, including Xception, Resnet50, SE-Resnet50, ResNext50, SE-ResNext50, ST-ResNext50, and SET-ResNext50, were used to predict FUS automatically with the area under the receiver operating characteristic curves (AUCs) that ranged from 0.951 to 0.977. Our proposed SET-ResNext50 model (accuracy = 0.930; Precision = 0.918; Recall = 0.923; F1 measure = 0.920) with an AUC of 0.977 consistently outperformed the other networks and outperformed general ophthalmologists by a large margin. Heat-map visualizations of the SET-ResNext50 were provided to identify the target areas in the slit-lamp images. In conclusion, we confirmed that a trained classification method based on DCNNs achieved high effectiveness in distinguishing FUS from other forms of anterior uveitis. The performance of the DCNNs was better than that of general ophthalmologists and could be of value in the diagnosis of FUS.
C1 [Zhang, Wanyun; Chen, Zhijun; Su, Guannan; Chang, Rui; Chen, Lin; Zhu, Ying; Cao, Qingfeng; Zhou, Chunjiang; Wang, Yao; Yang, Peizeng] Chongqing Med Univ, Chongqing Key Lab Ophthalmol, Affiliated Hosp 1, Chongqing, Peoples R China.
   [Zhang, Wanyun; Chen, Zhijun; Su, Guannan; Chang, Rui; Chen, Lin; Zhu, Ying; Cao, Qingfeng; Zhou, Chunjiang; Wang, Yao; Yang, Peizeng] Chongqing Eye Inst, Natl Clin Res Ctr Ocular Dis, Chongqing Branch, Chongqing, Peoples R China.
   [Zhang, Han] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
C3 Chongqing Medical University; Harbin Institute of Technology
RP Yang, PZ (corresponding author), Chongqing Med Univ, Chongqing Key Lab Ophthalmol, Affiliated Hosp 1, Chongqing, Peoples R China.; Yang, PZ (corresponding author), Chongqing Eye Inst, Natl Clin Res Ctr Ocular Dis, Chongqing Branch, Chongqing, Peoples R China.
EM peizengycmu@126.com
FU Chongqing Outstanding Scientists Project (2019); Chongqing Key Laboratory of Ophthalmology (CSTC) [2008CA5003]; Chongqing Science and Technology Platform and Base Construction Program [cstc2014pt-sy10002]; Chongqing Chief Medical Scientist Project (2018)
CR Abano JM, 2017, OCUL IMMUNOL INFLAMM, V25, PS75, DOI 10.1080/09273948.2017.1335755
   Accorinti M, 2016, J OPHTHALMOL, V2016, P0, DOI 10.1155/2016/1458624
   Arellanes-Garcia L, 2002, OCUL IMMUNOL INFLAMM, V10, P125, DOI 10.1076/ocii.10.2.125.13976
   Bonfioli Adriana A, 2005, SEMIN OPHTHALMOL, V20, P143, DOI 10.1080/08820530500231995
   Burlina PM, 2017, JAMA OPHTHALMOL, V135, P1170, DOI 10.1001/jamaophthalmol.2017.3782
   Carter JV, 2016, SURGERY, V159, P1638, DOI 10.1016/j.surg.2015.12.029
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Grassmann F, 2018, OPHTHALMOLOGY, V125, P1410, DOI 10.1016/j.ophtha.2018.02.037
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hogarty DT, 2019, CLIN EXP OPHTHALMOL, V47, P128, DOI 10.1111/ceo.13381
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Jiang JW, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0201142
   Kapoor R, 2019, SURV OPHTHALMOL, V64, P233, DOI 10.1016/j.survophthal.2018.09.002
   Kazokoglu H, 2008, OPHTHAL EPIDEMIOL, V15, P285, DOI 10.1080/09286580802262821
   LAHEY E, 1991, DOC OPHTHALMOL, V78, P225, DOI 10.1007/BF00165685
   Max J., 2015, ADV NEURAL INF PROCE, V28, P2017
   Menezo V, 2005, AM J OPHTHALMOL, V139, P988, DOI 10.1016/j.ajo.2005.01.029
   Mohamed Quresh, 2005, CURR OPIN OPHTHALMOL, V16, P356, DOI 10.1097/01.icu.0000187056.29563.8d
   Norrsell K, 2008, ACTA OPHTHALMOL, V86, P58, DOI 10.1111/j.1600-0420.2007.00990.x
   Ramanishka V, 2017, PROC CVPR IEEE, V0, PP3135, DOI 10.1109/CVPR.2017.334
   Russakoff DB, 2019, INVEST OPHTH VIS SCI, V60, P712, DOI 10.1167/iovs.18-25325
   Schlegl T, 2018, OPHTHALMOLOGY, V125, P549, DOI 10.1016/j.ophtha.2017.10.031
   Sun Y, 2020, SURV OPHTHALMOL, V65, P133, DOI 10.1016/j.survophthal.2019.10.003
   TABBUT BR, 1988, ARCH OPHTHALMOL-CHIC, V106, P1688, DOI 10.1001/archopht.1988.01060140860027
   Tandon M, 2012, OCUL IMMUNOL INFLAMM, V20, P429, DOI 10.3109/09273948.2012.723113
   Tappeiner C, 2015, GRAEF ARCH CLIN EXP, V253, P1169, DOI 10.1007/s00417-015-2960-z
   Ting DSW, 2019, PROG RETIN EYE RES, V72, P0, DOI 10.1016/j.preteyeres.2019.04.003
   Touhami S, 2019, INVEST OPHTH VIS SCI, V60, P2399, DOI 10.1167/iovs.18-24597
   Tran T., 2017, P ADV NEURAL INFORM, V0, P2794
   Treder M, 2018, GRAEF ARCH CLIN EXP, V256, P259, DOI 10.1007/s00417-017-3850-3
   Tugal-Tutkun I, 2009, AM J OPHTHALMOL, V148, P510, DOI 10.1016/j.ajo.2009.04.007
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Yang PZ, 2006, OPHTHALMOLOGY, V113, P473, DOI 10.1016/j.ophtha.2005.10.028
   Zhou B, 2016, PROC CVPR IEEE, V0, PP2921, DOI 10.1109/CVPR.2016.319
NR 37
TC 2
Z9 3
U1 2
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-634X
EI 
J9 FRONT CELL DEV BIOL
JI Front. Cell. Dev. Biol.
PD JUN 18
PY 2021
VL 9
IS 
BP 
EP 
DI 10.3389/fcell.2021.684522
PG 8
WC Cell Biology; Developmental Biology
SC Cell Biology; Developmental Biology
GA TC9ER
UT WOS:000668940700001
PM 34222252
DA 2023-04-26
ER

PT J
AU Lee, H
   Lee, K
   Kim, JH
   Na, Y
   Park, J
   Choi, JP
   Hwang, JY
AF Lee, Haeyun
   Lee, Kyungsu
   Kim, Jun Hee
   Na, Younghwan
   Park, Juhum
   Choi, Jihwan P.
   Hwang, Jae Youn
TI Local Similarity Siamese Network for Urban Land Change Detection on Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Feature extraction; Decoding; Training; Network architecture; Task analysis; Deep learning; Change detection; remote sensing; Siamese network; similarity attention
ID attention
AB Change detection is an important task in the field of remote sensing. Various change detection methods based on convolutional neural networks (CNNs) have recently been proposed for remote sensing using satellite or aerial images. However, existing methods allow only the partial use of content information in images during change detection because they adopt simple feature similarity measurements or pixel-level loss functions to construct their network architectures. Therefore, when these methods are applied to complex urban areas, their performance in terms of change detection tends to be limited. In this article, a novel CNN-based change detection approach, referred to as a local similarity Siamese network (LSS-Net), with a cosine similarity measurement, was proposed for better urban land change detection in remote sensing images. To use content information on two sequential images, a new change attention map-based content loss function was developed in this study. In addition, to enhance the performance of the LSS-Net in terms of change detection, a suitable feature similarity measurement method, incorporated into a local similarity attention module, was determined through systemic experiments. To verify the change detection performance of the LSS-Net, it was compared with other state-of-the-art methods. The experimental results show that the proposed method outperforms the state-of-the-art methods in terms of the F1 score (0.9630, 0.9377, and 0.7751) and kappa (0.9581, 0.9351, and 0.7646) on the three test datasets, thus suggesting its potential for various remote sensing applications.
C1 [Lee, Haeyun; Lee, Kyungsu; Na, Younghwan; Hwang, Jae Youn] Daegu Gyeongbuk Inst Sci & Technol, Informat & Commun Engn, Daegu 42988, South Korea.
   [Kim, Jun Hee] Agcy Def Dev, Daejoen 34186, South Korea.
   [Park, Juhum] Dabeeo Inc, Seoul 04107, South Korea.
   [Choi, Jihwan P.] Korea Adv Inst Sci & Technol, Dept Aerosp Engn, Daejoen 34141, South Korea.
C3 Daegu Gyeongbuk Institute of Science & Technology (DGIST); Agency of Defense Development (ADD), Republic of Korea; Korea Advanced Institute of Science & Technology (KAIST)
RP Hwang, JY (corresponding author), Daegu Gyeongbuk Inst Sci & Technol, Informat & Commun Engn, Daegu 42988, South Korea.
EM haeyun@dgist.ac.kr; ks_lee@dgist.ac.kr; kjh1127@add.re.kr; nyh0426@dgist.ac.kr; juhum.park@dabeeo.com; jhch@kaist.ac.kr; jyhwang@dgist.ac.kr
FU National Research Fundation of Korea (NRF) [NRF-2020R1A2B5B01002786]; Bio & Medical Technology Development Program of the National Research Foundation (NRF) through the Korean Government (MSIT) [NRF-2017M3A9G8084463]
CR Atzberger C, 2013, REMOTE SENS-BASEL, V5, P949, DOI 10.3390/rs5020949
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bourdis N, 2011, INT GEOSCI REMOTE SE, V0, PP4176, DOI 10.1109/IGARSS.2011.6050150
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3026587
   Chen H, 2019, I-PERCEPTION, V10, P0, DOI 10.1177/2041669519864971
   Chen LC, 2010, J APPL REMOTE SENS, V4, P0, DOI 10.1117/1.3525560
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, V0, PP2758, DOI 10.1109/ICCV.2015.316
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Hua YS, 2019, ISPRS J PHOTOGRAMM, V149, P188, DOI 10.1016/j.isprsjprs.2019.01.015
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030484
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim JH, 2019, IEEE GEOSCI REMOTE S, V16, P115, DOI 10.1109/LGRS.2018.2868880
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lebedev M., 2018, INT ARCH PHOTOGRAM R, V42, P565, DOI 10.5194/isprs-archives-XLII-2-565-2018
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI 10.1109/TGRS.2020.3018879
   Munyati C, 2000, INT J REMOTE SENS, V21, P1787, DOI 10.1080/014311600209742
   Na Y, 2021, IEEE T GEOSCI REMOTE, V59, P5171, DOI 10.1109/TGRS.2020.3010055
   Nghiem SV, 2001, J GLACIOL, V47, P539, DOI 10.3189/172756501781831738
   Paszke A., 2017, NIPS AUT WORKSH, V0, P0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1430, DOI 10.1109/LGRS.2019.2947473
   Shi WZ, 2016, PROC CVPR IEEE, V0, PP1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, ARXIV, V0, P0
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh PP, 2013, J INDIAN SOC REMOTE, V41, P631, DOI 10.1007/s12524-012-0241-4
   Varghese A., 2018, P EUR C COMP VIS ECC, V0, P0
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang JP, 2016, IEEE J-STARS, V9, P2343, DOI 10.1109/JSTARS.2016.2536943
   Zhao T, 2019, PROC CVPR IEEE, V0, PP3080, DOI 10.1109/CVPR.2019.00320
NR 36
TC 11
Z9 11
U1 9
U2 58
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4139
EP 4149
DI 10.1109/JSTARS.2021.3069242
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RU3XE
UT WOS:000645081200011
DA 2023-04-26
ER

PT J
AU Ekim, B
   Sertel, E
   Kabadayi, ME
AF Ekim, Burak
   Sertel, Elif
   Kabadayi, M. Erdem
TI Automatic Road Extraction from Historical Maps Using Deep Learning Techniques: A Regional Case Study of Turkey in a German World War II Map
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE convolutional neural networks; road classification; segmentation; deep learning; fully convolutional networks; historical maps
ID classification
AB Scanned historical maps are available from different sources in various scales and contents. Automatic geographical feature extraction from these historical maps is an essential task to derive valuable spatial information on the characteristics and distribution of transportation infrastructures and settlements and to conduct quantitative and geometrical analysis. In this research, we used the Deutsche Heereskarte 1:200,000 Turkei (DHK 200 Turkey) maps as the base geoinformation source to construct the past transportation networks using the deep learning approach. Five different road types were digitized and labeled to be used as inputs for the proposed deep learning-based segmentation approach. We adapted U-Net++ and ResneXt50_32x4d architectures to produce multi-class segmentation masks and perform feature extraction to determine various road types accurately. We achieved remarkable results, with 98.73% overall accuracy, 41.99% intersection of union, and 46.61% F1 score values. The proposed method can be implemented in DHK maps of different countries to automatically extract different road types and used for transfer learning of different historical maps.
C1 [Ekim, Burak] Istanbul Tech Univ, Inst Informat, Satellite Commun & Remote Sensing Program, TR-34469 Istanbul, Turkey.
   [Ekim, Burak; Kabadayi, M. Erdem] Koc Univ, Coll Social Sci & Humanities, Dept Hist, TR-34450 Istanbul, Turkey.
   [Sertel, Elif] Istanbul Tech Univ, Geomat Engn Dept, TR-34469 Istanbul, Turkey.
C3 Istanbul Technical University; Koc University; Istanbul Technical University
RP Sertel, E (corresponding author), Istanbul Tech Univ, Geomat Engn Dept, TR-34469 Istanbul, Turkey.
EM ekim19@itu.edu.tr; sertele@itu.edu.tr; mkabadayi@ku.edu.tr
FU European Research Council (ERC); European Union [679097]
CR Alganci U, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030458
   Andrade H.J.A., 2020, IEEE GEOSCI REMOTE S, V0, P0, DOI DOI 10.1109/LGRS.2020.3023170
   Can YS, 2021, IEEE ACCESS, V9, P62847, DOI 10.1109/ACCESS.2021.3074897
   Cheng G, 2020, IEEE J-STARS, V13, P3735, DOI 10.1109/JSTARS.2020.3005403
   Chiang Y.-Y., 2020, SPRINGER BRIEFS GEOG, V0, P0
   Chiang YY, 2014, ACM COMPUT SURV, V47, P0, DOI 10.1145/2557423
   Chiang YY, 2013, INT J DOC ANAL RECOG, V16, P55, DOI 10.1007/s10032-011-0177-1
   Congalton RG, 2001, INT J WILDLAND FIRE, V10, P321, DOI 10.1071/WF01031
   Foody GM, 2008, INT J REMOTE SENS, V29, P3137, DOI 10.1080/01431160701442120
   Laycock SD, 2011, COMPUT GRAPH-UK, V35, P242, DOI 10.1016/j.cag.2011.01.002
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Saeedimoghaddam M, 2020, INT J GEOGR INF SCI, V34, P947, DOI 10.1080/13658816.2019.1696968
   Scharfe W., 2003, P 21 INT CARTOGRAPHI, V0, P2475
   Sertel E., 2015, INT J ENV GEOINFORMA, V2, P63, DOI 10.30897/IJEGEO.303545
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Uhl JH, 2020, IEEE ACCESS, V8, P6978, DOI 10.1109/ACCESS.2019.2963213
   Ustaoglu E, 2021, PLOS ONE, V16, P0, DOI 10.1371/journal.pone.0251091
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Yuan XH, 2021, EXPERT SYST APPL, V169, P0, DOI 10.1016/j.eswa.2020.114417
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 23
TC 9
Z9 9
U1 4
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD AUG 15
PY 2021
VL 10
IS 8
BP 
EP 
DI 10.3390/ijgi10080492
PG 15
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA UG5RD
UT WOS:000689308400001
DA 2023-04-26
ER

PT J
AU Liu, C
   Tao, R
   Li, W
   Zhang, MM
   Sun, WW
   Du, Q
AF Liu, Chang
   Tao, Ran
   Li, Wei
   Zhang, Mengmeng
   Sun, Weiwei
   Du, Qian
TI Joint Classification of Hyperspectral and Multispectral Images for Mapping Coastal Wetlands
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Wetlands; Sea measurements; Feature extraction; Vegetation mapping; Hyperspectral imaging; Spatial resolution; Earth; Coastal wetlands; convolutional neural network (CNN); data fusion; hyperspectral imagery (HSI); least squares regression (LSR); multispectral imagery (MSI)
ID land-cover classification; river delta; vegetation; representation
AB It is significant for restoration and protection of natural resources and ecological services in coastal wetlands to map different land cover types with satellite remote sensing data. Considering difficulties of wetland species classification, hyperspectral images (HSIs) with high spectral resolution and multispectral images (MSI) with high spatial resolution are considered to achieve complementary advantages of multisource data. An effective approach, named as multistream convolutional neural network, is proposed to achieve fine classification of coastal wetlands. First, regression processing is adopted to make chaotically scattered coastal wetland data more compact and different. Second, through appropriate feature extraction and feature fusion strategies, high-level information of multisource data in regression domain is fused to distinguish different land cover. Experiments on GF-5 HSIs and Sentinel-2 MSIs are carried out in order to validate the classification performance of the proposed approach in two coastal wetlands of research value in China, i.e., Yellow River Estuary and Yancheng coastal wetland. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art methods in the field, especially when the number of sample size is extremely small.
C1 [Liu, Chang; Tao, Ran; Li, Wei; Zhang, Mengmeng] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
   [Sun, Weiwei] Ningbo Univ, Dept Geog & Spatial Informat Tech, Ningbo 315211, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
C3 Beijing Institute of Technology; Ningbo University; Mississippi State University
RP Tao, R (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
EM 2929166864@qq.com; rantao@bit.edu.cn; leewei36@gmail.com; 7520200002@bit.edu.cn; nbsww@outlook.com; du@ece.msstate.edu
FU Beijing Natural Science Foundation [L191004]; National Natural Science Foundation of China [61922013, 61421001, U1833203]
CR Aboulela HA, 2020, ARAB J SCI ENG, V45, P327, DOI 10.1007/s13369-019-04085-1
   Adam E, 2010, WETL ECOL MANAG, V18, P281, DOI 10.1007/s11273-009-9169-z
   AKIRA H, 2003, WETLANDS, V23, P436
   Amani M, 2018, ISPRS J PHOTOGRAMM, V144, P119, DOI 10.1016/j.isprsjprs.2018.07.005
   Anna V., 2018, LAND-BASEL, V7, P0
   [Anonymous], 2014, NIPS, V0, P0
   Belluco E, 2006, REMOTE SENS ENVIRON, V105, P54, DOI 10.1016/j.rse.2006.06.006
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Dronova I, 2015, REMOTE SENS-BASEL, V7, P6380, DOI 10.3390/rs70506380
   Duan HL, 2020, GLOB ECOL CONSERV, V22, P0, DOI 10.1016/j.gecco.2020.e01031
   Duan PH, 2020, ISPRS J PHOTOGRAMM, V166, P359, DOI 10.1016/j.isprsjprs.2020.06.009
   Duan PH, 2019, IEEE T GEOSCI REMOTE, V57, P10336, DOI 10.1109/TGRS.2019.2933588
   Dubeau P, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101056
   Ghassabi Z, 2013, EURASIP J IMAGE VIDE, V0, P0, DOI DOI 10.1186/1687-5281-2013-25
   Guo M, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17040777
   Han XS, 2018, FRONT EARTH SCI-PRC, V12, P521, DOI 10.1007/s11707-017-0672-x
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hsu C-W, 2003, PRACTICAL GUIDE SUPP, V0, P0
   Hu S., 2017, WETLANDS, V37, P1943
   Hu YB, 2019, IEEE GEOSCI REMOTE S, V16, P1110, DOI 10.1109/LGRS.2018.2890421
   Hu YB, 2019, ACTA OCEANOL SIN, V38, P142, DOI 10.1007/s13131-019-1445-z
   Jahncke R, 2018, INT J APPL EARTH OBS, V68, P139, DOI 10.1016/j.jag.2018.01.012
   Jiao LL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192238
   Jingzhe W., 2020, SCI TOTAL ENVIRON, V707, P0
   Kang XD, 2015, IEEE T GEOSCI REMOTE, V53, P2241, DOI 10.1109/TGRS.2014.2358615
   Kang XD, 2015, IEEE T GEOSCI REMOTE, V53, P144, DOI 10.1109/TGRS.2014.2319373
   LaRocque A., 2020, P ISPRS ANN PHOTOGRA, VVolume V-3-2020, P301
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Lehner B, 2004, J HYDROL, V296, P1, DOI 10.1016/j.jhydrol.2004.03.028
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Li X, 2018, INT C PATT RECOG, V0, PP483, DOI 10.1109/ICPR.2018.8545289
   Lin Z., 2010, ARXIV10095055, V0, P0
   Liu JT, 2016, INT J REMOTE SENS, V37, P1845, DOI 10.1080/01431161.2016.1165888
   Liu T, 2018, ISPRS J PHOTOGRAMM, V139, P154, DOI 10.1016/j.isprsjprs.2018.03.006
   McCarthy MJ, 2017, ENVIRON MANAGE, V60, P323, DOI 10.1007/s00267-017-0880-x
   Michael M., 2020, J APPL REMOTE SENS, V14, P0
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Onojeghuo AO, 2017, INT J APPL EARTH OBS, V59, P79, DOI 10.1016/j.jag.2017.03.007
   Ozesmi Stacy L., 2002, WETLANDS ECOLOGY AND MANAGEMENT, V10, P381, DOI 10.1023/A:1020908432489
   Rebelo AJ, 2018, REMOTE SENS ENVIRON, V210, P25, DOI 10.1016/j.rse.2018.02.031
   Renato S., 2020, INT J AGR SUSTAIN DE, V2, P1
   Reschke J, 2014, INT J APPL EARTH OBS, V28, P220, DOI 10.1016/j.jag.2013.12.014
   Riaza A, 2017, INT J REMOTE SENS, V38, P3735, DOI 10.1080/01431161.2017.1302621
   Samantha Y., 2020, ESTUARINE COASTAL SH, V236, P0
   Santurkar S, 2018, ADV NEUR IN, V31, P0
   Schmidt KS, 2004, PHOTOGRAMM ENG REM S, V70, P703, DOI 10.14358/PERS.70.6.703
   Schuerch M, 2018, NATURE, V561, P231, DOI 10.1038/s41586-018-0476-5
   Seydi ST, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122010
   Shang K., 2020, P SOC PHOTO-OPT INS, V11432, P0
   Spencer T, 2016, GLOBAL PLANET CHANGE, V139, P15, DOI 10.1016/j.gloplacha.2015.12.018
   Stratoulias D, 2018, INT J REMOTE SENS, V39, P5689, DOI 10.1080/01431161.2018.1466081
   Su HJ, 2020, IEEE T GEOSCI REMOTE, V58, P3778, DOI 10.1109/TGRS.2019.2957135
   Sun B, 2017, IEEE T GEOSCI REMOTE, V55, P212, DOI 10.1109/TGRS.2016.2604290
   Sun WW, 2018, IEEE T GEOSCI REMOTE, V56, P3185, DOI 10.1109/TGRS.2018.2794443
   Sun XX, 2014, IEEE GEOSCI REMOTE S, V11, P1235, DOI 10.1109/LGRS.2013.2290531
   Tao R., 1900, P2020, V0, P0
   Turpie KR, 2015, REMOTE SENS ENVIRON, V167, P206, DOI 10.1016/j.rse.2015.05.008
   Tuxen K, 2011, WETL ECOL MANAG, V19, P141, DOI 10.1007/s11273-010-9207-x
   Wang XX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161927
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Xu Y, 2014, NEUROCOMPUTING, V135, P253, DOI 10.1016/j.neucom.2013.11.025
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yang JF, 2013, MATH COMPUT, V82, P301
   Zang Z, 2019, ANTHROPOCENE COASTS, V2, P87, DOI 10.1139/anc-2018-0007
   Zhang AZ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080952
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhao XD, 2020, IEEE T GEOSCI REMOTE, V58, P7355, DOI 10.1109/TGRS.2020.2982064
   Zifei Z., 2018, BEIJING SURVEYING MA, V0, P0
   Zomer RJ, 2009, J ENVIRON MANAGE, V90, P2170, DOI 10.1016/j.jenvman.2007.06.028
NR 72
TC 15
Z9 16
U1 25
U2 63
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 982
EP 996
DI 10.1109/JSTARS.2020.3040305
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900030
DA 2023-04-26
ER

PT J
AU Wu, GQ
   Chen, X
   Lin, JX
   Wang, YY
   Yu, JH
AF Wu, Guoqing
   Chen, Xi
   Lin, Jixian
   Wang, Yuanyuan
   Yu, Jinhua
TI Identification of invisible ischemic stroke in noncontrast CT based on novel two-stage convolutional neural network model
SO MEDICAL PHYSICS
LA English
DT Article
DE deep convolutional neural network; identification; ischemic stroke; noncontrast computed tomography
AB Purpose Early identification of ischemic stroke lesion regions plays a vital role in its treatments like thrombolytic therapy and patients' recovery. Noncontrast computed tomography (ncCT) is the most widespread imaging modality in emergency departments. Unfortunately, it is extremely hard to distinguish the lesion from healthy tissue during the hyper-acute phase of stroke. In this paper, a two-stage convolutional neural network-based method was proposed to identify the invisible ischemic stroke from ncCT. Methods In order to combine the global and local information of images effectively, a cascaded structure with two coordinated networks was used to detect the suspicious stroke regions on the whole and optimize the detailed localization. In the first stage, an end-to-end U-net with adaptive threshold was proposed to integrate global position, symmetry and gray texture information to detect the suspicious regions. After reducing the interference from most normal regions, a ResNet-based patch classification network was used to eliminate some false positive samples on suspicious regions by mining deeper image features, contributing to a more precise localization of stroke. Finally, a MAP model was used to optimize the result by combining the classification results of each patch with their spatial constraint information. Results Three independent experiments, that is, training and testing on dataset from one hospital, on the combination of two, and on the two respectively, were performed on a total of 277 cases from two hospitals to validate the proposed model, The proposed method achieved identification accuracy of 91.89%, 87.21%, and 85.71% in the three experiments, and the final localization accuracy in terms of precise localization of stroke were 82.35%, 83.02%, and 81.40%, respectively, which indicated the robustness and clinical values of the method. Conclusions There are some deep image feature differences between stroke region and normal region on ncCT images. The proposed two-stage convolutional neural network model can well seize these features and use them to effectively identify and locate stroke.
C1 [Wu, Guoqing; Chen, Xi] Fudan Univ, Dept Elect Engn, Shanghai 200433, Peoples R China.
   [Lin, Jixian] Fudan Univ, Zhongshan Hosp, Dept Neurol, Minhang Branch, Shanghai 200433, Peoples R China.
   [Wang, Yuanyuan; Yu, Jinhua] Fudan Univ, Dept Elect Engn, KeyLab Med Imaging Comp & Comp Assisted Intervent, Shanghai 200433, Peoples R China.
C3 Fudan University; Fudan University; Fudan University
RP Wang, YY; Yu, JH (corresponding author), Fudan Univ, Dept Elect Engn, KeyLab Med Imaging Comp & Comp Assisted Intervent, Shanghai 200433, Peoples R China.
EM yywang@fudan.edu.cn; jhyu@fudan.edu.cn
FU National Natural Science Foundation of China Youth Foud [62001119]; Shanghai Municipal Science and Technology Major Project [2018SHZDZX01]; Natural Science Foundation; Major Basic Research Program of Shanghai [16JC1420100]; Major research plan of the National Natural Science Foundation [91959127]
CR Chen SF, 2010, IEEE T IMAGE PROCESS, V19, P2254, DOI 10.1109/TIP.2010.2047164
   Ciresan D., 2012, ADV NEURAL INFORM PR, V0, PP2843, DOI 10.5555/2999325.2999452
   Davis A, 2018, BIOMED SIGNAL PROCES, V45, P117, DOI 10.1016/j.bspc.2018.05.037
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   He K., 2016, P IEEE C COMP VIS PA, V2016, P1512.03385, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Jin, 2016, ZHEJIANG MED J, V38, P1178
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Mirajkar PR, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, V0, P1123, DOI 10.1109/ICACCI.2015.7275761
   Peter R, 2017, MED PHYS, V44, P192, DOI 10.1002/mp.12015
   Przelaskowski A, 2007, COMPUT BIOL MED, V37, P524, DOI 10.1016/j.compbiomed.2006.08.004
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schwamm LH, 1998, STROKE, V29, P2268, DOI 10.1161/01.STR.29.11.2268
   Shalikar A, 2014, INT J MECHATRON ELEC, V4, P67
   Sivakumar P, 2017, INT J IMAG SYST TECH, V27, P265, DOI 10.1002/ima.22231
   Sundaram, 2018, BIOCYBERN BIOMED ENG, V334, P1
   Usinskas A, 2004, INFORMATICA-LITHUAN, V15, P283
   Wardlaw JM, 2005, RADIOLOGY, V235, P444, DOI 10.1148/radiol.2352040262
   Wu GQ, 2019, BIOMED SIGNAL PROCES, V52, P41, DOI 10.1016/j.bspc.2019.03.008
   Yahiaoui AFZ, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SIGNAL, V0, P0
   Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8
NR 22
TC 3
Z9 4
U1 3
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD MAR 15
PY 2021
VL 48
IS 3
BP 1262
EP 1275
DI 10.1002/mp.14691
EA FEB 2021
PG 14
WC Radiology, Nuclear Medicine & Medical Imaging
SC Radiology, Nuclear Medicine & Medical Imaging
GA RB6HM
UT WOS:000615236500001
PM 33378585
DA 2023-04-26
ER

PT J
AU Li, HX
   Wang, CZ
   Cui, YX
   Hodgson, M
AF Li, Huixuan
   Wang, Cuizhen
   Cui, Yuxin
   Hodgson, Michael
TI Mapping salt marsh along coastal South Carolina using U-Net
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Salt marsh; Coastal remote sensing; U-Net; South Carolina
ID convolutional neural-network; spartina-alterniflora; land-cover; juncus-roemerianus; seasonal patterns; tidal inundation; vegetation; classification; elevation; area
AB Coastal wetland mapping is often difficult because of the heterogeneous vegetation compositions and associated tidal effects. In this study, we employed the U-Net and developed an adaptive deep learning approach to map statewide salt marshes in estuarine emergent wetlands of South Carolina (SC), USA, from 20 Sentinel-2A&B images. Considering the spatial heterogeneity of the coastal environment, two NOAA National Estuarine Research Reserves (NERRs) in SC were examined, the North Inlet-Winyah Bay (NIWB) NERR for model training and the ACE Basin NERR for testing. A high-resolution land cover map in the NIWB was downloaded for the training process. Ground reference points recorded by the NERR, as well as Google Earth were utilized during the accuracy assessment. The highest overall accuracy (90%) was achieved when all scenes with 10 Sentinel bands and the Normalized Difference Vegetation Index (NDVI) were included. The time used to train the model was 5 h, while then the statewide classification was performed in 20 min. Low marsh and high marsh distributions were successfully delineated. Compared to the national marsh maps from the NOAA Coastal Change Analysis Program (C-CAP), this study refined the land cover details concerning low marsh and high marsh distributions on the SC coast. Owing to the computational power of the U-Net, the seasonality and tide influence on marsh classification were mitigated by using multi-temporal images. With images available, the deep learning approach developed in this study could be easily adopted in other coastal areas.
C1 [Li, Huixuan; Wang, Cuizhen; Hodgson, Michael] Univ South Carolina, Dept Geog, Columbia, SC 29208 USA.
   [Cui, Yuxin] Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
C3 University of South Carolina System; University of South Carolina Columbia; University of South Carolina System; University of South Carolina Columbia
RP Li, HX (corresponding author), Univ South Carolina, Dept Geog, Columbia, SC 29208 USA.
EM huixuan@email.sc.edu; CWANG@mailbox.sc.edu; ycui@email.sc.edu; hodgsonm@sc.edu
CR Allen J, 2003, CONSERV ECOL, V8, P0
   Batie S.S., 1980, ESTUARINE PERSPECTIV, V0, P3
   Belluco E, 2006, REMOTE SENS ENVIRON, V105, P54, DOI 10.1016/j.rse.2006.06.006
   Benoit LK, 2002, WILSON BULL, V114, P314, DOI 10.1676/0043-5643(2002)114[0314:RBHAAT]2.0.CO;2
   BERTNESS MD, 1991, ECOLOGY, V72, P138, DOI 10.2307/1938909
   BERTNESS MD, 1987, ECOL MONOGR, V57, P129, DOI 10.2307/1942621
   Brinson MM, 1999, WETLANDS, V19, P65, DOI 10.1007/BF03161734
   Brooks RP, 2004, ENVIRON MONIT ASSESS, V94, P9, DOI 10.1023/B:EMAS.0000016876.63062.3d
   Bruno JF, 2000, ECOLOGY, V81, P1179, DOI 10.1890/0012-9658(2000)081[1179:FOCBPC]2.0.CO;2
   Campbell A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091107
   Campbell A, 2018, IEEE T GEOSCI REMOTE, V56, P5169, DOI 10.1109/TGRS.2018.2810503
   Cao KL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071128
   Chen F., 2018, P IEEE INT GEOSCIENC, V0, P22
   Chen QQ, 2020, FLORA, V273, P0, DOI 10.1016/j.flora.2020.151722
   Dahl T. E., 2013, STATUS TRENDS WETLAN, V0, P0
   DeLancey ER, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010002
   Demir N., 2016, ENSEMBLE METHODS ELE, V0, P0
   Dobson J.E., 1995, NOAA TECHNICAL REPOR, V0, P123
   ELEUTERIUS LN, 1981, GULF RES REP, V7, P27
   Farasin A, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10124332
   Feagin RA, 2010, ECOL SOC, V15, P0
   Feng QL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091006
   GALLAGHER JL, 1983, AM J BOT, V70, P212, DOI 10.2307/2443265
   GIURGEVICH JR, 1982, OECOLOGIA, V52, P404, DOI 10.1007/BF00367967
   GLEASON ML, 1981, ESTUAR COAST SHELF S, V13, P47, DOI 10.1016/S0302-3524(81)80104-1
   He Z, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202455
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hladik C, 2013, REMOTE SENS ENVIRON, V139, P318, DOI 10.1016/j.rse.2013.08.003
   Hladik C, 2012, REMOTE SENS ENVIRON, V121, P224, DOI 10.1016/j.rse.2012.01.018
   Hodgson M.E., 2017, FHWASC1705 USCSCDOT, V0, P0
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Huang H, 2007, ECOL ENG, V29, P164, DOI 10.1016/j.ecoleng.2006.06.005
   Ingram K., 2013, CLIMATE SE US VARIAB, V0, P0
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Dang KB, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12193270
   Kiraly S. J., 1990, FWS9018 N ATL TREAT, V0, P0
   Knopp L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152422
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Laban N., 2020, STUDIES COMPUTATIONA, V0, PP165, DOI 10.1007/978-3-030-20212-5_9
   Larkin D.J., 2018, WETL B STRUCT FUNCT, V0, PP177, DOI 10.1007/978-90-481-9659-3_52
   Li HX, 2020, INT J DIGIT EARTH, V13, P1467, DOI 10.1080/17538947.2020.1729263
   Li J, 2010, ACTA OCEANOL SIN, V29, P26, DOI 10.1007/s13131-010-0034-y
   Li WJ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010022
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   McCombs John, 2014, NOAAS COASTAL CHANGE, V0, P0
   Miller GJ, 2017, AIMS ENVIRON SCI, V4, P677, DOI 10.3934/environsci.2017.5.677
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Morris JT, 2005, INT J REMOTE SENS, V26, P5221, DOI 10.1080/01431160500219018
   Morris JT, 2002, ECOLOGY, V83, P2869, DOI 10.1890/0012-9658(2002)083[2869:ROCWTR]2.0.CO;2
   Ozesmi Stacy L., 2002, WETLANDS ECOLOGY AND MANAGEMENT, V10, P381, DOI 10.1023/A:1020908432489
   Pashaei M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060959
   Purcell A., 2019, S CAROLINAS COASTAL, V0, P0
   Reed DJ, 1997, ESTUARIES, V20, P301, DOI 10.2307/1352345
   Rezaee M, 2018, IEEE J-STARS, V11, P3030, DOI 10.1109/JSTARS.2018.2846178
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanger D, 2016, GUIDE SALT MARSHES T, V0, P0
   Sanger DM, 2004, ENVIRON MANAGE, V33, P741, DOI 10.1007/s00267-004-0018-9
   SC Department of Natural Resources (SCDNR), 2015, SEA SCI, V0, P1
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Shepard CC, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0027374
   Stoian A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171986
   Stolt MH, 1995, WETLANDS, V15, P346, DOI 10.1007/BF03160889
   SULLIVAN M J, 1974, CHESAPEAKE SCIENCE, V15, P121, DOI 10.2307/1351275
   Sun C, 2016, INT J APPL EARTH OBS, V45, P27, DOI 10.1016/j.jag.2015.10.008
   TEAL JM, 1966, J EXP BOT, V17, P355, DOI 10.1093/jxb/17.2.355
   Terando AJ, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0102261
   Timm BC, 2012, REMOTE SENS ENVIRON, V127, P106, DOI 10.1016/j.rse.2012.08.033
   Tiner R, 1974, INVENTORY S CAROLINA, V0, P0
   Tiner R.W., 2016, WETLAND INDICATORS G, V2nd ed., P0
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   USFWS (U.S. Fish and Wildlife Service), 1980, 101 USFWS ESM, V0, P7
   VALIELA I, 1978, AM NAT, V112, P461, DOI 10.1086/283290
   Van Dolah RF, 2008, SCI TOTAL ENVIRON, V390, P142, DOI 10.1016/j.scitotenv.2007.09.036
   Wang C, 2007, REMOTE SENS ENVIRON, V107, P559, DOI 10.1016/j.rse.2006.10.007
   Wang XX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161927
   Wei SS, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010068
   White SM, 2016, REMOTE SENS ENVIRON, V184, P605, DOI 10.1016/j.rse.2016.08.005
   Xu HQ, 2018, GISCI REMOTE SENS, V55, P477, DOI 10.1080/15481603.2017.1412145
   Yang J., 2009, REMOTE SENSING COAST, V0, P173
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Zhang C, 2018, IEEE T GEOSCI REMOTE, V56, P4507, DOI 10.1109/TGRS.2018.2822783
   Zhang YL, 2011, INT J REMOTE SENS, V32, P545, DOI 10.1080/01431160903475241
NR 88
TC 14
Z9 14
U1 12
U2 50
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD SEP 15
PY 2021
VL 179
IS 
BP 121
EP 132
DI 10.1016/j.isprsjprs.2021.07.011
EA AUG 2021
PG 12
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UC2UJ
UT WOS:000686386900009
DA 2023-04-26
ER

PT J
AU Khan, AH
   Fraz, MM
   Shahzad, M
AF Khan, Asim Hameed
   Fraz, Muhammad Moazam
   Shahzad, Muhammad
TI Deep Learning Based Land Cover and Crop Type Classification: A Comparative Study
SO 2021 INTERNATIONAL CONFERENCE ON DIGITAL FUTURES AND TRANSFORMATIVE TECHNOLOGIES (ICODT2)
LA English
DT Proceedings Paper
DE semantic segmentation; remote sensing; satellite imagery; convolutional neural networks; deep Learning; machine learning; landsat8; crop land data layer; classification
ID random forest; imagery; area
AB Remote sensing data is available free of cost with an ever-increase in the number of satellites. This satellite imagery can be used as raw input from which cultivated/non-cultivated and crop fields can be mapped. Previous trends included the use of traditional ML techniques and standard CNN, RNN for such mappings. In this paper, we investigate the segmentation models for the task of Landcover and Crop type Classification. We investigate the UNet, SegNet, and DeepLabv3+ in the data-rich states of Nebraska, Mid-West, United States. We acquire dataset from Cropland data Layer provided by USDA National Agricultural Statistics Service. Our Experimental results show that cultivated and non-cultivated landcover is classified with an accuracy of 90% and crop types are classified around 70% ensuring the models trained on one geographical area can be used for accurate classification in other geographical areas, which makes it more reliable for real-time application in agricultural business. [GitHub]
C1 [Khan, Asim Hameed; Fraz, Muhammad Moazam; Shahzad, Muhammad] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Khan, AH (corresponding author), Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
EM akhan.mscs19seecs@seecs.edu.pk; moazam.fraz@seecs.edu.pk; muhammad.shehzad@seecs.edu.pk
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Castelluccio M., 2015, LAND USE CLASSIFICAT, V0, P0
   Chen L.-C., 2017, RETHINKING ATROUS CO, V0, P0
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Cohn AS, 2016, NAT CLIM CHANGE, V6, P601, DOI 10.1038/nclimate2934
   de Lima RP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010086
   Fisette T, 2013, INT CONF AGRO-GEOINF, V0, P269
   Gilbertson JK, 2017, COMPUT ELECTRON AGR, V134, P151, DOI 10.1016/j.compag.2016.12.006
   Hao PY, 2020, SCI TOTAL ENVIRON, V733, P0, DOI 10.1016/j.scitotenv.2020.138869
   Hao PY, 2015, REMOTE SENS-BASEL, V7, P5347, DOI 10.3390/rs70505347
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Heller E, 2012, PHOTOGRAMM ENG REM S, V78, P815, DOI 10.14358/PERS.78.8.815
   Ienco Dino, 2017, IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, V14, P1685, DOI 10.1109/LGRS.2017.2728698
   Inglada J, 2015, REMOTE SENS-BASEL, V7, P12356, DOI 10.3390/rs70912356
   Kong YL, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030452
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   McCarty JL, 2017, REMOTE SENS ENVIRON, V202, P142, DOI 10.1016/j.rse.2017.06.040
   Petnehazi G., 2018, RECURRENT NEURAL NET, V0, P0
   Portmann FT, 2010, GLOBAL BIOGEOCHEM CY, V24, P0, DOI 10.1029/2008GB003435
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rwanga S. S., 2017, INTERNATIONAL JOURNAL OF GEOSCIENCES, V8, P611, DOI 10.4236/ijg.2017.84033
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Sherstinsky A, 2020, PHYSICA D, V404, P0, DOI 10.1016/j.physd.2019.132306
   Sukawattanavijit C, 2017, IEEE GEOSCI REMOTE S, V14, P284, DOI 10.1109/LGRS.2016.2628406
   Sun J, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19204363
   Sun LY, 2015, REMOTE SENS-BASEL, V7, P8368, DOI 10.3390/rs70708368
   Sun ZH, 2019, INT J REMOTE SENS, V40, P593, DOI 10.1080/01431161.2018.1516313
   Tong XY, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111322
   Waldner F, 2015, REMOTE SENS-BASEL, V7, P10400, DOI 10.3390/rs70810400
   Wang S., 2020, SCI DATA, V7, P1
   Wang S, 2019, REMOTE SENS ENVIRON, V222, P303, DOI 10.1016/j.rse.2018.12.026
   Wang SS, 2020, WIND ENERGY, V23, P1099, DOI 10.1002/we.2476
   Wu BF, 2015, REMOTE SENS-BASEL, V7, P3907, DOI 10.3390/rs70403907
   Xue ZH, 2014, IEEE J-STARS, V7, P1142, DOI 10.1109/JSTARS.2013.2294956
   Yaramasu R, 2020, COMPUT ELECTRON AGR, V176, P0, DOI 10.1016/j.compag.2020.105664
   You LZ, 2014, AGR SYST, V127, P53, DOI 10.1016/j.agsy.2014.01.002
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
NR 39
TC 1
Z9 1
U1 5
U2 11
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/ICoDT252288.2021.9441483
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA BS7GM
UT WOS:000760235700011
DA 2023-04-26
ER

PT J
AU Li, HP
   Zhang, C
   Zhang, Y
   Zhang, SQ
   Ding, XH
   Atkinson, PM
AF Li, Huapeng
   Zhang, Ce
   Zhang, Yong
   Zhang, Shuqing
   Ding, Xiaohui
   Atkinson, Peter M.
TI A Scale Sequence Object-based Convolutional Neural Network (SS-OCNN) for crop classification from fine spatial resolution remotely sensed imagery
SO INTERNATIONAL JOURNAL OF DIGITAL EARTH
LA English
DT Article
DE CNNs; multi-scale deep learning; object-based mapping; crop classification; image classification
ID land-use; algorithms; selection; machine
AB The highly dynamic nature of agro-ecosystems in space and time usually leads to high intra-class variance and low inter-class separability in the fine spatial resolution (FSR) remotely sensed imagery. This makes traditional classifiers essentially relying on spectral information for crop mapping from FSR imagery an extremely challenging task. To mine effectively the rich spectral and spatial information in FSR imagery, this paper proposed a Scale Sequence Object-based Convolutional Neural Network (SS-OCNN) that classifies images at the object level by taking segmented objects (crop parcels) as basic units of analysis, thus, ensuring that the boundaries between crop parcels are delineated precisely. These segmented objects were subsequently classified using a CNN model integrated with an automatically generated scale sequence of input patch sizes. This scale sequence can fuse effectively the features learned at different scales by transforming progressively the information extracted at small scales to larger scales. The effectiveness of the SS-OCNN was investigated using two heterogeneous agricultural areas with FSR SAR and optical imagery, respectively. Experimental results revealed that the SS-OCNN consistently achieved the most accurate classification results. The SS-OCNN, thus, provides a new paradigm for crop classification over heterogeneous areas using FSR imagery, and has a wide application prospect.
C1 [Li, Huapeng; Zhang, Shuqing] Chinese Acad Sci, Northeast Inst Geog & Agroecol, Changchun, Peoples R China.
   [Li, Huapeng; Zhang, Yong] Changchun Guanghua Univ, Sch Elect & Informat Engn, Changchun, Peoples R China.
   [Zhang, Ce; Atkinson, Peter M.] Univ Lancaster, Lancaster Environm Ctr, Lancaster, England.
   [Ding, Xiaohui] Guangzhou Inst Geog, Guangzhou, Peoples R China.
C3 Chinese Academy of Sciences; Northeast Institute of Geography & Agroecology, CAS; Lancaster University; Guangdong Academy of Sciences; Guangzhou Institute of Geography, Guangdong Academy of Sciences
RP Li, HP (corresponding author), 4888 Shengbei St, Changchun, Peoples R China.
EM lihuapeng@iga.ac.cn
FU National Natural Science Foundation of China [41301465]; Capital Construction Fund of Jilin Province [2021C045-2]; Open Fund of State Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University [20R04]
CR Alganci U, 2013, PHOTOGRAMM ENG REM S, V79, P1053, DOI 10.14358/PERS.79.11.1053
   Azar R, 2016, EUR J REMOTE SENS, V49, P361, DOI 10.5721/EuJRS20164920
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Cai YP, 2018, REMOTE SENS ENVIRON, V210, P35, DOI 10.1016/j.rse.2018.02.045
   Chai D, 2019, REMOTE SENS ENVIRON, V225, P307, DOI 10.1016/j.rse.2019.03.007
   Chen YY, 2019, EARTH SCI INFORM, V12, P341, DOI 10.1007/s12145-019-00383-2
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Debats SR, 2016, REMOTE SENS ENVIRON, V179, P210, DOI 10.1016/j.rse.2016.03.010
   Dey S, 2020, INT J APPL EARTH OBS, V88, P0, DOI 10.1016/j.jag.2020.102059
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu Q, 2019, INT J APPL EARTH OBS, V80, P218, DOI 10.1016/j.jag.2019.04.014
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HP, 2020, INT J APPL EARTH OBS, V87, P0, DOI 10.1016/j.jag.2019.102032
   Li HP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202370
   Li HP, 2019, INT J APPL EARTH OBS, V74, P45, DOI 10.1016/j.jag.2018.08.024
   Liu SJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060690
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lv XW, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121946
   Ming DP, 2015, ISPRS J PHOTOGRAMM, V106, P28, DOI 10.1016/j.isprsjprs.2015.04.010
   Nobre CA, 2016, P NATL ACAD SCI USA, V113, P10759, DOI 10.1073/pnas.1605516113
   Paludo A, 2020, INT J DIGIT EARTH, V13, P1624, DOI 10.1080/17538947.2020.1772893
   Pan X, 2019, INT J REMOTE SENS, V40, P5892, DOI 10.1080/01431161.2019.1584687
   Persello C, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111253
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sidike P, 2019, REMOTE SENS ENVIRON, V221, P756, DOI 10.1016/j.rse.2018.11.031
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang T, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010024
   Wardlow BD, 2008, REMOTE SENS ENVIRON, V112, P1096, DOI 10.1016/j.rse.2007.07.019
   Yang CH, 2011, COMPUT ELECTRON AGR, V75, P347, DOI 10.1016/j.compag.2010.12.012
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111593
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang C, 2018, ISPRS J PHOTOGRAMM, V140, P133, DOI 10.1016/j.isprsjprs.2017.07.014
   Zhao J, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111605
   Zhao WQ, 2019, IEEE T SYST MAN CY-S, V49, P1254, DOI 10.1109/TSMC.2017.2724440
   Zheng BJ, 2015, INT J APPL EARTH OBS, V34, P103, DOI 10.1016/j.jag.2014.07.002
   Zheng XT, 2019, IEEE T GEOSCI REMOTE, V57, P4799, DOI 10.1109/TGRS.2019.2893115
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhong YF, 2020, REMOTE SENS ENVIRON, V250, P0, DOI 10.1016/j.rse.2020.112012
NR 44
TC 8
Z9 8
U1 10
U2 31
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1753-8947
EI 1753-8955
J9 INT J DIGIT EARTH
JI Int. J. Digit. Earth
PD NOV 2
PY 2021
VL 14
IS 11
BP 1528
EP 1546
DI 10.1080/17538947.2021.1950853
EA JUL 2021
PG 19
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA WR1EX
UT WOS:000670807600001
DA 2023-04-26
ER

PT J
AU Maxwell, AE
   Warner, TA
   Guillen, LA
AF Maxwell, Aaron E.
   Warner, Timothy A.
   Guillen, Luis Andres
TI Accuracy Assessment in Convolutional Neural Network-Based Deep Learning Remote Sensing Studies-Part 2: Recommendations and Best Practices
SO REMOTE SENSING
LA English
DT Review
DE accuracy assessment; thematic mapping; feature extraction; object detection; semantic segmentation; instance segmentation; deep learning
ID mapping land-cover; map accuracy; classification accuracy; image classification; sampling designs; estimating area; segmentation; texture; scale; allocation
AB Convolutional neural network (CNN)-based deep learning (DL) has a wide variety of applications in the geospatial and remote sensing (RS) sciences, and consequently has been a focus of many recent studies. However, a review of accuracy assessment methods used in recently published RS DL studies, focusing on scene classification, object detection, semantic segmentation, and instance segmentation, indicates that RS DL papers appear to follow an accuracy assessment approach that diverges from that of traditional RS studies. Papers reporting on RS DL studies have largely abandoned traditional RS accuracy assessment terminology; they rarely reported a complete confusion matrix; and sampling designs and analysis protocols generally did not provide a population-based confusion matrix, in which the table entries are estimates of the probabilities of occurrence of the mapped landscape. These issues indicate the need for the RS community to develop guidance on best practices for accuracy assessment for CNN-based DL thematic mapping and object detection. As a first step in that process, we explore key issues, including the observation that accuracy assessments should not be biased by the CNN-based training and inference processes that rely on image chips. Furthermore, accuracy assessments should be consistent with prior recommendations and standards in the field, should support the estimation of a population confusion matrix, and should allow for assessment of model generalization. This paper draws from our review of the RS DL literature and the rich record of traditional remote sensing accuracy assessment research while considering the unique nature of CNN-based deep learning to propose accuracy assessment best practices that use appropriate sampling methods, training and validation data partitioning, assessment metrics, and reporting standards.
C1 [Maxwell, Aaron E.; Warner, Timothy A.; Guillen, Luis Andres] West Virginia Univ, Dept Geol & Geog, Morgantown, WV 26505 USA.
C3 West Virginia University
RP Maxwell, AE (corresponding author), West Virginia Univ, Dept Geol & Geog, Morgantown, WV 26505 USA.
EM Aaron.Maxwell@mail.wvu.edu; Tim.Warner@mail.wvu.edu; lg0018@mix.wvu.edu
FU National Science Foundation (NSF) [2046059]; Directorate For Geosciences [2046059] Funding Source: National Science Foundation; Division Of Earth Sciences [2046059] Funding Source: National Science Foundation
CR [Anonymous], 2021, MATT MASK RCNN, V0, P0
   [Anonymous], 2017, P IEEE INT C COMP VI, V0, P0
   Badrinarayanan V., 2015, 150507293 ARXIV, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bartsch A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8120979
   Basu S, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), V0, P0, DOI DOI 10.1145/2820783.2820816
   Berberoglu S, 2000, COMPUT GEOSCI-UK, V26, P385, DOI 10.1016/S0098-3004(99)00119-3
   Boguszewski A., 2021, P IEEE CVF C COMP VI, V0, P0
   Chen J, 2020, IEEE GEOSCI REMOTE S, V17, P681, DOI 10.1109/LGRS.2019.2930462
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, P0
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2020, IEEE J-STARS, V13, P3735, DOI 10.1109/JSTARS.2020.3005403
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Cingolani AM, 2004, REMOTE SENS ENVIRON, V92, P84, DOI 10.1016/j.rse.2004.05.008
   Clinton N, 2010, PHOTOGRAMM ENG REM S, V76, P289, DOI 10.14358/PERS.76.3.289
   Congalton R, 1900, VVOLUME 12, V0, P383
   Congalton R.G., 2019, ASSESSING ACCURACY R, V0, P0
   CONGALTON RG, 1983, PHOTOGRAMM ENG REM S, V49, P1671
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Cortes C., 2005, ADV NEURAL INFORM PR, V17, P305
   Dai JF, 2016, PROC CVPR IEEE, V0, PP3150, DOI 10.1109/CVPR.2016.343
   Demler OV, 2012, STAT MED, V31, P2577, DOI 10.1002/sim.5328
   Dennis M, 2018, LAND-BASEL, V7, P0, DOI 10.3390/land7010017
   Ferro CJS, 2002, PHOTOGRAMM ENG REM S, V68, P51
   Foody GM, 2008, INT J REMOTE SENS, V29, P3137, DOI 10.1080/01431160701442120
   Foody GM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111630
   Foody GM, 2009, INT J REMOTE SENS, V30, P5273, DOI 10.1080/01431160903130937
   Foody GM, 2005, INT J REMOTE SENS, V26, P1217, DOI 10.1080/01431160512331326521
   Foody GM, 1996, INT J REMOTE SENS, V17, P1317, DOI 10.1080/01431169608948706
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   FULLER RM, 1994, PHOTOGRAMM ENG REM S, V60, P553
   Gagne DJ, 2019, MON WEATHER REV, V147, P2827, DOI 10.1175/MWR-D-18-0316.1
   Graf L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12233937
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13
   Herold M, 2002, ENVIRON PLANN A, V34, P1443, DOI 10.1068/a3496
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12183053
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101667
   Howard J., 2020, DEEP LEARNING CODERS, V0, P0
   Howard J, 2020, INFORMATION, V11, P0, DOI 10.3390/info11020108
   Huang X, 2020, SCI BULL, V65, P1039, DOI 10.1016/j.scib.2020.03.003
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Kim M, 2011, INT J REMOTE SENS, V32, P2825, DOI 10.1080/01431161003745608
   Kim M, 2009, PHOTOGRAMM ENG REM S, V75, P819, DOI 10.14358/PERS.75.7.819
   Koutsoukas A, 2017, J CHEMINFORMATICS, V9, P0, DOI 10.1186/s13321-017-0226-y
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kucharczyk M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122012
   Li WM, 2020, IEEE J-STARS, V13, P1986, DOI 10.1109/JSTARS.2020.2988477
   Li XX, 2014, REMOTE SENS-BASEL, V6, P11372, DOI 10.3390/rs61111372
   Li Y, 2017, PROC CVPR IEEE, V0, PP4438, DOI 10.1109/CVPR.2017.472
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lizarazo I, 2014, INT J REMOTE SENS, V35, P6135, DOI 10.1080/01431161.2014.943328
   Lobo JM, 2008, GLOBAL ECOL BIOGEOGR, V17, P145, DOI 10.1111/j.1466-8238.2007.00358.x
   Luo S, 2020, ISPRS J PHOTOGRAMM, V167, P443, DOI 10.1016/j.isprsjprs.2020.07.016
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   Maxwell AE, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13132450
   Maxwell AE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12244145
   Maxwell AE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121905
   Maxwell AE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030547
   Maxwell AE, 2019, INT J REMOTE SENS, V40, P118, DOI 10.1080/01431161.2018.1506184
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   Maxwell AE, 2016, PHOTOGRAMM ENG REM S, V82, P437, DOI 10.14358/PERS.82.6.437
   Pham MT, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152501
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P7557, DOI 10.1109/TGRS.2020.2979552
   Oh S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182981
   Ngo PTT, 2021, GEOSCI FRONT, V12, P505, DOI 10.1016/j.gsf.2020.06.013
   Pinheiro P.O., 2015, 150606204 ARXIV, V0, P0
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Prakash N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030346
   Qi KL, 2020, IEEE J-STARS, V13, P632, DOI 10.1109/JSTARS.2020.2968564
   Radoux J, 2011, INT J GEOGR INF SCI, V25, P895, DOI 10.1080/13658816.2010.498378
   Radoux J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9070646
   Rees WG, 2003, REMOTE SENS ENVIRON, V85, P441, DOI 10.1016/S0034-4257(03)00037-3
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2016, PROC CVPR IEEE, V0, PP1525, DOI 10.1109/CVPR.2016.169
   Rigge M, 2020, RANGELAND ECOL MANAG, V73, P856, DOI 10.1016/j.rama.2020.03.009
   Robinson C, 2019, PROC CVPR IEEE, V0, PP12718, DOI 10.1109/CVPR.2019.01301
   Rodriguez-Galiano VF, 2012, REMOTE SENS ENVIRON, V121, P93, DOI 10.1016/j.rse.2011.12.003
   Rodriguez-Galiano VF, 2014, INT J DIGIT EARTH, V7, P492, DOI 10.1080/17538947.2012.748848
   Ronneberger O., 2015, 150504597 ARXIV, V0, P0
   Saito T, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0118432
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Senf C, 2015, REMOTE SENS ENVIRON, V156, P527, DOI 10.1016/j.rse.2014.10.018
   Singh A, 2020, IEEE T GEOSCI REMOTE, V58, P7570, DOI 10.1109/TGRS.2020.2981082
   Stehman S.V., 2009, SAGE HDB REMOTE SENS, V0, P297
   Stehman SV, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.018
   Stehman SV, 2014, INT J REMOTE SENS, V35, P4923, DOI 10.1080/01431161.2014.930207
   Stehman SV, 2013, REMOTE SENS ENVIRON, V132, P202, DOI 10.1016/j.rse.2013.01.016
   Stehman SV, 2011, REMOTE SENS ENVIRON, V115, P3044, DOI 10.1016/j.rse.2011.06.007
   Stehman SV, 2012, REMOTE SENS LETT, V3, P111, DOI 10.1080/01431161.2010.541950
   Stehman SV, 2009, INT J REMOTE SENS, V30, P5243, DOI 10.1080/01431160903131000
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Stehman SV, 1999, INT J REMOTE SENS, V20, P2423, DOI 10.1080/014311699212100
   Stehman SV, 2004, PHOTOGRAMM ENG REM S, V70, P743, DOI 10.14358/PERS.70.6.743
   STEHMAN SV, 1995, INT J REMOTE SENS, V16, P589, DOI 10.1080/01431169508954425
   Stehman SV, 1998, REMOTE SENS ENVIRON, V64, P331, DOI 10.1016/S0034-4257(98)00010-8
   Stehman SV, 2000, REMOTE SENS ENVIRON, V72, P35, DOI 10.1016/S0034-4257(99)00090-5
   Stehman SV, 2001, PHOTOGRAMM ENG REM S, V67, P727
   STEHMAN SV, 1992, PHOTOGRAMM ENG REM S, V58, P1343
   Stow DA, 2004, REMOTE SENS ENVIRON, V89, P281, DOI 10.1016/j.rse.2003.10.018
   Subramanian V., 2018, DEEP LEARNING PYTORC, V0, P0
   Tharwat A., 2021, APPL COMPUTING INFOR, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Tianheng Cheng, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP660, DOI 10.1007/978-3-030-58568-6_39
   Warner T, 2011, GEOGR COMPASS, V5, P781, DOI 10.1111/j.1749-8198.2011.00451.x
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Wei X, 2018, REMOTE SENS LETT, V9, P199, DOI 10.1080/2150704X.2017.1410291
   Witharana C, 2020, ISPRS J PHOTOGRAMM, V170, P174, DOI 10.1016/j.isprsjprs.2020.10.010
   Wright C, 2007, REMOTE SENS ENVIRON, V107, P582, DOI 10.1016/j.rse.2006.10.019
   Wu T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182910
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang WX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071085
   Zhang WX, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091487
   Zheng Z, 2020, ISPRS J PHOTOGRAMM, V166, P1, DOI 10.1016/j.isprsjprs.2020.04.019
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 121
TC 17
Z9 17
U1 13
U2 57
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL 15
PY 2021
VL 13
IS 13
BP 
EP 
DI 10.3390/rs13132591
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TG4OX
UT WOS:000671387200001
DA 2023-04-26
ER

PT J
AU He, D
   Zhong, YF
   Wang, XY
   Zhang, LP
AF He, Da
   Zhong, Yanfei
   Wang, Xinyu
   Zhang, Liangpei
TI Deep Convolutional Neural Network Framework for Subpixel Mapping
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Convolutional neural networks; Uncertainty; Hyperspectral imaging; Kernel; Training; Superresolution; Convolution; Convolutional neural network (CNN); hyperspectral imagery; mixed pixel problem; subpixel mapping (SPM); super-resolution (SR) network
ID land-cover; contouring methods; map model; pixel; superresolution
AB Subpixel mapping (SPM) is an effective way to solve the mixed pixel problem, which is a ubiquitous phenomenon in remotely sensed imagery, by characterizing subpixel distribution within the mixed pixels. In fact, the majority of the classical and state-of-the-art SPM algorithms can be viewed as a convolution process, but these methods rely heavily on fixed and handcrafted kernels that are insufficient in characterizing a geographically realistic distribution image. In addition, the traditional SPM approach is based on the prerequisite of abundance images derived from spectral unmixing (SU), during which process uncertainty inherently exists and is propagated to the SPM. In this article, a kernel-learnable convolutional neural network (CNN) framework for subpixel mapping (SPMCNN-F) is proposed. In SPMCNN-F, the kernel is learnable during the training stage based on the given training sample pairs of low- and high-resolution patches for learning a geographically realistic prior, instead of fixed priors. The end-to-end mapping structure enables direct subpixel information extraction from the original coarse image, avoiding the uncertainty propagation from the SU. In the experiments undertaken in this study, two state-of-the-art super-resolution networks were selected as application demonstrations of the proposed SPMCNN-F method. In experiment part, three hyperspectral image data sets were adopted, two in a synthetic coarse image approach and one in a real coarse image approach, for the validation. Additionally, a new data set with pairs of Moderate-resolution Imaging Spectroradiometer (MODIS) and Landsat images were adopted in a real coarse image approach, for further validation of SPMCNN-F in large-scale area. The restored fine distribution images obtained in all the experiments showed a perceptually better reconstruction quality, both qualitatively and quantitatively, confirming the superiority of the proposed SPM framework.
C1 [He, Da] Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
   [Zhong, Yanfei; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Zhong, Yanfei; Zhang, Liangpei] Wuhan Univ, Hubei Prov Engn Res Ctr Nat Resources Remote Sens, Wuhan 430079, Peoples R China.
   [Wang, Xinyu] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
C3 Sun Yat Sen University; Wuhan University; Wuhan University; Wuhan University
RP Zhong, YF (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM heda@mail.sysu.edu.cn; zhongyanfei@whu.edu.cn; wangxinyu@whu.edu.cn; zlp62@whu.edu.cn
FU National Natural Science Foundation of China [42071350, 41771385]; China Postdoctoral Science Foundation
CR Akbari H, 2010, IEEE T BIO-MED ENG, V57, P2011, DOI 10.1109/TBME.2010.2049110
   [Anonymous], 2021, ARXIV151106434, V0, P0
   Atkinson PM, 2009, INT J REMOTE SENS, V30, P5293, DOI 10.1080/01431160903131034
   Atkinson PM, 2005, PHOTOGRAMM ENG REM S, V71, P839, DOI 10.14358/PERS.71.7.839
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P917, DOI 10.1080/014311697217224
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP), V0, P0
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Chen YH, 2015, IEEE J-STARS, V8, P2040, DOI 10.1109/JSTARS.2015.2417191
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Farsiu S, 2006, IEEE T IMAGE PROCESS, V15, P141, DOI 10.1109/TIP.2005.860336
   Feng RY, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030250
   Feng RY, 2016, IEEE T GEOSCI REMOTE, V54, P2855, DOI 10.1109/TGRS.2015.2506612
   Fisher P, 1997, INT J REMOTE SENS, V18, P679, DOI 10.1080/014311697219015
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   He D, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110894
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kress R., 2014, TIKHONOV REGULARIZAT, V0, P0
   Ledig C, 2017, PROC CVPR IEEE, V0, PP105, DOI 10.1109/CVPR.2017.19
   Lee DK, 1999, NAT NEUROSCI, V2, P375, DOI 10.1038/7286
   Li XD, 2014, IEEE J-STARS, V7, P29, DOI 10.1109/JSTARS.2013.2264828
   Li XD, 2012, INT J REMOTE SENS, V33, P7886, DOI 10.1080/01431161.2012.703347
   Ling F, 2019, REMOTE SENS LETT, V10, P598, DOI 10.1080/2150704X.2019.1587196
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Ma XF, 2019, IEEE J-STARS, V12, P4930, DOI 10.1109/JSTARS.2019.2941089
   Mertens KC, 2003, INT J REMOTE SENS, V24, P4241, DOI 10.1080/01431160310001595073
   Mertens KC, 2006, INT J REMOTE SENS, V27, P3293, DOI 10.1080/01431160500497127
   Ng MK, 2007, EURASIP J ADV SIG PR, V0, P0, DOI DOI 10.1155/2007/74585
   Palsson B, 2018, IEEE ACCESS, V6, P25646, DOI 10.1109/ACCESS.2018.2818280
   Picon A, 2009, IEEE T IND INFORM, V5, P483, DOI 10.1109/TII.2009.2031238
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, PS110, DOI 10.1016/j.rse.2007.07.028
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Shi WZ, 2016, PROC CVPR IEEE, V0, PP1874, DOI 10.1109/CVPR.2016.207
   Su YF, 2012, IEEE J-STARS, V5, P1403, DOI 10.1109/JSTARS.2012.2191537
   Su YF, 2012, IEEE J-STARS, V5, P1428, DOI 10.1109/JSTARS.2012.2216514
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tatem AJ, 2002, REMOTE SENS ENVIRON, V79, P1, DOI 10.1016/S0034-4257(01)00229-2
   Tolpekin VA, 2009, IEEE T GEOSCI REMOTE, V47, P3283, DOI 10.1109/TGRS.2009.2019126
   Wang QM, 2016, IEEE T GEOSCI REMOTE, V54, P386, DOI 10.1109/TGRS.2015.2457672
   Wang QM, 2012, INT J REMOTE SENS, V33, P6480, DOI 10.1080/01431161.2012.690541
   Wang XY, 2017, IEEE T GEOSCI REMOTE, V55, P6287, DOI 10.1109/TGRS.2017.2724944
   Xu X, 2018, IEEE T GEOSCI REMOTE, V56, P6763, DOI 10.1109/TGRS.2018.2842748
   Xu X, 2014, IEEE T GEOSCI REMOTE, V52, P787, DOI 10.1109/TGRS.2013.2244095
   Xu X, 2013, IEEE J-STARS, V6, P580, DOI 10.1109/JSTARS.2012.2227246
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Zeiler MD, 2011, IEEE I CONF COMP VIS, V0, PP2018, DOI 10.1109/ICCV.2011.6126474
   Zhang LP, 2008, NEUROCOMPUTING, V71, P2046, DOI 10.1016/j.neucom.2007.08.033
   Zhao J, 2018, ISPRS J PHOTOGRAMM, V135, P31, DOI 10.1016/j.isprsjprs.2017.10.006
   Zhong YF, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111416
   Zhong YF, 2018, IEEE GEOSC REM SEN M, V6, P46, DOI 10.1109/MGRS.2018.2867592
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zhong YF, 2016, ISPRS J PHOTOGRAMM, V119, P49, DOI 10.1016/j.isprsjprs.2016.04.008
   Zhong YF, 2015, IEEE T GEOSCI REMOTE, V53, P1411, DOI 10.1109/TGRS.2014.2340734
   Zhong YF, 2013, PATTERN RECOGN, V46, P2902, DOI 10.1016/j.patcog.2013.04.009
   Zhu FY, 2014, ISPRS J PHOTOGRAMM, V88, P101, DOI 10.1016/j.isprsjprs.2013.11.014
   Zuo W., 2019, IEEE C COMP VIS PATT, V0, P0
NR 60
TC 23
Z9 23
U1 5
U2 41
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD NOV 15
PY 2021
VL 59
IS 11
BP 9518
EP 9539
DI 10.1109/TGRS.2020.3032475
PG 22
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology
GA WN6BE
UT WOS:000711850900046
DA 2023-04-26
ER

PT J
AU Ma, TH
   Xu, ZB
   Meng, DY
   Zhao, XL
AF Ma, Tian-Hui
   Xu, Zongben
   Meng, Deyu
   Zhao, Xi-Le
TI Hyperspectral Image Restoration Combining Intrinsic Image Characterization With Robust Noise Modeling
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Convolutional neural network (CNN); hyperspectral image (HSI) restoration; low-rank tensor approximation; maximum a posteriori (MAP); noise modeling
ID matrix factorization; recovery; representation; reduction; removal; tensors; sparse
AB In hyperspectral image (HSI) processing, a fundamental issue is to restore HSI data from various degradations such as noise corruption and information missing. However, most existing methods more or less ignore the abundant prior knowledge on HSIs and the embedded noise, leading to suboptimal performance in practice. In this article, we propose a novel HSI restoration method by fully considering the intrinsic image structures and the complex noise characteristics. For HSIs, the global correlation is captured by the Kronecker-basis-representation-based tensor low-rankness measure, which integrates the insights delivered by both CP and Tucker decompositions; the local regularity is depicted by a plug-and-play spatial-spectral convolutional neural network with strong fitting ability to complex image features. For realistic noise, its statistical characteristics are encoded by a nonidentical and nonindependent distributed mixture of Gaussians distribution with flexible fitting capability. Then, we incorporate these image and noise priors into a probabilistic model based on the maximum a posteriori principle, and develop a solving scheme by combining expectation-maximization and alternating direction method of multipliers. Extensive experimental results on both simulated and real scenarios demonstrate the effectiveness of the proposed method and its superiority over the compared state-of-the- arts.
C1 [Ma, Tian-Hui; Xu, Zongben; Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
   [Ma, Tian-Hui; Xu, Zongben; Meng, Deyu] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Peoples R China.
   [Zhao, Xi-Le] Univ Elect Sci & Technol China, Sch Math Sci, Res Ctr Image & Vis Comp, Chengdu 611731, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; University of Electronic Science & Technology of China
RP Meng, DY (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.; Meng, DY (corresponding author), Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Peoples R China.
EM nkmth0307@126.com; zbxu@mail.xjtu.edu.cn; dymeng@mail.xjtu.edu.cn; xlzhao122003@163.com
FU National Natural Science Foundation of China [U1811461, 11690011, 61721002, 11971373, 11901450, 61876203]; National Postdoctoral Program for Innovative Talents [BX20180252]; China Postdoctoral Science Foundation [2018M643611]
CR Aggarwal HK, 2016, IEEE GEOSCI REMOTE S, V13, P442, DOI 10.1109/LGRS.2016.2518218
   Bengua JA, 2017, IEEE T IMAGE PROCESS, V26, P2466, DOI 10.1109/TIP.2017.2672439
   Burger HC, 2012, PROC CVPR IEEE, V0, PP2392, DOI 10.1109/CVPR.2012.6247952
   Candes EJ, 2011, J ACM, V58, P0, DOI 10.1145/1970392.1970395
   Cao XY, 2016, IEEE T IMAGE PROCESS, V25, P4677, DOI 10.1109/TIP.2016.2593343
   CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286
   Chang Y, 2020, IEEE T CYBERNETICS, V50, P4558, DOI 10.1109/TCYB.2020.2983102
   Chang Y, 2019, IEEE T GEOSCI REMOTE, V57, P667, DOI 10.1109/TGRS.2018.2859203
   Chen XA, 2018, IEEE T NEUR NET LEAR, V29, P5380, DOI 10.1109/TNNLS.2018.2796606
   Chen Y, 2018, IEEE T CYBERNETICS, V48, P1054, DOI 10.1109/TCYB.2017.2677944
   Chen Y, 2020, IEEE T GEOSCI REMOTE, V58, P1348, DOI 10.1109/TGRS.2019.2946050
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fan HY, 2017, IEEE J-STARS, V10, P4589, DOI 10.1109/JSTARS.2017.2714338
   Gabay D., 1976, COMPUTERS & MATHEMATICS WITH APPLICATIONS, V2, P17, DOI 10.1016/0898-1221(76)90003-1
   GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41
   Golbabaee M, 2012, IEEE IMAGE PROC, V0, PP933, DOI 10.1109/ICIP.2012.6467014
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   He W, 2019, PROC CVPR IEEE, V0, PP6861, DOI 10.1109/CVPR.2019.00703
   He W, 2019, IEEE T GEOSCI REMOTE, V57, P8998, DOI 10.1109/TGRS.2019.2924017
   He W, 2018, IEEE J-STARS, V11, P713, DOI 10.1109/JSTARS.2018.2800701
   Jain V., 2008, NIPS 08, V21, P769
   Ji TY, 2018, IEEE T GEOSCI REMOTE, V56, P3047, DOI 10.1109/TGRS.2018.2790262
   Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Li XH, 2019, ISPRS J PHOTOGRAMM, V148, P103, DOI 10.1016/j.isprsjprs.2018.12.013
   Li XH, 2014, IEEE T GEOSCI REMOTE, V52, P7086, DOI 10.1109/TGRS.2014.2307354
   Lin BH, 2020, IEEE T IMAGE PROCESS, V29, P565, DOI 10.1109/TIP.2019.2928627
   Lin J, 2021, IEEE T GEOSCI REMOTE, V59, P7739, DOI 10.1109/TGRS.2020.3032168
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu XF, 2012, IEEE T GEOSCI REMOTE, V50, P3717, DOI 10.1109/TGRS.2012.2187063
   Liu YP, 2020, IEEE T CIRC SYST VID, V30, P944, DOI 10.1109/TCSVT.2019.2901311
   Ma TH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081278
   Mazya V, 1996, IMA J NUMER ANAL, V16, P13, DOI 10.1093/imanum/16.1.13
   Meng DY, 2013, IEEE I CONF COMP VIS, V0, PP1337, DOI 10.1109/ICCV.2013.169
   MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Othman H, 2006, IEEE T GEOSCI REMOTE, V44, P397, DOI 10.1109/TGRS.2005.860982
   Papa JP, 2010, PATTERN RECOGN LETT, V31, P1876, DOI 10.1016/j.patrec.2010.02.012
   Rasti B, 2020, IEEE GEOSCI REMOTE S, V17, P474, DOI 10.1109/LGRS.2019.2924344
   Rasti B, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030482
   Rasti B, 2017, IEEE GEOSCI REMOTE S, V14, P2335, DOI 10.1109/LGRS.2017.2764059
   Rasti B, 2012, INT GEOSCI REMOTE SE, V0, PP1349, DOI 10.1109/IGARSS.2012.6351286
   Renard N, 2008, IEEE GEOSCI REMOTE S, V5, P138, DOI 10.1109/LGRS.2008.915736
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Ryu E. K., 2019, P INT C MACH LEARN M, V0, P5546
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Vedaldi A, 2015, MM15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, V0, PP689, DOI 10.1145/2733373.2807412
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, V0, PP945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang Y, 2018, IEEE J-STARS, V11, P1227, DOI 10.1109/JSTARS.2017.2779539
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie Q, 2018, IEEE T PATTERN ANAL, V40, P1888, DOI 10.1109/TPAMI.2017.2734888
   Yang JH, 2020, J COMPUT APPL MATH, V363, P124, DOI 10.1016/j.cam.2019.06.004
   Yue ZS, 2020, IEEE T NEUR NET LEAR, V31, P1070, DOI 10.1109/TNNLS.2019.2917328
   Yuhas R. H., 1993, P SUMM 4 ANN JPL AIR, V0, P0
   Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang Z., 2014, P IEEE C COMP VIS PA, V0, P3838
   Zhao Q, 2014, PR MACH LEARN RES, V32, P55
   Zhao Q, 2015, IEEE T NEUR NET LEAR, V26, P825, DOI 10.1109/TNNLS.2014.2387376
   Zhao QB, 2015, IEEE T PATTERN ANAL, V37, P1751, DOI 10.1109/TPAMI.2015.2392756
   Zhao XL, 2020, NEUROCOMPUTING, V400, P137, DOI 10.1016/j.neucom.2020.03.018
   Zhao YQ, 2015, IEEE T GEOSCI REMOTE, V53, P296, DOI 10.1109/TGRS.2014.2321557
NR 65
TC 1
Z9 1
U1 6
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1628
EP 1644
DI 10.1109/JSTARS.2020.3046488
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PS3FD
UT WOS:000607810600015
DA 2023-04-26
ER

PT J
AU Harmati, IA
AF Harmati, Istvan A.
TI Dynamics of Fuzzy-Rough Cognitive Networks
SO SYMMETRY-BASEL
LA English
DT Article
DE fuzzy-rough cognitive network; fuzzy cognitive map; granular computing; fuzzy-rough sets; stability; convergence
ID maps; sets; uncertainty; stability
AB Fuzzy-rough cognitive networks (FRCNs) are interpretable recurrent neural networks, primarily designed for solving classification problems. Their structure is simple and transparent, while the performance is comparable to the well-known black-box classifiers. Although there are many applications on fuzzy cognitive maps and recently for FRCNS, only a very limited number of studies discuss the theoretical issues of these models. In this paper, we examine the behaviour of FRCNs viewing them as discrete dynamical systems. It will be shown that their mathematical properties highly depend on the size of the network, i.e., there are structural differences between the long-term behaviour of FRCN models of different size, which may influence the performance of these modelling tools.
C1 [Harmati, Istvan A.] Szecheny Istvan Univ, Dept Math & Computat Sci, H-9026 Gyor, Hungary.
RP Harmati, IA (corresponding author), Szecheny Istvan Univ, Dept Math & Computat Sci, H-9026 Gyor, Hungary.
EM harmati@sze.hu
FU National Research, Development and Innovation Office (NKFIH) [K124055]
CR Atanassov KT, 2012, STUD FUZZ SOFT COMP, V283, P1, DOI 10.1007/978-3-642-29127-2
   Boutalis Y, 2009, IEEE T FUZZY SYST, V17, P874, DOI 10.1109/TFUZZ.2009.2017519
   Cao B, 2020, IEEE T FUZZY SYST, V28, P939, DOI 10.1109/TFUZZ.2020.2972207
   Concepcion L, 2022, IEEE T CYBERNETICS, V52, P2994, DOI 10.1109/TCYB.2020.3022527
   Deveci M, 2020, J ENVIRON MANAGE, V270, P0, DOI 10.1016/j.jenvman.2020.110916
   Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, V0, P210
   DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107
   Falcon R, 2019, GRANULAR COMPUT, V4, P451, DOI 10.1007/s41066-018-0104-7
   Ganivada A, 2011, THEOR COMPUT SCI, V412, P5834, DOI 10.1016/j.tcs.2011.05.038
   Giesl P, 2007, J DIFFER EQU APPL, V13, P523, DOI 10.1080/10236190601135209
   Gokasar I, 2022, RES TRANSP ECON, V91, P0, DOI 10.1016/j.retrec.2021.101029
   Hadjistoykov PP, 2014, CR ACAD BULG SCI, V67, P1233
   Hajek P., 2017, INT C INTELLIGENT DE, V0, P207
   Hajek P, 2020, NEUROCOMPUTING, V400, P173, DOI 10.1016/j.neucom.2020.03.013
   Hajek P, 2016, IEEE INT FUZZY SYST, V0, PP531, DOI 10.1109/FUZZ-IEEE.2016.7737732
   Harmati IA, 2018, COMM COM INF SC, V853, P490, DOI 10.1007/978-3-319-91473-2_42
   Ji WT, 2021, WIRES DATA MIN KNOWL, V11, P0, DOI 10.1002/widm.1402
   Knight CJK, 2014, APPL SOFT COMPUT, V15, P193, DOI 10.1016/j.asoc.2013.10.030
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kuznetsov Y. A., 2013, ELEMENTS APPL BIFURC, V112, P0
   Lee IK, 2010, IEICE T INF SYST, VE93D, P2883, DOI 10.1587/transinf.E93.D.2883
   Li CZ, 2019, ENERGIES, V12, P0, DOI 10.3390/en12214214
   Li X, 2020, EXPERT SYST APPL, V160, P0, DOI 10.1016/j.eswa.2020.113763
   Lingras P, 2007, IEEE INT CONF FUZZY, V0, P125
   Napoles G, 2018, NEURAL NETWORKS, V97, P19, DOI 10.1016/j.neunet.2017.08.007
   Napoles G, 2017, INT J APPROX REASON, V85, P79, DOI 10.1016/j.ijar.2017.03.011
   Napoles G, 2016, KNOWL-BASED SYST, V91, P46, DOI 10.1016/j.knosys.2015.10.015
   Pal SK, 2017, STUD COMPUT INTELL, V712, P39, DOI 10.1007/978-3-319-57115-7_2
   Papageorgiou EI, 2013, IEEE T FUZZY SYST, V21, P342, DOI 10.1109/TFUZZ.2012.2214224
   Papageorgiou EI, 2013, IEEE T FUZZY SYST, V21, P66, DOI 10.1109/TFUZZ.2012.2201727
   PAWLAK Z, 1995, COMPUT INTELL-US, V11, P227, DOI 10.1111/j.1467-8640.1995.tb00029.x
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pawlak Z., 2002, J TELECOMMUNICATIONS, V3, P7
   Pedrycz W, 2001, NEUROCOMPUTING, V36, P205, DOI 10.1016/S0925-2312(00)00342-8
   Riaz S, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8101869
   Rudin W., 1976, PRINCIPLES MATH ANAL, V3, P0
   Salmeron JL, 2010, EXPERT SYST APPL, V37, P7581, DOI 10.1016/j.eswa.2010.04.085
   Samek W., 2019, EXPLAINABLE INTERPRE, V0, PP5, DOI 10.1007/978-3-030-28954-6_1
   Schultz P, 2017, NEW J PHYS, V19, P0, DOI 10.1088/1367-2630/aa5a7b
   Skowron A, 2018, NAT COMPUT, V17, P855, DOI 10.1007/s11047-018-9700-3
   Susanto H, 2009, APPL MATH COMPUT, V215, P1084, DOI 10.1016/j.amc.2009.06.041
   Szwed P, 2021, APPL SOFT COMPUT, V105, P0, DOI 10.1016/j.asoc.2021.107271
   Vanloffelt Marnick, 2019, 2019 18TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP922, DOI 10.1109/ICMLA.2019.00159
   Wiggins S., 2003, INTRO APPL NONLINEAR, V2, P0
   Zadeh L. A., 1978, FUZZY SETS AND SYSTEMS, V1, P3, DOI 10.1016/0165-0114(78)90029-5
   Zadeh L.A., 1979, ADV FUZZY SET THEORY, V11, P18
   Zhang C, 2020, COMPUT IND, V115, P0, DOI 10.1016/j.compind.2019.07.007
   Zhang HY, 2019, INT J APPROX REASON, V110, P31, DOI 10.1016/j.ijar.2019.03.011
   Zhang K, 2020, FUZZY SET SYST, V383, P92, DOI 10.1016/j.fss.2019.06.019
NR 50
TC 0
Z9 0
U1 0
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2073-8994
J9 SYMMETRY-BASEL
JI Symmetry-Basel
PD MAY 15
PY 2021
VL 13
IS 5
BP 
EP 
DI 10.3390/sym13050881
PG 24
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA SI1LY
UT WOS:000654588800001
DA 2023-04-26
ER

PT J
AU Stanislawski, LV
   Shavers, EJ
   Wang, SW
   Jiang, Z
   Usery, EL
   Moak, E
   Duffy, A
   Schott, J
AF Stanislawski, Lawrence, V
   Shavers, Ethan J.
   Wang, Shaowen
   Jiang, Zhe
   Usery, E. Lynn
   Moak, Evan
   Duffy, Alexander
   Schott, Joel
TI Extensibility of U-Net Neural Network Model for Hydrographic Feature Extraction and Implications for Hydrologic Modeling
SO REMOTE SENSING
LA English
DT Article
DE machine learning; neural network; U-net; feature extraction; hydrography
ID flow; classification; resolution; segmentation
AB Accurate maps of regional surface water features are integral for advancing ecologic, atmospheric and land development studies. The only comprehensive surface water feature map of Alaska is the National Hydrography Dataset (NHD). NHD features are often digitized representations of historic topographic map blue lines and may be outdated. Here we test deep learning methods to automatically extract surface water features from airborne interferometric synthetic aperture radar (IfSAR) data to update and validate Alaska hydrographic databases. U-net artificial neural networks (ANN) and high-performance computing (HPC) are used for supervised hydrographic feature extraction within a study area comprised of 50 contiguous watersheds in Alaska. Surface water features derived from elevation through automated flow-routing and manual editing are used as training data. Model extensibility is tested with a series of 16 U-net models trained with increasing percentages of the study area, from about 3 to 35 percent. Hydrography is predicted by each of the models for all watersheds not used in training. Input raster layers are derived from digital terrain models, digital surface models, and intensity images from the IfSAR data. Results indicate about 15 percent of the study area is required to optimally train the ANN to extract hydrography when F1-scores for tested watersheds average between 66 and 68. Little benefit is gained by training beyond 15 percent of the study area. Fully connected hydrographic networks are generated for the U-net predictions using a novel approach that constrains a D-8 flow-routing approach to follow U-net predictions. This work demonstrates the ability of deep learning to derive surface water feature maps from complex terrain over a broad area.
C1 [Stanislawski, Lawrence, V; Shavers, Ethan J.; Usery, E. Lynn] US Geol Survey, Ctr Excellence Geospatial Informat Sci, Rolla, MO 65401 USA.
   [Wang, Shaowen] Univ Illinois, Dept Geog & Geog Informat Sci, Urbana, IL 61801 USA.
   [Jiang, Zhe] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
   [Moak, Evan; Duffy, Alexander; Schott, Joel] Univ Missouri Sci & Technol, Coll Engn & Comp, Rolla, MO 65401 USA.
C3 United States Department of the Interior; United States Geological Survey; University of Illinois System; University of Illinois Urbana-Champaign; State University System of Florida; University of Florida; University of Missouri System; Missouri University of Science & Technology
RP Stanislawski, LV (corresponding author), US Geol Survey, Ctr Excellence Geospatial Informat Sci, Rolla, MO 65401 USA.
EM lstan@usgs.gov; eshavers@usgs.gov; shaowen@illinois.edu; zhe.jiang@ufl.edu; usery@usgs.gov; ebmy83@mst.edu; aduffy@contractor.usgs.gov; jschott@contractor.usgs.gov
FU National Science Foundation (NSF) [1743184, 1850546, 2008973]; Direct For Computer & Info Scie & Enginr; Div Of Information & Intelligent Systems [2008973] Funding Source: National Science Foundation; Office of Advanced Cyberinfrastructure (OAC); Direct For Computer & Info Scie & Enginr [1743184] Funding Source: National Science Foundation
CR Agarap A.F., 2019, ARXIV2019180308375, V0, P0
   Andersen HE, 2005, CAN J REMOTE SENS, V31, P283, DOI 10.5589/m05-016
   Archuleta C.M., 2020, ELEVATION DERIVED HY, V11, P0, DOI 10.3133/tm11B12
   Bernhardt H., 2020, EARTH SCI ARTIFICIAL, V0, P243
   Chen B, 2017, J HYDROL, V553, P338, DOI 10.1016/j.jhydrol.2017.08.009
   Chen Y, 2020, J HYDROL, V588, P0, DOI 10.1016/j.jhydrol.2020.125092
   Chen Y, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10050585
   Clubb FJ, 2014, WATER RESOUR RES, V50, P4283, DOI 10.1002/2013WR015167
   Deumlich D, 2010, J PLANT NUTR SOIL SC, V173, P843, DOI 10.1002/jpln.200900094
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Doneus M, 2013, REMOTE SENS-BASEL, V5, P6427, DOI 10.3390/rs5126427
   Ehlschlaeger C.R, 1989, P INT GEOGR INF SYST, V0, P0
   Feng WQ, 2019, IEEE GEOSCI REMOTE S, V16, P618, DOI 10.1109/LGRS.2018.2879492
   Gargiulo M, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20102969
   Guritz R., 2016, P AL SURV MAPP C ANC, V0, P0
   Hashim S., 2015, INT J COMPUT COMMUN, V2, P114, DOI 10.15242/IJCCIE.D0315014
   Ioffe S., 2015, J MACH LEARN RES, V37, P9
   Jasiewicz J, 2013, GEOMORPHOLOGY, V182, P147, DOI 10.1016/j.geomorph.2012.11.005
   Kampes B., 2011, P ASPRS 2011 ANN C M, V0, P0
   Kang YH, 2019, INT J CARTOGRAPHY, V5, P115, DOI 10.1080/23729333.2019.1615729
   Kavzoglu T, 2009, ENVIRON MODELL SOFTW, V24, P850, DOI 10.1016/j.envsoft.2008.11.012
   Kennelly PJ, 2014, INT J GEOGR INF SCI, V28, P383, DOI 10.1080/13658816.2013.848985
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lin PR, 2021, SCI DATA, V8, P0, DOI 10.1038/s41597-021-00819-9
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Maidment DR, 2017, J AM WATER RESOUR AS, V53, P245, DOI 10.1111/1752-1688.12474
   Maune D.F., 2008, AL DEM WORKSH WHIT, V0, P0
   Metz M, 2011, HYDROL EARTH SYST SC, V15, P667, DOI 10.5194/hess-15-667-2011
   Mitas L, 1998, WATER RESOUR RES, V34, P505, DOI 10.1029/97WR03347
   Mitasova H, 2004, DEV WATER SCI, V55, P1479
   Montgomery L., 2014, ANCHORAGE DAILY 1015, V0, P0
   MOORE ID, 1991, HYDROL PROCESS, V5, P3, DOI 10.1002/hyp.3360050103
   Nemni E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162532
   Newman DR, 2018, GEOMORPHOLOGY, V312, P40, DOI 10.1016/j.geomorph.2018.04.003
   Passalacqua P, 2010, J GEOPHYS RES-EARTH, V115, P0, DOI 10.1029/2009JF001254
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Poppenga SK, 2013, J AM WATER RESOUR AS, V49, P371, DOI 10.1111/jawr.12027
   Regan RS, 2019, ENVIRON MODELL SOFTW, V111, P192, DOI 10.1016/j.envsoft.2018.09.023
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sangireddy H, 2016, ENVIRON MODELL SOFTW, V83, P58, DOI 10.1016/j.envsoft.2016.04.026
   Schultz LD, 2017, J ARID ENVIRON, V145, P60, DOI 10.1016/j.jaridenv.2017.05.008
   Shaker A, 2019, ISPRS J PHOTOGRAMM, V152, P94, DOI 10.1016/j.isprsjprs.2019.04.005
   Shavers E, 2020, ENVIRON MODELL SOFTW, V132, P0, DOI 10.1016/j.envsoft.2020.104809
   Shin S, 2017, HYDROL PROCESS, V31, P1650, DOI 10.1002/hyp.11135
   Simley J. D., 2009, US GEOLOGICAL SURVEY, V0, P0
   Stanislawski L., 2018, INT ARCH PHOTOGRAMM, V42, P671, DOI 10.5194/isprs-archives-XLII-4-597-2018
   Stanislawski L.V., 2019, ABSTR INT CARTOGR AS, V1, P350, DOI 10.5194/ica-abs-1-350-2019
   Stepinski T., 2011, PROC GEOMORPHOMETRY, V0, P109
   Tarboton D.G., 2009, P 18 WORLD IMACS MOD, V0, P0
   Tarboton D. G., 2004, P WORLD WAT ENV RES, V0, P0, DOI DOI 10.1061/40569(2001)166
   Tarboton DG, 1997, WATER RESOUR RES, V33, P309, DOI 10.1029/96WR03137
   Terziotti S., 2018, AWRA WATER RESOUR IM, V20, P28
   Terziotti S., 2020, TECHNIQUES METHODS, V0, P0, DOI DOI 10.3133/tm11B11
   Tompson J, 2015, P IEEE C COMP VIS PA, V0, P0
   U.S. Geological Survey, 2017, AL DIG SURF MOD DSMS, V0, P0
   U.S. Geological Survey, 2017, AL ORTH RAD INT IM U, V0, P0
   U.S. Geological Survey, 2017, 5 MET AL DIG EL MOD, V0, P0
   Wang GJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050795
   Wilson JP, 2007, HYDROL PROCESS, V21, P1026, DOI 10.1002/hyp.6277
   Woodrow K, 2016, J HYDROL, V540, P1022, DOI 10.1016/j.jhydrol.2016.07.018
   Wright W., 2012, P AGR APPL EC ASS 20, V0, P0
   Xu Z., 2019, P ASPRS INT LID MAPP, V0, P0
   Xu ZW, 2021, ENVIRON MODELL SOFTW, V140, P0, DOI 10.1016/j.envsoft.2021.104992
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zaksek K, 2011, REMOTE SENS-BASEL, V3, P398, DOI 10.3390/rs3020398
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8
NR 68
TC 7
Z9 7
U1 5
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 15
PY 2021
VL 13
IS 12
BP 
EP 
DI 10.3390/rs13122368
PG 27
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SZ1OC
UT WOS:000666342600001
DA 2023-04-26
ER

PT J
AU Moutoussis, M
   Garzon, B
   Neufeld, S
   Bach, DR
   Rigoli, F
   Goodyer, I
   Bullmore, E
   Guitart-Masip, M
   Dolan, RJ
AF Moutoussis, Michael
   Garzon, Benjamin
   Neufeld, Sharon
   Bach, Dominik R.
   Rigoli, Francesco
   Goodyer, Ian
   Bullmore, Edward
   Guitart-Masip, Marc
   Dolan, Raymond J.
TI Decision-making ability, psychopathology, and brain connectivity
SO NEURON
LA English
DT Article
ID orbitofrontal cortex; individual-differences; prefrontal cortex; human hippocampus; conclusions bias; working-memory; cognitive map; whole-brain; reward; reliability
AB Decision-making is a cognitive process of central importance for the quality of our lives. Here, we ask whether a common factor underpins our diverse decision-making abilities. We obtained 32 decision-making measures from 830 young people and identified a common factor that we call "decision acuity,"which was distinct from IQ and reflected a generic decision-making ability. Decision acuity was decreased in those with aberrant thinking and low general social functioning. Crucially, decision acuity and IQ had dissociable brain signatures, in terms of their associated neural networks of resting-state functional connectivity. Decision acuity was reliably measured, and its relationship with functional connectivity was also stable when measured in the same individuals 18 months later. Thus, our behavioral and brain data identify a new cognitive construct that underpins decision-making ability across multiple domains. This construct may be important for understanding mental health, particularly regarding poor social function and aberrant thought patterns.
C1 [Moutoussis, Michael; Bach, Dominik R.; Dolan, Raymond J.] UCL, Wellcome Ctr Human Neuroimaging, London WC1N 3BG, England.
   [Moutoussis, Michael; Bach, Dominik R.; Guitart-Masip, Marc; Dolan, Raymond J.] Max Planck Univ Coll London, Ctr Computat Psychiat & Ageing Res, London WC1B 5EH, England.
   [Garzon, Benjamin] Karolinska Inst, Aging Res Ctr, Stockholm, Sweden.
   [Neufeld, Sharon; Goodyer, Ian; Bullmore, Edward] Univ Cambridge, Dept Psychiat, Cambridge CB2 0SZ, England.
   [Bach, Dominik R.] Univ Zurich, Psychiat Hosp, Dept Psychiat Psychotherapy & Psychosomat, Computat Psychiat Res, CH-8032 Zurich, Switzerland.
   [Rigoli, Francesco] City Univ London, Dept Psychol, London, England.
C3 University of London; University College London; Karolinska Institutet; University of Cambridge; University of Zurich; City University London
RP Moutoussis, M (corresponding author), UCL, Wellcome Ctr Human Neuroimaging, London WC1N 3BG, England.; Moutoussis, M (corresponding author), Max Planck Univ Coll London, Ctr Computat Psychiat & Ageing Res, London WC1B 5EH, England.
EM m.moutoussis@ucl.ac.uk
FU Wellcome Trust; Wellcome Strategic Award [095844/7/11/Z.]; Wellcome Investigator Award [098362/Z/12/Z]; Swedish Research Council [VR521-2013-2589, 2016-07213]; European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program [ERC-2018 CoG816564]; National Institute for Health Research (NIHR) UCLH Biomedical Research Centre
CR Axelrod BN, 2002, ASSESSMENT, V9, P17, DOI 10.1177/1073191102009001003
   Bach DR, 2020, NAT HUM BEHAV, V4, P832, DOI 10.1038/s41562-020-0867-0
   Bach DR, 2014, CURR BIOL, V24, P541, DOI 10.1016/j.cub.2014.01.046
   Badre D, 2012, NEURON, V73, P595, DOI 10.1016/j.neuron.2011.12.025
   Bickel WK, 2012, PHARMACOL THERAPEUT, V134, P287, DOI 10.1016/j.pharmthera.2012.02.004
   Blondel VD, 2008, J STAT MECH-THEORY E, V0, P0, DOI DOI 10.1088/1742-5468/2008/10/P10008
   Boorman ED, 2016, NEURON, V89, P1343, DOI 10.1016/j.neuron.2016.02.014
   Brown VM, 2020, BIOL PSYCHIAT-COGN N, V5, P601, DOI 10.1016/j.bpsc.2019.12.019
   Caspi A, 2014, CLIN PSYCHOL SCI, V2, P119, DOI 10.1177/2167702613497473
   Cavanagh JF, 2013, J NEUROSCI, V33, P8541, DOI 10.1523/JNEUROSCI.5754-12.2013
   Chen J, 2020, NEUROSCIENCE, V0, P0, DOI DOI 10.1101/2020.06.24.168724
   Christopoulos GI, 2009, J NEUROSCI, V29, P12574, DOI 10.1523/JNEUROSCI.2614-09.2009
   Chu C, 2012, NEUROIMAGE, V60, P59, DOI 10.1016/j.neuroimage.2011.11.066
   Chun H, 2010, J R STAT SOC B, V72, P3, DOI 10.1111/j.1467-9868.2009.00723.x
   Ciric R, 2018, NAT PROTOC, V13, P2801, DOI 10.1038/s41596-018-0065-y
   Collins AGE, 2018, P NATL ACAD SCI USA, V115, P2502, DOI 10.1073/pnas.1720963115
   Collins AGE, 2017, BIOL PSYCHIAT, V82, P431, DOI 10.1016/j.biopsych.2017.05.017
   Daw ND, 2011, NEURON, V69, P1204, DOI 10.1016/j.neuron.2011.02.027
   Daw ND, 2005, NAT NEUROSCI, V8, P1704, DOI 10.1038/nn1560
   Dayan P, 2014, TOP COGN SCI, V6, P204, DOI 10.1111/tops.12082
   de Boer L, 2019, P NATL ACAD SCI USA, V116, P261, DOI 10.1073/pnas.1816704116
   Dolan RJ, 2013, NEURON, V80, P312, DOI 10.1016/j.neuron.2013.09.007
   Dubois J, 2018, PHILOS T R SOC B, V373, P0, DOI 10.1098/rstb.2017.0284
   Eisenberg IW, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-10301-1
   Enkavi AZ, 2019, P NATL ACAD SCI USA, V116, P5472, DOI 10.1073/pnas.1818430116
   Eppinger B, 2017, COGN AFFECT BEHAV NE, V17, P406, DOI 10.3758/s13415-016-0487-3
   Ettinger U, 2015, SCHIZOPHRENIA BULL, V41, PS417, DOI 10.1093/schbul/sbu190
   Fair DA, 2009, PLOS COMPUT BIOL, V5, P0, DOI 10.1371/journal.pcbi.1000381
   da Silva CF, 2020, NAT HUM BEHAV, V4, P1053, DOI 10.1038/s41562-020-0905-y
   Fett AKJ, 2012, BRAIN, V135, P976, DOI 10.1093/brain/awr359
   Finn ES, 2015, NAT NEUROSCI, V18, P1664, DOI 10.1038/nn.4135
   Fox J, 2006, STRUCT EQU MODELING, V13, P465, DOI 10.1207/s15328007sem1303_7
   Friston KJ, 2013, FRONT HUM NEUROSCI, V7, P0, DOI 10.3389/fnhum.2013.00598
   Garvert MM, 2015, NEURON, V85, P418, DOI 10.1016/j.neuron.2014.12.033
   Geerligs L, 2015, J NEUROSCI, V35, P13949, DOI 10.1523/JNEUROSCI.1324-15.2015
   Giedd JN, 2004, ANN NY ACAD SCI, V1021, P77, DOI 10.1196/annals.1308.009
   Guitart-Masip M, 2012, NEUROIMAGE, V62, P154, DOI 10.1016/j.neuroimage.2012.04.024
   Hedge C, 2020, BIOL PSYCHIAT-COGN N, V5, P837, DOI 10.1016/j.bpsc.2020.05.004
   Hula A, 2015, PLOS COMPUT BIOL, V11, P0, DOI 10.1371/journal.pcbi.1004254
   Huys QJM, 2016, NAT NEUROSCI, V19, P404, DOI 10.1038/nn.4238
   Ito T, 2017, NAT COMMUN, V8, P0, DOI 10.1038/s41467-017-01000-w
   Jocham G, 2016, NEURON, V90, P177, DOI 10.1016/j.neuron.2016.02.018
   Kable JW, 2009, NEURON, V63, P733, DOI 10.1016/j.neuron.2009.09.003
   Kerr M, 2012, J CHILD PSYCHOL PSYC, V53, P826, DOI 10.1111/j.1469-7610.2011.02492.x
   Kiddle B, 2018, INT J EPIDEMIOL, V47, P18, DOI 10.1093/ije/dyx117
   King-Casas B, 2008, SCIENCE, V321, P806, DOI 10.1126/science.1156902
   Kong R, 2019, CEREB CORTEX, V29, P2533, DOI 10.1093/cercor/bhy123
   Kool W, 2017, PSYCHOL SCI, V28, P1321, DOI 10.1177/0956797617708288
   Kundu P, 2017, NEUROIMAGE, V154, P59, DOI 10.1016/j.neuroimage.2017.03.033
   Lincoln TM, 2010, J ABNORM PSYCHOL, V119, P40, DOI 10.1037/a0018118
   Lincoln TM, 2010, PSYCHOL MED, V40, P169, DOI 10.1017/S003329170999095X
   Loh E, 2017, CEREB CORTEX, V27, P201, DOI 10.1093/cercor/bhw378
   Luo Y, 2018, NAT COMMUN, V9, P0, DOI 10.1030/s41467-018-07138-5
   McDermott CL, 2019, J NEUROSCI, V39, P1365, DOI 10.1523/JNEUROSCI.1808-18.2018
   Moutoussis M, 2018, PLOS COMPUT BIOL, V14, P0, DOI 10.1371/journal.pcbi.1006679
   Moutoussis M, 2016, PLOS COMPUT BIOL, V12, P0, DOI 10.1371/journal.pcbi.1004965
   Moutoussis M, 2011, COGN NEUROPSYCHIATRY, V16, P422, DOI 10.1080/13546805.2010.548678
   Murray JD, 2017, J NEUROSCI, V37, P12167, DOI 10.1523/JNEUROSCI.0343-17.2017
   Muthen L.K., 2008, EXPLORATORY FACTOR A, V0, P0
   Nicolle A, 2012, NEURON, V75, P1114, DOI 10.1016/j.neuron.2012.07.023
   Noble S, 2017, CEREB CORTEX, V27, P5415, DOI 10.1093/cercor/bhx230
   ONeil EB, 2015, J NEUROSCI, V35, P15039, DOI 10.1523/JNEUROSCI.1915-15.2015
   Padoa-Schioppa C, 2006, NATURE, V441, P223, DOI 10.1038/nature04676
   Patalay P, 2015, BRIT J PSYCHIAT, V207, P15, DOI 10.1192/bjp.bp.114.149591
   Paus T, 2008, NAT REV NEUROSCI, V9, P947, DOI 10.1038/nrn2513
   Payzan-LeNestour E, 2013, NEURON, V79, P191, DOI 10.1016/j.neuron.2013.04.037
   Pearson JM, 2011, TRENDS COGN SCI, V15, P143, DOI 10.1016/j.tics.2011.02.002
   Pearson RM, 2015, J AFFECT DISORDERS, V171, P60, DOI 10.1016/j.jad.2014.08.057
   Phelps EA, 2014, ANNU REV NEUROSCI, V37, P263, DOI 10.1146/annurev-neuro-071013-014119
   Polek E, 2018, BMC PSYCHIATRY, V18, P0, DOI 10.1186/s12888-018-1595-0
   Power JD, 2012, NEUROIMAGE, V59, P2142, DOI 10.1016/j.neuroimage.2011.10.018
   Power JD, 2011, NEURON, V72, P665, DOI 10.1016/j.neuron.2011.09.006
   Rigoli F, 2016, NEUROPSYCHOPHARMACOL, V41, P2658, DOI 10.1038/npp.2016.68
   Rosenberg MD, 2016, NAT NEUROSCI, V19, P165, DOI 10.1038/nn.4179
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Rushworth MFS, 2011, NEURON, V70, P1054, DOI 10.1016/j.neuron.2011.05.014
   Scholl J, 2018, BEHAV BRAIN RES, V355, P56, DOI 10.1016/j.bbr.2017.09.050
   Schuck NW, 2016, NEURON, V91, P1402, DOI 10.1016/j.neuron.2016.08.019
   Shahar N, 2019, P NATL ACAD SCI USA, V116, P15871, DOI 10.1073/pnas.1821647116
   Shahar N, 2019, PLOS COMPUT BIOL, V15, P0, DOI 10.1371/journal.pcbi.1006803
   Smith SM, 2004, NEUROIMAGE, V23, PS208, DOI 10.1016/j.neuroimage.2004.07.051
   Smith SM, 2015, NAT NEUROSCI, V18, P1565, DOI 10.1038/nn.4125
   Smith SM, 2011, NEUROIMAGE, V54, P875, DOI 10.1016/j.neuroimage.2010.08.063
   Smith SM, 2009, P NATL ACAD SCI USA, V106, P13040, DOI 10.1073/pnas.0905267106
   Sripada C., 2020, CONNECTOMIC ALTERATI, V0, P0, DOI DOI 10.1101/2020.08.21.260927
   Sripada CS, 2009, NEUROREPORT, V20, P984, DOI 10.1097/WNR.0b013e32832d0a67
   St Clair MC, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0175381
   Stalnaker TA, 2018, NEUROBIOL LEARN MEM, V153, P137, DOI 10.1016/j.nlm.2018.01.013
   Sun Y, 2009, EPL-EUROPHYS LETT, V86, P0, DOI 10.1209/0295-5075/86/28004
   Sutton R., 1998, INTRO REINFORCEMENT, V0, P0, DOI DOI 10.1109/TNN.1998.712192
   Swart JC, 2018, PLOS BIOL, V16, P0, DOI 10.1371/journal.pbio.2005979
   Symmonds M, 2011, NEUROIMAGE, V58, P1139, DOI 10.1016/j.neuroimage.2011.06.087
   Todd N, 2016, NEUROIMAGE, V124, P32, DOI 10.1016/j.neuroimage.2015.08.056
   Uddin LQ, 2015, NAT REV NEUROSCI, V16, P55, DOI 10.1038/nrn3857
   van der Maas HLJ, 2006, PSYCHOL REV, V113, P842, DOI 10.1037/0033-295X.113.4.842
   Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041
   Vidaurre D, 2017, P NATL ACAD SCI USA, V114, P12827, DOI 10.1073/pnas.1705120114
   Voorhees CM, 2016, J ACAD MARKET SCI, V44, P119, DOI 10.1007/s11747-015-0455-4
   Walton ME, 2010, NEURON, V65, P927, DOI 10.1016/j.neuron.2010.02.027
   Weiskopf N, 2013, FRONT NEUROSCI-SWITZ, V7, P0, DOI 10.3389/fnins.2013.00095
   Whitaker KJ, 2016, P NATL ACAD SCI USA, V113, P9105, DOI 10.1073/pnas.1601745113
   Wilson RC, 2014, NEURON, V81, P267, DOI 10.1016/j.neuron.2013.11.005
   Winkler AM, 2016, NEUROIMAGE, V141, P502, DOI 10.1016/j.neuroimage.2016.05.068
NR 103
TC 8
Z9 8
U1 8
U2 22
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0896-6273
EI 1097-4199
J9 NEURON
JI Neuron
PD JUN 16
PY 2021
VL 109
IS 12
BP 2025
EP +
DI 10.1016/j.neuron.2021.04.019
EA JUN 2021
PG 24
WC Neurosciences
SC Neurosciences & Neurology
GA SV0QH
UT WOS:000663531600015
PM 34019810
DA 2023-04-26
ER

PT J
AU Ding, FQ
   Luo, C
AF Ding Fengqian
   Luo Chao
TI Structured sparsity learning for large-scale fuzzy cognitive maps
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Fuzzy cognitive maps; Structured sparsity learning; Inference system; Convex optimization
ID regression; shrinkage; algorithm; selection
AB Fuzzy cognitive map (FCM) as a kind of intelligent soft computing method, by combining the advantages of neural network and fuzzy logic, can be used to mine the causal relationships between concepts and make reasoning. However, how to effectively learn the large-scale FCMs is still an open problem. In this article, by means of structured sparsity learning, a robust learning method for large-scale FCMs based on iterative smoothing algorithm is proposed. Firstly, in terms of sparse signal reconstruction, the objective function of learning method is constructed by using elastic and total variation (TV) penalties, which can be conducive to capture the sparse structure information of FCM and improve the robustness of network reconstruction. Due to the non-smoothness of the TV penalty, Nesterov's smoothing technique is used to solve the non-smooth problem, thus transforming the problem into a convex optimization problem. Subsequently, in order to quickly solve the convex optimization, the algorithm based on proximal gradient descent is applied. In the experiment part, synthetic FCM models with different densities, sizes and noises are used to evaluate the proposed method, and the experimental results demonstrate the proposed method can make full use of the observations to learn the structural information of FCM. Moreover, the real-world data from the gene regulatory networks (GRNs) are further used to evaluate the effect of network reconstruction, and a higher reconstruction accuracy can be verified.
C1 [Ding Fengqian; Luo Chao] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
   [Luo Chao] Shandong Prov Key Lab Novel Distributed Comp Soft, Jinan 250014, Peoples R China.
C3 Shandong Normal University
RP Luo, C (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
EM cluo79@gmail.com
FU National Natural Science Founda-tion of China [62172264]; Shandong Provincial Natural Science Foundation [ZR2019MF020]
CR Acampora G, 2015, IEEE T FUZZY SYST, V23, P2397, DOI 10.1109/TFUZZ.2015.2426311
   Ahmed M. U., 2019, INT J ARTIF INTELL, V17, P154
   [Anonymous], 2019, INT J ARTIF INTELL, V0, P0
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bertsekas D. P., 1997, J OPER RES SOC, V48, P334, DOI 10.1057/palgrave.jors.2600425
   Borlea ID, 2021, KNOWL-BASED SYST, V214, P0, DOI 10.1016/j.knosys.2020.106731
   Chen, 2012, IEEE INT C POW SYST, V0, P1
   Chen Y, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, V0, PP9, DOI 10.1145/2330163.2330166
   Chi YX, 2019, NAT COMPUT, V18, P301, DOI 10.1007/s11047-016-9547-4
   Chi YX, 2016, IEEE T FUZZY SYST, V24, P71, DOI 10.1109/TFUZZ.2015.2426314
   Dash S, 2020, INT J DISTRIB SENS N, V16, P0, DOI 10.1177/1550147719895210
   Duchesnay E., 2016, ARXIV160509658, V0, P0
   Gonzalez J, 2018, IFAC PAPERSONLINE, V51, P485, DOI 10.1016/j.ifacol.2018.07.326
   Greenfield A, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0013397
   Groumpos P. P., 2003, INT J BIOMED SOFT CO, V9, P25
   Hajek P, 2019, INFORM SCIENCES, V485, P394, DOI 10.1016/j.ins.2019.02.035
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Liu J, 2016, IEEE T FUZZY SYST, V24, P419, DOI 10.1109/TFUZZ.2015.2459756
   Liu X, 2019, IEEE T CYBERNETICS, V0, P0
   LIU Z, 2020, KNOWL-BASED SYST, V203, P0
   Lucas C, 2008, 2008 4 INT IEEE C IN, V3, P8
   Luo C, 2020, IEEE T FUZZY SYST, V28, P1694, DOI 10.1109/TFUZZ.2019.2921263
   Meng X, 2018, IEEE T IND INFORM, V14, P931, DOI 10.1109/TII.2017.2734686
   Mishra M, 2020, ENG APPL ARTIF INTEL, V96, P0, DOI 10.1016/j.engappai.2020.104000
   Natarajan R, 2016, COMPUT ELECTRON AGR, V127, P147, DOI 10.1016/j.compag.2016.05.016
   Nesterov Y, 2005, SIAM J OPTIMIZ, V16, P235, DOI 10.1137/S1052623403422285
   Papageorgiou E, 2003, LECT NOTES ARTIF INT, V2903, P256
   Papageorgiou EI, 2005, J INTELL INF SYST, V25, P95, DOI 10.1007/s10844-005-0864-9
   Papageorgiou EI, 2013, IEEE T FUZZY SYST, V21, P66, DOI 10.1109/TFUZZ.2012.2201727
   Papageorgiou EI, 2012, APPL SOFT COMPUT, V12, P3798, DOI 10.1016/j.asoc.2012.03.064
   Papageorgiou EI, 2012, IEEE T SYST MAN CY C, V42, P150, DOI 10.1109/TSMCC.2011.2138694
   Precup RE, 2020, IEEE T INSTRUM MEAS, V69, P4625, DOI 10.1109/TIM.2020.2983531
   Prill RJ, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0009202
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Salmeron JL, 2016, KNOWL-BASED SYST, V105, P29, DOI 10.1016/j.knosys.2016.04.023
   Sirbu A, 2010, BMC BIOINFORMATICS, V11, P0, DOI 10.1186/1471-2105-11-59
   Stach W, 2005, FUZZY SET SYST, V153, P371, DOI 10.1016/j.fss.2005.01.009
   Stach W, 2012, IEEE T SYST MAN CY B, V42, P900, DOI 10.1109/TSMCB.2011.2182646
   Stach W, 2008, IEEE INT CONF FUZZY, V0, P1977
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tsadiras AK, 2008, INFORM SCIENCES, V178, P3880, DOI 10.1016/j.ins.2008.05.015
   Wu K, 2016, KNOWL-BASED SYST, V113, P23, DOI 10.1016/j.knosys.2016.09.010
   Yang YL, 2017, SCI REP-UK, V7, P0, DOI 10.1038/srep39883
   Yesil E, 2013, IEEE INT CONF FUZZY, V0, P0, DOI DOI 10.1109/FUZZ-IEEE.2013.6622488
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou XM, 2018, IEEE T FUZZY SYST, V26, P2120, DOI 10.1109/TFUZZ.2017.2764445
NR 46
TC 2
Z9 2
U1 0
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD OCT 15
PY 2021
VL 105
IS 
BP 
EP 
DI 10.1016/j.engappai.2021.104444
EA AUG 2021
PG 12
WC Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic
SC Automation & Control Systems; Computer Science; Engineering
GA UY1HA
UT WOS:000701281200001
DA 2023-04-26
ER

PT J
AU Gholami, H
   Mohammadifar, A
   Golzari, S
   Kaskaoutis, DG
   Collins, AL
AF Gholami, Hamid
   Mohammadifar, Aliakbar
   Golzari, Shahram
   Kaskaoutis, Dimitris G.
   Collins, Adrian L.
TI Using the Boruta algorithm and deep learning models for mapping land susceptibility to atmospheric dust emissions in Iran
SO AEOLIAN RESEARCH
LA English
DT Article
DE Wind erosion; Land susceptibility; Convergent prediction; Taylor diagram; Recurrent neural network; Iran
ID neural-networks; wrf-chem; jazmurian basin; middle-east; desert dust; wind; storms; asia; sea; classification
AB Wind erosion have many negative effects on global terrestrial and aquatic ecosystems and these phenomena are controlled by several factors including climatic, meteorological, topographic, vegetation, surface and soil characteristics. This study applied, for the first time, the Boruta algorithm for identification of effective variables controlling wind erosion. The novelty of the study was increased further using application of two deep learning (DL) models comprising a simple recurrent neural network (RNN) and restricted boltzmann machine (RBM). Collectively, these tools were used to map land susceptibility to wind erosion in parts of Kerman province, southeastern Iran. Among 18 potential variables for controlling dust emissions via wind erosion, 4 and 14 were identified as non-important and important, respectively, by the Boruta algorithm, while three (precipitation, digital elevation model and soil organic carbon) were selected as the most important factors. An inventory map of the wind erosion confirmed using both a test dataset (30%) and a training dataset (70%) was used to construct predictive models of land susceptibility to wind erosion. Both DL predictive models exhibited highly satisfactory performance according to a Taylor diagram, but the simple RNN performed slightly better than RBM. Based on the simple RNN, 35.6%, 5%, 2.4%, 22.7% and 34.3% of the total study area were characterized by very low, low, moderate, high and very high susceptibility, respectively. Convergent prediction of the same susceptibility classes by intersecting the maps generated by both models classified 17.4%, 0.07%, 0.06%, 7.4% and 34% of the total study area as very low, low, moderate, high and very high susceptibility classes, respectively. We conclude that applying the Boruta algorithm and DL models as new methods in aeolian geomorphology, may provide accurate spatial maps of dust sources to help target mitigation of detrimental dust effects on climate, ecosystems and human health.
C1 [Gholami, Hamid; Mohammadifar, Aliakbar] Univ Hormozgan, Dept Nat Resources Engn, Bandar Abbas, Hormozgan, Iran.
   [Golzari, Shahram] Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Hormozgan, Iran.
   [Golzari, Shahram] Univ Hormozgan, Deep Learning Res Grp, Bandar Abbas, Hormozgan, Iran.
   [Kaskaoutis, Dimitris G.] Natl Observ Athens, Inst Environm Res & Sustainable Dev, Athens 15784, Greece.
   [Kaskaoutis, Dimitris G.] Univ Crete, Dept Chem, Environm Chem Proc Lab, Iraklion 71003, Greece.
   [Collins, Adrian L.] Rothamsted Res, Sustainable Agr Sci Dept, Okehampton EX20 2SB, Devon, England.
C3 University of Hormozgan; University of Hormozgan; University of Hormozgan; National Observatory of Athens; University of Crete; UK Research & Innovation (UKRI); Biotechnology and Biological Sciences Research Council (BBSRC); Rothamsted Research
RP Gholami, H (corresponding author), Univ Hormozgan, Dept Nat Resources Engn, Bandar Abbas, Hormozgan, Iran.
EM hgholami@hormozgan.ac.ir
FU Faculty of Agriculture and Natural Resources, University of Hormozgan, Iran; project "PANhellenic infrastructure for Atmospheric Composition and climatE change" PANACEA - Operational Program "Competitiveness, Entrepreneurship and Innovation" (NSRF 2014-2020) [MIS 5021516]; European Union; UKRI-BBSRC (UK Research and Innovation Biotechnology and Biological Sciences Research Council) [BBS/E/C/000I0330]; BBSRC [BBS/E/C/000I0330] Funding Source: UKRI
CR Abbasi HR, 2019, AEOLIAN RES, V41, P0, DOI 10.1016/j.aeolia.2019.07.005
   Abbasi H, 2019, Z GEOMORPHOL, V62, P41, DOI 10.1127/zfg_suppl/2019/0543
   Abdollahi Z, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104156
   Alizadeh Motaghi F., 2020, CATENA, V194, P0
   Alkhayer Mais, 2019, JOURNAL OF APPLIED SCIENCES & ENVIRONMENTAL MANAGEMENT, V23, P1511, DOI 10.4314/jasem.v23i8.15
   [Anonymous], 2006, DESERT DUST GLOBAL S, V0, P0
   Balkanlou KR, 2020, SCI TOTAL ENVIRON, V716, P0, DOI 10.1016/j.scitotenv.2020.137100
   Basart S, 2016, AEOLIAN RES, V23, P37, DOI 10.1016/j.aeolia.2016.09.005
   Beegum SN, 2018, ATMOS RES, V199, P62, DOI 10.1016/j.atmosres.2017.09.003
   Behrens T, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-33516-6
   Behrooz RD, 2019, AEOLIAN RES, V37, P1, DOI 10.1016/j.aeolia.2018.12.001
   Behrooz RD, 2017, AEOLIAN RES, V25, P87, DOI 10.1016/j.aeolia.2017.04.001
   Boroughani M, 2020, ECOL INFORM, V56, P0, DOI 10.1016/j.ecoinf.2020.101059
   Bou Karam D., 2016, EPSC20165547 EGUGA, V0, P0
   Burnett KM, 2019, CONSERV LETT, V12, P0, DOI 10.1111/conl.12606
   Cao H, 2015, SCI TOTAL ENVIRON, V502, P224, DOI 10.1016/j.scitotenv.2014.09.025
   Chen FY, 2019, ENERGIES, V12, P0, DOI 10.3390/en12010150
   Choobari OA, 2013, ANN GEOPHYS-GERMANY, V31, P625, DOI 10.5194/angeo-31-625-2013
   CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188
   Dadashi-Roudbari A., 2020, IRAN J GEOPHYS, V13, P43, DOI 10.30499/IJG.2020.104783
   Bui DT, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104426
   Bui DT, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134413
   Emadodin I, 2019, HYDROLOGY-BASEL, V6, P0, DOI 10.3390/hydrology6030066
   Fan JL, 2020, RENEW ENERG, V145, P2034, DOI 10.1016/j.renene.2019.07.104
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   Ge YX, 2016, ATMOS RES, V178, P196, DOI 10.1016/j.atmosres.2016.04.002
   Gholami H., 2020, SCI REP-UK, V10, P1
   Gholami H, 2020, ATMOS POLLUT RES, V11, P1303, DOI 10.1016/j.apr.2020.05.009
   Gholami H, 2020, ENVIRON SCI POLLUT R, V27, P42022, DOI 10.1007/s11356-020-10168-6
   Gholami H, 2020, SCI TOTAL ENVIRON, V723, P0, DOI 10.1016/j.scitotenv.2020.138090
   Gholami H, 2020, ATMOS RES, V233, P0, DOI 10.1016/j.atmosres.2019.104716
   Gholami H, 2019, ENVIRON SCI POLLUT R, V26, P13560, DOI 10.1007/s11356-019-04857-0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Goudie AS, 2014, ENVIRON INT, V63, P101, DOI 10.1016/j.envint.2013.10.011
   Groll M, 2013, AEOLIAN RES, V9, P49, DOI 10.1016/j.aeolia.2012.08.002
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hamidi M, 2017, AEOLIAN RES, V24, P133, DOI 10.1016/j.aeolia.2016.12.004
   Hamidi M, 2013, ASIA-PAC J ATMOS SCI, V49, P279, DOI 10.1007/s13143-013-0027-9
   Hamilton D. S., 2019, GEOSCIENTIFIC MODEL, V12, P0
   Hermida L, 2018, ATMOS RES, V199, P29, DOI 10.1016/j.atmosres.2017.09.004
   Heung B, 2016, GEODERMA, V265, P62, DOI 10.1016/j.geoderma.2015.11.014
   Hou N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010181
   Karam DB, 2009, J GEOPHYS RES-ATMOS, V114, P0, DOI 10.1029/2008JD011444
   Kaskaoutis DG, 2017, INT J CLIMATOL, V37, P1013, DOI 10.1002/joc.5053
   Kaskaoutis DG, 2015, CLIM DYNAM, V45, P407, DOI 10.1007/s00382-014-2208-3
   Kaskaoutis DG, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9100453
   Keskin H, 2019, GEODERMA, V339, P40, DOI 10.1016/j.geoderma.2018.12.037
   Khusfi ZE, 2020, GEODERMA, V365, P0, DOI 10.1016/j.geoderma.2020.114225
   Khusfi ZE, 2020, ARID LAND RES MANAG, V34, P239, DOI 10.1080/15324982.2019.1694087
   King DB, 2015, ACS SYM SER, V1214, P1
   Kontos S, 2018, ATMOS ENVIRON, V190, P294, DOI 10.1016/j.atmosenv.2018.07.033
   Kosmopoulos PG, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121870
   Kursa MB, 2010, FUND INFORM, V101, P271, DOI 10.3233/FI-2010-288
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Lal R, 2004, SCIENCE, V304, P1623, DOI 10.1126/science.1097396
   Ledari DG, 2020, AEOLIAN RES, V44, P0, DOI 10.1016/j.aeolia.2020.100592
   Li LL, 2018, J GEOPHYS RES-ATMOS, V123, P4564, DOI 10.1029/2017JD027667
   Li SJ, 2020, GEOMORPHOLOGY, V354, P0, DOI 10.1016/j.geomorph.2020.107045
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Maghrabi AH, 2016, ATMOS RES, V182, P30, DOI 10.1016/j.atmosres.2016.07.024
   Maghsoudi M., 2017, DESERT, V22, P11
   Mahowald N, 2014, AEOLIAN RES, V15, P53, DOI 10.1016/j.aeolia.2013.09.002
   Mahowald NM, 2005, GLOBAL BIOGEOCHEM CY, V19, P0, DOI 10.1029/2004GB002402
   Middleton NJ, 2017, AEOLIAN RES, V24, P53, DOI 10.1016/j.aeolia.2016.12.001
   Middleton N, 2018, NAT HAZARDS, V92, P57, DOI 10.1007/s11069-016-2592-6
   Miri A., 2007, INT J ENERGY ENV, V2, P101
   Monjezi M, 2009, ENVIRON GEOL, V58, P205, DOI 10.1007/s00254-008-1509-4
   Nabavi SO, 2017, AEOLIAN RES, V24, P115, DOI 10.1016/j.aeolia.2016.12.005
   Najafpour N, 2018, J GEOPHYS RES-ATMOS, V123, P5038, DOI 10.1029/2017JD027593
   Opp C, 2017, QUATERN INT, V429, P86, DOI 10.1016/j.quaint.2015.12.103
   Padarian J, 2019, GEODERMA REG, V16, P0, DOI 10.1016/j.geodrs.2018.e00198
   Parajuli SP, 2019, J GEOPHYS RES-ATMOS, V124, P10109, DOI 10.1029/2019JD030248
   Parajuli SP, 2017, AEOLIAN RES, V27, P47, DOI 10.1016/j.aeolia.2017.06.002
   Parajuli SP, 2016, AEOLIAN RES, V21, P21, DOI 10.1016/j.aeolia.2016.02.002
   Parajuli SP, 2016, J GEOPHYS RES-ATMOS, V121, P1776, DOI 10.1002/2015JD024424
   Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1
   Prasad R, 2019, CATENA, V177, P149, DOI 10.1016/j.catena.2019.02.012
   Prospero JM, 2002, REV GEOPHYS, V40, P0, DOI 10.1029/2000RG000095
   Rahman M., 2019, BIORXIV, V0, P0
   Rashki A, 2021, AEOLIAN RES, V48, P0, DOI 10.1016/j.aeolia.2020.100655
   Rashki A, 2019, AEOLIAN RES, V36, P27, DOI 10.1016/j.aeolia.2018.11.002
   Rashki A, 2017, AEOLIAN RES, V24, P145, DOI 10.1016/j.aeolia.2017.01.002
   Rashki A, 2013, SCI TOTAL ENVIRON, V463, P552, DOI 10.1016/j.scitotenv.2013.06.045
   Saadoud D, 2018, AEOLIAN RES, V32, P24, DOI 10.1016/j.aeolia.2018.01.002
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shahsavani A, 2020, ENVIRON INT, V134, P0, DOI 10.1016/j.envint.2019.105299
   Shao Y, 2009, ATMOS OCEAN SCI LIB, V37, P1, DOI 10.1007/978-1-4020-8895-7
   Shao ZF, 2019, REMOTE SENS ENVIRON, V235, P0, DOI 10.1016/j.rse.2019.111425
   Shi LM, 2020, ATMOS ENVIRON, V222, P0, DOI 10.1016/j.atmosenv.2019.117176
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shirani M, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-61838-x
   Sirjani E, 2019, GEODERMA, V333, P69, DOI 10.1016/j.geoderma.2018.07.012
   Stirnberg R, 2020, J GEOPHYS RES-ATMOS, V125, P0, DOI 10.1029/2019JD031380
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Tieleman T., 2012, LECT 6 5 RMSPROP NEU, V0, P0
   Tong XW, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050357
   Torshizi MR, 2020, J ENVIRON MANAGE, V265, P0, DOI 10.1016/j.jenvman.2020.110486
   Vaezi A, 2019, PALAEOGEOGR PALAEOCL, V514, P754, DOI 10.1016/j.palaeo.2018.09.026
   Van Dao D., 2020, CATENA, V188, P0
   Zaman NAFK, 2017, ATMOS RES, V193, P142, DOI 10.1016/j.atmosres.2017.04.019
   Zender CS, 2003, J GEOPHYS RES-ATMOS, V108, P0, DOI 10.1029/2002JD003039
   Zhang D, 2018, J HYDROL, V565, P720, DOI 10.1016/j.jhydrol.2018.08.050
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhao R, 2019, MECH SYST SIGNAL PR, V115, P213, DOI 10.1016/j.ymssp.2018.05.050
NR 105
TC 16
Z9 16
U1 3
U2 12
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1875-9637
EI 2212-1684
J9 AEOLIAN RES
JI Aeolian Res.
PD MAR 15
PY 2021
VL 50
IS 
BP 
EP 
DI 10.1016/j.aeolia.2021.100682
EA FEB 2021
PG 14
WC Geography, Physical
SC Physical Geography
GA RY3DO
UT WOS:000647796000001
DA 2023-04-26
ER

PT J
AU Zheng, YJ
   Liu, SC
   Du, Q
   Zhao, H
   Tong, XH
   Dalponte, M
AF Zheng, Yongjie
   Liu, Sicong
   Du, Qian
   Zhao, Hui
   Tong, Xiaohua
   Dalponte, Michele
TI A Novel Multitemporal Deep Fusion Network (MDFN) for Short-Term Multitemporal HR Images Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Image classification; Feature extraction; Logic gates; Convolutional neural networks; Satellites; Convolution; Spatial resolution; Convolutional neural network (CNN); deep feature fusion; land use; land cover (LULC) classification; long short term memory (LSTM); multitemporal images
ID land-cover classification
AB High-resolution (HR) satellite images, due to the technical constraints on spectral and spatial resolutions, usually contain only several broad spectral bands but with a very high spatial resolution. This provides rich spatial details of the objects on the Earth surface, while their spectral discrimination is relatively low. Recently, the increase of the satellite revisit times made it possible to acquire more frequent data coverage for finer classification. In this article, we proposed a novel multitemporal deep fusion network (MDFN) for short-term multitemporal HR images classification. Specifically, a two-branch structure of MDFN is designed, which includes a long short-term memory (LSTM) and a convolutional neural network (CNN). The LSTM branch is mainly used to learn the joint expression of different temporal-spectral features. For the CNN branch, the three-dimensional (3-D) convolution is firstly applied along the temporal and spectral dimensions to jointly learn the temporal-spatial and spectral-spatial information, respectively, and then the 2-D convolution is performed along the spatial dimension to further extract the spatial context information. Finally, features generated from the two different branches are fused to obtain the discriminative high-level semantic information for classification. Experimental results carried on two real multitemporal HR remote sensing datasets demonstrate that the proposed MDFN provides better classification performance over the state-of-the-art methods, and it also shows the potentiality to use short-term multitemporal HR images for more accurate land use/land cover mapping.
C1 [Zheng, Yongjie; Liu, Sicong; Zhao, Hui; Tong, Xiaohua] Tongji Univ, Coll Surveying & Geoinformat, Shanghai 200092, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
   [Dalponte, Michele] Res & Innovat Ctr Fdn E Mach, Dept Sustainable Agroecosyst & Bioresources, I-38010 San Michele All Adige, Italy.
C3 Tongji University; Mississippi State University
RP Liu, SC (corresponding author), Tongji Univ, Coll Surveying & Geoinformat, Shanghai 200092, Peoples R China.
EM yongjie@tongji.edu.cn; sicong.liu@tongji.edu.cn; du@ece.msstate.edu; zhaohui@tongji.edu.cn; hui@tongji.edu.cn; michele.dalponte@fmach.it
FU National Key R&D Program of China [2018YFB0505000]; Natural Science Foundation of China [42071324]; Shanghai RisingStar Program [21QA1409100]
CR Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Dalla Mura M, 2010, INT GEOSCI REMOTE SE, V0, PP76, DOI 10.1109/IGARSS.2010.5652469
   Feng J, 2021, IEEE T GEOSCI REMOTE, V59, P5054, DOI 10.1109/TGRS.2020.3011943
   Gewali UB, 2016, 2016 8TH WORKSHOP ON HYPERSPECTRAL IMAGE AND SIGNAL PROCESSING: EVOLUTION IN REMOTE SENSING (WHISPERS), V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P163
   Gu YF, 2017, IEEE T GEOSCI REMOTE, V55, P6547, DOI 10.1109/TGRS.2017.2729882
   Han Y, 2015, 2015 8TH INTERNATIONAL WORKSHOP ON THE ANALYSIS OF MULTITEMPORAL REMOTE SENSING IMAGES (MULTI-TEMP), V0, P0
   Hao X, 2016, INT J SEMANT COMPUT, V10, P417, DOI 10.1142/S1793351X16500045
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, ISPRS J PHOTOGRAMM, V178, P68, DOI 10.1016/j.isprsjprs.2021.05.011
   Hong DF, 2022, IEEE T NEUR NET LEAR, V33, P6518, DOI 10.1109/TNNLS.2021.3082289
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Jin H, 2008, P IEEE INT GEOSC REM, V0, P742
   Khaliq A., 2018, P 2018 INT C COMPUTI, V0, PP1, DOI 10.1109/ICCSE1.2018.8374203
   Li ZT, 2019, IEEE ACCESS, V7, P134677, DOI 10.1109/ACCESS.2019.2939152
   Liu SC, 2021, IEEE J-STARS, V14, P464, DOI 10.1109/JSTARS.2020.3041868
   Liu SC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050862
   Liu SC, 2019, IEEE J-STARS, V12, P3578, DOI 10.1109/JSTARS.2019.2929514
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Moser G, 2009, INT GEOSCI REMOTE SE, V0, PP3145, DOI 10.1109/IGARSS.2009.5417489
   Neves AK, 2019, INT GEOSCI REMOTE SE, V0, PP3716, DOI 10.1109/IGARSS.2019.8898649
   Niazmardi S, 2017, IEEE J-STARS, V10, P2012, DOI 10.1109/JSTARS.2017.2662484
   Praveen B, 2021, IEEE J-STARS, V14, P0, DOI 10.1109/JSTARS.2020.3046414
   Rajadell O, 2013, IEEE GEOSCI REMOTE S, V10, P860, DOI 10.1109/LGRS.2012.2226426
   Saha S, 2020, IEEE T GEOSCI REMOTE, V58, P8780, DOI 10.1109/TGRS.2020.2990640
   Salberg AB, 2011, IEEE T GEOSCI REMOTE, V49, P377, DOI 10.1109/TGRS.2010.2052464
   Tuia D, 2016, ISPRS J PHOTOGRAMM, V120, P1, DOI 10.1016/j.isprsjprs.2016.07.004
   Wang Allen Guishi, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS (PERCOM WORKSHOPS), V0, P0, DOI DOI 10.1109/PERCOMW.2016.7457144
   Wang WJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071068
   Wang YP, 2020, IEEE J-STARS, V13, P5508, DOI 10.1109/JSTARS.2020.3023645
   Wen-Shuai Hu, 2020, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V58, P4237, DOI 10.1109/TGRS.2019.2961947
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yamada T, 2021, IEEE LAT AM T, V19, P1657
   Yang H. L., 2011, P IEEE WORKSH HYP IM, V0, P1
   Yu CY, 2020, IEEE J-STARS, V13, P2485, DOI 10.1109/JSTARS.2020.2983224
   Zhang ZQ, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3067356
   Zheng ZF, 2019, IEEE ACCESS, V7, P118472, DOI 10.1109/ACCESS.2019.2936295
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
NR 41
TC 9
Z9 10
U1 1
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10691
EP 10704
DI 10.1109/JSTARS.2021.3119942
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WR0MR
UT WOS:000714204000008
DA 2023-04-26
ER

PT J
AU Moon, JH
   Lee, DY
   Cha, WC
   Chung, MJ
   Lee, KS
   Cho, BH
   Choi, JH
AF Moon, Jong Hak
   Lee, Da Young
   Cha, Won Chul
   Chung, Myung Jin
   Lee, Kyu-Sung
   Cho, Baek Hwan
   Choi, Jin Ho
TI Automatic stenosis recognition from coronary angiography using convolutional neural networks
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Coronary angiography; Coronary artery stenosis; Deep learning; Stenosis recognition; Automated screening
ID segmentation
AB Background and objective: Coronary artery disease, which is mostly caused by atherosclerotic narrowing of the coronary artery lumen, is a leading cause of death. Coronary angiography is the standard method to estimate the severity of coronary artery stenosis, but is frequently limited by intraand inter-observer variations. We propose a deep-learning algorithm that automatically recognizes stenosis in coronary angiographic images. Methods: The proposed method consists of key frame detection, deep learning model training for classification of stenosis on each key frame, and visualization of the possible location of the stenosis. Firstly, we propose an algorithm that automatically extracts key frames essential for diagnosis from 452 right coronary artery angiography movie clips. Our deep learning model is then trained with image-level annotations to classify the areas narrowed by over 50 %. To make the model focus on the salient features, we apply a self-attention mechanism. The stenotic locations are visualized using the activated area of feature maps with gradient-weighted class activation mapping. Results: The automatically detected key frame was very close to the manually selected key frame (average distance (1.70 +/- 0.12) frame per clip). The model was trained with key frames on internal datasets, and validated with internal and external datasets. Our training method achieved high frame-wise area-under the-curve of 0.971, frame-wise accuracy of 0.934, and clip-wise accuracy of 0.965 in the average values of cross-validation evaluations. The external validation results showed high performances with the mean frame-wise area-under-the-curve of (0.925 and 0.956) in the single and ensemble model, respectively. Heat map visualization shows the location for different types of stenosis in both internal and external data sets. With the self-attention mechanism, the stenosis could be precisely localized, which helps to accurately classify the stenosis by type. Conclusions: Our automated classification algorithm could recognize and localize coronary artery stenosis highly accurately. Our approach might provide the basis for a screening and assistant tool for the interpretation of coronary angiography. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Moon, Jong Hak; Lee, Kyu-Sung; Cho, Baek Hwan; Choi, Jin Ho] Sungkyunkwan Univ, Dept Med Device Management & Res, SAIHST, Seoul 06351, South Korea.
   [Cha, Won Chul; Choi, Jin Ho] Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Emergency Med, 115 Irwon Ro, Seoul 06351, South Korea.
   [Chung, Myung Jin; Cho, Baek Hwan] Samsung Med Ctr, Med AI Res Ctr, 81 Irwon Ro, Seoul 06351, South Korea.
   [Lee, Da Young] Sungkyunkwan Univ, Dept Digital Hlth, SAIHST, Seoul 06351, South Korea.
   [Chung, Myung Jin] Sungkyunkwan Univ, Samsung Med Ctr, Sch Med, Dept Radiol, Seoul 06351, South Korea.
   [Lee, Kyu-Sung] Sungkyunkwan Univ, Samsung Med Ctr, Sch Med, Dept Urol, Seoul 06351, South Korea.
   [Moon, Jong Hak] Korea Adv Inst Sci & Technol, Grad Sch AI, Daejeon 34141, South Korea.
C3 Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); Samsung Medical Center; Korea Advanced Institute of Science & Technology (KAIST)
RP Cho, BH; Choi, JH (corresponding author), Sungkyunkwan Univ, Dept Med Device Management & Res, SAIHST, Seoul 06351, South Korea.; Choi, JH (corresponding author), Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Emergency Med, 115 Irwon Ro, Seoul 06351, South Korea.; Cho, BH (corresponding author), Samsung Med Ctr, Med AI Res Ctr, 81 Irwon Ro, Seoul 06351, South Korea.
EM jhak.moon@kaist.ac.kr; rebe.lee17@gmail.com; wc.cha@samsung.com; mj1.chung@samsung.com; ks63.lee@samsung.com; baekhwan.cho@samsung.com; jhchoimd@gmail.com
FU Bio & Medical Technology Development Program of the National Research Foundation of Korea (NRF) - Korean government, MSIT [NRF-2017M3A9E1064784]; Basic Science Research Program through the NRF - Ministry of Education [NRF-2020R1F1A1070952]; National Research Foundation of Korea [2020R1F1A1070952] Funding Source: Korea Institute of Science & Technology Information (KISTI), National Science & Technology Information Service (NTIS)
CR Abbas N, 2018, COGENT SOC SCI, V4, P0, DOI 10.1080/23311886.2018.1457421
   Adjedj J, 2017, CIRC-CARDIOVASC IMAG, V10, P0, DOI 10.1161/CIRCIMAGING.117.006243
   [Anonymous], 2020, CIRCULATION, V141, Pe33, DOI 10.1161/CIR.0000000000000746
   Bai XZ, 2012, OPT LASER TECHNOL, V44, P328, DOI 10.1016/j.optlastec.2011.07.009
   Brieva J., 2004, 26 ANN INT C IEEE EN, V0, P0
   Chattopadhyay A., 2017, ARXIV171011063, V0, P0
   Compas C.B., 2014, 2014 IEEE 11 INT S B, V0, P0
   Condurache A., 2004, BILDVERARBEITUNG FUE, V0, P5
   Cui H.F., 2015, INT C INN BIOM ENG L, V0, P56
   Cui HF, 2018, MACH VISION APPL, V29, P1287, DOI 10.1007/s00138-018-0978-z
   Eiho S, 1997, COMPUT CARDIOL, V24, P525, DOI 10.1109/CIC.1997.647950
   Fatemi M. R., 2011, INT J COMPUTER APPL, V0, P0
   Fazlali H.R., 2015, IEEE INT C IM PROC I, V0, P0
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Glorot X., 2010, P 13 INT C ART INT S, V0, P249
   Gondal WM, 2017, IEEE IMAGE PROC, V0, P2069
   Hernandez-Vela A, 2012, IEEE T INF TECHNOL B, V16, P1332, DOI 10.1109/TITB.2012.2220781
   Herrman JPR, 1996, INT J CARDIAC IMAG, V12, P21, DOI 10.1007/BF01798114
   Hu J., 2018, ADV NEURAL INFORM PR, V0, P0
   Hu J, 2018, 2017 IEEE C COMP VIS, V0, P0
   Kim JY, 2019, COMPUT METH PROG BIO, V182, P0, DOI 10.1016/j.cmpb.2019.105063
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Li B., 2019, 2019 41 ANN INT C IE, V0, P0
   Luong MT, 2015, EMNLP, V0, P0
   Ma H., 2017, INT C MED IM COMP CO, V0, P0
   Milletari F., 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Nakamura M, 2011, CIRC J, V75, P204, DOI 10.1253/circj.CJ-10-0881
   Nasr-Esfahani E, 2018, BIOMED SIGNAL PROCES, V40, P240, DOI 10.1016/j.bspc.2017.09.012
   Nasr-Esfahani E., 2016, IEEE ENG MED BIOL SO, V0, P0
   Oquab M., 2015, PROC CVPR IEEE, V0, P685
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park, 2018, BRIT MACH VIS C, V0, P0
   SANCHISGOMAR F, 2016, ANN TRANSL MED, V4, P0, DOI 10.21037/atm.2016.06.33
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   SCHWEIGER MJ, 1987, CATHETER CARDIO DIAG, V13, P239, DOI 10.1002/ccd.1810130404
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Shah R, 2017, AM HEART J, V184, P0, DOI 10.1016/j.ahj.2016.10.014
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Syeda-Mahmood T., 2010, 2010 20 INT C PATT R, V0, P0
   Szegedy, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tang YX, 2018, LECT NOTES COMPUT SC, V11046, P249, DOI 10.1007/978-3-030-00919-9_29
   Teh E.W., 2016, ATTENTION NETWORKS W, V0, P0
   Vaswani A, 2017, ADV NEURAL INFORM PR, V30, P5998, DOI 10.48550/ARXIV.1706.03762
   Wan T, 2018, COMPUT METH PROG BIO, V167, P13, DOI 10.1016/j.cmpb.2018.10.013
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang XB, 2017, ADV SOC SCI EDUC HUM, V72, P8
   Wang Y., 2019, INT C MED IM COMP CO, V0, P0
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao T, 2015, PROC CVPR IEEE, V0, PP2691, DOI 10.1109/CVPR.2015.7298885
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
   Zhou B., 2016, P 2016 IEEE C COMPUT, V0, PP2921, DOI 10.1109/CVPR.2016.319
NR 53
TC 19
Z9 19
U1 3
U2 21
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD JAN 15
PY 2021
VL 198
IS 
BP 
EP 
DI 10.1016/j.cmpb.2020.105819
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics
SC Computer Science; Engineering; Medical Informatics
GA PD0KS
UT WOS:000597384600013
PM 33213972
DA 2023-04-26
ER

PT J
AU Zhu, YS
   Zhong, QH
AF Zhu, Yongsheng
   Zhong, Qinghua
TI Differential Entropy Feature Signal Extraction Based on Activation Mode and Its Recognition in Convolutional Gated Recurrent Unit Network
SO FRONTIERS IN PHYSICS
LA English
DT Article
DE differential entropy; signal extraction; activation mode; convolutional neural network; bidirectional gated recurrent unit network
ID emotion recognition; eeg
AB In brain-computer-interface (BCI) devices, signal acquisition via reducing the electrode channels can reduce the computational complexity of models and filter out the irrelevant noise. Differential entropy (DE) plays an important role in emotional components of signals, which can reflect the area activity differences. Therefore, to extract distinctive feature signals and improve the recognition accuracy based on feature signals, a method of DE feature signal recognition based on a Convolutional Gated Recurrent Unit network was proposed in this paper. Firstly, the DE and power spectral density (PSD) of each original signal were mapped to two topographic maps, and the activated channels could be selected in activation modes. Secondly, according to the position of original electrodes, 1D feature signal sequences with four bands were reconstructed into a 3D feature signal matrix, and a radial basis function interpolation was used to fill in zero values. Then, the 3D feature signal matrices were fed into a 2D Convolutional Neural Network (2DCNN) for spatial feature extraction, and the 1D feature signal sequences were fed into a bidirectional Gated Recurrent Unit (BiGRU) network for temporal feature extraction. Finally, the spatial-temporal features were fused by a fully connected layer, and recognition experiments based on DE feature signals at the different time scales were carried out on a DEAP dataset. The experimental results showed that there were different activation modes at different time scales, and the reduction of the electrode channel could achieve a similar accuracy with all channels. The proposed method achieved 87.89% on arousal and 88.69% on valence.
C1 [Zhu, Yongsheng; Zhong, Qinghua] South China Normal Univ, Sch Phys & Telecommun Engn, Guangzhou, Peoples R China.
   [Zhong, Qinghua] South China Normal Univ, South China Acad Adv Optoelect, Guangzhou, Peoples R China.
C3 South China Normal University; South China Normal University
RP Zhong, QH (corresponding author), South China Normal Univ, Sch Phys & Telecommun Engn, Guangzhou, Peoples R China.; Zhong, QH (corresponding author), South China Normal Univ, South China Acad Adv Optoelect, Guangzhou, Peoples R China.
EM zhongqinghua@m.scnu.edu.cn
FU National Natural Science Foundation of China [61871433]; Natural Science Foundation of Guangdong Province [2019A1515011940]; Science and Technology Program of Guangzhou [202002030353, 2019050001]; Science and Technology Planning Project of Guangdong Province [2017B030308009, 2017KZ010101]; Guangdong Provincial Key Laboratory of Optical Information Materials and Technology [2017B030301007]; Guangzhou Key Laboratory of Electronic Paper Displays Materials and Devices
CR Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355
   Chao H, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19092212
   Chen J, 2015, IEEE INT C BIOINFORM, V0, PP395, DOI 10.1109/BIBM.2015.7359713
   Cho J, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20123491
   Cho K., 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/v1/d14-1179
   Hu B, 2018, IEEE ACM T COMPUT BI, V15, P38, DOI 10.1109/TCBB.2016.2616395
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Korovesis N, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8121387
   Kwon YH, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18051383
   Li PY, 2019, IEEE T BIO-MED ENG, V66, P2869, DOI 10.1109/TBME.2019.2897651
   Li X, 2016, IEEE INT C BIOINFORM, V0, PP352, DOI 10.1109/BIBM.2016.7822545
   Li Y, 2022, IEEE T AFFECT COMPUT, V13, P568, DOI 10.1109/TAFFC.2019.2922912
   Liu YJ, 2018, IEEE T AFFECT COMPUT, V9, P550, DOI 10.1109/TAFFC.2017.2660485
   Mahata S, 2018, DIGIT SIGNAL PROCESS, V72, P96, DOI 10.1016/j.dsp.2017.10.001
   Mert A, 2018, PATTERN ANAL APPL, V21, P81, DOI 10.1007/s10044-016-0567-6
   Salama ES, 2018, INT J ADV COMPUT SC, V9, P329
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Xiao GR, 2020, MECH SYST SIGNAL PR, V142, P0, DOI 10.1016/j.ymssp.2020.106736
   Xiao LW, 2022, MULTIMED TOOLS APPL, V81, P19051, DOI 10.1007/s11042-020-10107-0
   Xiao LW, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10030957
   Xing XF, 2019, FRONT NEUROROBOTICS, V13, P0, DOI 10.3389/fnbot.2019.00037
   Yin Z, 2017, FRONT NEUROROBOTICS, V11, P0, DOI 10.3389/fnbot.2017.00019
   Zheng WL, 2019, IEEE T AFFECT COMPUT, V10, P417, DOI 10.1109/TAFFC.2017.2712143
   Zhong QH, 2020, FRONT HUM NEUROSCI, V14, P0, DOI 10.3389/fnhum.2020.589001
   Zhuang N, 2017, BIOMED RES INT, V2017, P0, DOI 10.1155/2017/8317357
NR 25
TC 5
Z9 5
U1 9
U2 27
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-424X
EI 
J9 FRONT PHYS-LAUSANNE
JI Front. Physics
PD JAN 18
PY 2021
VL 8
IS 
BP 
EP 
DI 10.3389/fphy.2020.629620
PG 11
WC Physics, Multidisciplinary
SC Physics
GA QA0MD
UT WOS:000613144500001
DA 2023-04-26
ER

PT J
AU de Oliveira, VA
   Rodrigues, AF
   Morais, MAV
   Terra, MDNS
   Guo, L
   de Mello, CR
AF de Oliveira, Vinicius Augusto
   Rodrigues, Andre Ferreira
   Morais, Marco Antonio Vieira
   Terra, Marcela de Castro Nunes Santos
   Guo, Li
   de Mello, Carlos Rogerio
TI Spatiotemporal modelling of soil moisture in an Atlantic forest through machine learning algorithms
SO EUROPEAN JOURNAL OF SOIL SCIENCE
LA English
DT Article
DE forest hydrology; neural networks; random forest; soil physics; support vector machine; weighted k&#8208; nearest neighbour
ID temporal stability; functional traits; neural-networks; water; surface; prediction; variability; catchment; retrieval
AB Understanding the spatiotemporal behaviour of soil moisture in tropical forests is fundamental because it mediates processes such as infiltration, groundwater recharge, runoff and evapotranspiration. This study aims to model the spatiotemporal dynamics of soil moisture in an Atlantic forest remnant (AFR) through four machine learning algorithms, as these dynamics represent an important knowledge gap under tropical conditions. Random forest (RF), support vector machine, average neural network and weighted k-nearest neighbour were studied. The abilities of the models were evaluated by means of root mean square error, mean absolute error, coefficient of determination (R-2) and Nash-Sutcliffe efficiency (NS) for two calibration approaches: (a) chronological and (b) randomized. The models were further compared with a multilinear regression (MLR). The study period spans from September 2012 to November 2019 and relies on variables representing the weather, geographical location, forest structure, soil physics and morphology. RF was the best algorithm for modelling the spatiotemporal dynamics of the soil moisture with an NS of 0.77 and R-2 of 0.51 in the randomized approach. This finding highlights the ability of RF to generalize a dataset with contrasting weather conditions. Kriging maps highlighted the suitability of RF to track the spatial distribution of soil moisture in the AFR. Throughfall (TF), potential evapotranspiration (ETo), longitude (Long), diameter at breast height (DBH) and species diversity (H) were the most important variables controlling soil moisture. MLR performed poorly in modelling the spatiotemporal dynamics of soil moisture due to the highly nonlinear condition of this process. Highlights Modelling soil moisture in an Atlantic forest through machine learning. Machine learning algorithms are powerful tools to address the spatiotemporal dynamics of soil moisture. Climate, position and forest variables drive the spatiotemporal pattern of soil moisture. Random forest is the best algorithm to simulate soil moisture dynamics.
C1 [de Oliveira, Vinicius Augusto; Rodrigues, Andre Ferreira; de Mello, Carlos Rogerio] Univ Fed Lavras, Water Resources Dept, CP3037, BR-37200900 Lavras, MG, Brazil.
   [Morais, Marco Antonio Vieira] Fed Inst Sci & Technol Mato Grosso, Barra Garcas, Brazil.
   [Terra, Marcela de Castro Nunes Santos] Univ Fed Lavras, Forest Sci Dept, Lavras, Brazil.
   [Guo, Li] Sichuan Univ, Coll Water Resource & Hydropower, State Key Lab Hydraul & Mt River Engn, Chengdu, Peoples R China.
C3 Universidade Federal de Lavras; Universidade Federal de Lavras; Sichuan University
RP de Mello, CR (corresponding author), Univ Fed Lavras, Water Resources Dept, CP3037, BR-37200900 Lavras, MG, Brazil.
EM crmello@ufla.br
FU Coordination for the Improvement of Higher Education Personnel - CAPES [88882.306661/2018-01]; National Council for Scientific and Technological Development - CNPq [401760/2016-2, 301556/2017-2]; FAPEMIG [PPMX-545/18]
CR Ahmad S, 2010, ADV WATER RESOUR, V33, P69, DOI 10.1016/j.advwatres.2009.10.008
   Amorim JD, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12092571
   Andrade NPV, 2020, WATER RESOUR MANAG, V34, P5031, DOI 10.1007/s11269-020-02711-4
   [Anonymous], 2000, ARTIFICIAL NEURAL NE, V0, P0
   [Anonymous], 1998, 56 FAO, V0, P0
   Arnold JG, 1998, J AM WATER RESOUR AS, V34, P73, DOI 10.1111/j.1752-1688.1998.tb05961.x
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Biecek P., 2018, J MACH LEARN RES, V19, P1, DOI 10.5555/3291125.3309646
   Botula YD, 2013, VADOSE ZONE J, V12, P0, DOI 10.2136/vzj2012.0123
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Bruijnzeel L, 2010, TROPICAL MONTANE CLO, V0, P0
   Chaturvedi R.K., 2018, MOJ ECOLOGY ENV SCI, V3, P0, DOI 10.15406/mojes.2018. 03.00059
   Chen T, 2014, REMOTE SENS ENVIRON, V140, P330, DOI 10.1016/j.rse.2013.08.022
   Cherkassky V, 1997, IEEE TRANS NEURAL NETW, V8, P1564, DOI 10.1109/TNN.1997.641482
   Coelho CAS, 2016, CLIM DYNAM, V46, P3737, DOI 10.1007/s00382-015-2800-1
   Cooper T., 2018, R J, V0, P0, DOI DOI 10.1887/0750303123/B365C43
   Coopersmith EJ, 2016, ADV WATER RESOUR, V98, P122, DOI 10.1016/j.advwatres.2016.10.007
   Crawford J, 2019, J HYDROL, V568, P160, DOI 10.1016/j.jhydrol.2018.10.054
   Crisci C, 2012, ECOL MODEL, V240, P113, DOI 10.1016/j.ecolmodel.2012.03.001
   de Carvalho W, 2014, REV BRAS CIENC SOLO, V38, P706, DOI 10.1590/S0100-06832014000300003
   de Mello CR, 2011, SCI AGR, V68, P285, DOI 10.1590/S0103-90162011000300003
   de Oliveira VA, 2017, INT J CLIMATOL, V37, P5005, DOI 10.1002/joc.5138
   Devi GK, 2015, AQUAT PR, V4, P1001, DOI 10.1016/j.aqpro.2015.02.126
   Fisher A, 2019, J MACH LEARN RES, V20, P0
   Gao L, 2015, CATENA, V132, P29, DOI 10.1016/j.catena.2015.03.022
   Gao XD, 2011, CATENA, V87, P357, DOI 10.1016/j.catena.2011.07.004
   Gill MK, 2006, J AM WATER RESOUR AS, V42, P1033, DOI 10.1111/j.1752-1688.2006.tb04512.x
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Granata F, 2016, WATER-SUI, V8, P0, DOI 10.3390/w8030069
   Hassan-Esfahani L, 2015, REMOTE SENS-BASEL, V7, P2627, DOI 10.3390/rs70302627
   Heathman GC, 2012, CATENA, V95, P91, DOI 10.1016/j.catena.2012.03.008
   Hechenbichler K., 2004, TECHNICAL REPORT, V386, P0
   Hengl Tomislav, 2018, PEERJ, V6, Pe5518, DOI 10.7717/peerj.5518
   Hsu C.-C., 2016, PRACTICAL GUIDE SUPP, V0, PP1, DOI 10.1109/APSIPA.2016.7820786
   Jia Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223679
   Joshi C, 2011, WATER RESOUR RES, V47, P0, DOI 10.1029/2009WR009002
   Junqueira JA, 2017, GEODERMA, V288, P64, DOI 10.1016/j.geoderma.2016.10.034
   Junqueira JA, 2019, AGR FOREST METEOROL, V275, P170, DOI 10.1016/j.agrformet.2019.05.016
   Kalra A, 2009, WATER RESOUR RES, V45, P0, DOI 10.1029/2008WR006855
   Klos PZ, 2014, J HYDROL, V519, P2180, DOI 10.1016/j.jhydrol.2014.10.004
   Kuhn M., 2013, APPL PREDICTIVE MODE, V0, P0, DOI DOI 10.1007/978-1-4614-6849-3
   Liang WL, 2014, J HYDROL, V516, P210, DOI 10.1016/j.jhydrol.2014.01.032
   Liang X, 1994, J GEOPHYS RES-ATMOS, V99, P14415, DOI 10.1029/94JD00483
   Liu ZB, 2018, J FORESTRY RES, V29, P187, DOI 10.1007/s11676-017-0407-6
   Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9
   Mello CR, 2019, CATENA, V173, P9, DOI 10.1016/j.catena.2018.09.046
   Meng L, 2008, J HYDROMETEOROL, V9, P641, DOI 10.1175/2008JHM916.1
   Moghadas D, 2019, NEAR SURF GEOPHYS, V17, P181, DOI 10.1002/nsg.12036
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, V0, P27
   Terra MDNS, 2018, J PLANT ECOL, V11, P803, DOI 10.1093/jpe/rty017
   Terra MDNS, 2018, TREES-STRUCT FUNCT, V32, P323, DOI 10.1007/s00468-017-1634-3
   Oliveira-Filho A. T., 1994, EDINBURGH JOURNAL OF BOTANY, V51, P355
   Oroza CA, 2018, VADOSE ZONE J, V17, P0, DOI 10.2136/vzj2017.10.0178
   Padarian J, 2020, SOIL-GERMANY, V6, P35, DOI 10.5194/soil-6-35-2020
   Paliy O, 2016, MOL ECOL, V25, P1032, DOI 10.1111/mec.13536
   Peck E.L., 1976, NOAA TECH MEMO, V69, P0
   Pinto LC, 2016, CATENA, V143, P26, DOI 10.1016/j.catena.2016.03.033
   Prasad R, 2018, GEODERMA, V330, P136, DOI 10.1016/j.geoderma.2018.05.035
   Raghavendra NS, 2014, APPL SOFT COMPUT, V19, P372, DOI 10.1016/j.asoc.2014.02.002
   Ritchie J.T., 1985, ARS, V0, P159
   Rodrigues AF, 2020, ACTA SCI-AGRON, V42, P0, DOI 10.4025/actasciagron.v42i1.43518
   Rosado BHP, 2016, TREES-STRUCT FUNCT, V30, P47, DOI 10.1007/s00468-015-1165-8
   Santi E, 2016, INT J APPL EARTH OBS, V48, P61, DOI 10.1016/j.jag.2015.08.002
   Sehgal V, 2014, WATER RESOUR MANAG, V28, P1733, DOI 10.1007/s11269-014-0584-4
   Sims RA, 1996, ENVIRON MONIT ASSESS, V39, P471, DOI 10.1007/BF00396162
   Song XD, 2016, J ARID LAND, V8, P734, DOI 10.1007/s40333-016-0049-0
   Srinivasan R, 1998, J AM WATER RESOUR AS, V34, P91, DOI 10.1111/j.1752-1688.1998.tb05962.x
   Suo LZ, 2018, J HYDROL, V562, P635, DOI 10.1016/j.jhydrol.2018.05.036
   Suykens J.A.K., 2011, TECHNICAL REPORT, V0, P0
   Tian Y, 2018, SCI TOTAL ENVIRON, V622, P710, DOI 10.1016/j.scitotenv.2017.12.025
   Tyralis H, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11050910
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Wang YX, 2020, ADV WATER RESOUR, V146, P0, DOI 10.1016/j.advwatres.2020.103755
   Yu ZB, 2012, J HYDROL, V475, P53, DOI 10.1016/j.jhydrol.2012.08.034
   Zhao W, 2018, J HYDROL, V563, P1009, DOI 10.1016/j.jhydrol.2018.06.081
   Zhu JF, 2016, J HYDROL, V533, P343, DOI 10.1016/j.jhydrol.2015.12.012
NR 77
TC 11
Z9 11
U1 10
U2 43
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1351-0754
EI 1365-2389
J9 EUR J SOIL SCI
JI Eur. J. Soil Sci.
PD SEP 15
PY 2021
VL 72
IS 5
BP 1969
EP 1987
DI 10.1111/ejss.13123
EA MAY 2021
PG 19
WC Soil Science
SC Agriculture
GA UK5AH
UT WOS:000647116100001
DA 2023-04-26
ER

PT J
AU Arabameri, A
   Pal, SC
   Costache, R
   Saha, A
   Rezaie, F
   Danesh, AS
   Pradhan, B
   Lee, S
   Hoang, ND
AF Arabameri, Alireza
   Pal, Subodh Chandra
   Costache, Romulus
   Saha, Asish
   Rezaie, Fatemeh
   Danesh, Amir Seyed
   Pradhan, Biswajeet
   Lee, Saro
   Nhat-Duc Hoang
TI Prediction of gully erosion susceptibility mapping using novel ensemble machine learning algorithms
SO GEOMATICS NATURAL HAZARDS & RISK
LA English
DT Article
DE Gully erosion; spatial modelling; ensemble learning; extreme gradient boosting machine; GIS; genetic algorithm
ID geographically weighted regression; support vector machine; fuzzy inference system; soil-erosion; logistic-regression; neural-network; random forest; gis; models; hybrid
AB Spatial modelling of gully erosion at regional level is very relevant for local authorities to establish successful counter-measures and to change land-use planning. This work is exploring and researching the potential of a genetic algorithm-extreme gradient boosting (GE-XGBoost) hybrid computer education solution for spatial mapping of the susceptibility of gully erosion. The new machine learning approach is to combine the extreme gradient boosting machine (XGBoost) and the genetic algorithm (GA). The GA metaheuristic is being used to improve the efficiency of the XGBoost classification approach. A GIS database has been developed that contains recorded instances of gully erosion incidents and 18 conditioning variables. These parameters are used as predictive variables used to assess the condition of non-erosion or erosion in a given region within the Kohpayeh-Sagzi River Watershed research area in Iran. Exploratory results indicate that the proposed GE-XGBoost model is superior to the other benchmark solution with the desired predictive precision (89.56%). Therefore, the newly built model may be a promising method for large-scale mapping of gully erosion susceptibility.
C1 [Arabameri, Alireza] Tarbiat Modares Univ, Dept Geomorphol, Tehran, Iran.
   [Pal, Subodh Chandra; Saha, Asish] Univ Burdwan, Dept Geog, Bardhaman, W Bengal, India.
   [Costache, Romulus] Res Inst Univ Bucharest, Bucharest, Romania.
   [Costache, Romulus] Natl Inst Hydrol & Water Management, Bucharest, Romania.
   [Rezaie, Fatemeh; Lee, Saro] Korea Inst Geosci & Mineral Resources KIGAM, Geosci Platform Res Div, Daejeon, South Korea.
   [Rezaie, Fatemeh; Lee, Saro] Korea Univ Sci & Technol, Dept Geophys Explorat, Daejeon, South Korea.
   [Danesh, Amir Seyed] Univ Guilan, Fac Technol & Engn, Rudsar Vajargah, East Of Guilan, Iran.
   [Pradhan, Biswajeet] Univ Technol Sydney, Fac Engn & Informat Technol, Ctr Adv Modelling & Geospatial Informat Syst CAMG, Ultimo, NSW, Australia.
   [Pradhan, Biswajeet] Sejong Univ, Dept Energy & Mineral Resources Engn, Seoul, South Korea.
   [Pradhan, Biswajeet] King Abdulaziz Univ, Ctr Excellence Climate Change Res, Dept Meteorol, Jeddah, Saudi Arabia.
   [Pradhan, Biswajeet] Univ Kebangsaan Malaysia, Earth Observat Ctr, Inst Climate Change, Bangi, Selangor, Malaysia.
   [Nhat-Duc Hoang] Duy Tan Univ, Fac Civil Engn, Inst Res & Dev, Danang, Vietnam.
C3 Tarbiat Modares University; University of Burdwan; Korea Institute of Geoscience & Mineral Resources (KIGAM); University of Science & Technology (UST); University of Guilan; University of Technology Sydney; Sejong University; King Abdulaziz University; Universiti Kebangsaan Malaysia; Duy Tan University
RP Lee, S (corresponding author), Korea Inst Geosci & Mineral Resources KIGAM, Geosci Platform Res Div, Daejeon, South Korea.; Lee, S (corresponding author), Korea Univ Sci & Technol, Dept Geophys Explorat, Daejeon, South Korea.
EM leesaro@klgam.re.kr
FU Korea Institute of Geoscience and Mineral Resources (KIGAM); Project of Environmental Business Big Data Platform and Center Construction - Ministry of Science and ICT
CR Abedini M, 2019, GEOCARTO INT, V34, P1427, DOI 10.1080/10106049.2018.1499820
   Alin A, 2010, WIRES COMPUT STAT, V2, P370, DOI 10.1002/wics.84
   Amare S, 2019, LAND-BASEL, V8, P0, DOI 10.3390/land8090141
   Amjad MK, 2018, MATH PROBL ENG, V2018, P0, DOI 10.1155/2018/9270802
   [Anonymous], 2003, CATEGORICAL DATA ANA, V0, P0
   [Anonymous], 1998, STAT LEARNING THEORY, V0, P0
   [Anonymous], 1995, MACH LEARN, V0, P0, DOI DOI 10.1038/ng.142
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203389
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172833
   Arabameri A, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, V0, PP299, DOI 10.1016/B978-0-12-815226-3.00013-2
   Arabameri A, 2019, CATENA, V180, P282, DOI 10.1016/j.catena.2019.04.032
   Arabameri A, 2019, SCI TOTAL ENVIRON, V688, P903, DOI 10.1016/j.scitotenv.2019.06.205
   Arabameri A, 2019, GEOSCI J, V23, P669, DOI 10.1007/s12303-018-0067-3
   Arabameri A, 2019, J ENVIRON MANAGE, V232, P928, DOI 10.1016/j.jenvman.2018.11.110
   Arabameri A, 2018, LAND DEGRAD DEV, V29, P4035, DOI 10.1002/ldr.3151
   Arabameri A, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7808-5
   Ayele GK, 2015, AFR J AGRIC RESOUR E, V10, P265
   Band SS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213568
   Band SS, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20195609
   Bednarik M, 2010, PHYS CHEM EARTH, V35, P162, DOI 10.1016/j.pce.2009.12.002
   Ben Slimane A, 2016, LAND DEGRAD DEV, V27, P785, DOI 10.1002/ldr.2387
   Berhe AA, 2012, J GEOPHYS RES-BIOGEO, V117, P0, DOI 10.1029/2011JG001790
   BOUAZIZ M., 2011, GEOSCI FRONT, V2, P237, DOI 10.1016/J.GSF.2011.03.004
   Cao B, 2020, IEEE T FUZZY SYST, V28, P2702, DOI 10.1109/TFUZZ.2020.3026140
   Cao B, 2020, IEEE NETWORK, V34, P78, DOI 10.1109/MNET.011.1900536
   Cao B, 2020, IEEE T FUZZY SYST, V28, P939, DOI 10.1109/TFUZZ.2020.2972207
   Chang YC, 2018, APPL SOFT COMPUT, V73, P914, DOI 10.1016/j.asoc.2018.09.029
   Chao LJ, 2018, J HYDROL, V558, P275, DOI 10.1016/j.jhydrol.2018.01.042
   Chaplot VAM, 2005, GLOBAL BIOGEOCHEM CY, V19, P0, DOI 10.1029/2005GB002493
   Chen HZ, 2020, AGR WATER MANAGE, V240, P0, DOI 10.1016/j.agwat.2020.106303
   Chen T., 2016, KDD16 P 22 ACM, V0, PP785, DOI 10.1145/2939672.2939785
   Chen W, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12233854
   Chen W, 2021, GEOSCI FRONT, V12, P93, DOI 10.1016/j.gsf.2020.07.012
   Chen W, 2020, CATENA, V195, P0, DOI 10.1016/j.catena.2020.104777
   Chen W, 2020, J HYDROL, V583, P0, DOI 10.1016/j.jhydrol.2020.124602
   Chen W, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8122540
   Chen YZ, 2021, J CLEAN PROD, V278, P0, DOI 10.1016/j.jclepro.2020.123209
   Cheng X, 2016, J HYDROL, V540, P412, DOI 10.1016/j.jhydrol.2016.06.041
   Chowdhuri I, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213620
   Conoscenti C, 2018, LAND DEGRAD DEV, V29, P724, DOI 10.1002/ldr.2772
   Conoscenti C, 2014, GEOMORPHOLOGY, V204, P399, DOI 10.1016/j.geomorph.2013.08.021
   De Reu J, 2013, GEOMORPHOLOGY, V186, P39, DOI 10.1016/j.geomorph.2012.12.015
   Deng LJ, 2015, APPL MICROBIOL BIOT, V99, P8259, DOI 10.1007/s00253-015-6662-6
   Deng SH, 2019, J COMPUT CIVIL ENG, V33, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000814
   Bui DT, 2019, J HYDROL, V575, P314, DOI 10.1016/j.jhydrol.2019.05.046
   Bui DT, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19112444
   Dlapa P, 2012, CATENA, V92, P155, DOI 10.1016/j.catena.2011.12.002
   Droogers P, 2002, HYDROL PROCESS, V16, P1543, DOI 10.1002/hyp.1019
   El Maaoui MA, 2012, CATENA, V93, P97, DOI 10.1016/j.catena.2012.02.004
   Feng W, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-71295-1
   Fistikoglu O, 2002, WATER RESOUR MANAG, V16, P447, DOI 10.1023/A:1022282125760
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gayen A, 2019, SCI TOTAL ENVIRON, V668, P124, DOI 10.1016/j.scitotenv.2019.02.436
   Gessesse B, 2015, LAND DEGRAD DEV, V26, P711, DOI 10.1002/ldr.2276
   Gitas I. Z., 2009, EARSEL EPROCEEDINGS, V8, P40
   Goldberg D. E., 1989, GENETIC ALGORITHMS S, V0, P0
   Gormley MA, 2016, PREHOSP EMERG CARE, V20, P439, DOI 10.3109/10903127.2015.1128029
   Guisan A, 1999, PLANT ECOL, V143, P107, DOI 10.1023/A:1009841519580
   Gusain K, 2018, ADV INTELL SYST COMP, V562, P41, DOI 10.1007/978-981-10-4603-2_5
   Hamel L.H., 2011, KNOWLEDGE DISCOVERY, V0, P0
   Han CY, 2019, AGR WATER MANAGE, V218, P165, DOI 10.1016/j.agwat.2019.03.035
   He L, 2021, ENVIRON DEV SUSTAIN, V23, P1759, DOI 10.1007/s10668-020-00650-z
   He L, 2018, RESOUR CONSERV RECY, V133, P206, DOI 10.1016/j.resconrec.2018.02.015
   He L, 2018, J ENVIRON MANAGE, V206, P1115, DOI 10.1016/j.jenvman.2017.11.059
   Helming K, 2005, EARTH SURF PROC LAND, V30, P131, DOI 10.1002/esp.1179
   Nguyen H, 2019, GEOMAT NAT HAZ RISK, V10, P1667, DOI 10.1080/19475705.2019.1607782
   Hosseinalizadeh M, 2019, GEOMORPHOLOGY, V329, P184, DOI 10.1016/j.geomorph.2019.01.006
   Jaafari A, 2019, CATENA, V175, P430, DOI 10.1016/j.catena.2018.12.033
   Kavzoglu T, 2019, ADV NAT TECH HAZ RES, V50, P283, DOI 10.1007/978-3-319-77377-3_13
   Keesstra S, 2018, LAND-BASEL, V7, P0, DOI 10.3390/land7040133
   Keesstra SD, 2016, SOIL-GERMANY, V2, P111, DOI 10.5194/soil-2-111-2016
   Kilinc M, 2019, ADV CIV ENG, V2019, P0, DOI 10.1155/2019/7475156
   Kornejady A, 2017, CATENA, V152, P144, DOI 10.1016/j.catena.2017.01.010
   Kou M, 2016, LAND DEGRAD DEV, V27, P919, DOI 10.1002/ldr.2356
   Lal R, 2003, ENVIRON INT, V29, P437, DOI 10.1016/S0160-4120(02)00192-7
   Li TY, 2019, IEEE T IMAGE PROCESS, V28, P0, DOI 10.1109/TIP.2019.2921877
   Liu S, 2021, INT J INTELL SYST, V36, P1015, DOI 10.1002/int.22329
   Lombardo L, 2018, ENG GEOL, V244, P14, DOI 10.1016/j.enggeo.2018.07.019
   Lopez-Vicente M, 2020, LAND-BASEL, V9, P0, DOI 10.3390/land9070230
   Lu HW, 2019, RENEW SUST ENERG REV, V112, P788, DOI 10.1016/j.rser.2019.06.013
   Lu J, 2019, COMPLEXITY, V0, P0, DOI DOI 10.1155/2019/3094670
   Lv ZH, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106300
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mekonnen M, 2017, LAND DEGRAD DEV, V28, P708, DOI 10.1002/ldr.2629
   Meliho M, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7844-1
   Mirjalili S., 2020, EXPERT SYST APPL, V0, PP69, DOI 10.1007/978-3-030-12127-3_5
   Moayedi H, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8090391
   Nguyen NT, 2018, ECOL INFORM, V46, P74, DOI 10.1016/j.ecoinf.2018.05.009
   Hoang ND, 2019, COMPLEXITY, V2019, P0, DOI 10.1155/2019/5910625
   Hoang ND, 2018, B ENG GEOL ENVIRON, V77, P191, DOI 10.1007/s10064-016-0924-0
   Novara A, 2021, SOIL TILL RES, V208, P0, DOI 10.1016/j.still.2020.104896
   Novara A, 2016, SCI TOTAL ENVIRON, V550, P330, DOI 10.1016/j.scitotenv.2016.01.095
   Nyssen J, 2006, EARTH SURF PROC LAND, V31, P167, DOI 10.1002/esp.1317
   Nyssen J, 2002, EARTH SURF PROC LAND, V27, P1267, DOI 10.1002/esp.404
   Oh HJ, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/3730913
   Pal SC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223675
   Pal SC, 2019, ADV SPACE RES, V64, P352, DOI 10.1016/j.asr.2019.04.033
   Peng SB, 2021, J NAT GAS SCI ENG, V85, P0, DOI 10.1016/j.jngse.2020.103716
   Pimentel David, 2006, ENVIRONMENT DEVELOPMENT AND SUSTAINABILITY, V8, P119, DOI 10.1007/s10668-005-1262-8
   Ping Lu, 2010, PROCEEDINGS 2010 SECOND WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS (GCIS 2010), V0, PP302, DOI 10.1109/GCIS.2010.57
   Poesen J, 2003, CATENA, V50, P91, DOI 10.1016/S0341-8162(02)00143-1
   Poesen J, 1998, NATO ASI SER SER I, V55, P285
   Qian JM, 2020, APL PHOTONICS, V5, P0, DOI 10.1063/5.0003217
   Qu SJ, 2021, GROUP DECIS NEGOT, V30, P1395, DOI 10.1007/s10726-020-09707-w
   Rahmati O, 2017, SCI TOTAL ENVIRON, V579, P913, DOI 10.1016/j.scitotenv.2016.10.176
   Rahmati O, 2016, NAT HAZARDS, V82, P1231, DOI 10.1007/s11069-016-2239-7
   Rahmati O, 2016, CATENA, V137, P360, DOI 10.1016/j.catena.2015.10.010
   Rodrigo-Comino J, 2020, EARTH SYST ENVIRON, V4, P827, DOI 10.1007/s41748-020-00191-5
   Rodrigo-Comino J, 2018, BEVERAGES, V4, P0, DOI 10.3390/beverages4020031
   Rojas R, 2010, J HYDROL, V394, P416, DOI 10.1016/j.jhydrol.2010.09.016
   Roy P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203284
   Sarkar T, 2018, J GEOVIS SPAT ANAL, V2, P0, DOI 10.1007/s41651-018-0015-9
   Sayed GI, 2018, ADV INTELL SYST COMP, V723, P23, DOI 10.1007/978-3-319-74690-6_3
   Shi KB, 2020, FUZZY SET SYST, V381, P1, DOI 10.1016/j.fss.2018.11.017
   SHIT PK, 2015, MODEL EARTH SYST ENV, V1, P28
   Siahkamari S, 2018, GEOCARTO INT, V33, P927, DOI 10.1080/10106049.2017.1316780
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Tian PP, 2020, CATENA, V187, P0, DOI 10.1016/j.catena.2019.104340
   van Erkel AR, 1998, EUR J RADIOL, V27, P88, DOI 10.1016/S0720-048X(97)00157-5
   van Hall RL, 2017, CATENA, V149, P836, DOI 10.1016/j.catena.2016.05.021
   Dang VH, 2019, B ENG GEOL ENVIRON, V78, P2835, DOI 10.1007/s10064-018-1273-y
   Visser S, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11236792
   Wang H, 2021, ENG COMPUT-GERMANY, V37, P3067, DOI 10.1007/s00366-020-00957-5
   Wang YQ, 2013, LAND DEGRAD DEV, V24, P296, DOI 10.1002/ldr.1128
   Xiong JB, 2018, SHOCK VIB, V2018, P0, DOI 10.1155/2018/3091618
   Yan JK, 2020, INFORM FUSION, V55, P173, DOI 10.1016/j.inffus.2019.08.010
   Yang WJ, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17082942
   Zema DA, 2012, LAND DEGRAD DEV, V23, P205, DOI 10.1002/ldr.1068
   Zhang K, 2020, ENVIRON MODELL SOFTW, V128, P0, DOI 10.1016/j.envsoft.2020.104704
   Zhang K, 2019, J HYDROL, V574, P903, DOI 10.1016/j.jhydrol.2019.04.087
   Zhao G, 2019, SCI TOTAL ENVIRON, V659, P940, DOI 10.1016/j.scitotenv.2018.12.217
   Zhu JX, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10062009
   Zhu JX, 2019, AUTOMAT CONSTR, V106, P0, DOI 10.1016/j.autcon.2019.102859
   Zhu JX, 2019, AUTOMAT CONSTR, V102, P105, DOI 10.1016/j.autcon.2019.02.014
   Zhu Q, 2020, IEEE INTELL SYST, V35, P18, DOI 10.1109/MIS.2019.2942836
NR 136
TC 32
Z9 32
U1 4
U2 34
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1947-5705
EI 1947-5713
J9 GEOMAT NAT HAZ RISK
JI Geomat. Nat. Hazards Risk
PD JAN 1
PY 2021
VL 12
IS 1
BP 469
EP 498
DI 10.1080/19475705.2021.1880977
PG 30
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources
SC Geology; Meteorology & Atmospheric Sciences; Water Resources
GA QH5QU
UT WOS:000618331000001
DA 2023-04-26
ER

PT J
AU Wu, X
   Shi, ZW
   Zou, ZX
AF Wu, Xi
   Shi, Zhenwei
   Zou, Zhengxia
TI A geographic information-driven method and a new large scale dataset for remote sensing cloud/snow detection
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Geographic information; Cloud and snow detection; Deep convolutional neural networks; Remote sensing image
ID detection algorithm; shadow detection; satellite imagery; automated cloud; landsat imagery; snow detection
AB Geographic information such as the altitude, latitude, and longitude are common but fundamental meta-records in remote sensing image products. In this paper, it is shown that such a group of records provides important priors for cloud and snow detection in remote sensing imagery. The intuition comes from some common geographical knowledge, where many of them are important but are often overlooked. For example, it is generally known that snow is less likely to exist in low-latitude or low-altitude areas, and clouds in different geographic may have various visual appearances. Previous cloud and snow detection methods simply ignore the use of such information, and perform detection solely based on the image data (band reflectance). Due to the neglect of such priors, most of these methods are difficult to obtain satisfactory performance in complex scenarios (e.g., cloud-snow coexistence). In this paper, a novel neural network called "Geographic Information-driven Network (GeoInfoNet)" is proposed for cloud and snow detection. In addition to the use of the image data, the model integrates the geographic information at both training and detection phases. A "geographic information encoder" is specially designed, which encodes the altitude, latitude, and longitude of imagery to a set of auxiliary maps and then feeds them to the detection network. The proposed network can be trained in an end-to-end fashion with dense robust features extracted and fused. A new dataset called "Levir_CS" for cloud and snow detection is built, which contains 4,168 Gaofen-1 satellite images and corresponding geographical records, and is over 20x larger than other datasets in this field. On "Levir_CS", experiments show that the method achieves 90.74% intersection over union of cloud and 78.26% intersection over union of snow. It outperforms other state of the art cloud and snow detection methods with a large margin. Feature visualizations also show that the method learns some important priors which is close to the common sense. The proposed dataset and the code of GeoInfoNet are available in https://github.com/permanentCH5/GeoInfoNet.
C1 [Wu, Xi; Shi, Zhenwei] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
   [Wu, Xi; Shi, Zhenwei] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Wu, Xi; Shi, Zhenwei] Beihang Univ, Sch Astronaut, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Zou, Zhengxia] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
C3 Beihang University; Beihang University; Beihang University; University of Michigan System; University of Michigan
RP Shi, ZW (corresponding author), Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
EM xiwu1000@buaa.edu.cn; shizhenwei@buaa.edu.cn; zzhengxi@unich.edu
FU National Key R&D Program of China [2019YFC1510905]; National Natural Science Foundation of China [61671037]; Beijing Natural Science Foundation [4192034]
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   An ZY, 2015, IEEE J-STARS, V8, P4206, DOI 10.1109/JSTARS.2015.2438015
   Andersen T., 1982, P EX S, V0, P149
   [Anonymous], 2015, ICLR, V0, P0
   Bi JZ, 2019, REMOTE SENS ENVIRON, V221, P665, DOI 10.1016/j.rse.2018.12.002
   Bian JH, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010031
   Bian JH, 2014, INT GEOSCI REMOTE SE, V0, P0, DOI DOI 10.1109/IGARSS.2014.6946469
   Campbell JL, 2005, FRONT ECOL ENVIRON, V3, P314, DOI 10.1890/1540-9295(2005)003[0314:WINNAA]2.0.CO;2
   Chai D, 2019, REMOTE SENS ENVIRON, V225, P307, DOI 10.1016/j.rse.2019.03.007
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Choi H, 2004, REMOTE SENS ENVIRON, V91, P237, DOI 10.1016/j.rse.2004.03.007
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng CW, 2019, IEEE GEOSCI REMOTE S, V16, P608, DOI 10.1109/LGRS.2018.2878239
   Erhan Dumitru, 2009, TECHNICAL REPORT, V1341, P1
   Foga S, 2017, REMOTE SENS ENVIRON, V194, P379, DOI 10.1016/j.rse.2017.03.026
   Francis A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192312
   Gang C, 2007, GEO-SPAT INF SCI, V10, P117, DOI 10.1007/s11806-007-0047-7
   Glorot X., 2011, P 14 INT C ART INT S, V0, P315
   Goff M. L., 2017, P 8 INT C PATT REC S, V10, P1, DOI 10.1049/CP.2017.0139
   Hagolle O, 2010, REMOTE SENS ENVIRON, V114, P1747, DOI 10.1016/j.rse.2010.03.002
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Tran H, 2019, SCI DATA, V6, P0, DOI 10.1038/sdata.2018.300
   Hollstein A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080666
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Irish RR, 2006, PHOTOGRAMM ENG REM S, V72, P1179, DOI 10.14358/PERS.72.10.1179
   Irish RR, 2000, P SOC PHOTO-OPT INS, V4049, P348, DOI 10.1117/12.410358
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, V0, P0
   Jeppesen JH, 2019, REMOTE SENS ENVIRON, V229, P247, DOI 10.1016/j.rse.2019.03.039
   Kang XD, 2019, IEEE GEOSCI REMOTE S, V16, P110, DOI 10.1109/LGRS.2018.2866499
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Li PF, 2015, NEUROCOMPUTING, V169, P34, DOI 10.1016/j.neucom.2014.09.102
   Li WY, 2020, IEEE T GEOSCI REMOTE, V58, P8490, DOI 10.1109/TGRS.2020.2988265
   Li XH, 2019, HYDROL EARTH SYST SC, V23, P2401, DOI 10.5194/hess-23-2401-2019
   Li XH, 2014, IEEE T GEOSCI REMOTE, V52, P7086, DOI 10.1109/TGRS.2014.2307354
   Li ZW, 2019, ISPRS J PHOTOGRAMM, V150, P197, DOI 10.1016/j.isprsjprs.2019.02.017
   Li ZW, 2017, REMOTE SENS ENVIRON, V191, P342, DOI 10.1016/j.rse.2017.01.026
   Lin HN, 2017, IEEE GEOSCI REMOTE S, V14, P1665, DOI 10.1109/LGRS.2017.2727515
   Lin HN, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050480
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu JY, 2019, IEEE ACCESS, V7, P87323, DOI 10.1109/ACCESS.2019.2925565
   Mateo-Garcia G, 2017, INT GEOSCI REMOTE SE, V0, P2255
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Musial JP, 2014, ATMOS MEAS TECH, V7, P799, DOI 10.5194/amt-7-799-2014
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Qiu S, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.024
   Qiu S, 2017, REMOTE SENS ENVIRON, V199, P107, DOI 10.1016/j.rse.2017.07.002
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Scaramuzza PL, 2012, IEEE T GEOSCI REMOTE, V50, P1140, DOI 10.1109/TGRS.2011.2164087
   Selkowitz DJ, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010016
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Shao ZF, 2019, IEEE T GEOSCI REMOTE, V57, P4062, DOI 10.1109/TGRS.2018.2889677
   Shi MY, 2016, INT GEOSCI REMOTE SE, V0, PP701, DOI 10.1109/IGARSS.2016.7729176
   Shi TY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071130
   Srivastava A.N., 2003, P ICML CIT, V3, P0
   Sun L, 2017, ISPRS J PHOTOGRAMM, V124, P70, DOI 10.1016/j.isprsjprs.2016.12.005
   Wang XY, 2018, IEEE J-STARS, V11, P1433, DOI 10.1109/JSTARS.2018.2810094
   Warmerdam F., 2008, OPEN SOURCE APPROACH, V0, PP87, DOI 10.1007/978-3-540-74831-1_5
   Weldon TP, 1996, PATTERN RECOGN, V29, P2005, DOI 10.1016/S0031-3203(96)00047-7
   Wieland M, 2019, REMOTE SENS ENVIRON, V230, P0, DOI 10.1016/j.rse.2019.05.022
   Wu X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111853
   Xie FY, 2017, IEEE J-STARS, V10, P3631, DOI 10.1109/JSTARS.2017.2686488
   Xie SN, 2015, IEEE I CONF COMP VIS, V0, PP1395, DOI 10.1109/ICCV.2015.164
   Yan ZY, 2018, IEEE GEOSCI REMOTE S, V15, P1600, DOI 10.1109/LGRS.2018.2846802
   Yang JY, 2019, IEEE T GEOSCI REMOTE, V57, P6195, DOI 10.1109/TGRS.2019.2904868
   Zhan YJ, 2017, IEEE GEOSCI REMOTE S, V14, P1785, DOI 10.1109/LGRS.2017.2735801
   Zhang Q, 2014, IEEE T GEOSCI REMOTE, V52, P7264, DOI 10.1109/TGRS.2014.2310240
   Zhao S., 2010, 2019 IEEE INT C SIGN, V0, PP1, DOI 10.1109/iceee.2010.5660314
   Zhong B, 2017, IEEE J-STARS, V10, P4898, DOI 10.1109/JSTARS.2017.2734912
   Zhu XL, 2018, REMOTE SENS ENVIRON, V214, P135, DOI 10.1016/j.rse.2018.05.024
   Zhu Z, 2014, REMOTE SENS ENVIRON, V152, P217, DOI 10.1016/j.rse.2014.06.012
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   Zi Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060877
   Zou ZX, 2019, IEEE I CONF COMP VIS, V0, PP201, DOI 10.1109/ICCV.2019.00029
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P5832, DOI 10.1109/TGRS.2016.2572736
NR 80
TC 20
Z9 21
U1 7
U2 37
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2021
VL 174
IS 
BP 87
EP 104
DI 10.1016/j.isprsjprs.2021.01.023
EA FEB 2021
PG 18
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO4AQ
UT WOS:000640987800007
DA 2023-04-26
ER

PT J
AU Mohan, A
   Singh, AK
   Kumar, B
   Dwivedi, R
AF Mohan, Amrita
   Singh, Amit Kumar
   Kumar, Basant
   Dwivedi, Ramji
TI Review on remote sensing methods for landslide detection using machine and deep learning
SO TRANSACTIONS ON EMERGING TELECOMMUNICATIONS TECHNOLOGIES
LA English
DT Review
ID susceptibility assessment; permanent scatterers; logistic-regression; wenchuan earthquake; spatial prediction; satellite imagery; neural-networks; decision tree; time-series; classification
AB Landslide, one of the most critical natural hazards, is caused due to specific compositional slope movement. In the past decades, due to inflation of urbanized area and climate change, a compelling expansion in landslide prevalence took place which is also termed as mass/slope movement and mass wasting, causing extensive collapse around the world. The principal reason for its pursuance is a reduction in the internal resistance of soil and rocks, classified as a slide, topple, fall, and flow. Slopes can be differentiated based on earth material and the nature of its movements. The downward flow of landslides occurs due to excessive rainfall, snowmelt, earthquake, volcanic eruption, and so on. This review article revisits the conventional approaches for identification of landslides, predicting future risk, associated with slope failures, followed by emphasizing the advantages of modern geospatial techniques such as aerial photogrammetry, satellite remote sensing images (ie, panchromatic, multispectral, radar images), Terrestrial laser scanning, and High-Resolution Digital Elevation Model (HR-DEM) in updating landslide inventory maps. Machine learning techniques like Support Vector Machine, Artificial neural network, deep learning has been extensively used with geographical data producing effective results for assessment of natural hazard/resources and environmental research. Based on recent studies, deep learning is a reliable tool addressing remote sensing challenges such as trade-off in imaging system producing poor quality investigation, in addition, to expedite consequent task such as image recognition, object detection, classification, and so on. Conventional methods, like pixel and object-based machine learning methods, have been broadly explored. Advanced development in deep learning technique like CNN (Convolutional neural network) has been extensively successful in information extraction from an image and has exceeded other traditional approaches. Over the past few years, minor attempts have been made for landslide susceptibility mapping using CNN. In addition, small sample sizes for training purpose will be major drawback and notably remarkable while using deep learning techniques. Also, assessment of the model's performance with diverse training and testing proportion other than commonly utilized ratio, that is, 70/30 needs to be explored further. The review article briefly highlights the remote sensing methods for landslide detection using machine learning and deep learning.
C1 [Mohan, Amrita; Dwivedi, Ramji] MNNIT Allahabad, GIS Cell, Allahabad, Uttar Pradesh, India.
   [Singh, Amit Kumar] NIT Patna, CSE Dept, Patna, Bihar, India.
   [Kumar, Basant] MNNIT Allahabad, ECE Dept, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National Institute of Technology; National Institute of Technology (NIT System); National Institute of Technology Patna; National Institute of Technology (NIT System); Motilal Nehru National Institute of Technology
RP Mohan, A (corresponding author), MNNIT Allahabad, GIS Cell, Allahabad, Uttar Pradesh, India.
EM er.amritacs@gmail.com
CR Agliardi F, 2009, GEOMORPHOLOGY, V103, P113, DOI 10.1016/j.geomorph.2007.09.015
   Ahmadyfard A, 2008, 2008 INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS, VOLS 1 AND 2, P688, DOI 10.1109/ISTEL.2008.4651388
   ALHAIDARI MAA, 2019, J COMMUN, V14, P432
   Alimohammadlou Y, 2014, CATENA, V120, P149, DOI 10.1016/j.catena.2014.04.009
   Alkevli T, 2011, B ENG GEOL ENVIRON, V70, P607, DOI 10.1007/s10064-011-0353-z
   [Anonymous], 2014, PROC IEEE C COMPUT V, V0, P0
   ARBANAS SM, 2014, 4 S MAC ASS GEOT JAN, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bai SB, 2014, ENVIRON EARTH SCI, V71, P731, DOI 10.1007/s12665-013-2475-z
   BAJRACHARYA B, 2008, P MT GIS E C JAN, V0, P0
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Barlow J, 2006, PHOTOGRAMM ENG REM S, V72, P687, DOI 10.14358/PERS.72.6.687
   Bialas J, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.036025
   Pham BT, 2016, ENVIRON MODELL SOFTW, V84, P240, DOI 10.1016/j.envsoft.2016.07.005
   Pham BT, 2016, NAT HAZARDS, V83, P97, DOI 10.1007/s11069-016-2304-2
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brenning A, 2005, NAT HAZARD EARTH SYS, V5, P853, DOI 10.5194/nhess-5-853-2005
   BRODLEY CE, 1992, MULTIVARIATE VERSUS, V0, P0
   BRUNSDEN D, 1993, GEOMORPHOLOGY, V7, P85, DOI 10.1016/0169-555X(93)90013-R
   Butt TA, 2022, T EMERG TELECOMMUN T, V33, P0, DOI 10.1002/ett.3646
   Cascini L, 2010, ENG GEOL, V112, P29, DOI 10.1016/j.enggeo.2010.01.003
   Chen JF, 2012, MATH PROBL ENG, V2012, P0, DOI 10.1155/2012/235929
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, PP801, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng G, 2016, INT GEOSCI REMOTE SE, V0, PP767, DOI 10.1109/IGARSS.2016.7729193
   Cheng KS, 2004, ADV SPACE RES-SERIES, V33, P296, DOI 10.1016/S0273-1177(03)00471-X
   Chigira M, 2004, LANDSLIDES, V1, P203, DOI 10.1007/s10346-004-0029-x
   Cigna F, 2011, NAT HAZARD EARTH SYS, V11, P865, DOI 10.5194/nhess-11-865-2011
   Costanzo D, 2012, NAT HAZARD EARTH SYS, V12, P327, DOI 10.5194/nhess-12-327-2012
   Bui DT, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104426
   Bui DT, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5919-4
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), V0, PP444, DOI 10.1109/YAC.2016.7804935
   Dou J, 2020, LANDSLIDES, V17, P641, DOI 10.1007/s10346-019-01286-5
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Eisenbeiss H., 2008, INT ARCH PHOTOGRAM R, V37, P977
   Farina P, 2006, ENG GEOL, V88, P200, DOI 10.1016/j.enggeo.2006.09.007
   Ferretti A, 2001, IEEE T GEOSCI REMOTE, V39, P8, DOI 10.1109/36.898661
   Fiorucci F, 2011, GEOMORPHOLOGY, V129, P59, DOI 10.1016/j.geomorph.2011.01.013
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Galli M, 2008, GEOMORPHOLOGY, V94, P268, DOI 10.1016/j.geomorph.2006.09.023
   Ghorbanzadeh O, 2019, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON GEOGRAPHICAL INFORMATION SYSTEMS THEORY, V0, P33, DOI 10.5220/0007675300330040
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   GOALS MP, 2019, NIPPON RONEN IGAKKAI, V56, P1
   Goetz JN, 2015, COMPUT GEOSCI-UK, V81, P1, DOI 10.1016/j.cageo.2015.04.007
   Golovko D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090943
   Gorum T, 2011, GEOMORPHOLOGY, V133, P152, DOI 10.1016/j.geomorph.2010.12.030
   Gu YT, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9102110
   Guzzetti F, 2000, ENVIRON MANAGE, V25, P247, DOI 10.1007/s002679910020
   GUZZETTI F, 2005, THESIS, V0, P373
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   HAEBERLIN Y, 2004, INT ARCH PHOTOGRAMM, V35, P273
   Harvey PK, 2005, GEOL SOC SPEC PUBL, V240, P207, DOI 10.1144/GSL.SP.2005.240.01.16
   Highland L.M., 2008, LANDSLIDE HDB A GUID, V0, P0
   Huang Y, 2018, CATENA, V165, P520, DOI 10.1016/j.catena.2018.03.003
   Huang ZJ, 2019, PROC CVPR IEEE, V0, PP6402, DOI 10.1109/CVPR.2019.00657
   Hungr O, 2014, LANDSLIDES, V11, P167, DOI 10.1007/s10346-013-0436-y
   IAN HW, 2017, DATA MINING PRACTICA, V0, P0
   Jung HS, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9122446
   KADAVI PR, 2018, REMOTE SENS, V10, P1
   Kavzoglu T, 2019, ADV NAT TECH HAZ RES, V50, P283, DOI 10.1007/978-3-319-77377-3_13
   Kavzoglu T, 2015, NAT HAZARDS, V76, P471, DOI 10.1007/s11069-014-1506-8
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai JS, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19173717
   Lauknes TR, 2010, REMOTE SENS ENVIRON, V114, P2097, DOI 10.1016/j.rse.2010.04.015
   Lee S, 2003, ENVIRON GEOL, V44, P820, DOI 10.1007/s00254-003-0825-y
   Lee S, 2006, MATH GEOL, V38, P199, DOI 10.1007/s11004-005-9012-x
   Li CX, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19204586
   Li DR, 2012, SCI CHINA EARTH SCI, V55, P1043, DOI 10.1007/s11430-012-4445-9
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1264
   Lim M, 2005, PHOTOGRAMM REC, V20, P109, DOI 10.1111/j.1477-9730.2005.00315.x
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050752
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Marjanovic M, 2011, ACTA GEOTECH SLOV, V8, P45
   MADAAN S, 2017, B SEISMOLOG SOC AM, V0, P9
   Manconi A, 2014, NAT HAZARD EARTH SYS, V14, P1835, DOI 10.5194/nhess-14-1835-2014
   Marcelino EV, 2009, INT J APPL EARTH OBS, V11, P181, DOI 10.1016/j.jag.2009.01.003
   Martha Tapas R., 2015, GEOSCIENCE FRONTIERS, V6, P793, DOI 10.1016/j.gsf.2013.12.011
   Martha TR, 2016, J INDIAN SOC REMOTE, V44, P515, DOI 10.1007/s12524-015-0532-7
   Martha TR, 2012, ISPRS J PHOTOGRAMM, V67, P105, DOI 10.1016/j.isprsjprs.2011.11.004
   Mboga N, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050597
   Melville B, 2018, INT J APPL EARTH OBS, V66, P46, DOI 10.1016/j.jag.2017.11.006
   Mezaal MR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071029
   Micheletti N, 2014, MATH GEOSCI, V46, P33, DOI 10.1007/s11004-013-9511-0
   MIKO M, 2017, ADV CULT LIV LANDSLI, V5, P1
   Oppikofer T, 2009, NAT HAZARD EARTH SYS, V9, P1003, DOI 10.5194/nhess-9-1003-2009
   Othman AA, 2013, REMOTE SENS-BASEL, V5, P1024, DOI 10.3390/rs5031024
   Pagot E, 2008, IEEE J-STARS, V1, P120, DOI 10.1109/JSTARS.2008.2001154
   Pak M, 2017, INT C SYNTH MODEL AN, V0, P0
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
   Parker RN, 2011, NAT GEOSCI, V4, P449, DOI 10.1038/ngeo1154
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050523
   Pham B.T., 2016, J GEOMAT, V10, P71
   Phengsuwan J, 2022, T EMERG TELECOMMUN T, V33, P0, DOI 10.1002/ett.3899
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Pourghasemi HR, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10103697
   Pradhan SP, 2019, ADV NAT TECH HAZ RES, V50, P3, DOI 10.1007/978-3-319-77377-3_1
   Prakash N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030346
   PRASAD NB, 1995, LANDSLIDES CAUSES MI, V0, P0
   Rajmohan G, 2021, T EMERG TELECOMMUN T, V32, P0, DOI 10.1002/ett.3927
   Razak KA, 2011, GEOMORPHOLOGY, V126, P186, DOI 10.1016/j.geomorph.2010.11.003
   REDMON J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Roodposhti MS, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19102274
   Roodposhti MS, 2019, ENVIRON MODELL SOFTW, V112, P70, DOI 10.1016/j.envsoft.2018.10.006
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   SASSA K, 2014, LANDSLIDE SCI SAFER, V2, P1
   Shirzadi A, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113777
   Sun XH, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7110438
   Tarolli P, 2012, NAT HAZARDS, V61, P65, DOI 10.1007/s11069-010-9695-2
   Tavakkoli Piralilou S, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212575
   Tien Bui D., 2014, CARTOGRAPHY POLE POL, V0, PP303, DOI 10.1007/978-3-642-32618-9_22
   TOTH CK, 2010, TOPOGRAPHIC LASER RA, V1161, P3333
   Tsai F, 2010, NAT HAZARD EARTH SYS, V10, P2179, DOI 10.5194/nhess-10-2179-2010
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Van Westen CJ, 1996, TRANSPORTATION RES B, V247, P129
   VANWESTEN C, 2014, MOUNTAIN RISKS PREDI, V34, P0
   Vasu NN, 2016, GEOMORPHOLOGY, V263, P50, DOI 10.1016/j.geomorph.2016.03.023
   Nhu VH, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2020.104458
   Walia N., 2015, INT J COMPUT APPL, V123, P32, DOI 10.5120/IJCA2015905635
   Wan SA, 2013, ENVIRON EARTH SCI, V68, P1349, DOI 10.1007/s12665-012-1832-7
   Wang LJ, 2016, GEOSCI J, V20, P117, DOI 10.1007/s12303-015-0026-1
   Wang YM, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16101769
   Wang YY, 2019, DISCRETE DYN NAT SOC, V2019, P0, DOI 10.1155/2019/5071268
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Xu C, 2014, LANDSLIDES, V11, P441, DOI 10.1007/s10346-013-0404-6
   Ye CM, 2019, IEEE J-STARS, V12, P5047, DOI 10.1109/JSTARS.2019.2951725
   Yu XY, 2016, INT J ENV RES PUB HE, V13, P0, DOI 10.3390/ijerph13050487
   Zhang L, 2018, INT J COMPUT VISION, V126, P797, DOI 10.1007/s11263-018-1080-8
   Zhao HZ, 2019, INT J REMOTE SENS, V40, P8506, DOI 10.1080/01431161.2019.1615652
   Zhao YH, 2008, ADV SPACE RES, V41, P1955, DOI 10.1016/j.asr.2007.07.020
   Zhong C, 2020, INT J REMOTE SENS, V41, P1555, DOI 10.1080/01431161.2019.1672904
   ZHU M, 2019, MICROMACHINES, V10, P1
   2012, 1900, V3, V0, P45
NR 139
TC 54
Z9 54
U1 56
U2 331
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2161-3915
EI 
J9 T EMERG TELECOMMUN T
JI Trans. Emerg. Telecommun. Technol.
PD JUL 15
PY 2021
VL 32
IS 7
BP 
EP 
DI 10.1002/ett.3998
EA JUN 2020
PG 23
WC Telecommunications
SC Telecommunications
GA TD8CC
UT WOS:000542033600001
DA 2023-04-26
ER

PT J
AU Hashemi-Beni, L
   Gebrehiwot, AA
AF Hashemi-Beni, Leila
   Gebrehiwot, Asmamaw A.
TI Flood Extent Mapping: An Integrated Method Using Deep Learning and Region Growing Using UAV Optical Data
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Floods; Vegetation mapping; Remote sensing; Training; Deep learning; Optical sensors; Optical imaging; Convolutional neural network (CNN); flood mapping; LiDAR; region growing (RG); remote sensing
ID areas
AB Flooding occurs frequently and causes loss of lives, and extensive damages to infrastructure and the environment. Accurate and timely mapping of flood extent to ascertain damages is critical and essential for relief activities. Recently, deep-learning-based approaches, including convolutional neural network (CNN) has shown promising results for flood extent mapping. However, these methods cannot extract floods underneath vegetation canopy using the optical imagery. This article attempts to address this problem by introducing an integrated CNN and region growing (RG) method for the mapping of both visible and underneath vegetation flooded areas. The CNN-based classifier is used to extract flooded areas from the optical images, whereas, the RG method is applied to estimate the extent of floods underneath vegetation that are not visible from imagery using the digital elevation model. A data augmentation technique is applied for training the CNN-based classifier to improve the classification results. The results show that the data augmentation can enhance the accuracy of image classification and the proposed integrated method efficiently detects floods in both the visible and the areas covered by vegetation, which is essential to supporting effective flood emergency response and recovery activities.
C1 [Hashemi-Beni, Leila] North Carolina A&T State Univ, Dept Built Environm, Greensboro, NC 27411 USA.
   [Gebrehiwot, Asmamaw A.] North Carolina A&T State Univ, Program Appl Sci & Technol, Greensboro, NC 27411 USA.
C3 University of North Carolina; North Carolina A&T State University; University of North Carolina; North Carolina A&T State University
RP Hashemi-Beni, L (corresponding author), North Carolina A&T State Univ, Dept Built Environm, Greensboro, NC 27411 USA.
EM lhashemibeni@ncat.edu; aagebrehiwot@aggies.ncat.edu
FU U.S. National Science Foundation [1800768, 1832110]; North Carolina Collaboratory (Flood Resilience: Data Collection and Data Analytics in support of Flood Management); Division Of Human Resource Development; Direct For Education and Human Resources [1800768] Funding Source: National Science Foundation
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Vo AV, 2015, ISPRS J PHOTOGRAMM, V104, P88, DOI 10.1016/j.isprsjprs.2015.01.011
   [Anonymous], 2020, GET STARTED IMAGE LA, V0, P0
   Bins L. SantAnna, 1996, S BRASILEIRO SENSORI, V8, P677, DOI 10.1016/b978-008042848-2/50002-6
   Boccardo P, 2015, SENSORS-BASEL, V15, P15717, DOI 10.3390/s150715717
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Eaton-Rosen, 2018, INT C MED IM DEEP LE, V0, P0
   Eigen D, 2015, IEEE I CONF COMP VIS, V0, PP2650, DOI 10.1109/ICCV.2015.304
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Feng QL, 2015, WATER-SUI, V7, P1437, DOI 10.3390/w7041437
   Gebrehiwot A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071486
   Hashemi-Beni L, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113843
   Ireland G, 2015, REMOTE SENS-BASEL, V7, P3372, DOI 10.3390/rs70303372
   Klemas V, 2015, J COASTAL RES, V31, P1005, DOI 10.2112/JCOASTRES-D-14-00160.1
   Klemas VV, 2015, J COASTAL RES, V31, P1260, DOI 10.2112/JCOASTRES-D-15-00005.1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lang MW, 2009, WETLANDS, V29, P1166, DOI 10.1672/08-197.1
   Manfreda S, 2019, J FLOOD RISK MANAG, V12, P0, DOI 10.1111/jfr3.12541
   Nardi F, 2006, WATER RESOUR RES, V42, P0, DOI 10.1029/2005WR004155
   Pan J, 2016, GEO-SPAT INF SCI, V19, P1, DOI 10.1080/10095020.2015.1127628
   Perez L., 2017, ARXIV, V0, P0
   Piramanayagam S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091429
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Romanowicz R, 2003, WATER RESOUR RES, V39, P0, DOI 10.1029/2001WR001056
   Sainath TN, 2013, INT CONF ACOUST SPEE, V0, PP8614, DOI 10.1109/ICASSP.2013.6639347
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, ARXIV, V0, P0
   Taigman Y, 2014, PROC CVPR IEEE, V0, PP1701, DOI 10.1109/CVPR.2014.220
   Tin Kam Ho, 1995, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, V0, PP278, DOI 10.1109/ICDAR.1995.598994
   Vapnik V., 2013, NATURE STAT LEARNING, V0, P0
   Yang HL, 2017, INT GEOSCI REMOTE SE, V0, P870
   Yao H, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121443
   Zheng YY, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19051058
   Zhong YF, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.025006
   Zhong ZL, 2016, INT GEOSCI REMOTE SE, V0, PP1591, DOI 10.1109/IGARSS.2016.7729406
   [周敏 Zhou Min], 2017, 中国图象图形学报 JOURNAL OF IMAGE AND GRAPHICS, V22, P702
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 40
TC 20
Z9 20
U1 6
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2127
EP 2135
DI 10.1109/JSTARS.2021.3051873
PG 9
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QC7WE
UT WOS:000615042800012
DA 2023-04-26
ER

PT J
AU Tsadiras, A
   Pempetzoglou, M
   Viktoratos, I
AF Tsadiras, Athanasios
   Pempetzoglou, Maria
   Viktoratos, Iosif
TI Making Predictions of Global Warming Impacts Using a Semantic Web Tool that Simulates Fuzzy Cognitive Maps
SO COMPUTATIONAL ECONOMICS
LA English
DT Article
DE Global Warming; Fuzzy Cognitive Maps; Semantic Web; Neural Networks; Simulation Modeling
ID support; management; models
AB One of the most important environmental problems of our era is Global Warming (GW), which derives its roots mainly from anthropogenic activities and is expected to cause far-reaching and long-lasting impacts to the natural environment, ecosystems and human societies. The purpose of this paper is twofold: (a) to develop a model of the causal relationships that exist in the field of GW, using the well-established Artificial Intelligence technique of Fuzzy Cognitive Maps (FCMs) and (b) to develop a Semantic Web simulation software tool, that visually simulates the FCM dynamic behavior and studies the equilibrium that the FCM dynamic system reaches. Using this generic tool, various scenarios can be imposed to the FCM model and predictions can be made on these, in a "what-if" manner. The features of the web simulation tool are exhibited using the FCM that was created and concerns "Global Warming". By applying Semantic Web technologies, the tool makes the results and the various FCM models, that can be implemented in it, easily accessible to various users or systems, through the Internet. In this way, policy makers can use this technique and tool to make predictions by viewing dynamically the consequences that the system predicts to their imposed scenarios and share them through the world wide web.
C1 [Tsadiras, Athanasios; Viktoratos, Iosif] Aristotle Univ Thessaloniki, Sch Econ, Thessaloniki, Greece.
   [Pempetzoglou, Maria] Democritus Univ Thrace, Sch Social Policy, Komotini, Greece.
C3 Aristotle University of Thessaloniki; Democritus University of Thrace
RP Tsadiras, A (corresponding author), Aristotle Univ Thessaloniki, Sch Econ, Thessaloniki, Greece.
EM tsadiras@econ.auth.gr; mariap@sp.duth.gr; viktorat@econ.auth.gr
CR Andreou AS, 2003, DEFENCE PEACE ECON, V14, P293, DOI 10.1080/10242690302931
   [Anonymous], 1900, DOI DOI 10.1023/A:1019090117643 10.1023/A:1019090117643, V0, P0
   [Anonymous], 2010, ADAPTCOST PROJECT AN, V0, P0
   [Anonymous], 1976, STRUCTURE DECISION C, V0, P0
   Bassiliades N., 2005, INT SCI C COMP SCI H, V0, P0
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Buchanan BG., 1984, RULE BASED EXPERT SY, V0, P0
   Buyukozkan G, 2012, EXPERT SYST APPL, V39, P10438, DOI 10.1016/j.eswa.2012.02.014
   Carvalho JP, 2013, FUZZY SET SYST, V214, P6, DOI 10.1016/j.fss.2011.12.009
   Case DM, 2018, FUZZY HYBRID COMPUTING IN CONSTRUCTION ENGINEERING AND MANAGEMENT: THEORY AND APPLICATIONS, V0, P413
   Cheah WP, 2011, EXPERT SYST APPL, V38, P15316, DOI 10.1016/j.eswa.2011.06.032
   Chichilnisky G, 2017, EC GLOBAL ENV CATAST, V0, P0
   Coban O, 2005, INFORM SCIENCES, V169, P131, DOI 10.1016/j.ins.2004.02.009
   de Franciscis D., 2014, FUZZY COGNITIVE MAPS, V0, PP199, DOI 10.1007/978-3-642-39739-4_12
   Dickerson J.A., 2001, ATL S MOL BIOL GEN I, V0, P0
   Doukas H, 2020, EUR J OPER RES, V280, P1, DOI 10.1016/j.ejor.2019.01.017
   Duane K, 2001, WEB DEV JAVA SERVER, V0, P0
   Espinosa-Paredes G, 2009, PROG NUCL ENERG, V51, P434, DOI 10.1016/j.pnucene.2008.10.001
   FORD JD, 1984, ACAD MANAGE J, V27, P271, DOI 10.2307/255925
   Ghaderi SF, 2012, EXPERT SYST APPL, V39, P4635, DOI 10.1016/j.eswa.2011.08.097
   Gray SA, 2013, P ANN HICSS, V0, PP965, DOI 10.1109/HICSS.2013.399
   HART JA, 1977, WORLD POLIT, V30, P115, DOI 10.2307/2010077
   Hatwagner M, 2019, TRENDS MATH COMPUTAT, V0, P0
   Hobbs BF, 2002, ECOL APPL, V12, P1548, DOI 10.1890/1051-0761(2002)012[1548:FCMAAT]2.0.CO;2
   Jose A, 2010, STUD FUZZ SOFT COMP, V247, P71
   Jung JJ, 2012, EXPERT SYST APPL, V39, P5857, DOI 10.1016/j.eswa.2011.11.082
   Kang I, 2004, EXPERT SYST APPL, V26, P545, DOI 10.1016/j.eswa.2003.10.012
   Karmacharya A., 2016, INT 24 CART C, V0, P0
   Kim MC, 2008, EXPERT SYST APPL, V35, P1166, DOI 10.1016/j.eswa.2007.08.015
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kosko B., 1992, NEURAL NETWORKS FUZZ, V0, P0
   Lee KC, 2012, EXPERT SYST APPL, V39, P9255, DOI 10.1016/j.eswa.2012.02.079
   Lee KC, 2012, EXPERT SYST APPL, V39, P8626, DOI 10.1016/j.eswa.2012.01.191
   Lee SJ, 2009, EXPERT SYST APPL, V36, P10447, DOI 10.1016/j.eswa.2009.01.070
   Mohr S., 1997, SOFTWARE DESIGN FUZZ, V0, P0
   Moscholios N. M., 1967, TAX INCENTIVES COMP, V0, P0
   NAKAMURA K, 1982, IEEE T SYST MAN CYB, V12, P765, DOI 10.1109/TSMC.1982.4308910
   Napoles G, 2020, INTELLIGENT DECISION, V0, P0
   Napoles G, 2018, INT J ARTIF INTELL T, V27, P0, DOI 10.1142/S0218213018600102
   Nasirzadeh F, 2020, INT J CONSTR MANAG, V20, P223, DOI 10.1080/15623599.2018.1484847
   Osoba OA, 2017, J DEF MODEL SIMUL-AP, V14, P17, DOI 10.1177/1548512916680779
   Papageorgiou EI, 2017, NEUROCOMPUTING, V232, P113, DOI 10.1016/j.neucom.2016.10.072
   Papageorgiou EI, 2012, J BIOMED INFORM, V45, P45, DOI 10.1016/j.jbi.2011.08.018
   PAPAGEORGIOU K, 2020, ENERGIES, V13, P0
   Ramsey D, 2005, J ANIM ECOL, V74, P905, DOI 10.1111/j.1365-2656.2005.00986.x
   Roberts F, 1976, STRUCTURE DECISION, V0, P142
   ROBERTS FS, 1975, ENVIRON PLANN A, V7, P703, DOI 10.1068/a070703
   Salmeron JL, 2012, APPL SOFT COMPUT, V12, P3704, DOI 10.1016/j.asoc.2012.01.015
   Stern N., 2007, EC CLIMATE CHANGE ST, V0, P0
   Tietenberg T., 1999, INT YB ENV RESOUR EC, V0, P171
   Trappey AJC, 2010, EXPERT SYST APPL, V37, P7329, DOI 10.1016/j.eswa.2010.04.026
   Tryfona N, 2005, LECT NOTES COMPUT SC, V3534, P168
   Tsadiras A. K., 1995, P 1 ICSC INT S FUZZ, V0, PB2
   Tsadiras AK, 1998, FUZZY SET SYST, V93, P263, DOI 10.1016/S0165-0114(96)00185-6
   Tsadiras AK, 2003, LECT NOTES COMPUT SC, V2563, P172
   Tsadiras AK, 1997, INFORM SCIENCES, V101, P109, DOI 10.1016/S0020-0255(97)00001-7
   Tsadiras A, 2013, EXPERT SYST APPL, V40, P1413, DOI 10.1016/j.eswa.2012.08.035
   Tsadirus A. K., 1996, NEURAL NETWORK WORLD, V6, P719
   Uzawa H, 2008, EC THEORY GLOBAL WAR, V0, P0
   Viktoratos I, 2017, PERVASIVE MOB COMPUT, V38, P14, DOI 10.1016/j.pmcj.2016.08.002
   WMO-World Meteorological Organization, 2019, 1233 WMO MO, V0, P0
   Wrightson M.T., 1976, STRUCTURE DECISION C, V0, P291
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 63
TC 5
Z9 5
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0927-7099
EI 1572-9974
J9 COMPUT ECON
JI Comput. Econ.
PD OCT 15
PY 2021
VL 58
IS 3
BP 715
EP 745
DI 10.1007/s10614-020-10025-1
EA JUL 2020
PG 31
WC Economics; Management; Mathematics, Interdisciplinary Applications
SC Business & Economics; Mathematics
GA WD2UT
UT WOS:000559363900001
DA 2023-04-26
ER

PT J
AU Aguirre, GA
   Robles, RRC
   Duarez, FMG
   Achata, LR
   Chacon, LEG
   Garate-Quispe, J
AF Alarcon Aguirre, Gabriel
   Canahuire Robles, Rembrandt R.
   Guevara Duarez, Felipe M.
   Rodriguez Achata, Liset
   Gallegos Chacon, Luis E.
   Garate-Quispe, Jorge
TI Dynamics of forest loss in the southeast of the Peruvian Amazon: a case study in Madre de Dios
SO ECOSISTEMAS
LA Spanish
DT Article
DE agriculture; annual exchange rate; cover change; gold mining; neural network; residual disposal water
ID tri-national frontier; land-cover change; protected areas; deforestation; conservation; infrastructure; biodiversity; expansion; highway; trends
AB The western Amazon, specifically the region of Madre de Dios, is known as the biodiversity capital of Peru and is globally recognized as one of the most biodiverse places on Earth. However, it has been threatening by a serious problem of forest loss. The main environmental threats are due to mismanagement of the territory that causes the concentration of land, agricultural expansion, livestock, gold mining, and uncontrolled economic exploitation. This study analyzes the dynamics of forest loss and changes in land use and cover between 1999-2018. Remote sensing techniques were used to quantify forest loss. Landsat 5 Thematic Mapper (TM) and 8 Operational Land Imagery (OLI). The images were processed using a supervised classification called Neural Net. The methodology includes validation procedures using field verification points and medium and high-resolution remote sensing images of different sensors (SPOT-5, PlanetScope, WorldView, and Drone). The results showed a forest loss of 1698.63 km(2) during 1999-2018, with an annual deforestation rate of -0.21%, and an average forest loss of 59.28 km(2)/year. For changes from forests to other land use, we found the conversion of 841.41 km(2) during 2014-2018. Our results indicate that agriculture is the most responsible for advancing deforestation (72.90%), while gold mining has a greater incidence in targeted sectors
C1 [Alarcon Aguirre, Gabriel; Gallegos Chacon, Luis E.] Univ Nacl Amazon Madre de Dios, Fac Ingn, Ctr Teledetecc Estudio & Gest Recursos Nat CETEGE, Puerto Maldonado 17001, Peru.
   [Canahuire Robles, Rembrandt R.; Garate-Quispe, Jorge] Univ Nacl Amazon Madre de Dios Peru, Fac Ingn, Dept Acad Ingn Forestal & Medio Ambiente, Puerto Maldonado 17001, Peru.
   [Guevara Duarez, Felipe M.] Univ Nacl Amazon Madre de Dios, Fac Educ, Dept Acad Educ, Puerto Maldonado 17001, Peru.
   [Rodriguez Achata, Liset] Univ Nacl Amazon Madre de Dios, Fac Ingn, Dept Acad Ciencias Basicas, Puerto Maldonado 17001, Peru.
   [Garate-Quispe, Jorge] Fac Biol, Dept Biol Evolut Ecol & Ciencias Ambientales, Barcelona 08028, Spain.
C3 Universidad Nacional Amazonica De Madre De Dios; Universidad Nacional Amazonica De Madre De Dios; Universidad Nacional Amazonica De Madre De Dios; University of Barcelona
RP Aguirre, GA (corresponding author), Univ Nacl Amazon Madre de Dios, Fac Ingn, Ctr Teledetecc Estudio & Gest Recursos Nat CETEGE, Puerto Maldonado 17001, Peru.
EM galarcona@hotmail.com
CR Alarcon G, 2016, REV INVESTIG ALTOAND, V18, P319, DOI 10.18271/ria.2016.221
   Andersen LE, 2017, ECOL ECON, V135, P76, DOI 10.1016/j.ecolecon.2016.12.033
   [Anonymous], 2006, REMOTE SENSING DIGIT, V0, P0
   Asner GP, 2017, ENVIRON RES LETT, V12, P0, DOI 10.1088/1748-9326/aa7dab
   Asner GP, 2014, P NATL ACAD SCI USA, V111, PE5016, DOI 10.1073/pnas.1419550111
   Asner GP, 2013, P NATL ACAD SCI USA, V110, P18454, DOI 10.1073/pnas.1318271110
   Baraloto C, 2015, BIOL CONSERV, V191, P674, DOI 10.1016/j.biocon.2015.08.024
   Bax V, 2018, APPL GEOGR, V91, P99, DOI 10.1016/j.apgeog.2018.01.002
   Bennett A, 2018, WORLD DEV, V109, P29, DOI 10.1016/j.worlddev.2018.04.001
   Bonilla-Bedoya S, 2018, SCI TOTAL ENVIRON, V644, P1044, DOI 10.1016/j.scitotenv.2018.07.028
   Cabral AIR, 2018, APPL GEOGR, V100, P101, DOI 10.1016/j.apgeog.2018.10.003
   Carvalho WD, 2019, PERSPECT ECOL CONSER, V17, P122, DOI 10.1016/j.pecon.2019.06.002
   Chuvieco E., 2010, PLAN NACL TELEDETECC, V0, P0
   Cortes-McPherson D, 2019, EXTRACT IND SOC, V6, P382, DOI 10.1016/j.exis.2019.01.002
   Diringer SE, 2020, ENVIRON SCI TECHNOL, V54, P286, DOI 10.1021/acs.est.9b06620
   Dourojeanni M, 2002, B CF S, V19, P1
   Dourojeanni M, 2009, AMAZONIA PERUANA 202, V0, P0
   Dourojeanni M.J., 2019, REV PER, V34, P4, DOI 10.21704/rfp.v34i1.1244
   Dourojeanni M.J, 2006, ESTUDIO CASO CARRETE, V0, P0
   Dourojeanni Marc J., 2014, ECOL. APL., V13, P225
   Duff PM, 2019, EXTRACT IND SOC, V6, P552, DOI 10.1016/j.exis.2019.01.005
   Felde GW, 2003, INT GEOSCI REMOTE SE, V0, P90
   Giudice R, 2012, ECOL ECON, V77, P158, DOI 10.1016/j.ecolecon.2012.02.024
   Glinskis EA, 2019, LAND USE POLICY, V80, P95, DOI 10.1016/j.landusepol.2018.09.032
   Goodman RC, 2019, FOREST ECOL MANAG, V439, P18, DOI 10.1016/j.foreco.2019.02.037
   Holdridge L. R., 1967, LIFE ZONE ECOLOGY., V0, P0
   Instituto Nacional de Pesquisas Espaciais (INPE), 2020, PROJETO PRODES MONIT, V0, P0
   JENSEN JR, 2015, INTRO DIGITAL IMAGE, V0, P501
   Kahhat R, 2019, SCI TOTAL ENVIRON, V662, P940, DOI 10.1016/j.scitotenv.2019.01.246
   Lesschen J.P., 2005, STAT METHODS ANAL SP, V0, P0
   Lipscomb M, 2020, WORLD DEV, V129, P0, DOI 10.1016/j.worlddev.2019.104854
   Lopez S, 2020, ECOL INDIC, V115, P0, DOI 10.1016/j.ecolind.2020.106357
   McClelland JL., 1987, PARALLEL DISTRIBUTED, V0, P0, DOI DOI 10.7551/mitpress/5237.001.0001
   Moody KH, 2020, ENVIRON RES, V182, P0, DOI 10.1016/j.envres.2019.109042
   Morales-Hidalgo D, 2015, FOREST ECOL MANAG, V352, P68, DOI 10.1016/j.foreco.2015.06.011
   Murad Cesar Augusto, 2018, REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT, V11, P161, DOI 10.1016/j.rsase.2018.07.003
   Ofosu G, 2020, ENVIRON SCI POLICY, V106, P210, DOI 10.1016/j.envsci.2020.02.005
   Oliveira AS, 2019, LANDSCAPE URBAN PLAN, V188, P171, DOI 10.1016/j.landurbplan.2019.04.025
   Perz S., 2016, NATURALEZA SOC PERPE, V0, P0
   Perz SG, 2016, LAND USE POLICY, V58, P9, DOI 10.1016/j.landusepol.2016.07.008
   Perz SG, 2013, LAND USE POLICY, V34, P27, DOI 10.1016/j.landusepol.2013.01.009
   Postigo J., 2016, PERSP SOC EC CAMB GL, V0, P0
   Puyravaud JP, 2003, FOREST ECOL MANAG, V177, P593, DOI 10.1016/S0378-1127(02)00335-3
   RAISG, 2020, BBC NEWS MUNDO, V0, P0
   Recanati F, 2015, PROCEDIA ENGINEER, V118, P630, DOI 10.1016/j.proeng.2015.08.496
   Recanati F, 2018, ECOL ENG, V117, P194, DOI 10.1016/j.ecoleng.2018.03.010
   Salo M, 2016, EXTRACT IND SOC, V3, P1058, DOI 10.1016/j.exis.2016.10.001
   Scullion JJ, 2014, BIOL CONSERV, V171, P247, DOI 10.1016/j.biocon.2014.01.036
   Silva CHL, 2021, NAT ECOL EVOL, V5, P144, DOI 10.1038/s41559-020-01368-x
   Siqueira-Gay J, 2020, RESOUR POLICY, V67, P0, DOI 10.1016/j.resourpol.2020.101662
   Soto-Benavento M, 2020, SCI AGROPEC, V11, P49, DOI 10.17268/sci.agropecu.2020.01.06
   Southworth J, 2011, REMOTE SENS-BASEL, V3, P1047, DOI 10.3390/rs3051047
   Swenson JJ, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0018875
   Tarazona Y, 2020, REMOTE SENS APPL, V19, P0, DOI 10.1016/j.rsase.2020.100337
   Tubbeh R, 2019, J LAT AM GEOGR, V18, P224
   Ramirez MGV, 2020, CATENA, V189, P0, DOI 10.1016/j.catena.2020.104454
   Wang D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020169
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111309
   Zinngrebe Y, 2016, J NAT CONSERV, V32, P10, DOI 10.1016/j.jnc.2016.03.006
NR 65
TC 1
Z9 1
U1 3
U2 10
PU ASOCIACION ESPANOLA ECOLOGIA TERRESTRE
PI MOSTOLES
PA C/ TULIPSAN S-N, DEPT BIOLOGIA & GEOLOGIA, UNIV REY JUAN CARLOS, MOSTOLES, 28933, SPAIN
SN 1697-2473
EI 
J9 ECOSISTEMAS
JI Ecosistemas
PD MAY-AUG 15
PY 2021
VL 30
IS 2
BP 
EP 
DI 10.7818/ECOS.2175
PG 11
WC Ecology
SC Environmental Sciences & Ecology
GA UE2BX
UT WOS:000687700600006
DA 2023-04-26
ER

PT J
AU Liu, YF
   Zhu, QG
   Cao, F
   Chen, JK
   Lu, G
AF Liu, Yifan
   Zhu, Qigang
   Cao, Feng
   Chen, Junke
   Lu, Gang
TI High-Resolution Remote Sensing Image Segmentation Framework Based on Attention Mechanism and Adaptive Weighting
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE multi-scale convolutional; computer vision; semantic segmentation; remote sensing; neural network; ISPRS Vaihingen
ID extraction; network
AB Semantic segmentation has been widely used in the basic task of extracting information from images. Despite this progress, there are still two challenges: (1) it is difficult for a single-size receptive field to acquire sufficiently strong representational features, and (2) the traditional encoder-decoder structure directly integrates the shallow features with the deep features. However, due to the small number of network layers that shallow features pass through, the feature representation ability is weak, and noise information will be introduced to affect the segmentation performance. In this paper, an Adaptive Multi-Scale Module (AMSM) and Adaptive Fuse Module (AFM) are proposed to solve these two problems. AMSM adopts the idea of channel and spatial attention and adaptively fuses three-channel branches by setting branching structures with different void rates, and flexibly generates weights according to the content of the image. AFM uses deep feature maps to filter shallow feature maps and obtains the weight of deep and shallow feature maps to filter noise information in shallow feature maps effectively. Based on these two symmetrical modules, we have carried out extensive experiments. On the ISPRS Vaihingen dataset, the F1-score and Overall Accuracy (OA) reached 86.79% and 88.35%, respectively.
C1 [Liu, Yifan; Zhu, Qigang; Lu, Gang] Shandong Univ Sci & Technol, Dept Elect Engn & Informat Technol, Jinan 250031, Peoples R China.
   [Cao, Feng] Fujian Anta Logist Informat Technol Co Ltd, Quanzhou 362200, Peoples R China.
   [Chen, Junke] Shandong Univ Sci & Technol, Dept Finance & Econ, Jinan 250031, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of Science & Technology
RP Zhu, QG (corresponding author), Shandong Univ Sci & Technol, Dept Elect Engn & Informat Technol, Jinan 250031, Peoples R China.
EM 201803204418@sdust.edu.cn; skd992356@sdust.edu.cn; yingyu-liuyifan@yqsx.onexmail.com; 201903104102@sdust.edu.cn; 201903204415@sdust.edu.cn
FU Provincial and School-level Educational Reform Project Communication Engineering CDIO Talent Training [310301815]; Excellent Teaching Team Project [310302202]
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bilinski P, 2018, PROC CVPR IEEE, V0, PP6596, DOI 10.1109/CVPR.2018.00690
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng BW, 2019, IEEE I CONF COMP VIS, V0, PP5217, DOI 10.1109/ICCV.2019.00532
   Cheng JY, 2017, 2017 18TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), V0, PP589, DOI 10.1109/ICAR.2017.8023671
   Dai JF, 2017, IEEE I CONF COMP VIS, V0, PP764, DOI 10.1109/ICCV.2017.89
   Guo H, 2019, PROC CVPR IEEE, V0, PP729, DOI 10.1109/CVPR.2019.00082
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Kan K, 2021, RENEW ENERG, V168, P960, DOI 10.1016/j.renene.2020.12.103
   Ke T.W., 2018, P EUR C COMP VIS ECC, V0, P0
   Kumar BGV, 2016, PROC CVPR IEEE, V0, PP5385, DOI 10.1109/CVPR.2016.581
   Li B, 2019, IEEE I CONF COMP VIS, V0, PP8518, DOI 10.1109/ICCV.2019.00861
   Lin D, 2018, LECT NOTES COMPUT SC, V11207, P622, DOI 10.1007/978-3-030-01219-9_37
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Liu SK, 2019, PROC CVPR IEEE, V0, PP1871, DOI 10.1109/CVPR.2019.00197
   Liu W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242912
   Liu YF, 2021, BASIC CLIN PHARMACOL, V128, P183
   Liu ZW, 2015, IEEE I CONF COMP VIS, V0, PP1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2019, PROC CVPR IEEE, V0, PP3618, DOI 10.1109/CVPR.2019.00374
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P7092, DOI 10.1109/TGRS.2017.2740362
   Matikainen L, 2011, REMOTE SENS-BASEL, V3, P1777, DOI 10.3390/rs3081777
   Mnih V., 2014, ARXIV, V0, P1406.6247
   Nassar AS, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9110687
   Pan XG, 2018, AAAI CONF ARTIF INTE, V0, P7276
   Pan XR, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113774
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruan T, 2019, AAAI CONF ARTIF INTE, V0, P4814
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Shi Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222719
   Song A, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9100601
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wen DW, 2017, IEEE J-STARS, V10, P1413, DOI 10.1109/JSTARS.2016.2645798
   Woo J., 2018, P EUR C COMP VIS ECC, V0, PP3, DOI 10.1007/978-3-030-01234-2_1
   Woo S, 2018, ADV NEUR IN, V31, P0
   Xu SB, 2018, IEEE T GEOSCI REMOTE, V56, P7369, DOI 10.1109/TGRS.2018.2850972
   Yang F, 2019, IEEE I CONF COMP VIS, V0, PP8310, DOI 10.1109/ICCV.2019.00840
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu CQ, 2018, PROC CVPR IEEE, V0, PP1857, DOI 10.1109/CVPR.2018.00199
   Zhang R, 2017, IEEE I CONF COMP VIS, V0, PP2050, DOI 10.1109/ICCV.2017.224
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zheng HL, 2019, PROC CVPR IEEE, V0, PP5007, DOI 10.1109/CVPR.2019.00515
   Zhou JC, 2019, IEEE PHOTONICS J, V11, P0, DOI 10.1109/JPHOT.2019.2950949
   Zhou K, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10010039
NR 46
TC 12
Z9 14
U1 2
U2 30
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD APR 15
PY 2021
VL 10
IS 4
BP 
EP 
DI 10.3390/ijgi10040241
PG 18
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RR4MU
UT WOS:000643075200001
DA 2023-04-26
ER

PT J
AU Gbodjo, YJE
   Montet, O
   Ienco, D
   Gaetano, R
   Dupuy, S
AF Gbodjo, Yawogan Jean Eudes
   Montet, Olivier
   Ienco, Dino
   Gaetano, Raffaele
   Dupuy, Stephane
TI Multisensor Land Cover Classification With Sparsely Annotated Data Based on Convolutional Neural Networks and Self-Distillation
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Optical sensors; Optical imaging; Remote sensing; Spatial resolution; Synthetic aperture radar; Convolutional neural networks; Optical computing; Convolutional neural networks (CNNs); land use and land cover (LULC) mapping; multisensor; multitemporal and multiscale remote sensing; self-distillation; sparsely annotated data
ID image time-series; fusion; system
AB Extensive research studies have been conducted in recent years to exploit the complementarity among multisensor (or multimodal) remote sensing data for prominent applications such as land cover mapping. In order to make a step further with respect to previous studies, which investigate multitemporal SAR and optical data or multitemporal/multiscale optical combinations, here, we propose a deep learning framework that simultaneously integrates all these input sources, specifically multitemporal SAR/optical data and fine-scale optical information at their native temporal and spatial resolutions. Our proposal relies on a patch-based multibranch convolutional neural network (CNN) that exploits different per-source encoders to deal with the specificity of the input signals. In addition, we introduce a new self-distillation strategy to boost the per-source analyses and exploit the interplay among the different input sources. This new strategy leverages the final prediction of the multisource framework to guide the learning of the per-source CNN encoders supporting the network to learn from itself. Experiments are carried out on two real-world benchmarks, namely, the Reunion island (a French overseas department) and the Dordogne study site (a southwest department in France), where the annotated reference data were collected under operational constraints (sparsely annotated ground-truth data). Obtained results providing an overall classification accuracy of about 94% (respectively, 88%) on the Reunion island (respectively, the Dordogne) study site highlight the effectiveness of our framework based on CNNs and self-distillation to combine heterogeneous multisensor remote sensing data and confirm the benefit of multimodal analysis for downstream tasks such as land cover mapping.
C1 [Gbodjo, Yawogan Jean Eudes; Montet, Olivier; Ienco, Dino] Univ Montpellier, Natl Res Inst Agr Food & Environm, TETIS Res Unit, F-34000 Montpellier, France.
   [Gaetano, Raffaele; Dupuy, Stephane] French Agr Res Ctr Int Dev, TETIS Res Unit, F-34000 Montpellier, France.
C3 INRAE; Universite de Montpellier; CIRAD
RP Ienco, D (corresponding author), Univ Montpellier, Natl Res Inst Agr Food & Environm, TETIS Res Unit, F-34000 Montpellier, France.
EM jean-eudes.gbodjo@inrae.fr; olivier.montet@inrae.fr; dinolenco@inrae.fr; raffaele.gaetano@cirad.fr; stephane.dupuy@cirad.fr
FU French National Research Agency under the Investments for the Future Program [ANR-16-CONV-0004, PNTS-2020-13]
CR Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Benedetti P, 2018, IEEE J-STARS, V11, P4939, DOI 10.1109/JSTARS.2018.2876357
   Berger M, 2012, REMOTE SENS ENVIRON, V120, P84, DOI 10.1016/j.rse.2011.07.023
   Cresson R, 2015, IEEE J-STARS, V8, P4151, DOI 10.1109/JSTARS.2015.2449233
   Dong YN, 2021, IEEE T CYBERNETICS, V51, P3185, DOI 10.1109/TCYB.2020.3004263
   Dupuy S, 2020, DATA BRIEF, V28, P0, DOI 10.1016/j.dib.2019.104934
   Gadiraju KK, 2020, KDD 20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP3234, DOI 10.1145/3394486.3403375
   Gaetano R, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111746
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Guo HN, 2021, IEEE T GEOSCI REMOTE, V59, P4287, DOI 10.1109/TGRS.2020.3014312
   He D, 2021, IEEE T GEOSCI REMOTE, V59, P9518, DOI 10.1109/TGRS.2020.3032475
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2020, IEEE GEOSCI REMOTE S, V17, P1470, DOI 10.1109/LGRS.2019.2944599
   Hu Y, 2019, NEURAL NETWORKS, V109, P31, DOI 10.1016/j.neunet.2018.10.009
   Ienco Dino, 2017, IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, V14, P1685, DOI 10.1109/LGRS.2017.2728698
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Inglada J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010095
   Interdonato R, 2019, ISPRS J PHOTOGRAMM, V149, P91, DOI 10.1016/j.isprsjprs.2019.01.011
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI 10.1109/TGRS.2020.3018879
   Liu SJ, 2020, ISPRS J PHOTOGRAMM, V164, P229, DOI 10.1016/j.isprsjprs.2020.04.008
   Liu X, 2018, IEEE T GEOSCI REMOTE, V56, P461, DOI 10.1109/TGRS.2017.2750220
   Lucas B, 2020, INT GEOSCI REMOTE SE, V0, PP1074, DOI 10.1109/IGARSS39084.2020.9324339
   Lucas B, 2021, MACH LEARN, V0, P0, DOI DOI 10.1007/s10994-020-05942-z
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050523
   Quegan S, 2001, IEEE T GEOSCI REMOTE, V39, P2373, DOI 10.1109/36.964973
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Schmitt M, 2016, IEEE GEOSC REM SEN M, V4, P6, DOI 10.1109/MGRS.2016.2561021
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Tang PF, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3095505
   Valero S, 2019, INT GEOSCI REMOTE SE, V0, PP6243, DOI 10.1109/IGARSS.2019.8898011
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang L., 2021, INT J PHYTOREMEDIAT, V0, P0, DOI DOI 10.1080/15226514.2021.2002808
   Wang PY, 2017, IEEE SIGNAL PROC LET, V24, P1763, DOI 10.1109/LSP.2017.2758203
   Yuan Y, 2021, IEEE J-STARS, V14, P474, DOI 10.1109/JSTARS.2020.3036602
   Zhang LF, 2019, IEEE I CONF COMP VIS, V0, PP3712, DOI 10.1109/ICCV.2019.00381
NR 40
TC 1
Z9 1
U1 2
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11485
EP 11499
DI 10.1109/JSTARS.2021.3119191
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XA2YM
UT WOS:000720519100015
DA 2023-04-26
ER

PT J
AU Oettli, P
   Nonaka, M
   Kuroki, M
   Koshiba, H
   Tokiya, Y
   Behera, SK
AF Oettli, Pascal
   Nonaka, Masami
   Kuroki, Masahiko
   Koshiba, Hiroyuki
   Tokiya, Yosuke
   Behera, Swadhin K.
TI Understanding global teleconnections to surface air temperatures in Japan based on a new climate classification
SO INTERNATIONAL JOURNAL OF CLIMATOLOGY
LA English
DT Article
DE climate classification; interannual variability; Japan; teleconnection
ID self-organizing maps; polar maritime airmass; cautionary note; northeasterly wind; western pacific; summer climate; intraseasonal amplification; interannual variability; koppen-geiger; cold spell
AB Utilizing the self-organizing map (SOM), a type of artificial neural network, a new classification of the climate of Japan is proposed. The SOM is applied on the monthly mean surface air temperature (SAT) anomalies, extracted from 762 stations. Considering the strong seasonal cycle in mid-latitudes, the classification is performed for two distinct seasons, boreal winter and boreal summer. Applied on monthly average temperature, to capture the seasonal signal, the SOM is an easily implementable interesting tool to (a) objectively capture the patterns present in the input data, and (b) identify the source of interannual variability, which is crucial for power demand forecasting. While modulated by local conditions, SAT in Japan is mainly influenced by large-scale circulation. It is found in this study that stronger relationships exist for tropics with southern regions and for extra-tropics with northern regions, in the seasonally oriented teleconnection patterns. In winter, the regions are organized along a north-south orientation, with a secondary west-east orientation in the central part of the country. This organization is a function of the strength of the link with the tropical Pacific and Indian Oceans sea-surface temperatures. Changes in the speed of the westerly jet, together with the modulation of the Western Pacific (WP)-like and Eurasian (EU)-like patterns, are also important for SAT in Japan in winter. In summer, the main organization follows a west-east orientation. The Pacific Japan (PJ)-like pattern plays an important role in the geographical distribution of the SAT, together with the existence of mid-latitude and subtropical wave trains, like the Silk Road (SR)-like pattern.
C1 [Oettli, Pascal; Nonaka, Masami; Behera, Swadhin K.] Japan Agcy Marine Earth Sci & Technol JAMSTEC, Res Inst Value Added Informat Generat Applicat La, Yokohama, Kanagawa, Japan.
   [Kuroki, Masahiko; Koshiba, Hiroyuki; Tokiya, Yosuke] JERA Japan Energy Era Co Inc, Tokyo, Japan.
C3 Japan Agency for Marine-Earth Science & Technology (JAMSTEC)
RP Oettli, P (corresponding author), 3173-25 Showa Machi,Kanazawa Ku, Yokohama, Kanagawa 2360001, Japan.
EM oettli@jamstec.go.jp
FU JERA Co., Inc.
CR Annas S., 2007, AGRICULTURAL INFORMATION RESEARCH, V16, P44, DOI 10.3173/air.16.44
   ANYADIKE RNC, 1987, J CLIMATOL, V7, P157, DOI 10.1002/joc.3370070206
   Astel A, 2007, WATER RES, V41, P4566, DOI 10.1016/j.watres.2007.06.030
   Ayoade J.O., 1976, ARCH METEOROLOGIE B, V24, P257, DOI 10.1007/BF02263458
   BARNSTON AG, 1987, MON WEATHER REV, V115, P1083, DOI 10.1175/1520-0493(1987)115<1083:CSAPOL>2.0.CO;2
   Behera SK, 2003, J CLIMATE, V16, P1087, DOI 10.1175/1520-0442(2003)016<1087:COACNO>2.0.CO;2
   Behera S, 2013, CLIM DYNAM, V41, P663, DOI 10.1007/s00382-012-1524-8
   Bjornsson H., 1997, MANUAL EOF SVD ANAL, V0, P52
   Branstator G, 2002, J CLIMATE, V15, P1893, DOI 10.1175/1520-0442(2002)015<1893:CTTJSW>2.0.CO;2
   Cannon AJ, 2012, HYDROL EARTH SYST SC, V16, P217, DOI 10.5194/hess-16-217-2012
   Chattopadhyay R, 2013, J CLIMATE, V26, P1716, DOI 10.1175/JCLI-D-12-00123.1
   DESER C, 1990, J CLIMATE, V3, P1254, DOI 10.1175/1520-0442(1990)003<1254:LSACFO>2.0.CO;2
   Ding QH, 2005, J CLIMATE, V18, P3483, DOI 10.1175/JCLI3473.1
   Dommenget D, 2003, J CLIMATE, V16, P1094, DOI 10.1175/1520-0442(2003)016<1094:R>2.0.CO;2
   Dommenget D, 2002, J CLIMATE, V15, P216, DOI 10.1175/1520-0442(2002)015<0216:ACNOTI>2.0.CO;2
   Enomoto T, 2003, Q J ROY METEOR SOC, V129, P157, DOI 10.1256/qj.01.211
   Enomoto T, 2004, J METEOROL SOC JPN, V82, P1019, DOI 10.2151/jmsj.2004.1019
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Fukui E, 1933, GEOGRAPHICAL REV JAP, V9, P195
   Fukui E., 1933, GEOGRAPHICAL REV JAP, V9, P271
   Fukui E, 1933, GEOGRAPHICAL REV JAP, V9, P109
   Fukui E., 1938, CLIMATOLOGY, V0, P0
   Fukui E., 1957, TOKYO KYOIKU DAIGAKU, V1, P103
   Fukui E, 1933, GEOGRAPHICAL REV JAP, V9, P1
   Geiger R., 1954, CLASSIFICATION CLIMA, V0, P603
   Hannachi A, 2006, INT J CLIMATOL, V26, P7, DOI 10.1002/joc.1243
   Hartigan J. A., 1979, APPLIED STATISTICS, V28, P100, DOI 10.2307/2346830
   Hewitson BC, 2002, CLIMATE RES, V22, P13, DOI 10.3354/cr022013
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hothorn T, 2006, AM STAT, V60, P257, DOI 10.1198/000313006X118430
   Hothorn T, 2008, J STAT SOFTW, V28, P1
   Isozaki M., 1933, CHIGAKU ZASSHI, V45, P234, DOI 10.5026/jgeography.45.234
   JMA, 2018, COMM MET OBS STAT, V0, P126
   Jolliffe IT, 2003, J CLIMATE, V16, P1084, DOI 10.1175/1520-0442(2003)016<1084:ACNOAE>2.0.CO;2
   Kanamitsu M, 2002, B AM METEOROL SOC, V83, P1631, DOI 10.1175/BAMS-83-11-1631(2002)083<1631:NAR>2.3.CO;2
   Kanno H, 1997, J METEOROL SOC JPN, V75, P1053, DOI 10.2151/jmsj1965.75.6_1053
   Klein SA, 1999, J CLIMATE, V12, P917, DOI 10.1175/1520-0442(1999)012<0917:RSSTVD>2.0.CO;2
   Kodama YM, 1997, J METEOROL SOC JPN, V75, P737, DOI 10.2151/jmsj1965.75.3_737
   Kodera K, 1998, J METEOROL SOC JPN, V76, P347, DOI 10.2151/jmsj1965.76.3_347
   Koppen W, 1918, PETERMANNS MITT, V64, P243
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kohonen T., 2001, SELF ORGANIZING MAPS, V0, P0
   Koizumi K., 2012, P I NATURAL SCI NIHO, V47, P185
   Kojima C., 1973, JOURNAL OF AGRICULTURAL METEOROLOGY, V0, P0
   Koppen W., 1900, J HERED, V6, P657
   Kosaka Y, 2013, P NATL ACAD SCI USA, V110, P7574, DOI 10.1073/pnas.1215582110
   Kottek M, 2006, METEOROL Z, V15, P259, DOI 10.1127/0941-2948/2006/0130
   Kubota H, 2016, INT J CLIMATOL, V36, P1575, DOI 10.1002/joc.4441
   Langfelder P, 2008, BMC BIOINFORMATICS, V9, P0, DOI 10.1186/1471-2105-9-559
   Langfelder P, 2012, J STAT SOFTW, V46, P1
   Leloup J, 2008, CLIM DYNAM, V30, P277, DOI 10.1007/s00382-007-0284-3
   Leloup JA, 2007, CLIM DYNAM, V28, P147, DOI 10.1007/s00382-006-0173-1
   Li C, 2012, J CLIMATE, V25, P1587, DOI 10.1175/JCLI-D-11-00145.1
   LIEBMANN B, 1982, J ATMOS SCI, V39, P1153
   Liu Y, 2006, J GEOPHYS RES-SPACE, V111, P0, DOI 10.1029/2006JA011890
   Liu YG, 2011, SELF ORGANIZING MAPS - APPLICATIONS AND NOVEL ALGORITHM DESIGN, V0, P253
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu RY, 2002, TELLUS A, V54, P44, DOI 10.1034/j.1600-0870.2002.00248.x
   MacQueen J.B., 1967, PROC 5 BERKELEY S MA, V0, P281
   McBoyle G.R., 1972, CLIMATOL B, V12, P1
   MCBOYLE GR, 1971, AUST GEOGR STUD, V9, P1, DOI 10.1111/j.1467-8470.1971.tb00239.x
   Mizukoshi M., 1977, THE CLIMATE OF JAPAN, V0, P225
   Morioka Y, 2010, CLIM DYNAM, V35, P1075, DOI 10.1007/s00382-010-0843-x
   Nakagawa G., 1899, CHIGAKU ZASSHI, V11, P347, DOI 10.5026/jgeography.11.347
   NINOMIYA K, 1985, J METEOROL SOC JPN, V63, P859, DOI 10.2151/jmsj1965.63.5_859
   NINOMIYA K, 1985, J METEOROL SOC JPN, V63, P845, DOI 10.2151/jmsj1965.63.5_845
   NITTA T, 1987, J METEOROL SOC JPN, V65, P373, DOI 10.2151/jmsj1965.65.3_373
   Oettli P, 2014, CLIM DYNAM, V43, P1557, DOI 10.1007/s00382-013-1985-4
   Ohba M, 2016, TELLUS A, V68, P0, DOI 10.3402/tellusa.v68.29293
   Oliver J.E., 2005, ENCY WORLD CLIMATOLO, V0, P218
   Oshika M, 2015, CLIM DYNAM, V45, P1355, DOI 10.1007/s00382-014-2384-1
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Preisendorfer R. W., 1988, DEV ATMOSPHERIC SCI, V0, P0
   Preston-Whyte R.A., 1974, S AFR GEOGR J, V56, P79, DOI 10.1080/03736245.1974.10559527
   Rayner NA, 2003, J GEOPHYS RES-ATMOS, V108, P0, DOI 10.1029/2002JD002670
   Reusch DB, 2005, POLAR GEOGR, V29, P188, DOI 10.1080/789610199
   Saji NH, 1999, NATURE, V401, P360, DOI 10.1038/43855
   Sekiguchi T., 1949, SHAKAI CHIRI, V15, P12
   Sekiguchi T., 1959, TOKYO KYOIKU DAIGAKU, V3, P65
   Shimada T, 2014, J METEOROL SOC JPN, V92, P17, DOI 10.2151/jmsj.2014-102
   Shiozaki M., 2017, DISASTER PREVENTION, V60, P486
   Steiner D., 1960, E AFR AGR FORESTRY J, V50, P329
   Strasser H, 1999, ASYMPTOTIC THEORY PE, V0, P0
   Suzuki H., 1962, GEOGRAPHICAL REV JAP, V35, P205, DOI 10.4157/grj.35.205
   Takaya K, 2005, J ATMOS SCI, V62, P4441, DOI 10.1175/JAS3628.1
   Takaya K, 2005, J ATMOS SCI, V62, P4423, DOI 10.1175/JAS3629.1
   Takaya K, 2013, J CLIMATE, V26, P9445, DOI 10.1175/JCLI-D-12-00842.1
   Tanaka M., 2015, ENSEMBLE PREDICTION, V0, P152
   Tanaka S, 2016, J CLIMATE, V29, P6597, DOI 10.1175/JCLI-D-15-0549.1
   Thornthwaite CW, 1943, GEOGR REV, V33, P233, DOI 10.2307/209776
   Thornthwaite CW, 1948, GEOGR REV, V38, P55, DOI 10.2307/210739
   Thornthwaite CW, 1931, GEOGR REV, V21, P633, DOI 10.2307/209372
   Torrence C, 1998, B AM METEOROL SOC, V79, P61, DOI 10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2
   Tozuka T, 2008, CLIM DYNAM, V31, P333, DOI 10.1007/s00382-007-0356-4
   Wakabayashi S, 2004, J METEOROL SOC JPN, V82, P1577, DOI 10.2151/jmsj.82.1577
   WALLACE JM, 1981, MON WEATHER REV, V109, P784, DOI 10.1175/1520-0493(1981)109<0784:TITGHF>2.0.CO;2
   Wehrens R, 2018, J STAT SOFTW, V87, P1, DOI 10.18637/iss.v087.i07
   Wehrens R, 2007, J STAT SOFTW, V21, P1
   Wickham H., 2016, GGPLOT2 ELEGANT GRAP, V0, P0, DOI DOI 10.1007/978-3-319-24277-4
   Wilks D. S., 2011, STAT METHODS ATMOSPH, V0, P0
   Willmott C.J., 1977, P 2 NAT SOL RAD DAT, V0, PD1
   Wolski P, 2018, CLIM DYNAM, V50, P479, DOI 10.1007/s00382-017-3621-1
   Yoshino M., 1980, ERDKUNDE, V34, P81, DOI 10.2307/25644163
   YULAEVA E, 1994, J CLIMATE, V7, P1719, DOI 10.1175/1520-0442(1994)007<1719:TSOEIG>2.0.CO;2
   Zscheischler J, 2012, PROCEDIA COMPUT SCI, V9, P897, DOI 10.1016/j.procs.2012.04.096
NR 107
TC 0
Z9 0
U1 2
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-8418
EI 1097-0088
J9 INT J CLIMATOL
JI Int. J. Climatol.
PD FEB 15
PY 2021
VL 41
IS 2
BP 1112
EP 1127
DI 10.1002/joc.6754
EA AUG 2020
PG 16
WC Meteorology & Atmospheric Sciences
SC Meteorology & Atmospheric Sciences
GA PZ0FF
UT WOS:000556815600001
DA 2023-04-26
ER

PT J
AU Lu, XC
   Yang, DZ
   Jia, FD
   Yang, YL
   Zhang, L
AF Lu, Xiaochen
   Yang, Dezheng
   Jia, Fengde
   Yang, Yunlong
   Zhang, Lei
TI Hyperspectral Image Classification Based on Multilevel Joint Feature Extraction Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Convolutional neural networks; Three-dimensional displays; Task analysis; Transforms; Training; Redundancy; Attention details; convolutional neural network (CNN); hyperspectral image (HSI); image classification; multilevel feature extraction (MFE)
ID representation
AB Over the past few years, convolutional neural network (CNN) has been broadly adopted in remote sensing (RS) imagery processing areas due to its impressive capabilities in feature extraction. Nevertheless, it is still a challenge for CNN-based hyperspectral image (HSI) classification methods to extract more effective spectral-spatial features considering all spectral bands. Driven by this issue, we propose a novel approach to cope with the HSI classification task, referring to the multilevel joint feature extraction network. The proposed network makes full use of the information on each channel of HSI and transforms it into valid channel-wised spatial features through a designed convolution process. Moreover, these feature maps form global attention details to guide the extraction of spectral-spatial features, which are taken to the next level for further feature mining. Then, the features obtained at different levels are integrated for ground object classification. In contrast with several state-of-the-art HSI classification methods on four public datasets, experimental results demonstrate the effectiveness and remarkable feature extraction capability of our proposed approach.
C1 [Lu, Xiaochen; Yang, Dezheng; Jia, Fengde; Yang, Yunlong; Zhang, Lei] Donghua Univ, Sch Informat Sci & Technol, Shanghai 201620, Peoples R China.
C3 Donghua University
RP Yang, DZ (corresponding author), Donghua Univ, Sch Informat Sci & Technol, Shanghai 201620, Peoples R China.
EM lxchen09@dhu.edu.cn; dezheng.yang@mail.dhu.edu.cn; fdjia@dhu.edu.cn; yangyl@dhu.edu.cn; lei.zhang@dhu.edu.cn
FU Fundamental Research Funds for the Central Universities [2232021D-33]; National Natural Science Foundation of China (NSFC) [61901104]; Science and Technology Research Project of Shanghai Songjiang District [20SJKJGG4]
CR Acosta ICC, 2020, IEEE J-STARS, V13, P4214, DOI 10.1109/JSTARS.2020.3011221
   Cao XH, 2019, IEEE J-STARS, V12, P4861, DOI 10.1109/JSTARS.2019.2938208
   Delalieux S, 2012, REMOTE SENS ENVIRON, V126, P222, DOI 10.1016/j.rse.2012.08.029
   Feng J, 2021, IEEE T GEOSCI REMOTE, V59, P5054, DOI 10.1109/TGRS.2020.3011943
   Feng J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071149
   Fernando T, 2021, IEEE SIGNAL PROC MAG, V38, P87, DOI 10.1109/MSP.2020.2988287
   Ghamisi P, 2018, IEEE GEOSC REM SEN M, V6, P10, DOI 10.1109/MGRS.2018.2854840
   Gu YF, 2016, IEEE T GEOSCI REMOTE, V54, P3235, DOI 10.1109/TGRS.2015.2514161
   Guo WH, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3051056
   Hang RL, 2019, IEEE T GEOSCI REMOTE, V57, P5384, DOI 10.1109/TGRS.2019.2899129
   He X, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3061088
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2020, IEEE T GEOSCI REMOTE, V58, P3791, DOI 10.1109/TGRS.2019.2957251
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Khodadadzadeh M, 2014, IEEE GEOSCI REMOTE S, V11, P2105, DOI 10.1109/LGRS.2014.2320258
   Li JJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030396
   Li L, 2021, IEEE GEOSCI REMOTE S, V18, P1816, DOI 10.1109/LGRS.2020.3007811
   Li X, 2020, IEEE T GEOSCI REMOTE, V58, P2615, DOI 10.1109/TGRS.2019.2952758
   Li ZK, 2020, IEEE J-STARS, V13, P1258, DOI 10.1109/JSTARS.2020.2982614
   Lu XC, 2021, IEEE T IMAGE PROCESS, V30, P6815, DOI 10.1109/TIP.2021.3098246
   Meng Z, 2021, IEEE J-STARS, V14, P2494, DOI 10.1109/JSTARS.2021.3053567
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P110, DOI 10.1109/TGRS.2019.2933609
   Rangnekar A, 2020, IEEE T GEOSCI REMOTE, V58, P8116, DOI 10.1109/TGRS.2020.2987199
   Rasti B, 2020, IEEE GEOSC REM SEN M, V8, P60, DOI 10.1109/MGRS.2020.2979764
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Sabat-Tomala A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030516
   Shabbir S., 1900, P2021, V0, P0
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Tan K, 2020, ISPRS J PHOTOGRAMM, V165, P1, DOI 10.1016/j.isprsjprs.2020.04.022
   Vohland M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182962
   Wang L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070884
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wu H, 2018, IEEE T IMAGE PROCESS, V27, P1259, DOI 10.1109/TIP.2017.2772836
   Xiao Z, 2020, IEEE INTERNET THINGS, V7, P2828, DOI 10.1109/JIOT.2019.2962863
   Xiao Z, 2020, IEEE INTERNET THINGS, V7, P2038, DOI 10.1109/JIOT.2019.2960631
   Xue ZH, 2021, IEEE T GEOSCI REMOTE, V59, P9600, DOI 10.1109/TGRS.2020.3048128
   Yu CY, 2019, IEEE J-STARS, V12, P1866, DOI 10.1109/JSTARS.2019.2911987
   Zheng JW, 2021, IEEE T GEOSCI REMOTE, V59, P522, DOI 10.1109/TGRS.2020.2995575
   Zhou PC, 2019, IEEE T GEOSCI REMOTE, V57, P4823, DOI 10.1109/TGRS.2019.2893180
   Zhu J, 2018, IEEE GEOSCI REMOTE S, V15, P1254, DOI 10.1109/LGRS.2018.2830403
   Zhu MH, 2021, IEEE T GEOSCI REMOTE, V59, P449, DOI 10.1109/TGRS.2020.2994057
NR 42
TC 3
Z9 3
U1 3
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10977
EP 10989
DI 10.1109/JSTARS.2021.3123371
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WU7CJ
UT WOS:000716698800008
DA 2023-04-26
ER

PT J
AU Sugg, JW
AF Sugg, Johnathan W.
TI Exploratory Geovisualization of the Character and Distribution of American Climate Change Beliefs
SO WEATHER CLIMATE AND SOCIETY
LA English
DT Article
DE Social Science; Climate change; Communications; decision making; Societal impacts; Clustering; Neural networks
ID self-organizing maps; audience segmentation; geographic-variation; public-opinion; perceptions; visualization; communication; proximity; usability; extremes
AB Americans remain polarized about climate change. However, recent scholarship reveals a plurality of climate change opinions among the public, with nontrivial support for a range of awareness, risk perceptions, and policy prescriptions. This study uses publicly available opinion estimates to examine the geographic variability of American climate change opinions and maps them as regions that share similarities or differences in the character of their beliefs. The exploratory geovisual environment of a self-organizing map is used to compare the support for 56 different climate opinions across all counties in the United States and arrange them into a spatially coherent grid of nodes. To facilitate the exploration of the patterns, a statistical cluster analysis groups together counties with the most similar climate beliefs. Choropleth maps visualize the clustering results from the self-organizing map. This study finds six groups of climate beliefs in which member counties exhibit a distinct regionality across the United States and share similarities in the magnitude of support for specific opinions. Groups that generally exhibit high or low levels of support for climate change awareness, risk perceptions, and policy prescriptions vary in their relative support for specific opinions. The results provide a nuanced understanding of different types of climate change opinions and where they exist geographically.
C1 [Sugg, Johnathan W.] Appalachian State Univ, Dept Geog & Planning, Boone, NC 28608 USA.
C3 University of North Carolina; Appalachian State University
RP Sugg, JW (corresponding author), Appalachian State Univ, Dept Geog & Planning, Boone, NC 28608 USA.
EM suggjw@appstate.edu
CR AGARWAL P, 2008, SELF ORG MAPS APPL G, V0, P0
   Andrienko G, 2010, COMPUT GRAPH FORUM, V29, P913, DOI 10.1111/j.1467-8659.2009.01664.x
   Barnes AP, 2012, CLIMATIC CHANGE, V112, P507, DOI 10.1007/s10584-011-0226-2
   Bashir MF, 2020, SCI TOTAL ENVIRON, V728, P0, DOI 10.1016/j.scitotenv.2020.138835
   Boykoff MT, 2013, AM BEHAV SCI, V57, P796, DOI 10.1177/0002764213476846
   Brugger A, 2015, NAT CLIM CHANGE, V5, P1031, DOI 10.1038/NCLIMATE2760
   Budayan C, 2009, EXPERT SYST APPL, V36, P11772, DOI 10.1016/j.eswa.2009.04.022
   Capstick S, 2015, WIRES CLIM CHANGE, V6, P35, DOI 10.1002/wcc.321
   Carmichael JT, 2017, CLIMATIC CHANGE, V141, P599, DOI 10.1007/s10584-017-1908-1
   Chryst B, 2018, ENVIRON COMMUN, V12, P1109, DOI 10.1080/17524032.2018.1508047
   Crampton JW, 2002, CARTOGR GEOGR INF SC, V29, P85, DOI 10. 1559/152304002782053314
   Delmelle E, 2013, URBAN STUD, V50, P923, DOI 10.1177/0042098012458003
   Detenber BH, 2016, INT J COMMUN-US, V10, P4736
   Dunlap RE, 2011, OXFORD HDB CLIMATE C, V0, PP144, DOI 10.1093/OXFORDHB/9780199566600.003.0010
   Dunlap RE, 2013, AM BEHAV SCI, V57, P691, DOI 10.1177/0002764213477097
   Feldman L, 2017, PUBLIC UNDERST SCI, V26, P481, DOI 10.1177/0963662515595348
   Feldman L, 2012, INT J PRESS/POLIT, V17, P3, DOI 10.1177/1940161211425410
   Fielding KS, 2016, FRONT PSYCHOL, V7, P0, DOI 10.3389/fpsyg.2016.00121
   Gao PC, 2019, J SPAT SCI, V64, P239, DOI 10.1080/14498596.2018.1440649
   Gibson PB, 2016, CLIM DYNAM, V47, P2235, DOI 10.1007/s00382-015-2961-y
   Goldberg M., 2020, 1 TIME ALARMED ARE N, V0, P0
   Hagenauer J, 2013, INT J GEOGR INF SCI, V27, P2026, DOI 10.1080/13658816.2013.788249
   Hamilton LC, 2016, SOCIOLOGY, V50, P913, DOI 10.1177/0038038516648547
   Hamilton LC, 2009, INT J CLIMATOL, V29, P2348, DOI 10.1002/joc.1930
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hart PS, 2012, COMMUN RES, V39, P701, DOI 10.1177/0093650211416646
   Hepburn C., 2020, SMITH SCH WORKING PA, V0, P0
   Hine DW, 2014, WIRES CLIM CHANGE, V5, P441, DOI 10.1002/wcc.279
   Howe PD, 2015, NAT CLIM CHANGE, V5, P596, DOI 10.1038/nclimate2583
   Howe PD, 2013, GLOBAL ENVIRON CHANG, V23, P1488, DOI 10.1016/j.gloenvcha.2013.09.014
   Hulme M, 2009, WHY WE DISAGREE ABOUT CLIMATE CHANGE: UNDERSTANDING CONTROVERSY, V0, P1
   Hulme M, 2020, WIRES CLIM CHANGE, V11, P0, DOI 10.1002/wcc.619
   Hulme M, 2019, ISSUES SCI TECHNOL, V36, P23
   Janetzko H., 2013, P 3 INT C ADV INF MI, V0, P12
   Jones MD, 2014, POLIT PSYCHOL, V35, P447, DOI 10.1111/pops.12057
   Joslyn S, 2019, WEATHER CLIM SOC, V11, P651, DOI 10.1175/WCAS-D-18-0126.1
   Kahan D, 2012, NATURE, V488, P255, DOI 10.1038/488255a
   Kahan DM, 2015, POLIT PSYCHOL, V36, P1, DOI 10.1111/pops.12244
   Kaufman L.R.P., 1990, FINDING GROUPS DATA, V0, P0, DOI DOI 10.1002/9780470316801.CH2
   Kohonen T., 2001, SELF ORG MAPS, V0, P0, DOI DOI 10.1007/978-3-642-56927-2
   Koua EL, 2006, INT J GEOGR INF SCI, V20, P425, DOI 10.1080/13658810600607550
   Koua E.L., 2003, P 21 INT CART REN IC, V0, P1694
   Koua EL, 2004, CARTOGR J, V41, P217, DOI 10.1179/000870404X13283
   Lee TM, 2015, NAT CLIM CHANGE, V5, P1014, DOI 10.1038/NCLIMATE2728
   Leiserowitz A., 2017, TRUMP VOTERS GLOBAL, V0, P0
   LEISEROWITZ A, 2010, RACE ETHNICITY PUBLI, V0, P0
   Leiserowitz AA, 2013, AM BEHAV SCI, V57, P818, DOI 10.1177/0002764212458272
   Lin CT, 1999, J MANAGE INFORM SYST, V16, P57, DOI 10.1080/07421222.1999.11518256
   Lyons BA, 2018, ENVIRON COMMUN, V12, P876, DOI 10.1080/17524032.2018.1520735
   Maibach EW, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0017571
   Marquart-Pyatt ST, 2014, GLOBAL ENVIRON CHANG, V29, P246, DOI 10.1016/j.gloenvcha.2014.10.004
   Marquart-Pyatt ST, 2011, ENVIRONMENT, V53, P38, DOI 10.1080/00139157.2011.588555
   McCright AM, 2016, TOP COGN SCI, V8, P76, DOI 10.1111/tops.12171
   McCright AM, 2011, GLOBAL ENVIRON CHANG, V21, P1163, DOI 10.1016/j.gloenvcha.2011.06.003
   Merkley E, 2018, SCI COMMUN, V40, P258, DOI 10.1177/1075547018760334
   Mildenberger M, 2017, CLIMATIC CHANGE, V145, P539, DOI 10.1007/s10584-017-2103-0
   Milfont TL, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0103180
   Murtagh F, 2014, J CLASSIF, V31, P274, DOI 10.1007/s00357-014-9161-z
   Neme A, 2011, J COMPUT SCI-NETH, V2, P345, DOI 10.1016/j.jocs.2011.08.003
   Nisbet MC, 2009, ENVIRONMENT, V51, P12, DOI 10.3200/ENVT.51.2.12-23
   Pearce W, 2017, ENVIRON COMMUN, V11, P723, DOI 10.1080/17524032.2017.1333965
   Pew, 2014, POLITICAL POLARIZATI, V0, P0
   R Core Team, 2020, R LANG ENV STAT COMP, V0, P0
   Ratcliffe M., 2016, DEFINING RURAL US CE, V0, P0
   Rentfrow PJ, 2008, PERSPECT PSYCHOL SCI, V3, P339, DOI 10.1111/j.1745-6924.2008.00084.x
   Retchless DP, 2018, ENVIRON BEHAV, V50, P483, DOI 10.1177/0013916517709043
   Reusch DB, 2005, POLAR GEOGR, V29, P188, DOI 10.1080/789610199
   Rolfe-Redding J.C., 2011, REPUBLICANS CLIMATE, V0, P0, DOI DOI 10.2139/ssrn.2026002
   Roser-renouf C., 2009, GLOBAL WARMINGS 6 AM, V0, P0
   Roth RE, 2010, CARTOGR J, V47, P130, DOI 10.1179/000870409X12488753453372
   Sahin M, 2020, SCI TOTAL ENVIRON, V728, P0, DOI 10.1016/j.scitotenv.2020.138810
   Sester M, 2005, INT J GEOGR INF SCI, V19, P871, DOI 10.1080/13658810500161179
   Sharma A., 2013, ARXIV13093946, V0, P0
   Smith TW, 2017, INT J SOCIOL, V47, P62, DOI 10.1080/00207659.2017.1264837
   Spence A, 2012, RISK ANAL, V32, P957, DOI 10.1111/j.1539-6924.2011.01695.x
   Stover D, 2017, B ATOM SCI, V73, P364, DOI 10.1080/00963402.2017.1388661
   Tosepu R, 2020, SCI TOTAL ENVIRON, V725, P0, DOI 10.1016/j.scitotenv.2020.138436
   Unsworth KL, 2014, GLOBAL ENVIRON CHANG, V27, P131, DOI 10.1016/j.gloenvcha.2014.05.002
   Van Boven L, 2018, PERSPECT PSYCHOL SCI, V13, P492, DOI 10.1177/1745691617748966
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   Vesanto J., 1999, INTELL DATA ANAL, V3, P111, DOI 10.1016/S1088-467X(99)00013-X
   Wehrens R, 2018, J STAT SOFTW, V87, P1, DOI 10.18637/iss.v087.i07
   Wehrens R, 2007, J STAT SOFTW, V21, P1
NR 83
TC 2
Z9 2
U1 0
U2 4
PU AMER METEOROLOGICAL SOC
PI BOSTON
PA 45 BEACON ST, BOSTON, MA 02108-3693, UNITED STATES
SN 1948-8327
EI 1948-8335
J9 WEATHER CLIM SOC
JI Weather Clim. Soc.
PD JAN 15
PY 2021
VL 13
IS 1
BP 67
EP 82
DI 10.1175/WCAS-D-20-0071.1
PG 16
WC Environmental Studies; Meteorology & Atmospheric Sciences
SC Environmental Sciences & Ecology; Meteorology & Atmospheric Sciences
GA SY3JS
UT WOS:000665787800006
DA 2023-04-26
ER

PT J
AU Zhu, LJ
   Webb, GI
   Yebra, M
   Scortechini, G
   Miller, L
   Petitjean, F
AF Zhu, Liujun
   Webb, Geoffrey, I
   Yebra, Marta
   Scortechini, Gianluca
   Miller, Lynn
   Petitjean, Francois
TI Live fuel moisture content estimation from MODIS: A deep learning approach
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Live fuel moisture content; MODIS; Convolutional neural network; Time series analysis; Fire risk; Fire danger
ID fire danger assessment; neural-networks; forest; model; retrieval; images
AB Live fuel moisture content (LFMC) is an essential variable to model fire danger and behaviour. This paper presents the first application of deep learning to LFMC estimation based on the historical LFMC ground samples of the Globe-LFMC database, as a step towards operational daily LFMC mapping in the Contiguous United States (CONUS). One-year MODerate resolution Imaging Spectroradiometer (MODIS) time series preceding each LFMC sample were extracted as the primary data source for training. The proposed temporal convolutional neural network for LFMC (TempCNN-LFMC) comprises three 1-D convolutional layers that learn the multi-scale temporal dynamics (features) of one-year MODIS time series specific to LFMC estimation. The learned features, together with a few auxiliary variables (e.g., digital elevation model), are then passed to three fully connected layers to extract the non-linear relationships with LFMC. In the primary training and validation scenario, the neural network was trained using samples from 2002 to 2013 and then adopted to estimating the LFMC from 2014 to 2018, achieving an overall root mean square error (RMSE) of 25.57% and a correlation coefficient (R) of 0.74. Good consistency on spatial patterns and temporal trends of accuracy was observed. The trained model achieved a similar RMSE of 25.98%, 25.20% and 25.93% for forest, shrubland, and grassland, respectively, without requiring prior information on the vegetation type.
C1 [Zhu, Liujun; Webb, Geoffrey, I; Miller, Lynn; Petitjean, Francois] Monash Univ, Dept Data Sci & Artificial Intelligence, Clayton, Vic 3800, Australia.
   [Zhu, Liujun] Hohai Univ, Yangtze Inst Conservat & Dev, Nanjing, Peoples R China.
   [Webb, Geoffrey, I] Monash Univ, Monash Data Futures Inst, Clayton, Vic 3800, Australia.
   [Yebra, Marta; Scortechini, Gianluca] Australian Natl Univ, Fenner Sch Environm & Soc, Acton, ACT, Australia.
   [Yebra, Marta] Australian Natl Univ, Sch Engn, Acton, ACT, Australia.
   [Yebra, Marta] Bushfire & Nat Hazards Cooperat Res Ctr, Melbourne, Vic, Australia.
C3 Monash University; Hohai University; Monash University; Australian National University; Australian National University
RP Zhu, LJ (corresponding author), Monash Univ, Dept Data Sci & Artificial Intelligence, Clayton, Vic 3800, Australia.; Zhu, LJ (corresponding author), Hohai Univ, Yangtze Inst Conservat & Dev, Nanjing, Peoples R China.
EM Liujun.zhu@hhu.edu.cn
FU Air Force Office of Scientific Research, Asian Office of Aerospace Research and Development (AOARD) [FA2386-18-1-4030]; Australian Research Council [DE170100037]; Australian Government Research Training Program (RTP) Scholarship
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Bottou Leon, 2012, NEURAL NETWORKS: TRICKS OF THE TRADE. SECOND EDITION: LNCS 7700, V0, PP421, DOI 10.1007/978-3-642-35289-8_25
   Caccamo G, 2012, INT J WILDLAND FIRE, V21, P257, DOI 10.1071/WF11024
   Chollett F, 2015, KERAS, V0, P0
   Chuvieco E, 2014, INT J WILDLAND FIRE, V23, P606, DOI 10.1071/WF12052
   DALY C, 1994, J APPL METEOROL, V33, P140, DOI 10.1175/1520-0450(1994)033&lt;0140:ASTMFM&gt;2.0.CO;2
   Danson FM, 2004, REMOTE SENS ENVIRON, V92, P309, DOI 10.1016/j.rse.2004.03.017
   Dasgupta S, 2007, REMOTE SENS ENVIRON, V108, P138, DOI 10.1016/j.rse.2006.06.023
   Davis RE, 1997, J GEOPHYS RES-ATMOS, V102, P29389, DOI 10.1029/97JD01335
   Dillon GK, 2011, ECOSPHERE, V2, P0, DOI 10.1890/ES11-00271.1
   Fan L, 2018, REMOTE SENS ENVIRON, V205, P210, DOI 10.1016/j.rse.2017.11.020
   Garcia M, 2008, REMOTE SENS ENVIRON, V112, P3618, DOI 10.1016/j.rse.2008.05.002
   Hall D. K., 2016, MODIS TERRA SNOW COV, V0, P0
   Hao XJ, 2007, REMOTE SENS ENVIRON, V108, P130, DOI 10.1016/j.rse.2006.09.033
   Jia SY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131575
   Jurdao S, 2013, REMOTE SENS ENVIRON, V132, P59, DOI 10.1016/j.rse.2013.01.004
   Jurdao S, 2012, FIRE ECOL, V8, P77, DOI 10.4996/fireecology.0801077
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Li FJ, 2018, J GEOPHYS RES-ATMOS, V123, P4545, DOI 10.1029/2017JD027823
   Li WJ, 2016, INT J REMOTE SENS, V37, P5632, DOI 10.1080/01431161.2016.1246775
   McCandless TC, 2020, MACH LEARN-SCI TECHN, V1, P0, DOI 10.1088/2632-2153/aba480
   Monsivais-Huertero A, 2018, IEEE T GEOSCI REMOTE, V56, P4989, DOI 10.1109/TGRS.2018.2803153
   Mouillot F, 2002, GLOBAL CHANGE BIOL, V8, P423, DOI 10.1046/j.1365-2486.2002.00494.x
   Nolan RH, 2016, GEOPHYS RES LETT, V43, P4229, DOI 10.1002/2016GL068614
   Arganaraz JP, 2016, IEEE J-STARS, V9, P5339, DOI 10.1109/JSTARS.2016.2575366
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050523
   Peterson SH, 2008, REMOTE SENS ENVIRON, V112, P4272, DOI 10.1016/j.rse.2008.07.012
   Pimont F, 2019, INT J WILDLAND FIRE, V28, P254, DOI 10.1071/WF18056
   Pimont F, 2019, INT J WILDLAND FIRE, V28, P127, DOI 10.1071/WF18091
   Qi Y, 2012, FIRE ECOL, V8, P71, DOI 10.4996/fireecology.0803071
   Quan XW, 2021, INT J APPL EARTH OBS, V101, P0, DOI 10.1016/j.jag.2021.102354
   Quan XW, 2016, IEEE J-STARS, V9, P910, DOI 10.1109/JSTARS.2015.2472415
   Rao K, 2020, REMOTE SENS ENVIRON, V245, P0, DOI 10.1016/j.rse.2020.111797
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Riggs GA., 2015, MODIS SNOW PRODUCTS, V0, P66
   Ruffault J, 2018, AGR FOREST METEOROL, V262, P391, DOI 10.1016/j.agrformet.2018.07.031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Safran I., 2017, P2979, V0, P0
   Schaaf C., 2015, NASA EOSDIS LAND PRO, V0, P0
   Schlerf M, 2006, REMOTE SENS ENVIRON, V100, P281, DOI 10.1016/j.rse.2005.10.006
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stow D, 2007, INT J REMOTE SENS, V28, P5175, DOI 10.1080/01431160701616129
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Trombetti M, 2008, REMOTE SENS ENVIRON, V112, P203, DOI 10.1016/j.rse.2007.04.013
   Ulaby F., 2014, MICROWAVE RADAR RADI, V0, P0, DOI DOI 10.3998/0472119356
   Viegas DX, 2001, INT J WILDLAND FIRE, V10, P223, DOI 10.1071/WF01022
   Wang L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131568
   Williams AP, 2016, CURR CLIM CHANGE REP, V2, P1, DOI 10.1007/s40641-016-0031-0
   Yebra M, 2008, AGR FOREST METEOROL, V148, P523, DOI 10.1016/j.agrformet.2007.12.005
   Yebra M, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0164-9
   Yebra M, 2018, REMOTE SENS ENVIRON, V212, P260, DOI 10.1016/j.rse.2018.04.053
   Yebra M, 2013, REMOTE SENS ENVIRON, V136, P455, DOI 10.1016/j.rse.2013.05.029
   Yebra M, 2009, REMOTE SENS ENVIRON, V113, P2403, DOI 10.1016/j.rse.2009.07.001
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zhu LJ, 2019, REMOTE SENS ENVIRON, V235, P0, DOI 10.1016/j.rse.2019.111433
   Zhu LJ, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111237
NR 56
TC 9
Z9 9
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD SEP 15
PY 2021
VL 179
IS 
BP 81
EP 91
DI 10.1016/j.isprsjprs.2021.07.010
EA AUG 2021
PG 11
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UC2UJ
UT WOS:000686386900006
DA 2023-04-26
ER

PT J
AU Fang, YY
   Yin, ZH
AF Fang, Yi-Yu
   Yin, Zi-Hao
TI A Text Correction and Recognition for Intelligent Railway Drawing Detection
SO PROCEEDINGS OF THE 2021 IEEE 16TH CONFERENCE ON INDUSTRIAL ELECTRONICS AND APPLICATIONS (ICIEA 2021)
LA English
DT Proceedings Paper
DE character correction; character recognition; railway drawing; deep learning
AB In current train control system, there are many drawings that need to be identified manually. This approach leads to many problems, such as misidentification and low efficiency. It is difficult to recognize these drawings automatically because the text on them often has a series of changes, like rotation, tilt, font changes and close to lines To solve this problem, we divide the task into two parts: text recognition and graphical symbol recognition. This article focuses on text recognition. We use aerial detection technology to classify and detect graphical symbol and text, followed by choosing BIL-STM to conducting sequence modeling and using convolutional recurrent neural network (CRNN) iterative training to focus on single word rotation, including tilting, noise-addition, and blurring post-processing. So that the training model can cope with complex scenario and improve the recognition rate of text on drawings. Finally, RESNET is applied to CRNN feature extraction network, and CRNN outputs the recognition and detection results in sequence according to the detection sequence, achieving entry-level detection, and the text recognition rate reaches 98.36%
C1 [Fang, Yi-Yu] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
   [Yin, Zi-Hao] Southwest Jiaotong Univ, Sch Elect Engn, Chengdu, Peoples R China.
C3 Southwest Jiaotong University; Southwest Jiaotong University
RP Fang, YY (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
EM fangyiyu@my.swjtu.edu.cn; zhy@my.swjtu.edu.cn
CR Baek Y, 2019, PROC CVPR IEEE, V0, PP9357, DOI 10.1109/CVPR.2019.00959
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liu ZC, 2019, IEEE ACCESS, V7, P68281, DOI 10.1109/ACCESS.2019.2916842
   Luo CJ, 2019, PATTERN RECOGN, V90, P109, DOI 10.1016/j.patcog.2019.01.020
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Shi BG, 2017, PROC CVPR IEEE, V0, PP3482, DOI 10.1109/CVPR.2017.371
   Xiang T., 2020, J SCI TECHNOLOGY NEI, V41, P39
   Zou Beiji, 2021, JOURNAL OF ZHEJIANG UNIVERSITY (SCIENCE EDITION), V48, P1, DOI 10.3785/j.issn.1008-9497.2021.01.001
NR 11
TC 0
Z9 0
U1 0
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2156-2318
EI 
J9 C IND ELECT APPL
PD JUN 15
PY 2021
VL 0
IS 
BP 1438
EP 1443
DI 10.1109/ICIEA51954.2021.9516318
PG 6
WC Engineering, Industrial; Engineering, Electrical & Electronic
SC Engineering
GA BS3DX
UT WOS:000709847700257
DA 2023-04-26
ER

PT J
AU Sun, L
   Lan, YF
AF Sun, Lei
   Lan, Yufeng
TI Statistical downscaling of daily temperature and precipitation over China using deep learning neural models: Localization and comparison with other methods
SO INTERNATIONAL JOURNAL OF CLIMATOLOGY
LA English
DT Article
DE China; convolutional neural network; intercomparison; statistical downscaling
ID scale climate data; regional climate; extreme precipitation; part i; cmip5; machine; cordex; configuration; projections; framework
AB Convolutional neural network (CNN) is an effective tool for extracting interpretable information from big data and has been recently used as a promising approach for statistical downscaling. In this study, CNN models of different configurations are used to downscale daily temperature and precipitation over China with the use of large-scale atmospheric variables from ECMWF Interim reanalysis (ERI) and high-resolution gridded observations as predictors and predictands respectively. A 21-year period from 1979 to 1999 is used for calibration and a relatively warmer period during 2000-2017 is used for validation, which helps to examine the extrapolation capability of models. It is shown that model performance varies among different configurations. For a realistic multi-site downscaling over whole China, the convolutional process is indispensable and much more spatial features are required to parameterize temperature characteristics than precipitation. As compared with ERI, CNN model shows added value in reproducing geographic distributions of seasonal mean climate and seasonal cycle as well as reducing biases in mean and extreme percentiles for both temperature and precipitation. However, ERI performs better in terms of temporal correlations. Then the model is further compared with Generalized Linear regression Model (GLM) and two quantile mapping based techniques including bias correction and spatial disaggregation (BCSD) and bias correction and climate imprint (BCCI). It is shown that bias correction methods show superior performances to other models in reducing biases and representing temporal correlations especially for precipitation. CNN model achieves better precipitation downscaling performances than GLM. It also achieves good skills in reproducing seasonal cycle of temperature and frequency distributions of daily precipitation, and presents better stabilities between the calibration and validation period. These results indicate that CNN model has good potential for downscaling application over large regions (e.g., continents).
C1 [Sun, Lei] Nanjing Univ Informat Sci & Technol, Sch Atmospher Sci, Climate Environm & Sustainabil Ctr, Nanjing, Peoples R China.
   [Lan, Yufeng] Guangxi Meteorol Training Ctr, Nanning, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Sun, L (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Atmospher Sci, Climate Environm & Sustainabil Ctr, Nanjing, Peoples R China.
EM sunlei@nuist.edu.cn
FU Nanjing University of Information Science and Technology; Meteorological Research Program of Guangxi [2019TG03]
CR Alizamir M, 2018, ENVIRON PROG SUSTAIN, V37, P1853, DOI 10.1002/ep.12856
   [Anonymous], 2014, CLIM CHANG 2013, V0, P0, DOI DOI 10.1017/CBO9781107415324
   Ardabili S, 2020, LECT NOTE NETW SYST, V101, P52, DOI 10.1007/978-3-030-36841-8_5
   Ayar PV, 2016, CLIM DYNAM, V46, P1301, DOI 10.1007/s00382-015-2647-5
   Bano-Medina J, 2020, GEOSCI MODEL DEV, V13, P2109, DOI 10.5194/gmd-13-2109-2020
   Bao JW, 2015, J GEOPHYS RES-ATMOS, V120, P8227, DOI 10.1002/2015JD023275
   Bedia J, 2020, GEOSCI MODEL DEV, V13, P1711, DOI 10.5194/gmd-13-1711-2020
   Burger G, 2012, J CLIMATE, V25, P4366, DOI 10.1175/JCLI-D-11-00408.1
   Burger G, 2009, WATER RESOUR RES, V45, P0, DOI 10.1029/2009WR007779
   Cannon AJ, 2008, J HYDROMETEOROL, V9, P1284, DOI 10.1175/2008JHM960.1
   Chen L, 2014, J GEOPHYS RES-ATMOS, V119, P5767, DOI 10.1002/2013JD021190
   Chen YY, 2011, J GEOPHYS RES-ATMOS, V116, P0, DOI 10.1029/2011JD015921
   Chu JT, 2010, THEOR APPL CLIMATOL, V99, P149, DOI 10.1007/s00704-009-0129-6
   Dee DP, 2011, Q J ROY METEOR SOC, V137, P553, DOI 10.1002/qj.828
   Eden JM, 2014, J CLIMATE, V27, P312, DOI 10.1175/JCLI-D-13-00063.1
   Eum HI, 2017, INT J CLIMATOL, V37, P3381, DOI 10.1002/joc.4924
   Giorgi F., 2009, BULLETIN - WORLD METEOROLOGICAL ORGANIZATION, V58, P175
   Giorgi F, 2015, ANNU REV ENV RESOUR, V40, P467, DOI 10.1146/annurev-environ-102014-021217
   Gutierrez JM, 2019, INT J CLIMATOL, V39, P3750, DOI 10.1002/joc.5462
   Gutmann E, 2014, WATER RESOUR RES, V50, P7167, DOI 10.1002/2014WR015559
   Ham YG, 2019, NATURE, V573, P568, DOI 10.1038/s41586-019-1559-7
   Hersbach H, 2020, Q J ROY METEOR SOC, V146, P1999, DOI 10.1002/qj.3803
   Hessami M, 2008, ENVIRON MODELL SOFTW, V23, P813, DOI 10.1016/j.envsoft.2007.10.004
   Huang J, 2011, STOCH ENV RES RISK A, V25, P781, DOI 10.1007/s00477-010-0441-9
   Huffman GJ, 2007, J HYDROMETEOROL, V8, P38, DOI 10.1175/JHM560.1
   Hunter RD, 2005, J APPL METEOROL, V44, P1501, DOI 10.1175/JAM2295.1
   Hutengs C, 2016, REMOTE SENS ENVIRON, V178, P127, DOI 10.1016/j.rse.2016.03.006
   Jacob D, 2014, REG ENVIRON CHANGE, V14, P563, DOI 10.1007/s10113-013-0499-2
   Jiang ZH, 2015, J CLIMATE, V28, P8603, DOI 10.1175/JCLI-D-15-0099.1
   Liang XZ, 2019, CLIM DYNAM, V52, P2159, DOI 10.1007/s00382-018-4257-5
   Liang XZ, 2012, B AM METEOROL SOC, V93, P1363, DOI 10.1175/BAMS-D-11-00180.1
   Liang XZ, 2004, J CLIMATE, V17, P3510, DOI 10.1175/1520-0442(2004)017&lt;3510:RCMSOU&gt;2.0.CO;2
   Liu SY, 2013, CLIM DYNAM, V41, P1871, DOI 10.1007/s00382-012-1632-5
   Liu YH, 2019, ATMOS RES, V224, P99, DOI 10.1016/j.atmosres.2019.03.022
   Liu ZF, 2011, INT J CLIMATOL, V31, P2006, DOI 10.1002/joc.2211
   Maraun D, 2010, REV GEOPHYS, V48, P0, DOI 10.1029/2009RG000314
   Maraun D, 2015, EARTHS FUTURE, V3, P1, DOI 10.1002/2014EF000259
   Maurer EP, 2008, HYDROL EARTH SYST SC, V12, P551
   Maurer EP, 2010, HYDROL EARTH SYST SC, V14, P1125, DOI 10.5194/hess-14-1125-2010
   Meehl GA, 2007, B AM METEOROL SOC, V88, P1383, DOI 10.1175/BAMS-88-9-1383
   Monjo R, 2016, INT J CLIMATOL, V36, P757, DOI 10.1002/joc.4380
   Murphy J, 1999, J CLIMATE, V12, P2256, DOI 10.1175/1520-0442(1999)012<2256:AEOSAD>2.0.CO;2
   Hoai ND, 2011, J APPL MATH, V0, P0, DOI DOI 10.1155/2011/246286
   NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614
   Pan BX, 2019, WATER RESOUR RES, V55, P2301, DOI 10.1029/2018WR024090
   RACSKO P, 1991, ECOL MODEL, V57, P27, DOI 10.1016/0304-3800(91)90053-4
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Sachindra DA, 2018, ATMOS RES, V212, P240, DOI 10.1016/j.atmosres.2018.05.022
   Sheffield J, 2006, J CLIMATE, V19, P3088, DOI 10.1175/JCLI3790.1
   Sillmann J, 2013, J GEOPHYS RES-ATMOS, V118, P1716, DOI 10.1002/jgrd.50203
   Spak S, 2007, J GEOPHYS RES-ATMOS, V112, P0, DOI 10.1029/2005JD006712
   Sun Y, 2014, NAT CLIM CHANGE, V4, P1082, DOI 10.1038/NCLIMATE2410
   Sunyer MA, 2015, HYDROL EARTH SYST SC, V19, P1827, DOI 10.5194/hess-19-1827-2015
   Tang JP, 2016, J GEOPHYS RES-ATMOS, V121, P2110, DOI 10.1002/2015JD023977
   Taylor KE, 2012, B AM METEOROL SOC, V93, P485, DOI 10.1175/BAMS-D-11-00094.1
   Tripathi S, 2006, J HYDROL, V330, P621, DOI 10.1016/j.jhydrol.2006.04.030
   Vandal T, 2019, THEOR APPL CLIMATOL, V137, P557, DOI 10.1007/s00704-018-2613-3
   Wang L, 2014, INT J CLIMATOL, V34, P2059, DOI 10.1002/joc.3822
   Wang WG, 2013, J GEOPHYS RES-ATMOS, V118, P4049, DOI 10.1002/jgrd.50393
   Wang Y, 2005, GEOPHYS RES LETT, V32, P0, DOI 10.1029/2005GL023344
   Wen X, 2016, THEOR APPL CLIMATOL, V126, P369, DOI 10.1007/s00704-015-1584-x
   Werner AT, 2016, HYDROL EARTH SYST SC, V20, P1483, DOI 10.5194/hess-20-1483-2016
   Wilby R. L., 2002, ENVIRONMENTAL MODELLING & SOFTWARE, V17, P147, DOI 10.1016/S1364-8152(01)00060-3
   Wilby RL, 1997, PROG PHYS GEOG, V21, P530, DOI 10.1177/030913339702100403
   Wilks D. S., 2011, STAT METHODS ATMOSPH, V0, P0
   Wood AW, 2004, CLIMATIC CHANGE, V62, P189, DOI 10.1023/B:CLIM.0000013685.99609.9e
   Wood AW, 2002, J GEOPHYS RES-ATMOS, V107, P0, DOI 10.1029/2001JD000659
   Xu Y, 2015, ATMOS OCEAN SCI LETT, V8, P185, DOI 10.3878/AOSL20150006
   Xue YK, 2014, ATMOS RES, V147, P68, DOI 10.1016/j.atmosres.2014.05.001
   Yang Y, 2019, CLIM DYNAM, V53, P4629, DOI 10.1007/s00382-019-04809-x
NR 71
TC 20
Z9 20
U1 18
U2 88
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-8418
EI 1097-0088
J9 INT J CLIMATOL
JI Int. J. Climatol.
PD FEB 15
PY 2021
VL 41
IS 2
BP 1128
EP 1147
DI 10.1002/joc.6769
EA AUG 2020
PG 20
WC Meteorology & Atmospheric Sciences
SC Meteorology & Atmospheric Sciences
GA PZ0FF
UT WOS:000561794600001
DA 2023-04-26
ER

PT J
AU Moris, P
   De Pauw, J
   Postovskaya, A
   Gielis, S
   De Neuter, N
   Bittremieux, W
   Ogunjimi, B
   Laukens, K
   Meysman, P
AF Moris, Pieter
   De Pauw, Joey
   Postovskaya, Anna
   Gielis, Sofie
   De Neuter, Nicolas
   Bittremieux, Wout
   Ogunjimi, Benson
   Laukens, Kris
   Meysman, Pieter
TI Current challenges for unseen-epitope TCR interaction prediction and a new perspective derived from image classification
SO BRIEFINGS IN BIOINFORMATICS
LA English
DT Article
DE T-cell epitope prediction; T-cell receptor; epitope specificity; immunoinformatics; convolutional neural network; deep learning
ID neural-networks; cell
AB The prediction of epitope recognition by T-cell receptors (TCRs) has seen many advancements in recent years, with several methods now available that can predict recognition for a specific set of epitopes. However, the generic case of evaluating all possible TCR-epitope pairs remains challenging, mainly due to the high diversity of the interacting sequences and the limited amount of currently available training data. In this work, we provide an overview of the current state of this unsolved problem. First, we examine appropriate validation strategies to accurately assess the generalization performance of generic TCR-epitope recognition models when applied to both seen and unseen epitopes. In addition, we present a novel feature representation approach, which we call ImRex (interaction map recognition). This approach is based on the pairwise combination of physicochemical properties of the individual amino acids in the CDR3 and epitope sequences, which provides a convolutional neural network with the combined representation of both sequences. Lastly, we highlight various challenges that are specific to TCR-epitope data and that can adversely affect model performance. These include the issue of selecting negative data, the imbalanced epitope distribution of curated TCR-epitope datasets and the potential exchangeability of TCR alpha and beta chains. Our results indicate that while extrapolation to unseen epitopes remains a difficult challenge, ImRex makes this feasible for a subset of epitopes that are not too dissimilar from the training data. We show that appropriate feature engineering methods and rigorous benchmark standards are required to create and validate TCR-epitope predictive models.
C1 [Meysman, Pieter] Univ Antwerp, Dept Comp Sci, Adrem Data Lab, B-2020 Antwerp, Belgium.
C3 University of Antwerp
RP Meysman, P (corresponding author), Univ Antwerp, Dept Comp Sci, Adrem Data Lab, B-2020 Antwerp, Belgium.
EM pieter.meysman@uantwerpen.be
FU Research Foundation Flanders (FWO) [1141217N, 1S48819N, 1861219N]; University of Antwerp; Flemish Government; Research Foundation - Flanders (FWO); Flemish Government - department EWI
CR AbadiM Agarwal A., 2015, TENSORFLOW LARGE SCA, V0, P0
   Akbar R., 2019, IMMUNOLOGY, V0, P0
   Bagaev DV, 2019, NUCLEIC ACIDS RES, V0, PPGKZ874, DOI 10.1093/nar/gkz874
   Bi JS, 2019, IEEE ACCESS, V7, P151273, DOI 10.1109/ACCESS.2019.2948178
   Chen MH, 2019, BIOINFORMATICS, V35, PI305, DOI 10.1093/bioinformatics/btz328
   Cock PJA, 2009, BIOINFORMATICS, V25, P1422, DOI 10.1093/bioinformatics/btp163
   Dash P, 2017, NATURE, V547, P89, DOI 10.1038/nature22383
   De Neuter N, 2018, IMMUNOGENETICS, V70, P159, DOI 10.1007/s00251-017-1023-5
   Dean J, 2015, GENOME MED, V7, P0, DOI 10.1186/s13073-015-0238-z
   Fischer DS, 2020, MOL SYST BIOL, V16, P0, DOI 10.15252/msb.20199416
   Gielis S, 2019, FRONT IMMUNOL, V10, P0, DOI 10.3389/fimmu.2019.02820
   Glanville J, 2017, NATURE, V547, P94, DOI 10.1038/nature22976
   Goloborodko AA, 2013, J AM SOC MASS SPECTR, V24, P301, DOI 10.1007/s13361-012-0516-6
   Han Y, 2017, BMC BIOINFORMATICS, V18, P0, DOI 10.1186/s12859-017-1997-x
   Hinton G., 2012, COURSERA NEURAL NETW, V4, P26
   Hu Y, 2019, BIOINFORMATICS, V35, P4946, DOI 10.1093/bioinformatics/btz427
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jokinen E, 2019, DETERMINING EPITOPE, V0, P0
   Jurtz V.I., 2018, NETTCR SEQUENCE BASE, V0, PP433706, DOI 10.1101/433706
   Jurtz V, 2017, J IMMUNOL, V199, P3360, DOI 10.4049/jimmunol.1700893
   Levitsky LI, 2019, J PROTEOME RES, V18, P709, DOI 10.1021/acs.jproteome.8b00717
   Liu ZH, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-018-37214-1
   Mahajan S, 2018, FRONT IMMUNOL, V9, P0, DOI 10.3389/fimmu.2018.02688
   Masters D., 2018, ARXIV180407612, V0, P0, DOI DOI 10.48550/ARXIV.1804.07612
   Meysman P, 2019, BIOINFORMATICS, V35, P1461, DOI 10.1093/bioinformatics/bty821
   Nielsen M, 2003, PROTEIN SCI, V12, P1007, DOI 10.1110/ps.0239403
   ODonnell TJ, 2018, CELL SYST, V7, P129, DOI 10.1016/j.cels.2018.05.014
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Petrova G, 2012, CRIT REV IMMUNOL, V32, P349
   Phloyphisut P, 2019, BMC BIOINFORMATICS, V20, P0, DOI 10.1186/s12859-019-2892-4
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI 10.1162/NECO_a_00990
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Sidhom JW, 2019, BIORXIV, V0, P0, DOI DOI 10.1101/464107
   Springer I, 2020, FRONT IMMUNOL, V11, P0, DOI 10.3389/fimmu.2020.01803
   Tickotsky N, 2017, BIOINFORMATICS, V33, P2924, DOI 10.1093/bioinformatics/btx286
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   van der Walt Stefan., 2010, P 9 PYTH SCI C, V0, P51
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Yao Y, 2019, PEERJ, V7, P0, DOI 10.7717/peerj.7126
   Zeng HY, 2019, BIOINFORMATICS, V35, PI278, DOI 10.1093/bioinformatics/btz330
   Zheng C, 1900, V2019A, V0, P0
NR 41
TC 18
Z9 18
U1 5
U2 15
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1467-5463
EI 1477-4054
J9 BRIEF BIOINFORM
JI Brief. Bioinform.
PD JUL 15
PY 2021
VL 22
IS 4
BP 
EP 
DI 10.1093/bib/bbaa318
PG 12
WC Biochemical Research Methods; Mathematical & Computational Biology
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA WK1AV
UT WOS:000709466800084
PM 33346826
DA 2023-04-26
ER

PT J
AU Davahli, MR
   Karwowski, W
   Fiok, K
AF Davahli, Mohammad Reza
   Karwowski, Waldemar
   Fiok, Krzysztof
TI Optimizing COVID-19 vaccine distribution across the United States using deterministic and stochastic recurrent neural networks
SO PLOS ONE
LA English
DT Article
ID interval
AB Optimizing COVID-19 vaccine distribution can help plan around the limited production and distribution of vaccination, particularly in early stages. One of the main criteria for equitable vaccine distribution is predicting the geographic distribution of active virus at the time of vaccination. This research developed sequence-learning models to predict the behavior of the COVID-19 pandemic across the US, based on previously reported information. For this objective, we used two time-series datasets of confirmed COVID-19 cases and COVID-19 effective reproduction numbers from January 22, 2020 to November 26, 2020 for all states in the US. The datasets have 310 time-steps (days) and 50 features (US states). To avoid training the models for all states, we categorized US states on the basis of their similarity to previously reported COVID-19 behavior. For this purpose, we used an unsupervised self-organizing map to categorize all states of the US into four groups on the basis of the similarity of their effective reproduction numbers. After selecting a leading state (the state with earliest outbreaks) in each group, we developed deterministic and stochastic Long Short Term Memory (LSTM) and Mixture Density Network (MDN) models. We trained the models with data from each leading state to make predictions, then compared the models with a baseline linear regression model. We also remove seasonality and trends from a dataset of non-stationary COVID-19 cases to determine the effects on prediction. We showed that the deterministic LSTM model trained on the COVID-19 effective reproduction numbers outperforms other prediction methods.
C1 [Davahli, Mohammad Reza; Karwowski, Waldemar; Fiok, Krzysztof] Univ Cent Florida, Dept Ind Engn & Management Syst, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Davahli, MR (corresponding author), Univ Cent Florida, Dept Ind Engn & Management Syst, Orlando, FL 32816 USA.
EM mohammadreza.davahli@ucf.edu
CR Abadi M, 2016, PROC 12 USENIX C OPE, V0, PP265, DOI 10.48550/ARXIV.1605.08695
   Abu-Raya B, 2020, CAN MED ASSOC J, V192, PE982, DOI 10.1503/cmaj.201237
   [Anonymous], 1997, NEURAL COMPUT, V0, P0
   [Anonymous], 2015, UNDERSTANDING LSTM N, V0, P0
   [Anonymous], 2018, ASCL 18061022, V0, P0
   Arora P, 2020, CHAOS SOLITON FRACT, V139, P0, DOI 10.1016/j.chaos.2020.110017
   Bishop C., 1994, MIXTURE DENSITY NETW, V0, P0
   Borchers DO, 2019, MEDIUM, V0, P0
   Centers for Disease Control Prevention (CDC) ., 2020, COVID 19 CAS DEATH T, V0, P0
   Chakraborty T, 2020, CHAOS SOLITON FRACT, V135, P0, DOI 10.1016/j.chaos.2020.109850
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, P0, DOI 10.1016/j.chaos.2020.109864
   CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188
   Cori A, 2013, AM J EPIDEMIOL, V178, P1505, DOI 10.1093/aje/kwt133
   Ribeiro MHD, 2020, CHAOS SOLITON FRACT, V135, P0, DOI 10.1016/j.chaos.2020.109853
   Davahli MR, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17207366
   Davahli MR, 2020, INPUT DATASETS DEV M, V0, P0
   Davis CN, 2020, PLOS COMPUT BIOL, V16, P0, DOI 10.1371/journal.pcbi.1006869
   de Myttenaere A, 2016, NEUROCOMPUTING, V192, P38, DOI 10.1016/j.neucom.2015.12.114
   Douzas G, 2017, EXPERT SYST APPL, V82, P40, DOI 10.1016/j.eswa.2017.03.073
   Fiok K, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10103386
   Flor M, 2021, CHORDDIAG INTERACTIV, V0, P0
   Gao J., 2020, ARXIV200209545, V0, P0
   Ghosal S, 2020, DIABETES METAB SYND, V14, P311, DOI 10.1016/j.dsx.2020.03.017
   Gostic KM, 2020, PLOS COMPUT BIOL, V16, P0, DOI 10.1371/journal.pcbi.1008409
   Hartono Pitoyo, 2020, INFORM MED UNLOCKED, V20, P100386, DOI 10.1016/j.imu.2020.100386
   Huang FM, 2017, ENG GEOL, V223, P11, DOI 10.1016/j.enggeo.2017.04.013
   Jeremie S, 2020, SWISS MED WKLY, V150, P0, DOI 10.4414/smw.2020.20271
   Kapoor A., 2020, EXAMINING COVID 19 F, V0, P0
   Kenah E, 2008, MATH BIOSCI, V213, P71, DOI 10.1016/j.mbs.2008.02.007
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kohonen T, 2013, NEURAL NETWORKS, V37, P52, DOI 10.1016/j.neunet.2012.09.018
   Lalmuanawma S, 2020, CHAOS SOLITON FRACT, V139, P0, DOI 10.1016/j.chaos.2020.110059
   Li Z, 2020, ARXIV200710929, V0, P0
   National Academy of Sciences, 2020, FRAM EQ ALL VACC NOV, V0, P0
   Nishiura H, 2020, INT J INFECT DIS, V93, P284, DOI 10.1016/j.ijid.2020.02.060
   Persad G, 2020, JAMA-J AM MED ASSOC, V324, P1601, DOI 10.1001/jama.2020.18513
   Qin L, 2019, NEUROCOMPUTING, V356, P244, DOI 10.1016/j.neucom.2019.04.061
   Schaffer DeRoo S, 2020, JAMA-J AM MED ASSOC, V323, P2458, DOI 10.1001/jama.2020.8711
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, P0, DOI 10.1016/j.chaos.2020.110212
   Tomar A, 2020, SCI TOTAL ENVIRON, V728, P0, DOI 10.1016/j.scitotenv.2020.138762
   Vettigli G, 2020, MINISOM MINIMALISTIC, V0, P0
   Xu J, 2018, IEEE T INTELL TRANSP, V19, P2572, DOI 10.1109/TITS.2017.2755684
   Yang Y, 2020, ANN TOURISM RES, V83, P0, DOI 10.1016/j.annals.2020.102913
NR 43
TC 7
Z9 7
U1 0
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
EI 
J9 PLOS ONE
JI PLoS One
PD JUL 6
PY 2021
VL 16
IS 7
BP 
EP 
DI 10.1371/journal.pone.0253925
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA TK6VN
UT WOS:000674293700003
PM 34228740
DA 2023-04-26
ER

PT J
AU Liu, SJ
   Zhou, ZZ
   Ding, HX
   Zhong, YJ
   Shi, Q
AF Liu, Shengjie
   Zhou, Zhize
   Ding, Huaxiang
   Zhong, Yuanjun
   Shi, Qian
TI Crop Mapping Using Sentinel Full-Year Dual-Polarized SAR Data and a CPU-Optimized Convolutional Neural Network With Two Sampling Strategies
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Agriculture; Synthetic aperture radar; Training; Remote sensing; Earth; Satellites; Clouds; Convolutional neural network (CNN); crop mapping; multitemporal; radar remote sensing; sampling strategy; synthetic aperture radar (SAR)
ID hyperspectral image classification; time-series; land-cover; growing-season; random forest; phenology; coherence; china
AB Although optical remote sensing can capture the Earth's environment with visible and infrared sensors, it is limited by weather conditions. Often, only a few sets of cloud-free optical imagery are available in cloudy regions, where many agricultural towns are located. On the other hand, radar remote sensing can capture imagery under cloudy conditions. In this study, we examined the capability of Sentinel-1 multitemporal dual-polarized synthetic aperture radar (SAR) imagery in a whole year from Google Earth Engine in crop mapping in two study sites in Chongqing, China, and Landivisiau, France. Results show that it is possible to produce better crop classification maps using multitemporal SAR imagery, but the performance is limited by local terrain. Flat agricultural regions, such as Western Europe, are expected to benefit from the multitemporal SAR information. Mountain agricultural regions, such as Southwestern China, will encounter difficulties due to the undulate terrain. We also tested two sampling strategies, i.e., random sampling and regional sampling, and observed high variation in overall accuracy: the former led to a higher accuracy. The gap is caused by the diversity of training sets examined using tSNE visualization. The importance of SAR channels in each month are correlated with their entropy. Data from the growing season are important in distinguishing crop types. The 3-D convolutional neural network (CNN) achieved similar results under a huge computation cost compared with 2-D CNNs. Based on the experiments, we recommend to use a lightweight 2-D CNN that can run on the CPU for real-world crop mapping with SAR data.
C1 [Liu, Shengjie] Univ Hong Kong, Dept Phys, Pokfulam, Hong Kong, Peoples R China.
   [Zhou, Zhize] Zhejiang Univ, State Key Lab Comp Aided Design & Comp Graph, Hangzhou 310058, Peoples R China.
   [Ding, Huaxiang; Zhong, Yuanjun] Inst Surveying & Mapping, Dept Nat Resources Guangdong Prov, Guangzhou 510500, Peoples R China.
   [Shi, Qian] Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
C3 University of Hong Kong; Zhejiang University; Sun Yat Sen University
RP Ding, HX; Zhong, YJ (corresponding author), Inst Surveying & Mapping, Dept Nat Resources Guangdong Prov, Guangzhou 510500, Peoples R China.
EM sjliu.me@gmail.com; zhouzhize@zju.edu.cn; wydinghx@163.com; gdzyj1222@163.com; shixi5@mail.sysu.edu.cn
FU National Natural Science Foundation of China [61976234]; Guangdong Basic and Applied Basic Research Foundation [2019A1515011057]
CR [Anonymous], 2016, GLOBAL HUNGER INDEX, V0, P0
   Arias M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020278
   Bargiel D, 2017, REMOTE SENS ENVIRON, V198, P369, DOI 10.1016/j.rse.2017.06.022
   Boureau Y.-L., 2010, P 27 INT C INT C MAC, V0, P111
   Busquier M, 2020, IEEE GEOSCI REMOTE S, V17, P819, DOI 10.1109/LGRS.2019.2933738
   Cao XH, 2019, APPL SOFT COMPUT, V83, P0, DOI 10.1016/j.asoc.2019.105630
   Chen SW, 2015, INT J REMOTE SENS, V36, P4233, DOI 10.1080/01431161.2015.1079345
   de Castro AI, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020285
   Du PJ, 2015, ISPRS J PHOTOGRAMM, V105, P38, DOI 10.1016/j.isprsjprs.2015.03.002
   Gao F, 2017, REMOTE SENS ENVIRON, V188, P9, DOI 10.1016/j.rse.2016.11.004
   Garonna I, 2014, GLOBAL CHANGE BIOL, V20, P3457, DOI 10.1111/gcb.12625
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Hansch R, 2017, INT GEOSCI REMOTE SE, V0, P3672
   He C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040655
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jacob AW, 2020, IEEE J-STARS, V13, P535, DOI 10.1109/JSTARS.2019.2958847
   Jiao XF, 2014, ISPRS J PHOTOGRAMM, V96, P38, DOI 10.1016/j.isprsjprs.2014.06.014
   Kandaswamy U, 2005, IEEE T GEOSCI REMOTE, V43, P2075, DOI 10.1109/TGRS.2005.852768
   Ke Guolin, 2017, ADV NEURAL INFORM PR, V0, PP3146, DOI 10.5555/3294996.3295074
   Kouw WM, 2021, IEEE T PATTERN ANAL, V43, P766, DOI 10.1109/TPAMI.2019.2945942
   Kussul N, 2015, INT ARCH PHOTOGRAMM, V47, P45, DOI 10.5194/isprsarchives-XL-7-W3-45-2015
   Lange J, 2018, INT GEOSCI REMOTE SE, V0, P2087
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   LeToan T, 1997, IEEE T GEOSCI REMOTE, V35, P41, DOI 10.1109/36.551933
   Li HP, 2020, INT J APPL EARTH OBS, V87, P0, DOI 10.1016/j.jag.2019.102032
   Liang J, 2017, IEEE T GEOSCI REMOTE, V55, P862, DOI 10.1109/TGRS.2016.2616489
   Liu SJ, 2020, IEEE GEOSCI REMOTE S, V17, P2110, DOI 10.1109/LGRS.2019.2962768
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI 10.1109/TGRS.2020.3018879
   Liu SJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060690
   Liu SJ, 2018, INT GEOSCI REMOTE SE, V0, P7145
   Liu X, 2019, IEEE T GEOSCI REMOTE, V57, P3040, DOI 10.1109/TGRS.2018.2879984
   Ma WP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111307
   Mestre-Quereda A, 2020, IEEE J-STARS, V13, P4070, DOI 10.1109/JSTARS.2020.3008096
   Molinier M, 2019, INT GEOSCI REMOTE SE, V0, PP5049, DOI 10.1109/IGARSS.2019.8900328
   Murray H, 2010, INT J APPL EARTH OBS, V12, P138, DOI 10.1016/j.jag.2010.01.006
   Pan ZK, 2015, INT J APPL EARTH OBS, V34, P188, DOI 10.1016/j.jag.2014.08.011
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pelletier C, 2016, REMOTE SENS ENVIRON, V187, P156, DOI 10.1016/j.rse.2016.10.010
   Qi ZX, 2012, REMOTE SENS ENVIRON, V118, P21, DOI 10.1016/j.rse.2011.11.001
   Ren B, 2018, INT J REMOTE SENS, V39, P7861, DOI 10.1080/01431161.2018.1479786
   Robinet C, 2007, GLOBAL ECOL BIOGEOGR, V16, P460, DOI 10.1111/j.1466-8238.2006.00302.x
   Russwurm M., 2019, ISPRS INT ARCH PHOTO, V43, P1545
   Shelestov A, 2017, FRONT EARTH SC-SWITZ, V5, P1, DOI 10.3389/feart.2017.00017
   Skakun S, 2017, AIMS GEOSCI, V3, P163, DOI 10.3934/geosci.2017.2.163
   Skriver H, 2012, IEEE T GEOSCI REMOTE, V50, P2138, DOI 10.1109/TGRS.2011.2172994
   Skriver H, 2011, IEEE J-STARS, V4, P423, DOI 10.1109/JSTARS.2011.2106198
   Song YL, 2010, INT J CLIMATOL, V30, P33, DOI 10.1002/joc.1868
   Sonobe R, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101148
   Tamiminia H, 2017, INT J APPL EARTH OBS, V58, P201, DOI 10.1016/j.jag.2017.02.010
   Tomppo E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212480
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang S, 2019, REMOTE SENS ENVIRON, V222, P303, DOI 10.1016/j.rse.2018.12.026
   Wang WJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071068
   Wardlow BD, 2008, REMOTE SENS ENVIRON, V112, P1096, DOI 10.1016/j.rse.2007.07.019
   Wen ZD, 2019, IEEE T GEOSCI REMOTE, V57, P8914, DOI 10.1109/TGRS.2019.2923738
   Xiao X., 2019, PROC IEEE 24 OPTOELE, V0, P1
   Yang YH, 2009, THEOR APPL CLIMATOL, V97, P91, DOI 10.1007/s00704-008-0049-x
   Yao RM, 2015, SUSTAIN CITIES SOC, V14, P187, DOI 10.1016/j.scs.2014.09.007
   Zeiler M.D., 2012, ARXIV12125701, V0, P0
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JH, 2008, J MT SCI-ENGL, V5, P241, DOI 10.1007/s11629-008-0189-6
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhong ZL, 2017, INT GEOSCI REMOTE SE, V0, P1824
NR 69
TC 2
Z9 2
U1 8
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7017
EP 7031
DI 10.1109/JSTARS.2021.3094973
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TQ5RV
UT WOS:000678338200009
DA 2023-04-26
ER

PT J
AU Underwood, KL
   Rizzo, DM
   Dewoolkar, MM
   Kline, M
AF Underwood, Kristen L.
   Rizzo, Donna M.
   Dewoolkar, Mandar M.
   Kline, Michael
TI Analysis of reach-scale sediment process domains in glacially-conditioned catchments using self-organizing maps
SO GEOMORPHOLOGY
LA English
DT Article
DE Process domain; channel classification; Sediment transport; Self-Organizing Map
ID artificial neural-networks; stream power; lake champlain; new-england; hierarchical framework; flood power; river; classification; gravel; morphology
AB Given the limited resources available for managing erosion hazards and addressing water quality impairment along rivers, stakeholders engaged in water resource management would benefit from tools to identify those river reaches most prone to adjustment and which disproportionately load sediment to receiving waters. The extent and rate of vertical and lateral channel adjustments in response to natural and human disturbances vary considerably across space and time; and this complexity and nonlinearity introduce challenges for classification or modeling of river reaches using conventional statistical techniques. The Self-Organizing Map (SOM) is a data driven computational tool with advantages for clustering or classifying multivariate observations and for exploratory data analysis and visualization of complex, nonlinear systems. We applied a SOM to cluster multivariate stream geomorphic assessment data into reach-scale sediment process domains for 193 river reaches in glacially-conditioned catchments of northeastern US using field-and GIS-derived hydraulic and geomorphic parameters. The reaches comprised a range of channel types from confined to unconfined, steep-to shallow gradient, mid-to-high order, and bedrock to alluvial channels. Fifteen variables were identified that meaningfully separated reaches into seven sediment regimes, following a two-stage application of the SOM. A coarse-tune SOM identified sediment regime classes at the supply-limited and transport-limited extremes of a continuum, including bedrock channels and confined, steep-gradient reaches as well as braided, depositional channels at alluvial fan or delta settings. A second-stage, fine-tune SOM nuanced differences in sediment production and transport for unconfined reaches with varying degrees of floodplain disconnection resulting from natural or human stressors. This classification framework is transferable to other hydroclimatic regions, with consideration of additional or alternate independent variables unique to those regions, and can provide valuable insights for river management to promote flood resiliency, restore water quality and improve instream and riparian habitats. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Underwood, Kristen L.; Rizzo, Donna M.; Dewoolkar, Mandar M.] Univ Vermont, Dept Civil & Environm Engn, Votey Bldg,33 Colchester Ave, Burlington, VT 05405 USA.
   [Kline, Michael] Vermont Agcy Nat Resources, Dept Environm Conservat, One Natl Life Dr, Montpelier, VT 05620 USA.
   [Kline, Michael] Fluvial Matters LLC, 401 S Bear Swamp Rd, Middlesex, VT 05602 USA.
C3 University of Vermont
RP Underwood, KL (corresponding author), Univ Vermont, Dept Civil & Environm Engn, Votey Bldg,33 Colchester Ave, Burlington, VT 05405 USA.
EM Kristen.Underwood@uvm.edu; Donna.Rizzo@uvm.edu; Mandar.Dewoolkar@uvm.edu
FU National Science Foundation under Vermont EPSCoR Grant [EPS-1101317]; NSF [OIA 1556770]; National Oceanic and Atmospheric Administration National Sea Grant College Program, U.S. Department of Commerce [NA180AR4170099]; FEMA Hazard Mitigation program; Lake Champlain Basin Program; Vermont Agency of Natural Resources
CR Alvarez-Guerra M, 2008, ENVIRON INT, V34, P782, DOI 10.1016/j.envint.2008.01.006
   Anderson I, 2017, J BRIDGE ENG, V22, P0, DOI 10.1061/(ASCE)BE.1943-5592.0001022
   Anderson MJ, 2001, AUSTRAL ECOL, V26, P32, DOI 10.1046/j.1442-9993.2001.01070.x
   ANDREWS ED, 1983, GEOL SOC AM BULL, V94, P1225, DOI 10.1130/0016-7606(1983)94<1225:EOGFNS>2.0.CO;2
   [Anonymous], 2018, NATL WATER INFORM SY, V0, P0
   [Anonymous], 2000, A57 HELS U TECHN, V0, P0
   [Anonymous], 2005, RIVER VARIABILITY CO, V0, P0
   [Anonymous], 2017, DATASETVT AGENCY NAT, V0, P0
   [Anonymous], 1997, GSA TODAY, V0, P0
   [Anonymous], 2011, J DATA SCI, V0, P0, DOI DOI 10.6339/JDS.201104_09(2).0009
   [Anonymous], 1900, DOI 10.1191/0309133303PP340RA, V0, P0
   Ballantyne CK, 2002, QUATERNARY SCI REV, V21, P1935, DOI 10.1016/S0277-3791(02)00005-7
   Benda L, 1997, WATER RESOUR RES, V33, P2849, DOI 10.1029/97WR02388
   Besaw LE, 2009, J HYDROL, V373, P34, DOI 10.1016/j.jhydrol.2009.04.007
   Bierman GM, 2010, ICFP 2010: PROCEEDINGS OF THE 2010 ACM SIGPLAN INTERNATIONAL CONFERENCE ON FUNCTIONAL PROGRAMMING, V0, P105
   Bizzi S, 2015, RIVER RES APPL, V31, P16, DOI 10.1002/rra.2717
   BOOTH DB, 1990, WATER RESOUR BULL, V26, P407
   BRAKENRIDGE GR, 1988, QUATERNARY RES, V30, P190, DOI 10.1016/0033-5894(88)90023-3
   Brardinoni F, 2006, J GEOPHYS RES-EARTH, V111, P0, DOI 10.1029/2005JF000358
   Brardinoni F, 2007, J GEOPHYS RES-EARTH, V112, P0, DOI 10.1029/2006JF000741
   Brierley GJ, 2005, GEOMORPHOLOGY AND RIVER MANAGEMENT: APPLICATIONS OF THE RIVER STYLES FRAMEWORK, V0, P1
   Brookes A., 1987, REGUL RIVERS RES MAN, V1, P3, DOI 10.1002/rrr.3450010103
   BULL WB, 1979, GEOL SOC AM BULL, V90, P453, DOI 10.1130/0016-7606(1979)90<453:TOCPIS>2.0.CO;2
   Buraas EM, 2014, EARTH SURF PROC LAND, V39, P1778, DOI 10.1002/esp.3562
   Cereghino R, 2009, ENVIRON MODELL SOFTW, V24, P945, DOI 10.1016/j.envsoft.2009.01.008
   Chappell J., 1983, AUSTR GEOGRAPHER, V15, P357, DOI 10.1080/00049188308702839
   CHURCH M, 1972, GEOL SOC AM BULL, V83, P3059, DOI 10.1130/0016-7606(1972)83[3059:PSACOF]2.0.CO;2
   Collins MJ, 2009, J AM WATER RESOUR AS, V45, P279, DOI 10.1111/j.1752-1688.2008.00277.x
   DeSimone D., 2000, VG002 VERM GEOL SURV, V0, P0
   Dethier E, 2016, EARTH SURF PROC LAND, V41, P1437, DOI 10.1002/esp.3958
   Downs PW, 2016, EARTH SURF PROC LAND, V41, P147, DOI 10.1002/esp.3785
   Dubois King Inc, 2017, FLOOD STUDY MAD RIVE, V0, P0
   DUNNE T, 1970, WATER RESOUR RES, V6, P1296, DOI 10.1029/WR006i005p01296
   Ferguson RI, 2005, GEOMORPHOLOGY, V70, P33, DOI 10.1016/j.geomorph.2005.03.009
   Flores A. N., 2006, WATER RESOURCES RESEARCH, V42, PW06412, DOI 10.1029/2005WR004226
   Foster D.R., 2004, FORESTS TIME ENV CON, V0, P0
   FRISSELL CA, 1986, ENVIRON MANAGE, V10, P199, DOI 10.1007/BF01867358
   Fryirs K, 2013, EARTH SURF PROC LAND, V38, P30, DOI 10.1002/esp.3242
   Fryirs KA, 2007, CATENA, V70, P49, DOI 10.1016/j.catena.2006.07.007
   Fytilis N, 2013, WATER RESOUR RES, V49, P7747, DOI 10.1002/2012WR013422
   Gartner JD, 2015, GEOLOGY, V43, P983, DOI 10.1130/G36969.1
   Guilbert J, 2015, GEOPHYS RES LETT, V42, P1888, DOI 10.1002/2015GL063124
   Guilbert J, 2014, J APPL METEOROL CLIM, V53, P1861, DOI 10.1175/JAMC-D-13-0338.1
   Harrelson C. C., 1994, RM245 USDA FOR SERV, V0, P0, DOI DOI 10.2737/RM-GTR-245
   Isles PDF, 2015, J GREAT LAKES RES, V41, P818, DOI 10.1016/j.jglr.2015.06.006
   Jaquith S., 2001, VERMONT REGIONAL HYD, V0, P0
   JAQUITH S, 2006, VERMONT REGIONAL HYD, V0, P0
   Kline M., 2009, VERMONT STREAM GEOMO, V0, P0
   Kline M., 2010, VERMONT ANR RIVER CO, Vsecond, P0
   Kline M, 2010, J AM WATER RESOUR AS, V46, P227, DOI 10.1111/j.1752-1688.2010.00417.x
   Knighton D., 1998, FLUVIAL FORMS PROCES, V0, P0
   Kohonen T, 2001, SELF ORGANIZING MAPS, V0, PP502, DOI 10.1007/978-3-642-56927-2
   Kohonen T, 2013, NEURAL NETWORKS, V37, P52, DOI 10.1016/j.neunet.2012.09.018
   Lea DM, 2016, GEOMORPHOLOGY, V252, P66, DOI 10.1016/j.geomorph.2015.05.033
   Lenzi MA, 2006, J HYDROL, V326, P257, DOI 10.1016/j.jhydrol.2005.10.031
   Leopold L.B, 1994, VIEW RIVER, V0, P320
   Lisenby PE, 2016, WATER RESOUR RES, V52, P3408, DOI 10.1002/2015WR017747
   Livers B, 2015, GEOMORPHOLOGY, V231, P72, DOI 10.1016/j.geomorph.2014.12.003
   MAGILLIGAN FJ, 1992, GEOMORPHOLOGY, V5, P373, DOI 10.1016/0169-555X(92)90014-F
   Magilligan FJ, 2008, ANN ASSOC AM GEOGR, V98, P267, DOI 10.1080/00045600801944160
   Mangiameli P, 1996, EUR J OPER RES, V93, P402, DOI 10.1016/0377-2217(96)00038-0
   McClain ME, 2003, ECOSYSTEMS, V6, P301, DOI 10.1007/s10021-003-0161-9
   Montgomery DR, 1997, GEOL SOC AM BULL, V109, P596, DOI 10.1130/0016-7606(1997)109<0596:CRMIMD>2.3.CO;2
   Montgomery DR, 1999, J AM WATER RESOUR AS, V35, P397, DOI 10.1111/j.1752-1688.1999.tb03598.x
   NANSON GC, 1992, GEOMORPHOLOGY, V4, P459, DOI 10.1016/0169-555X(92)90039-Q
   Noe GB, 2005, ECOL APPL, V15, P1178, DOI 10.1890/04-1677
   Oksanen J., 1975, STREAM REACH INVENTO, V0, P0
   Park YS, 2003, ECOL MODEL, V160, P265, DOI 10.1016/S0304-3800(02)00258-2
   Parker C, 2015, EARTH SURF PROC LAND, V40, P403, DOI 10.1002/esp.3641
   Parker C, 2011, GEOMORPHOLOGY, V126, P51, DOI 10.1016/j.geomorph.2010.10.027
   Pearce AR, 2013, ENVIRON SCI TECHNOL, V47, P14267, DOI 10.1021/es403490g
   Pearce AR, 2011, WATER RESOUR RES, V47, P0, DOI 10.1029/2010WR009992
   Phillips RTJ, 2014, GEOMORPHOLOGY, V206, P271, DOI 10.1016/j.geomorph.2013.09.030
   Phillips RTJ, 2015, EARTH SURF PROC LAND, V40, P756, DOI 10.1002/esp.3681
   PICKUP G, 1979, EARTH SURF PROC LAND, V4, P37, DOI 10.1002/esp.3290040104
   Poff NL, 1997, BIOSCIENCE, V47, P769, DOI 10.2307/1313099
   R Core Team, 2017, R LANG ENV STAT COMP, V0, P0
   Randall A.D., 1996, 96395 US GEOL SURV, V0, P0
   Ratcliffe N.M., 2011, BEDROCK GEOLOGIC MAP, V0, P3184
   Raven PJ., 1900, V2, V0, P1998
   Rice S, 1998, EARTH SURF PROC LAND, V23, P345, DOI 10.1002/(SICI)1096-9837(199804)23:4<345::AID-ESP850>3.0.CO;2-B
   Righini M, 2017, GEOMORPHOLOGY, V290, P184, DOI 10.1016/j.geomorph.2017.04.014
   Rinaldi M, 2013, GEOMORPHOLOGY, V180, P96, DOI 10.1016/j.geomorph.2012.09.009
   Rosgen D., 1996, APPL FLUVIAL MORPHOL, V0, P0
   Schumm S.A., 1984, INCISED CHANNELS MOR, V0, P0
   SCHUMM SA, 1995, GEOLOGY, V23, P391, DOI 10.1130/0091-7613(1995)023<0391:SYFDES>2.3.CO;2
   Shanley J.B., 1999, LAKE CHAMPLAIN TRANS, V0, PP41, DOI 10.1029/WS001P0041
   Somerville D.E., 2004, PHYS STREAM ASSESSME, V0, P0
   Stewart D. P., 1969, BULLETIN, V31, P0
   Stojkovic M, 2013, ECOL MODEL, V248, P20, DOI 10.1016/j.ecolmodel.2012.09.014
   Surian N, 2016, GEOMORPHOLOGY, V272, P78, DOI 10.1016/j.geomorph.2016.02.002
   Thompson C, 2013, GEOMORPHOLOGY, V197, P156, DOI 10.1016/j.geomorph.2013.05.006
   Thompson E. H., 2000, WETLAND WOODLAND WIL, V0, P0
   Thorp JH, 2013, ENVIRON MONIT ASSESS, V185, P7165, DOI 10.1007/s10661-013-3091-9
   Toone J, 2014, GEOMORPHOLOGY, V205, P5, DOI 10.1016/j.geomorph.2012.05.033
   U.S. Environmental Protection Agency, 2016, PHOSPH TMDLS VERM SE, V0, P0
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   WALLING DE, 1983, J HYDROL, V65, P209, DOI 10.1016/0022-1694(83)90217-2
   Walter RC, 2008, SCIENCE, V319, P299, DOI 10.1126/science.1151716
   Watson KB, 2016, ECOL ECON, V130, P16, DOI 10.1016/j.ecolecon.2016.05.015
   Weber MD, 2017, GEOMORPHOLOGY, V288, P39, DOI 10.1016/j.geomorph.2017.03.018
   Weekes AA, 2012, ENVIRON MANAGE, V50, P982, DOI 10.1007/s00267-012-9957-8
   Wehrens R, 2007, J STAT SOFTW, V21, P1
   Wohl E, 2018, PROG PHYS GEOG, V42, P841, DOI 10.1177/0309133318776488
   Wohl E, 2015, BIOSCIENCE, V65, P358, DOI 10.1093/biosci/biv002
   Wohl E, 2010, WATER RES M, V19, P1, DOI 10.1029/WM019
   WOLMAN MG, 1978, EARTH SURF PROC LAND, V3, P189, DOI 10.1002/esp.3290030207
   WOLMAN MG, 1960, J GEOL, V68, P54, DOI 10.1086/626637
   WOLMAN MG, 1954, T AM GEOPHYS UNION, V35, P951, DOI 10.1029/TR035I006P00951
   Yellen B, 2014, GEOMORPHOLOGY, V226, P124, DOI 10.1016/j.geomorph.2014.07.028
   Yochum SE, 2017, GEOMORPHOLOGY, V292, P178, DOI 10.1016/j.geomorph.2017.03.004
NR 111
TC 4
Z9 4
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-555X
EI 1872-695X
J9 GEOMORPHOLOGY
JI Geomorphology
PD JUN 1
PY 2021
VL 382
IS 
BP 
EP 
DI 10.1016/j.geomorph.2021.107684
EA MAR 2021
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary
SC Physical Geography; Geology
GA RN5ER
UT WOS:000640374900005
DA 2023-04-26
ER

PT J
AU Wang, SY
   Wang, YH
   Liu, HW
   Sun, YS
AF Wang, Siyuan
   Wang, Yinghua
   Liu, Hongwei
   Sun, Yuanshuang
TI Attribute-Guided Multi-Scale Prototypical Network for Few-Shot SAR Target Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Synthetic aperture radar; Radar polarimetry; Feature extraction; Training; Optical imaging; Azimuth; Optical sensors; Attribute classification; few-shot; synthetic aperture radar (SAR); target classification
ID convolutional neural-network
AB Few-shot synthetic aperture radar (SAR) target classification has received more and more attention in recent years, where most of the existing methods have applied off-the-shelf networks designed for natural images to SAR images, ignoring the special characteristics of SAR data. Therefore, in this article, we propose an attribute-guided multi-scale prototypical network (AG-MsPN) combined with subband decomposition for few-shot SAR target classification, aiming to learn more discriminative features from a few labeled data. Since the SAR images are essentially complex-valued images containing both amplitude and phase information, we implement the subband decomposition of complex-valued SAR images to explore the backscattering variations of targets, thus obtaining more complete descriptions of targets. Then, considering the complementary features extracted by different convolutional layers, based on the prototypical network, a multi-scale prototypical network (MsPN) is proposed to fuse the features of different layers to enhance the discrimination of feature representations, thus relieving the problem of high intra-class diversity and inter-class similarity for the images of SAR targets. Besides, we devise the prior binary attributes of SAR targets and add an extra attribute classification module (ACM) into the MsPN to map the images into the attribute space for classification. During the training phase, the proposed MsPN and the ACM are jointly utilized to realize the target classification in both the feature space and the attribute space, and meanwhile, the model parameters are optimized by the joint loss. Thus, the classification performance of the MsPN is further enhanced under the joint supervision of class label information from a few labeled data and the target attribute information from the prior knowledge. Therefore, we name the proposed method the AG-MsPN. We demonstrate the effectiveness of our proposed AG-MsPN on the Moving and Stationary Target Acquisition and Recognition benchmark dataset, and our method surpasses many other existing methods in the few-shot cases.
C1 [Wang, Siyuan; Wang, Yinghua; Liu, Hongwei; Sun, Yuanshuang] Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Peoples R China.
C3 Xidian University
RP Wang, YH (corresponding author), Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Peoples R China.
EM wangsiyuan@stu.xidian.edu.cn; yhwang@xidian.edu.cn; hwliu@xidian.edu.cn; sunsun5544@126.com
FU National Natural Science Foundation of China [61671354]; National Science Fund forDistinguishedYoung Scholars ofChina [61525105]; Shaanxi Innovation Team Project; 111 Project
CR Akata Z, 2013, PROC CVPR IEEE, V0, PP819, DOI 10.1109/CVPR.2013.111
   Amrani M., 2017, PROC PCM, V0, P68
   Amrani M, 2018, IEEE J-STARS, V11, P3794, DOI 10.1109/JSTARS.2018.2866684
   Amrani M, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042616
   [Anonymous], 2011, ACM T INTEL SYST TEC, V0, P0
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SZ, 2016, IEEE T GEOSCI REMOTE, V54, P4806, DOI 10.1109/TGRS.2016.2551720
   Chen Yinbo, 2020, ABS200304390 CORR, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Ding BY, 2017, IEEE GEOSCI REMOTE S, V14, P979, DOI 10.1109/LGRS.2017.2692386
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   [丁军 Ding Jun], 2014, 电子与信息学报 JOURNAL OF ELECTRONICS & INFORMATION TECHNOLOGY, V36, P2194
   Du YL, 2019, IEEE ACCESS, V7, P152023, DOI 10.1109/ACCESS.2019.2946852
   Ferro-Famil L, 2003, IEEE T GEOSCI REMOTE, V41, P2264, DOI 10.1109/TGRS.2003.817188
   Ferro-Famil L, 2002, INT GEOSCI REMOTE SE, V0, PP417, DOI 10.1109/IGARSS.2002.1025058
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Frome A, 2013, P ADV NEURAL INFORM, V26, P0
   Fu K, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3058249
   Gao F, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060846
   Garcia V., 2018, P ICLR, V0, P1
   Glorot X., 2011, P 14 INT C ART INT S, V0, P315
   Guberman N., 2016, ARXIV160209046, V0, P0
   Guo JY, 2017, IEEE GEOSCI REMOTE S, V14, P1111, DOI 10.1109/LGRS.2017.2699196
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang ZL, 2021, IEEE T GEOSCI REMOTE, V59, P3054, DOI 10.1109/TGRS.2020.3014335
   Huang ZL, 2020, ISPRS J PHOTOGRAMM, V161, P179, DOI 10.1016/j.isprsjprs.2020.01.016
   Huang ZL, 2020, IEEE T GEOSCI REMOTE, V58, P2324, DOI 10.1109/TGRS.2019.2947634
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090907
   Ioffe S, 2015, INT C MACH LEARN PML, V0, P0
   Kingma D. P., 2015, P 3 INT C LEARNING R, V0, P0
   Koch GR, 2015, SIAMESE NEURAL NETWO, V0, P0
   Lake B., 2011, P ANN M COGN SCI SOC, V33, P1
   Lampert CH, 2009, PROC CVPR IEEE, V0, PP951, DOI 10.1109/CVPRW.2009.5206594
   Larochelle H., 2017, P INT C LEARN REPR, V0, P1
   Li AX, 2019, IEEE I CONF COMP VIS, V0, PP9714, DOI 10.1109/ICCV.2019.00981
   Li AX, 2019, PROC CVPR IEEE, V0, PP7205, DOI 10.1109/CVPR.2019.00738
   Li Y, 2018, PROC CVPR IEEE, V0, PP7463, DOI 10.1109/CVPR.2018.00779
   Li YB, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3022435
   Li Z., 2017, P INT C MACH LEARN, V0, P0
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Lin Z, 2017, IEEE GEOSCI REMOTE S, V14, P1091, DOI 10.1109/LGRS.2017.2698213
   Lu D., 2019, 2019 12 INT C IMAGE, V0, P1
   Munkhdalai T, 2017, PR MACH LEARN RES, V70, P0
   Norouzi M., 2014, ICLR, V0, P0
   Pei JF, 2018, IEEE T GEOSCI REMOTE, V56, P2196, DOI 10.1109/TGRS.2017.2776357
   Quan D, 2019, IEEE I CONF COMP VIS, V0, PP3017, DOI 10.1109/ICCV.2019.00311
   Rostami M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111374
   Rusu A.A., 2019, 7 INT C LEARN REPR, V0, P0
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Simonyan K, 2015, ARXIV, V0, P0
   Singh J, 2012, IEEE GEOSCI REMOTE S, V9, P247, DOI 10.1109/LGRS.2011.2164051
   Snell J., 2017, P ADV NEUR INF PROC, V1703, P0
   Souyris JC, 2003, IEEE T GEOSCI REMOTE, V41, P2725, DOI 10.1109/TGRS.2003.817809
   Spigai M, 2011, IEEE T GEOSCI REMOTE, V49, P2699, DOI 10.1109/TGRS.2011.2107914
   Sun QR, 2019, PROC CVPR IEEE, V0, PP403, DOI 10.1109/CVPR.2019.00049
   Sun YS, 2020, IEEE GEOSCI REMOTE S, V17, P1928, DOI 10.1109/LGRS.2019.2958379
   Sung F, 2018, PROC CVPR IEEE, V0, PP1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tang JX, 2019, INT GEOSCI REMOTE SE, V0, PP1212, DOI 10.1109/IGARSS.2019.8898180
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O., 2016, ADV NEURAL INFORM PR, V29, P3630
   Wang CC, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3069224
   Wang K, 2021, IEEE GEOSCI REMOTE S, V18, P682, DOI 10.1109/LGRS.2020.2983988
   Wang L., 2019, P AS PAC C SYNTH AP, V0, P1
   Wang L., 2021, INT J PHYTOREMEDIAT, V0, P0, DOI DOI 10.1080/15226514.2021.2002808
   Wang ZL, 2019, J ENG-JOE, V2019, P7615, DOI 10.1049/joe.2019.0567
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu WJ, 2018, IEEE T GEOSCI REMOTE, V56, P6159, DOI 10.1109/TGRS.2018.2833156
   Yin XY, 2003, ANN BOT-LONDON, V91, P361, DOI 10.1093/aob/mcg029
   Yu LJ, 2020, IEEE GEOSCI REMOTE S, V17, P1752, DOI 10.1109/LGRS.2019.2953892
   Zhang M, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3031593
   Zhang W, 2019, IEEE ACCESS, V7, P152412, DOI 10.1109/ACCESS.2019.2948404
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
   Zhong CL, 2019, IEEE GEOSCI REMOTE S, V16, P412, DOI 10.1109/LGRS.2018.2876378
NR 75
TC 13
Z9 14
U1 4
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 12224
EP 12245
DI 10.1109/JSTARS.2021.3126688
PG 22
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XM6GZ
UT WOS:000728924400004
DA 2023-04-26
ER

PT J
AU Nankani, D
   Baruah, RD
AF Nankani, Deepankar
   Baruah, Rashmi Dutta
TI Ventricular Arrhythmia Classification and Interpretation Using Residual Neural Network with Guided Backpropagation
SO 2021 IEEE REGION 10 CONFERENCE (TENCON 2021)
LA English
DT Proceedings Paper
DE Ventricular Tachycardia; Ventricular Fibrillation; Residual Neural Network; Interpretability; Guided Back-propagation
ID fibrillation; tachycardia
AB Sudden cardiac death is the leading cause of natural death ocurring due to life-threatening lethal ventricular arrhythmias such as Ventricular Tachycardia (VT) and Ventricular Fibrillation (VF). This paper employs a supervised deep-learning interpretable framework for detecting VT and VF from Electrocardiogram (ECG) signals. The framework consists of two stages: (i) single-lead ECG classification using convolution-based Residual Neural Network (ResNet); and (ii) interpretation of classified segments using gradient-based Guided Backpropagation. The single-lead ECG is decluttered from noise, augmented, and classified using the ResNet classifier. The convolution layers in ResNet encode temporal variations present in ECG to provide better feature abstraction. The fully connected layer aggregates the encoding based on clinical relevance and performs classification. Lastly, the saliency maps of the penultimate convolution layer are visualized using guided backpropagation to highlight important signal timestamps responsible for classification. The proposed method is robust and outperforms state-of-the-art methods when verified on datasets acquired from five different geographic locations.
C1 [Nankani, Deepankar; Baruah, Rashmi Dutta] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati 781039, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Guwahati
RP Nankani, D (corresponding author), Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati 781039, Assam, India.
EM d.nankani@iitg.ac.in; r.duttabaruah@iitg.ac.in
CR Acharya UR, 2018, FUTURE GENER COMP SY, V79, P952, DOI 10.1016/j.future.2017.08.039
   Alonso-Atienza F, 2014, IEEE T BIO-MED ENG, V61, P832, DOI 10.1109/TBME.2013.2290800
   Amann A, 2007, IEEE T BIO-MED ENG, V54, P174, DOI 10.1109/TBME.2006.880909
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Goldberger AL, 2000, CIRCULATION, V101, PE215, DOI 10.1161/01.CIR.101.23.e215
   Greenwald S. D., 1986, THESIS, V0, P0
   He HB, 2008, IEEE IJCNN, V0, PP1322, DOI 10.1109/IJCNN.2008.4633969
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Heng W. W., 2019, 2019 COMPUTING CARDI, V0, P1
   Katritsis DG, 2016, ARRHYTH ELECTROPHYSI, V5, P177, DOI 10.15420/aer.2016:11:2
   Li Q, 2014, IEEE T BIO-MED ENG, V61, P1607, DOI 10.1109/TBME.2013.2275000
   Mandala S, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0231635
   Nguyen MT, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-33424-9
   Mohanty M, 2019, J MECH MED BIOL, V19, P0, DOI 10.1142/S0219519419500088
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Mousavi S., 2020, ARXIV PREPRINT ARXIV, V0, P0
   Nankani D., 2020, INT C MACHINE LEARNI, V0, P310
   Nankani D, 2020, COMPUT CARDIOL CONF, V0, P0, DOI DOI 10.22489/CinC.2020.424
   Nankani D, 2019, TENCON IEEE REGION, V0, PP690, DOI 10.1109/TENCON.2019.8929342
   Nguyen Hien M., 2011, INTERNATIONAL JOURNAL OF KNOWLEDGE ENGINEERING AND SOFT DATA PARADIGMS, V3, P4, DOI 10.1504/IJKESDP.2011.039875
   Nolle F.M., 1986, COMPUT CARDIOL, V13, P515
   Picon A, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0216756
   Samie FH, 2001, CARDIOVASC RES, V50, P242, DOI 10.1016/S0008-6363(00)00289-3
   Santos G. S. d., 2006, THESIS MIT, V0, P0
   Springenberg Jost, 2014, CORR, V0, P0
   Taye GT, 2019, FRONT PHYSIOL, V10, P0, DOI 10.3389/fphys.2019.01193
   Tripathy RK, 2016, J MED SYST, V40, P0, DOI 10.1007/s10916-016-0441-5
   Tripathy RK, 2018, FRONT PHYSIOL, V9, P0, DOI 10.3389/fphys.2018.00722
   Xu Y, 2018, BIOMED SIGNAL PROCES, V39, P219, DOI 10.1016/j.bspc.2017.07.031
   Yao QH, 2020, INFORM FUSION, V53, P174, DOI 10.1016/j.inffus.2019.06.024
   Zheng JW, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-0440-8
NR 31
TC 0
Z9 0
U1 1
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 574
EP 579
DI 10.1109/TENCON54134.2021.9707469
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Multidisciplinary; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA BT1OC
UT WOS:000799485900101
DA 2023-04-26
ER

PT J
AU Chi, J
   Kim, HC
AF Chi, Junhwa
   Kim, Hyun-Cheol
TI Retrieval of daily sea ice thickness from AMSR2 passive microwave data using ensemble convolutional neural networks
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE AMSR2; Arctic sea ice; convolutional neural network; deep learning; passive microwave; sea ice thickness
ID melt season; classification; cryosat-2; freeboard; drift; enhancement; algorithm; ocean
AB Recently, measurement of sea ice thickness (SIT) has received increasing attention due to the importance of thinning ice in the context of global warming. Although altimeter sensors onboard satellite missions enable continuous SIT measurements over larger areas compared to in situ observations, these sensors are inadequate for mapping daily Arctic SIT because of their small footprints. We exploited passive microwave data from AMSR2 (Advanced Microwave Scanning Radiometer 2) by incorporating a state-of-the-art deep learning (DL) approach to address this limitation. Passive microwave data offer better temporal resolutions than those from a single altimeter sensors, but are rarely used for SIT estimations due to their limited physical relationship with SIT. In this study, we proposed an ensemble DL model with different modalities to produce daily pan-Arctic SIT retrievals. The proposed model determined the hidden and unknown relationships between the brightness temperatures of AMSR2 channels and SITs measured by CryoSat-2 (CS2) from the extended input features defined by our feature augmentation strategy. Although AMSR2-based SITs agreed well with CS2-derived gridded SIT values, they had similar uncertainties and errors in the CS2 SIT measurements, particularly for thin ice. However, based on quantitative validations using long-term unseen data and IceBridge data, the proposed retrieval model consistently generated SITs from AMSR2 at 25 km spatial resolution, regardless of time and space.
C1 [Chi, Junhwa; Kim, Hyun-Cheol] Korea Polar Res Inst, Ctr Remote Sensing & GIS, Incheon, South Korea.
C3 Korea Polar Research Institute (KOPRI)
RP Kim, HC (corresponding author), Korea Polar Res Inst, Ctr Remote Sensing & GIS, Incheon, South Korea.
EM kimhc@kopri.re.kr
FU Korea Polar Research Institute [PE21040]
CR Aaboe S., 2016, EUMETSAT, V250, P1
   Agarap Abien Fred, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Alexandrov V, 2010, CRYOSPHERE, V4, P373, DOI 10.5194/tc-4-373-2010
   Bellman R.E., 2015, ADAPTIVE CONTROL PRO, V0, P0
   Brochu E., 2010, ARXIV PREPRINT ARXIV, V0, P0
   Cavalieri DJ, 1999, J GEOPHYS RES-OCEANS, V104, P15803, DOI 10.1029/1999JC900081
   CAVALIERI DJ, 1984, J GEOPHYS RES-ATMOS, V89, P5355, DOI 10.1029/JD089iD04p05355
   Chi J, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.023
   Chi J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121305
   COMISO JC, 1986, J GEOPHYS RES-OCEANS, V91, P975, DOI 10.1029/JC091iC01p00975
   Comiso JC, 2008, GEOPHYS RES LETT, V35, P0, DOI 10.1029/2007GL031972
   Durner GM, 2017, GLOBAL CHANGE BIOL, V23, P3460, DOI 10.1111/gcb.13746
   Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   GLOERSEN P, 1986, J GEOPHYS RES-OCEANS, V91, P3913, DOI 10.1029/JC091iC03p03913
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Han H, 2020, GISCI REMOTE SENS, V57, P650, DOI 10.1080/15481603.2020.1767857
   Helm, 2016, AWI CRYOSAT 2 SEA IC, V0, P0
   Huang SZ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19092018
   Ince T, 2016, IEEE T IND ELECTRON, V63, P7067, DOI 10.1109/TIE.2016.2582729
   Ivanova N, 2015, CRYOSPHERE, V9, P1797, DOI 10.5194/tc-9-1797-2015
   Iwamoto K, 2014, J GEOPHYS RES-OCEANS, V119, P3574, DOI 10.1002/2013JC009749
   Kaleschke L, 2012, GEOPHYS RES LETT, V39, P0, DOI 10.1029/2012GL050916
   Kaleschke L, 2015, INT GEOSCI REMOTE SE, V0, PP5232, DOI 10.1109/IGARSS.2015.7327014
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Koenig L, 2010, EOS T AM GEOPHYS UN, V91, P333, DOI 10.1029/2010E0380002
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kurtz NT, 2014, CRYOSPHERE, V8, P1217, DOI 10.5194/tc-8-1217-2014
   Kurtz NT, 2013, CRYOSPHERE, V7, P1035, DOI 10.5194/tc-7-1035-2013
   Kurtz NT, 2011, GEOPHYS RES LETT, V38, P0, DOI 10.1029/2011GL049216
   Kwok R, 2019, J GEOPHYS RES-OCEANS, V124, P6942, DOI 10.1029/2019JC015486
   Kwok R, 2011, J GEOPHYS RES-OCEANS, V116, P0, DOI 10.1029/2011JC007371
   Laxon SW, 2013, GEOPHYS RES LETT, V40, P732, DOI 10.1002/grl.50193
   Lee SM, 2018, J GEOPHYS RES-ATMOS, V123, P9220, DOI 10.1029/2018JD028688
   Lee S, 2020, IEEE T BIO-MED ENG, V67, P2669, DOI 10.1109/TBME.2020.2967802
   Li T, 2014, IEEE IMAGE PROC, V0, PP5132, DOI 10.1109/ICIP.2014.7026039
   Liu YH, 2020, CRYOSPHERE, V14, P1325, DOI 10.5194/tc-14-1325-2020
   Lund B, 2018, J GEOPHYS RES-OCEANS, V123, P4298, DOI 10.1029/2018JC013769
   Maggiori E, 2016, INT GEOSCI REMOTE SE, V0, PP5071, DOI 10.1109/IGARSS.2016.7730322
   Markus T, 2000, IEEE T GEOSCI REMOTE, V38, P1387, DOI 10.1109/36.843033
   MARKUS T, 1998, ANTAR RES S, V74, P19
   Markus T, 2009, J GEOPHYS RES-OCEANS, V114, P0, DOI 10.1029/2009JC005436
   Martin S, 2004, J GEOPHYS RES-OCEANS, V109, P0, DOI 10.1029/2004JC002428
   Nakayama Y, 2012, J PHYS OCEANOGR, V42, P179, DOI 10.1175/JPO-D-11-018.1
   Naoki K, 2008, J GEOPHYS RES-OCEANS, V113, P0, DOI 10.1029/2007JC004270
   Okuyama A, 2015, IEEE T GEOSCI REMOTE, V53, P4568, DOI 10.1109/TGRS.2015.2402204
   Peng DD, 2019, IEEE ACCESS, V7, P10278, DOI 10.1109/ACCESS.2018.2888842
   Peng G, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091328
   Proshutinsky A, 2002, GEOPHYS RES LETT, V29, P0, DOI 10.1029/2002GL015847
   Qu YR, 2019, ACM T INFORM SYST, V37, P0, DOI 10.1145/3233770
   Ricker R, 2017, CRYOSPHERE, V11, P1607, DOI 10.5194/tc-11-1607-2017
   Sak H, 2014, INTERSPEECH, V0, P338
   Smith DM, 1998, GEOPHYS RES LETT, V25, P655, DOI 10.1029/98GL00251
   Spreen G, 2008, J GEOPHYS RES-OCEANS, V113, P0, DOI 10.1029/2005JC003384
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stroeve JC, 2014, GEOPHYS RES LETT, V41, P1216, DOI 10.1002/2013GL058951
   Stroeve JC, 2012, CLIMATIC CHANGE, V110, P1005, DOI 10.1007/s10584-011-0101-1
   Tamura T, 2011, J GEOPHYS RES-OCEANS, V116, P0, DOI 10.1029/2010JC006586
   Tilling RL, 2018, ADV SPACE RES, V62, P1203, DOI 10.1016/j.asr.2017.10.051
   VANT MR, 1978, J APPL PHYS, V49, P1264, DOI 10.1063/1.325018
   Vinnikov KY, 1999, SCIENCE, V286, P1934, DOI 10.1126/science.286.5446.1934
   Wang L, 2016, IEEE T GEOSCI REMOTE, V54, P4524, DOI 10.1109/TGRS.2016.2543660
   Xiao F, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20247011
   Yoshizawa E, 2018, J ATMOS OCEAN TECH, V35, P2147, DOI 10.1175/JTECH-D-18-0034.1
   Yu XR, 2017, GISCI REMOTE SENS, V54, P741, DOI 10.1080/15481603.2017.1323377
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 66
TC 3
Z9 3
U1 3
U2 13
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD AUG 18
PY 2021
VL 58
IS 6
BP 812
EP 830
DI 10.1080/15481603.2021.1943213
EA JUL 2021
PG 19
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA UR5NM
UT WOS:000673377900001
DA 2023-04-26
ER

PT J
AU Ghorbanzadeh, O
   Meena, SR
   Abadi, HSS
   Piralilou, ST
   Lv, ZY
   Blaschke, T
AF Ghorbanzadeh, Omid
   Meena, Sansar Raj
   Shahabi Sorman Abadi, Hejar
   Tavakkoli Piralilou, Sepideh
   Zhiyong Lv
   Blaschke, Thomas
TI Landslide Mapping Using Two Main Deep-Learning Convolution Neural Network Streams Combined by the Dempster-Shafer Model
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Terrain factors; Rivers; Surface topography; Remote sensing; Earth; Data models; Artificial neural networks; Earthquake-induced landslide (EQIL); hydropower; landslide-induced lakes; topographical factors; Trishuli river
ID machine
AB Beyond the direct hazards of earthquakes, the deposited mass of earthquake-induced landslide (EQIL) in the riverbeds causes the river to thrust upward. The EQIL inventories are generated mostly by the traditional or semisupervised mapping approaches, which required a parameter's tuning or binary threshold decision in the practical application. In this study, we investigated the impact of optical data from the PlanetScope sensor and topographic factors from the ALOS sensor on EQIL mapping using a deep-learning convolution neural network (CNN). Thus, six training datasets were prepared and used to evaluate the performance of the CNN model using only optical data and using these data along with each and all topographic factors across the west coast of the Trishuli river in Nepal. For the first time, the Dempster-Shafer (D-S) model was applied for combining the resulting maps from each CNN stream that trained with different datasets. Finally, seven different resulting maps were compared against a detailed and accurate inventory of landslide polygons by a mean intersection-over-union (mIOU). Our results confirm that using the training dataset of the spectral information along with the topographic factor of the slope is helpful to distinguish the landslide bodies from other similar features, such as barren lands, and consequently increases the mapping accuracy. The improvement of the mIOU was a range from approximately zero to more than 17%. Moreover, the D-S model can be considered as an optimizer method to combine the results from different scenarios.
C1 [Ghorbanzadeh, Omid; Tavakkoli Piralilou, Sepideh; Blaschke, Thomas] Univ Salzburg, Z GIS Ctr Geoinformat, A-5020 Salzburg, Austria.
   [Meena, Sansar Raj] Univ Salzburg, Dept Geoinformat, A-5050 Salzburg, Austria.
   [Shahabi Sorman Abadi, Hejar] Univ Tabriz, Remote Sensing & GIS, Tabriz 5166616471, Iran.
   [Zhiyong Lv] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
C3 Salzburg University; Salzburg University; University of Tabriz; Xi'an University of Technology
RP Ghorbanzadeh, O (corresponding author), Univ Salzburg, Z GIS Ctr Geoinformat, A-5020 Salzburg, Austria.
EM omid.ghorbanzadeh@stud.sbg.ac.at; sansarraj.meena@sbg.ac.at; hejarshahabi@gmail.com; sepideh.tavakkoli-piralilou@stud.sbg.ac.at; lvzhiyong_fly@hotmail.com; thomas.blaschke@sbg.ac.at
FU Austrian Science Fund (FWF) through the Doctoral College GIScience at the University of Salzburg [DKW1237-N23]
CR Al-Najjar HAH, 2019, PROC SPIE, V11156, P0, DOI 10.1117/12.2532687
   Althuwaynee OF, 2012, COMPUT GEOSCI-UK, V44, P120, DOI 10.1016/j.cageo.2012.03.003
   [Anonymous], 2018, PLAN APPL PROGR INT, V0, P0
   Baraldi P, 2010, RISK ANAL, V30, P1139, DOI 10.1111/j.1539-6924.2010.01416.x
   Chen W, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8122540
   Danneels G, 2007, INT GEOSCI REMOTE SE, V0, PP3014, DOI 10.1109/IGARSS.2007.4423479
   DeLancey ER, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010002
   Dempster AP, 2008, STUD FUZZ SOFT COMP, V219, P57
   Bui DT, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19112444
   Domenech G, 2019, ENG GEOL, V250, P34, DOI 10.1016/j.enggeo.2019.01.010
   Fan XM, 2019, REV GEOPHYS, V57, P421, DOI 10.1029/2018RG000626
   Fan XM, 2018, LANDSLIDES, V15, P2325, DOI 10.1007/s10346-018-1054-5
   Fan XM, 2018, LANDSLIDES, V15, P967, DOI 10.1007/s10346-018-0960-x
   Fayne JV, 2019, EARTH INTERACT, V23, P0, DOI 10.1175/EI-D-17-0022.1
   Feizizadeh B, 2014, INT J DIGIT EARTH, V7, P688, DOI 10.1080/17538947.2012.749950
   Foody G.M., 2020, IEEE T GEOSCI REMOTE, V0, P0
   Friedl B., 2018, GEOPH RES ABSTR, V20, P0
   Ghorbanzadeh O., 2018, INT ARCH PHOTOGRAMM, V42, P161, DOI 10.5194/ISPRS-ARCHIVES-XLII-1-161-2018
   Ghorbanzadeh O, 2019, FIRE-BASEL, V2, P0, DOI 10.3390/fire2030043
   Ghorbanzadeh O, 2019, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON GEOGRAPHICAL INFORMATION SYSTEMS THEORY, V0, P33, DOI 10.5220/0007675300330040
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Gonzalez C, 2018, SCI TOTAL ENVIRON, V613, P1024, DOI 10.1016/j.scitotenv.2017.09.105
   Herrera F., 2017, ARXIV170600917, V0, P0
   Holbling D, 2012, REMOTE SENS-BASEL, V4, P1310, DOI 10.3390/rs4051310
   Jaafari A, 2019, AGR FOREST METEOROL, V266, P198, DOI 10.1016/j.agrformet.2018.12.015
   Kalantar B, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111737
   Kannaujiya S., 2019, REMOTE SENSING NW HI, V0, PP37, DOI 10.1007/978-981-13-2128-3_3
   Kim H., 1989, P INT GEOSC REM SENS, V0, P829
   Kubik K, 1900, V6, V0, P283
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P0, DOI 10.5555/303568.303704
   Li H., 2020, IEEE J SEL TOPICS AP, V13, P3971
   Lu H, 2017, J MT SCI-ENGL, V14, P731, DOI 10.1007/s11629-016-3950-2
   Lu K, 2018, THESIS PROQUEST, V0, P0
   Lu Y, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, V0, P666, DOI 10.1109/UEMCON.2018.8796838
   Lv ZY, 2019, IEEE T GEOSCI REMOTE, V57, P9554, DOI 10.1109/TGRS.2019.2927659
   Lv ZY, 2021, IEEE GEOSCI REMOTE S, V18, P1284, DOI 10.1109/LGRS.2020.2998684
   Marano KD, 2010, NAT HAZARDS, V52, P319, DOI 10.1007/s11069-009-9372-5
   Martha TR, 2010, GEOMORPHOLOGY, V116, P24, DOI 10.1016/j.geomorph.2009.10.004
   Maser B., 2019, P JOINT ARW OAGM WOR, V0, P1
   Meena SR, 2019, ISPRS INT GEO-INF, V8, P0, DOI 10.3390/ijgi8020094
   Mezaal MR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071029
   Moine M. W., 2009, P LANDSL PROC GEOM, V0, P1
   Nachappa TG, 2020, J HYDROL, V590, P0, DOI 10.1016/j.jhydrol.2020.125275
   Nachappa TG, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9245393
   Ng W, 2020, SCI TOTAL ENVIRON, V702, P0, DOI 10.1016/j.scitotenv.2019.134723
   Petley D, 2012, GEOLOGY, V40, P927, DOI 10.1130/G33217.1
   Pham BT, 2019, GEOCARTO INT, V34, P1385, DOI 10.1080/10106049.2018.1489422
   Pourghasemi HR, 2014, ARAB J GEOSCI, V7, P1857, DOI 10.1007/s12517-012-0825-x
   Pourghasemi HR, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10103697
   Pourghasemi HR, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4950-1
   Quinn JA, 2018, PHILOS T R SOC A, V376, P0, DOI 10.1098/rsta.2017.0363
   Rahmati O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242995
   Rahmati O, 2016, SCI TOTAL ENVIRON, V568, P1110, DOI 10.1016/j.scitotenv.2016.06.176
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   Schwanghart W, 2018, GEOPHYS RES LETT, V45, P8985, DOI 10.1029/2018GL079173
   Shahabi H, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19224893
   Sheykhmousa M, 2020, IEEE J-STARS, V13, P6308, DOI 10.1109/JSTARS.2020.3026724
   Svalova V, 2019, RISK MANAGEMENT TREA, V0, P1
   Tanyas H, 2017, J GEOPHYS RES-EARTH, V122, P1991, DOI 10.1002/2017JF004236
   Tavakkoli Piralilou S, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212575
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Ye CM, 2019, IEEE J-STARS, V12, P5047, DOI 10.1109/JSTARS.2019.2951725
   Zhang J, 2006, P ISPRS 7 MIDT S REM, V0, P1
   Zhu AX, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104188
NR 64
TC 27
Z9 28
U1 6
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 452
EP 463
DI 10.1109/JSTARS.2020.3043836
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900015
DA 2023-04-26
ER

PT J
AU Alebele, Y
   Wang, WH
   Yu, WG
   Zhang, X
   Yao, X
   Tian, YC
   Zhu, Y
   Cao, WX
   Cheng, T
AF Alebele, Yeshanbele
   Wang, Wenhui
   Yu, Weiguo
   Zhang, Xue
   Yao, Xia
   Tian, Yongchao
   Zhu, Yan
   Cao, Weixing
   Cheng, Tao
TI Estimation of Crop Yield From Combined Optical and SAR Imagery Using Gaussian Kernel Regression
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Optical interferometry; Crops; Optical imaging; Optical sensors; Vegetation mapping; Optical saturation; Coherence; Gaussian regression; kernels; optical vegetation indices (VIs); SAR interferometric coherence; Sentinel-1; Sentinel-2; yield
ID leaf-area index; rice grain-yield; spectral reflectance; parameter-estimation; vegetation index; neural-networks; model; optimization; retrieval; variables
AB The synthetic aperture radar (SAR) interferometric coherence can complement optical data for the estimation of crop growth parameters, but it has not been yet investigated for predicting crop yield. Many studies have used machine-learning methods, such as neural networks, random forest, and Gaussian process regression, to estimate crop yield from remotely sensed data. However, their performance depends on the amount of available ground truth data. This study proposed Gaussian kernel regression for rice yield estimation from optical and SAR imagery using a limited amount of ground truth data. The main objective was to investigate the synergetic use of Sentinel-2 vegetation indices and Sentinel-1 interferometric coherence data through Gaussian kernel regression for estimating rice grain yield. The prediction accuracy was assessed using in situ measured yield data collected in 2019 and 2020 over Xinghua county in Jiangsu Province, China. In all cases, Gaussian kernel regression outperformed the probabilistic Gaussian regression and Bayesian linear inference. With the independently used optical and SAR data, a better prediction accuracy was achieved with the optical red edge difference vegetation index (RDVI1) (r(2) = 0.65, RMSE = 0.61 t/ha) than with the interferometric coherence (r(2) = 0.52 and RMSE = 0.79 t/ha).The highest prediction accuracy can be achieved by combining RDVI1 with interferometric coherence at the heading stage (r(2) = 0.81 and RMSE = 0.55 t/ha). The results suggest the value of synergy between satellite interferometric coherence and optical indices for crop yield mapping with Gaussian kernel regression.
C1 [Alebele, Yeshanbele; Wang, Wenhui; Yu, Weiguo; Zhang, Xue; Yao, Xia; Tian, Yongchao; Zhu, Yan; Cao, Weixing; Cheng, Tao] Nanjing Agr Univ, Natl Engn & Technol Ctr Informat Agr NETCIA, MOE Engn Res Ctr Smart Agr,Jiangsu Key Lab Inform, Inst Smart Agr,MARA Key Lab Crop Syst Anal & Deci, Nanjing 210095, Peoples R China.
C3 Nanjing Agricultural University
RP Cheng, T (corresponding author), Nanjing Agr Univ, Natl Engn & Technol Ctr Informat Agr NETCIA, MOE Engn Res Ctr Smart Agr,Jiangsu Key Lab Inform, Inst Smart Agr,MARA Key Lab Crop Syst Anal & Deci, Nanjing 210095, Peoples R China.
EM 2017201102@njau.edu.cn; 2017201078@njau.edu.cn; 2019201091@njau.edu.cn; 2018101167@njau.edu.cn; yaoxia@njau.edu.cn; yctian@njau.edu.cn; yanzhu@njau.edu.cn; caow@njau.edu.cn; tcheng@njau.edu.cn
FU National Key R&D Program of China [2019YFE0126900]; National Natural Science Foundation of China [41871259, 32021004]; Jiangsu Collaborative Innovation Center for Modern Crop Production [CX(20) 3072]; Jiangsu Agricultural Science and Technology Innovation Fund [CX(20) 3072]
CR Adsuara JE, 2019, IEEE T GEOSCI REMOTE, V57, P10025, DOI 10.1109/TGRS.2019.2931085
   Aghighi H, 2018, IEEE J-STARS, V11, P4563, DOI 10.1109/JSTARS.2018.2823361
   Alebele Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162564
   Aschbacher J, 2012, REMOTE SENS ENVIRON, V120, P3, DOI 10.1016/j.rse.2011.08.028
   Bai ZC, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-63560-0
   Barnes E. M., 2000, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON PRECISION AGRICULTURE, V0, P1
   Bastiaanssen WGM, 2003, AGR ECOSYST ENVIRON, V94, P321, DOI 10.1016/S0167-8809(02)00034-8
   Bolton DK, 2013, AGR FOREST METEOROL, V173, P74, DOI 10.1016/j.agrformet.2013.01.007
   Bose P, 2016, IEEE T GEOSCI REMOTE, V54, P6563, DOI 10.1109/TGRS.2016.2586602
   Campos-Taberner M, 2016, REMOTE SENS ENVIRON, V187, P102, DOI 10.1016/j.rse.2016.10.009
   Camps-Vails G., 2009, 2009 IEEE INT GEOSC, V4, PIV, DOI 10.1109/IGARSS.2009
   Dong TF, 2020, ISPRS J PHOTOGRAMM, V168, P236, DOI 10.1016/j.isprsjprs.2020.08.003
   Doraiswamy PC, 2003, PHOTOGRAMM ENG REM S, V69, P665, DOI 10.14358/PERS.69.6.665
   Dumont B, 2014, ENVIRON MODELL SOFTW, V52, P121, DOI 10.1016/j.envsoft.2013.10.022
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Gilks W.R, 2005, ENCY BIOSTATISTICS, V4, P0, DOI 10.1002/0470011815.B2A14021
   GITELSON A, 1994, J PLANT PHYSIOL, V143, P286, DOI 10.1016/S0176-1617(11)81633-0
   Svendsen DH, 2018, IEEE T GEOSCI REMOTE, V56, P1718, DOI 10.1109/TGRS.2017.2767205
   Henderson DJ, 2018, J LABOR RES, V39, P355, DOI 10.1007/s12122-018-9279-6
   Huang JX, 2019, AGR FOREST METEOROL, V276, P0, DOI 10.1016/j.agrformet.2019.06.008
   Iizumi T, 2009, AGR FOREST METEOROL, V149, P333, DOI 10.1016/j.agrformet.2008.08.015
   Inoue Y, 2014, REMOTE SENS ENVIRON, V140, P257, DOI 10.1016/j.rse.2013.09.001
   Ishwaran H, 2007, ELECTRON J STAT, V1, P519, DOI 10.1214/07-EJS039
   Jin XL, 2018, EUR J AGRON, V92, P141, DOI 10.1016/j.eja.2017.11.002
   Jin XL, 2015, REMOTE SENS-BASEL, V7, P13251, DOI 10.3390/rs71013251
   Johnson DM, 2014, REMOTE SENS ENVIRON, V141, P116, DOI 10.1016/j.rse.2013.10.027
   Kamir E, 2020, ISPRS J PHOTOGRAMM, V160, P124, DOI 10.1016/j.isprsjprs.2019.11.008
   Kross A, 2015, INT J APPL EARTH OBS, V34, P235, DOI 10.1016/j.jag.2014.08.002
   Li D., 2013, ECONOMET THEOR, V32, P655
   Lindsten F., 2017, PROBABILISTIC MODELI, V7, P0
   LIU HQ, 1995, IEEE T GEOSCI REMOTE, V33, P457, DOI 10.1109/36.377946
   Makowski D, 2002, AGRONOMIE, V22, P191, DOI 10.1051/agro:2002007
   Martinez LB, 2022, INT J FINANC ECON, V27, P1870, DOI 10.1002/ijfe.2247
   Mateo-Sanchis A, 2019, REMOTE SENS ENVIRON, V234, P0, DOI 10.1016/j.rse.2019.111460
   Mkhabela MS, 2011, AGR FOREST METEOROL, V151, P385, DOI 10.1016/j.agrformet.2010.11.012
   Ouaadi N, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112050
   Palmisano D, 2019, INT GEOSCI REMOTE SE, V0, PP6219, DOI 10.1109/IGARSS.2019.8899164
   Parry M, 2005, PHILOS T R SOC B, V360, P2125, DOI 10.1098/rstb.2005.1751
   Pinty B., 1994, REMOTE SENSING REV, V10, P265, DOI 10.1080/02757259409532250
   Pipia L, 2019, REMOTE SENS ENVIRON, V235, P0, DOI 10.1016/j.rse.2019.111452
   Rondeaux G, 1996, REMOTE SENS ENVIRON, V55, P95, DOI 10.1016/0034-4257(95)00186-7
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Sambasivan R, 2020, COMPUTATION STAT, V35, P893, DOI 10.1007/s00180-020-00970-8
   Shimazaki H, 2010, J COMPUT NEUROSCI, V29, P171, DOI 10.1007/s10827-009-0180-4
   Sims DA, 2002, REMOTE SENS ENVIRON, V81, P337, DOI 10.1016/S0034-4257(02)00010-X
   Song RZ, 2016, INT GEOSCI REMOTE SE, V0, PP6300, DOI 10.1109/IGARSS.2016.7730647
   Steele-Dunne SC, 2017, IEEE J-STARS, V10, P2249, DOI 10.1109/JSTARS.2016.2639043
   Stepanov A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121936
   Tian F, 2018, NAT ECOL EVOL, V2, P1428, DOI 10.1038/s41559-018-0630-3
   Tibshirani R., 2017, LECT NOTES, V0, P1
   Veloso A, 2017, REMOTE SENS ENVIRON, V199, P415, DOI 10.1016/j.rse.2017.07.015
   Verrelst J, 2013, ISPRS J PHOTOGRAMM, V86, P157, DOI 10.1016/j.isprsjprs.2013.09.012
   Wang JJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192274
   Xie QY, 2019, INT J APPL EARTH OBS, V80, P187, DOI 10.1016/j.jag.2019.04.019
   Xu XJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040546
   Yang Q, 2019, FIELD CROP RES, V235, P142, DOI 10.1016/j.fcr.2019.02.022
   Zhang Y, 2017, INT J APPL EARTH OBS, V57, P75, DOI 10.1016/j.jag.2016.12.014
NR 57
TC 6
Z9 6
U1 10
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10520
EP 10534
DI 10.1109/JSTARS.2021.3118707
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WN2ZC
UT WOS:000711641000023
DA 2023-04-26
ER

PT J
AU Emmi, L
   Le Flecher, E
   Cadenat, V
   Devy, M
AF Emmi, L.
   Le Flecher, E.
   Cadenat, V.
   Devy, M.
TI A hybrid representation of the environment to improve autonomous navigation of mobile robots in agriculture
SO PRECISION AGRICULTURE
LA English
DT Article
DE Hybrid topological map; Crop classification; Semantic identification; Autonomous navigation; Agricultural robotics
ID identification; segmentation; orchards; position; crop
AB This paper considers the problem of autonomous navigation in agricultural fields. It proposes a localization and mapping framework based on semantic place classification and key location estimation, which together build a hybrid topological map. This map benefits from generic partitioning of the field, which contains a finite set of well-differentiated workspaces and, through a semantic analysis, it is possible to estimate in a probabilistic way the position (state) of a mobile system in the field. Moreover, this map integrates both metric (key locations) and semantic features (working areas). One of its advantages is that a full and precise map prior to navigation is not necessary. The identification of the key locations and working areas is carried out by a perception system based on 2D LIDAR and RGB cameras. Fusing these data with odometry allows the robot to be located in the topological map. The approach is assessed through off-line data recorded in real conditions in diverse fields during different seasons. It exploits a real-time object detector based on a convolutional neural network called you only look once, version 3, which has been trained to classify a considerable number of crops, including market-garden crops such as broccoli and cabbage, and to identify grapevine trunks. The results show the interest in the approach, which allows (i) obtaining a simple and easy-to-update map, (ii) avoiding the use of artificial landmarks, and thus (iii) improving the autonomy of agricultural robots.
C1 [Emmi, L.; Le Flecher, E.; Cadenat, V.; Devy, M.] Univ Toulouse, CNRS, LAAS, 7 Ave Colonel Roche, F-31077 Toulouse, France.
   [Cadenat, V.] Univ Toulouse, UPS, LAAS, F-31400 Toulouse, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de Toulouse; Universite de Toulouse; Universite Toulouse III - Paul Sabatier
RP Emmi, L; Cadenat, V (corresponding author), Univ Toulouse, CNRS, LAAS, 7 Ave Colonel Roche, F-31077 Toulouse, France.; Cadenat, V (corresponding author), Univ Toulouse, UPS, LAAS, F-31400 Toulouse, France.
EM luis.emmi@laas.fr; cadenat@laas.fr
FU program "Investment for the Future" of the French government
CR Adao T, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111110
   Ampatzidis Y, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9061010
   [Anonymous], 2014, INT J DISTRIB SENS N, V0, P0, DOI DOI 10.1371/J0URNAL.P0NE.0110734
   Bechar A, 2016, BIOSYST ENG, V149, P94, DOI 10.1016/j.biosystemseng.2016.06.014
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P1, DOI 10.1007/978-3-642-00296-0_1
   Bergerman M, 2016, SPRINGER HANDBOOK OF ROBOTICS, V0, P1463
   Biber P., 2010, P IROS WORKSH SEM MA, V0, P0
   Blanke M, 2012, FAULT DIAGNOSIS ROBO, V0, P1
   Blok PM, 2019, COMPUT ELECTRON AGR, V157, P261, DOI 10.1016/j.compag.2018.12.046
   Bochtis DD, 2010, COMPUT ELECTRON AGR, V74, P80, DOI 10.1016/j.compag.2010.06.008
   Chen KH, 2000, AUTOMAT CONSTR, V10, P1, DOI 10.1016/S0926-5805(99)00010-2
   Cherubini A, 2014, IEEE T INTELL TRANSP, V15, P2101, DOI 10.1109/TITS.2014.2308977
   Comba L., 2010, INTERNATIONAL CONFERENCE, V0, P471
   Durand-Petiteville A, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, V0, P172, DOI 10.5220/0006478601720181
   Futterlieb Marcus, 2014, ICINCO 2014. 11TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, V0, P57
   Garcia-Santillan I, 2018, PRECIS AGRIC, V19, P18, DOI 10.1007/s11119-016-9494-1
   Gonzalez-de-Santos P, 2017, PRECIS AGRIC, V18, P574, DOI 10.1007/s11119-016-9476-3
   Hague T, 2000, COMPUT ELECTRON AGR, V25, P11, DOI 10.1016/S0168-1699(99)00053-8
   Hamuda E, 2016, COMPUT ELECTRON AGR, V125, P184, DOI 10.1016/j.compag.2016.04.024
   IFV, 2020, I FRANC VIGN VIN, V0, P0
   Kanagasingham S, 2020, PRECIS AGRIC, V21, P831, DOI 10.1007/s11119-019-09697-z
   Kayacan E, 2015, COMPUT ELECTRON AGR, V115, P78, DOI 10.1016/j.compag.2015.05.012
   Keskin M, 2017, PRECIS AGRIC, V18, P264, DOI 10.1007/s11119-016-9453-x
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006
   Kuipers B., 1991, ROBOTICS AND AUTONOMOUS SYSTEMS, V8, P47, DOI 10.1016/0921-8890(91)90014-C
   Lee SH, 2017, PATTERN RECOGN, V71, P1, DOI 10.1016/j.patcog.2017.05.015
   Li M, 2010, T ASABE, V53, P297
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Malavazi FBP, 2018, COMPUT ELECTRON AGR, V154, P71, DOI 10.1016/j.compag.2018.08.034
   Naio, 2020, ROB AGR NAIO TECHN, V0, P0
   Penizzotto F, 2015, IEEE LAT AM T, V13, P1303, DOI 10.1109/TLA.2015.7111983
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7_9
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Rottmann A., 2005, PROC NAT C ARTIF INT, V5, P1306
   Royakkers L, 2015, INT J SOC ROBOT, V7, P549, DOI 10.1007/s12369-015-0295-x
   Shamshiri RR, 2018, INT J AGR BIOL ENG, V11, P1, DOI 10.25165/j.ijabe.20181101.3210
   Sharifi M, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, V0, P251, DOI 10.1109/ICARA.2015.7081155
   Shi WN, 2019, BIOSYST ENG, V187, P81, DOI 10.1016/j.biosystemseng.2019.08.014
   STERELA, 2020, SOC IND ING SERV, V0, P0
   Thanpattranon P, 2016, BIOSYST ENG, V147, P90, DOI 10.1016/j.biosystemseng.2016.02.009
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7
   Tu CL, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), V0, PP655, DOI 10.1109/CISP.2014.7003860
   Vougioukas SG, 2019, ANNU REV CONTR ROBOT, V2, P365, DOI 10.1146/annurev-control-053018-023617
   Waldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Xue JR, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/1353691
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 47
TC 18
Z9 18
U1 11
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1385-2256
EI 1573-1618
J9 PRECIS AGRIC
JI Precis. Agric.
PD APR 15
PY 2021
VL 22
IS 2
BP 524
EP 549
DI 10.1007/s11119-020-09773-9
EA JAN 2021
PG 26
WC Agriculture, Multidisciplinary
SC Agriculture
GA RL6QE
UT WOS:000604197700005
DA 2023-04-26
ER

PT J
AU Ruiz, A
   Agudo, A
   Moreno-Noguer, F
AF Ruiz, Adria
   Agudo, Antonio
   Moreno-Noguer, Francesc
TI Generating Attribution Maps with Disentangled Masked Backpropagation
SO 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021)
LA English
DT Proceedings Paper
AB Attribution map visualization has arisen as one of the most effective techniques to understand the underlying inference process of Convolutional Neural Networks. In this task, the goal is to compute an score for each image pixel related to its contribution to the network output. In this paper, we introduce Disentangled Masked Backpropagation (DMBP), a novel gradient-based method that lever-ages on the piecewise linear nature of ReLU networks to decompose the model function into different linear mappings. This decomposition aims to disentangle the attribution maps into positive, negative and nuisance factors by learning a set of variables masking the contribution of each filter during back-propagation. A thorough evaluation over standard architectures (ResNet50 and VGG16) and benchmark datasets (PASCAL VOC and ImageNet) demonstrates that DMBP generates more visually interpretable attribution maps than previous approaches. Additionally, we quantitatively show that the maps produced by our method are more consistent with the true contribution of each pixel to the final network output.
C1 [Ruiz, Adria; Agudo, Antonio; Moreno-Noguer, Francesc] UPC, CSIC, Inst Robot & Informat Ind, Barcelona, Spain.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya
RP Ruiz, A (corresponding author), UPC, CSIC, Inst Robot & Informat Ind, Barcelona, Spain.
EM aruiz@iri.upc.edu; aagudo@iri.upc.edu; fmoreno@iri.upc.edu
FU Spanish government [MoHuCo PID2020-120049RB-I00]; MICINN (Spain) through the program Juan de la Cierva
CR Adebayo J., 2018, ADV NEURAL INFORM PR, V0, P0, DOI DOI 10.5555/3327546.3327621
   Ancona Marco, 2018, INT C LEARN REPR, V0, P0
   Bach S, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0130140
   Bakken Marianne, 2020, ECCV, V0, P0
   Bansal Naman, 2020, IEEE C COMP VIS PATT, V0, P0
   Ching T, 2018, J R SOC INTERFACE, V15, P0, DOI 10.1098/rsif.2017.0387
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fong Ruth, 2019, INT C COMP VIS, V0, P0
   Fong RC, 2017, IEEE I CONF COMP VIS, V0, PP3449, DOI 10.1109/ICCV.2017.371
   García Herrera Arístides Lázaro, 2017, REV.MED.ELECTRÓN., V0, P1
   Geirhos R., 2019, INT C LEARN REPR, V0, P1
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Hossain MD Zakir, 2019, ACM COMPUTING SURVEY, V0, P0
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Kapishnikov Andrei, 2019, IEEE C COMP VIS PATT, V0, P0
   Kim J, 2017, COMPUT INTEL NEUROSC, V2017, P0, DOI 10.1155/2017/4216281
   Kindermans P.-J., 2018, 6 INT C LEARNING REP, V0, P0
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
   Petsiuk Vitali, 2018, BRIT MACH VIS C, V0, P0
   Rebuffi Sylvestre-Alvise, 2020, P IEEE CVF C COMP VI, V0, PP8839, DOI 10.1109/CVPR42600.2020.00886
   Ribeiro MT, 2016, P 22 ACM SIGKDD INT, V0, PP1135, DOI 10.1145/2939672.2939778
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju Ramprasaath R, 2020, INT J COMPUT VIS, V0, P0
   Shrikumar A, 2017, PR MACH LEARN RES, V70, P0
   Simonyan K, 2015, ARXIV, V0, P0
   Simonyan Karen, 2014, INT C LEARN REPR, V0, P0
   Smilkov Daniel, 2017, INT C MACH LEARN, V0, P0
   Springenberg Jost Tobias, 2015, ICLR WORKSH, V0, P0
   Srinivas Suraj, 2019, ADV NEURAL INFORM PR, V2, P7
   Sundararajan M, 2017, PR MACH LEARN RES, V70, P0
   Wang H., 2020, IEEE C COMP VIS PATT, V0, P0
   Xiong Huan, 2020, INT C MACH LEARN, V0, P0
   Xu Shawn, 2020, IEEE C COMP VIS PATT, V0, P0
   Yang Y., 2020, ECCV, V0, P0
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang J., 2016, ECCV, V0, P0
   Zhang QS, 2018, FRONT INFORM TECH EL, V19, P27, DOI 10.1631/FITEE.1700808
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou B., 2016, P 2016 IEEE C COMPUT, V0, PP2921, DOI 10.1109/CVPR.2016.319
   Zintgraf L. M., 2017, 5 INT C LEARN REPR I, V0, P0
NR 41
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 885
EP 894
DI 10.1109/ICCV48922.2021.00094
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA BT1IF
UT WOS:000797698901007
DA 2023-04-26
ER

PT J
AU Vemulapalli, SC
   Mesapam, S
AF Vemulapalli, Sai Charitha
   Mesapam, Shashi
TI Slope Stability Analysis for Mine Hazard Assessment Using UAV
SO JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING
LA English
DT Article
DE Artificial neural networks; Mines; Slope stability; Unmanned air vehicles (UAV)
AB Slopes in open-pit mines are excavated to the steepest feasible angle for maximum profits, which involves a great risk of failure. Unmanned Air Vehicles (UAV) are emerging as new technology to provide information at a high spatial resolution which leads to fast and accurate qualitative results that can be used for stability analysis. The acquired images from the UAV flight plan are processed to produce Digital Elevation Model (DEM). Parameters of slope instability derived from DEM, namely slope, aspect along with inventory maps are fed as an input to Artificial Neural Network (ANN) models. ANNs have the ability to learn and generalize the knowledge on unseen data. Opencast mines in different areas are selected as training sites using random sampling. A feedforward back-propagation algorithm is implemented to analyze slope susceptibility, and the area is classified into four hazard-prone zones. Four input parameters, namely slope, aspect, drainage density and geological structures, are trained using the algorithm. The factors are rated based on the role played by each of them in causing slope failure. 20% of the training sites are selected for testing and 20% for validation purpose. Hazard-prone zones provide useful information regarding possible future which helps in drawing up measures for mitigation.
C1 [Vemulapalli, Sai Charitha; Mesapam, Shashi] NIT Warangal, Dept Civil Engn, Warangal 506004, Andhra Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of Technology Warangal
RP Mesapam, S (corresponding author), NIT Warangal, Dept Civil Engn, Warangal 506004, Andhra Pradesh, India.
EM vemulapallisai@student.nitw.ac.in; mshashi@nitw.ac.in
FU Terra drone Pvt Ltd
CR Aleotti P., 1999, B ENG GEOL ENVIRON, V58, P21, DOI 10.1007/s100640050066
   Arora MK, 2004, INT J REMOTE SENS, V25, P559, DOI 10.1080/0143116031000156819
   Chauhan S, 2010, INT J APPL EARTH OBS, V12, P340, DOI 10.1016/j.jag.2010.04.006
   Koeva M, 2018, SURV REV, V50, P312, DOI 10.1080/00396265.2016.1268756
   Liu S., 2016, ELECTRON J GEOTECH E, V21, P7613
   Oguz, 2018, GEOD LIST, V0, P0, DOI DOI 10.5194/nhess-2018-13
   Rahul, 2015, GEOMECH GEOPHYS GEO-, V1, P69, DOI 10.1007/s40948-015-0009-8
   Riping, 2007, APPL REMOTE SENSING, V0, P55
   Sengupta S, 2018, J EARTH SYST SCI, V127, P0, DOI 10.1007/s12040-018-0982-8
   Tsangaratos P., 2013, B GEOL SOC GREECE, V47, P1901, DOI 10.12681/BGSG.10945
   Uysal M, 2015, MEASUREMENT, V73, P539, DOI 10.1016/j.measurement.2015.06.010
NR 11
TC 2
Z9 2
U1 3
U2 25
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0255-660X
EI 0974-3006
J9 J INDIAN SOC REMOTE
JI J. Indian Soc. Remote Sens.
PD JUL 15
PY 2021
VL 49
IS 7
BP 1483
EP 1491
DI 10.1007/s12524-020-01239-9
EA FEB 2021
PG 9
WC Environmental Sciences; Remote Sensing
SC Environmental Sciences & Ecology; Remote Sensing
GA TL2DR
UT WOS:000619753900002
DA 2023-04-26
ER

PT J
AU Vinayak, B
   Lee, HS
   Gedem, S
AF Vinayak, Bhanage
   Lee, Han Soo
   Gedem, Shirishkumar
TI Prediction of Land Use and Land Cover Changes in Mumbai City, India, Using Remote Sensing Data and a Multilayer Perceptron Neural Network-Based Markov Chain Model
SO SUSTAINABILITY
LA English
DT Article
DE LULC; Markov chain model; multiple perceptron neural network; urban growth; urbanization
ID urban; urbanization; biodiversity; coefficient; environment; impacts; pattern; wetland; desert; region
AB In this study, prediction of the future land use land cover (LULC) changes over Mumbai and its surrounding region, India, was conducted to have reference information in urban development. To obtain the historical dynamics of the LULC, a supervised classification algorithm was applied to the Landsat images of 1992, 2002, and 2011. Based on spatial drivers and LULC of 1992 and 2002, the multiple perceptron neural network (MLPNN)-based Markov chain model (MCM) was applied to simulate the LULC in 2011, which was further validated using kappa statistics. Thereafter, by using 2002 and 2011 LULC, MLPNN-MCM was applied to predict the LULC in 2050. This study predicted the prompt urban growth over the suburban regions of Mumbai, which shows, by 2050, the Urban class will occupy 46.87% (1328.77 km(2)) of the entire study area. As compared to the LULC in 2011, the Urban and Forest areas in 2050 will increase by 14.31% and 2.05%, respectively, while the area under the Agriculture/Sparsely Vegetated and Barren land will decline by 16.87%. The class of water and the coastal feature will experience minute fluctuations (<1%) in the future. The predicted LULC for 2050 can be used as a thematic map in various climatic, environmental, and urban planning models to achieve the aims of sustainable development over the region.
C1 [Vinayak, Bhanage; Gedem, Shirishkumar] Indian Inst Technol, Ctr Studies Resources Engn, Mumbai 400076, India.
   [Vinayak, Bhanage; Lee, Han Soo] Hiroshima Univ, Grad Sch Int Dev & Cooperat IDEC, Dept Dev Technol, Hiroshima 7398529, Japan.
   [Lee, Han Soo] Hiroshima Univ, Grad Sch Adv Sci & Engn, Transdisciplinary Sci & Engn Program, Hiroshima 7398529, Japan.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay; Hiroshima University; Hiroshima University
RP Lee, HS (corresponding author), Hiroshima Univ, Grad Sch Int Dev & Cooperat IDEC, Dept Dev Technol, Hiroshima 7398529, Japan.; Lee, HS (corresponding author), Hiroshima Univ, Grad Sch Adv Sci & Engn, Transdisciplinary Sci & Engn Program, Hiroshima 7398529, Japan.
EM bhanage7@gmail.com; leehs@hiroshima-u.ac.jp; shirish@iitb.ac.in
FU Japan-India International Linkage Degree Program (ILDP) [K190112]; DST-INSPIRE program at Hiroshima University [DST/INSPIRE/03/2015/005692 IF160608]; IIT Bombay
CR Abdulrahman AI., 2020, ACAD J NAWROZ U, V9, P71, DOI 10.25007/ajnu.v9n4a892
   Aghsaei H, 2020, SCI TOTAL ENVIRON, V712, P0, DOI 10.1016/j.scitotenv.2019.136449
   [Anonymous], 2014, ADV LAND CHANG MOD O, V0, P0
   [Anonymous], 2011, CENS IND 2011, V46, P5
   Ansari A, 2019, INT SOIL WATER CONSE, V7, P64, DOI 10.1016/j.iswcr.2018.10.001
   Araya YH, 2010, REMOTE SENS-BASEL, V2, P1549, DOI 10.3390/rs2061549
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Balzter H, 2000, ECOL MODEL, V126, P139, DOI 10.1016/S0304-3800(00)00262-3
   Battisti F, 2020, LAND-BASEL, V9, P0, DOI 10.3390/land9010008
   Bhatti SS, 2015, HABITAT INT, V50, P354, DOI 10.1016/j.habitatint.2015.09.005
   Chen LP, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0200493
   Chim K, 2019, HYDROLOGY-BASEL, V6, P0, DOI 10.3390/hydrology6030064
   Cihlar J, 2000, INT J REMOTE SENS, V21, P1093, DOI 10.1080/014311600210092
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cromley RG., 1999, J GEOGR SYST, V1, P137, DOI 10.1007/s101090050009
   da Silva RFB, 2016, LAND USE POLICY, V58, P133, DOI 10.1016/j.landusepol.2016.07.021
   Demeritt D., 2005, QUESTIONING GEOGRAPH, V0, PP206, DOI 10.2478/v10090
   Deshmukh DS, 2013, J HYDROL, V492, P89, DOI 10.1016/j.jhydrol.2013.04.001
   Eastman J.R., 2012, IDRISI PRODUCTION, V45, P51
   Eastman J.R., 2006, IDRISI ANDES GUIDE G, VVolume 328, P0
   Eastman JR, 2016, IDRISI TERRSET MANUA, V0, P0
   Feng HH, 2012, PEDOSPHERE, V22, P206, DOI 10.1016/S1002-0160(12)60007-1
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Franklin S.E., 2003, GEOMETRIC CORRECTION, V0, P143
   Ghosh Pramit, 2017, REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT, V5, P64, DOI 10.1016/j.rsase.2017.01.005
   Gogoi PP, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-45213-z
   Guarini MR, 2017, BUILDINGS, V7, P0, DOI 10.3390/buildings7020044
   Halmy MWA, 2015, APPL GEOGR, V63, P101, DOI 10.1016/j.apgeog.2015.06.015
   Hamud Ahmed Mohammed, 2019, IOP CONFERENCE SERIES: EARTH AND ENVIRONMENTAL SCIENCE, V357, P0, DOI 10.1088/1755-1315/357/1/012038
   Hassan Z, 2016, SPRINGERPLUS, V5, P0, DOI 10.1186/s40064-016-2414-z
   Hosseinali F, 2015, KSCE J CIV ENG, V19, P285, DOI 10.1007/s12205-012-0367-5
   Hu XF, 2009, REMOTE SENS ENVIRON, V113, P2089, DOI 10.1016/j.rse.2009.05.014
   HUDSON WD, 1987, PHOTOGRAMM ENG REM S, V53, P421
   Islam K, 2018, ECOL INDIC, V88, P439, DOI 10.1016/j.ecolind.2018.01.047
   Ku CA, 2016, APPL GEOGR, V69, P1, DOI 10.1016/j.apgeog.2016.02.005
   Liebetrau A.M., 1983, MEASURES ASS, V32, P0
   Liu Y., 2008, INT ARCH PHOTOGRAMME, VXXXVI, P1123
   Losiri C, 2016, SUSTAINABILITY-BASEL, V8, P0, DOI 10.3390/su8070686
   Mahmoud MI, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030220
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Matlhodi B, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11195174
   Mendiratta P, 2018, APPL GEOGR, V98, P110, DOI 10.1016/j.apgeog.2018.05.017
   Mishra VN, 2018, APPL GEOMAT, V10, P257, DOI 10.1007/s12518-018-0223-5
   Mishra VN, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2138-3
   MMRDA, 2016, MUMB METR REG PLAN, V0, P0
   Mondal B, 2017, GEOCARTO INT, V32, P401, DOI 10.1080/10106049.2016.1155656
   Mortoja MG, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12233938
   Mortoja MG, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142270
   Mozumder C, 2014, INT J APPL EARTH OBS, V32, P92, DOI 10.1016/j.jag.2014.03.002
   Nayak S, 2012, CURR SCI INDIA, V102, P1166
   Onate-Valdivieso F, 2010, J HYDROL, V395, P256, DOI 10.1016/j.jhydrol.2010.10.033
   Pahlavani P., 2017, EARTH OBSERV GEOMATI, V1, P82, DOI 10.22059/eoge.2017.220342.1006
   Parsamehr K, 2020, SPAT INF RES, V28, P159, DOI 10.1007/s41324-019-00273-1
   Paul S, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-22322-9
   Pontius RG, 2002, PHOTOGRAMM ENG REM S, V68, P1041
   Pontius RG, 2001, AGR ECOSYST ENVIRON, V85, P191, DOI 10.1016/S0167-8809(01)00183-9
   Rahman MTU, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-6272-0
   Saadat H, 2011, ISPRS J PHOTOGRAMM, V66, P608, DOI 10.1016/j.isprsjprs.2011.04.001
   Sahebgharani A., 2016, JOURNAL OF URBAN AND ENVIRONMENTAL ENGINEERING (JUEE), V10, P42
   Sangermano F, 2010, T GIS, V14, P569, DOI 10.1111/j.1467-9671.2010.01226.x
   Saputra MH, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11113024
   Seto KC, 2012, P NATL ACAD SCI USA, V109, P16083, DOI 10.1073/pnas.1211658109
   Shastri H, 2019, CLIM DYNAM, V52, P6033, DOI 10.1007/s00382-018-4493-8
   Shi G, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10020426
   Shoyama K, 2019, SUSTAIN SCI, V14, P39, DOI 10.1007/s11625-018-0617-7
   Smith B, 2003, GEOPHYS RES LETT, V30, P0, DOI 10.1029/2002GL016643
   Triantakonstantis D., 2012, J GEOGRAPHIC INFORM, V04, P555, DOI 10.4236/JGIS.2012.46060
   Vadrevu KP, 2015, J ENVIRON MANAGE, V148, P1, DOI 10.1016/j.jenvman.2014.12.005
   Vitousek PM, 1997, SCIENCE, V277, P494, DOI 10.1126/science.277.5325.494
   Xu QL, 2015, NAT HAZARDS, V75, P95, DOI 10.1007/s11069-014-1303-4
   Xu X, 2018, SCI TOTAL ENVIRON, V624, P1561, DOI 10.1016/j.scitotenv.2017.12.143
   Xystrakis F, 2017, SCI TOTAL ENVIRON, V587, P360, DOI 10.1016/j.scitotenv.2017.02.161
   Yang X, 2016, GEOMAT NAT HAZ RISK, V7, P918, DOI 10.1080/19475705.2014.1001797
   Zhong S, 2017, ATMOS CHEM PHYS, V17, P5439, DOI 10.5194/acp-17-5439-2017
   Zhou YR, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0048-z
NR 75
TC 24
Z9 24
U1 2
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2071-1050
J9 SUSTAINABILITY-BASEL
JI Sustainability
PD JAN 15
PY 2021
VL 13
IS 2
BP 
EP 
DI 10.3390/su13020471
PG 22
WC Green & Sustainable Science & Technology; Environmental Sciences; Environmental Studies
SC Science & Technology - Other Topics; Environmental Sciences & Ecology
GA PY0MH
UT WOS:000611743800001
DA 2023-04-26
ER

PT J
AU Ahmadlou, M
   Al-Fugara, A
   Al-Shabeeb, AR
   Arora, A
   Al-Adamat, R
   Pham, QB
   Al-Ansari, N
   Linh, NTT
   Sajedi, H
AF Ahmadlou, Mohammad
   Al-Fugara, A'kif
   Al-Shabeeb, Abdel Rahman
   Arora, Aman
   Al-Adamat, Rida
   Quoc Bao Pham
   Al-Ansari, Nadhir
   Nguyen Thi Thuy Linh
   Sajedi, Hedieh
TI Flood susceptibility mapping and assessment using a novel deep learning model combining multilayer perceptron and autoencoder neural networks
SO JOURNAL OF FLOOD RISK MANAGEMENT
LA English
DT Article
DE deep learning; flood susceptibility; GIS; mapping; multilayer perceptron
ID multicriteria decision-making; spatial prediction; artificial-intelligence; statistical-models; frequency ratio; river catchment; bivariate; area; regression; city
AB Floods are one of the most destructive natural disasters causing financial damages and casualties every year worldwide. Recently, the combination of data-driven techniques with remote sensing (RS) and geographical information systems (GIS) has been widely used by researchers for flood susceptibility mapping. This study presents a novel hybrid model combining the multilayer perceptron (MLP) and autoencoder models to produce the susceptibility maps for two study areas located in Iran and India. For two cases, nine, and twelve factors were considered as the predictor variables for flood susceptibility mapping, respectively. The prediction capability of the proposed hybrid model was compared with that of the traditional MLP model through the area under the receiver operating characteristic (AUROC) criterion. The AUROC curve for the MLP and autoencoder-MLP models were, respectively, 75 and 90, 74 and 93% in the training phase and 60 and 91, 81 and 97% in the testing phase, for Iran and India cases, respectively. The results suggested that the hybrid autoencoder-MLP model outperformed the MLP model and, therefore, can be used as a powerful model in other studies for flood susceptibility mapping.
C1 [Ahmadlou, Mohammad] KN Toosi Univ Technol, Geodesy & Geomat Fac, GIS Dept, Tehran, Iran.
   [Al-Fugara, A'kif] Al al Bayt Univ, Fac Engn, Dept Surveying Engn, Mafraq, Jordan.
   [Al-Shabeeb, Abdel Rahman; Al-Adamat, Rida] Al al Bayt Univ, Inst Earth & Environm Sci, Dept GIS & Remote Sensing, Mafraq, Jordan.
   [Arora, Aman] Fac Nat Sci, Dept Geog, New Delhi, India.
   [Quoc Bao Pham] Ton Duc Thang Univ, Environm Qual Atmospher Sci & Climate Change Res, Ho Chi Minh City, Vietnam.
   [Quoc Bao Pham] Ton Duc Thang Univ, Fac Environm & Labour Safety, Ho Chi Minh City, Vietnam.
   [Al-Ansari, Nadhir] Lulea Univ Technol, Dept Civil Environm & Nat Resources Engn, S-97187 Lulea, Sweden.
   [Nguyen Thi Thuy Linh] Duy Tan Univ, Inst Res & Dev, Danang 550000, Vietnam.
   [Nguyen Thi Thuy Linh] Duy Tan Univ, Fac Environm & Chem Engn, Danang 550000, Vietnam.
   [Sajedi, Hedieh] Univ Tehran, Coll Sci, Sch Math, Dept Comp Sci, Tehran, Iran.
C3 K. N. Toosi University of Technology; Al al-Bayt University; Al al-Bayt University; Ton Duc Thang University; Ton Duc Thang University; Lulea University of Technology; Duy Tan University; Duy Tan University; University of Tehran
RP Pham, QB (corresponding author), Ton Duc Thang Univ, Environm Qual Atmospher Sci & Climate Change Res, Ho Chi Minh City, Vietnam.
EM phambaoquoc@tdtu.edu.vn
CR Abbas A, 2015, NAT HAZARDS, V75, P2119, DOI 10.1007/s11069-014-1415-x
   Ahmadlou M, 2019, GEOCARTO INT, V34, P1252, DOI 10.1080/10106049.2018.1474276
   Ali SA, 2020, ECOL INDIC, V117, P0, DOI 10.1016/j.ecolind.2020.106620
   [Anonymous], 1998, FLOODS PHYS PROCESSE, V0, P0
   [Anonymous], 2010, J SPAT HYDROL, V0, P0
   Arabameri A, 2019, SCI TOTAL ENVIRON, V660, P443, DOI 10.1016/j.scitotenv.2019.01.021
   Arora A, 2021, GEOCARTO INT, V36, P2085, DOI 10.1080/10106049.2019.1687594
   Baz I, 2009, ADV ENG SOFTW, V40, P128, DOI 10.1016/j.advengsoft.2008.03.016
   Bhatt CM, 2016, GEOMAT NAT HAZ RISK, V7, P747, DOI 10.1080/19475705.2014.949877
   Bracken LJ, 2008, HYDROL PROCESS, V22, P683, DOI 10.1002/hyp.6641
   Cao B, 2020, IEEE T FUZZY SYST, V28, P939, DOI 10.1109/TFUZZ.2020.2972207
   Chao LJ, 2018, J HYDROL, V558, P275, DOI 10.1016/j.jhydrol.2018.01.042
   Chapi K, 2017, ENVIRON MODELL SOFTW, V95, P229, DOI 10.1016/j.envsoft.2017.06.012
   Chen M, 2017, IEEE TRANS BIG DATA, VPP, P1, DOI 10.1109/tbdata.2017.2717439
   Chicco D., 2014, P 5 ACM C BIOINF COM, V0, PP533, DOI 10.1145/2649387
   Costache R, 2020, J HYDROL, V585, P0, DOI 10.1016/j.jhydrol.2020.124808
   Costache R, 2020, J ENVIRON MANAGE, V265, P0, DOI 10.1016/j.jenvman.2020.110485
   Costache R, 2020, SCI TOTAL ENVIRON, V712, P0, DOI 10.1016/j.scitotenv.2019.136492
   Costache R, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.134514
   Costache R, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104179
   Costache R, 2019, SCI TOTAL ENVIRON, V691, P1098, DOI 10.1016/j.scitotenv.2019.07.197
   Costache R, 2019, SCI TOTAL ENVIRON, V659, P1115, DOI 10.1016/j.scitotenv.2018.12.397
   Dassanayake DR, 2015, COAST ENG J, V57, P0, DOI 10.1142/S0578563415400070
   Diaz JH, 2006, J TRAVEL MED, V13, P361, DOI 10.1111/j.1708-8305.2006.00072.x
   Bui DT, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134413
   Bui DT, 2016, J HYDROL, V540, P317, DOI 10.1016/j.jhydrol.2016.06.027
   Elnazer AA, 2017, NAT HAZARDS, V89, P1389, DOI 10.1007/s11069-017-3030-0
   Fernandez DS, 2010, ENG GEOL, V111, P90, DOI 10.1016/j.enggeo.2009.12.006
   GAILLARD J., 2007, DISASTER PREVENTION, V16, P522, DOI 10.1108/09653560710817011
   Gajbhiye S, 2014, APPL WATER SCI, V4, P51, DOI 10.1007/s13201-013-0129-7
   Garmdareh ES, 2018, HYDROLOG SCI J, V63, P426, DOI 10.1080/02626667.2018.1432056
   Hernandez E, 2016, LECT NOTES ARTIF INT, V9648, P151, DOI 10.1007/978-3-319-32034-2_13
   Hong HY, 2018, SCI TOTAL ENVIRON, V625, P575, DOI 10.1016/j.scitotenv.2017.12.256
   Hong HY, 2018, SCI TOTAL ENVIRON, V621, P1124, DOI 10.1016/j.scitotenv.2017.10.114
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Janizadeh S, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11195426
   JUDI DR, 2018, WATER SUI, V10, P0
   Kadam P., 2012, J HYDRAULIC ENG, V18, P129, DOI 10.1080/09715010.2012.695449
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Khosravi K, 2016, NAT HAZARDS, V83, P947, DOI 10.1007/s11069-016-2357-2
   Kia MB, 2012, ENVIRON EARTH SCI, V67, P251, DOI 10.1007/s12665-011-1504-z
   Kourgialas NN, 2017, SCI TOTAL ENVIRON, V601, P441, DOI 10.1016/j.scitotenv.2017.05.197
   Kousky C, 2018, RISK MANAG INSUR REV, V21, P11, DOI 10.1111/RMIR.12090
   Lee S, 2006, ENVIRON GEOL, V50, P847, DOI 10.1007/s00254-006-0256-7
   Lee S, 2017, GEOMAT NAT HAZ RISK, V8, P1185, DOI 10.1080/19475705.2017.1308971
   Li KZ, 2012, NAT HAZARDS, V63, P737, DOI 10.1007/s11069-012-0180-y
   Lv ZH, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106300
   Nair V, 2010, ICML, V27, P807
   Oh HJ, 2011, J HYDROL, V399, P158, DOI 10.1016/j.jhydrol.2010.12.027
   Pachauri R.K., 2014, CLIMATE CHANGE 2014, V0, P0
   Pourghasemi H., 2012, TERRIGENOUS MASS MOV, V0, P0, DOI DOI 10.1007/978-3-642-25495-6_2
   Prado Oliveira Tiago, 2014, NETWORK AND PARALLEL COMPUTING. 11TH IFIP WG 10.3 INTERNATIONAL CONFERENCE, V0, P61, DOI 10.1007/978-3-662-44917-2_6
   Quan Q, 2022, NEURAL COMPUT APPL, V34, P8501, DOI 10.1007/s00521-020-04836-4
   Rahmati O, 2016, GEOCARTO INT, V31, P42, DOI 10.1080/10106049.2015.1041559
   SCHUMM SA, 1965, AM J SCI, V263, P110, DOI 10.2475/ajs.263.2.110
   Shafizadeh-Moghadam H, 2018, J ENVIRON MANAGE, V217, P1, DOI 10.1016/j.jenvman.2018.03.089
   Shafizadeh-Moghadam H, 2017, GISCI REMOTE SENS, V54, P639, DOI 10.1080/15481603.2017.1309125
   Shaluf I.M., 2007, DISASTER PREV MANAG, V16, P704, DOI 10.1108/09653560710837019
   Shi KB, 2020, FUZZY SET SYST, V381, P1, DOI 10.1016/j.fss.2018.11.017
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Souissi D, 2020, GEOCARTO INT, V35, P991, DOI 10.1080/10106049.2019.1566405
   Sun WJ, 2016, MEASUREMENT, V89, P171, DOI 10.1016/j.measurement.2016.04.007
   Talukdar S, 2020, STOCH ENV RES RISK A, V34, P2277, DOI 10.1007/s00477-020-01862-5
   Tang ZQ, 2018, STOCH ENV RES RISK A, V32, P701, DOI 10.1007/s00477-017-1431-y
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Tehrany MS, 2014, ENVIRON EARTH SCI, V72, P4001, DOI 10.1007/s12665-014-3289-3
   Tehrany MS, 2013, J HYDROL, V504, P69, DOI 10.1016/j.jhydrol.2013.09.034
   Teng WH, 2006, NAT HAZARDS, V37, P191, DOI 10.1007/s11069-005-4667-7
   Termeh SVR, 2018, SCI TOTAL ENVIRON, V615, P438, DOI 10.1016/j.scitotenv.2017.09.262
   Testa G, 2007, J HYDRAUL RES, V45, P37, DOI 10.1080/00221686.2007.9521831
   van Alphen J, 2006, FLOODS, V0, P0
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang S, 2020, ENVIRON MODELL SOFTW, V124, P0, DOI 10.1016/j.envsoft.2019.104607
   Wang ZL, 2015, J HYDROL, V527, P1130, DOI 10.1016/j.jhydrol.2015.06.008
   Yang L, 2019, NEURAL COMPUT APPL, V31, P4463, DOI 10.1007/s00521-018-3525-y
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yariyan P, 2020, WATER RESOUR MANAG, V34, P3037, DOI 10.1007/s11269-020-02603-7
   Youssef AM, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4830-8
   Zeiler MD, 2013, INT CONF ACOUST SPEE, V0, PP3517, DOI 10.1109/ICASSP.2013.6638312
   Zurada, 1992, INTRO ARTIFICIAL NEU, V0, P0
NR 81
TC 39
Z9 39
U1 3
U2 35
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1753-318X
EI 
J9 J FLOOD RISK MANAG
JI J. Flood Risk Manag.
PD MAR 15
PY 2021
VL 14
IS 1
BP 
EP 
DI 10.1111/jfr3.12683
EA DEC 2020
PG 22
WC Environmental Sciences; Water Resources
SC Environmental Sciences & Ecology; Water Resources
GA QK9MU
UT WOS:000599620700001
DA 2023-04-26
ER

PT J
AU Yu, JC
   Zhang, L
   Li, Q
   Li, YCA
   Huang, W
   Sun, ZW
   Ma, YN
   He, P
AF Yu, Junchuan
   Zhang, Liang
   Li, Qiang
   Li, Yichuan
   Huang, Wei
   Sun, Zhiwei
   Ma, Yanni
   He, Peng
TI 3D autoencoder algorithm for lithological mapping using ZY-1 02D hyperspectral imagery: a case study of Liuyuan region
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE deep learning; lithological mapping; autoencoder; hyperspectral; small sample; ZY-1 02D
ID classification; discrimination; spectra; rocks; tool
AB A hyperspectral image (HSI) contains hundreds of spectral bands, which provide detailed spectral information, thus offering an inherent advantage in classification. The successful launch of the Gaofen-5 and ZY-1 02D hyperspectral satellites has promoted the need for large-scale geological applications, such as mineral and lithological mapping (LM). In recent years, following the success of computer vision, deep learning methods have shown their advantage in solving the problem of hyperspectral classification. However, the combination of deep learning and HSI to solve the problem of geological mapping is insufficient. We propose a new 3D convolutional autoencoder for LM. A pixel-based and cube-based 3D convolutional neural network architecture is designed to extract spatial-spectral features. Traditional and machine learning methods are employed as competing methods, trained on two real hyperspectral datasets, and evaluated according to the overall accuracy, F1 score, and other metrics. Results indicate that the proposed method can provide convincing results for LM applications on the basis of the hyperspectral data provided by the ZY-1 02D satellite. Compared with traditional methods, the combination of deep learning and hyperspectral can provide more efficient and highly accurate results. The proposed method has better robustness than supervised learning methods and shows great promise under small sample conditions. As far as we know, this work is the first attempt to apply unsupervised spatial-spectral feature learning technology in LM applications, which is of great significance for large-scale applications. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 International License.
C1 [Yu, Junchuan; Li, Yichuan; Huang, Wei; Ma, Yanni; He, Peng] China Aero Geophys Survey, Beijing, Peoples R China.
   [Yu, Junchuan; Li, Yichuan; Huang, Wei; Ma, Yanni; He, Peng] Remote Sensing Ctr Land & Resources, Beijing, Peoples R China.
   [Zhang, Liang] China Univ Geosci, Beijing, Peoples R China.
   [Li, Qiang] Shenyang Geotech Invest & Surveying Res Inst Co L, Shenyang, Peoples R China.
   [Sun, Zhiwei] Beijing GEOWAY Spatial Co Ltd, Beijing, Peoples R China.
C3 China University of Geosciences
RP Yu, JC (corresponding author), China Aero Geophys Survey, Beijing, Peoples R China.; Yu, JC (corresponding author), Remote Sensing Ctr Land & Resources, Beijing, Peoples R China.
EM yujunchuan@mail.cgs.gov.cn
FU National Key Research and Development Program of China [2016YFB0501401]; Advance Research Project of Civil Space Technology
CR ADAMS JB, 1986, J GEOPHYS RES-SOLID, V91, P8098, DOI 10.1029/JB091iB08p08098
   ALBERTI A, 1993, J AFR EARTH SCI, V17, P261, DOI 10.1016/0899-5362(93)90072-X
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Black M, 2016, REMOTE SENS ENVIRON, V176, P225, DOI 10.1016/j.rse.2016.01.022
   Carli C, 2015, GEOL SOC SPEC PUBL, V401, P139, DOI 10.1144/SP401.19
   Chakouri M., 2020, IJATCSE, V9, P5772, DOI 10.30534/IJATCSE/2020/234942020
   Chang CI, 2000, IEEE T INFORM THEORY, V46, P1927, DOI 10.1109/18.857802
   Clark R. N, 1999, MANUAL REMOTE SENSIN, V3, P3, DOI 10.1111/J.1945-5100.2004.TB00079.X
   CLARK RN, 1984, J GEOPHYS RES, V89, P6329, DOI 10.1029/JB089iB07p06329
   Dasgupta S., 2019, DEV STRUCTURAL GEOLO, V0, P205
   Ghulam A., 2010, ASPRS ANN C, V0, P0
   GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001
   Gupta R.P., 2017, REMOTE SENSING GEOLO, V0, P0
   Hecker C, 2008, IEEE T GEOSCI REMOTE, V46, P4162, DOI 10.1109/TGRS.2008.2001035
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   Hunt G. R., 1974, MODERN GEOLOGY, V5, P15
   HUNT GR, 1977, GEOPHYSICS, V42, P501, DOI 10.1190/1.1440721
   Jain R, 2019, INT J APPL EARTH OBS, V81, P137, DOI 10.1016/j.jag.2019.05.007
   Khajehrayeni F, 2020, IEEE J-STARS, V13, P567, DOI 10.1109/JSTARS.2020.2966512
   Kokaly R. F., 2017, DATA SER, V0, P0, DOI DOI 10.3133/ds1035
   [刘银年 Liu Yinnian], 2020, 遥感学报 JOURNAL OF REMOTE SENSING, V24, P333
   Longhi I, 2001, INT J REMOTE SENS, V22, P3763, DOI 10.1080/01431160010006980
   Mwaniki MW, 2015, IEEE J-STARS, V8, P1855, DOI 10.1109/JSTARS.2015.2395094
   Niu HQ, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON ELECTRICAL MATERIALS AND POWER EQUIPMENT (ICEMPE), V0, PP163, DOI 10.1109/ICEMPE.2017.7982056
   Qu Y, 2019, IEEE T GEOSCI REMOTE, V57, P1698, DOI 10.1109/TGRS.2018.2868690
   Rani N, 2016, J GEOL SOC INDIA, V88, P440, DOI 10.1007/s12594-016-0507-5
   Savas O., 2017, IEEE T GEOSCI ELECT, V57, P482
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Su YC, 2019, IEEE T GEOSCI REMOTE, V57, P4309, DOI 10.1109/TGRS.2018.2890633
   Vasuki Y, 2017, COMPUT GEOSCI-UK, V100, P27, DOI 10.1016/j.cageo.2016.12.001
   Wang WG, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8091513
   Wang X, 2020, IEEE T GEOSCI REMOTE, V58, P5676, DOI 10.1109/TGRS.2020.2968304
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P7232, DOI 10.1109/TGRS.2019.2912468
   Xu N, 2011, SPECTROSC SPECT ANAL, V31, P1639, DOI 10.3964/j.issn.1000-0593(2011)06-1639-05
   Yang YK, 2018, INT GEOSCI REMOTE SE, V0, P2543
   Ye B, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12233990
   Yu JC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12132106
   Zhang XR, 2018, IEEE GEOSCI REMOTE S, V15, P1755, DOI 10.1109/LGRS.2018.2857804
   Zhang XY, 2014, INT J APPL EARTH OBS, V31, P95, DOI 10.1016/j.jag.2014.03.007
   Zhong YF, 2021, GEO-SPAT INF SCI, V24, P95, DOI 10.1080/10095020.2020.1860653
NR 40
TC 2
Z9 2
U1 10
U2 14
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 
EI 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD SEP 20
PY 2021
VL 15
IS 4
BP 
EP 
DI 10.1117/1.JRS.15.042610
PG 14
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology
GA 2D4JA
UT WOS:000811514200002
DA 2023-04-26
ER

PT J
AU John, J
   Varkey, MS
   Selvi, M
AF John, Jacob
   Varkey, Mariam Sunil
   Selvi, M.
TI Multi-class Text Classification and Publication of Crime Data from Online News Sources
SO 2021 8TH INTERNATIONAL CONFERENCE ON SMART COMPUTING AND COMMUNICATIONS (ICSCC)
LA English
DT Proceedings Paper
DE Crime hotspot mapping; Hybrid neural networks; Multiclass classification; Deep learning; Community information systems
ID geographical information-systems; named entity recognition
AB Over the past decade, India's major cities have been deemed as some of the most unsafe places in the world for women. We know that crimes against women occur every day as newspapers show reports of the activities that occur to not just women but also minor girls. As a result of this, women's safety is a growing concern for the government. The women in our lives deserve to feel secure wherever they go. This paper aims to help women select the states they travel to or relocate to based on recent criminal activity. The proposed methodology is a web application utilizing the Django framework. The web application provides a map with the crime hotspots of India sourced from reputed news articles on the Internet. Articles are first scraped using a web crawler we have designed. The scraped article is classified into a corresponding category to depict them on the heatmap. Classifying news articles is a multi-class classification problem that requires a robust and powerful machine learning model. A novel hybrid architecture of Convolutional Neural Network (CNN) and Gated Recurrent Unit (GRU) is adopted and proposed in this paper. The ensemble model performs incredibly well on news sources collated from reputed websites and successfully classifies news articles with an accuracy of 95.1%.
C1 [John, Jacob; Varkey, Mariam Sunil; Selvi, M.] Vellore Inst Technol, Sch Comp Sci & Engn SCOPE, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP John, J (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn SCOPE, Vellore, Tamil Nadu, India.
EM jacob.john2016@vitalum.ac.in; mariamsunil.varkey2016@vitalum.ac.in; selvi.m@vit.ac.in
CR ACPO, 2001, REASS CIV 1 PROP POL, V0, P0
   [Anonymous], 2001, USING ARCGIS GEOSTAT, V0, P0
   Bowers K., 2001, MAPPING ANALYSING CR, V0, P120
   Chainey S, 2012, POLIC-J POLICY PRACT, V6, P228, DOI 10.1093/police/pas006
   Chainey S, 2008, SECUR J, V21, P4, DOI 10.1057/palgrave.sj.8350066
   Chen GB, 2017, IEEE IJCNN, V0, PP2377, DOI 10.1109/IJCNN.2017.7966144
   Di Martino S, 2011, STUD COMPUT INTELL, V348, P163
   Economist, 1995, ECONOMIST, V331, P20
   Erdogan S, 2008, ACCIDENT ANAL PREV, V40, P174, DOI 10.1016/j.aap.2007.05.004
   Florian R, 2003, P 7 C NAT LANG LEARN, V4, P168, DOI 10.3115/1119176.1119201
   Ghiassi M, 2012, EXPERT SYST APPL, V39, P10967, DOI 10.1016/j.eswa.2012.03.027
   Guo JF, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP267, DOI 10.1145/1571941.1571989
   Harrag F, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT 2009), V0, PP778, DOI 10.1109/ICADIWT.2009.5273841
   John J., 2019, INT J INNOVATIVE TEC, V9, P2088
   Joulin A, 2016, BAG TRICKS EFFICIENT, V0, P0
   Kuo PF, 2013, J TRANSP GEOGR, V30, P138, DOI 10.1016/j.jtrangeo.2013.04.006
   Lample G., 2016, P NAACL HLT, V0, PP260, DOI 10.18653/V1/N16-1030
   Martin D., 1998, CRIME MAPPING CASE S, V0, P3
   PAULSEN D, 2004, INT J POLICE SCI MAN, V6, P234, DOI 10.1350/IJPS.6.4.234.54136
   Paulsen D. J., 2004, SPATIAL ASPECTS CRIM, V0, P0
   Ratcliffe JH., 2002, POLIC SOC, V12, P211, DOI 10.1080/10439460290018463
   Reimers N., 2014, GERMEVAL 2014 NESTED, V0, P0
   Ritter A., 2011, P 2011 C EMPIRICAL M, V0, PP1524, DOI 10.1075/LI.30.1.03NAD
   Santos L, 2011, DECIS SUPPORT SYST, V51, P1, DOI 10.1016/j.dss.2010.11.008
   Secretary of State Home Department, 2010, POL 21 CENT REC POL, V0, P0
   Shabat H.A., 2015, MIDDLE-EAST J SCI RE, V23, P1215, DOI 10.5829/idosi.mejsr.2015.23.06.22271
   Singh H., 2012, INT J RES COMPUTER S, V2, P57, DOI 10.7815/ijorcs.23.2012.030
   Tayal DK, 2015, AI SOC, V30, P117, DOI 10.1007/s00146-014-0539-6
   Torisawa K., 2007, P 2007 JOINT C EMP M, V0, P698
   Wang P, 2016, NEUROCOMPUTING, V174, P806, DOI 10.1016/j.neucom.2015.09.096
   Williamson D., 2001, MAPPING ANAL CRIME D, V0, P187
   Wu YH, 2015, STUD HEALTH TECHNOL, V216, P624, DOI 10.3233/978-1-61499-564-7-624
   Zhang Xiang, 2015, ADV NEURAL INFORM PR, V0, PP649, DOI 10.5555/2969239.2969312
   Zhou GD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P473
NR 34
TC 1
Z9 1
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 64
EP 69
DI 10.1109/ICSCC51209.2021.9528127
PG 6
WC Computer Science, Theory & Methods; Telecommunications
SC Computer Science; Telecommunications
GA BS3DO
UT WOS:000709816800013
DA 2023-04-26
ER

PT J
AU Wang, Y
   Ksienzyk, AK
   Liu, M
   Bronner, M
AF Wang, Ying
   Ksienzyk, Anna K.
   Liu, Ming
   Broenner, Marco
TI Multigeophysical data integration using cluster analysis: assisting geological mapping in Trondelag, Mid-Norway
SO GEOPHYSICAL JOURNAL INTERNATIONAL
LA English
DT Article
DE Neural networks, fuzzy logic; Numerical solutions; Persistence, memory, correlations, clustering; Spatial analysis
ID tool
AB Modern geophysical data acquisition technology makes it possible to measure multiple geophysical properties with high spatial density over large areas with great efficiency. Instead of presenting these co-located multigeophysical data sets in separate maps, we take advantage of cluster analysis and its pattern exploration power to generate a cluster map with objectively integrated information. Each cluster in the resulting cluster map is characterized by multigeophysical properties and can be associated with certain geological attributes or rock types based on existing geological maps, field data and rock sample analysis. Such a cluster map is usually high in resolution and proven to be more helpful than single-attribute maps in terms of assisting geological mapping and interpretation. In this paper, we present the workflow and technical details of applying cluster analysis to multigeophysical data of a study area in the Trandelag region in Mid-Norway. We address the importance of carefully designed pre-processing procedures regarding the input data sets to ensure an unbiased data integration using cluster analysis. Random forest as a supervised machine learning method for classification/regression is strategically employed post-clustering for quality evaluation of the results. The multigeophysical data used for this study include airborne magnetic, frequency electromagnetic and radiometric measurements, together with ground gravity measurements. Due to the nature of these input data, the resulting cluster map carries multidepth information. When associated with available geological information, the cluster map can help interpret not only bedrock outcrops but also rocks underneath the sediment cover.
C1 [Wang, Ying; Ksienzyk, Anna K.; Broenner, Marco] Geol Survey Norway NGU, N-7040 Trondheim, Norway.
   [Liu, Ming] Hunan Key Lab Nonferrous Resources & Geol Hazard, Changsha 410083, Peoples R China.
C3 Geological Survey of Norway
RP Wang, Y (corresponding author), Geol Survey Norway NGU, N-7040 Trondheim, Norway.
EM ying.wang@ngu.no
CR Bergen KJ, 2019, SCIENCE, V363, P1299, DOI 10.1126/science.aau0323
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Calinski T., 1974, COMMUN STAT, V3, P1, DOI 10.1080/03610927408827101
   Dekkers MJ, 2014, GEOCHEM GEOPHY GEOSY, V15, P3430, DOI 10.1002/2014GC005343
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Eberle D., 1993, INT I AEROSP SURV EA, V1993-2, P173
   Eberle D, 2015, J AFR EARTH SCI, V106, P60, DOI 10.1016/j.jafrearsci.2015.03.011
   Eberle DG, 2012, GEOPHYSICS, V77, PB167, DOI 10.1190/GEO2011-0063.1
   Gee D.G., 1985, CALEDONIDE OROGEN SC, V0, P109
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Kitzig MC, 2017, EXPLOR GEOPHYS, V48, P344, DOI 10.1071/EG15117
   Lindsey CR, 2018, GEOTHERMICS, V72, P358, DOI 10.1016/j.geothermics.2017.12.009
   Nilsen O., 1981, NGU B, V412, P55
   Novak V., 1999, MATH PRINCIPLES FUZZ, V0, P0
   Olesen O, 2010, PETROL GEOL CONF P, V0, PP559, DOI 10.1144/0070559
   Paasche H, 2011, EXPLOR GEOPHYS, V42, P275, DOI 10.1071/EG11014
   Paasche H, 2009, EXPLOR GEOPHYS, V40, P277, DOI 10.1071/EG08028
   PIRKLE FL, 1984, J INT ASS MATH GEOL, V16, P479, DOI 10.1007/BF01886328
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Thorndike R.L., 1953, PSYCHOMETRIKA, V18, P267, DOI 10.1007/BF02289263
   Wang Y., 2019, 2019034 NGU, V0, P0
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wolff F.C., 1967, NGU B, V245, P0
   Zheng A., 2018, FEATURE ENG MACHINE, V0, P0
NR 25
TC 3
Z9 3
U1 0
U2 1
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0956-540X
EI 1365-246X
J9 GEOPHYS J INT
JI Geophys. J. Int.
PD MAY 15
PY 2021
VL 225
IS 2
BP 1142
EP 1157
DI 10.1093/gji/ggaa571
EA MAR 2021
PG 16
WC Geochemistry & Geophysics
SC Geochemistry & Geophysics
GA RW9VC
UT WOS:000646866900026
DA 2023-04-26
ER

PT J
AU Zhang, XQ
   An, WN
   Sun, JG
   Wu, H
   Zhang, WC
   Du, YH
AF Zhang, Xinqi
   An, Weining
   Sun, Jinggong
   Wu, Hang
   Zhang, Wenchang
   Du, Yaohua
TI Best Representation Branch Model for Remote Sensing Image Scene Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Semantics; Data mining; Residual neural networks; Convolutional neural networks; Remote sensing; Sun; Best representation branch model; deep learning (DL); remote sensing (RS) image; spatial information
ID convolutional neural-network; attention; descriptors; features
AB Remote sensing image scene classification is an important method for understanding the high-resolution remote sensing images. Based on convolutional neural network, various classification methods have been applied into this field and achieved remarkable results. These methods mainly rely on the semantic information to improve the classification performance. However, as the network goes deeper, the highly abstract and global semantic information makes it difficult for the network to accurately classify scene images with similar layout and structures, limiting further improvement of classification accuracy. Relying on the semantic information only is not sufficient to effectively classify these similar scene images and the network needs spatial information to enhance the classification capability. To solve this dilemma, this article proposes a best representation branch model, which reaches the optimal balance point where the network can make use of both the semantic information and spatial information to improve the final classification accuracy. In the proposed method, ResNet50 pretrained on the ImageNet dataset is first divided into four branches with different depths to extract feature maps and a capsule network is used as the classifier. The Grad-CAM algorithm is adopted to explain the mechanism of the optimal balance point from the perspective of attention and guide the further feature fusion. In addition, ablation studies are conducted to prove the effectiveness of our method and extensive experiments are conducted on three public benchmark remote sensing datasets. The results demonstrate that the proposed method can achieve competitive classification performance compared to the state-of-the-art methods.
C1 [Zhang, Xinqi; An, Weining; Wu, Hang; Zhang, Wenchang; Du, Yaohua] Acad Mil Sci, Res Dept Med Support Technol, Tianjin 300161, Peoples R China.
   [Sun, Jinggong] Acad Mil Sci, Inst Syst Engn, Beijing 100171, Peoples R China.
C3 Academy of Military Medical Sciences - China
RP Wu, H (corresponding author), Acad Mil Sci, Res Dept Med Support Technol, Tianjin 300161, Peoples R China.; Sun, JG (corresponding author), Acad Mil Sci, Inst Syst Engn, Beijing 100171, Peoples R China.
EM zhangxinqi_ams@126.com; asdawnasd@163.com; sunjg@vip.sina.com; 2008.wuhang@163.com; zwc0501@163.com; qsyaohua@sina.com
FU Foundation of Tianjin Science and Technology Plan [19YFZCSN01150]; Foundation of National Defense Science and Technology innovation [20-163-12-ZT-006-002-09]; Academy of Military Sciences Equipment Scientific Research [JK20191A010024]; Major Research Program of National Natural Science Foundation of China [91948303]; Tianjin Natural Science Foundation of China [18JCZDJC40300, 19ZXJRGX00080]
CR Alhichri H, 2021, IEEE ACCESS, V9, P14078, DOI 10.1109/ACCESS.2021.3051085
   [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   Bai L, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3078518
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chen C., 2015, SIGNAL IMAGE VIDEO P, V10, P1, DOI 10.1371/J0URNAL.P0NE.0139565
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Guo DE, 2021, IEEE J-STARS, V14, P2508, DOI 10.1109/JSTARS.2021.3056883
   Guo YY, 2019, IEEE ACCESS, V7, P67200, DOI 10.1109/ACCESS.2019.2918732
   Guo ZQ, 2021, IEEE GEOSCI REMOTE S, V18, P964, DOI 10.1109/LGRS.2020.2992661
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu Q, 2013, REMOTE SENS-BASEL, V5, P6026, DOI 10.3390/rs5116026
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jiang XF, 2021, IEEE GEOSCI REMOTE S, V18, P1094, DOI 10.1109/LGRS.2020.2991405
   Karimzadeh S, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20174751
   Li BY, 2020, IEEE GEOSCI REMOTE S, V17, P1687, DOI 10.1109/LGRS.2019.2952660
   Li BY, 2019, IEEE J-STARS, V12, P3508, DOI 10.1109/JSTARS.2019.2934165
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li HC, 2020, IEEE J-STARS, V13, P738, DOI 10.1109/JSTARS.2020.2968930
   Lin C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121397
   Liu XN, 2019, IEEE GEOSCI REMOTE S, V16, P1200, DOI 10.1109/LGRS.2019.2894399
   Liu YF, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030444
   Lu XQ, 2019, IEEE T GEOSCI REMOTE, V57, P7894, DOI 10.1109/TGRS.2019.2917161
   Luo B, 2013, IEEE J-STARS, V6, P1899, DOI 10.1109/JSTARS.2012.2228254
   Mazzia V, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-93977-0
   Mishra DR, 2005, IEEE T GEOSCI REMOTE, V43, P1592, DOI 10.1109/TGRS.2005.847790
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rau JY, 2012, NAT HAZARDS, V61, P469, DOI 10.1007/s11069-011-9929-y
   Sabour S., 2017, DYNAMIC ROUTING CAPS, V0, P0
   Shen Y, 2021, IEEE T GEOSCI REMOTE, V59, P6029, DOI 10.1109/TGRS.2020.3014286
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P82, DOI 10.1109/TGRS.2019.2931801
   Tian T, 2019, INT GEOSCI REMOTE SE, V0, PP525, DOI 10.1109/IGARSS.2019.8898656
   Tong W, 2020, IEEE J-STARS, V13, P4121, DOI 10.1109/JSTARS.2020.3009352
   Wang K, 2010, SENSORS-BASEL, V10, P9647, DOI 10.3390/s101109647
   Wu H, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/8513949
   Wu H, 2016, IEEE GEOSCI REMOTE S, V13, P1895, DOI 10.1109/LGRS.2016.2616440
   Wu H, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050436
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xiang CQ, 2018, IEEE SIGNAL PROC LET, V25, P1850, DOI 10.1109/LSP.2018.2873892
   Xiaohui D, 2021, REMOTE SENS-BASEL, V13, P0
   Xie J, 2019, IEEE T GEOSCI REMOTE, V57, P6916, DOI 10.1109/TGRS.2019.2909695
   Xu K., 1900, DOI 10.1109/LGRS.2021.3075712, V0, P0
   Xu KJ, 2022, IEEE T NEUR NET LEAR, V33, P5751, DOI 10.1109/TNNLS.2021.3071369
   Xu KJ, 2020, IEEE GEOSCI REMOTE S, V17, P1894, DOI 10.1109/LGRS.2019.2960026
   Xue W, 2020, IEEE ACCESS, V8, P28746, DOI 10.1109/ACCESS.2020.2968771
   Xue ZX, 2021, IEEE J-STARS, V14, P3566, DOI 10.1109/JSTARS.2021.3065987
   Yang Y, 2008, IEEE IMAGE PROC, V0, PP1852, DOI 10.1109/ICIP.2008.4712139
   Yu DH, 2020, IEEE J-STARS, V13, P6372, DOI 10.1109/JSTARS.2020.3030257
   Yu YT, 2020, IEEE GEOSCI REMOTE S, V17, P1263, DOI 10.1109/LGRS.2019.2940505
   Yu YL, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/8639367
   Zeng D, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050734
   Zhang W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050494
   Zhao B, 2017, IEEE GEOSCI REMOTE S, V14, P1436, DOI 10.1109/LGRS.2017.2691013
   Zhao LJ, 2014, IEEE J-STARS, V7, P4620, DOI 10.1109/JSTARS.2014.2339842
   Zhao LJ, 2014, INT J REMOTE SENS, V35, P2296, DOI 10.1080/01431161.2014.890762
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
   Zhu QQ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040568
   Zhu QQ, 2016, IEEE GEOSCI REMOTE S, V13, P747, DOI 10.1109/LGRS.2015.2513443
NR 61
TC 7
Z9 7
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9768
EP 9780
DI 10.1109/JSTARS.2021.3114404
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WD3DB
UT WOS:000704824700009
DA 2023-04-26
ER

PT J
AU Adolfs, M
   Hoque, MM
AF Adolfs, Marjolijn
   Hoque, Mohammed Mainul
TI A Neural Network-Based TEC Model Capable of Reproducing Nighttime Winter Anomaly
SO REMOTE SENSING
LA English
DT Article
DE ionosphere; total electron content; nighttime winter anomaly; neural network; NTCM
ID nwa
AB With the availability of fast computing machines, as well as the advancement of machine learning techniques and Big Data algorithms, the development of a more sophisticated total electron content (TEC) model featuring the Nighttime Winter Anomaly (NWA) and other effects is possible and is presented here. The NWA is visible in the Northern Hemisphere for the American sector and in the Southern Hemisphere for the Asian longitude sector under solar minimum conditions. During the NWA, the mean ionization level is found to be higher in the winter nights compared to the summer nights. The approach proposed here is a fully connected neural network (NN) model trained with Global Ionosphere Maps (GIMs) data from the last two solar cycles. The day of year, universal time, geographic longitude, geomagnetic latitude, solar zenith angle, and solar activity proxy, F10.7, were used as the input parameters for the model. The model was tested with independent TEC datasets from the years 2015 and 2020, representing high solar activity (HSA) and low solar activity (LSA) conditions. Our investigation shows that the root mean squared (RMS) deviations are in the order of 6 and 2.5 TEC units during HSA and LSA period, respectively. Additionally, NN model results were compared with another model, the Neustrelitz TEC Model (NTCM). We found that the neural network model outperformed the NTCM by approximately 1 TEC unit. More importantly, the NN model can reproduce the evolution of the NWA effect during low solar activity, whereas the NTCM model cannot reproduce such effect in the TEC variation.
C1 [Adolfs, Marjolijn; Hoque, Mohammed Mainul] German Aerosp Ctr DLR, Inst Solar Terr Phys, Kalkhorstweg 53, D-17235 Neustrelitz, Germany.
C3 Helmholtz Association; German Aerospace Centre (DLR)
RP Adolfs, M (corresponding author), German Aerosp Ctr DLR, Inst Solar Terr Phys, Kalkhorstweg 53, D-17235 Neustrelitz, Germany.
EM Marjolijn.Adolfs@dlr.de
FU German Research Foundation (DFG) [HO 6136/1-1]; Helmholtz Pilot Projects Information & Data Science II from the Initiative and Networking Fund of the Hermann von Helmholtz Association Deutscher Forschungszentren e.V. [ZT-I-0022]; project named 'MAchine learning based Plasma density model' (MAP)
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Adewale AO, 2012, ADV SPACE RES, V50, P415, DOI 10.1016/j.asr.2012.05.006
   Alken P, 2021, EARTH PLANETS SPACE, V73, P0, DOI 10.1186/s40623-020-01288-x
   Balan N, 2018, EARTH PLANET PHYS, V2, P257, DOI 10.26464/epp2018025
   Camporeale E, 2019, SPACE WEATHER, V17, P1166, DOI 10.1029/2018SW002061
   Cesaroni C, 2020, J SPACE WEATHER SPAC, V10, P0, DOI 10.1051/swsc/2020013
   Cherrier N, 2017, LECT NOTES COMPUT SC, V10638, P545, DOI 10.1007/978-3-319-70139-4_55
   Chollet F, 2015, KERAS, V0, P0
   Davies K. P., 1990, IBC 1990. INTERNATIONAL BROADCASTING CONVENTION (CONF. PUBL. NO.327), V0, P1
   European GNSS (Galileo) Open Service, 2016, SIGN SPAC INT CONTR, V0, P0
   Freedman D., 2007, STATISTICS-ABINGDON, V0, P0
   GPS Directorate, 2018, SYST ENG INT NT SPEC, V0, P0
   Hoque MM, 2017, GPS SOLUT, V21, P1563, DOI 10.1007/s10291-017-0632-7
   Hoque MM, 2015, I NAVIG SAT DIV INT, V0, P3755
   Hoque MM, 2015, J GEODESY, V89, P391, DOI 10.1007/s00190-014-0783-z
   Hoque MM, 2008, RADIO SCI, V43, P0, DOI 10.1029/2007RS003817
   Hoque MM, 2019, GPS SOLUT, V23, P0, DOI 10.1007/s10291-019-0833-3
   Hoque MM, 2018, J SPACE WEATHER SPAC, V8, P0, DOI 10.1051/swsc/2018009
   JAKOWSKI N, 1995, PLANET SPACE SCI, V43, P603, DOI 10.1016/0032-0633(94)00115-8
   Jakowski N, 2015, J GEOPHYS RES-SPACE, V120, P9148, DOI 10.1002/2015JA021600
   Jakowski N, 2011, J GEODESY, V85, P965, DOI 10.1007/s00190-011-0455-1
   Jakowski N., 1990, GERLANDS BEITRAEGE ZUR GEOPHYSIK, V99, P163
   Kalogirou SA, 2014, SOLAR ENERGY ENG PRO, V51, P123, DOI 10.1016/B978-0-12-397270-5.00002-9
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   KLOBUCHAR JA, 1987, IEEE T AERO ELEC SYS, V23, P325, DOI 10.1109/TAES.1987.310829
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Machado WC, 2011, I NAVIG SAT DIV INT, V0, P2552
   Nava B, 2008, J ATMOS SOL-TERR PHY, V70, P1856, DOI 10.1016/j.jastp.2008.01.015
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Perez RO, 2019, ADV SPACE RES, V63, P1607, DOI 10.1016/j.asr.2018.11.011
   Ridpath I., 2012, DICT ASTRONOMY, V0, P0
   Schaer S., 1998, P 1998 IGS AN CTR WO, V0, P0
   Shim JS, 2012, SPACE WEATHER, V10, P0, DOI 10.1029/2012SW000851
   Tapping KF, 2013, SPACE WEATHER, V11, P394, DOI 10.1002/swe.20064
   Xiong P, 2021, SPACE WEATHER, V19, P0, DOI 10.1029/2020SW002706
NR 35
TC 5
Z9 5
U1 0
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV 15
PY 2021
VL 13
IS 22
BP 
EP 
DI 10.3390/rs13224559
PG 15
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XH1PA
UT WOS:000725212700001
DA 2023-04-26
ER

PT J
AU Guan, T
   Zhang, GB
   Chen, PY
AF Guan, Tong
   Zhang, Guobing
   Chen, Pengyun
TI A terrain matching navigation algorithm for UAV
SO PROCEEDINGS OF THE 33RD CHINESE CONTROL AND DECISION CONFERENCE (CCDC 2021)
LA English
DT Proceedings Paper
DE PCNN; Nonlinear; Terrain matching; Coupling
AB Terrain matching positioning navigation uses the traditional algorithm to linearize the terrain and compares with the datum terrain. It can provide more accurate positioning, but due to the strong nonlinear characteristics of terrain, in the process of terrain linearization, most of the terrain features are ignored. So the matching result error is relatively large. Because the pulse coupled neural network has the characteristics of neuron's characteristic of linear addition and nonlinear multiplication adjustment coupling, it does not need to establish an accurate mathematical model, and it can better deal with nonlinear problems. Therefore, this paper will explore the application of pulse coupled neural network in terrain matching positioning. Firstly, the distance difference matrix between the prior terrain data and the measured matching terrain is normalized, then the nodes on each matching surface of the topographic map will be searched and summed one by one through the coupling relationship between the similar nodes, and the magnitude of ignition times represents the similarity degree. By selecting different regions and different parameters in the topographic map for simulation, the high-precision performance of the algorithm is verified.
C1 [Guan, Tong; Zhang, Guobing; Chen, Pengyun] North Univ China, Coll Mechatron Engn, Taiyuan 030051, Peoples R China.
C3 North University of China
RP Guan, T (corresponding author), North Univ China, Coll Mechatron Engn, Taiyuan 030051, Peoples R China.
EM 1090112342@qq.com
FU National Nature Science Foundation [51909245, 62003314]; Aeronautical Science Foundation of China [2019020U0002]; Open Fund of Key Laboratory of High Performance Ship Technology (Wuhan University of Technology). Ministry of Education [gxnc19051802]; Scientific and Technological Innovation Programs ofHigher Education Institutions in Shanxi [2019L0537]; Natural Science Foundation of Shanxi Province [201901D211244, 201801D221210, 201801D221038]
CR BURKITTGRAY A, 2001, P 15 CHIN OC SHOR EN, V0, P4
   EROGLU O, 2014, TERRAIN REFERENCED U, V73, P309, DOI 10.1007/S10846-013-9922-7
   Francisco C. T., 2016, AUV TERRAIN AIDED NA, V42, P166
   Gao Yongqi, 2014, JOURNAL OF PROJECTILES, V0, P0
   Hagen OK, 2014, MAR TECHNOL SOC J, V48, P45, DOI 10.4031/MTSJ.48.2.6
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Lucido L., 1998, SEGMENTATION BATHYME, V29, P1157
   Wang J., 2019, INT J CONTROL AUTOMA, V17, P0
   Yao J., 2019, OPTICAL OPTOELECTRON, V17, P10
   Zou Wei, 2017, SHIP ELECT ENG, V37, P5
NR 10
TC 1
Z9 1
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1948-9439
EI 
J9 CHIN CONT DECIS CONF
PD JUN 15
PY 2021
VL 0
IS 
BP 5203
EP 5207
DI 10.1109/CCDC52312.2021.9602743
PG 5
WC Automation & Control Systems
SC Automation & Control Systems
GA BT3XF
UT WOS:000824370105025
DA 2023-04-26
ER

PT J
AU Silva, SA
   Lima, JSS
   Queiroz, DM
   Paiva, AQ
   Medauar, CC
   Santos, RO
AF Silva, Samuel A.
   Lima, Juliao S. S.
   Queiroz, Daniel M.
   Paiva, Arlicelio Q.
   Medauar, Caique C.
   Santos, Railton O.
TI Artificial neural networks in the prediction of soil chemical attributes using apparent electrical conductivity
SO SPANISH JOURNAL OF AGRICULTURAL RESEARCH
LA English
DT Article
DE precision agriculture; computational intelligence; remote sensing; predictive models; digital soil mapping
ID multivariate-analysis; spatial variability
AB Aim of study: To use artificial neural networks (ANN) to predict the values and spatial distribution of soil chemical attributes from apparent soil electrical conductivity (ECa) and soil clay contents. Area of study: The study was carried out in an area of 1.2-ha cultivated with cocoa, located in the state of Bahia, Brazil. Material and methods: Data collections were performed on a sampling grid containing 120 points. Soil samples were collected to determine the attributes: clay, silt, sand, P, K+, Ca2+, Mg2+, S, pH, H+Al, SB, CTC, V, OM and P-rem. ECa was measured using the electrical resistivity method in three different periods related to soil sampling: 60 days before (60ECa), 30 days before (30ECa) and when collecting soil samples (0ECa). For the prediction of chemical and physical-chemical attributes of the soil, models based on ANN were used. As input variables, the ECa and the clay contents were used. The quality of ANN predictions was determined using different statistical indicators. Thematic maps were constructed for the attributes determined in the laboratory and those predicted by the ANNs and the values were grouped using the fuzzy k-means algorithm. The agreement between classes was performed using the kappa coefficient. Main results: Only P and K+ attributes correlated with all ANN input variables. ECa and clay contents in the soil proved to be good variables for predicting soil attributes. Research highlights: The best results in the prediction process of the P and K+ attributes were obtained with the combination of ECa and the clay content.
C1 [Silva, Samuel A.; Lima, Juliao S. S.; Medauar, Caique C.] Univ Fed Espirito Santo, Dept Rural Engn, Alegre, ES, Brazil.
   [Queiroz, Daniel M.] Univ Fed Vicosa, Dept Agr Engn, Vicosa, MG, Brazil.
   [Paiva, Arlicelio Q.; Santos, Railton O.] Univ Estadual Santa Cruz, Post Grad Plant Prod, Ilheus, BA, Brazil.
C3 Universidade Federal do Espirito Santo; Universidade Federal de Vicosa; Universidade Estadual de Santa Cruz
RP Silva, SA (corresponding author), Univ Fed Espirito Santo, Dept Rural Engn, Alegre, ES, Brazil.
EM samuel.assilva@gmail.com
CR Aitkenhead MJ, 2016, GEODERMA, V262, P187, DOI 10.1016/j.geoderma.2015.08.034
   [Anonymous], 1999, NEURAL NETWORKS COMP, V0, P0
   [Anonymous], 2018, SISTEMA BRASILEIRO C, V0, P0
   Blackmore S, 2003, BIOSYST ENG, V84, P455, DOI 10.1016/S1537-5110(03)00038-2
   Bottega E. L., 2017, AUSTRALIAN JOURNAL OF CROP SCIENCE, V11, P573, DOI 10.21475/ajcs.17.11.05.p381
   Braga A.P., 2011, REDES NEURAIS ARTIFI, V0, P0
   Brevik EC, 2006, PRECIS AGRIC, V7, P393, DOI 10.1007/s11119-006-9021-x
   Carvalho Filho R, 1987, B TECNICO, V0, P0
   Chepote R. E., 2013, B TECNICO, Vn203, P1
   Corwin D.L., 2002, METHODS SOIL ANAL PA, V0, P1282
   Corwin DL, 2003, AGRON J, V95, P455, DOI 10.2134/agronj2003.0455
   Daniel KW, 2003, AUST J SOIL RES, V41, P47, DOI 10.1071/SR02027
   dos Santos RO, 2017, REV BRAS ENG AGR AMB, V21, P88, DOI 10.1590/1807-1929/agriambi.v21n2p88-93
   Embrapa (Centro Nacional de Pesquisas de Solos), 2017, MANUAL METODOS ANALI, V0, P0
   Ernani P.R., 2007, FERTILIDADE SOLO, V0, P551
   Fortes R, 2015, PRECIS AGRIC, V16, P441, DOI 10.1007/s11119-015-9388-7
   Leal AJF, 2015, BRAGANTIA, V74, P436, DOI 10.1590/1678-4499.0140
   Grego CR, 2011, REV BRAS CIENC SOLO, V35, P337, DOI 10.1590/S0100-06832011000200005
   Grubbs RA, 2019, PRECIS AGRIC, V20, P496, DOI 10.1007/s11119-018-9593-2
   Guastaferro F, 2010, PRECIS AGRIC, V11, P600, DOI 10.1007/s11119-010-9183-4
   Guo PT, 2013, NUTR CYCL AGROECOSYS, V95, P333, DOI 10.1007/s10705-013-9566-9
   Jafarzadeh AA, 2016, INT J ENVIRON SCI TE, V13, P87, DOI 10.1007/s13762-015-0856-4
   Kitchen NR, 2005, COMPUT ELECTRON AGR, V46, P285, DOI 10.1016/j.compag.2004.11.012
   Kolassa J, 2018, REMOTE SENS ENVIRON, V204, P43, DOI 10.1016/j.rse.2017.10.045
   Koppen W, 1928, KLIMATE RRDE1, V0, P0
   Luck E, 2009, NEAR SURF GEOPHYS, V7, P15, DOI 10.3997/1873-0604.2008031
   Medauar CC, 2020, EMIR J FOOD AGR, V32, P165, DOI 10.9755/ejfa.2020.v32.i3.2083
   Medeiros WN, 2018, REV CIENC AGRON, V49, P43, DOI 10.5935/1806-6690.20180005
   Moral FJ, 2010, SOIL TILL RES, V106, P335, DOI 10.1016/j.still.2009.12.002
   Moral FJ, 2019, PRECIS AGRIC, V20, P1000, DOI 10.1007/s11119-018-09631-9
   Ng W, 2019, GEODERMA, V352, P251, DOI 10.1016/j.geoderma.2019.06.016
   Sanches GM, 2018, SOIL TILL RES, V175, P217, DOI 10.1016/j.still.2017.09.010
   Sanches GM, 2019, SCI AGR, V76, P10, DOI 10.1590/1678-992X-2017-0128
   Serrano JM, 2017, PRECIS AGRIC, V18, P245, DOI 10.1007/s11119-016-9460-y
   Silva I.N., 2010, REDES NEURAIS ARTIFI, V0, P0
   Silva SD, 2014, REV BRAS CIENC SOLO, V38, P1439, DOI 10.1590/S0100-06832014000500009
   Silva Samuel de Assis, 2010, REV. CERES, V57, P560
   Silva SD, 2012, REV BRAS CIENC SOLO, V36, P467, DOI 10.1590/S0100-06832012000200016
   Silva SD, 2010, REV CIENC AGRON, V41, P1, DOI 10.5935/1806-6690.20100001
   Singh G, 2016, AGRONOMY-BASEL, V6, P0, DOI 10.3390/agronomy6040057
   Stadler A, 2015, EUR J AGRON, V64, P8, DOI 10.1016/j.eja.2014.12.004
   Terron JM, 2011, PRECIS AGRIC, V12, P750, DOI 10.1007/s11119-011-9218-5
   Uribeetxebarria A, 2018, GEODERMA, V319, P185, DOI 10.1016/j.geoderma.2018.01.008
   Valckx J, 2009, APPL SOIL ECOL, V41, P315, DOI 10.1016/j.apsoil.2008.12.005
   Valente DSM, 2014, ENG AGR-JABOTICABAL, V34, P1224, DOI 10.1590/S0100-69162014000600017
   WILLMOTT CJ, 1985, J GEOPHYS RES-OCEANS, V90, P8995, DOI 10.1029/JC090iC05p08995
NR 46
TC 0
Z9 0
U1 1
U2 4
PU INST NACIONAL INVESTIGACION & TECNOLOGIA AGRARIA & ALIMENTARIA-INIA-CSIC
PI MADRID
PA CTRA CORUNA KM 7 5, MADRID, 28040, SPAIN
SN 1695-971X
EI 2171-9292
J9 SPAN J AGRIC RES
JI Span. J. Agric. Res.
PD JUN 15
PY 2021
VL 19
IS 3
BP 
EP 
DI 10.5424/sjar/2021193-17600
PG 13
WC Agriculture, Multidisciplinary; Soil Science
SC Agriculture
GA UA1QM
UT WOS:000684940400015
DA 2023-04-26
ER

PT J
AU Du, ZH
   Qi, J
   Wu, SS
   Zhang, F
   Liu, RY
AF Du, Zhenhong
   Qi, Jin
   Wu, Sensen
   Zhang, Feng
   Liu, Renyi
TI A Spatially Weighted Neural Network Based Water Quality Assessment Method for Large-Scale Coastal Areas
SO ENVIRONMENTAL SCIENCE & TECHNOLOGY
LA English
DT Article
DE Water quality assessment; Coastal water quality; Large-scale areas; Remote sensing; Geographically neural network weighted regression; Spatial nonstationarity
AB The accurate assessment of large-scale and complex coastal waters is a grand challenge due to the spatial nonstationarity and complex nonlinearity involved in integrating remote sensing and in situ data. We developed a water quality assessment method based on a newly proposed geographically neural network weighted regression (GNNWR) model to address that challenge and obtained a highly accurate and realistic water quality distribution on the basis of the comprehensive index of Chinese Water Quality Classification Standards. Using geostationary ocean color imager (GOCI) data and observations from 1240 water quality sampling sites, we conducted experiments for a typical large-scale coastal area of the Zhejiang Coastal Sea (ZCS), People's Republic of China. The GNNWR model achieved higher prediction performance (average R-2 = 84%) in comparison to the widely used models, and the obtained water quality classification (WQC) maps in May of 2015-2017 and August 2015 can depict intuitively reasonable spatiotemporal patterns of water quality in the ZCS. Furthermore, an analysis of WQC maps successfully illustrated how terrestrial discharges, anthropogenic activities, and seasonal changes influenced the coastal environment in the ZCS. Finally, we identified essential regions and provided targeted regulatory interventions for them to facilitate the management and restoration of large-scale and complex coastal environments.
C1 [Du, Zhenhong; Qi, Jin; Wu, Sensen; Zhang, Feng; Liu, Renyi] Zhejiang Univ, Sch Earth Sci, Hangzhou 310027, Peoples R China.
   [Du, Zhenhong; Wu, Sensen; Zhang, Feng; Liu, Renyi] Zhejiang Prov Key Lab Geog Informat Sci, Hangzhou 310028, Peoples R China.
C3 Zhejiang University
RP Du, ZH (corresponding author), Zhejiang Univ, Sch Earth Sci, Hangzhou 310027, Peoples R China.; Du, ZH (corresponding author), Zhejiang Prov Key Lab Geog Informat Sci, Hangzhou 310028, Peoples R China.
EM duzhenhong@zju.edu.cn
FU National Natural Science Foundation of China [41922043, 41871287, 42001323]; National Key Research and Development Program of China [2018YFB0505000]; Public Science and Technology Research Funds' Projects of Ocean [201305012, 201505003]; Fundamental Research Funds for the Central Universities from the Ministry of Education of the People's Republic of China [2016XZZX004-02]
CR Aguilera PA, 2001, WATER RES, V35, P4053, DOI 10.1016/S0043-1354(01)00151-8
   Alvarez X, 2017, LAND USE POLICY, V69, P1, DOI 10.1016/j.landusepol.2017.08.028
   [Anonymous], 1997, GB30971997 MIN EC EN, V0, P0
   Bierman P, 2011, ECOL INDIC, V11, P103, DOI 10.1016/j.ecolind.2009.11.001
   Breitburg D, 2018, SCIENCE, V359, P46, DOI 10.1126/science.aam7240
   Chang NB, 2013, REMOTE SENS ENVIRON, V134, P100, DOI 10.1016/j.rse.2013.03.002
   [陈斌 Chen Bin], 2017, 海洋学报 ACTA OCEANOLOGICA SINICA, V39, P96
   Chen CC, 2009, J GEOPHYS RES-OCEANS, V114, P0, DOI 10.1029/2008JC004891
   Chen J, 2019, ENVIRON INT, V130, P0, DOI 10.1016/j.envint.2019.104934
   Chen SL, 2017, REMOTE SENS ENVIRON, V201, P115, DOI 10.1016/j.rse.2017.09.004
   Choi JK, 2014, REMOTE SENS ENVIRON, V146, P24, DOI 10.1016/j.rse.2013.05.032
   Diaz RJ, 2008, SCIENCE, V321, P926, DOI 10.1126/science.1156401
   Du ZH, 2020, INT J GEOGR INF SCI, V34, P1353, DOI 10.1080/13658816.2019.1707834
   Du ZH, 2018, INT J GEOGR INF SCI, V32, P1927, DOI 10.1080/13658816.2018.1471607
   Du ZH, 2018, ECOL INFORM, V43, P185, DOI 10.1016/j.ecoinf.2017.12.005
   Harvey ET, 2015, REMOTE SENS ENVIRON, V158, P417, DOI 10.1016/j.rse.2014.11.017
   He XQ, 2013, REMOTE SENS ENVIRON, V133, P225, DOI 10.1016/j.rse.2013.01.023
   He Yuefeng, 2018, JOURNAL OF ZHEJIANG UNIVERSITY (SCIENCE EDITION), V45, P234, DOI 10.3785/j.issn.1008-9497.2018.02.014
   Hering D, 2010, SCI TOTAL ENVIRON, V408, P4007, DOI 10.1016/j.scitotenv.2010.05.031
   Ioannou I, 2011, APPL OPTICS, V50, P3168, DOI 10.1364/AO.50.003168
   IOCCG, 2000, REMOTE SENSING OCEAN, V0, P0
   Jha DK, 2015, MAR POLLUT BULL, V100, P555, DOI 10.1016/j.marpolbul.2015.08.032
   Jiang Q, 2019, LIMNOL OCEANOGR, V64, P3, DOI 10.1002/lno.11013
   Jiang ZB, 2015, CONT SHELF RES, V101, P71, DOI 10.1016/j.csr.2015.04.009
   LANDWEHR JM, 1976, J WATER POLLUT CON F, V48, P954
   Le CF, 2011, REMOTE SENS ENVIRON, V115, P725, DOI 10.1016/j.rse.2010.10.014
   Lei GB, 2016, ACTA OCEANOL SIN, V35, P114, DOI 10.1007/s13131-016-0802-4
   [李冠男 Li Guannan], 2014, 海洋环境科学 MARINE ENVIRONMENTAL SCIENCE, V33, P966
   Li P., 2014, J MARINE SCI, V03, P16
   Li T, 2018, SCI TOTAL ENVIRON, V628-629, P1446, DOI 10.1016/j.scitotenv.2018.02.163
   Lou X., 2012, P SPIE, V0, P0
   Massi L, 2019, OCEANOLOGIA, V61, P445, DOI 10.1016/j.oceano.2019.04.001
   Nazeer M, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6110360
   Nazeer M, 2016, J HYDROL, V541, P1119, DOI 10.1016/j.jhydrol.2016.08.020
   Nourisson DH, 2013, ECOL INFORM, V14, P79, DOI 10.1016/j.ecoinf.2012.11.011
   Oliveira EN, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.026003
   Pan D, 2006, P SPIE, V6406F, P0
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Qin MJ, 2017, KNOWL-BASED SYST, V125, P39, DOI 10.1016/j.knosys.2017.03.027
   Ryu Joo-Hyung, 2012, OCEAN SCIENCE JOURNAL, V47, P223, DOI 10.1007/s12601-012-0024-4
   Ryu Joo-Hyung, 2012, OCEAN SCIENCE JOURNAL, V47, P221, DOI 10.1007/s12601-012-0023-5
   Shi XiaoYong, 2013, OCEANOLOGIA ET LIMNOLOGIA SINICA / HAI YANG YU HU CHAO, V44, P1208
   Tong YD, 2017, J HAZARD MATER, V321, P728, DOI 10.1016/j.jhazmat.2016.09.011
   Tu J, 2011, APPL GEOGR, V31, P376, DOI 10.1016/j.apgeog.2010.08.001
   Wan YS, 2017, WATER RES, V115, P180, DOI 10.1016/j.watres.2017.02.068
   Wang DF, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121896
   Wang MH, 2013, OPT EXPRESS, V21, P3835, DOI 10.1364/OE.21.003835
   WANG MH, 1994, REMOTE SENS ENVIRON, V50, P231, DOI 10.1016/0034-4257(94)90073-6
   Wang Y, 2015, INT J ENV RES PUB HE, V12, P5420, DOI 10.3390/ijerph120505420
   Whitehouse BG, 2006, RE S D I PR, V9, P201, DOI 10.1007/1-4020-3968-9_9
   Yacobi YZ, 2011, WATER RES, V45, P2428, DOI 10.1016/j.watres.2011.02.002
   Zhang F, 2017, ENVIRON MODELL SOFTW, V96, P128, DOI 10.1016/j.envsoft.2017.06.052
   Zhao BF, 2018, CHEMOSPHERE, V212, P1163, DOI 10.1016/j.chemosphere.2018.09.020
   Zhu GH, 2013, APPL MECH MATER, V316-317, P395, DOI 10.4028/www.scientific.net/AMM.316-317.395
NR 54
TC 11
Z9 11
U1 19
U2 88
PU AMER CHEMICAL SOC
PI WASHINGTON
PA 1155 16TH ST, NW, WASHINGTON, DC 20036 USA
SN 0013-936X
EI 1520-5851
J9 ENVIRON SCI TECHNOL
JI Environ. Sci. Technol.
PD FEB 16
PY 2021
VL 55
IS 4
BP 2553
EP 2563
DI 10.1021/acs.est.0c05928
EA JAN 2021
PG 11
WC Engineering, Environmental; Environmental Sciences
SC Engineering; Environmental Sciences & Ecology
GA QL2QT
UT WOS:000620926800036
PM 33507073
DA 2023-04-26
ER

PT J
AU Gallo, I
   La Grassa, R
   Landro, N
   Boschetti, M
AF Gallo, Ignazio
   La Grassa, Riccardo
   Landro, Nicola
   Boschetti, Mirco
TI Sentinel 2 Time Series Analysis with 3D Feature Pyramid Network and Time Domain Class Activation Intervals for Crop Mapping
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE convolutional neural networks; Sentinel-2 satellite images; 3D feature pyramid network; time domain class activation intervals; time series
AB In this paper, we provide an innovative contribution in the research domain dedicated to crop mapping by exploiting the of Sentinel-2 satellite images time series, with the specific aim to extract information on "where and when" crops are grown. The final goal is to set up a workflow able to reliably identify (classify) the different crops that are grown in a given area by exploiting an end-to-end (3+2)D convolutional neural network (CNN) for semantic segmentation. The method also has the ambition to provide information, at pixel level, regarding the period in which a given crop is cultivated during the season. To this end, we propose a solution called Class Activation Interval (CAI) which allows us to interpret, for each pixel, the reasoning made by CNN in the classification determining in which time interval, of the input time series, the class is likely to be present or not. Our experiments, using a public domain dataset, show that the approach is able to accurately detect crop classes with an overall accuracy of about 93% and that the network can detect discriminatory time intervals in which crop is cultivated. These results have twofold importance: (i) demonstrate the ability of the network to correctly interpret the investigated physical process (i.e., bare soil condition, plant growth, senescence and harvesting according to specific cultivated variety) and (ii) provide further information to the end-user (e.g., the presence of crops and its temporal dynamics).
C1 [Gallo, Ignazio; La Grassa, Riccardo; Landro, Nicola] Univ Insubria, Dept Theoret & Appl Sci, Via O Rossi 9, I-21100 Varese, Italy.
   [Boschetti, Mirco] IREA CNR, Via Corti 12, I-20133 Milan, Italy.
C3 University of Insubria; Consiglio Nazionale delle Ricerche (CNR); Istituto Per Il Rilevamento Elettromagnetico Dell'Ambiente (IREA-CNR)
RP Gallo, I (corresponding author), Univ Insubria, Dept Theoret & Appl Sci, Via O Rossi 9, I-21100 Varese, Italy.
EM ignazio.gallo@uninsubria.it; rlagrassa@uninsubria.it; nlandro@uninsubria.it; boschetti.m@irea.cnr.it
CR [Anonymous], 2021, SENTINEL DATAFLOW CO, V0, P0
   Burceanu E, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P495
   Cui Y., 2019, P IEEE C COMP VIS PA, V0, P0
   Feichtenhofer C, 2016, PROC CVPR IEEE, V0, PP1933, DOI 10.1109/CVPR.2016.213
   Gallo I., 2021, PYTORCH SOURCE CODE, V0, P0
   Hara K, 2018, PROC CVPR IEEE, V0, PP6546, DOI 10.1109/CVPR.2018.00685
   Isensee F., 2019, ARXIV2019190408128 ARXIV2019190408128, V0, P0
   Kirillov A, 2019, PROC CVPR IEEE, V0, PP6392, DOI 10.1109/CVPR.2019.00656
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu J., 2019, ARXIV2019190711704 ARXIV2019190711704, V0, P0
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Qiu Y, 2017, IEEE ICC, V0, P0
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Ru&beta;wurm M.K.M., 2018, MUNICH DATASET, V0, P0
   Russwurm M, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7040129
   Seferbekov S, 2018, IEEE COMPUT SOC CONF, V0, PP272, DOI 10.1109/CVPRW.2018.00051
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, V0, PP618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2014, ADV NEUR IN, V27, P0
   Sochor J, 2016, PROC CVPR IEEE, V0, PP3006, DOI 10.1109/CVPR.2016.328
   Tran D, 2018, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2018.00675
   Zhou B., 2014, ARXIV201414126856 ARXIV201414126856, V0, P0
   Zhou B, 2016, PROC CVPR IEEE, V0, PP2921, DOI 10.1109/CVPR.2016.319
   Zhu L., 2018, P EUR C COMP VIS ECC P EUR C COMP VIS ECC, V0, P121
NR 25
TC 5
Z9 5
U1 3
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD JUL 15
PY 2021
VL 10
IS 7
BP 
EP 
DI 10.3390/ijgi10070483
PG 14
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA TN7VH
UT WOS:000676437600001
DA 2023-04-26
ER

PT J
AU Guo, HN
   Su, X
   Tang, SK
   Du, B
   Zhang, LP
AF Guo, Haonan
   Su, Xin
   Tang, Shengkun
   Du, Bo
   Zhang, Liangpei
TI Scale-Robust Deep-Supervision Network for Mapping Building Footprints From High-Resolution Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Buildings; Feature extraction; Architecture; Computer architecture; Remote sensing; Decoding; Semantics; Building footprint extraction; convolutional neural network; deep learning; remote sensing image
ID convolutional neural-network; extraction; classification; index
AB Building footprint information is one of the key factors for sustainable urban planning and environmental monitoring. Mapping building footprints from remote sensing images is an important and challenging task in the earth observation field. Over the years, convolutional neural networks have shown outstanding improvements in the building extraction field due to their ability to automatically extract hierarchical features and make building predictions. However, as buildings are various in different sizes, scenes, and roofing materials, it is hard to precisely depict buildings of varied sizes, especially in large areas (e.g., nationwide). To tackle these limitations, we propose a novel deep-supervision convolutional neural network (denoted as DS-Net) for extracting building footprints from high-resolution remote sensing images. In the proposed network, we applied deep supervision with an extra lightweight encoder, which enables the network to learn representative building features of different scales. Furthermore, a scale attention module is designed to aggregate multiscale features and generate the final building prediction. Experiments on two publicly available building datasets, including the WHU Building Dataset and the Massachusetts Building Dataset, show the effectiveness of the proposed method. With only a 0.22-M increment of parameters compared with U-Net, the proposed DS-Net achieved an IoU of 90.4% on the WHU Building Dataset and 73.8% on the Massachusetts Dataset. DS-Net also outperforms the state-of-the-art building extraction methods on the two datasets, indicating the effectiveness of the proposed deep supervision and scale attention.
C1 [Guo, Haonan; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Su, Xin; Tang, Shengkun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Du, Bo] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Inst Artificial Intelligence, Wuhan 430079, Peoples R China.
   [Du, Bo] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University; Wuhan University
RP Su, X (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM guohnwhu@163.com; xinsu.rs@whu.edu.cn; shengkuntang@whu.edu.cn; gunspace@163.com; zlp62@whu.edu.cn
FU Chang'an University, Xi'an, China, through the National Key Research and Development Program of China [2020YFC1512000]; National Natural Science Foundation of China [61801332]
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bittner K, 2018, IEEE J-STARS, V11, P2615, DOI 10.1109/JSTARS.2018.2849363
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Dong YN, 2022, IEEE T CYBERNETICS, V52, P11093, DOI 10.1109/TCYB.2021.3070909
   Dong YN, 2021, IEEE T CYBERNETICS, V51, P3185, DOI 10.1109/TCYB.2020.3004263
   Guo HN, 2021, REMOTE SENS ENVIRON, V264, P0, DOI 10.1016/j.rse.2021.112589
   Guo HN, 2021, IEEE T GEOSCI REMOTE, V59, P4287, DOI 10.1109/TGRS.2020.3014312
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Huang X, 2012, IEEE J-STARS, V5, P161, DOI 10.1109/JSTARS.2011.2168195
   Huang X, 2011, PHOTOGRAMM ENG REM S, V77, P721, DOI 10.14358/PERS.77.7.721
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang X, 2021, IEEE J-STARS, V14, P2699, DOI 10.1109/JSTARS.2020.3017934
   King DB, 2015, ACS SYM SER, V1214, P1
   Li L, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091350
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Liu H, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202380
   Liu M., 2021, INT J OCCUP SAF ERGO, V0, PP1, DOI 10.1109/TGRS.2021.3091758
   Liu PH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070830
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI 10.1109/TGRS.2020.3018879
   Liu YY, 2021, IEEE T GEOSCI REMOTE, V59, P6106, DOI 10.1109/TGRS.2020.3022410
   Liu ZJ, 2005, INT GEOSCI REMOTE SE, V0, P2250
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi Q, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3085870
   Shi Q, 2021, IEEE T GEOSCI REMOTE, V59, P10348, DOI 10.1109/TGRS.2020.3045273
   Shi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1430, DOI 10.1109/LGRS.2019.2947473
   Shi YL, 2020, ISPRS J PHOTOGRAMM, V159, P184, DOI 10.1016/j.isprsjprs.2019.11.004
   Shrestha S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071135
   Sun GY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030227
   Sun K, 2019, PROC CVPR IEEE, V0, PP5686, DOI 10.1109/CVPR.2019.00584
   Volodymyr M, 2013, MACHINE LEARNING AER, V0, P0
   Wei SQ, 2020, IEEE T GEOSCI REMOTE, V58, P2178, DOI 10.1109/TGRS.2019.2954461
   Xie YK, 2020, IEEE J-STARS, V13, P1842, DOI 10.1109/JSTARS.2020.2991391
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010144
   Yu YT, 2021, IEEE GEOSCI REMOTE S, V18, P895, DOI 10.1109/LGRS.2020.2986380
   Zha Y, 2003, INT J REMOTE SENS, V24, P583, DOI 10.1080/01431160304987
   Zhang HY, 2022, IEEE T NEUR NET LEAR, V33, P1269, DOI 10.1109/TNNLS.2020.3041646
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang T, 2017, IEEE J-STARS, V10, P3265, DOI 10.1109/JSTARS.2017.2669217
   Zheng Z, 2021, ISPRS J PHOTOGRAMM, V174, P254, DOI 10.1016/j.isprsjprs.2020.12.009
   Zhu Q, 2021, IEEE T GEOSCI REMOTE, V59, P6169, DOI 10.1109/TGRS.2020.3026051
NR 43
TC 10
Z9 10
U1 5
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10091
EP 10100
DI 10.1109/JSTARS.2021.3109237
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WH1JB
UT WOS:000707442300011
DA 2023-04-26
ER

PT J
AU Xiao, XX
   Liang, SL
   He, T
   Wu, DQ
   Pei, CY
   Gong, JY
AF Xiao, Xiongxin
   Liang, Shunlin
   He, Tao
   Wu, Daiqiang
   Pei, Congyuan
   Gong, Jianya
TI Estimating fractional snow cover from passive microwave brightness temperature data using MODIS snow cover product over North America
SO CRYOSPHERE
LA English
DT Article
ID adaptive regression splines; remote-sensing data; random forest; water equivalent; accuracy assessment; image classification; sample selection; mapping accuracy; tibetan plateau; depth
AB The dynamic characteristics of seasonal snow cover are critical for hydrology management, the climate system, and the ecosystem functions. Optical satellite remote sensing has proven to be an effective tool for monitoring global and regional variations in snow cover. However, accurately capturing the characteristics of snow dynamics at a finer spatiotemporal resolution continues to be problematic as observations from optical satellite sensors are greatly impacted by clouds and solar illumination. Traditional methods of mapping snow cover from passive microwave data only provide binary information at a spatial resolution of 25 km. This innovative study applies the random forest regression technique to enhanced-resolution passive microwave brightness temperature data (6.25 km) to estimate fractional snow cover over North America in winter months (January and February). Many influential factors, including land cover, topography, and location information, were incorporated into the retrieval models. Moderate Resolution Imaging Spectro-radiometer (MODIS) snow cover products between 2008 and 2017 were used to create the reference fractional snow cover data as the "true" observations in this study. Although over-estimating and underestimating around two extreme values of fractional snow cover, the proposed retrieval algorithm outperformed the other three approaches (linear regression, artificial neural networks, and multivariate adaptive regression splines) using independent test data for all land cover classes with higher accuracy and no out-of-range estimated values. The method enabled the evaluation of the estimated fractional snow cover using independent datasets, in which the root mean square error of evaluation results ranged from 0.189 to 0.221. The snow cover detection capability of the proposed algorithm was validated using meteorological station observations with more than 310 000 records. We found that binary snow cover obtained from the estimated fractional snow cover was in good agreement with ground measurements (kappa: 0.67). There was significant improvement in the accuracy of snow cover identification using our algorithm; the overall accuracy increased by 18% (from 0.71 to 0.84), and the omission error was reduced by 71% (from 0.48 to 0.14) when the threshold of fractional snow cover was 0.3. The experimental results show that passive microwave brightness temperature data may potentially be used to estimate fractional snow cover directly in that this retrieval strategy offers a competitive advantage in snow cover detection.
C1 [Xiao, Xiongxin; He, Tao; Wu, Daiqiang; Pei, Congyuan; Gong, Jianya] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Liang, Shunlin] Univ Maryland, Dept Geog Sci, College Pk, MD 20742 USA.
C3 Wuhan University; University System of Maryland; University of Maryland College Park
RP He, T (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM taohers@whu.edu.cn
FU National Natural Science Foundation of China [42090012, 41771379]; National Key Research and Development Program of China [2016YFA0600103]
CR [Anonymous], 2009, J REMOTE SENSING SOC, V0, P0
   [Anonymous], 1987, ANN GLACIOL, V0, P0
   [Anonymous], 1900, DOI 10.7289/V5C8276M, V0, P0
   [Anonymous], 1900, DOI 10.5067/MODIS/MOD10A1.006, V0, P0
   [Anonymous], 1900, DOI 10.7289/V5D21VHZ, V0, P0
   Arsenault KR, 2014, HYDROL PROCESS, V28, P980, DOI 10.1002/hyp.9636
   Barnett TP, 2005, NATURE, V438, P303, DOI 10.1038/nature04141
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Berman EE, 2018, REMOTE SENS ENVIRON, V216, P635, DOI 10.1016/j.rse.2018.07.029
   Bormann KJ, 2018, NAT CLIM CHANGE, V8, P923, DOI 10.1038/s41558-018-0318-3
   Brodzik MJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111793
   Brown RD, 2013, ENVIRON RES LETT, V8, P0, DOI 10.1088/1748-9326/8/2/024006
   Brown R, 2010, J GEOPHYS RES-ATMOS, V115, P0, DOI 10.1029/2010JD013975
   Che T, 2016, REMOTE SENS ENVIRON, V183, P334, DOI 10.1016/j.rse.2016.06.005
   Che T, 2008, ANN GLACIOL-SER, V49, P145, DOI 10.3189/172756408787814690
   Chen XN, 2018, REMOTE SENS ENVIRON, V215, P284, DOI 10.1016/j.rse.2018.06.021
   Cheng ZL, 2019, RENEW SUST ENERG REV, V116, P0, DOI 10.1016/j.rser.2019.109428
   Cohen J, 2015, IEEE T GEOSCI REMOTE, V53, P6593, DOI 10.1109/TGRS.2015.2444422
   Coll J, 2018, ISPRS J PHOTOGRAMM, V144, P435, DOI 10.1016/j.isprsjprs.2018.08.004
   Czyzowska-Wisniewski EH, 2015, REMOTE SENS ENVIRON, V156, P403, DOI 10.1016/j.rse.2014.09.026
   Dai LY, 2017, CRYOSPHERE, V11, P1933, DOI 10.5194/tc-11-1933-2017
   Dai LY, 2012, REMOTE SENS ENVIRON, V127, P14, DOI 10.1016/j.rse.2011.08.029
   De Lannoy GJM, 2012, WATER RESOUR RES, V48, P0, DOI 10.1029/2011WR010588
   Derksen C, 2000, REMOTE SENS ENVIRON, V71, P297, DOI 10.1016/S0034-4257(99)00084-X
   Dietz AJ, 2012, INT J REMOTE SENS, V33, P4094, DOI 10.1080/01431161.2011.640964
   Dobreva ID, 2011, REMOTE SENS ENVIRON, V115, P3355, DOI 10.1016/j.rse.2011.07.018
   Dong CY, 2016, REMOTE SENS ENVIRON, V186, P439, DOI 10.1016/j.rse.2016.09.019
   Dong JR, 2014, J HYDROMETEOROL, V15, P551, DOI 10.1175/JHM-D-13-060.1
   Du PJ, 2015, ISPRS J PHOTOGRAMM, V105, P38, DOI 10.1016/j.isprsjprs.2015.03.002
   Flanner MG, 2011, NAT GEOSCI, V4, P151, DOI 10.1038/NGEO1062
   Foody GM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111630
   Foster JL, 2011, INT J REMOTE SENS, V32, P1371, DOI 10.1080/01431160903548013
   Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261
   FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963
   Gafurov A, 2009, HYDROL EARTH SYST SC, V13, P1361, DOI 10.5194/hess-13-1361-2009
   Gao J, 2019, NATURE, V565, P19, DOI 10.1038/d41586-018-07838-4
   Gascoin S, 2015, HYDROL EARTH SYST SC, V19, P2337, DOI 10.5194/hess-19-2337-2015
   Gascoin S, 2019, EARTH SYST SCI DATA, V11, P493, DOI 10.5194/essd-11-493-2019
   Grippa M, 2004, REMOTE SENS ENVIRON, V93, P30, DOI 10.1016/j.rse.2004.06.012
   Grody NC, 1996, IEEE T GEOSCI REMOTE, V34, P237, DOI 10.1109/36.481908
   Hall D. K., 2016, **DATA OBJECT**, V0, P0, DOI DOI 10.5067/MODIS/MYD10A1.006
   Hall D. K., 2001, ALGORITHM THEORETICA, V0, P0
   Hall DK, 1998, REMOTE SENS ENVIRON, V66, P129, DOI 10.1016/S0034-4257(98)00051-0
   HALL DK, 1995, REMOTE SENS ENVIRON, V54, P127, DOI 10.1016/0034-4257(95)00137-P
   Hall DK, 2007, HYDROL PROCESS, V21, P1534, DOI 10.1002/hyp.6715
   Han ML, 2015, IEEE T GEOSCI REMOTE, V53, P2775, DOI 10.1109/TGRS.2014.2364823
   Hao SR, 2019, IEEE J-STARS, V12, P533, DOI 10.1109/JSTARS.2018.2879666
   Hao XH, 2019, INT J DIGIT EARTH, V12, P375, DOI 10.1080/17538947.2017.1421721
   Haykin S., 2009, NEURAL NETWORKS LEAR, V3rd ed., P0
   He T, 2014, J GEOPHYS RES-ATMOS, V119, P0, DOI 10.1002/2014JD021667
   Hecht-Nielsen R, 1992, NEURAL NETWORKS PERC, V0, PP65, DOI 10.1016/B978-0-12-741252-8.50010-8
   Henderson GR, 2018, NAT CLIM CHANGE, V8, P954, DOI 10.1038/s41558-018-0295-6
   Tran H, 2019, SCI DATA, V6, P0, DOI 10.1038/sdata.2018.300
   Hori M, 2017, REMOTE SENS ENVIRON, V191, P402, DOI 10.1016/j.rse.2017.01.023
   Huang XD, 2016, CRYOSPHERE, V10, P2453, DOI 10.5194/tc-10-2453-2016
   Huang Y, 2018, REMOTE SENS ENVIRON, V204, P568, DOI 10.1016/j.rse.2017.10.001
   Jin HR, 2014, INT J REMOTE SENS, V35, P2067, DOI 10.1080/01431161.2014.885152
   Josberger EG, 2002, HYDROL PROCESS, V16, P1557, DOI 10.1002/hyp.1020
   Kattenborn T, 2019, REMOTE SENS ENVIRON, V227, P61, DOI 10.1016/j.rse.2019.03.025
   Kim RS, 2019, REMOTE SENS ENVIRON, V226, P1, DOI 10.1016/j.rse.2019.03.016
   Kim RS, 2018, REMOTE SENS ENVIRON, V205, P469, DOI 10.1016/j.rse.2017.07.025
   Kostadinov TS, 2015, REMOTE SENS ENVIRON, V164, P155, DOI 10.1016/j.rse.2015.04.002
   Kuter S, 2018, REMOTE SENS ENVIRON, V205, P236, DOI 10.1016/j.rse.2017.11.021
   Kuter S, 2015, INVERSE PROBL SCI EN, V23, P651, DOI 10.1080/17415977.2014.933828
   Lemmetyinen J, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020170
   [李晓静 Li Xiaojing], 2007, 应用气象学报 JOURNAL OF APPLIED METEOROLGICAL SCIENCE, V18, P12
   Liang H, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121332
   Liu XJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040524
   Long DG, 2016, IEEE T GEOSCI REMOTE, V54, P2763, DOI 10.1109/TGRS.2015.2505677
   Luojus K, 2018, INT GEOSCI REMOTE SE, V0, P6255
   Lyons MB, 2018, REMOTE SENS ENVIRON, V208, P145, DOI 10.1016/j.rse.2018.02.026
   Marchane A, 2015, REMOTE SENS ENVIRON, V160, P72, DOI 10.1016/j.rse.2015.01.002
   Masson T, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040619
   Menne MJ, 2012, J ATMOS OCEAN TECH, V29, P897, DOI 10.1175/JTECH-D-11-00103.1
   Metsamaki SJ, 2005, REMOTE SENS ENVIRON, V95, P77, DOI 10.1016/j.rse.2004.11.013
   Millard K, 2015, REMOTE SENS-BASEL, V7, P8489, DOI 10.3390/rs70708489
   Moosavi V, 2014, J HYDROL, V511, P160, DOI 10.1016/j.jhydrol.2014.01.015
   Mutanga O, 2012, INT J APPL EARTH OBS, V18, P399, DOI 10.1016/j.jag.2012.03.012
   NEALE CMU, 1990, IEEE T GEOSCI REMOTE, V28, P829, DOI 10.1109/36.58970
   Nguyen LH, 2020, REMOTE SENS ENVIRON, V238, P0, DOI 10.1016/j.rse.2018.12.016
   Pan JM, 2012, INT GEOSCI REMOTE SE, V0, PP4863, DOI 10.1109/IGARSS.2012.6352523
   Pan M, 2014, REMOTE SENS ENVIRON, V140, P130, DOI 10.1016/j.rse.2013.08.020
   Parajka J, 2008, WATER RESOUR RES, V44, P0, DOI 10.1029/2007WR006204
   Parajka J, 2006, HYDROL EARTH SYST SC, V10, P679, DOI 10.5194/hess-10-679-2006
   Parajka J, 2012, HYDROL EARTH SYST SC, V16, P2365, DOI 10.5194/hess-16-2365-2012
   Peng G, 2013, EARTH SYST SCI DATA, V5, P311, DOI 10.5194/essd-5-311-2013
   Qu YQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060683
   Quiros E, 2009, SENSORS-BASEL, V9, P9011, DOI 10.3390/s91109011
   Revuelto J, 2014, CRYOSPHERE, V8, P1989, DOI 10.5194/tc-8-1989-2014
   Riggs G. A., 2006, MODIS SNOW PRODUCTS, V0, P0
   Riggs GA, 2017, EARTH SYST SCI DATA, V9, P765, DOI 10.5194/essd-9-765-2017
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Colditz RR, 2015, REMOTE SENS-BASEL, V7, P9655, DOI 10.3390/rs70809655
   Romanov P, 2007, REMOTE SENS ENVIRON, V108, P97, DOI 10.1016/j.rse.2006.11.013
   Rosenthal W, 1996, WATER RESOUR RES, V32, P115, DOI 10.1029/95WR02718
   Saberi N., 2019, SNOW PROPERTIES RETR, V0, P0
   Salomonson VV, 2006, IEEE T GEOSCI REMOTE, V44, P1747, DOI 10.1109/TGRS.2006.876029
   Salomonson VV, 2004, REMOTE SENS ENVIRON, V89, P351, DOI 10.1016/j.rse.2003.10.016
   Savoie MH, 2009, REMOTE SENS ENVIRON, V113, P2661, DOI 10.1016/j.rse.2009.08.006
   Singh PR, 2000, REMOTE SENS ENVIRON, V74, P275, DOI 10.1016/S0034-4257(00)00121-8
   Smith T, 2016, REMOTE SENS ENVIRON, V181, P174, DOI 10.1016/j.rse.2016.03.037
   Sturm M, 2015, WATER RESOUR RES, V51, P4948, DOI 10.1002/2015WR017242
   Sturm M, 2010, J HYDROMETEOROL, V11, P1380, DOI 10.1175/2010JHM1202.1
   Sulla-Menashe D., 2018, USE GUIDE COLLECTION, V0, P0
   Takala M, 2011, REMOTE SENS ENVIRON, V115, P3517, DOI 10.1016/j.rse.2011.08.014
   Tedesco M, 2004, REMOTE SENS ENVIRON, V90, P76, DOI 10.1016/j.rse.2003.12.002
   Tedesco M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8121037
   Tsai YLS, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080895
   Wang GX, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9100983
   Wang XW, 2008, REMOTE SENS ENVIRON, V112, P1497, DOI 10.1016/j.rse.2007.05.016
   Wang YL, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111268
   Wei J, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111221
   Wiesmann A, 1999, REMOTE SENS ENVIRON, V70, P307, DOI 10.1016/S0034-4257(99)00046-2
   Witten IH, 2011, MOR KAUF D, V0, P1
   Wolfe RE, 2002, REMOTE SENS ENVIRON, V83, P31, DOI 10.1016/S0034-4257(02)00085-8
   Xiao XX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172728
   Xiao XX, 2018, REMOTE SENS ENVIRON, V210, P48, DOI 10.1016/j.rse.2018.03.008
   Xin QC, 2012, REMOTE SENS ENVIRON, V118, P50, DOI 10.1016/j.rse.2011.10.029
   Xu XC, 2016, REMOTE SENS ENVIRON, V182, P227, DOI 10.1016/j.rse.2016.05.010
   Yu JY, 2016, IEEE T GEOSCI REMOTE, V54, P2171, DOI 10.1109/TGRS.2015.2496950
   Zhang HB, 2019, SCI TOTAL ENVIRON, V651, P2712, DOI 10.1016/j.scitotenv.2018.10.128
   Zhang TJ, 2005, REV GEOPHYS, V43, P0, DOI 10.1029/2004RG000157
   Zhang WG, 2016, GEOSCI FRONT, V7, P45, DOI 10.1016/j.gsf.2014.10.003
   Zhao W, 2019, ISPRS J PHOTOGRAMM, V152, P109, DOI 10.1016/j.isprsjprs.2019.04.008
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zona D, 2016, P NATL ACAD SCI USA, V113, P40, DOI 10.1073/pnas.1516017113
NR 127
TC 5
Z9 5
U1 9
U2 28
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1994-0416
EI 1994-0424
J9 CRYOSPHERE
JI Cryosphere
PD FEB 18
PY 2021
VL 15
IS 2
BP 835
EP 861
DI 10.5194/tc-15-835-2021
PG 27
WC Geography, Physical; Geosciences, Multidisciplinary
SC Physical Geography; Geology
GA QL9EK
UT WOS:000621382900001
DA 2023-04-26
ER

PT J
AU Polewski, P
   Shelton, J
   Yao, W
   Heurich, M
AF Polewski, Przemyslaw
   Shelton, Jacquelyn
   Yao, Wei
   Heurich, Marco
TI Instance segmentation of fallen trees in aerial color infrared imagery using active multi-contour evolution with fully convolutional network-based intensity priors
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE simulated annealing; U-net; sample consensus; precision forestry; energy minimization
ID optimization; minimization; algorithms; mortality
AB Over the last several years, semantic image segmentation based on deep neural networks has been greatly advanced. On the other hand, single-instance segmentation still remains a challenging problem. In this paper, we introduce a framework for segmenting instances of a common object class by multiple active contour evolution over semantic segmentation maps of images obtained through fully convolutional networks. The contour evolution is cast as an energy minimization problem, where the aggregate energy functional incorporates a data fit term, an explicit shape model, and accounts for object overlap. Efficient solution neighborhood operators are proposed, enabling optimization through metaheuristics such as simulated annealing. We instantiate the proposed framework in the context of segmenting individual fallen stems from high-resolution aerial multispectral imagery, providing problem-specific energy potentials. We validated our approach on 3 real-world scenes of varying complexity, using 730 manually labeled polygon outlines as ground truth. The test plots were situated in regions of the Bavarian Forest National Park, Germany, which sustained a heavy bark beetle infestation. Evaluations were performed on both the polygon and line segment level, showing that the multi-contour segmentation can achieve up to 0.93 precision and 0.82 recall. An improvement of up to 7 percentage points (pp) in recall and 6 in precision compared to an iterative sample consensus line segment detection baseline was achieved. Despite the simplicity of the applied shape parametrization, an explicit shape model incorporated into the energy function improved the results by up to 4 pp of recall. Finally, we show the importance of using a high-quality semantic segmentation method (e.g. U-net) as the basis for individual stem detection, as the quality of the results degraded dramatically in our baseline experiment utilizing a simpler method. Our method is a step towards increased accessibility of automatic fallen tree mapping in forests, due to higher cost efficiency of aerial imagery acquisition compared to laser scanning. The precise fallen tree maps could be further used as a basis for plant and animal habitat modeling, studies on carbon sequestration as well as soil quality in forest ecosystems.
C1 [Polewski, Przemyslaw; Shelton, Jacquelyn; Yao, Wei] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Kowloon, Hong Kong, Peoples R China.
   [Heurich, Marco] Bavarian Forest Natl Pk, Dept Visitor Management & Natl Pk Monitoring, D-94481 Grafenau, Germany.
C3 Hong Kong Polytechnic University
RP Yao, W (corresponding author), Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Kowloon, Hong Kong, Peoples R China.
EM wei.hn.yao@polyu.edu.hk; marco.heurich@npv-bw.bayern.de
FU Research Grants Council of the Hong Kong Special Administrative Region, China [PolyU 25211819]; Hong Kong Polytechnical University [1-ZE8E, G-YBZ9]
CR Akeret J, 2017, ASTRON COMPUT, V18, P35, DOI 10.1016/j.ascom.2017.01.002
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Arnab A., 2017, ABS170402386 CORR, V0, P0
   Cremers D, 2007, TOP BIOMED ENG, V0, PP447, DOI 10.1007/978-0-387-68343-0_13
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Douglas D. H., 1973, CARTOGRAPHICA INT J, V10, P112, DOI 10.3138/FM57-6770-U75U-7727
   Duan FZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040306
   Einzmann K, 2017, FORESTS, V8, P0, DOI 10.3390/f8010021
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Freeman MP, 2016, PHOTOGRAMM ENG REM S, V82, P571, DOI 10.14358/PERS.82.7.571
   Jensen J. R., 2006, REMOTE SENSING ENV E, V0, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Latifi H, 2018, GISCI REMOTE SENS, V55, P839, DOI 10.1080/15481603.2018.1458463
   Lausch A, 2013, ECOL INDIC, V31, P73, DOI 10.1016/j.ecolind.2012.07.026
   Leica,, 2017, LEIC GEOS DMC 3 AIRB, V0, P0
   Li Y, 2017, PROC CVPR IEEE, V0, PP4438, DOI 10.1109/CVPR.2017.472
   LI ZQ, 1987, P NATL ACAD SCI USA, V84, P6611, DOI 10.1073/pnas.84.19.6611
   Long J., 1900, P610, V0, P0
   Lorensen W.E., 1987, P 14 ANN C COMPUTER, V0, PP163, DOI 10.1145/37402.37422
   Marchi N, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091356
   Marcos D, 2018, PROC CVPR IEEE, V0, PP8877, DOI 10.1109/CVPR.2018.00925
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Muller J, 2010, EUR J FOREST RES, V129, P981, DOI 10.1007/s10342-010-0400-5
   NIEVERGELT J, 1982, COMMUN ACM, V25, P739, DOI 10.1145/358656.358681
   Ostovar A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071579
   Panagiotidis D, 2019, NEW ZEAL J FOR SCI, V49, P0, DOI 10.33494/nzjfs492019x26x
   Polewski P, 2015, ISPRS ANN PHOTO REM, V2-3, P181, DOI 10.5194/isprsannals-II-3-W4-181-2015
   Polewski P., 2020, ISPRS INT ARCH PHOTO, V0, P717
   Polewski P, 2017, ISPRS J PHOTOGRAMM, V129, P118, DOI 10.1016/j.isprsjprs.2017.04.023
   Polewski P, 2015, ISPRS J PHOTOGRAMM, V105, P252, DOI 10.1016/j.isprsjprs.2015.01.010
   Queiroz GL, 2019, FORESTS, V10, P0, DOI 10.3390/f10060471
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Safonova A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060643
   Seibold S, 2018, ZOOL MONOGR, V1, P607, DOI 10.1007/978-3-319-75937-1_18
   Seidl R, 2017, NAT CLIM CHANGE, V7, P395, DOI 10.1038/NCLIMATE3303
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siarry P, 1997, INT J NUMER METH ENG, V40, P2449, DOI 10.1002/(SICI)1097-0207(19970715)40:13<2449::AID-NME172>3.0.CO;2-O
   Thiel C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203293
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Wales DJ, 1997, J PHYS CHEM A, V101, P5111, DOI 10.1021/jp970984n
   WAND MP, 1994, COMPUTATION STAT, V9, P97
   Watson JEM, 2018, NAT ECOL EVOL, V2, P599, DOI 10.1038/s41559-018-0490-x
   Xu S, 2018, ABS180705511 CORR, V0, P0
   Zalik B, 2000, COMPUT GEOSCI, V26, P137, DOI 10.1016/S0098-3004(99)00071-0
NR 49
TC 5
Z9 5
U1 3
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG 15
PY 2021
VL 178
IS 
BP 297
EP 313
DI 10.1016/j.isprsjprs.2021.06.016
EA JUL 2021
PG 17
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TE4AS
UT WOS:000669954900020
DA 2023-04-26
ER

PT J
AU Chen, X
   Chen, W
AF Chen, Xi
   Chen, Wei
TI GIS-based landslide susceptibility assessment using optimized hybrid machine learning methods
SO CATENA
LA English
DT Article
DE Kernel logistic regression; Kernel functions; Hybrid models; Landslide; Geographic information system
ID weights-of-evidence; sediment transport capacity; artificial neural-network; logistic-regression; frequency ratio; cross-validation; decision tree; ensemble; models; area
AB Globally, but especially in China, landslides are considered to be one of the most severe and significant natural hazards. In this study, bivariate statistical-based kernel logistic regression (KLR) models with different kernel functions (Polynomial, PUK, and Radial Basis Function), named the PLKLR, PUKLR, and RBFKLR models, were proposed for landslide susceptibility evaluation in Zichang City, China. Meanwhile, the present study aims to build landslide susceptibility maps based on bivariate statistical correlation analysis, optimization of different kernel functions, comparison of three landslide susceptibility maps and systematic analysis of spatial patterns. The steps of this article are organized as follows: Firstly, a landslide inventory containing 263 historical landslide locations was constructed. For the purpose of training and validation of models, 263 landslide locations were randomly divided into two parts with a ratio of 70/30. Secondly, 14 landslide conditioning factors were extracted from the spatial database. Subsequently, correlation analysis between the conditioning factors and the occurrence of landslides was conducted using frequency ratios. Then, the conditioning factors with normalized frequency ratios values were used as inputs to build the landslide susceptibility maps using the three models. A multicollinearity analysis was performed using collinearity statistics. Finally, the area under the receiver operating characteristic curve (AUC) was used for comparison and validation of models for recognizing the prediction capability. By further quantitative comparing mapped susceptibility values on a pixel-by-pixel basis, which can acquire underestimations and overestimations of factors (distance to river and slope) and susceptibility area. The results indicated that the PUKLR model had superior performance in landslide susceptibility assessment, with the highest AUC values of 0.884 and 0.766 for training and validation datasets, respectively. This model was followed by the RBFKLR model and the PLKLR model for the training datasets (AUC values of 0.879 and 0.797, respectively), and the PLKLR model and the RBFKLR model for the validation datasets (AUC values of 0.758 and 0.752, respectively). The landslide susceptibility map could help government agencies and decision-makers make wise decisions for future natural hazards prevention in Zichang region.
C1 [Chen, Xi; Chen, Wei] Xian Univ Sci & Technol, Coll Geol & Environm, Xian 710054, Peoples R China.
   [Chen, Wei] Minist Nat Resources, Key Lab Coal Resources Explorat & Comprehens Util, Xian 710021, Peoples R China.
C3 Xi'an University of Science & Technology; Ministry of Natural Resources of the People's Republic of China
RP Chen, W (corresponding author), Xian Univ Sci & Technol, Coll Geol & Environm, Xian 710054, Peoples R China.
EM chenwei0930@xust.edu.cn
FU National Natural Science Foundation of China [41807192]; Innovation Capability Support Program of Shaanxi [2020KJXX-005]; Natural Science Basic Research Program of Shaanxi [2019JLM-7]
CR Ada M, 2018, NAT HAZARDS, V90, P237, DOI 10.1007/s11069-017-3043-8
   Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   ALEOTTI P, 1999, B ENG GEOL ENVIRON, V58, P21, DOI 10.1007/S100640050066
   Althuwaynee OF, 2014, CATENA, V114, P21, DOI 10.1016/j.catena.2013.10.011
   [Anonymous], 2019, ENVIRON SCI POLLUT R, V0, P0
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030475
   Ayalew L, 2005, GEOMORPHOLOGY, V65, P15, DOI 10.1016/j.geomorph.2004.06.010
   Azuaje F., 2006, BIOMED CENTRAL, V2nd, P0
   BENEDIKTSSON JA, 1990, IEEE T GEOSCI REMOTE, V28, P540, DOI 10.1109/TGRS.1990.572944
   Pham BT, 2019, CATENA, V175, P203, DOI 10.1016/j.catena.2018.12.018
   Pham BT, 2019, B ENG GEOL ENVIRON, V78, P1911, DOI 10.1007/s10064-017-1202-5
   Calo F, 2014, REMOTE SENS ENVIRON, V142, P69, DOI 10.1016/j.rse.2013.11.003
   Cawley GC, 2008, MACH LEARN, V71, P243, DOI 10.1007/s10994-008-5055-9
   Chen W, 2020, ENERGY, V195, P0, DOI 10.1016/j.energy.2020.116951
   Chen W, 2020, J HYDROL, V583, P0, DOI 10.1016/j.jhydrol.2020.124602
   Chen W, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10010029
   Chen W, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9183755
   Chen W, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8122540
   Chen W, 2019, B ENG GEOL ENVIRON, V78, P4397, DOI 10.1007/s10064-018-1401-8
   Chen W, 2018, SCI TOTAL ENVIRON, V634, P853, DOI 10.1016/j.scitotenv.2018.04.055
   Chen W, 2018, GEOCARTO INT, V33, P1398, DOI 10.1080/10106049.2018.1425738
   Chen W, 2017, GEOMAT NAT HAZ RISK, V8, P1955, DOI 10.1080/19475705.2017.1401560
   Chen W, 2017, GEOMAT NAT HAZ RISK, V8, P950, DOI 10.1080/19475705.2017.1289250
   Chung CJ, 2008, GEOMORPHOLOGY, V94, P438, DOI 10.1016/j.geomorph.2006.12.036
   Conoscenti C, 2008, GEOMORPHOLOGY, V94, P325, DOI 10.1016/j.geomorph.2006.10.039
   Cross M, 1998, GEOL SOC ENG GEOL SP, V0, P247
   DEWEIJER AP, 1994, ANAL CHEM, V66, P23, DOI 10.1021/ac00073a006
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Ding QF, 2017, GEOCARTO INT, V32, P619, DOI 10.1080/10106049.2016.1165294
   Duc D, 2013, LANDSLIDES, V10, P219, DOI 10.1007/s10346-012-0362-4
   Erener A, 2010, LANDSLIDES, V7, P55, DOI 10.1007/s10346-009-0188-x
   ESRI R., 2014, ARCGIS DESKT REL 10, V0, P0
   Fanos AM, 2019, CATENA, V172, P435, DOI 10.1016/j.catena.2018.09.012
   Fernandez T, 2003, NAT HAZARDS, V30, P297, DOI 10.1023/B:NHAZ.0000007092.51910.3f
   Gokceoglu C, 1996, ENG GEOL, V44, P147, DOI 10.1016/S0013-7952(97)81260-4
   Gokceoglu C, 2009, LANDSLIDES, V6, P345, DOI 10.1007/s10346-009-0166-3
   Gorsevski PV, 2016, LANDSLIDES, V13, P467, DOI 10.1007/s10346-015-0587-0
   Gupta SK, 1998, J APPL CRYSTALLOGR, V31, P474, DOI 10.1107/S0021889897011047
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   HALL MM, 1977, J APPL CRYSTALLOGR, V10, P66, DOI 10.1107/S0021889877012849
   He QF, 2019, SCI TOTAL ENVIRON, V663, P1, DOI 10.1016/j.scitotenv.2019.01.329
   Hong HY, 2016, GEOMORPHOLOGY, V259, P105, DOI 10.1016/j.geomorph.2016.02.012
   Hong HY, 2015, CATENA, V133, P266, DOI 10.1016/j.catena.2015.05.019
   Kumar R, 2015, J EARTH SYST SCI, V124, P431, DOI 10.1007/s12040-015-0536-2
   Lee S, 2007, LANDSLIDES, V4, P33, DOI 10.1007/s10346-006-0047-y
   Lei XX, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9070443
   Li Y, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12010113
   Liu J., 2012, QUANTITATIVE METHODS, V0, P0
   Thanh LN, 2014, LANDSLIDES, V11, P897, DOI 10.1007/s10346-013-0437-x
   Malamud BD, 2004, EARTH SURF PROC LAND, V29, P687, DOI 10.1002/esp.1064
   Maltman A, 2012, GEOLOGICAL DEFORMATI, V0, P0
   Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016
   Mohammady M, 2012, J ASIAN EARTH SCI, V61, P221, DOI 10.1016/j.jseaes.2012.10.005
   MOORE ID, 1986, WATER RESOUR RES, V22, P1350, DOI 10.1029/WR022i008p01350
   Peduzzi P, 2010, NAT HAZARD EARTH SYS, V10, P623, DOI 10.5194/nhess-10-623-2010
   Peng JB, 2015, ENG GEOL, V186, P79, DOI 10.1016/j.enggeo.2014.08.015
   Pourghasemi HR, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4950-1
   Pradhan B, 2010, IEEE T GEOSCI REMOTE, V48, P4164, DOI 10.1109/TGRS.2010.2050328
   Pradhan B, 2010, COMPUT ENVIRON URBAN, V34, P216, DOI 10.1016/j.compenvurbsys.2009.12.004
   Pradhan B, 2010, ENVIRON EARTH SCI, V60, P1037, DOI 10.1007/s12665-009-0245-8
   Prosser IP, 2000, PROG PHYS GEOG, V24, P179, DOI 10.1177/030913330002400202
   Romer C, 2016, ENG GEOL, V201, P29, DOI 10.1016/j.enggeo.2015.12.013
   Sar N., 2016, WITHDRAWN COUPLING A, V0, P0
   Suzen ML, 2012, INT J DIGIT EARTH, V5, P338, DOI 10.1080/17538947.2011.586443
   Tehrany MS, 2014, J HYDROL, V512, P332, DOI 10.1016/j.jhydrol.2014.03.008
   Toebe M, 2013, J CEREAL SCI, V57, P453, DOI 10.1016/j.jcs.2013.01.014
   Tsangaratos P, 2016, CATENA, V145, P164, DOI 10.1016/j.catena.2016.06.004
   Ustun B, 2006, CHEMOMETR INTELL LAB, V81, P29, DOI 10.1016/j.chemolab.2005.09.003
   Van Den Eeckhaut M., 2006, GEOMORPHOLOGY, V76, P392, DOI 10.1016/J.GE0M0RPH.2005.12.003
   vanWesten CJ, 1996, EARTH SURF PROCESSES, V21, P853, DOI 10.1002/(SICI)1096-9837(199609)21:9&lt;853::AID-ESP676&gt;3.0.CO;2-C
   Wang GR, 2020, SYMMETRY-BASEL, V12, P0, DOI 10.3390/sym12030325
   Wang LJ, 2016, GEOSCI J, V20, P117, DOI 10.1007/s12303-015-0026-1
   Wu YM, 2015, ENG GEOL, V195, P63, DOI 10.1016/j.enggeo.2015.05.022
   Xiao T, 2020, LANDSLIDES, V17, P627, DOI 10.1007/s10346-019-01299-0
   Yilmaz C, 2012, ENVIRON EARTH SCI, V65, P2161, DOI 10.1007/s12665-011-1196-4
   Zhang M, 2015, LANDSLIDES, V12, P973, DOI 10.1007/s10346-015-0611-4
   Zhang TY, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21020218
   Zhang ZW, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5732-0
   Zhao X, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142180
   Zhao X, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10010016
   Zhou C, 2018, COMPUT GEOSCI-UK, V112, P23, DOI 10.1016/j.cageo.2017.11.019
NR 81
TC 112
Z9 114
U1 32
U2 174
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0341-8162
EI 1872-6887
J9 CATENA
JI Catena
PD JAN 15
PY 2021
VL 196
IS 
BP 
EP 
DI 10.1016/j.catena.2020.104833
PG 16
WC Geosciences, Multidisciplinary; Soil Science; Water Resources
SC Geology; Agriculture; Water Resources
GA OJ4TF
UT WOS:000583955200021
DA 2023-04-26
ER

PT J
AU Hu, TL
   Liao, Q
AF Hu, Tianlun
   Liao, Qi
TI Real-Time Camera Localization with Deep Learning and Sensor Fusion
SO IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC 2021)
LA English
DT Proceedings Paper
AB Real-time camera localization is a key enabler for interactive network service, e.g. visualizing network performance with augmented reality (AR) in user devices. We propose a deep learning and sensor fusion approach for real-time camera localization. A multi-input deep neural network is designed to regress the camera pose from a single image and motion sensor measurements. We perform a comprehensive analysis to find the best choices of input features, loss function, convolutional neural network model, and hyperparameters. We show that by adding features extracted from motion sensor data, our approach significantly outperforms the state-of-the-art visual-based camera localization approaches. In an indoor environment where we conduct a proof-of-concept of the proposed end-to-end AR-supported radio map visualization solution, our camera localization approach achieves an orientation error of 2.5179 degrees and a position error of 0.0222 meters with an inference time lower than 4 ms per frame.
C1 [Hu, Tianlun; Liao, Qi] Nokia Bell Labs, Stuttgart, Germany.
C3 Nokia Corporation
RP Hu, TL (corresponding author), Nokia Bell Labs, Stuttgart, Germany.
EM tianlun.hu@nokia.com; qi.liao@nokia-bell-labs.com
FU German Federal Ministry of Education and Research (BMBF) project KICK [16KIS1102K]
CR Altmann S.L., 2005, ROTATIONS QUATERNION, V0, P0
   Bai X., 2019, INT SYMP WIREL, V0, P1
   Brahmbhatt S, 2018, PROC CVPR IEEE, V0, PP2616, DOI 10.1109/CVPR.2018.00277
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Campos C., 2020, ORB SLAM3 ACCURATE O, V0, P0
   Chen CH, 2020, IEEE INTERNET THINGS, V7, P4431, DOI 10.1109/JIOT.2020.2966773
   Diebel J., 2006, MATRIX, V58, P15
   He K., 2015, PROC CVPR IEEE, V5, P6
   Hussain G, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8040375
   Kendall A, 2017, PROC CVPR IEEE, V0, PP6555, DOI 10.1109/CVPR.2017.694
   Kendall A, 2015, IEEE I CONF COMP VIS, V0, PP2938, DOI 10.1109/ICCV.2015.336
   Li W, 2018, BMVC, V0, P0
   Liao Q., 2019, US PATENT APP, V0, Patent No. 16347029
   Liao QY, 2021, IEEE T GEOSCI REMOTE, V59, P8992, DOI 10.1109/TGRS.2020.3036248
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Radwan N, 2018, IEEE ROBOT AUTOM LET, V3, P4407, DOI 10.1109/LRA.2018.2869640
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Schubert D, 2018, IEEE INT C INT ROBOT, V0, PP1680, DOI 10.1109/IROS.2018.8593419
   Simonyan K, 2015, ARXIV, V0, P0
   Su H, 2015, IEEE I CONF COMP VIS, V0, PP2686, DOI 10.1109/ICCV.2015.308
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   TUM Computer Vision Group, 2018, VIS IN DAT, V0, P0
   Walch F, 2017, IEEE I CONF COMP VIS, V0, PP627, DOI 10.1109/ICCV.2017.75
NR 23
TC 0
Z9 0
U1 0
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1550-3607
EI 
J9 IEEE ICC
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/ICC42927.2021.9500770
PG 7
WC Telecommunications
SC Telecommunications
GA BS4HX
UT WOS:000719386003030
DA 2023-04-26
ER

PT J
AU Xu, Y
   Yu, JT
   Li, WX
   Feng, JQ
AF Xu, Yao
   Yu, Jintong
   Li, Wenxue
   Feng, Jiqiang
TI Global asymptotic stability of fractional-order competitive neural networks with multiple time-varying-delay links
SO APPLIED MATHEMATICS AND COMPUTATION
LA English
DT Article
DE Competitive neural networks; Fractional derivatives; Global asymptotic stability; Time-varying delays; Multiple links
ID finite-time; exponential stability; group models; synchronization; dispersal
AB Competitive neural networks have become increasingly popular since this kind of neural networks can better describe the dynamics of cortical cognitive maps with unsupervised synaptic modifications. In this paper, we first propose fractional-order competitive neural networks with multiple time-varying-delay links and explore the global asymptotic stability of this class of neural networks. A novel and generalized integral inequality related to every upper bound of each time-varying delay is given. Moreover, based on Lyapunov method and graph theory, we obtain some sufficient conditions with the help of this integral inequality to guarantee the global asymptotic stability. The theoretical results offer a new perspective to show the close relationship between the stability criterion and the topological structure of networks. Finally, an illustrative numerical example is given to demonstrate the feasibility and effectiveness of the theoretical results. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Xu, Yao; Yu, Jintong; Li, Wenxue] Harbin Inst Technol Weihai, Dept Math, Weihai 264209, Peoples R China.
   [Feng, Jiqiang] Shenzhen Univ, Coll Math & Stat, Shenzhen Key Lab Adv Machine Learning & Applicat, Shenzhen 518060, Peoples R China.
C3 Harbin Institute of Technology; Shenzhen University
RP Li, WX (corresponding author), Harbin Inst Technol Weihai, Dept Math, Weihai 264209, Peoples R China.
EM wenxuetg@hitwh.edu.cn
FU Shandong Province Natural Science Foundation [ZR2018MA005, ZR2018MA020, ZR2017MA008]; Key Project of Science and Technology of Weihai [2014DXGJMS08]; Innovation Technology Funding Project in Harbin Institute of Technology [HIT.NSRIF.201703]; Science and Technology Program of Shenzhen [JCYJ20170818091621856]; National Science Foundation of China [61872429]
CR Aguila-Camacho N, 2014, COMMUN NONLINEAR SCI, V19, P2951, DOI 10.1016/j.cnsns.2014.01.022
   Akhmet MU, 2010, NEURAL NETWORKS, V23, P805, DOI 10.1016/j.neunet.2010.05.006
   Arbi A, 2017, NEURAL PROCESS LETT, V46, P719, DOI 10.1007/s11063-017-9620-8
   Chen LP, 2019, NEURAL NETWORKS, V118, P289, DOI 10.1016/j.neunet.2019.07.006
   COHEN MA, 1983, IEEE T SYST MAN CYB, V13, P815, DOI 10.1109/TSMC.1983.6313075
   Duan L, 2014, NEUROCOMPUTING, V123, P318, DOI 10.1016/j.neucom.2013.07.026
   Gu HB, 2010, J FRANKLIN I, V347, P719, DOI 10.1016/j.jfranklin.2009.03.005
   Guo Y, 2019, APPL MATH COMPUT, V343, P114, DOI 10.1016/j.amc.2018.07.058
   Gupta M. M., 2004, STATIC DYNAMIC NEURA, V0, P0
   Halanay A., 1966, OSCILLATIONS TIME LA, V23, P0
   Huang LL, 2020, J COMPUT APPL MATH, V370, P0, DOI 10.1016/j.cam.2019.112633
   Katchinskiy N, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep20529
   Li HL, 2019, NEURAL NETWORKS, V118, P102, DOI 10.1016/j.neunet.2019.06.008
   Li MY, 2010, J DIFFER EQUATIONS, V248, P1, DOI 10.1016/j.jde.2009.09.003
   Li RX, 2017, APPL MATH COMPUT, V313, P37, DOI 10.1016/j.amc.2017.05.073
   Li S, 2020, J MATH ANAL APPL, V489, P0, DOI 10.1016/j.jmaa.2020.124150
   Li S, 2020, NONLINEAR ANAL-HYBRI, V35, P0, DOI 10.1016/j.nahs.2019.100819
   Li S, 2021, INT J CONTROL, V94, P7, DOI 10.1080/00207179.2019.1577562
   Liu PP, 2018, NEURAL NETWORKS, V108, P452, DOI 10.1016/j.neunet.2018.09.005
   Liu XM, 2018, NEUROCOMPUTING, V273, P357, DOI 10.1016/j.neucom.2017.07.047
   Liu Y, 2019, NONLINEAR ANAL-HYBRI, V33, P93, DOI 10.1016/j.nahs.2019.01.007
   Lu HT, 2005, NEURAL NETWORKS, V18, P243, DOI 10.1016/j.neunet.2004.11.009
   Meyer-Baese A, 2003, IEEE T NEURAL NETWOR, V14, P716, DOI 10.1109/TNN.2003.810594
   Peng HP, 2010, PHYS LETT A, V374, P2335, DOI 10.1016/j.physleta.2010.03.052
   Peng X, 2017, NEURAL NETWORKS, V94, P46, DOI 10.1016/j.neunet.2017.06.011
   Podlubny L., 1999, FRACTIONAL DIFFERENT, V0, P0
   Pratap A, 2019, J FRANKLIN I, V356, P2212, DOI 10.1016/j.jfranklin.2019.01.017
   Pratap A, 2018, NEUROCOMPUTING, V317, P110, DOI 10.1016/j.neucom.2018.08.016
   Su TT, 2016, DISCRETE CONT DYN-B, V21, P3655, DOI 10.3934/dcdsb.2016115
   Sun ZR, 2020, APPL MATH LETT, V99, P0, DOI 10.1016/j.aml.2019.07.013
   Wang H, 2015, NEUROCOMPUTING, V154, P15, DOI 10.1016/j.neucom.2014.12.031
   Wang PF, 2020, NONLINEAR ANAL-HYBRI, V38, P0, DOI 10.1016/j.nahs.2020.100916
   West D. B., 1996, INTRO GRAPH THEORY, V0, P0
   Wu GC, 2019, CHAOS, V29, P0, DOI 10.1063/1.5096645
   Wu GC, 2019, FRACT CALC APPL ANAL, V22, P180, DOI 10.1515/fca-2019-0012
   Wu GC, 2018, FRACT CALC APPL ANAL, V21, P354, DOI 10.1515/fca-2018-0021
   Wu YB, 2021, IEEE T SYST MAN CY-S, V51, P3251, DOI 10.1109/TSMC.2019.2920451
   Wu YB, 2020, IEEE T CYBERNETICS, V50, P2414, DOI 10.1109/TCYB.2019.2930579
   Xu Y, 2020, J APPL ANAL COMPUT, V10, P1, DOI 10.11948/20180051
   Xu Y, 2020, INT J CONTROL, V93, P505, DOI 10.1080/00207179.2018.1479538
   Zhang CM, 2020, PHYSICA A, V538, P0, DOI 10.1016/j.physa.2019.122827
   Zhang CM, 2015, NONLINEAR ANAL-HYBRI, V15, P37, DOI 10.1016/j.nahs.2014.07.003
   Zhou H, 2020, MATH METHOD APPL SCI, V43, P9557, DOI 10.1002/mma.6624
   Zhou YH, 2017, NEURAL COMPUT APPL, V28, P775, DOI 10.1007/s00521-015-2105-7
   Zou XL, 2020, COMMUN NONLINEAR SCI, V83, P0, DOI 10.1016/j.cnsns.2019.105136
NR 45
TC 33
Z9 33
U1 12
U2 136
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0096-3003
EI 1873-5649
J9 APPL MATH COMPUT
JI Appl. Math. Comput.
PD JAN 15
PY 2021
VL 389
IS 
BP 
EP 
DI 10.1016/j.amc.2020.125498
PG 12
WC Mathematics, Applied
SC Mathematics
GA OC7RE
UT WOS:000579354200016
DA 2023-04-26
ER

PT J
AU Bi, H
   Deng, JR
   Yang, TW
   Wang, J
   Wang, L
AF Bi, Hui
   Deng, Jiarui
   Yang, Tianwen
   Wang, Jian
   Wang, Ling
TI CNN-Based Target Detection and Classification When Sparse SAR Image Dataset is Available
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Convolutional neural network (CNN); complex approximate message passing (CAMP); sparse synthetic aperture radar (SAR) image; target detection and classification
ID bistatic sar; signal recovery; range-doppler
AB Synthetic aperture radar (SAR) is an earth observation technology that can obtain high-resolution image in allweather and all-time conditions,and hence, has been widely used in civil and military applications. SAR target detection and classification are the key processes for the detailed feature information extraction of the interested target. Compared with traditional matched filtering (MF) recovered result, sparse SAR image has lower sidelobes, noise, and clutter. Thus, it will theoretically has better performance in target detection and classification. In this article, we propose a novel sparse SAR image based target detection and classification framework. This novel framework first obtains the sparse SAR image dataset by complex approximate message passing (CAMP), which is an L-1-norm regularization sparse imaging method. Different from other regularization recovery algorithms, CAMP can output not only a sparse solution, but also a nonsparse estimation of considered scene that well preserves the statistical characteristic of the image when protruding the target. Then, we detect and classify the targets by using the convolutional neural network based technologies from the sparse SAR image datasets constructed by the sparse and nonsparse solutions of CAMP, respectively. For clarify, these two kinds of sparse SAR image datasets are named as D-sp, and D-Nsp. Experimental results show that under standard operating conditions, the proposed framework can obtain 92.60% and 99.29% mAP on Faster RCNN and YOLOv3 by using the D-Nsp sparse SAR image dataset. Under extended operating conditions, the mAP value of Faster RCNN and YOLOv3 are 95.69% and 89.91% mAP, respectively. These values based on the D-Nsp dataset are much higher than the classified result based on the corresponding MF dataset.
C1 [Bi, Hui; Deng, Jiarui; Wang, Jian; Wang, Ling] Nanjing Univ Aeronaut & Astronaut, Key Lab Radar Imaging & Microwave Photon, Minist Educ, Nanjing 211106, Peoples R China.
   [Bi, Hui; Deng, Jiarui; Yang, Tianwen; Wang, Jian; Wang, Ling] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 211106, Peoples R China.
   [Yang, Tianwen] Southeast Univ, Natl Mobile Commun Res Lab, Nanjing 211189, Peoples R China.
   [Yang, Tianwen] Southeast Univ, Coll Elect & Informat Engn, Nanjing 211189, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of Aeronautics & Astronautics; Southeast University - China; Southeast University - China
RP Bi, H (corresponding author), Nanjing Univ Aeronaut & Astronaut, Key Lab Radar Imaging & Microwave Photon, Minist Educ, Nanjing 211106, Peoples R China.; Bi, H (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 211106, Peoples R China.
EM bihui@nuaa.edu.cn; djr_919@163.com; yangtianwen0524@163.com; 1528114249@qq.com; tulip_wling@nuaa.edu.cn
FU Fundamental Research Funds for the Central Universities [NE2020004]; National Natural Science Foundation of China [61901213]; Natural Science Foundation of Jiangsu Province [BK20190397]; Aeronautical Science Foundation of China [201920052001]; Young Science and Technology Talent Support Project of Jiangsu Science and Technology Association
CR Ahmmed R, 2016, INT CONF COMP COMMUN, V0, P0
   Anitori L, 2013, IEEE T SIGNAL PROCES, V61, P813, DOI 10.1109/TSP.2012.2225057
   BAMLER R, 1992, IEEE T GEOSCI REMOTE, V30, P706, DOI 10.1109/36.158864
   Baraniuk RG, 2010, P IEEE, V98, P906, DOI 10.1109/JPROC.2010.2047424
   Bi H., 2019, P IEEE RAD C BOST MA P IEEE RAD C BOST MA, V0, P1
   Bi H, 2019, SCI CHINA INFORM SCI, V62, P0, DOI 10.1007/s11432-018-9662-y
   Bi H, 2018, IEEE T GEOSCI REMOTE, V56, P5006, DOI 10.1109/TGRS.2018.2803802
   Bi H, 2017, IEEE T GEOSCI REMOTE, V55, P3426, DOI 10.1109/TGRS.2017.2671519
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Cerutti-Maori D, 2008, IEEE T GEOSCI REMOTE, V46, P3019, DOI 10.1109/TGRS.2008.923026
   Cetin M, 2003, IEEE T AERO ELEC SYS, V39, P1375, DOI 10.1109/TAES.2003.1261134
   Clemente C, 2012, IEEE T GEOSCI REMOTE, V50, P3219, DOI 10.1109/TGRS.2011.2180394
   Cumming I. G., 2004, DIGITAL PROCESSING S, V0, P0
   Curlander J. C., 1991, SYNTIC APERTURE R, V0, P0
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong M., 2019, PROC INT JOINT C NEU, V0, P1
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2009, P NATL ACAD SCI USA, V106, P18914, DOI 10.1073/pnas.0909892106
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gertler J. J., 1988, IEEE CONTROL SYSTEMS MAGAZINE, V8, P3, DOI 10.1109/37.9163
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Henderson F.M., 1998, PRINCIPLE APPL IMAGI, V0, P0
   Kang M, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017), V0, P0
   Krizhevsky A, 2015, P 25 INT C NEUR INF P 25 INT C NEUR INF, V0, P1
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Magna G, 2015, 2015 18TH AISEM ANNUAL CONFERENCE, V0, P0
   Maleki A, 2013, IEEE T INFORM THEORY, V59, P4290, DOI 10.1109/TIT.2013.2252232
   Mittermayer J, 2003, INT GEOSCI REMOTE SE, V0, P1462
   Neo YL, 2008, IEEE T GEOSCI REMOTE, V46, P14, DOI 10.1109/TGRS.2007.909090
   Neumann M, 2010, IEEE T GEOSCI REMOTE, V48, P1086, DOI 10.1109/TGRS.2009.2031101
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, V0, P0
   RANEY RK, 1994, IEEE T GEOSCI REMOTE, V32, P786, DOI 10.1109/36.298008
   Redmon J, 2018, P IEEE C COMP VIS PA, V0, P1
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shan CF, 2004, INT C PATT RECOG, V0, PP954, DOI 10.1109/ICPR.2004.1334687
   Sheikhi A, 2006, PROCEEDINGS OF 2006 CIE INTERNATIONAL CONFERENCE ON RADAR, VOLS 1 AND 2, P57
   Singha S, 2013, IEEE J-STARS, V6, P2355, DOI 10.1109/JSTARS.2013.2251864
   Wang N, 2017, IEEE GEOSCI REMOTE S, V14, P1695, DOI 10.1109/LGRS.2017.2729159
   Wong FH, 2008, IEEE T GEOSCI REMOTE, V46, P2493, DOI 10.1109/TGRS.2008.917599
   Zhang BC, 2012, SCI CHINA INFORM SCI, V55, P1722, DOI 10.1007/s11432-012-4633-4
   Zhu JW, 2017, IEEE GEOSCI REMOTE S, V14, P222, DOI 10.1109/LGRS.2016.2635699
NR 48
TC 6
Z9 6
U1 2
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 6815
EP 6826
DI 10.1109/JSTARS.2021.3093645
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TJ6XZ
UT WOS:000673623400004
DA 2023-04-26
ER

PT J
AU Yao, X
   Gao, Y
   Zhu, D
   Manley, E
   Wang, JE
   Liu, Y
AF Yao, Xin
   Gao, Yong
   Zhu, Di
   Manley, Ed
   Wang, Jiaoe
   Liu, Yu
TI Spatial Origin-Destination Flow Imputation Using Graph Convolutional Networks
SO IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
LA English
DT Article
DE Spatial databases; Gravity; Convolution; Biological system modeling; Data models; Predictive models; Neural networks; Origin-destination flow; data imputation; spatial interaction network; graph embedding; graph convolution
ID interaction patterns; neural-networks; mobility; matrices; models; china; urban; community; inference
AB Due to the limitation of data collection techniques and privacy issues, the problem of missing spatial origin-destination flows frequently occurs. Data imputation provides great support for the acquisition of complete flow data, which enables us to better understand regional connections and mobility patterns. However, existing models or approaches neglect the network structure of spatial flows, thus resulting in inappropriate estimates and a low performance. The development of graph neural networks offers a powerful tool to deal with graph-structured data. In this article, we proposed a spatial interaction graph convolutional network model, which combines graph convolution and a mapping function to predict flow data from the perspective of network learning. This model utilizes geographical unit embedding in local spatial networks to improve prediction accuracy. A negative sampling technique is adopted to reduce misestimation. Experiments on Beijing taxi trip data verified the usefulness of our model in spatial flow prediction. We also demonstrated that a biased training sample had a negative impact on the model's performance. More attributes of geographical units, a more proper negative sampling rate and a larger training set can increase the prediction accuracy of flow data.
C1 [Yao, Xin; Gao, Yong; Zhu, Di; Liu, Yu] Peking Univ, Sch Earth & Space Sci, Inst Remote Sensing & Geog Informat Syst, Beijing 100871, Peoples R China.
   [Manley, Ed] Univ Leeds, Sch Geog, Leeds LS2 9JT, W Yorkshire, England.
   [Wang, Jiaoe] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, Beijing 100101, Peoples R China.
   [Wang, Jiaoe] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
C3 Peking University; University of Leeds; Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Gao, Y (corresponding author), Peking Univ, Sch Earth & Space Sci, Inst Remote Sensing & Geog Informat Syst, Beijing 100871, Peoples R China.
EM yaoxin@pku.edu.cn; gaoyong@pku.edu.cn; patrick.zhu@pku.edu.cn; e.j.manley@leeds.ac.uk; wangje@igsnrr.ac.cn; liuyu@urban.pku.edu.cn
FU National Natural Science Foundation of China [41971331, 41830645, 41625003, 41771425]; National Key Research and Development Program of China [2017YFB0503602]; Smart Guangzhou Spatio-Temporal Information Cloud Platform Construction [GZIT2016-A5-147]
CR Abel GJ, 2014, SCIENCE, V343, P1520, DOI 10.1126/science.1248676
   Barbosa H, 2018, PHYS REP, V734, P1, DOI 10.1016/j.physrep.2018.01.001
   Batty M., 2008, DYNAMICS COMPLEX URB, V0, PP1, DOI 10.1007/978-3-7908-1937-3_1
   Black WR., 1995, J TRANSP GEOGR, V3, P159, DOI 10.1016/0966-6923(95)00013-S
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Calabrese F, 2011, IEEE PERVAS COMPUT, V10, P36, DOI 10.1109/MPRV.2011.41
   Celik H. M, 2004, J TRANSP GEOGR, V12, P141, DOI 10.1016/J.JTRANGEO.2003.12.003
   Chai D, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), V0, PP397, DOI 10.1145/3274895.3274896
   Chen YG, 2015, CHAOS SOLITON FRACT, V77, P174, DOI 10.1016/j.chaos.2015.05.022
   Chen Y, 2015, INT J GEOGR INF SCI, V29, P889, DOI 10.1080/13658816.2014.999244
   Chiang WL, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP257, DOI 10.1145/3292500.3330925
   de Montjoye YA, 2013, SCI REP-UK, V3, P0, DOI 10.1038/srep01376
   Defferrard M., 2016, ADV NEURAL INFORM PR, V29, P3837, DOI 10.5555/3157382.3157527
   Esparza A., 2005, PAPERS REGIONAL SCI, V73, P55
   Expert P, 2011, P NATL ACAD SCI USA, V108, P7663, DOI 10.1073/pnas.1018962108
   FISCHER MM, 1994, J REGIONAL SCI, V34, P503, DOI 10.1111/j.1467-9787.1994.tb00880.x
   FOTHERINGHAM AS, 1981, ANN ASSOC AM GEOGR, V71, P425
   Gao S, 2013, T GIS, V17, P463, DOI 10.1111/tgis.12042
   Geng X, 2019, AAAI CONF ARTIF INTE, V0, P3656
   Grosche T, 2007, J AIR TRANSP MANAG, V13, P175, DOI 10.1016/j.jairtraman.2007.02.001
   Guo DS, 2012, T GIS, V16, P411, DOI 10.1111/j.1467-9671.2012.01344.x
   Haynes K. E., 2020, GRAVITY SPATIAL INTE, V0, P0
   Hazelton ML, 2001, TRANSPORT RES B-METH, V35, P667, DOI 10.1016/S0191-2615(00)00009-6
   Jang W, 2011, T GIS, V15, P541, DOI 10.1111/j.1467-9671.2011.01273.x
   Jenks G., 1967, INT YB CARTOGRAPHY, V7, P186
   Kipf T. N., 2017, ICLR, V0, P0
   Kong XQ, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6020038
   Kordi M, 2016, ANN AM ASSOC GEOGR, V106, P990
   Kotnis Bhushan, 2017, ABS170806816 CORR, V0, P0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lenormand M, 2012, PLOS ONE, V7, P0, DOI 10.1371/journal.pone.0045985
   Li BB, 2009, TRANSPORT RES B-METH, V43, P301, DOI 10.1016/j.trb.2008.07.001
   Li BB, 2005, TECHNOMETRICS, V47, P399, DOI 10.1198/004017005000000283
   Li QM, 2018, AAAI CONF ARTIF INTE, V0, P3538
   Lin JY, 2012, J TRANSP GEOGR, V22, P109, DOI 10.1016/j.jtrangeo.2011.12.002
   Liu X, 2016, INT J GEOGR INF SCI, V30, P334, DOI 10.1080/13658816.2015.1086923
   Liu Y, 2015, ANN ASSOC AM GEOGR, V105, P512, DOI 10.1080/00045608.2015.1018773
   Liu Y, 2012, J GEOGR SYST, V14, P463, DOI 10.1007/s10109-012-0166-z
   Long Y, 2015, COMPUT ENVIRON URBAN, V53, P19, DOI 10.1016/j.compenvurbsys.2015.02.005
   Manley E, 2019, APPL SPAT ANAL POLIC, V12, P45, DOI 10.1007/s12061-018-9264-8
   Marrocu E, 2013, TOURISM MANAGE, V39, P71, DOI 10.1016/j.tourman.2012.10.009
   Mazzoli M, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-11841-2
   Mennis J, 2009, COMPUT ENVIRON URBAN, V33, P403, DOI 10.1016/j.compenvurbsys.2009.11.001
   Mozolin M, 2000, TRANSPORT RES B-METH, V34, P53, DOI 10.1016/S0191-2615(99)00014-4
   Nakaya T., 2001, GEOJOURNAL, V53, P347, DOI 10.1023/A:1020149315435
   OPENSHAW S, 1993, GEOGRAPHIC INFORMATI, V0, P147
   Roy JR, 2004, PAP REG SCI, V83, P339, DOI 10.1007/s10110-003-0189-4
   Simini F, 2012, NATURE, V484, P96, DOI 10.1038/nature10856
   Stouffer SA, 1940, AM SOCIOL REV, V5, P845, DOI 10.2307/2084520
   TAYLOR PJ, 1971, GEOGR ANAL, V3, P221
   Tesselkin A, 2017, PROCEDIA ENGINEER, V178, P107, DOI 10.1016/j.proeng.2017.01.071
   Thill JC, 2000, ADV SPAT SCI, V0, P355
   TOBLER W, 1977, J ENVIRON SYST, V6, P271
   Trouillon T, 2016, PR MACH LEARN RES, V48, P0
   van-den Berg R., 2018, SEMANT WEB, V0, P0
   Wang J, 2014, J TRANSP GEOGR, V40, P145, DOI 10.1016/j.jtrangeo.2014.02.002
   WILSON AG, 1967, TRANSPORT RES, V1, P253, DOI 10.1016/0041-1647(67)90035-4
   Xiao Y, 2013, PROF GEOGR, V65, P265, DOI 10.1080/00330124.2012.679445
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Yang Bishan, 2015, P ICLR, V0, P0
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3634
   Zhang Y, 2020, INT J GEOGR INF SCI, V34, P969, DOI 10.1080/13658816.2019.1697879
   Zhao ZL, 2016, INT J GEOGR INF SCI, V30, P1738, DOI 10.1080/13658816.2015.1137298
   Zheng XH, 2016, IEEE T INTELL TRANSP, V17, P620, DOI 10.1109/TITS.2015.2480157
   Zhu D, 2020, ANN AM ASSOC GEOGR, V110, P408, DOI 10.1080/24694452.2019.1694403
   Zhu D, 2018, INT J GEOGR INF SCI, V32, P783, DOI 10.1080/13658816.2017.1413192
   Zhu D, 2017, APPL GEOGR, V86, P152, DOI 10.1016/j.apgeog.2017.07.001
   Zhu L, 2019, IEEE T INTELL TRANSP, V20, P383, DOI 10.1109/TITS.2018.2815678
NR 69
TC 24
Z9 24
U1 17
U2 44
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1524-9050
EI 1558-0016
J9 IEEE T INTELL TRANSP
JI IEEE Trans. Intell. Transp. Syst.
PD DEC 15
PY 2021
VL 22
IS 12
BP 7474
EP 7484
DI 10.1109/TITS.2020.3003310
PG 11
WC Engineering, Civil; Engineering, Electrical & Electronic; Transportation Science & Technology
SC Engineering; Transportation
GA XD4ZF
UT WOS:000722718400016
DA 2023-04-26
ER

PT J
AU Khanna, K
   Martha, TR
   Roy, P
   Kumar, KV
AF Khanna, Kirti
   Martha, Tapas R.
   Roy, Priyom
   Kumar, K. Vinod
TI Effect of time and space partitioning strategies of samples on regional landslide susceptibility modelling
SO LANDSLIDES
LA English
DT Article
DE Predictive Modelling; Bivariate; Multivariate; Geofactors; Temporal and ROC
AB Assessment of the spatial probability of future landslide occurrences for disaster risk reduction is done through landslide susceptibility modelling. In this study, we investigated the effect of time and space partitioning strategies of samples on the performance of regional landslide susceptibility models on macro-scale mapping in the state of Mizoram, India, covering 21,087 km(2) area. We used landslide inventory data of 2014 and 2017 periods consisting of 1205 and 2265 landslides, respectively, to train and test the models with four sampling strategies such as spatial, temporal, temporal (size constrained) and temporal (geographic constrained). We used five commonly inherited models such as multiclass weighted overlay (MCWO), information value (IV), weights of evidence (WoE), logistic regression (LR) and artificial neural network (ANN) to evaluate the effect of sampling strategies on the model performance for regional landslide susceptibility mapping. Validation of model performance was done using receiver operating characteristic (ROC) curve. Traditional spatial sampling strategy applied to landslides in 2014 with a random split in 70:30 proportion provided a high performance of all the five models but failed to predict landslides in 2017. The landslide incidences in 2017, when used for model validation either entirely or in different split conditions (both size and geographic constrained), provided consistent performance, even though the testing sample size is large or have a different spatial disposition, if the training was carried out with non-linear susceptibility models such as LR and ANN using landslide incidences in 2014. Results show the importance of sample selection during validation of landslide susceptibility models on a regional scale.
C1 [Khanna, Kirti; Martha, Tapas R.; Roy, Priyom; Kumar, K. Vinod] Indian Space Res Org, Geosci Grp, Natl Remote Sensing Ctr, Hyderabad 500037, Telangana, India.
C3 Department of Space (DoS), Government of India; Indian Space Research Organisation (ISRO); National Remote Sensing Centre (NRSC)
RP Martha, TR (corresponding author), Indian Space Res Org, Geosci Grp, Natl Remote Sensing Ctr, Hyderabad 500037, Telangana, India.
EM trmartha@rediffmail.com
CR Aleotti P., 1999, B ENG GEOL ENVIRON, V58, P21, DOI 10.1007/s100640050066
   [Anonymous], 1995, NEURAL NETWORKS PATT, V0, P0
   Ayalew L, 2005, GEOMORPHOLOGY, V65, P15, DOI 10.1016/j.geomorph.2004.06.010
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Blahut J, 2010, GEOMORPHOLOGY, V119, P36, DOI 10.1016/j.geomorph.2010.02.017
   Bonham-Carter GF., 1994, GEOGRAPHIC INFORM SY, V13, P398
   CARRARA A, 1991, EARTH SURF PROCESSES, V16, P427, DOI 10.1002/esp.3290160505
   Cevasco A, 2014, B ENG GEOL ENVIRON, V73, P859, DOI 10.1007/s10064-013-0544-x
   Chung CJF, 2003, NAT HAZARDS, V30, P451, DOI 10.1023/B:NHAZ.0000007172.62651.2b
   Di Napoli M, 2020, LANDSLIDES, V17, P1897, DOI 10.1007/s10346-020-01392-9
   Ermini L, 2005, GEOMORPHOLOGY, V66, P327, DOI 10.1016/j.geomorph.2004.09.025
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Frattini P, 2010, ENG GEOL, V111, P62, DOI 10.1016/j.enggeo.2009.12.004
   Froude MJ, 2018, NAT HAZARD EARTH SYS, V18, P2161, DOI 10.5194/nhess-18-2161-2018
   Ghosh S, 2011, GEOMORPHOLOGY, V131, P35, DOI 10.1016/j.geomorph.2011.04.019
   Gomez H, 2005, ENG GEOL, V78, P11, DOI 10.1016/j.enggeo.2004.10.004
   GSI, 2020, GEOL 50K MAP MIZ, V0, P0
   Guzzetti F, 2005, GEOMORPHOLOGY, V72, P272, DOI 10.1016/j.geomorph.2005.06.002
   Guzzetti F, 1999, GEOMORPHOLOGY, V31, P181, DOI 10.1016/S0169-555X(99)00078-1
   Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007
   HUTCHINSON JN, 1995, LANDSLIDES: GLISSEMENTS DE TERRAIN, VOL 3, P1805
   Kanungo D., 2009, J S ASIA DISASTER ST, V2, P81
   Kanungo DP, 2006, ENG GEOL, V85, P347, DOI 10.1016/j.enggeo.2006.03.004
   Kavzoglu T, 2014, LANDSLIDES, V11, P425, DOI 10.1007/s10346-013-0391-7
   Lee S, 2005, INT J REMOTE SENS, V26, P1477, DOI 10.1080/01431160412331331012
   Lee S, 2004, INT J REMOTE SENS, V25, P2037, DOI 10.1080/01431160310001618734
   Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X
   Lee S, 2002, ENVIRON GEOL, V43, P120, DOI 10.1007/s00254-002-0616-x
   Lee S, 2006, ENVIRON GEOL, V50, P847, DOI 10.1007/s00254-006-0256-7
   Lombardo L, 2020, EARTH-SCI REV, V209, P0, DOI 10.1016/j.earscirev.2020.103318
   Martha TR, 2016, J INDIAN SOC REMOTE, V44, P515, DOI 10.1007/s12524-015-0532-7
   Martha TR, 2010, GEOMORPHOLOGY, V116, P24, DOI 10.1016/j.geomorph.2009.10.004
   Martha TR, 2011, IEEE T GEOSCI REMOTE, V49, P4928, DOI 10.1109/TGRS.2011.2151866
   Mathew J, 2007, CURR SCI INDIA, V92, P628
   Mathew J, 2014, LANDSLIDES, V11, P575, DOI 10.1007/s10346-013-0408-2
   Montrasio L, 2014, NAT HAZARDS, V74, P1263, DOI 10.1007/s11069-014-1239-8
   Neuhauser B, 2007, GEOMORPHOLOGY, V86, P12, DOI 10.1016/j.geomorph.2006.08.002
   NRSC, 2012, NRSCRSAAERGGANDGDSEP, V0, P0
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
   Pardeshi SD, 2013, SPRINGERPLUS, V2, P0, DOI 10.1186/2193-1801-2-523
   Pellicani R, 2017, GEOMAT NAT HAZ RISK, V8, P1012, DOI 10.1080/19475705.2017.1292411
   Pradhan B, 2010, GEO-SPAT INF SCI, V13, P93, DOI 10.1007/s11806-010-0236-7
   Pudi R, 2018, J GEOL SOC INDIA, V91, P664, DOI 10.1007/s12594-018-0921-y
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Remondo J, 2003, NAT HAZARDS, V30, P437, DOI 10.1023/B:NHAZ.0000007201.80743.fc
   Sarkar S, 2013, J GEOL SOC INDIA, V82, P351, DOI 10.1007/s12594-013-0162-z
   Sawatzky D.L., 2009, SPATIAL DATA MODELLE, V0, P0
   Segoni S, 2020, LANDSLIDES, V17, P2443, DOI 10.1007/s10346-019-01340-2
   Sepe C., 2019, P IAEG AEG ANN M P, V1, P155, DOI 10.1007/978-3-319-93124-1_19
   SPSS, 2017, SPSS WIND VERS 23 20, V0, P0
   Taalab K, 2018, BIG EARTH DATA, V2, P159, DOI 10.1080/20964471.2018.1472392
   Vahidnia MH, 2010, COMPUT GEOSCI-UK, V36, P1101, DOI 10.1016/j.cageo.2010.04.004
   Vakhshoori V, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11112292
   Valdiya K.S., 2016, MAKING INDIA, V0, P0, DOI DOI 10.1007/978-3-319-25029-8
   Van Westen CJ, 1993, ITC PUBLICATION, V0, P0
   vanWesten CJ, 1997, GEOL RUNDSCH, V86, P404, DOI 10.1007/s005310050149
   Varnes and the IAEG Commission on Landslides and Other Mass-Movements, 1984, NATURAL HAZARDS SERI, V3, P63
   Xiao T, 2020, LANDSLIDES, V17, P627, DOI 10.1007/s10346-019-01299-0
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   YIN KL, 1988, LANDSLIDES VOLS 13, V0, P1269
NR 60
TC 12
Z9 12
U1 10
U2 49
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1612-510X
EI 1612-5118
J9 LANDSLIDES
JI Landslides
PD JUN 15
PY 2021
VL 18
IS 6
BP 2281
EP 2294
DI 10.1007/s10346-021-01627-3
EA JAN 2021
PG 14
WC Engineering, Geological; Geosciences, Multidisciplinary
SC Engineering; Geology
GA SK1LC
UT WOS:000612890400002
DA 2023-04-26
ER

PT J
AU Liu, X
   Fatoyinbo, TE
   Thomas, NM
   Guan, WW
   Zhan, YN
   Mondal, P
   Lagomasino, D
   Simard, M
   Trettin, CC
   Deo, R
   Barenblitt, A
AF Liu, Xue
   Fatoyinbo, Temilola E.
   Thomas, Nathan M.
   Guan, Weihe Wendy
   Zhan, Yanni
   Mondal, Pinki
   Lagomasino, David
   Simard, Marc
   Trettin, Carl C.
   Deo, Rinki
   Barenblitt, Abigail
TI Large-Scale High-Resolution Coastal Mangrove Forests Mapping Across West Africa With Machine Learning Ensemble and Satellite Big Data
SO FRONTIERS IN EARTH SCIENCE
LA English
DT Article
DE coastal environment; land cover and land use; mangrove forests; remote sensing; machine learning; high resolution; satellite big data; large scale
ID neural-network classification; landsat-8 data; cover; biomass; extent; opportunity; sentinel-2; algorithms; height; marsh
AB Coastal mangrove forests provide important ecosystem goods and services, including carbon sequestration, biodiversity conservation, and hazard mitigation. However, they are being destroyed at an alarming rate by human activities. To characterize mangrove forest changes, evaluate their impacts, and support relevant protection and restoration decision making, accurate and up-to-date mangrove extent mapping at large spatial scales is essential. Available large-scale mangrove extent data products use a single machine learning method commonly with 30 m Landsat imagery, and significant inconsistencies remain among these data products. With huge amounts of satellite data involved and the heterogeneity of land surface characteristics across large geographic areas, finding the most suitable method for large-scale high-resolution mangrove mapping is a challenge. The objective of this study is to evaluate the performance of a machine learning ensemble for mangrove forest mapping at 20 m spatial resolution across West Africa using Sentinel-2 (optical) and Sentinel-1 (radar) imagery. The machine learning ensemble integrates three commonly used machine learning methods in land cover and land use mapping, including Random Forest (RF), Gradient Boosting Machine (GBM), and Neural Network (NN). The cloud-based big geospatial data processing platform Google Earth Engine (GEE) was used for pre-processing Sentinel-2 and Sentinel-1 data. Extensive validation has demonstrated that the machine learning ensemble can generate mangrove extent maps at high accuracies for all study regions in West Africa (92%-99% Producer's Accuracy, 98%-100% User's Accuracy, 95%-99% Overall Accuracy). This is the first-time that mangrove extent has been mapped at a 20 m spatial resolution across West Africa. The machine learning ensemble has the potential to be applied to other regions of the world and is therefore capable of producing high-resolution mangrove extent maps at global scales periodically.
C1 [Liu, Xue; Guan, Weihe Wendy; Deo, Rinki] Harvard Univ, Ctr Geog Anal CGA, Cambridge, MA 02138 USA.
   [Liu, Xue; Zhan, Yanni; Mondal, Pinki] Columbia Univ, Ctr Int Earth Sci Informat Network CIESIN, Palisades, NY 10964 USA.
   [Fatoyinbo, Temilola E.; Thomas, Nathan M.; Barenblitt, Abigail] NASA, Biospher Sci Lab, GSFC, Greenbelt, MD USA.
   [Thomas, Nathan M.; Barenblitt, Abigail] Univ Maryland, Earth Syst Sci Interdisciplinary Ctr, College Pk, MD 20742 USA.
   [Mondal, Pinki] Univ Delaware, Dept Geog & Spatial Sci, Newark, DE USA.
   [Mondal, Pinki] Univ Delaware, Dept Plant & Soil Sci, Newark, DE 19717 USA.
   [Lagomasino, David] East Carolina Univ, Dept Coastal Studies, Wanchese, NC USA.
   [Simard, Marc] CALTECH, Jet Prop Lab, Pasadena, CA USA.
   [Trettin, Carl C.] US Forest Serv, Southern Res Stn, Ctr Forested Wetlands Res, Cordesville, SC USA.
C3 Harvard University; Columbia University; National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center; University System of Maryland; University of Maryland College Park; University of Delaware; University of Delaware; University of North Carolina; East Carolina University; California Institute of Technology; National Aeronautics & Space Administration (NASA); NASA Jet Propulsion Laboratory (JPL); United States Department of Agriculture (USDA); United States Forest Service
RP Liu, X (corresponding author), Harvard Univ, Ctr Geog Anal CGA, Cambridge, MA 02138 USA.; Liu, X (corresponding author), Columbia Univ, Ctr Int Earth Sci Informat Network CIESIN, Palisades, NY 10964 USA.
EM xliu@fas.harvard.edu
FU NSF I/UCRC Spatiotemporal Innovation Center [1841520]; National Aeronautics and Space Administration (NASA); Direct For Computer & Info Scie & Enginr; Division Of Computer and Network Systems [1841520] Funding Source: National Science Foundation
CR Abdi AM, 2020, GISCI REMOTE SENS, V57, P1, DOI 10.1080/15481603.2019.1650447
   Ali K., 2016, INT J COMPUT APPL, V141, P0975, DOI 10.5120/ijca2016909936
   Asian A, 2016, REMOTE SENS ENVIRON, V183, P65, DOI 10.1016/j.rse.2016.04.026
   Atzberger C, 2013, REMOTE SENS-BASEL, V5, P949, DOI 10.3390/rs5020949
   Avdan U., 2018, 2018 ISPRS TC 3 MIDT, V0, P0
   Bandaranayake W., 1998, MANGROVES SALT MARSH, V2, P133, DOI 10.1023/A:1009988607044
   Bunting P, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101669
   Colin B., 2017, OPEN J STAT, V7, P859
   Corcoran E, 2007, MANGROVES W CENTRAL, V0, P0
   Curnick DJ, 2019, SCIENCE, V363, P239, DOI 10.1126/science.aaw0809
   Danielsen F, 2005, SCIENCE, V310, P643, DOI 10.1126/science.1118387
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Donato DC, 2011, NAT GEOSCI, V4, P293, DOI 10.1038/ngeo1123
   Duke NC, 2016, MAR POLLUT BULL, V109, P700, DOI 10.1016/j.marpolbul.2016.06.082
   Emuedo O.A., 2014, GLOBAL J HUMAN SOCIA, V14, P9
   Fatoyinbo TE, 2013, INT J REMOTE SENS, V34, P668, DOI 10.1080/01431161.2012.712224
   Feka Njisuh Z., 2011, INTERNATIONAL JOURNAL OF BIODIVERSITY SCIENCE ECOSYSTEM SERVICES & MANAGEMENT, V7, P217, DOI 10.1080/21513732.2011.634436
   Gauci A, 2018, ENVIRON MODELL SOFTW, V99, P1, DOI 10.1016/j.envsoft.2017.09.014
   GEE, 2019, SENT 1 ALG, V0, P0
   GEE, 2019, SENT 2 MSI MULTISPEC, V0, P0
   Georganos S, 2018, IEEE GEOSCI REMOTE S, V15, P607, DOI 10.1109/LGRS.2018.2803259
   Giri C, 2011, GLOBAL ECOL BIOGEOGR, V20, P154, DOI 10.1111/j.1466-8238.2010.00584.x
   Giri C, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8090783
   Gislason P.O., 2004, P 2004 IEEE INT GEOS, V0, P0
   Godinho S, 2016, INT J APPL EARTH OBS, V49, P151, DOI 10.1016/j.jag.2016.02.008
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Hamdan O, 2014, IOP C SER EARTH ENV, V18, P0, DOI 10.1088/1755-1315/18/1/012016
   Hamilton SE, 2016, GLOBAL ECOL BIOGEOGR, V25, P729, DOI 10.1111/geb.12449
   Hird JN, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121315
   Horning N., 2010, INT C GEOINF SPAT IN, V0, P0
   Hutchison J, 2014, CONSERV LETT, V7, P233, DOI 10.1111/conl.12060
   Jhonnerie R, 2015, PROCEDIA ENVIRON SCI, V24, P215, DOI 10.1016/j.proenv.2015.03.028
   Karakizi C, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081214
   Kathiresan K, 2005, ESTUAR COAST SHELF S, V65, P601, DOI 10.1016/j.ecss.2005.06.022
   Knudby A, 2014, INT J APPL EARTH OBS, V28, P90, DOI 10.1016/j.jag.2013.11.015
   Kuenzer C, 2014, APPL GEOGR, V53, P354, DOI 10.1016/j.apgeog.2014.07.002
   Lagomasino D, 2019, ENVIRON RES LETT, V14, P0, DOI 10.1088/1748-9326/aaf0de
   Li M., 2014, 22 INT C GEOINF KAOH, V0, P0
   Liu X, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101247
   Lopes M, 2020, METHODS ECOL EVOL, V11, P532, DOI 10.1111/2041-210X.13359
   Lucas R, 2014, MAR FRESHWATER RES, V65, P589, DOI 10.1071/MF13177
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   MILLER DM, 1995, COMPUT GEOSCI, V21, P377, DOI 10.1016/0098-3004(94)00082-6
   Ming DP, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.035021
   Mondal P, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242928
   Mondal P, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010012
   Murdiyarso D, 2015, NAT CLIM CHANGE, V5, P1089, DOI 10.1038/nclimate2734
   Na XD, 2010, PHOTOGRAMM ENG REM S, V76, P833, DOI 10.14358/PERS.76.7.833
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, P0, DOI 10.3389/fnbot.2013.00021
   Onyena AP, 2020, GLOB ECOL CONSERV, V22, P0, DOI 10.1016/j.gecco.2020.e00961
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Pan X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060920
   Pimple U., 2018, J COMPUT COMMUN, V6, P247, DOI 10.4236/jcc.
   Piramanayagam S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091429
   Reed R., 1999, NEURAL SMITHING SUPE, V0, P0
   Rogers K, 2017, HYDROBIOLOGIA, V803, P49, DOI 10.1007/s10750-017-3257-5
   Rovai AS, 2018, NAT CLIM CHANGE, V8, P534, DOI 10.1038/s41558-018-0162-5
   Sanderman J, 2018, ENVIRON RES LETT, V13, P0, DOI 10.1088/1748-9326/aabe1c
   Shelestov A, 2017, FRONT EARTH SC-SWITZ, V5, P1, DOI 10.3389/feart.2017.00017
   Sifleet S., 2011, R1104 NI NICH I ENV, V0, P1
   Siikamaki J, 2012, P NATL ACAD SCI USA, V109, P14369, DOI 10.1073/pnas.1200519109
   Simard M, 2019, NAT GEOSCI, V12, P40, DOI 10.1038/s41561-018-0279-1
   Skakun S., 2016, P IEEE GEOSC REM SEN, V0, P0
   Tappan G.G., 2016, W AFRICA LAND USE LA, V0, P0
   Thomas N, 2019, INT J APPL EARTH OBS, V80, P257, DOI 10.1016/j.jag.2019.03.013
   Thomas N, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091466
   Tian SH, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110954
   Pham TD, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030230
   Toosi NB, 2019, GLOB ECOL CONSERV, V19, P0, DOI 10.1016/j.gecco.2019.e00662
   Walsh G.M., 2015, NEW CROPLAND RURAL S, V0, P0
   Wan LM, 2019, ANN GIS, V25, P45, DOI 10.1080/19475683.2018.1564791
   Wang L, 2008, PHOTOGRAMM ENG REM S, V74, P921, DOI 10.14358/PERS.74.7.921
   White JC, 2016, CAN J REMOTE SENS, V42, P619, DOI 10.1080/07038992.2016.1207484
   Xiong J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101065
   Yuan H, 2009, REMOTE SENS-BASEL, V1, P243, DOI 10.3390/rs1030243
   Zhan X, 2002, REMOTE SENS ENVIRON, V83, P336, DOI 10.1016/S0034-4257(02)00081-0
   Zhang CY, 2018, REMOTE SENS ENVIRON, V204, P366, DOI 10.1016/j.rse.2017.10.018
   Zhang CY, 2014, GEOCARTO INT, V29, P228, DOI 10.1080/10106049.2012.756940
   Zhang X, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030417
   Zhu Z., 2012, ENSEMBLE METHODS FDN, V0, P0
NR 81
TC 15
Z9 17
U1 15
U2 49
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 2296-6463
J9 FRONT EARTH SC-SWITZ
JI Front. Earth Sci.
PD JAN 21
PY 2021
VL 8
IS 
BP 
EP 
DI 10.3389/feart.2020.560933
PG 15
WC Geosciences, Multidisciplinary
SC Geology
GA QB6SU
UT WOS:000614271300001
DA 2023-04-26
ER

PT J
AU Elhag, M
   Bahrawi, J
   Boteva, S
AF Elhag, Mohamed
   Bahrawi, Jarbou
   Boteva, Silvena
TI Input/output inconsistencies of daily evapotranspiration conducted empirically using remote sensing data in arid environments
SO OPEN GEOSCIENCES
LA English
DT Article
DE daily evapotranspiration; desirability function; neural network analysis; SEBS
ID artificial neural-networks; regional evapotranspiration; energy-balance; water-quality; surface; model; optimization; prediction; vegetation; algorithm
AB The reliable quantification of daily evapotranspiration (ET) over vast croplands is a quest in many scholarly works aimed at the precise practice of water resources management. Remote sensing-based empirical and nonempirical models were developed to overcome large-scale quantification issues, which are usually experienced when using conventional approaches for the estimation of ET. The surface energy balance system (SEBS) model was used to quantify the daily ET in the arid/semiarid over Wadi Ad-Dwaser, Saudi. SEBS input variables are parametrically sensitive and climatic dependent, and the model input/output dependencies are of high comprehensibility; therefore, the optimization analysis of SEBS input/ output parameters is the target of the current research. SEBS inputs reciprocal inconsistencies were determined using the artificial neural network analysis, while the output dependencies on the daily ET estimation were mapped. Results demonstrated that the temperature and relative humidity are the most sensitive parameters to be considered in the routine crop monitoring procedure. SEBS output thematic maps showed the robust proportional correlation between the daily ET and the conducted temperature map. Moreover, the estimated daily ET was inversely correlated with the estimated cold sensible heat fluxes. The findings suggest systematic monitoring and forecasting procedures for efficient water-saving management plans in Saudi Arabia.
C1 [Elhag, Mohamed; Bahrawi, Jarbou] King Abdulaziz Univ, Fac Meteorol Environm & Arid Land Agr, Dept Hydrol & Water Resources Management, Jeddah 21589, Saudi Arabia.
   [Elhag, Mohamed] Chinese Acad Sci, Inst Remote Sensing & Digital Earth RADI, Beijing 100094, Peoples R China.
   [Elhag, Mohamed] German Univ Technol Oman, Fac Sci, Dept Appl Geosci, Muscat 1816, Oman.
   [Boteva, Silvena] Sofia Univ St Kl Ohridski, Dept Ecol & Nat Conservat, Fac Biol, 8 Dragan Tsankov Blvd, Sofia 1164, Bulgaria.
C3 King Abdulaziz University; Chinese Academy of Sciences; The Institute of Remote Sensing & Digital Earth, CAS; University of Sofia
RP Elhag, M (corresponding author), King Abdulaziz Univ, Fac Meteorol Environm & Arid Land Agr, Dept Hydrol & Water Resources Management, Jeddah 21589, Saudi Arabia.; Elhag, M (corresponding author), Chinese Acad Sci, Inst Remote Sensing & Digital Earth RADI, Beijing 100094, Peoples R China.; Elhag, M (corresponding author), German Univ Technol Oman, Fac Sci, Dept Appl Geosci, Muscat 1816, Oman.
EM melhag@kau.edu.sa
FU Deanship of Scientific Research (DSR), King Abdulaziz University, Jeddah [G-65-155-1440]
CR Abyaneh HZ, 2014, J ENVIRON HEALTH SCI, V12, P0, DOI 10.1186/2052-336X-12-40
   ALLEN RG, 1989, AGRON J, V81, P650, DOI 10.2134/agronj1989.00021962008100040019x
   Allen RG, 2007, J IRRIG DRAIN ENG, V133, P380, DOI 10.1061/(ASCE)0733-9437(2007)133:4(380)
   Almazroui M, 2013, INT J CLIMATOL, V33, P2247, DOI 10.1002/joc.3721
   BRUNET Y, 1991, ISPRS J PHOTOGRAMM, V46, P311, DOI 10.1016/0924-2716(91)90062-Z
   Chen KS, 2003, IEEE T GEOSCI REMOTE, V41, P90, DOI 10.1109/TGRS.2002.807587
   Chen X, 2013, HYDROL EARTH SYST SC, V17, P1607, DOI 10.5194/hess-17-1607-2013
   Cheng C, 1997, J STAT PLAN INFER, V59, P291, DOI 10.1016/S0378-3758(96)00110-3
   Cleugh HA, 2007, REMOTE SENS ENVIRON, V106, P285, DOI 10.1016/j.rse.2006.07.007
   DERRINGER G, 1980, J QUAL TECHNOL, V12, P214, DOI 10.1080/00224065.1980.11980968
   Dureja JS, 2016, P I MECH ENG B-J ENG, V230, P389, DOI 10.1177/0954405414558731
   El Bastawesy M, 2013, HYDROL EARTH SYST SC, V17, P1493, DOI 10.5194/hess-17-1493-2013
   Elhag M, 2014, LIFE SCI J, V11, P201
   Elhag M, 2017, GEOSCI INSTRUM METH, V6, P141, DOI 10.5194/gi-6-141-2017
   Elhag M, 2016, J INDIAN SOC REMOTE, V44, P435, DOI 10.1007/s12524-015-0502-0
   Elhag M, 2016, J SENSORS, V2016, P0, DOI 10.1155/2016/7596175
   Elhag M, 2014, ENVIRON EARTH SCI, V72, P4995, DOI 10.1007/s12665-014-3367-6
   Elhag M, 2011, WATER RESOUR MANAG, V25, P2731, DOI 10.1007/s11269-011-9835-9
   Elkan C, 2015, CORR, V0, P0
   Ficici F, 2012, INT J ADV SCI, V2, P114
   Glenn EP, 2008, SENSORS-BASEL, V8, P2136, DOI 10.3390/s8042136
   HAJKOWICZ SA, 2000, J ENVIRON PLANN MAN, V43, P505, DOI 10.1080/713676575
   Hartman MD, 2007, ECOL MODEL, V200, P493, DOI 10.1016/j.ecolmodel.2006.09.001
   Jia K, 2016, REMOTE SENS ENVIRON, V177, P184, DOI 10.1016/j.rse.2016.02.019
   Johnson Norman L, 1995, BETA DISTRIBUTIONS, V0, P0
   Krishnan N, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7619-8
   Kumar V, 1997, J AM WATER RESOUR AS, V33, P1255, DOI 10.1111/j.1752-1688.1997.tb03550.x
   Kunnan AJ, 2013, ENCY APPL LINGUISTIC, V0, P0
   Kustas WP, 1996, HYDROLOG SCI J, V41, P495, DOI 10.1080/02626669609491522
   LADSON AR, 1992, J HYDROL, V138, P385, DOI 10.1016/0022-1694(92)90127-H
   Lek S., 2012, ARTIFICIAL NEURONAL, V0, P0
   Li FQ, 2005, J HYDROMETEOROL, V6, P878, DOI 10.1175/JHM464.1
   Li ZL, 2009, SENSORS-BASEL, V9, P3801, DOI 10.3390/s90503801
   Liu C, 1999, INTERFACE PROCESSES, V0, P0
   Maiyar LM, 2013, PROCEDIA ENGINEER, V64, P1276, DOI 10.1016/j.proeng.2013.09.208
   McColl KA, 2019, J ADV MODEL EARTH SY, V11, P2036, DOI 10.1029/2019MS001685
   Monahan AH, 2000, J CLIMATE, V13, P821, DOI 10.1175/1520-0442(2000)013<0821:NPCABN>2.0.CO;2
   Montes C, 2017, IEEE GEOSCI REMOTE S, V14, P459, DOI 10.1109/LGRS.2017.2650143
   Muthukrishnan N, 2012, J IND PROD ENG, V29, P515, DOI 10.1080/10170669.2012.728540
   Norman L., 2010, SUSTAINABILITY, V2, P2044, DOI 10.3390/su2072044
   Olioso A, 1999, REMOTE SENS ENVIRON, V68, P341, DOI 10.1016/S0034-4257(98)00121-7
   Peng J, 2012, INT GEOSCI REMOTE SE, V0, PP702, DOI 10.1109/IGARSS.2012.6351468
   Pettorelli N, 2005, TRENDS ECOL EVOL, V20, P503, DOI 10.1016/j.tree.2005.05.011
   Pinnix GD, 2019, AGR WATER MANAGE, V223, P0, DOI 10.1016/j.agwat.2019.105725
   Psilovikos A, 2013, WATER RESOUR MANAG, V27, P4115, DOI 10.1007/s11269-013-0368-2
   Robert CP, 1996, J AM STAT ASSOC, V91, P167, DOI 10.2307/2291392
   Roerink GJ, 2000, PHYS CHEM EARTH PT B, V25, P147, DOI 10.1016/S1464-1909(99)00128-8
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Sarkkola S, 2010, CAN J FOREST RES, V40, P1485, DOI 10.1139/X10-084
   Sewell PD, 2020, FOREST ECOL MANAG, V462, P0, DOI 10.1016/j.foreco.2020.117986
   ShahzadSultan IA, 2008, PAK J METEOROL, V4, P49
   Sibalija TV, 2012, J INTELL MANUF, V23, P1511, DOI 10.1007/s10845-010-0451-y
   Singh Ankita, 2013, INTERNATIONAL JOURNAL OF INDUSTRIAL AND SYSTEMS ENGINEERING, V14, P175
   Su HB, 2005, J HYDROMETEOROL, V6, P910, DOI 10.1175/JHM466.1
   Su Z, 2002, HYDROL EARTH SYST SC, V6, P85, DOI 10.5194/hess-6-85-2002
   Su Z, 2001, J APPL METEOROL, V40, P1933, DOI 10.1175/1520-0450(2001)040<1933:AEOTMF>2.0.CO;2
   Su ZB, 2003, PHYS CHEM EARTH, V28, P89, DOI 10.1016/S1474-7065(03)00010-X
   조성래, 2015, JOURNAL OF THE KOREA SOCIETY OF DIGITAL INDUSTRY AND INFORMATION MANAGEMENT (사)디지털산업정보학회 논문지, V11, P33
   Taylor AR, 1981, METHOD SURFACE IRRIG, V0, P0
   Vafakhah M, 2012, CAN J CIVIL ENG, V39, P402, DOI 10.1139/L2012-011
   Vinukollu RK, 2011, REMOTE SENS ENVIRON, V115, P801, DOI 10.1016/j.rse.2010.11.006
   Wen XH, 2013, ENVIRON MONIT ASSESS, V185, P4361, DOI 10.1007/s10661-012-2874-8
   Wu CD, 2010, WATER RESOUR MANAG, V24, P3773, DOI 10.1007/s11269-010-9633-9
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   Yilmaz N, 2017, DESALIN WATER TREAT, V91, P386, DOI 10.5004/dwt.2017.20844
   Zhang Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101029
NR 66
TC 3
Z9 3
U1 2
U2 7
PU DE GRUYTER POLAND SP Z O O
PI WARSAW
PA BOGUMILA ZUGA 32A STR, 01-811 WARSAW, MAZOVIA, POLAND
SN 2391-5447
EI 
J9 OPEN GEOSCI
JI Open Geosci.
PD MAR 17
PY 2021
VL 13
IS 1
BP 321
EP 334
DI 10.1515/geo-2020-0141
PG 14
WC Geosciences, Multidisciplinary
SC Geology
GA RL5PD
UT WOS:000639024000001
DA 2023-04-26
ER

PT J
AU Alsabban, MS
   Salem, N
   Malik, HM
AF Alsabban, Maha S.
   Salem, Nema
   Malik, Hebatullah M.
TI Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) Power Forecasting
SO APPEEC 2021: 2021 13TH IEEE PES ASIA PACIFIC POWER &AMP; ENERGY ENGINEERING CONFERENCE (APPEEC)
LA English
DT Proceedings Paper
DE LSTM-RNN; load forecasting; power; deep learning; artificial intelligence
AB The geographical position of the Kingdom of Saudi Arabia has significant potentials for utilizing renewable energy resources, which aligns with the country's vision for 2030. This paper proposes a solution to achieve energy sustainability by forecasting future load demands through adopting three different scenarios. We used the outsourced Individual Household Electric Power Consumption Dataset, University of California- Irvine repository, for testing our proposed system. We utilized the Long Short-term Memory-Recurrent Neural Network (LSTM-RNN) algorithm to estimate the whole house power consumption for different horizons: every 15 minutes, daily, weekly, and monthly. Next, we evaluated the performance of the system by Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Square Error (RMSE), and R-2 score metrics. Then, we applied the Mean Absolute Percentage Error (MAPE) to find its accuracy. The results showed that the monthly forecasting interpretation scenario was the best performing model. That scenario used (n-1) months for training and the last month for testing. The scores for that model were 0.034 (MAE), 0.001 (MSE), 0.034 (RMSE), and 97.16% (accuracy). The constructed model successfully achieved its goals of predicting the active power of the household and now can be accommodated on energy applications not only in Saudi Arabia but also in any other country.
C1 [Alsabban, Maha S.; Salem, Nema; Malik, Hebatullah M.] Effat Univ, Elect & Comp Engn, Jeddah, Saudi Arabia.
C3 Effat University
RP Alsabban, MS (corresponding author), Effat Univ, Elect & Comp Engn, Jeddah, Saudi Arabia.
EM maalsabban@effat.edu.sa; nsalem@effatuniversity.edu.sa; hemalik@effat.edu.sa
CR Alam SMM, 2020, INNOV SMART GRID TEC, V0, P0
   Algorithmia, 2018, INTRO LOSS FUNCTIONS, V0, P0
   Amarasinghe K, 2017, PROC IEEE INT SYMP, V0, PP1483, DOI 10.1109/ISIE.2017.8001465
   [Anonymous], 2016, ELECT LOAD FORECASTI, V0, P0
   Brownlee J., 2016, OVERFITTING UNDERFIT, V0, P0
   Brownlee J, 2017, RESHAPE INPUT DATA L, V0, P0
   Brownlee J., 2018, DIFFERENCE BATCH EPO, V0, P0
   Brownlee J., 2019, MACH LEARN MASTERY, V0, P1
   Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679
   Estebsari A, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9010068
   Han Jun, 2020, 2020 ASIA ENERGY AND ELECTRICAL ENGINEERING SYMPOSIUM (AEEES), V0, PP816, DOI 10.1109/AEEES48850.2020.9121467
   HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2
   Hong Y, 2020, IEEE ACCESS, V8, P55785, DOI 10.1109/ACCESS.2020.2981817
   Jones M., 2014, BUILDING VALVE AMPLI, Vsecond, P381
   Kolter J. Zico, 2011, SUSTKDD, V0, P0
   Kong WC, 2019, IEEE T SMART GRID, V10, P841, DOI 10.1109/TSG.2017.2753802
   Leonel J., 2019, HYPERPARAMETERS MACH, V0, P0
   Madsen H, 2005, WIND ENG, V29, P475, DOI 10.1260/030952405776234599
   Makonin S., 2020, AMPDS2: THE ALMANAC OF MINUTELY POWER DATASET (VERSION 2), V0, P0, DOI DOI 10.7910/DVN/FIE0S4
   Olah C, 2015, UNDERSTANDING LSTM N, V0, P0
   PARK DC, 1991, IEEE T POWER SYST, V6, P442, DOI 10.1109/59.76685
   Peng Q, 2020, CHIN CONTR CONF, V0, PP5423, DOI 10.23919/CCC50068.2020.9188453
   Shaker H, 2013, CAN CON EL COMP EN, V0, P109
   Singh S., 2019, FULLY CONNECTED LAYE, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stellwagen E., 2011, FORECASTING 101 GUID, V0, P0
   Subrat, 2016, NEURAL NETWORK WHAT, V0, P0
   Tuovila A, 2020, FORECASTING DEFINITI, V0, P0
   Vadda Praveen, 2013, SMART METERING SMART, V0, P0
   Wang XL, 2020, APPL ENERG, V259, P0, DOI 10.1016/j.apenergy.2019.114145
   Wang Y., 2014, RES APPLICABILITY UL, V0, P0, DOI DOI 10.1049/cp.2014.0869
   Welikala S, 2019, IEEE T SMART GRID, V10, P448, DOI 10.1109/TSG.2017.2743760
   Yuvaraju M, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), V0, PP395, DOI 10.1109/ICICCS48265.2020.9121116
   Zhang XM, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP110, DOI 10.1109/ICMLA.2018.00024
NR 39
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/APPEEC50844.2021.9687681
PG 8
WC Energy & Fuels; Engineering, Electrical & Electronic
SC Energy & Fuels; Engineering
GA BS9GL
UT WOS:000780531700008
DA 2023-04-26
ER

PT J
AU Agren, AM
   Larson, J
   Paul, SS
   Laudon, H
   Lidberg, W
AF Agren, Anneli M.
   Larson, Johannes
   Paul, Siddhartho Shekhar
   Laudon, Hjalmar
   Lidberg, William
TI Use of multiple LIDAR-derived digital terrain indices and machine learning for high-resolution national-scale soil moisture mapping of the Swedish forest landscape
SO GEODERMA
LA English
DT Article
DE LIDAR; Soil moisture; Machine learning; Extreme gradient boosting; Land-use management
ID wet-areas; classification; dynamics; patterns; runoff; dem
AB Spatially extensive high-resolution soil moisture mapping is valuable in practical forestry and land management, but challenging. Here we present a novel technique involving use of LIDAR-derived terrain indices and machine learning (ML) algorithms capable of accurately modeling soil moisture at 2 m spatial resolution across the entire Swedish forest landscape. We used field data from about 20,000 sites across Sweden to train and evaluate multiple ML models. The predictor features (variables) included a suite of terrain indices generated from a national LIDAR digital elevation model and ancillary environmental features, including surficial geology, climate and land use, enabling adjustment of soil moisture class maps to regional or local conditions. Extreme gradient boosting (XGBoost) provided better performance for a 2-class model, manifested by Cohen's Kappa and Matthews Correlation Coefficient (MCC) values of 0.69 and 0.68, respectively, than the other tested ML methods: Artificial Neural Network, Random Forest, Support Vector Machine, and Naive Bayes classification. The depth to water index, topographic wetness index, and 'wetland' categorization derived from Swedish property maps were the most important predictors for all models. The presented technique enabled generation of a 3-class model with Cohen's Kappa and MCC values of 0.58. In addition to the classified moisture maps, we investigated the technique's potential for producing continuous soil moisture maps. We argue that the probability of a pixel being classified as wet from a 2-class model can be used as a 0-100% index (dry to wet) of soil moisture, and the resulting maps could provide more valuable information for practical forest management than classified maps.
C1 [Agren, Anneli M.; Larson, Johannes; Paul, Siddhartho Shekhar; Laudon, Hjalmar; Lidberg, William] Swedish Univ Agr Sci, Dept Forest Ecol & Management, Umea, Sweden.
C3 Swedish University of Agricultural Sciences
RP Agren, AM (corresponding author), Swedish Univ Agr Sci, Dept Forest Ecol & Management, Umea, Sweden.
EM anneli.agren@slu.se
FU VINNOVA, EU Interreg
CR Agren AM, 2014, HYDROL EARTH SYST SC, V18, P3623, DOI 10.5194/hess-18-3623-2014
   Agren AM, 2014, BIOGEOSCIENCES, V11, P1199, DOI 10.5194/bg-11-1199-2014
   Agren AM, 2015, FORESTS, V6, P2982, DOI 10.3390/f6092982
   Akumu CE, 2019, GEODERMA, V351, P25, DOI 10.1016/j.geoderma.2019.05.014
   Ali I, 2015, REMOTE SENS-BASEL, V7, P16398, DOI 10.3390/rs71215841
   Bauer-Marschallingere B, 2019, IEEE T GEOSCI REMOTE, V57, P520, DOI 10.1109/TGRS.2018.2858004
   Beven K., 1979, HYDROLOG SCI J, V24, P43, DOI 10.1080/02626667909491834
   Beven K, 2013, WATER RESOUR RES, V49, P3071, DOI 10.1002/wrcr.20156
   Bhargavi P, 2009, INT J COMPUT SCI NET, V9, P117
   Biswas A, 2018, PEDOSPHERE, V28, P1, DOI 10.1016/S1002-0160(18)60001-3
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1961189.1961199
   CHEN L, 2019, ISPRS INT J GEO-INF, V8, P0
   Chen T., 2016, KDD16 P 22 ACM, V0, PP785, DOI 10.1145/2939672.2939785
   Chen Ting, 2020, XGBOOST EXTREME GRAD, V0, P0
   Chicco D, 2020, BMC GENOMICS, V21, P0, DOI 10.1186/s12864-019-6413-7
   Chicco D, 2017, BIODATA MIN, V10, P0, DOI 10.1186/s13040-017-0155-3
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Daher M, 2019, LAND USE SWEDEN, V0, P187
   Delancey ER, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0218165
   Delgado R, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0222916
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Edwards G, 2016, SOIL TILL RES, V155, P339, DOI 10.1016/j.still.2015.08.013
   El Hajj M, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121292
   Erdozain M, 2020, ECOL APPL, V30, P0, DOI 10.1002/eap.2077
   Fridman J, 2014, SILVA FENN, V48, P0, DOI 10.14214/sf.1095
   Gao Q, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17091966
   Georganos S, 2018, IEEE GEOSCI REMOTE S, V15, P607, DOI 10.1109/LGRS.2018.2803259
   Goldman MA, 2020, GEODERMA, V373, P0, DOI 10.1016/j.geoderma.2020.114420
   Grabs T, 2009, J HYDROL, V373, P15, DOI 10.1016/j.jhydrol.2009.03.031
   H ogbom L., 2020, GUIDE USING WET AREA, V0, P0
   Hird JN, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121315
   Hjerdt KN, 2004, WATER RESOUR RES, V40, P0, DOI 10.1029/2004WR003130
   Jaeger KL, 2019, J HYDROL X, V2, P0, DOI 10.1016/j.hydroa.2018.100005
   Jensen CK, 2017, HYDROL PROCESS, V31, P3350, DOI 10.1002/hyp.11259
   Jia Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141655
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Kuglerova L, 2017, HYDROL PROCESS, V31, P4238, DOI 10.1002/hyp.11281
   Kuglerova L, 2014, FOREST ECOL MANAG, V334, P74, DOI 10.1016/j.foreco.2014.08.033
   Kuglerova L, 2014, ECOLOGY, V95, P715, DOI 10.1890/13-0363.1
   Laudon H, 2013, WATER RESOUR RES, V49, P7154, DOI 10.1002/wrcr.20520
   Leach JA, 2017, WATER RESOUR RES, V53, P5420, DOI 10.1002/2016WR019804
   Leempoel K, 2015, METHODS ECOL EVOL, V6, P1373, DOI 10.1111/2041-210X.12427
   Lidberg W, 2020, AMBIO, V49, P475, DOI 10.1007/s13280-019-01196-9
   Lidberg W, 2017, HYDROL PROCESS, V31, P4660, DOI 10.1002/hyp.11385
   Lindsay J.B, 2020, WHITEBOXTOOLS USER M, V0, P0
   Lindsay JB, 2016, HYDROL PROCESS, V30, P846, DOI 10.1002/hyp.10648
   Lyon SW, 2004, HYDROL PROCESS, V18, P2757, DOI 10.1002/hyp.1494
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   Maxwell AE, 2016, PHOTOGRAMM ENG REM S, V82, P437, DOI 10.14358/PERS.82.6.437
   McGarty C., 2018, INT ENCY SOCIAL BEHA, V0, P0, DOI DOI 10.1016/B978-0-08-097086-8.24091-9
   Meles MB, 2020, J ENVIRON MANAGE, V255, P0, DOI 10.1016/j.jenvman.2019.109863
   Mohanty BP, 2017, VADOSE ZONE J, V16, P0, DOI 10.2136/vzj2016.10.0105
   Mohtashami S, 2017, SILVA FENN, V51, P0, DOI 10.14214/sf.2018
   Murphy PNC, 2008, FOREST CHRON, V84, P568, DOI 10.5558/tfc84568-4
   Murphy PNC, 2007, WETLANDS, V27, P846, DOI 10.1672/0277-5212(2007)27[846:MWACOT]2.0.CO;2
   Murphy PNC, 2011, ECOL MODEL, V222, P2314, DOI 10.1016/j.ecolmodel.2011.01.003
   Nielsen D., 2016, TREE BOOSTING XGBOOS, V0, P0
   Nussbaum M, 2018, SOIL-GERMANY, V4, P1, DOI 10.5194/soil-4-1-2018
   Nyberg L, 1999, HYDROL PROCESS, V13, P1557, DOI 10.1002/(SICI)1099-1085(19990815)13:11&lt;1557::AID-HYP835&gt;3.0.CO;2-S
   ONeil GL, 2020, ENVIRON MODELL SOFTW, V126, P0, DOI 10.1016/j.envsoft.2020.104665
   Ploum SW, 2018, HYDROL PROCESS, V32, P3049, DOI 10.1002/hyp.13184
   Powers D. M. W., 2011, J MACH LEARN TECHNOL, V2, P37
   QUINN PF, 1993, HYDROL PROCESS, V7, P425, DOI 10.1002/hyp.3360070407
   RASHMI KV, 2015, 18 INT C ART INT STA, V0, P0
   Renno CD, 2008, REMOTE SENS ENVIRON, V112, P3469, DOI 10.1016/j.rse.2008.03.018
   Ripley B. D., 2007, PATTERN RECOGN, V0, P0, DOI DOI 10.1017/CBO9780511812651
   Sabaghy S, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111586
   Seneviratne SI, 2010, EARTH-SCI REV, V99, P125, DOI 10.1016/j.earscirev.2010.02.004
   Sorensen R, 2007, J HYDROL, V347, P79, DOI 10.1016/j.jhydrol.2007.09.001
   STORY M, 1986, PHOTOGRAMM ENG REM S, V52, P397
   Tenenbaum DE, 2006, HYDROL PROCESS, V20, P219, DOI 10.1002/hyp.5895
   Wei L, 2018, AGR FOREST METEOROL, V259, P211, DOI 10.1016/j.agrformet.2018.05.012
   White B, 2012, CAN WATER RESOUR J, V37, P333, DOI 10.4296/cwrj2011-909
   Zeng LL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030284
NR 76
TC 20
Z9 20
U1 3
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0016-7061
EI 1872-6259
J9 GEODERMA
JI Geoderma
PD DEC 15
PY 2021
VL 404
IS 
BP 
EP 
DI 10.1016/j.geoderma.2021.115280
EA JUN 2021
PG 16
WC Soil Science
SC Agriculture
GA UX5LF
UT WOS:000700886000010
DA 2023-04-26
ER

PT J
AU Cheng, HQ
   Wu, HY
   Zheng, J
   Qi, KL
   Liu, WX
AF Cheng, Hongquan
   Wu, Huayi
   Zheng, Jie
   Qi, Kunlun
   Liu, Wenxuan
TI A hierarchical self-attention augmented Laplacian pyramid expanding network for change detection in high-resolution remote sensing images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE High-resolution remote sensing image; Change detection; Convolutional neural network; Self-attention; Laplacian pyramid
ID convolutional neural-network; land-use change; urban; classification
AB Change detection methods can achieve high learning ability and recognition accuracy with the introduction of deep convolutional neural networks, but due to the influence of the convolution kernel and deep feature sampling, problems such as the limited feature extraction range and loss of information are inevitable. In addition, there can be severe imbalance in the proportions of changed and unchanged pixels compromising the stability of model training. To address these interrelated problems, we propose a hierarchical self-attention augmented Laplacian pyramid expanding network (H-SALENet) for supervised change detection in high-resolution remote sensing images. H-SALENet is composed of an encoder and a decoder. In the encoder, H-SALENet combines a deep convolutional module with a hierarchical and long-range context augmentation module (HLAM) to extract the deep features of bi-temporal images; the representation capability of multi-level and long-range dependent change features is enhanced through deep convolution and 2D transformer-structured multihead self-attention learning. In the decoder, a Laplacian pyramid expansion module (LPEM) is proposed to catch change information at different scales and reduce high-frequency information loss simultaneously, thus weakening the influence of deep feature resampling on the change map. In addition, a data-balanced loss function concentrating on both the quantity and the complexity of the pixels was designed to reduce the influence of the imbalance between changed and unchanged pixels. H-SALENet was tested on two kinds of public datasets; the qualitative and quantitative experimental results show that the proposed network outperformed three benchmark change detection networks in terms of the integrity of change objects and the capability to obtain change contours.
C1 [Cheng, Hongquan; Wu, Huayi; Zheng, Jie; Liu, Wenxuan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Wu, Huayi] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Qi, Kunlun] China Univ Geosci Wuhan, Sch Geog & Informat Engn, 388 Lumo Rd, Wuhan 430078, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University; China University of Geosciences
RP Wu, HY (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
EM wuhuayi@whu.edu.cn
FU National Key Research and Development Program of China [2017YFB0503802]
CR Alcantarilla PF, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII, V0, P0
   Alexakis EB., 2020, INT ARCH PHOTOGRAMM, V43, P1507, DOI 10.5194/isprs-archives-XLIII-B3-2020-1507-2020
   Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Bello I, 2019, IEEE I CONF COMP VIS, V0, PP3285, DOI 10.1109/ICCV.2019.00338
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   BYRNE GF, 1980, REMOTE SENS ENVIRON, V10, P175, DOI 10.1016/0034-4257(80)90021-8
   Chen H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Cordonnier Jean-Baptiste, 2020, ICLR, V0, P0
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   GORDON SI, 1980, REMOTE SENS ENVIRON, V9, P189, DOI 10.1016/0034-4257(80)90028-0
   Guo E., 2018, LEARNING MEASURE CHA, V0, P0
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   He Q., 2021, IEEE T GEOSCI REMOTE, V0, PP1, DOI 10.1109/TGRS.2020.3045474
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   HOWARTH PJ, 1983, REMOTE SENS ENVIRON, V13, P149, DOI 10.1016/0034-4257(83)90019-6
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   JENSEN JR, 1982, PHOTOGRAMM ENG REM S, V48, P629
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030484
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Lebedev M., 2018, INT ARCH PHOTOGRAM R, V42, P565, DOI 10.5194/isprs-archives-XLII-2-565-2018
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060506
   NELSON RF, 1983, PHOTOGRAMM ENG REM S, V49, P1303
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, V0, PP214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Peng DF, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.024512
   Pfaff B., 1998, MULTISPECTRAL CHANGE, V0, P0
   Ramachandran P, 2019, ADV NEUR IN, V32, P0
   Saha S, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3043822
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Stow D, 2008, REMOTE SENS ENVIRON, V112, P1051, DOI 10.1016/j.rse.2007.07.011
   Sui Haigang, 2018, GEOMATICS AND INFORMATION SCIENCE OF WUHAN UNIVERSITY, V43, P1885, DOI 10.13203/j.whugis20180251
   Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015
   SWAIN PH, 1978, IEEE T SYST MAN CYB, V8, P879
   TODD WJ, 1977, J RES US GEOL SURV, V5, P529
   Wei JJ, 2020, CAN J REMOTE SENS, V46, P272, DOI 10.1080/07038992.2020.1783993
   WEISMILLER RA, 1977, PHOTOGRAMM ENG REM S, V43, P1533
   Wiemker R., 1997, LECT NOTES COMPUTER, V0, PP263, DOI 10.1007/3-540-63460-6_126
   Wiratama W, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8101785
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8040189
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhao WZ, 2020, IEEE T GEOSCI REMOTE, V58, P2720, DOI 10.1109/TGRS.2019.2953879
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 59
TC 8
Z9 8
U1 5
U2 59
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD DEC 15
PY 2021
VL 182
IS 
BP 52
EP 66
DI 10.1016/j.isprsjprs.2021.10.001
EA OCT 2021
PG 15
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA WK6CD
UT WOS:000709811500004
DA 2023-04-26
ER

PT J
AU Tengtrairat, N
   Woo, WL
   Parathai, P
   Aryupong, C
   Jitsangiam, P
   Rinchumphu, D
AF Tengtrairat, Naruephorn
   Woo, Wai Lok
   Parathai, Phetcharat
   Aryupong, Chuchoke
   Jitsangiam, Peerapong
   Rinchumphu, Damrongsak
TI Automated Landslide-Risk Prediction Using Web GIS and Machine Learning Models
SO SENSORS
LA English
DT Article
DE landslide risk prediction; geographic information system; google map; machine learning; linear regression; artificial intelligence; long short-term memory
ID induced shallow landslides; logistic-regression; displacement prediction; optimization; phetchabun; province; network; index; area
AB Spatial susceptible landslide prediction is the one of the most challenging research areas which essentially concerns the safety of inhabitants. The novel geographic information web (GIW) application is proposed for dynamically predicting landslide risk in Chiang Rai, Thailand. The automated GIW system is coordinated between machine learning technologies, web technologies, and application programming interfaces (APIs). The new bidirectional long short-term memory (Bi-LSTM) algorithm is presented to forecast landslides. The proposed algorithm consists of 3 major steps, the first of which is the construction of a landslide dataset by using Quantum GIS (QGIS). The second step is to generate the landslide-risk model based on machine learning approaches. Finally, the automated landslide-risk visualization illustrates the likelihood of landslide via Google Maps on the website. Four static factors are considered for landslide-risk prediction, namely, land cover, soil properties, elevation and slope, and a single dynamic factor i.e., precipitation. Data are collected to construct a geospatial landslide database which comprises three historical landslide locations-Phu Chifa at Thoeng District, Ban Pha Duea at Mae Salong Nai, and Mai Salong Nok in Mae Fa Luang District, Chiang Rai, Thailand. Data collection is achieved using QGIS software to interpolate contour, elevation, slope degree and land cover from the Google satellite images, aerial and site survey photographs while the physiographic and rock type are on-site surveyed by experts. The state-of-the-art machine learning models have been trained i.e., linear regression (LR), artificial neural network (ANN), LSTM, and Bi-LSTM. Ablation studies have been conducted to determine the optimal parameters setting for each model. An enhancement method based on two-stage classifications has been presented to improve the landslide prediction of LSTM and Bi-LSTM models. The landslide-risk prediction performances of these models are subsequently evaluated using real-time dataset and it is shown that Bi-LSTM with Random Forest (Bi-LSTM-RF) yields the best prediction performance. Bi-LSTM-RF model has improved the landslide-risk predicting performance over LR, ANNs, LSTM, and Bi-LSTM in terms of the area under the receiver characteristic operator (AUC) scores by 0.42, 0.27, 0.46, and 0.47, respectively. Finally, an automated web GIS has been developed and it consists of software components including the trained models, rainfall API, Google API, and geodatabase. All components have been interfaced together via JavaScript and Node.js tool.
C1 [Tengtrairat, Naruephorn; Parathai, Phetcharat] Payap Univ, Sch Software Engn, Chiang Mai 50000, Thailand.
   [Woo, Wai Lok] Northumbria Univ, Dept Comp & Informat Sci, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Aryupong, Chuchoke; Jitsangiam, Peerapong; Rinchumphu, Damrongsak] Chiang Mai Univ, Ctr Excellence Nat Disaster Management CENDIM, Chiang Mai 50200, Thailand.
   [Aryupong, Chuchoke; Jitsangiam, Peerapong; Rinchumphu, Damrongsak] Chiang Mai Univ, Dept Civil Engn, Fac Engn, Chiang Mai 50200, Thailand.
C3 Northumbria University; Chiang Mai University; Chiang Mai University
RP Woo, WL (corresponding author), Northumbria Univ, Dept Comp & Informat Sci, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
EM naruephorn_t@payap.ac.th; wailok.woo@northumbria.ac.uk; phetcharat@payap.ac.th; chuchoke.a@cmu.ac.th; peerapong@eng.cmu.ac.th; damrongsak.r@cmu.ac.th
FU Thailand Science Research and Innovation, Thailand
CR Abraham MT, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12030804
   An K, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10020293
   Batar AK, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10030114
   Battineni G, 2019, MACHINES, V7, P0, DOI 10.3390/machines7040074
   Chang ZL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030502
   Chen W, 2018, B ENG GEOL ENVIRON, V77, P647, DOI 10.1007/s10064-017-1010-y
   Chen YY, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19092047
   Chow TE, 2008, T GIS, V12, P179, DOI 10.1111/j.1467-9671.2008.01094.x
   Cui WQ, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040194
   Dai FC, 2001, ENG GEOL, V59, P253, DOI 10.1016/S0013-7952(00)00077-6
   Bui DT, 2016, INT J DIGIT EARTH, V9, P1077, DOI 10.1080/17538947.2016.1169561
   DiGangi Elizabeth A., 2013, REMETHODHUMAN SK, V0, P0, DOI DOI 10.1016/B978-0-12-385189-5.11001-5
   Fowze JSM, 2012, GEOTEXT GEOMEMBRANES, V30, P50, DOI 10.1016/j.geotexmem.2011.01.007
   Golovko D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090943
   Hamad RA, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10155293
   Hong-Hong Wang, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL APPLICATION OF ARTIFICIAL INTELLIGENCE (IAAI), V0, PP149, DOI 10.1109/IAAI51705.2020.9332814
   Hu BZ, 2021, IEEE T IMAGE PROCESS, V30, P472, DOI 10.1109/TIP.2020.3036770
   Huang FM, 2021, CATENA, V202, P0, DOI 10.1016/j.catena.2021.105250
   Huang FM, 2020, LANDSLIDES, V17, P2919, DOI 10.1007/s10346-020-01473-9
   Hungr O, 2014, LANDSLIDES, V11, P167, DOI 10.1007/s10346-013-0436-y
   Inoue N., 2014, P 19 IAHR APD C 2014, V0, P0
   Iqbal MZ, 2021, INT J ENERG RES, V45, P1449, DOI 10.1002/er.5954
   Jiang HW, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10217830
   Jiang SH, 2020, ENG GEOL, V271, P0, DOI 10.1016/j.enggeo.2020.105597
   Jing L, 2019, NEURAL COMPUT, V31, P765, DOI 10.1162/neco_a_01174
   Kadavi PR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081252
   Kaderuppan SS, 2020, IEEE ACCESS, V8, P214801, DOI 10.1109/ACCESS.2020.3040319
   Koh BHD, 2019, IEEE ACCESS, V7, P32482, DOI 10.1109/ACCESS.2019.2903571
   Koh BHD, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21020603
   Komori D, 2018, CLIM RISK MANAG, V20, P126, DOI 10.1016/j.crm.2018.03.002
   Liu J, 2018, ENTROPY-SWITZ, V20, P0, DOI 10.3390/e20110868
   Moresi FV, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10080309
   Nobaew B., 2010, J INF SCI TECHNOL, V1, P11
   Ono K, 2014, NAT HAZARDS, V74, P2089, DOI 10.1007/s11069-014-1292-3
   Parathai P, 2019, CIRC SYST SIGNAL PR, V38, P5786, DOI 10.1007/s00034-019-01156-4
   Parathai P., 2017, P 2 INT C INF TECHN, V0, P0
   Parathai P, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20164368
   Pourghasemi HR, 2013, NAT HAZARDS, V69, P749, DOI 10.1007/s11069-013-0728-5
   Qi Q, 2020, 2020 IEEE 13TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2020), V0, PP413, DOI 10.1109/ICWS49710.2020.00060
   Rodriguez-Rodriguez I, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11041742
   Roy AC, 2019, INT CONF ADV ELECTR, V0, PP874, DOI 10.1109/ICAEE48663.2019.8975696
   Ruan LF, 2020, NEUROCOMPUTING, V417, P441, DOI 10.1016/j.neucom.2020.07.093
   Schein AI, 2007, MACH LEARN, V68, P235, DOI 10.1007/s10994-007-5019-5
   Sepulveda NE, 2020, MACHINES, V8, P0, DOI 10.3390/machines8040066
   Siami-Namini S, 2019, IEEE INT CONF BIG DA, V0, PP3285, DOI 10.1109/BigData47090.2019.9005997
   Tengtrairat N., 2017, P 2 INT C INF TECHN, V0, P0
   Nhu VH, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17082749
   Wang HJ, 2021, ENG GEOL, V288, P0, DOI 10.1016/j.enggeo.2021.106103
   Woo WL, 2020, IEEE INSTRU MEAS MAG, V23, P71, DOI 10.1109/MIM.2020.9062691
   Xie PH, 2019, IEEE ACCESS, V7, P54305, DOI 10.1109/ACCESS.2019.2912419
   Yang JT, 2019, GEOMORPHOLOGY, V324, P62, DOI 10.1016/j.geomorph.2018.09.019
   Yousefi S, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-69233-2
   Youssef AM, 2015, GEOSCI J, V19, P113, DOI 10.1007/s12303-014-0032-8
   Yumuang S, 2006, ENVIRON GEOL, V51, P545, DOI 10.1007/s00254-006-0351-9
   Zhang YG, 2021, NAT HAZARDS, V105, P783, DOI 10.1007/s11069-020-04337-6
   Zhu L, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20061576
NR 56
TC 11
Z9 11
U1 10
U2 35
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD JUL 15
PY 2021
VL 21
IS 13
BP 
EP 
DI 10.3390/s21134620
PG 32
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA TF9LX
UT WOS:000671037200001
PM 34283153
DA 2023-04-26
ER

PT J
AU Zi, Y
   Xie, FY
   Zhang, N
   Jiang, ZG
   Zhu, WT
   Zhang, HP
AF Zi, Yue
   Xie, Fengying
   Zhang, Ning
   Jiang, Zhiguo
   Zhu, Wentao
   Zhang, Haopeng
TI Thin Cloud Removal for Multispectral Remote Sensing Images Using Convolutional Neural Networks Combined With an Imaging Model
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Clouds; Remote sensing; Cloud computing; Earth; Artificial satellites; Imaging; Satellites; Convolutional neural network (CNN); multispectral remote sensing images; thin cloud removal; thin cloud thickness map
ID haze detection
AB Multispectral remote sensing images are often degraded by clouds, resulting in the reduced efficiency and accuracy of image interpretation. Thin cloud removal is one of the most important and significant tasks for optical multispectral images. In this article, we propose a novel thin cloud removal method for multispectral images, which is a combination of traditional methods and deep learning methods. First, we adopt U-Net to estimate the reference thin cloud thickness map of the cloudy image. Then, a convolutional neural network named Slope-Net is designed to estimate the thickness coefficient of each band relative to the reference thin cloud thickness map to obtain the thin cloud thickness maps of different bands. Finally, the recovered clear image can be obtained by subtracting the thin cloud thickness maps from the cloudy image according to the traditional thin cloud imaging model. To train U-Net and Slope-Net, a wavelength-dependent thin cloud simulation method is presented to generate a labeled dataset composed of synthetic cloudy images, corresponding clear images, reference thin cloud thickness maps, and thickness coefficients. Qualitative and quantitative comparison experiments are conducted on both synthetic cloudy images and real cloudy images from the Landsat 8 Operational Land Imager. The results indicate that the proposed method can effectively remove thin clouds in multispectral images with various land cover types and maintain good color fidelity.
C1 [Zi, Yue; Xie, Fengying; Jiang, Zhiguo; Zhang, Haopeng] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Astronaut, Beijing 100191, Peoples R China.
   [Zhang, Ning; Zhu, Wentao] Shanghai Aerosp Elect Technol Inst, Shanghai 201109, Peoples R China.
   [Zi, Yue; Xie, Fengying; Jiang, Zhiguo; Zhang, Haopeng] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Xie, FY (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Astronaut, Beijing 100191, Peoples R China.; Xie, FY (corresponding author), Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
EM ziyue91@buaa.eud.cn; xfy_73@buaa.edu.cn; dzs.zhangning@gmail.com; jiangzg@buaa.edu.cn; 337938145@qq.com; zhanghaopeng@buaa.edu.cn
FU National Key Research and Development Program of China [2019YFC1510905]; Beijing Natural Science Foundation [4192032]; NationalNatural Science Foundation of China [61871011, 61771031]
CR Berk A., 1985, AFGLTR83018, V0, P0
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   CHAVEZ PS, 1988, REMOTE SENS ENVIRON, V24, P459, DOI 10.1016/0034-4257(88)90019-3
   Chavez PS, 1996, PHOTOGRAMM ENG REM S, V62, P1025
   Du Y, 2002, IEEE T GEOSCI REMOTE, V40, P210, DOI 10.1109/36.981363
   Enomoto K, 2017, IEEE COMPUT SOC CONF, V0, PP1533, DOI 10.1109/CVPRW.2017.197
   Gonalves LT, 2017, SIBGRAPI, V0, PP436, DOI 10.1109/SIBGRAPI.2017.64
   Hadjimitsis DG, 2004, INT J REMOTE SENS, V25, P3651, DOI 10.1080/01431160310001647993
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   ISAACS RG, 1987, APPL OPTICS, V26, P1272, DOI 10.1364/AO.26.001272
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Li JY, 2019, IEEE GEOSCI REMOTE S, V16, P472, DOI 10.1109/LGRS.2018.2874084
   Li WB, 2019, ISPRS J PHOTOGRAMM, V153, P137, DOI 10.1016/j.isprsjprs.2019.05.003
   Liu J, 2014, OPT EXPRESS, V22, P618, DOI 10.1364/OE.22.000618
   Liu Q, 2017, SIGNAL PROCESS, V137, P33, DOI 10.1016/j.sigpro.2017.01.036
   Makarau A, 2016, IEEE GEOSCI REMOTE S, V13, P379, DOI 10.1109/LGRS.2016.2515110
   Makarau A, 2014, IEEE T GEOSCI REMOTE, V52, P5895, DOI 10.1109/TGRS.2013.2293662
   Markchom T, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2018), V0, PP100, DOI 10.1109/ICFSP.2018.8552064
   MITCHELL OR, 1977, IEEE T GEOSCI REMOTE, V15, P137, DOI 10.1109/TGE.1977.6498971
   Pacifici F, 2014, IEEE T GEOSCI REMOTE, V52, P6241, DOI 10.1109/TGRS.2013.2295819
   Qin MJ, 2017, LECT NOTES COMPUT SC, V10666, P664, DOI 10.1007/978-3-319-71607-7_58
   Qin MJ, 2018, IEEE J-STARS, V11, P1645, DOI 10.1109/JSTARS.2018.2812726
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Richter R, 1996, INT J REMOTE SENS, V17, P1201, DOI 10.1080/01431169608949077
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen HF, 2014, ISPRS J PHOTOGRAMM, V96, P224, DOI 10.1016/j.isprsjprs.2014.06.011
   Vermote EF, 1997, IEEE T GEOSCI REMOTE, V35, P675, DOI 10.1109/36.581987
   Xie FY, 2018, IEEE ACCESS, V6, P67982, DOI 10.1109/ACCESS.2018.2879893
   Xu M, 2019, ISPRS J PHOTOGRAMM, V149, P215, DOI 10.1016/j.isprsjprs.2019.01.025
   Xu M, 2014, INT GEOSCI REMOTE SE, V0, PP2511, DOI 10.1109/IGARSS.2014.6946983
   Zhang R., 2018, P SPIE, V0, P0
   Zhou BX, 2019, INT GEOSCI REMOTE SE, V0, PP1434, DOI 10.1109/IGARSS.2019.8898644
NR 32
TC 15
Z9 15
U1 3
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3811
EP 3823
DI 10.1109/JSTARS.2021.3068166
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RP8HD
UT WOS:000641963300002
DA 2023-04-26
ER

PT J
AU Cui, YK
   Zeng, C
   Chen, X
   Fan, WJ
   Liu, HJ
   Liu, Y
   Xiong, WT
   Sun, C
   Luo, ZL
AF Cui, Yaokui
   Zeng, Chao
   Chen, Xi
   Fan, Wenjie
   Liu, Haijiang
   Liu, Yuan
   Xiong, Wentao
   Sun, Cong
   Luo, Zengliang
TI A New Fusion Algorithm for Simultaneously Improving Spatio-Temporal Continuity and Quality of Remotely Sensed Soil Moisture Over the Tibetan Plateau
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Land surface temperature; Meteorology; Land surface; Soil moisture; Vegetation mapping; Training; Satellites; Essential climate variables (ECV); Fengyun (FY); general regression neural network (GRNN); quality; soil moisture (SM); spatio-temporal continuity
ID satellite; smap; retrievals; validation; products; network; smos
AB Spatio-temporally continuous and high-quality soil moisture (SM) is very important for assessing changes in the water cycle and climate, especially over the Tibetan plateau (TP). Data fusion is an important method to improve the quality of SM product. However, limited observation overlaps between different satellite SM products, caused by inherent gaps, make it difficult to fuse them to create a continuous and high-quality product. In this study, an SM spatio-temporal continuity and quality simultaneously improving algorithm is proposed. The first step of the approach is obtaining spatio-temporally continuous reference data, including land surface temperature (LST), normalized difference vegetation index (NDVI), Albedo, and digital elevation model (DEM). The second step is training the general regression neural network (GRNN) model with all available essential climate variables (ECV) and Fengyun (FY) SM. The last step is predicting the spatio-temporally continuous and high-quality SM using the trained GRNN derived by the spatio-temporal continuity reference data. An implementation of the algorithm on the TP showed that, compared with the original ECV and FY SM, both the continuity and quality of the fused SM product were largely improved in terms of coverage (72.5%), correlation (R = 0.809), root mean square error (0.081 cm(3) cm(-3)) and bias (0.050 cm(3) cm(-3)). The algorithm showed a good performance in obtaining spatio-temporal variation fusion weights over the TP. This spatio-temporally continuous and high-quality SM of the TP will help advance our understanding of global and regional changes in water cycle and climate.
C1 [Cui, Yaokui; Fan, Wenjie; Xiong, Wentao; Luo, Zengliang] Peking Univ, Inst RS & GIS, Sch Earth & Space Sci, Beijing 100871, Peoples R China.
   [Cui, Yaokui; Fan, Wenjie] Beijing Key Lab Spatial Informat Integrat & Its A, Beijing 100871, Peoples R China.
   [Zeng, Chao] Wuhan Univ, Sch Resource & Environm Sci, Wuhan 430072, Peoples R China.
   [Chen, Xi] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100094, Peoples R China.
   [Liu, Haijiang; Sun, Cong] China Natl Environmen Monitoring Ctr, Beijing 100012, Peoples R China.
   [Liu, Yuan] China Fire & Rescue Inst, Beijing 102202, Peoples R China.
C3 Peking University; Wuhan University; Chinese Academy of Sciences
RP Cui, YK (corresponding author), Peking Univ, Inst RS & GIS, Sch Earth & Space Sci, Beijing 100871, Peoples R China.; Liu, HJ (corresponding author), China Natl Environmen Monitoring Ctr, Beijing 100012, Peoples R China.
EM yaokuicui@pku.edu.cn; zengchaozc@hotmail.com; chenxi928@pku.edu.cn; fanwj@pku.edu.cn; liuhj@cnemc.cn; 2008.liuyuan.2008@163.com; wtxiong@pku.edu.cn; suncong@cnemc.cn; zengliangluo@pku.edu.cn
FU National Natural Science Foundation of China [41901348]; Key R&D Program of the Ministry of Science and Technology, China [2018YFC1506500]; Strategic Priority Research Program of the Chinese Academy of Sciences [XDA19030203]; National Key Research and Development Program of China [2016YFC0500205]
CR Arndt DS, 2015, B AM METEOROL SOC, V96, PS1, DOI 10.1175/2015BAMSStateoftheClimate.1
   Brocca L, 2010, HYDROL EARTH SYST SC, V14, P1881, DOI 10.5194/hess-14-1881-2010
   CARLSON TN, 1995, AGR FOREST METEOROL, V77, P191, DOI 10.1016/0168-1923(95)02261-U
   Carrao H, 2016, INT J APPL EARTH OBS, V48, P74, DOI 10.1016/j.jag.2015.06.011
   Chauhan NS, 2003, INT J REMOTE SENS, V24, P4599, DOI 10.1080/0143116031000156837
   Chen YY, 2017, J GEOPHYS RES-ATMOS, V122, P5780, DOI 10.1002/2016JD026388
   Cui YK, 2020, J HYDROL, V587, P0, DOI 10.1016/j.jhydrol.2020.124993
   Cui YK, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030455
   Cui YK, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0228-x
   Cui YK, 2016, J HYDROL, V543, P242, DOI 10.1016/j.jhydrol.2016.10.005
   Dorigo W, 2017, REMOTE SENS ENVIRON, V203, P185, DOI 10.1016/j.rse.2017.07.001
   Entekhabi D, 2010, J HYDROMETEOROL, V11, P832, DOI 10.1175/2010JHM1223.1
   Entekhabi D, 2010, P IEEE, V98, P704, DOI 10.1109/JPROC.2010.2043918
   Gruber A, 2017, IEEE T GEOSCI REMOTE, V55, P6780, DOI 10.1109/TGRS.2017.2734070
   Jia L, 2011, HYDROL EARTH SYST SC, V15, P1047, DOI 10.5194/hess-15-1047-2011
   Jiang HT, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111224
   Liu NF, 2013, HYDROL EARTH SYST SC, V17, P2121, DOI 10.5194/hess-17-2121-2013
   Liu YY, 2011, HYDROL EARTH SYST SC, V15, P425, DOI 10.5194/hess-15-425-2011
   Ma YM, 2008, B AM METEOROL SOC, V89, P1487, DOI 10.1175/2008BAMS2545.1
   Montzka C, 2014, INT GEOSCI REMOTE SE, V0, PP2427, DOI 10.1109/IGARSS.2014.6946962
   Nicolai-Shaw N, 2016, GEOPHYS RES LETT, V43, P8554, DOI 10.1002/2016GL069847
   Rodell M, 2015, J CLIMATE, V28, P8289, DOI 10.1175/JCLI-D-14-00555.1
   Sandholt I, 2002, REMOTE SENS ENVIRON, V79, P213, DOI 10.1016/S0034-4257(01)00274-7
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Srivastava PK, 2013, WATER RESOUR MANAG, V27, P5069, DOI 10.1007/s11269-013-0452-7
   Su Z, 2013, J GEOPHYS RES-ATMOS, V118, P5304, DOI 10.1002/jgrd.50468
   Tang RL, 2010, REMOTE SENS ENVIRON, V114, P540, DOI 10.1016/j.rse.2009.10.012
   van der Schalie R, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010107
   Wagner W., 2012, ISPRS ANN PHOTOGRA I, VI-7, P315, DOI 10.5194/ISPRSANNALS-I-7-315-2012
   Wagner W, 2013, METEOROL Z, V22, P5, DOI 10.1127/0941-2948/2013/0399
   Wen FP, 2020, IEEE T GEOSCI REMOTE, V58, P913, DOI 10.1109/TGRS.2019.2941696
   Yang K, 2013, B AM METEOROL SOC, V94, P1907, DOI 10.1175/BAMS-D-12-00203.1
   Zeng C, 2015, IEEE GEOSCI REMOTE S, V12, P512, DOI 10.1109/LGRS.2014.2348651
   Zeng JY, 2015, REMOTE SENS ENVIRON, V163, P91, DOI 10.1016/j.rse.2015.03.008
   Zhao W, 2018, J HYDROL, V563, P1009, DOI 10.1016/j.jhydrol.2018.06.081
NR 35
TC 3
Z9 3
U1 7
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 83
EP 91
DI 10.1109/JSTARS.2020.3043336
PG 9
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900004
DA 2023-04-26
ER

PT J
AU Zhong, XW
   Qian, YR
   Liu, H
   Chen, L
   Wan, YL
   Gao, L
   Qian, J
   Liu, J
AF Zhong, Xiwu
   Qian, Yurong
   Liu, Hui
   Chen, Long
   Wan, Yaling
   Gao, Liang
   Qian, Jing
   Liu, Jun
TI Attention_FPNet: Two-Branch Remote Sensing Image Pansharpening Network Based on Attention Feature Fusion
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Pansharpening; Remote sensing; Spatial resolution; Feature extraction; Image resolution; Image reconstruction; Software; Attention feature fusion (AFF); convolutional neural network (CNN); image fusion; pansharpening; remote sensing
ID pan-sharpening method; wavelet transform; satellite images; quality; pca; algorithm; framework
AB Inspired by the impressive achievements of convolutional neural networks in various computer vision tasks and the effective role of attention mechanisms, this article proposes a two-branch fusion network based on attention feature fusion (AFF) called Attention_FPNet to solve the pansharpening problem. We reconstruct the spatial information of the image in the high-pass filter domain and fully consider the spatial information in the multispectral (MS) and panchromatic (PAN) images. At the same time, the input PAN image and the upsampled MS image are directly transmitted to the reconstructed image through a long skip connection. The spectral information of the PAN and MS images is considered to improve the spectral resolution of the fused image. It also supplements the loss of spatial information that may be caused by network deepening. Moreover, an AFF method is used to replace the existing simple channel concatenation method commonly used in pansharpening, which fully considers the relationship between different feature maps and improves the fusion quality. Through experiments on image datasets acquired by the Pleiades, SPOT-6 and Gaofen-2 satellites, the results show that this method can effectively fuse PAN and MS images and generate a fused image and outperforms existing methods.
C1 [Zhong, Xiwu] Xinjiang Univ, Coll Software, Key Lab Software Engn, Key Lab Signal Detect & Proc Xinjiang Uygur Auton, Urumqi, Peoples R China.
   [Zhong, Xiwu; Qian, Jing] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Qian, Yurong; Chen, Long; Wan, Yaling; Gao, Liang] Xinjiang Univ, Coll Software, Key Lab Software Engn, Urumqi 830046, Peoples R China.
   [Qian, Yurong; Liu, Hui; Chen, Long; Wan, Yaling; Gao, Liang] Key Lab Signal Detect & Proc Xinjiang Uygur Auton, Urumqi 830046, Peoples R China.
   [Liu, Hui] Xinjiang Univ, Coll Informat Sci & Engn, Key Lab Software Engn, Urumqi 830046, Peoples R China.
   [Qian, Jing] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Liu, Jun] TripleSAI Technol, Shenzhen 518109, Peoples R China.
C3 Xinjiang University; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Xinjiang University; Xinjiang University; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Qian, YR (corresponding author), Xinjiang Univ, Coll Software, Key Lab Software Engn, Urumqi 830046, Peoples R China.; Qian, YR (corresponding author), Key Lab Signal Detect & Proc Xinjiang Uygur Auton, Urumqi 830046, Peoples R China.
EM xw.zhong@siat.ac.cn; qyr@xju.edu.cn; liuhui@stu.xju.edu.cn; ry19chenlong@stu.xju.edu.cn; wyl@stu.xju.edu.cn; gaoliang@stu.xju.edu.cn; jing.qian@siat.ac.cn; rsliujun@163.com
FU National Natural Science Foundation of China [61966035]; International Cooperation Project of the Science and Technology Department of the Autonomous Region "Data-Driven Construction of Sino-Russian Cloud Computing Sharing Platform" [2020E01023]; National Science Foundation of China [U1803261]; Autonomous Region Graduate Innovation Project [XJ2021G062, XJ2021G080]; Shenzhen International S&T Cooperation Project [GJHZ20190821155805960]; Key S&T Special Project of the Autonomous Region [2020A03004-4]
CR Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   Aly HA, 2014, IEEE T IMAGE PROCESS, V23, P2596, DOI 10.1109/TIP.2014.2316641
   Boardman J. W, 1992, P SUMM ANN JPL AIRB, V1, P147
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Chen FR, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10186262
   Chen Z, 2014, IEEE GEOSCI REMOTE S, V11, P1418, DOI 10.1109/LGRS.2013.2294476
   Cheng J, 2015, ISPRS J PHOTOGRAMM, V104, P158, DOI 10.1016/j.isprsjprs.2015.02.015
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Choi M, 2005, IEEE GEOSCI REMOTE S, V2, P136, DOI 10.1109/LGRS.2005.845313
   Dai YM, 2021, IEEE WINT CONF APPL, V0, PP3559, DOI 10.1109/WACV48630.2021.00360
   Deng LJ, 2021, IEEE T GEOSCI REMOTE, V59, P6995, DOI 10.1109/TGRS.2020.3031366
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fu SP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101674
   Gatys LA, 2016, PROC CVPR IEEE, V0, PP2414, DOI 10.1109/CVPR.2016.265
   Ghahremani M, 2015, INT J REMOTE SENS, V36, P4131, DOI 10.1080/01431161.2015.1071897
   GILLESPIE AR, 1987, REMOTE SENS ENVIRON, V22, P343, DOI 10.1016/0034-4257(87)90088-5
   Gonzalez-Audicana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He L, 2019, IEEE J-STARS, V12, P1188, DOI 10.1109/JSTARS.2019.2898574
   He XY, 2014, IEEE T IMAGE PROCESS, V23, P4160, DOI 10.1109/TIP.2014.2333661
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   King RL, 2001, INT GEOSCI REMOTE SE, V0, PP849, DOI 10.1109/IGARSS.2001.976657
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Laben C. A., 2000, US PATENT, V0, Patent No. 6011875
   Li ST, 2011, IEEE T GEOSCI REMOTE, V49, P738, DOI 10.1109/TGRS.2010.2067219
   Li WS, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030535
   Liu JM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172804
   Liu XY, 2020, INFORM FUSION, V55, P1, DOI 10.1016/j.inffus.2019.07.010
   Luo Y., 2008, INT ARCH PHOTOGRAMM, V37, P1155
   Masi G, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070594
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selva M, 2018, IEEE GEOSCI REMOTE S, V15, P320, DOI 10.1109/LGRS.2017.2777916
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Shandoosti HR, 2016, INFORM FUSION, V27, P150, DOI 10.1016/j.inffus.2015.06.006
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Tai Y, 2017, IEEE I CONF COMP VIS, V0, PP4549, DOI 10.1109/ICCV.2017.486
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Valizadeh SA, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), V0, PP1184, DOI 10.1109/ISTEL.2012.6483168
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wald L., 2000, PROC 3 C FUSION EART, V0, P99
   Wei Q, 2015, IEEE J-STSP, V9, P1117, DOI 10.1109/JSTSP.2015.2407855
   Yang Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040676
   Yokoya N, 2012, IEEE T GEOSCI REMOTE, V50, P528, DOI 10.1109/TGRS.2011.2161320
   Yuan QQ, 2018, IEEE J-STARS, V11, P978, DOI 10.1109/JSTARS.2018.2794888
   [张立福 Zhang Lifu], 2019, 遥感学报 JOURNAL OF REMOTE SENSING, V23, P603
   Zhang Y, 2004, PHOTOGRAMM ENG REM S, V70, P657
   Zhou CS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142318
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 57
TC 8
Z9 8
U1 4
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11879
EP 11891
DI 10.1109/JSTARS.2021.3126645
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XI0GL
UT WOS:000725801600006
DA 2023-04-26
ER

PT J
AU Wen, JB
   Yang, JC
   Jiang, B
   Song, HB
   Wang, HH
AF Wen, Jiabao
   Yang, Jiachen
   Jiang, Bin
   Song, Houbing
   Wang, Huihui
TI Big Data Driven Marine Environment Information Forecasting: A Time Series Prediction Network
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Time series analysis; Big Data; Predictive models; Data models; Forecasting; Sparks; Training; Big data; forecasting model; fuzzy time series; long short-term memory (LSTM); semisupervised learning
ID recurrent neural-network; fuzzy cognitive maps; rule induction; real-time; model; mapreduce; algorithm; optimization; spark; index
AB The continuous development of industry big data technology requires better computing methods to discover the data value. Information forecast, as an important part of data mining technology, has achieved excellent applications in some industries. However, the existing deviation and redundancy in the data collected by the sensors make it difficult for some methods to accurately predict future information. This article proposes a semisupervised prediction model, which exploits the improved unsupervised clustering algorithm to establish the fuzzy partition function, and then utilize the neural network model to build the information prediction function. The main purpose of this article is to effectively solve the time analysis of massive industry data. In the experimental part, we built a data platform on Spark, and used some marine environmental factor datasets and UCI public datasets as analysis objects. Meanwhile, we analyzed the results of the proposed method compared with other traditional methods, and the running performance on the Spark platform. The results show that the proposed method achieved satisfactory prediction effect.
C1 [Wen, Jiabao; Yang, Jiachen; Jiang, Bin] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Song, Houbing] Embry Riddle Aeronaut Univ, Dept Elect Comp Software & Syst Engn, Daytona Beach, FL 32114 USA.
   [Wang, Huihui] Jacksonville Univ, Dept Engn, Jacksonville, FL 32211 USA.
C3 Tianjin University; Embry-Riddle Aeronautical University; Jacksonville University
RP Yang, JC (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM Wen_Jiabao@tju.edu.cn; yangjiachen@tju.edu.cn; jiangbin@tju.edu.cn; h.song@ieee.org; hwang1@ju.edu
FU National Natural Science Foundation of China [61871283]; Major Civil-Military Integration Project of Tianjin City [18ZXJMTG00170]; Natural Science Foundation of Tianjin City [18JCJQJC46400]
CR Abu Alsheikh M, 2016, IEEE NETWORK, V30, P22, DOI 10.1109/MNET.2016.7474340
   Arguez A, 2013, GEOPHYS RES LETT, V40, P5965, DOI 10.1002/2013GL057999
   Arora S, 2013, IEEE T POWER SYST, V28, P3235, DOI 10.1109/TPWRS.2013.2252929
   Bai XZ, 2014, IEEE IMAGE PROC, V0, PP5127, DOI 10.1109/ICIP.2014.7026038
   Barbounis TG, 2006, IEEE T ENERGY CONVER, V21, P273, DOI 10.1109/TEC.2005.847954
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Birjali M, 2017, PROCEDIA COMPUT SCI, V113, P280, DOI 10.1016/j.procs.2017.08.299
   Bischl B, 2016, J MACH LEARN RES, V17, P0
   Cai QS, 2015, KNOWL-BASED SYST, V74, P61, DOI 10.1016/j.knosys.2014.11.003
   Cao B, 2018, IEEE T IND INFORM, V14, P5487, DOI 10.1109/TII.2018.2803758
   Chen DQ, 2017, IEEE T IND INFORM, V13, P595, DOI 10.1109/TII.2016.2645606
   Chen JG, 2019, INFORM SCIENCES, V496, P506, DOI 10.1016/j.ins.2018.06.045
   Chen MY, 2015, INFORM SCIENCES, V294, P227, DOI 10.1016/j.ins.2014.09.038
   Cheng CH, 2018, NEUROCOMPUTING, V302, P33, DOI 10.1016/j.neucom.2018.04.014
   de Souza RWR, 2020, IEEE T FUZZY SYST, V28, P3076, DOI 10.1109/TFUZZ.2019.2949771
   Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492
   Efendi R, 2018, INFORM SCIENCES, V441, P113, DOI 10.1016/j.ins.2018.02.016
   Elkano M, 2020, IEEE T FUZZY SYST, V28, P163, DOI 10.1109/TFUZZ.2019.2900856
   Gonzalez-Vidal A, 2019, ENERG BUILDINGS, V196, P71, DOI 10.1016/j.enbuild.2019.05.021
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Han QY, 2017, IEEE T SIGNAL PROCES, V65, P4994, DOI 10.1109/TSP.2017.2716898
   Haupt SE, 2017, IEEE T SUSTAIN ENERG, V8, P725, DOI 10.1109/TSTE.2016.2604679
   Jiang B, 2019, IEEE INTERNET THINGS, V6, P1375, DOI 10.1109/JIOT.2018.2842229
   Jiang B, 2019, IEEE INTERNET THINGS, V6, P3525, DOI 10.1109/JIOT.2018.2886964
   Lammel R, 2008, SCI COMPUT PROGRAM, V70, P1, DOI 10.1016/j.scico.2007.07.001
   Lee YS, 2011, KNOWL-BASED SYST, V24, P66, DOI 10.1016/j.knosys.2010.07.006
   Lu CH, 2008, IEEE T IND ELECTRON, V55, P1366, DOI 10.1109/TIE.2007.896492
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Merigaud A, 2019, IEEE J OCEANIC ENG, V44, P401, DOI 10.1109/JOE.2018.2822498
   Giang NL, 2020, IEEE T FUZZY SYST, V28, P858, DOI 10.1109/TFUZZ.2019.2948586
   Ogawa H., 2010, PROCEEDINGS OF THE 2010 IEEE 2ND INTERNATIONAL CONFERENCE ON CLOUD COMPUTING TECHNOLOGY AND SCIENCE (CLOUDCOM 2010), V0, PP754, DOI 10.1109/CloudCom.2010.89
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Pulgar-Rubio F, 2017, KNOWL-BASED SYST, V117, P70, DOI 10.1016/j.knosys.2016.08.021
   Ray R. B., 2016, FAST COMPUTING MICRO, V0, P0
   Sadaei HJ, 2016, NEUROCOMPUTING, V175, P782, DOI 10.1016/j.neucom.2015.10.079
   Sakar CO, 2019, NEURAL COMPUT APPL, V31, P6893, DOI 10.1007/s00521-018-3523-0
   Salgado CM, 2017, IEEE T FUZZY SYST, V25, P1777, DOI 10.1109/TFUZZ.2016.2633375
   Segatori A, 2018, IEEE T FUZZY SYST, V26, P174, DOI 10.1109/TFUZZ.2016.2646746
   Selvachandran G, 2021, IEEE T FUZZY SYST, V29, P716, DOI 10.1109/TFUZZ.2019.2961350
   Song HJ, 2010, IEEE T FUZZY SYST, V18, P233, DOI 10.1109/TFUZZ.2009.2038371
   SONG Q, 1993, FUZZY SET SYST, V54, P269, DOI 10.1016/0165-0114(93)90372-O
   Su Z, 2016, IEEE NETWORK, V30, P52, DOI 10.1109/MNET.2016.7389831
   Sun BQ, 2015, NEUROCOMPUTING, V151, P1528, DOI 10.1016/j.neucom.2014.09.018
   Sun G, 2019, IEEE T VEH TECHNOL, V68, P908, DOI 10.1109/TVT.2018.2884525
   Wang H, 2017, KNOWL-BASED SYST, V118, P15, DOI 10.1016/j.knosys.2016.11.008
   Wen SL, 2019, IEEE T IND INFORM, V15, P5266, DOI 10.1109/TII.2019.2910416
   Xu F, 2017, IEEE T SERVICES COMP, V9, P796
   Yang JC, 2020, IEEE INTERNET THINGS, V7, P4238, DOI 10.1109/JIOT.2019.2946269
   Yang SC, 2018, IEEE T FUZZY SYST, V26, P3391, DOI 10.1109/TFUZZ.2018.2831640
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
   Zhong N, 2015, IEEE INTELL SYST, V30, P2, DOI 10.1109/MIS.2015.83
   Zhou W, 2017, BIOINFORMATICS, V33, P1090, DOI 10.1093/bioinformatics/btw750
NR 52
TC 87
Z9 87
U1 36
U2 172
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD JAN 15
PY 2021
VL 29
IS 1
BP 4
EP 18
DI 10.1109/TFUZZ.2020.3012393
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA PO7TI
UT WOS:000605370700002
DA 2023-04-26
ER

PT J
AU Jendryke, M
   McClure, SC
AF Jendryke, Michael
   McClure, Stephen C.
TI Spatial prediction of sparse events using a discrete global grid system; a case study of hate crimes in the USA
SO INTERNATIONAL JOURNAL OF DIGITAL EARTH
LA English
DT Article
DE Discrete global grid system; geospatial data integration; artificial neural network; spatial prediction; sparse events; hates crimes
AB Spatial prediction of any geographic phenomenon can be an intractable problem. Predicting sparse and uncertain spatial events related to many influencing factors necessitates the integration of multiple data sources. We present an innovative approach that combines data in a Discrete Global Grid System (DGGS) and uses machine learning for analysis. A DGGS provides a structured input for multiple types of spatial data, consistent over multiple scales. This data framework facilitates the training of an Artificial Neural Network (ANN) to map and predict a phenomenon. Spatial lag regression models (SLRM) are used to evaluate and rank the outputs of the ANN. In our case study, we predict hate crimes in the USA. Hate crimes get attention from mass media and the scientific community, but data on such events is sparse. We trained the ANN with data ingested in the DGGS based on a 50% sample of hate crimes as identified by the Southern Poverty Law Center (SPLC). Our spatial prediction is up to 78% accurate and verified at the state level against the independent FBI hate crime statistics with a fit of 80%. The derived risk maps are a guide to action for policy makers and law enforcement.
C1 [Jendryke, Michael] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Peoples R China.
   [Jendryke, Michael; McClure, Stephen C.] Wuhan Univ, Sch Resources & Environm Sci, Wuhan, Peoples R China.
C3 Wuhan University; Wuhan University
RP McClure, SC (corresponding author), Wuhan Univ, Sch Resources & Environm Sci, Wuhan, Peoples R China.
EM smcclure@whu.edu.cn
CR Adamczyk A, 2014, J CONTEMP CRIM JUST, V30, P310, DOI 10.1177/1043986214536659
   Adams B, 2017, INT J DIGIT EARTH, V10, P490, DOI 10.1080/17538947.2016.1229819
   Alderson T., 2020, SPECIAL ISSUE GLOBAL, V0, P0
   AMIRI A, 2015, ISPRS INT J GEO-INF, V4, P0
   Annoni Alessandro., 2020, MANUAL DIGITAL EARTH, V0, P357
   [Anonymous], 1999, THEORY PRACTICE ECON, V0, P0, DOI DOI 10.2307/2553707
   [Anonymous], 1998, MATH THEORY COMMUNIC, V0, P0
   Anselin L., 2014, MODERN SPATIAL ECONO, V0, P0
   Anselin L, 2010, PAP REG SCI, V89, P3, DOI 10.1111/j.1435-5957.2010.00279.x
   Byers BryanD., 2001, J CRIME JUSTICE, V24, P0, DOI 10.1080/0735648X.2001.9721135
   CHEN D, 2019, REMOTE SENS-BASEL, V11, P0
   Choudhuri, 2011, PLANETRISK DISCRETE, V0, P1
   DJAVAHERPOUR H, 2017, IEEE COMPUT GRAPH, V38, P0
   Espiritu A, 2004, SOC SCI J, V41, P197, DOI 10.1016/j.soscij.2004.01.006
   Federal Bureau of Investigation, 2017, UNIFORM CRIME REPORI, V0, P0
   FERKISS V, 1976, TECHNOL CULT, V17, P104, DOI 10.2307/3103256
   Gale L., 2002, E ECON J, V28, P203
   Gibb R.G., 2016, IOP C SERIES EARTH E, V34, P0, DOI 10.1088/1755-1315/34/1/012012
   Gibson C, 2010, CULT TRENDS, V19, P325, DOI 10.1080/09548963.2010.515006
   Goodchild MF, 2012, P NATL ACAD SCI USA, V109, P11088, DOI 10.1073/pnas.1202383109
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gore A, 1999, PHOTOGRAMM ENG REM S, V65, P528
   Grattet R, 2008, SOC FORCES, V87, P501
   GREEN D, 1998, AM J SOCIOL, V104, P0
   Green DP, 1998, J PERS SOC PSYCHOL, V75, P82, DOI 10.1037/0022-3514.75.1.82
   Green DP, 2001, ANNU REV SOCIOL, V27, P479, DOI 10.1146/annurev.soc.27.1.479
   Grekousis G, 2019, COMPUT ENVIRON URBAN, V74, P244, DOI 10.1016/j.compenvurbsys.2018.10.008
   Hawkin, 2014, NEURAL NETWORKS LEAR, V0, P0
   Hinton G., 2014, LECT NOTES NEURAL NE, V0, P0
   Jacobs JB, 1997, CRIME JUSTICE, V22, P1, DOI 10.1086/449259
   Jendryke M, 2019, APPL GEOGR, V111, P0, DOI 10.1016/j.apgeog.2019.102072
   KATZ C, 1992, ENVIRON PLANN D, V10, P495, DOI 10.1068/d100495
   Kitchin R, 2007, PROG HUM GEOG, V31, P331, DOI 10.1177/0309132507077082
   Kitchin R, 2013, T I BRIT GEOGR, V38, P480, DOI 10.1111/j.1475-5661.2012.00540.x
   Kitchin Rob., 2008, CARTOGRAPHICA, V43, P211, DOI 10.3138/carto.43.3.211
   KWAN MP, 2018, ANN AM ASSOC GEOGR, V4452, P0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LEGEWIE J, 2016, AM J SOCIOL, V122, P0
   LIN B, 2017, INT J GEOGR INF SCI, V0, P0
   Mahdavi-Amiri A., 2020, DIGITAL EARTH PLATFO, V0, P0
   Mahdavi-Amiri A, 2015, INT J DIGIT EARTH, V8, P750, DOI 10.1080/17538947.2014.927597
   MEDINA R, 2018, ANN AM ASSOC GEOGR, V108, P0
   Mulholland SE, 2013, PUBLIC CHOICE, V157, P91, DOI 10.1007/s11127-012-0045-7
   Nielsen M., 2015, NEURAL NETWORKS DEEP, V0, P0
   Pain Rachel, 2003, SOCIAL GEOGRAPHY ACT, V5, P649
   Philbin James., 2016, PLANET PHOTOGEOLOCAT, V0, P0, DOI DOI 10.1007/978-3-319-46484-8
   Potere D, 2009, INT J REMOTE SENS, V30, P6531, DOI 10.1080/01431160903121134
   Pryor, 1999, EC LETT, V65, P0, DOI 10.3917/reco.566.1249
   Purss MBJ, 2016, INT GEOSCI REMOTE SE, V0, PP3610, DOI 10.1109/IGARSS.2016.7729935
   Rose G, 1997, PROG HUM GEOG, V21, P305, DOI 10.1191/030913297673302122
   Ruggles, 2018, IPUMS NATL HIST GEOG, V2018, P0, DOI 10.18128/D050.V13.0
   Rummens A, 2017, APPL GEOGR, V86, P255, DOI 10.1016/j.apgeog.2017.06.011
   RYAN M, 2011, INT REV LAW ECON, V31, P0
   Sahr, 2014, CENTRAL PLACE INDEXI, V0, P1
   Sahr, 2017, DISCRETE GLOBAL GRID, V0, P0
   Sahr K., 2003, CARTOGR GEOGR INF SC, V30, P121, DOI 10.1559/152304003100011090
   SAHR K, 2019, CARTOGRAPHICA, V53, P0
   Sahr Kevin., 2011, KARTOGRAFII TELEDETE, V22, P363
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Southern Poverty Law Center, 2018, HATE MAP, V0, P0
   Southern Poverty Law Center, 2017, HATE CRIMES, V0, P0
   SUPP SR, 2015, ECOSPHERE, V0, P0
   The Officer Down Memorial Page (ODMP), 2018, FALLEN OFFICER, V0, P0
   Zhao PX, 2018, INT J ENV RES PUB HE, V15, P0, DOI 10.3390/ijerph15020308
NR 65
TC 2
Z9 2
U1 2
U2 24
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1753-8947
EI 1753-8955
J9 INT J DIGIT EARTH
JI Int. J. Digit. Earth
PD JUN 3
PY 2021
VL 14
IS 6
BP 789
EP 805
DI 10.1080/17538947.2021.1886356
EA FEB 2021
PG 17
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA RY8BQ
UT WOS:000618991600001
DA 2023-04-26
ER

PT J
AU Widyaningrum, E
   Bai, Q
   Fajari, MK
   Lindenbergh, RC
AF Widyaningrum, Elyta
   Bai, Qian
   Fajari, Marda K.
   Lindenbergh, Roderik C.
TI Airborne Laser Scanning Point Cloud Classification Using the DGCNN Deep Learning Method
SO REMOTE SENSING
LA English
DT Article
DE airborne point cloud; LiDAR; deep learning; classification; accuracy assessment
ID lidar
AB Classification of aerial point clouds with high accuracy is significant for many geographical applications, but not trivial as the data are massive and unstructured. In recent years, deep learning for 3D point cloud classification has been actively developed and applied, but notably for indoor scenes. In this study, we implement the point-wise deep learning method Dynamic Graph Convolutional Neural Network (DGCNN) and extend its classification application from indoor scenes to airborne point clouds. This study proposes an approach to provide cheap training samples for point-wise deep learning using an existing 2D base map. Furthermore, essential features and spatial contexts to effectively classify airborne point clouds colored by an orthophoto are also investigated, in particularly to deal with class imbalance and relief displacement in urban areas. Two airborne point cloud datasets of different areas are used: Area-1 (city of Surabaya-Indonesia) and Area-2 (cities of Utrecht and Delft-the Netherlands). Area-1 is used to investigate different input feature combinations and loss functions. The point-wise classification for four classes achieves a remarkable result with 91.8% overall accuracy when using the full combination of spectral color and LiDAR features. For Area-2, different block size settings (30, 50, and 70 m) are investigated. It is found that using an appropriate block size of, in this case, 50 m helps to improve the classification until 93% overall accuracy but does not necessarily ensure better classification results for each class. Based on the experiments on both areas, we conclude that using DGCNN with proper settings is able to provide results close to production.
C1 [Widyaningrum, Elyta; Bai, Qian; Lindenbergh, Roderik C.] Delft Univ Technol, Dept Geosci & Remote Sensing, NL-2628 CN Delft, Netherlands.
   [Widyaningrum, Elyta; Fajari, Marda K.] Geospatial Informat Agcy, Ctr Topog Base Mapping & Toponyms, Cibinong 16911, Indonesia.
C3 Delft University of Technology
RP Widyaningrum, E (corresponding author), Delft Univ Technol, Dept Geosci & Remote Sensing, NL-2628 CN Delft, Netherlands.; Widyaningrum, E (corresponding author), Geospatial Informat Agcy, Ctr Topog Base Mapping & Toponyms, Cibinong 16911, Indonesia.
EM e.widyaningrum@tudelft.nl; q.bai@student.tudelft.nl; marda.khoiria@big.go.id; r.c.lindenbergh@tudelft.nl
FU Indonesia Endowment Fund for Education (LPDP) - Delft University of Technology
CR Alakus TB, 2020, CHAOS SOLITON FRACT, V140, P0, DOI 10.1016/j.chaos.2020.110120
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, V0, P225, DOI 10.1109/RAM.2013.6758588
   Balado J, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19163466
   Bello SA, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111729
   Blaha M, 2016, IEEE C COMP VIS PATT, V0, P0
   Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077
   Carrio A, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/3296874
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Engelmann F, 2017, IEEE INT CONF COMP V, V0, PP716, DOI 10.1109/ICCVW.2017.90
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Gopalakrishnan R, 2020, INT J APPL EARTH OBS, V86, P0, DOI 10.1016/j.jag.2019.102012
   Griffiths D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121499
   Hensman P, 2015, THESIS, V0, P0
   Horwath JP, 2020, NPJ COMPUT MATER, V6, P0, DOI 10.1038/s41524-020-00363-x
   Huang R, 2020, ISPRS J PHOTOGRAMM, V163, P62, DOI 10.1016/j.isprsjprs.2020.02.020
   Johnson JM, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0192-5
   Kang ZZ, 2018, ISPRS J PHOTOGRAMM, V143, P108, DOI 10.1016/j.isprsjprs.2018.04.018
   Landrieu L, 2018, PROC CVPR IEEE, V0, PP4558, DOI 10.1109/CVPR.2018.00479
   Li Y., 2018, PROC ADV NEURAL INF, V31, P820
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Maratea A, 2014, INFORM SCIENCES, V257, P331, DOI 10.1016/j.ins.2013.04.016
   Poliyapram V, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242961
   Qi CR, 2017, PROC CVPR IEEE, V0, PP77, DOI 10.1109/CVPR.2017.16
   Singla S, 2019, PR MACH LEARN RES, V97, P0
   Soilan Rodriguez M., 2019, ISPRS ANN PHOTOGRAMM, V0, P445
   Sorgel U, 2019, ISPRS ANN PHOTOGRAMM, V0, PP77, DOI 10.5194/ISPRS-ANNALS-IV-2-W5-77-2019
   Tharwat A., 2021, APPL COMPUTING INFOR, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Toth C.K., 2019, TOPOGRAPHIC LASER RA, V0, P463
   Toth C.K, 2009, TOPOGRAPHIC LASER RA, V0, P389
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Wicaksono SB, 2019, 2019 4TH INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS 2019), V0, PP63, DOI 10.1109/IWBIS.2019.8935882
   Winiwarter L, 2019, PFG-J PHOTOGRAMM REM, V87, P75, DOI 10.1007/s41064-019-00073-0
   Xie YX, 2020, IEEE GEOSC REM SEN M, V8, P38, DOI 10.1109/MGRS.2019.2937630
   Xiu HY, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), V0, PP588, DOI 10.1145/3274895.3274950
   Yang ZS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050877
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhou XC, 2019, NEUROCOMPUTING, V331, P138, DOI 10.1016/j.neucom.2018.11.047
NR 42
TC 8
Z9 9
U1 15
U2 43
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR 15
PY 2021
VL 13
IS 5
BP 
EP 
DI 10.3390/rs13050859
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QW2TU
UT WOS:000628508300001
DA 2023-04-26
ER

PT J
AU Li, ZM
   Xin, QCA
   Sun, Y
   Cao, MY
AF Li, Ziming
   Xin, Qinchuan
   Sun, Ying
   Cao, Mengying
TI A Deep Learning-Based Framework for Automated Extraction of Building Footprint Polygons from Very High-Resolution Aerial Imagery
SO REMOTE SENSING
LA English
DT Article
DE building footprint; map vectorization; convolutional neural network; semantic segmentation
ID performance evaluation; segmentation; classification; generation; multiscale
AB Accurate building footprint polygons provide essential data for a wide range of urban applications. While deep learning models have been proposed to extract pixel-based building areas from remote sensing imagery, the direct vectorization of pixel-based building maps often leads to building footprint polygons with irregular shapes that are inconsistent with real building boundaries, making it difficult to use them in geospatial analysis. In this study, we proposed a novel deep learning-based framework for automated extraction of building footprint polygons (DLEBFP) from very high-resolution aerial imagery by combining deep learning models for different tasks. Our approach uses the U-Net, Cascade R-CNN, and Cascade CNN deep learning models to obtain building segmentation maps, building bounding boxes, and building corners, respectively, from very high-resolution remote sensing images. We used Delaunay triangulation to construct building footprint polygons based on the detected building corners with the constraints of building bounding boxes and building segmentation maps. Experiments on the Wuhan University building dataset and ISPRS Vaihingen dataset indicate that DLEBFP can perform well in extracting high-quality building footprint polygons. Compared with the other semantic segmentation models and the vector map generalization method, DLEBFP is able to achieve comparable mapping accuracies with semantic segmentation models on a pixel basis and generate building footprint polygons with concise edges and vertices with regular shapes that are close to the reference data. The promising performance indicates that our method has the potential to extract accurate building footprint polygons from remote sensing images for applications in geospatial analysis.
C1 [Li, Ziming; Xin, Qinchuan; Sun, Ying; Cao, Mengying] Sun Yat Sen Univ, Sch Geog & Planning, Guangdong Key Lab Urbanizat & Geosimulat, Guangzhou 510275, Peoples R China.
   [Xin, Qinchuan] Chinese Acad Sci, Res Ctr Ecol & Environm Cent Asia, State Key Lab Desert & Oasis Ecol, Urumqi 830011, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences
RP Xin, QCA (corresponding author), Sun Yat Sen Univ, Sch Geog & Planning, Guangdong Key Lab Urbanizat & Geosimulat, Guangzhou 510275, Peoples R China.; Xin, QCA (corresponding author), Chinese Acad Sci, Res Ctr Ecol & Environm Cent Asia, State Key Lab Desert & Oasis Ecol, Urumqi 830011, Peoples R China.
EM lizm9@mail2.sysu.edu.cn; xinqinchuan@mail.sysu.edu.cn; sunying23@mail.sysu.edu.cn; caomy7@mail2.sysu.edu.cn
FU National Natural Science Foundation of China [41875122, 41801351]; National Key R&D Program of China [2017YFA0604300, 2017YFA0604400]; Western Talents [2018XBYJRC004]; Guangdong Top Young Talents [2017TQ04Z359]
CR [Anonymous], 1998, CARTOGR GEOGR INFORM, V0, P0, DOI DOI 10.1559/152304098782441750
   Awrangjeb M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101512
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cai ZW, 2018, PROC CVPR IEEE, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Cao Z, 2017, PROC CVPR IEEE, V0, PP1302, DOI 10.1109/CVPR.2017.143
   Chen Q, 2020, ISPRS J PHOTOGRAMM, V170, P114, DOI 10.1016/j.isprsjprs.2020.10.008
   Chen Q, 2019, ISPRS J PHOTOGRAMM, V147, P42, DOI 10.1016/j.isprsjprs.2018.11.011
   Deng M, 2011, COMPUT ENVIRON URBAN, V35, P320, DOI 10.1016/j.compenvurbsys.2011.02.003
   Dey EK, 2020, INT J REMOTE SENS, V41, P6325, DOI 10.1080/01431161.2020.1737339
   Douglas D.H., 1973, CARTOGRAPHICA INT J, V10, P112, DOI 10.3138/FM57-6770-U75U-7727
   Du SH, 2015, ISPRS J PHOTOGRAMM, V105, P107, DOI 10.1016/j.isprsjprs.2015.03.011
   Fu G, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050498
   Gilani SAN, 2018, GISCI REMOTE SENS, V55, P63, DOI 10.1080/15481603.2017.1361509
   Girard N, 2018, INT GEOSCI REMOTE SE, V0, P2083
   Glorot X., 2011, P INT C ARTIFICIAL I, V0, P315
   He HQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091040
   He K., 2015, PROC CVPR IEEE, V5, P6
   He XJ, 2018, ISPRS J PHOTOGRAMM, V136, P26, DOI 10.1016/j.isprsjprs.2017.12.001
   Heckbert P.S., 1997, SURVEY POLYGONAL SUR, V0, P0
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Huang X, 2011, PHOTOGRAMM ENG REM S, V77, P721, DOI 10.14358/PERS.77.7.721
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaturapitpornchai R, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121444
   Jensen JR, 1999, PHOTOGRAMM ENG REM S, V65, P611
   Ji SP, 2019, INT J REMOTE SENS, V40, P3308, DOI 10.1080/01431161.2018.1528024
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P0, DOI 10.5555/303568.303704
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P11354
   Li QY, 2020, IEEE T GEOSCI REMOTE, V58, P7502, DOI 10.1109/TGRS.2020.2973720
   Liao C, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13061049
   Liasis G, 2016, INT J REMOTE SENS, V37, P1127, DOI 10.1080/01431161.2016.1148283
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242912
   Liu YC, 2018, ISPRS J PHOTOGRAMM, V145, P78, DOI 10.1016/j.isprsjprs.2017.12.007
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Maggiori E, 2017, IEEE IMAGE PROC, V0, P560
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Mahmud J, 2020, PROC CVPR IEEE, V0, PP438, DOI 10.1109/CVPR42600.2020.00052
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Marmanis D, 2016, ISPRS ANN PHOTO REM, V3, P473, DOI 10.5194/isprsannals-III-3-473-2016
   Milletari F, 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Ok AO, 2013, IEEE T GEOSCI REMOTE, V51, P1701, DOI 10.1109/TGRS.2012.2207123
   Pfister T, 2015, IEEE I CONF COMP VIS, V0, PP1913, DOI 10.1109/ICCV.2015.222
   Qin XB, 2018, IEEE GEOSCI REMOTE S, V15, P1775, DOI 10.1109/LGRS.2018.2857719
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rottensteiner F, 2007, ISPRS J PHOTOGRAMM, V62, P135, DOI 10.1016/j.isprsjprs.2007.03.001
   Rottensteiner F, 2014, ISPRS J PHOTOGRAMM, V93, P256, DOI 10.1016/j.isprsjprs.2013.10.004
   Shi WZ, 2006, CARTOGR J, V43, P27, DOI 10.1179/000870406X93490
   Shi YL, 2019, IEEE GEOSCI REMOTE S, V16, P603, DOI 10.1109/LGRS.2018.2878486
   Simonyan K, 2015, ARXIV, V0, P0
   Song WG, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19081915
   Tong XH, 2013, ISPRS J PHOTOGRAMM, V79, P53, DOI 10.1016/j.isprsjprs.2013.01.012
   Turker M, 2015, INT J APPL EARTH OBS, V34, P58, DOI 10.1016/j.jag.2014.06.016
   Wang M, 2013, INT GEOSCI REMOTE SE, V0, PP508, DOI 10.1109/IGARSS.2013.6721204
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu GM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030407
   Wu GM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081195
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Ye ZR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242970
   Yuan JY, 2018, IEEE T PATTERN ANAL, V40, P2793, DOI 10.1109/TPAMI.2017.2750680
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
   Zhou S, 2005, DEVELOPMENTS IN SPATIAL DATA HANDLING, V0, PP369, DOI 10.1007/3-540-26772-7_28
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 66
TC 9
Z9 9
U1 10
U2 40
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2021
VL 13
IS 18
BP 
EP 
DI 10.3390/rs13183630
PG 25
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UY7UD
UT WOS:000701723300001
DA 2023-04-26
ER

PT J
AU Meng, Z
   Jiao, LC
   Liang, MM
   Zhao, F
AF Meng, Zhe
   Jiao, Licheng
   Liang, Miaomiao
   Zhao, Feng
TI Hyperspectral Image Classification With Mixed Link Networks
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Hyperspectral imaging; Topology; Network topology; Additives; Redundancy; Computer architecture; Convolutional neural network (CNN); deep learning; hyperspectral image (HSI) classification; mixed link network (MLNet)
ID markov-random-fields; residual network; cnn
AB Convolutional neural networks (CNNs) have improved the accuracy of hyperspectral image (HSI) classification significantly. However, CNN models usually generate a large number of feature maps, which lead to high redundancy and cannot guarantee to effectively extract discriminative features for well characterizing the complex structures of HSIs. In this article, two novel mixed link networks (MLNets) are proposed to enhance the representational ability of CNNs for HSI classification. Specifically, the proposed mixed link architectures integrate the feature reusage property of the residual network and the capability of effective new feature exploration of the densely convolutional network, extracting more discriminative features from HSIs. Compared with the dual path architecture, the proposed mixed link architectures can further improve the information flow throughout the network. Experimental results on three hyperspectral benchmark datasets demonstrate that our MLNets achieve competitive results compared with other state-of-the-art HSI classification approaches.
C1 [Meng, Zhe; Zhao, Feng] Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
   [Jiao, Licheng] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
   [Liang, Miaomiao] Jiangxi Univ Sci & Technol, Sch Informat Engn, Ganzhou 341000, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xidian University; Jiangxi University of Science & Technology
RP Meng, Z (corresponding author), Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
EM zhemeng@xupt.edu.cn; lchjiao@mail.xidian.edu.cn; liangmiaom@gmail.com; fzhao.xupt@gmail.com
FU National Natural Science Foundation of China [61901198, 62071379]; Natural Science Basic Research Plan in Shaanxi Province of China [2019JQ-377]; New Star Team of Xi'an University of Posts and Telecommunications [xyt2016-01]
CR Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Cao XY, 2018, IEEE T IMAGE PROCESS, V27, P2354, DOI 10.1109/TIP.2018.2799324
   Cao XY, 2017, NEUROCOMPUTING, V226, P90, DOI 10.1016/j.neucom.2016.11.034
   Chen Y., 2017, PROC C ADV NEURAL IN, V0, P4467
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Delalieux S, 2012, REMOTE SENS ENVIRON, V126, P222, DOI 10.1016/j.rse.2012.08.029
   Gao QS, 2019, COMPUT VIS IMAGE UND, V188, P0, DOI 10.1016/j.cviu.2019.102801
   Gao QS, 2019, IEEE T GEOSCI REMOTE, V57, P7718, DOI 10.1109/TGRS.2019.2915809
   Ghamisi P, 2018, IEEE GEOSC REM SEN M, V6, P10, DOI 10.1109/MGRS.2018.2854840
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Glorot X., 2011, P 14 INT C ART INT S, V0, P315
   Gong ZQ, 2019, IEEE T GEOSCI REMOTE, V57, P3599, DOI 10.1109/TGRS.2018.2886022
   Gu YF, 2017, IEEE T GEOSCI REMOTE, V55, P6547, DOI 10.1109/TGRS.2017.2729882
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He L, 2018, IEEE T GEOSCI REMOTE, V56, P1579, DOI 10.1109/TGRS.2017.2765364
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Jiao LC, 2017, IEEE T GEOSCI REMOTE, V55, P5585, DOI 10.1109/TGRS.2017.2710079
   Kang XD, 2019, IEEE GEOSCI REMOTE S, V16, P447, DOI 10.1109/LGRS.2018.2873476
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Lei J, 2019, IEEE T GEOSCI REMOTE, V57, P8131, DOI 10.1109/TGRS.2019.2918387
   Li J, 2013, IEEE GEOSCI REMOTE S, V10, P318, DOI 10.1109/LGRS.2012.2205216
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010067
   Lin MPH, 2014, DES AUT CON, V0, P0, DOI DOI 10.1145/2593069.2593179
   Lu T, 2017, IEEE T GEOSCI REMOTE, V55, P4398, DOI 10.1109/TGRS.2017.2691906
   Ma XR, 2018, IEEE T GEOSCI REMOTE, V56, P4781, DOI 10.1109/TGRS.2018.2837142
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Meng Z, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222718
   Meng Z, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161896
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P2145, DOI 10.1109/TGRS.2018.2871782
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P740, DOI 10.1109/TGRS.2018.2860125
   Paoletti ME, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091454
   Qi WC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202363
   Roy SK, 2020, IEEE T GEOSCI REMOTE, V58, P5277, DOI 10.1109/TGRS.2019.2961681
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Shivers SW, 2019, REMOTE SENS ENVIRON, V222, P215, DOI 10.1016/j.rse.2018.12.030
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Veraverbeke S, 2018, REMOTE SENS ENVIRON, V216, P105, DOI 10.1016/j.rse.2018.06.020
   Wang L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070884
   Wang WH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2819
   Wang WJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071068
   Zhang CJ, 2019, IEEE T GEOSCI REMOTE, V57, P9201, DOI 10.1109/TGRS.2019.2925615
   Zhang K, 2018, PROC CVPR IEEE, V0, PP3262, DOI 10.1109/CVPR.2018.00344
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhao GZ, 2019, NEUROCOMPUTING, V339, P149, DOI 10.1016/j.neucom.2019.02.019
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhong P, 2017, IEEE T GEOSCI REMOTE, V55, P3516, DOI 10.1109/TGRS.2017.2675902
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhu KQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030223
NR 59
TC 14
Z9 14
U1 3
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2494
EP 2507
DI 10.1109/JSTARS.2021.3053567
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QM9MJ
UT WOS:000622097100003
DA 2023-04-26
ER

PT J
AU Kyriakou, C
   Christodoulou, SE
   Dimitriou, L
AF Kyriakou, Charalambos
   Christodoulou, Symeon E.
   Dimitriou, Loukas
TI Spatial Roadway Condition-Assessment Mapping Utilizing Smartphones and Machine Learning Algorithms
SO TRANSPORTATION RESEARCH RECORD
LA English
DT Article
AB The paper presents a data-driven framework and related field studies on the use of supervised machine learning and smartphone technology for the spatial condition-assessment mapping of roadway pavement surface anomalies. The study explores the use of data, collected by sensors from a smartphone and a vehicle's onboard diagnostic device while the vehicle is in movement, for the detection of roadway anomalies. The research proposes a low-cost and automated method to obtain up-to-date information on roadway pavement surface anomalies with the use of smartphone technology, artificial neural networks, robust regression analysis, and supervised machine learning algorithms for multiclass problems. The technology for the suggested system is readily available and accurate and can be utilized in pavement monitoring systems and geographical information system applications. Further, the proposed methodology has been field-tested, exhibiting accuracy levels higher than 90%, and it is currently expanded to include larger datasets and a bigger number of common roadway pavement surface defect types. The proposed system is of practical importance since it provides continuous information on roadway pavement surface conditions, which can be valuable for pavement engineers and public safety.
C1 [Kyriakou, Charalambos; Christodoulou, Symeon E.; Dimitriou, Loukas] Univ Cyprus, Dept Civil & Environm Engn, Nicosia, Cyprus.
C3 University of Cyprus
RP Kyriakou, C (corresponding author), Univ Cyprus, Dept Civil & Environm Engn, Nicosia, Cyprus.
EM kyriakou.charalambos@ucy.ac.cy
FU European Regional Development Fund; Republic of Cyprus through the Cyprus Research & Technology Foundation (''Restart 2016-2020'') [INTEGRATED/0918/0056]
CR AASHTO, 1990, GUID PAV MAN SYST, V0, P0
   Alam MY, 2020, PERVASIVE MOB COMPUT, V61, P0, DOI 10.1016/j.pmcj.2019.101103
   Allouch A, 2017, IEEE SENS J, V17, P4231, DOI 10.1109/JSEN.2017.2702739
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Kulkarni P., 2012, P 4 INT C COMM SYST, V0, P1
   Kyriakou C., 2019, P EUR C COMP CONSTR, V0, P0
   Kyriakou C., 2017, P LEAN COMP CONSTR C, V0, P0
   Kyriakou C., 2021, TRANSPORTATION RES P, V52, P203, DOI 10.1016/j.trpro.2021.01.023
   Kyriakou C, 2019, J INFRASTRUCT SYST, V25, P0, DOI 10.1061/(ASCE)IS.1943-555X.0000489
   Kyriakou C, 2016, IEEE MEDITERR ELECT, V0, P0
   McGhee K.H., 2004, NCHRP SYNTHESIS, V0, P0
   Miller J.S., 2003, PUBLICATION US FEDER, V03-031, P0
   Seraj F., 2015, INT WORKSH MACH LEAR, V0, P0
   Souza VMA, 2018, PERVASIVE MOB COMPUT, V51, P121, DOI 10.1016/j.pmcj.2018.10.008
   Varona B, 2020, PERS UBIQUIT COMPUT, V24, P519, DOI 10.1007/s00779-019-01234-z
NR 15
TC 3
Z9 3
U1 2
U2 7
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0361-1981
EI 2169-4052
J9 TRANSPORT RES REC
JI Transp. Res. Record
PD SEP 15
PY 2021
VL 2675
IS 9
BP 1118
EP 1126
DI 10.1177/03611981211006105
EA APR 2021
PG 9
WC Engineering, Civil; Transportation; Transportation Science & Technology
SC Engineering; Transportation
GA WL1RH
UT WOS:000684615600001
DA 2023-04-26
ER

PT J
AU Osco, LP
   Nogueira, K
   Ramos, APM
   Pinheiro, MMF
   Furuya, DEG
   Goncalves, WN
   Jorge, LAD
   Marcato, J
   dos Santos, JA
AF Osco, Lucas Prado
   Nogueira, Keiller
   Marques Ramos, Ana Paula
   Faita Pinheiro, Mayara Maezano
   Furuya, Danielle Elis Garcia
   Goncalves, Wesley Nunes
   de Castro Jorge, Lucio Andre
   Marcato Junior, Jose
   dos Santos, Jefersson Alex
TI Semantic segmentation of citrus-orchard using deep neural networks and multispectral UAV-based imagery
SO PRECISION AGRICULTURE
LA English
DT Article
DE Convolutional neural network; Remote sensing; Thematic map
ID trees
AB Accurately mapping farmlands is important for precision agriculture practices. Unmanned aerial vehicles (UAV) embedded with multispectral cameras are commonly used to map plants in agricultural landscapes. However, separating plantation fields from the remaining objects in a multispectral scene is a difficult task for traditional algorithms. In this connection, deep learning methods that perform semantic segmentation could help improve the overall outcome. In this study, state-of-the-art deep learning methods to semantic segment citrus-trees in multispectral images were evaluated. For this purpose, a multispectral camera that operates at the green (530-570 nm), red (640-680 nm), red-edge (730-740 nm) and also near-infrared (770-810 nm) spectral regions was used. The performance of the following five state-of-the-art pixelwise methods were evaluated: fully convolutional network (FCN), U-Net, SegNet, dynamic dilated convolution network (DDCN) and DeepLabV3 + . The results indicated that the evaluated methods performed similarly in the proposed task, returning F1-Scores between 94.00% (FCN and U-Net) and 94.42% (DDCN). It was also determined the inference time needed per area and, although the DDCN method was slower, based on a qualitative analysis, it performed better in highly shadow-affected areas. This study demonstrated that the semantic segmentation of citrus orchards is highly achievable with deep neural networks. The state-of-the-art deep learning methods investigated here proved to be equally suitable to solve this task, providing fast solutions with inference time varying from 0.98 to 4.36 min per hectare. This approach could be incorporated into similar research, and contribute to decision-making and accurate mapping of plantation fields.
C1 [Osco, Lucas Prado; Marques Ramos, Ana Paula; Faita Pinheiro, Mayara Maezano; Furuya, Danielle Elis Garcia] Univ Western Sao Paulo UNOESTE, Fac Engn & Architecture & Urbanism, Postgrad Program Environm & Reg Dev, Presidente Prudente, SP, Brazil.
   [Osco, Lucas Prado; Goncalves, Wesley Nunes; Marcato Junior, Jose] Fed Univ Mato Grosso Sul UFMS, Fac Engn Architecture & Urbanism & Geog, Campo Grande, MS, Brazil.
   [Nogueira, Keiller] Univ Stirling, Comp Sci & Math Div, Stirling FK9 4LA, Scotland.
   [Goncalves, Wesley Nunes] Fed Univ Mato Grosso Sul UFMS, Fac Comp Sci, Campo Grande, MS, Brazil.
   [de Castro Jorge, Lucio Andre] Brazilian Agr Res Agcy EMBRAPA, Natl Res Ctr Dev Agr Instrumentat, R 15 Novembro 1452, BR-13560970 Sao Carlos, SP, Brazil.
   [dos Santos, Jefersson Alex] Fed Univ Minas Gerais UFMG, Dept Comp Sci, Belo Horizonte, MG, Brazil.
C3 Universidade do Oeste Paulista; Universidade Federal de Mato Grosso do Sul; University of Stirling; Universidade Federal de Mato Grosso do Sul; Universidade Federal de Minas Gerais
RP Osco, LP (corresponding author), Univ Western Sao Paulo UNOESTE, Fac Engn & Architecture & Urbanism, Postgrad Program Environm & Reg Dev, Presidente Prudente, SP, Brazil.; Osco, LP (corresponding author), Fed Univ Mato Grosso Sul UFMS, Fac Engn Architecture & Urbanism & Geog, Campo Grande, MS, Brazil.
EM lucasosco@unoeste.br; keiller.nogueira@stir.ac.uk; anaramos@unoeste.br; mayarafaita@gmail.com; daniellegarciafuruya@gmail.com; wesley.goncalves@ufms.br; lucio.jorge@embrapa.br; jose.marcato@ufms.br; jefersson@dcc.ufmg.br
FU CNPq [p: 303559/2019-5, 433783/2018-4, 304173/2016-9]; CAPES Print [p: 88881.311850/2018-01]; Fundect [p. 59/300.066/2015, 59/300.095/2015]
CR Ampatzidis Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040410
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Bosilj P, 2020, J FIELD ROBOT, V37, P7, DOI 10.1002/rob.21869
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chiu MT, 2020, PROC CVPR IEEE, V0, PP2825, DOI 10.1109/CVPR42600.2020.00290
   Csillik O, 2018, DRONES-BASEL, V2, P0, DOI 10.3390/drones2040039
   Ganesh P, 2019, IFAC PAPERSONLINE, V52, P70, DOI 10.1016/j.ifacol.2019.12.499
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Hunt ER, 2018, INT J REMOTE SENS, V39, P5345, DOI 10.1080/01431161.2017.1410300
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leiva JN, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.036003
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Luo WJ, 2016, ADV NEUR IN, V29, P0
   Majeed Y, 2020, COMPUT ELECTRON AGR, V170, P0, DOI 10.1016/j.compag.2020.105277
   Nogueira Keiller, 2019, 2019 XV WORKSHOP DE VISAO COMPUTACIONAL (WVC) 2019 XV COMPUTER VISION WORKSHOP (WVC). PROCEEDINGS, V0, PP72, DOI 10.1109/WVC.2019.8876942
   Nogueira K, 2019, IEEE T GEOSCI REMOTE, V57, P7503, DOI 10.1109/TGRS.2019.2913861
   Nogueira K, 2018, IEEE GEOSCI REMOTE S, V15, P1446, DOI 10.1109/LGRS.2018.2845549
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Osco LP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060906
   Osco LP, 2020, ISPRS J PHOTOGRAMM, V160, P97, DOI 10.1016/j.isprsjprs.2019.12.010
   Osco LP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232797
   Osco LP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242925
   Ozdarici-Ok A, 2015, INT J REMOTE SENS, V36, P4275, DOI 10.1080/01431161.2015.1079663
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sa I, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091423
   TensorFlow, 2020, API TENSORFLOW COR V, V0, P0
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111402
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang HK, 2017, REMOTE SENS LETT, V8, P438, DOI 10.1080/2150704X.2017.1280200
NR 35
TC 17
Z9 18
U1 6
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1385-2256
EI 1573-1618
J9 PRECIS AGRIC
JI Precis. Agric.
PD AUG 15
PY 2021
VL 22
IS 4
BP 1171
EP 1188
DI 10.1007/s11119-020-09777-5
EA JAN 2021
PG 18
WC Agriculture, Multidisciplinary
SC Agriculture
GA TB1WS
UT WOS:000604197700004
DA 2023-04-26
ER

PT J
AU Tun, NL
   Gavrilov, A
   Tun, NM
   Trieu, D
   Aung, H
AF Tun, Nyan Linn
   Gavrilov, Alexander
   Tun, Naing Min
   Trieu, Do Minh
   Aung, Htet
TI Remote Sensing Data Classification Using A Hybrid Pre-Trained VGG16 CNN-SVM Classifier
SO PROCEEDINGS OF THE 2021 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (ELCONRUS)
LA English
DT Proceedings Paper
DE Deep learning; remote sensing datasets; hybrid VGG16-SVM classifier model
AB In recent years, deep learning techniques have been improved to classify geographical information by assigning remote sensing images pixels. CNN models can fix the feature learning techniques in the field of visualization systems. This paper proposed a hybrid pre-trained VGG16 -convolutional neural networks (CNNs) - SVM classifier models. VGG16 conducts the features extraction from the input remote sensing data, and SVM classifier solves the classification output based on the CNN output feature maps. Our proposed model can play its neural network layers with a novel feature extraction strategy to achieve good classification accuracy over high-resolution remote sensing data. Classification experience is performed on the two remote sensing public datasets (UC Merced Land and RSSCN7), using high computational performance support that achieved reliable classification results within the shortest time.
C1 [Tun, Nyan Linn; Gavrilov, Alexander; Tun, Naing Min; Trieu, Do Minh; Aung, Htet] Bauman Moscow State Tech Univ, Dept Automat Control Syst, Moscow, Russia.
C3 Bauman Moscow State Technical University
RP Tun, NL (corresponding author), Bauman Moscow State Tech Univ, Dept Automat Control Syst, Moscow, Russia.
EM nyanlin54@gmail.com; alexgavrilov@mail.ru; naingminhtun52@gmail.com; dominhtrieuvhp@gmail.com; happyland27057@gmail.com
CR Angelo NP, 2003, INT J REMOTE SENS, V24, P2167, DOI 10.1080/01431160210163146
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Li X., 2004, IEEE 2004 INT C IM P, V0, P0
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Tun Nyan Linn, 2020, IEEE INT C IND ENG A, V0, P0
   Yang B., 2020, ESTRO PO 1343, V0, PP1, DOI 10.3252/pso.eu.ESTRO2020.2020
NR 10
TC 5
Z9 5
U1 9
U2 24
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2376-6557
EI 
J9 IEEE NW RUSS YOUNG
PD JUN 15
PY 2021
VL 0
IS 
BP 2171
EP 2175
DI 10.1109/ElConRus51938.2021.9396706
PG 5
WC Engineering, Electrical & Electronic
SC Engineering
GA BR7SJ
UT WOS:000669709802044
DA 2023-04-26
ER

PT J
AU Yuan, LN
   Li, L
   Zhang, T
   Chen, LQ
   Liu, WQ
   Hu, S
   Yang, LH
AF Yuan, Lina
   Li, Long
   Zhang, Ting
   Chen, Longqian
   Liu, Weiqiang
   Hu, Sai
   Yang, Longhua
TI Modeling Soil Moisture from Multisource Data by Stepwise Multilinear Regression: An Application to the Chinese Loess Plateau
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE relative soil moisture; Chinese Loess Plateau; stepwise multilinear regression; dummy variables
ID multiple-linear-regression; artificial neural-networks; land-surface model; water content; data assimilation; small catchment; amsr-e; temporal variations; dummy variables; re-vegetation
AB This study aims to integrate multisource data to model the relative soil moisture (RSM) over the Chinese Loess Plateau in 2017 by stepwise multilinear regression (SMLR) in order to improve the spatial coverage of our previously published RSM. First, 34 candidate variables (12 quantitative and 22 dummy variables) from the Moderate Resolution Imaging Spectroradiometer (MODIS) and topographic, soil properties, and meteorological data were preprocessed. Then, SMLR was applied to variables without multicollinearity to select statistically significant (p-value < 0.05) variables. After the accuracy assessment, monthly, seasonal, and annual spatial patterns of RSM were mapped at 500 m resolution and evaluated. The results indicate that there was a high potential of SMLR to model RSM with the desired accuracy (best fit of the model with Pearson's r = 0.969, root mean square error = 0.761%, and mean absolute error = 0.576%) over the Chinese Loess Plateau. The variables of elevation (0-500 m and 2000-2500 m), precipitation, soil texture of loam, and nighttime land surface temperature can continuously be used in the regression models for all seasons. Including dummy variables improved the model fit both in calibration and validation. Moreover, the SMLR-modeled RSM achieved better spatial coverage than that of the reference RSM for almost all periods. This is a significant finding as the SMLR method supports the use of multisource data to complement and/or replace coarse resolution satellite imagery in the estimation of RSM.
C1 [Yuan, Lina; Li, Long; Zhang, Ting; Chen, Longqian] China Univ Min & Technol, Sch Publ Policy & Management, Daxue Rd 1, Xuzhou 221116, Jiangsu, Peoples R China.
   [Li, Long] Vrije Univ Brussel, Dept Geog & Earth Syst Sci, Pl Laan 2, B-1050 Brussels, Belgium.
   [Liu, Weiqiang] China Univ Min & Technol, Sch Environm & Spatial Informat, Daxue Rd 1, Xuzhou 221116, Jiangsu, Peoples R China.
   [Hu, Sai] Jiangsu Ocean Univ, Sch Humanities & Law, Cangwu Rd 59, Lianyungang 222005, Peoples R China.
   [Yang, Longhua] Shanghai Gongjing Environm Protect Co Ltd, Dept Res & Dev, Yuanjiang Rd 525, Shanghai 201100, Peoples R China.
C3 China University of Mining & Technology; Vrije Universiteit Brussel; China University of Mining & Technology; Jiangsu Ocean University
RP Chen, LQ (corresponding author), China Univ Min & Technol, Sch Publ Policy & Management, Daxue Rd 1, Xuzhou 221116, Jiangsu, Peoples R China.
EM lnyuan@cumt.edu.cn; long.li@cumt.edu.cn; tingzhang@cumt.edu.cn; chenlq@cumt.edu.cn; weiqiang.liu@cumt.edu.cn; saihu@jou.edu.cn; yanglh3@163.com
FU Fundamental Research Funds for the Central Universities [2018ZDPY07]
CR Abowarda AS, 2021, REMOTE SENS ENVIRON, V255, P0, DOI 10.1016/j.rse.2021.112301
   Albertson JD, 2001, J HYDROL, V243, P101, DOI 10.1016/S0022-1694(00)00405-4
   Awange JL, 2014, ADV WATER RESOUR, V74, P64, DOI 10.1016/j.advwatres.2014.07.012
   Bayat AT, 2020, PROCEEDINGS OF 2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR AGRICULTURE AND FORESTRY (METROAGRIFOR), V0, PP201, DOI 10.1109/MetroAgriFor50201.2020.9277557
   Bortolini D, 2018, REV BRAS CIENC SOLO, V42, P0, DOI 10.1590/18069657rbcs20170250
   Brust C, 2021, REMOTE SENS ENVIRON, V255, P0, DOI 10.1016/j.rse.2020.112277
   Capodici F, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10010023
   Carranza C, 2021, J HYDROL, V593, P0, DOI 10.1016/j.jhydrol.2020.125840
   Cenci L, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121950
   Chakravorty A, 2016, REMOTE SENS ENVIRON, V186, P514, DOI 10.1016/j.rse.2016.09.011
   Chen DS, 2017, FORESTS, V8, P0, DOI 10.3390/f8080268
   Chen JA, 2011, INT J REMOTE SENS, V32, P1165, DOI 10.1080/01431160903527421
   Chen MX, 2020, EARTH SPACE SCI, V7, P0, DOI 10.1029/2020EA001108
   Chen T, 2014, REMOTE SENS ENVIRON, V140, P330, DOI 10.1016/j.rse.2013.08.022
   Chen ZL, 2019, CHEMOMETR INTELL LAB, V195, P0, DOI 10.1016/j.chemolab.2019.103874
   Cheng L, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16193522
   Claps P, 2004, P SOC PHOTO-OPT INS, V5232, P378, DOI 10.1117/12.510984
   COHEN A, 1991, AM STAT, V45, P226, DOI 10.2307/2684296
   Colliander A, 2017, IEEE GEOSCI REMOTE S, V14, P2107, DOI 10.1109/LGRS.2017.2753203
   Cox NJ, 2019, STATA J, V19, P246, DOI 10.1177/1536867X19830921
   Djamai N, 2016, REMOTE SENS ENVIRON, V184, P1, DOI 10.1016/j.rse.2016.06.010
   Djamai N, 2015, REMOTE SENS ENVIRON, V170, P255, DOI 10.1016/j.rse.2015.09.013
   Dong JZ, 2015, ADV WATER RESOUR, V83, P111, DOI 10.1016/j.advwatres.2015.05.017
   Dorigo W, 2016, INT J APPL EARTH OBS, V48, P1, DOI 10.1016/j.jag.2016.02.007
   Doubkova M, 2012, REMOTE SENS ENVIRON, V120, P188, DOI 10.1016/j.rse.2011.09.031
   Dumedah G, 2014, ADV WATER RESOUR, V74, P231, DOI 10.1016/j.advwatres.2014.09.011
   Dumedah G, 2014, J HYDROL, V515, P330, DOI 10.1016/j.jhydrol.2014.04.068
   Ebrahimi-Khusfi M, 2018, INT J APPL EARTH OBS, V67, P148, DOI 10.1016/j.jag.2017.12.005
   Eeftens M, 2012, ENVIRON SCI TECHNOL, V46, P11195, DOI 10.1021/es301948k
   Elshorbagy A, 2008, J HYDROL, V362, P1, DOI 10.1016/j.jhydrol.2008.08.012
   Fang B, 2014, J HYDROL, V516, P258, DOI 10.1016/j.jhydrol.2013.12.008
   Fu BJ, 2003, CATENA, V54, P197, DOI 10.1016/S0341-8162(03)00065-1
   Futing Liao T., 2012, SAGE ENCY SOCIAL SCI, V0, P1
   Geng R, 2017, BIOSYST ENG, V160, P95, DOI 10.1016/j.biosystemseng.2017.06.001
   Gupta DK, 2017, ADV SPACE RES, V59, P996, DOI 10.1016/j.asr.2016.11.032
   Han JQ, 2018, J HYDROL, V563, P65, DOI 10.1016/j.jhydrol.2018.05.051
   He J, 2013, THERM SCI, V17, P1375, DOI 10.2298/TSCI1305375H
   Hirsch-Eshkol T, 2014, LAND, V3, P1015, DOI 10.3390/land3031015
   Holgersson T, 2016, J APPL STAT, V43, P1564, DOI 10.1080/02664763.2015.1092711
   Hu W, 2011, GEODERMA, V162, P260, DOI 10.1016/j.geoderma.2011.02.008
   Huza J, 2014, J HYDROL, V516, P330, DOI 10.1016/j.jhydrol.2014.01.041
   Jenkins DG, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0229345
   Jiao L, 2018, FOREST ECOL MANAG, V424, P428, DOI 10.1016/j.foreco.2018.05.011
   Jiao Q, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020156
   Karthikeyan L, 2017, ADV WATER RESOUR, V109, P236, DOI 10.1016/j.advwatres.2017.09.010
   Khaki M, 2020, AUST J EARTH SCI, V67, P265, DOI 10.1080/08120099.2019.1620855
   Kim S., 2019, REMOTE SENSING EARTH, V2, P225, DOI 10.1007/s41976-019-00025-7
   Koley S, 2020, GEODERMA, V378, P0, DOI 10.1016/j.geoderma.2020.114618
   Kumar SV, 2018, REMOTE SENS ENVIRON, V204, P392, DOI 10.1016/j.rse.2017.10.016
   Lee Y, 2019, AGR WATER MANAGE, V213, P580, DOI 10.1016/j.agwat.2018.09.004
   Leng P, 2014, INT J REMOTE SENS, V35, P988, DOI 10.1080/01431161.2013.875237
   Li FQ, 2010, ADV WATER RESOUR, V33, P201, DOI 10.1016/j.advwatres.2009.11.007
   Li L, 2020, FORESTS, V11, P0, DOI 10.3390/f11020125
   Li L, 2018, EARTH SURF PROC LAND, V43, P840, DOI 10.1002/esp.4284
   Li XZ, 2017, J HYDROL, V555, P659, DOI 10.1016/j.jhydrol.2017.10.045
   Liu D, 2017, J HYDROL, V553, P88, DOI 10.1016/j.jhydrol.2017.07.049
   Liu D, 2017, J HYDROL, V547, P67, DOI 10.1016/j.jhydrol.2017.01.036
   Liu D, 2016, J HYDROL, V538, P243, DOI 10.1016/j.jhydrol.2016.04.021
   Liu MS, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12113085
   Liu YXY, 2020, J HYDROL, V590, P0, DOI 10.1016/j.jhydrol.2020.125406
   Liu Y, 2021, IEEE J-STARS, V14, P1292, DOI 10.1109/JSTARS.2020.3043628
   Lu L, 2014, INT J REMOTE SENS, V35, P3797, DOI 10.1080/01431161.2014.919677
   [马红章 Ma Hongzhang], 2014, 遥感学报 JOURNAL OF REMOTE SENSING, V18, P673
   Maheu A, 2018, J HYDROL, V558, P532, DOI 10.1016/j.jhydrol.2018.01.065
   Mahmoud MA, 2015, QUAL RELIAB ENG INT, V31, P851, DOI 10.1002/qre.1644
   Malbeteau Y, 2016, INT J APPL EARTH OBS, V45, P221, DOI 10.1016/j.jag.2015.10.002
   McNally A, 2016, INT J APPL EARTH OBS, V48, P96, DOI 10.1016/j.jag.2016.01.001
   Merlin O, 2015, REMOTE SENS-BASEL, V7, P3783, DOI 10.3390/rs70403783
   Moon H, 2015, TERR ATMOS OCEAN SCI, V26, P599, DOI 10.3319/TAO.2015.04.22.01(Hy)
   Nakamura K, 2017, CHEMOSPHERE, V186, P501, DOI 10.1016/j.chemosphere.2017.07.131
   Niu CY, 2015, SOLID EARTH, V6, P1157, DOI 10.5194/se-6-1157-2015
   Pahlavan-Rad MR, 2020, CATENA, V194, P0, DOI 10.1016/j.catena.2020.104715
   Palombo A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071515
   Pan J, 2017, ENVIRON SCI POLLUT R, V24, P23953, DOI 10.1007/s11356-017-9974-5
   Panciera R, 2011, REMOTE SENS ENVIRON, V115, P3343, DOI 10.1016/j.rse.2011.07.017
   Pasolli L, 2011, CAN J REMOTE SENS, V37, P535
   Piles M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010095
   PRICE JC, 1985, REMOTE SENS ENVIRON, V18, P59, DOI 10.1016/0034-4257(85)90038-0
   Qiu Y, 2003, CATENA, V54, P173, DOI 10.1016/S0341-8162(03)00064-X
   Qiu Y, 2010, J ARID ENVIRON, V74, P208, DOI 10.1016/j.jaridenv.2009.08.003
   Rahimi-Ajdadi F, 2018, MEASUREMENT, V121, P179, DOI 10.1016/j.measurement.2018.02.060
   Raoult N, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111786
   Sabaghy S, 2018, REMOTE SENS ENVIRON, V209, P551, DOI 10.1016/j.rse.2018.02.065
   Sandells MJ, 2008, ADV WATER RESOUR, V31, P1433, DOI 10.1016/j.advwatres.2008.01.012
   Santi E, 2018, INT J APPL EARTH OBS, V65, P114, DOI 10.1016/j.jag.2017.10.010
   Sharma MJ, 2015, APPL MATH COMPUT, V253, P126, DOI 10.1016/j.amc.2014.12.050
   Sharma S, 2021, INT J WILDLAND FIRE, V30, P57, DOI 10.1071/WF19193
   Sharma S, 2018, RANGELAND ECOL MANAG, V71, P356, DOI 10.1016/j.rama.2018.01.001
   Singh A.K., 2019, J SOIL SALIN WATER Q, V11, P68
   Soleimani R, 2020, COMMUN SOIL SCI PLAN, V51, P2297, DOI 10.1080/00103624.2020.1822385
   Spennemann PC, 2018, INT J APPL EARTH OBS, V64, P96, DOI 10.1016/j.jag.2017.08.016
   Su CH, 2013, GLOBAL PLANET CHANGE, V101, P119, DOI 10.1016/j.gloplacha.2012.12.014
   Sun AY, 2018, ADV WATER RESOUR, V112, P203, DOI 10.1016/j.advwatres.2017.12.019
   Tagesson T, 2018, REMOTE SENS ENVIRON, V206, P424, DOI 10.1016/j.rse.2017.12.036
   Tasumi M, 2013, AGR WATER MANAGE, V118, P22, DOI 10.1016/j.agwat.2012.10.019
   Tayfur G, 2014, J HYDROL, V510, P363, DOI 10.1016/j.jhydrol.2013.12.045
   Wagle P, 2014, REMOTE SENS ENVIRON, V152, P1, DOI 10.1016/j.rse.2014.05.010
   Wang H, 2020, REMOTE SENS LETT, V11, P455, DOI 10.1080/2150704X.2020.1730469
   Wang S, 2013, CATENA, V101, P122, DOI 10.1016/j.catena.2012.10.006
   Wang SS, 2016, INT J APPL EARTH OBS, V48, P110, DOI 10.1016/j.jag.2015.10.010
   Wang XH, 2018, ECOL INDIC, V95, P320, DOI 10.1016/j.ecolind.2018.07.058
   Wang YK, 2021, J HYDROL, V593, P0, DOI 10.1016/j.jhydrol.2020.125865
   Wang YQ, 2018, GEODERMA, V322, P1, DOI 10.1016/j.geoderma.2018.02.007
   Wang ZX, 2019, ECON LETT, V177, P69, DOI 10.1016/j.econlet.2019.01.021
   Wu C.L., 2020, ISPRS INT ARCH PHOTO, V42, P895, DOI 10.5194/isprs-archives-XLII-3-W10-895-2020
   Wu ZH, 2019, ENVIRON EARTH SCI, V78, P0, DOI 10.1007/s12665-019-8111-9
   Xin QC, 2020, INT J APPL EARTH OBS, V93, P0, DOI 10.1016/j.jag.2020.102189
   Xin ZB, 2011, REG ENVIRON CHANGE, V11, P149, DOI 10.1007/s10113-010-0127-3
   Xu CY, 2020, INT J APPL EARTH OBS, V91, P0, DOI 10.1016/j.jag.2020.102156
   Xu L, 2015, REMOTE SENS-BASEL, V7, P14646, DOI 10.3390/rs71114646
   Xu Q, 2003, ADV ATMOS SCI, V20, P849, DOI 10.1007/BF02915509
   Yang RW, 2017, J MT SCI-ENGL, V14, P2284, DOI 10.1007/s11629-016-4262-2
   Yang XY, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7040145
   Yu BW, 2018, CATENA, V165, P125, DOI 10.1016/j.catena.2018.01.020
   Yuan LA, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13040589
   Yuan LN, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12183040
   Zaussinger F, 2019, HYDROL EARTH SYST SC, V23, P897, DOI 10.5194/hess-23-897-2019
   Zhang BQ, 2019, AGR FOREST METEOROL, V264, P247, DOI 10.1016/j.agrformet.2018.10.010
   Zhang DJ, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16081308
   Zhang X, 2016, CAN J REMOTE SENS, V42, P136, DOI 10.1080/07038992.2016.1175928
   Zhao CL, 2017, CATENA, V158, P55, DOI 10.1016/j.catena.2017.06.006
   Zhao JL, 2016, BIOGEOSCIENCES, V13, P4735, DOI 10.5194/bg-13-4735-2016
   Zhao L, 2014, REMOTE SENS ENVIRON, V152, P345, DOI 10.1016/j.rse.2014.07.005
NR 123
TC 5
Z9 5
U1 10
U2 34
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD APR 15
PY 2021
VL 10
IS 4
BP 
EP 
DI 10.3390/ijgi10040233
PG 29
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RR4JD
UT WOS:000643065700001
DA 2023-04-26
ER

PT J
AU Park, HG
   Yun, JP
   Kim, MY
   Jeong, SH
AF Park, Hae Gwang
   Yun, Jong Pil
   Kim, Min Young
   Jeong, Seung Hyun
TI Multichannel Object Detection for Detecting Suspected Trees With Pine Wilt Disease Using Multispectral Drone Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Vegetation; Drones; Vegetation mapping; Image edge detection; Cameras; Indexes; Training; Convolutional neural network (CNN); deep learning; drone; multispectral; pine wilt disease (PWD); remote sensing
ID nematode
AB In this article, a multichannel convolutional neural network (CNN) based object detection was used to detect suspected trees of pine wilt disease after acquiring aerial photographs through a rotorcraft drone equipped with a multispectral camera. The acquired multispectral aerial photographs consist of RGB, green, red, NIR, and red edge spectral bands per shooting point. The aerial photographs for each band performed image calibration to correct radiation distortion, image alignment to correct the distance error of the lenses of a multispectral camera, and image enhancement to edge enhancement to highlight the features of objects in the image. After that, a large amount of data obtained through data augmentation were put into multichannel CNN-based object detection for training and test. As a result of verifying the detection performance of the trained model, excellent detection results were obtained with mAP 86.63% and average intersection over union 71.47%.
C1 [Park, Hae Gwang; Yun, Jong Pil; Jeong, Seung Hyun] Korea Inst Ind Technol, Cheonan Si 31056, South Korea.
   [Kim, Min Young] Kyungpook Natl Univ, Sch Elect Engn, Deagu 41566, South Korea.
C3 Korea Institute of Industrial Technology (KITECH); Kyungpook National University
RP Jeong, SH (corresponding author), Korea Inst Ind Technol, Cheonan Si 31056, South Korea.; Kim, MY (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, Deagu 41566, South Korea.
EM dd4680@kitech.re.kr; rebirth@kitech.re.kr; shjeong@kitech.re.kr; minykim@knu.ac.kr
FU National Research Foundation of Korea [NBF-2018R1D1A1B07043406]; Korea Institute of Industrial Technology (KITECH) [JA-21-0002]
CR Al Mansoori S, 2018, PROC SPIE, V10792, P0, DOI 10.1117/12.2325732
   BERGDAHL DR, 1988, J NEMATOL, V20, P260
   Carlson TN, 1997, REMOTE SENS ENVIRON, V62, P241, DOI 10.1016/S0034-4257(97)00104-1
   Deng XL, 2020, AGRIENGINEERING, V2, P294, DOI 10.3390/agriengineering2020019
   Everaerts J., 2008, INT ARCH PHOTOGRAMM, V37, P1187
   Feduck C, 2018, FORESTS, V9, P0, DOI 10.3390/f9070432
   Franke J, 2007, PRECIS AGRIC, V8, P161, DOI 10.1007/s11119-007-9036-y
   Futai K, 2013, ANNU REV PHYTOPATHOL, V51, P61, DOI 10.1146/annurev-phyto-081211-172910
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Handique BK, 2017, P NATL A SCI INDIA A, V87, P713, DOI 10.1007/s40010-017-0443-9
   Hoshikawa T., 2020, JAN J REMOTE SENSING, V40, P13
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Karami E., 2015, NEWF EL COMP ENG C, V0, P0
   Kim Dong-Soo, 2003, KOREAN JOURNAL OF APPLIED ENTOMOLOGY, V42, P307
   Kim Joonbum, 2010, JOURNAL OF THE KOREAN ASSOCIATION OF GEOGRAPHIC INFORMATION STUDIES 한국지리정보학회지, V13, P28
   Kim SR, 2018, FORESTS, V9, P0, DOI 10.3390/f9030115
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Laliberte AS, 2011, REMOTE SENS-BASEL, V3, P2529, DOI 10.3390/rs3112529
   Lee JB, 2014, KOREAN J REMOTE SENS, V30, P665, DOI 10.7780/kjrs.2014.30.5.11
   MAMIYA Y, 1988, J NEMATOL, V20, P219
   Mikolajczyk A., 2018, 2018 INT INT PHD WOR, V0, PP117, DOI 10.1109/IIPHDW.2018.8388338
   Morales G, 2018, FORESTS, V9, P0, DOI 10.3390/f9120736
   Mota M.M., 2008, PINE WILT DIS WORLDW, V0, P0
   Park JeongMook, 2016, JOURNAL OF FOREST AND ENVIRONMENTAL SCIENCE, V32, P384
   Phillips M. C., 2020, P SYST INF ENG DES S, V0, P1
   Puliti S, 2018, FORESTS, V9, P0, DOI 10.3390/f9030102
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   RUTHERFORD TA, 1990, FOREST SCI, V36, P145
   Safonova A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060643
   Shin S. C., 2008, PINE WILT DIS, V0, PP26, DOI 10.1007/978-4-431-75655-2_5
   Simonyan K., 2015, ICLR, V0, P0
   Sin S.-C., 2005, P KOR SOC APPL ENT C, V0, P33
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Syifa M, 2020, ENGINEERING-PRC, V6, P919, DOI 10.1016/j.eng.2020.07.001
   Tai H. T., 1991, U.S. PATENT, V0, Patent No. [5 054 100, 5054100]
   Tang LN, 2015, J FORESTRY RES, V26, P791, DOI 10.1007/s11676-015-0088-y
   Trichon V, 2001, PLANT ECOL, V153, P301, DOI 10.1023/A:1017524126999
   Yahyanejad S., 2011, 2011 IEEE INTERNATIONAL SYMPOSIUM ON ROBOTIC AND SENSORS ENVIRONMENTS (ROSE 2011), V0, PP231, DOI 10.1109/ROSE.2011.6058528
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   김동수, 2009, KOREAN JOURNAL OF APPLIED ENTOMOLOGY 한국응용곤충학회지, V48, P527
NR 40
TC 13
Z9 13
U1 15
U2 38
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 8350
EP 8358
DI 10.1109/JSTARS.2021.3102218
PG 9
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UK8QR
UT WOS:000692230900001
DA 2023-04-26
ER

PT J
AU Kim, E
   Cho, S
AF Kim, Eunji
   Cho, Sungzoon
TI Exposing Fake Faces Through Deep Neural Networks Combining Content and Trace Feature Extractors
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Face recognition; Videos; Faces; Information integrity; Image forensics; Media; Convolutional neural networks; DeepFake; Face2Face; fake face detection; fake face image forensics; multi-channel constrained convolution; transfer learning
ID contrast enhancement; forensic detection; jpeg compression; image
AB With the breakthrough of computer vision and deep learning, there has been a surge of realistic-looking fake face media manipulated by AI such as DeepFake or Face2Face that manipulate facial identities or expressions. The fake faces were mostly created for fun, but abuse has caused social unrest. For example, some celebrities have become victims of fake pornography made by DeepFake. There are also growing concerns about fake political speech videos created by Face2Face. To maintain individual privacy as well as social, political, and international security, it is imperative to develop models that detect fake faces in media. Previous research can be divided into general-purpose image forensics and face image forensics. While the former has been studied for several decades and focuses on extracting hand-crafted features of traces left in the image after manipulation, the latter is based on convolutional neural networks mainly inspired by object detection models specialized to extract images' content features. This paper proposes a hybrid face forensics framework based on a convolutional neural network combining the two forensics approaches to enhance the manipulation detection performance. To validate the proposed framework, we used a public Face2Face dataset and a custom DeepFake dataset collected on our own. Experimental results using the two datasets showed that the proposed model is more accurate and robust at various video compression rates compared to the previous methods. Throughout class activation map visualization, the proposed framework provided information on which face parts are considered important and revealed the tempering traces invisible to naked eyes.
C1 [Kim, Eunji] Chung Ang Univ, Sch Business Adm, Seoul 06974, South Korea.
   [Cho, Sungzoon] Seoul Natl Univ, Dept Ind Engn, Seoul 08826, South Korea.
   [Cho, Sungzoon] Seoul Natl Univ, Inst Ind Syst Innovat, Seoul 08826, South Korea.
C3 Chung Ang University; Seoul National University (SNU); Seoul National University (SNU)
RP Cho, S (corresponding author), Seoul Natl Univ, Dept Ind Engn, Seoul 08826, South Korea.; Cho, S (corresponding author), Seoul Natl Univ, Inst Ind Syst Innovat, Seoul 08826, South Korea.
EM zoon@snu.ac.kr
FU National Research Foundation of Korea (NRF) - Korean Government (MSIT) [2021R1G1A1093263]
CR Afchar D, 2018, IEEE INT WORKS INFOR, V0, P0
   Alexander O., 2009, 2009 C VIS MED PROD, V0, PP176, DOI 10.1109/CVMP.2009.29
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bethge M., 2016, PROC CVPR IEEE, V0, PP2414, DOI 10.1109/CVPR.2016.265
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bitouk D, 2008, ACM T GRAPHIC, V27, P0, DOI 10.1145/1360612.1360638
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Bohme R., 2013, DIGITAL IMAGE FORENS, V0, P327
   Bregler C., 1997, P353, V0, P0
   Bulat A., 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.116
   Busch C., 2017, IEEE COMPUT SOC CONF, V0, PP1822, DOI 10.1109/CVPRW.2017.228
   Cao G., 2010, IEEE INT CON MULTI, V0, P89
   Chen C., 2011, P INT WORK DIG WAT, V0, P361
   Chollet F., 2017, PROC CVPR IEEE, V0, PP1251, DOI 10.1109/CVPR.2017.195
   Cozzolino D., 2017, P 5 ACM WORKSH INF H, V0, P159
   Dale K, 2011, ACM T GRAPHIC, V30, P0, DOI 10.1145/2024156.2024164
   Dalgaard N., 2010, IEEE IMAGE PROC, V0, P1753
   Dambre J., 2017, IEEE I CONF COMP VIS, V0, PP3697, DOI 10.1109/ICCV.2017.397
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Fridrich, 2015, PROC SPIE, V9409, P0, DOI 10.1117/12.2078399
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Garrido P., 2014, PROC CVPR IEEE, V0, PP4217, DOI 10.1109/CVPR.2014.537
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Jones M., 2001, PROC CVPR IEEE, V1, P0
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kemelmacher-Shlizerman I, 2016, ACM T GRAPHIC, V35, P0, DOI 10.1145/2897824.2925871
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG), V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Kirchner M., 2008, MMSEC08 P MULT SEC, V0, P11
   Kirchner M, 2010, PROC SPIE, V7541, P0, DOI 10.1117/12.839100
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Liu W., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/cvpr.2015.7298594
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Neelamani R, 2006, IEEE T IMAGE PROCESS, V15, P1365, DOI 10.1109/TIP.2005.864171
   Oliva A., 2016, PROC CVPR IEEE, V0, PP2921, DOI 10.1109/CVPR.2016.319
   Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qiu X., 2014, P 2 ACM WORKSH INF H, V0, P165
   Qu Z., 2008, INT CONF ACOUST SPEE, V0, P1661
   Rossler A., 2019, IEEE I CONF COMP VIS, V0, PP1, DOI 10.1109/ICCV.2019.00009
   Rossler Andreas, 2018, FACEFORENSICS LARGE, V1, P0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shlens J., 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Simonyan K, 2015, ARXIV, V0, P0
   Stamm M., 2008, IEEE IMAGE PROC, V0, P3112
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Sun JY, 2018, SIGNAL PROCESS-IMAGE, V63, P149, DOI 10.1016/j.image.2018.02.001
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3072959.3073640
   Thies J, 2015, ACM T GRAPHIC, V34, P0, DOI 10.1145/2816795.2818056
   Wolf L., 2010, PROC CVPR IEEE PROC CVPR IEEE, V0, PP817, DOI 10.1109/CVPR.2010.5540133
   Yao H., 2009, P94, V0, P0
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou P., 2017, IEEE COMPUT SOC CONF, V0, PP1831, DOI 10.1109/CVPRW.2017.229
NR 60
TC 2
Z9 2
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2021
VL 9
IS 
BP 123493
EP 123503
DI 10.1109/ACCESS.2021.3110859
PG 11
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA UQ4ZU
UT WOS:000696074000001
DA 2023-04-26
ER

PT J
AU Zhao, HW
   Wu, JX
   Zhang, DY
   Liu, PP
AF Zhao, Hongwei
   Wu, Jiaxin
   Zhang, Danyang
   Liu, Pingping
TI Toward Improving Image Retrieval via Global Saliency Weighted Feature
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE image retrieval; saliency weighting; convolutional feature aggregation
AB For full description of images' semantic information, image retrieval tasks are increasingly using deep convolution features trained by neural networks. However, to form a compact feature representation, the obtained convolutional features must be further aggregated in image retrieval. The quality of aggregation affects retrieval performance. In order to obtain better image descriptors for image retrieval, we propose two modules in our method. The first module is named generalized regional maximum activation of convolutions (GR-MAC), which pays more attention to global information at multiple scales. The second module is called saliency joint weighting, which uses nonparametric saliency weighting and channel weighting to focus feature maps more on the salient region without discarding overall information. Finally, we fuse the two modules to obtain more representative image feature descriptors that not only consider the global information of the feature map but also highlight the salient region. We conducted experiments on multiple widely used retrieval data sets such as roxford5k to verify the effectiveness of our method. The experimental results prove that our method is more accurate than the state-of-the-art methods.
C1 [Zhao, Hongwei; Wu, Jiaxin; Zhang, Danyang; Liu, Pingping] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Liu, Pingping] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Liu, Pingping] Jilin Univ, Sch Mech Sci & Engn, Changchun 130025, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Liu, PP (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Liu, PP (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Liu, PP (corresponding author), Jilin Univ, Sch Mech Sci & Engn, Changchun 130025, Peoples R China.
EM zhaohw@jlu.edu.cn; wujx19@mails.jlu.edu.cn; zhangdy19@mails.jlu.edu.cn; liupp@jlu.edu.cn
FU Nature Science Foundation of China [61841602]; Fundamental Research Funds of Central Universities, JLU; China Postdoctoral Science Foundation [2015M571363, 2015M570272]; Provincial Science and Technology Innovation Special Fund Project of Jilin Province [20190302026GX]; Natural Science Foundation of Jilin Province [20200201037JC]; Jilin Province Development and Reform Commission Industrial Technology Research and Development Project [2019C054-4]; State Key Laboratory of Applied Optics Open Fund Project [20173660]; Jilin Provincial Natural Science Foundation [20200201283JC]; Foundation of Jilin Educational Committee [JJKH20200994KJ]; Higher Education Research Project of Jilin Association for Higher Education [JGJX2018D10]; Fundamental Research Funds for the Central Universities for JLU
CR Alzubi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   [Anonymous], 2016, INT C LEARNING REPRE, V0, P0
   [Anonymous], 2006, P P 14 ACM INT C MUL, V0, P0, DOI DOI 10.1145/1180639.1180824
   Babenko A, 2015, IEEE I CONF COMP VIS, V0, PP1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chum O, 2007, IEEE I CONF COMP VIS, V0, PP496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, V0, PP889, DOI 10.1109/CVPR.2011.5995601
   Cimpoi M, 2015, PROC CVPR IEEE, V0, PP3828, DOI 10.1109/CVPR.2015.7299007
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Ghodrati A, 2017, INT J COMPUT VISION, V124, P115, DOI 10.1007/s11263-017-1006-x
   Gordo A, 2017, PROC CVPR IEEE, V0, PP5272, DOI 10.1109/CVPR.2017.560
   Hao J., 2018, P 2017 IEEE INT C MU, V0, P513
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jegou H, 2014, PROC CVPR IEEE, V0, PP3310, DOI 10.1109/CVPR.2014.417
   Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Joe Yue-Hei Ng, 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE: WORKSHOPS. PROCEEDINGS: LNCS 9913, V0, PP685, DOI 10.1007/978-3-319-46604-0_48
   Liu PP, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21111037
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K., 2007, P IEEE 11 INT C COMP, V0, PP1, DOI 10.1109/ICCV.2007.4408871
   Mohedano E, 2016, ICMR16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP327, DOI 10.1145/2911996.2912061
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva A, 2002, LECT NOTES COMPUT SC, V2525, P263
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Perronnin F, 2007, PROC CVPR IEEE, V0, P2272
   Philbin J, 2008, PROC CVPR IEEE, V0, P2285
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Radenovic F, 2018, PROC CVPR IEEE, V0, PP5706, DOI 10.1109/CVPR.2018.00598
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Razavian AS, 2016, ITE T MEDIA TECHNOL, V4, P251, DOI 10.3169/mta.4.251
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tolias G, 2014, LECT NOTES COMPUT SC, V8694, P382, DOI 10.1007/978-3-319-10599-4_25
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Xu J, 2019, IEEE T IMAGE PROCESS, V28, P601, DOI 10.1109/TIP.2018.2867104
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 40
TC 1
Z9 1
U1 6
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD APR 15
PY 2021
VL 10
IS 4
BP 
EP 
DI 10.3390/ijgi10040249
PG 23
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RR4UK
UT WOS:000643095000001
DA 2023-04-26
ER

PT J
AU Karatsiolis, S
   Kamilaris, A
   Cole, I
AF Karatsiolis, Savvas
   Kamilaris, Andreas
   Cole, Ian
TI IMG2nDSM: Height Estimation from Single Airborne RGB Images with Deep Learning
SO REMOTE SENSING
LA English
DT Article
DE building height estimation; deep learning; digital surface model; aerial imagery; LiDAR; convolutional neural networks; remote sensing; digital elevation models
ID aerial images; lidar data; surface
AB Estimating the height of buildings and vegetation in single aerial images is a challenging problem. A task-focused Deep Learning (DL) model that combines architectural features from successful DL models (U-NET and Residual Networks) and learns the mapping from a single aerial imagery to a normalized Digital Surface Model (nDSM) was proposed. The model was trained on aerial images whose corresponding DSM and Digital Terrain Models (DTM) were available and was then used to infer the nDSM of images with no elevation information. The model was evaluated with a dataset covering a large area of Manchester, UK, as well as the 2018 IEEE GRSS Data Fusion Contest LiDAR dataset. The results suggest that the proposed DL architecture is suitable for the task and surpasses other state-of-the-art DL approaches by a large margin.
C1 [Karatsiolis, Savvas; Kamilaris, Andreas; Cole, Ian] CYENS Ctr Excellence, CY-1016 Nicosia, Cyprus.
   [Kamilaris, Andreas] Univ Twente, Dept Comp Sci, NL-7522 NB Enschede, Netherlands.
   [Cole, Ian] Univ Cyprus, Dept Comp Sci, CY-2109 Aglantzia, Cyprus.
C3 University of Twente; University of Cyprus
RP Karatsiolis, S (corresponding author), CYENS Ctr Excellence, CY-1016 Nicosia, Cyprus.
EM s.karatsiolis@cyens.org.cy; a.kamilaris@cyens.org.cy; i.cole@cyens.org.cy
FU European Union [739578]; Government of the Republic of Cyprus through the Deputy Ministry of Research, Innovation and Digital Policy
CR Amirkolaee HA, 2019, ISPRS J PHOTOGRAMM, V149, P50, DOI 10.1016/j.isprsjprs.2019.01.013
   [Anonymous], 2005, C9512005 IEEE, V0, P0
   Bechtel B, 2015, P JOINT URB REM SENS, V0, P1
   Bhat S.F., 2020, ARXIV201114141, V0, P0
   Bosch M, 2019, IEEE WINT CONF APPL, V0, PP1524, DOI 10.1109/WACV.2019.00167
   Carvalho M, 2020, IEEE GEOSCI REMOTE S, V17, P1391, DOI 10.1109/LGRS.2019.2947783
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Christie G.A., 2020, P IEEECVF C COMPUTER, V0, P14500
   Cicek Ozgun, 2016, MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2016. 19TH INTERNATIONAL CONFERENCE. PROCEEDINGS: LNCS 9901, V0, PP424, DOI 10.1007/978-3-319-46723-8_49
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Eigen D, 2014, ADV NEUR IN, V27, P0
   Geiger A, 2012, PROC CVPR IEEE, V0, PP3354, DOI 10.1109/CVPR.2012.6248074
   Ghamisi P, 2018, IEEE GEOSCI REMOTE S, V15, P794, DOI 10.1109/LGRS.2018.2806945
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guler RA, 2018, PROC CVPR IEEE, V0, PP7297, DOI 10.1109/CVPR.2018.00762
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Iglovikov V., 2018, TERNAUSNET U NET VGG, V0, P0
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Jones KL, 2008, REMOTE SENS ENVIRON, V112, P4148, DOI 10.1016/j.rse.2008.01.024
   Kaiming He, 2020, IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Kaku K, 2019, INT J DISAST RISK RE, V33, P417, DOI 10.1016/j.ijdrr.2018.09.015
   Kingma D. P, 2015, PROC INT C LEARN REP, V0, P0
   Koutilya P. N. V. R., 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP13971, DOI 10.1109/CVPR42600.2020.01399
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Laina I., 2016, INT CONF 3D VISION, V0, P0, DOI DOI 10.1109/3DV.2016.32
   Lesiv M, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2018.56
   Liu CJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172719
   Liu XY, 2008, PROG PHYS GEOG, V32, P31, DOI 10.1177/0309133308089496
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060506
   Ma L, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8090761
   Mahjourian R, 2018, PROC CVPR IEEE, V0, PP5667, DOI 10.1109/CVPR.2018.00594
   Michalowska M, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030353
   Mou Lichao., 2018, ARXIV180210249, V0, P0
   Mulac BL, 2011, GEOCARTO INT, V26, P71, DOI 10.1080/10106049.2010.537786
   Muro J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100795
   Palmer D, 2018, ENERGIES, V11, P0, DOI 10.3390/en11123506
   Panagiotou E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122002
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schonberger JL, 2016, PROC CVPR IEEE, V0, PP4104, DOI 10.1109/CVPR.2016.445
   Shi WZ, 2016, PROC CVPR IEEE, V0, PP1874, DOI 10.1109/CVPR.2016.207
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sofia G, 2016, IEEE J-STARS, V9, P1567, DOI 10.1109/JSTARS.2016.2516900
   Srivastava S, 2017, INT GEOSCI REMOTE SE, V0, P5173
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   van Dijk T, 2019, IEEE I CONF COMP VIS, V0, PP2183, DOI 10.1109/ICCV.2019.00227
   Voumard J, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111732
   Wellmann T, 2020, LANDSCAPE URBAN PLAN, V204, P0, DOI 10.1016/j.landurbplan.2020.103921
   Wing MG, 2013, J FOREST, V111, P341, DOI 10.5849/jof.12-117
   Wonka P, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Xue F, 2020, ISPRS J PHOTOGRAMM, V167, P418, DOI 10.1016/j.isprsjprs.2020.07.020
   Yu DW, 2021, ISPRS J PHOTOGRAMM, V171, P155, DOI 10.1016/j.isprsjprs.2020.11.011
   Zhu Z, 2019, REMOTE SENS ENVIRON, V228, P164, DOI 10.1016/j.rse.2019.04.020
NR 59
TC 6
Z9 6
U1 7
U2 20
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 15
PY 2021
VL 13
IS 12
BP 
EP 
DI 10.3390/rs13122417
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SZ7GD
UT WOS:000666728000001
DA 2023-04-26
ER

PT J
AU Singha, S
   Das, P
   Singha, SS
AF Singha, Sudhakar
   Das, Pragnya
   Singha, Soumya S.
TI A fuzzy geospatial approach for delineation of groundwater potential zones in Raipur district, India
SO GROUNDWATER FOR SUSTAINABLE DEVELOPMENT
LA English
DT Article
DE Groundwater controlling factors; Fuzzy membership; GIS; Groundwater potentiality; Sensitivity analysis
ID geographic information-system; evidential belief function; artificial neural-network; frequency ratio; andhra-pradesh; gis; models; chhattisgarh; quality; basin
AB Delineation of groundwater potential zones was carried out using fuzzy geospatial approach for the sustainable groundwater resource management in Raipur district, Chhattisgarh, India. In the present study, eleven groundwater controlling factors were selected and their respective fuzzy membership (FM) layers were overlaid with fuzzy GAMMA operator to develop the groundwater potential zone (GPZ) map. A total of 62.62% and 37.38% of the total area fell under low to moderate and high GPZ category, respectively. Sensitivity analysis highlighted that lineament density (SD = 0.0057), proximity to surface water body (SD = 0.0046), and aquifer (SD = 0.0036) were the significant contributors towards the groundwater potentiality of the region. Ground truth verification of the proposed model was done with available well yield data of the study area and a linear relation between computed GPZ indices and well yield values was found with a significant positive correlation value of 0.77 (r) that justified the model reliability and authenticity. The proposed model is a robust tool and can be utilized with versatile scale dataset in any parts of the world.
C1 [Singha, Sudhakar; Singha, Soumya S.] Indian Sch Mines, Dept Civil Engn, Indian Inst Technol, Dhanbad 826004, Jharkhand, India.
   [Das, Pragnya] REVA Univ, Sch Civil Engn, Bengaluru, Karnataka, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (Indian School of Mines) Dhanbad; REVA University
RP Singha, SS (corresponding author), Indian Sch Mines, Dept Civil Engn, Indian Inst Technol, Dhanbad 826004, Jharkhand, India.
EM soumya.2014dr1085@eve.iitism.ac.in
FU Indian Institute of Technology (Indian School of Mines), Dhanbad, India
CR Achu AL, 2020, GROUNDWATER SUST DEV, V10, P0, DOI 10.1016/j.gsd.2020.100365
   Anbalagan R., 2015, GEOENVIRONMENTAL DIS, V2, P6, DOI 10.1186/s40677-014-0009-y
   Andualem TG, 2019, J HYDROL-REG STUD, V24, P0, DOI 10.1016/j.ejrh.2019.100610
   Arabameri A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11243015
   Arulbalaji P, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-38567-x
   Ayibotele N.B, 1992, P INT C WAT ENV DEV, V0, P1
   Census of India Chhattisgarh, 2011, DISTR CENS HDB 12, V23, P16
   CGWB, 2013, CGWB TECHN REP SER D, V0, P10
   CGWB, 2011, CENTR GROUND WAT BOA, V0, P114
   Chaudhry AK, 2021, GEOCARTO INT, V36, P2323, DOI 10.1080/10106049.2019.1695959
   Dar IA, 2010, J HYDROL, V394, P285, DOI 10.1016/j.jhydrol.2010.08.022
   Das S, 2019, GROUNDWATER SUST DEV, V8, P617, DOI 10.1016/j.gsd.2019.03.003
   DSR, 2019, DISTR SURV REP PER N, V0, P1
   Ganapuram S, 2009, ADV ENG SOFTW, V40, P506, DOI 10.1016/j.advengsoft.2008.10.001
   Indhulekha K, 2019, J WATER SUPPLY RES T, V68, P595, DOI 10.2166/aqua.2019.159
   Kayastha P, 2013, J GEOL SOC INDIA, V82, P249, DOI 10.1007/s12594-013-0147-y
   Khosravi K, 2018, HYDROL EARTH SYST SC, V22, P4771, DOI 10.5194/hess-22-4771-2018
   Kim JC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192285
   Kim JC, 2018, J HYDROINFORM, V20, P1436, DOI 10.2166/hydro.2018.120
   Lee S, 2018, GEOCARTO INT, V33, P847, DOI 10.1080/10106049.2017.1303091
   Lee S, 2012, HYDROGEOL J, V20, P1511, DOI 10.1007/s10040-012-0894-7
   Mallick J, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11122656
   Martin SL, 2017, SCI TOTAL ENVIRON, V579, P1794, DOI 10.1016/j.scitotenv.2016.11.158
   Murasingh Surajit, 2018, GROUNDWATER FOR SUSTAINABLE DEVELOPMENT, V7, P387, DOI 10.1016/j.gsd.2017.12.001
   Murmu P, 2019, GROUNDWATER SUST DEV, V9, P0, DOI 10.1016/j.gsd.2019.100239
   Murthy KSR, 2000, INT J REMOTE SENS, V21, P1867, DOI 10.1080/014311600209788
   Naghibi SA, 2017, J HYDROL, V548, P471, DOI 10.1016/j.jhydrol.2017.03.020
   Naghibi SA, 2015, EARTH SCI INFORM, V8, P171, DOI 10.1007/s12145-014-0145-7
   Nampak H, 2014, J HYDROL, V513, P283, DOI 10.1016/j.jhydrol.2014.02.053
   Nejad SG, 2017, GEOCARTO INT, V32, P167, DOI 10.1080/10106049.2015.1132481
   Pasupuleti S, 2019, J ENVIRON BIOL, V40, P61, DOI 10.22438/jeb/40/1/MRN-935
   Patra S, 2018, J CLEAN PROD, V172, P2485, DOI 10.1016/j.jclepro.2017.11.161
   Pourghasemi HR, 2012, CATENA, V97, P71, DOI 10.1016/j.catena.2012.05.005
   Pourtaghi ZS, 2014, HYDROGEOL J, V22, P643, DOI 10.1007/s10040-013-1089-6
   Rahmati O, 2018, J HYDROL, V565, P248, DOI 10.1016/j.jhydrol.2018.08.027
   Rajasekhar M., 2019, HYDRORESEARCH, V2, P97, DOI 10.1016/j.hydres.2019.11.006
   Ramesh V, 2022, GEOCARTO INT, V37, P581, DOI 10.1080/10106049.2020.1730448
   Razandi Y, 2015, EARTH SCI INFORM, V8, P867, DOI 10.1007/s12145-015-0220-8
   Razavi-Termeh SV, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11081596
   Selvam S, 2015, ENVIRON EARTH SCI, V73, P3785, DOI 10.1007/s12665-014-3664-0
   Sener E, 2005, HYDROGEOL J, V13, P826, DOI 10.1007/s10040-004-0378-5
   Shah T, 2003, NAT RESOUR FORUM, V27, P130, DOI 10.1111/1477-8947.00048
   Singha SS, 2021, GEOCARTO INT, V36, P1489, DOI 10.1080/10106049.2019.1648566
   Singha S, 2020, J GEOL SOC INDIA, V95, P609, DOI 10.1007/s12594-020-1487-z
   Singha S, 2019, ENVIRON EARTH SCI, V78, P0, DOI 10.1007/s12665-019-8724-z
   Tafreshi AM, 2018, WATER ENVIRON J, V32, P607, DOI 10.1111/wej.12358
   Trabelsi F., 2019, ADV SUSTAINABLE ENV, V0, PP341, DOI 10.1007/978-3-030-01572-5
   Venkatramanan S, 2017, ENVIRON SCI POLLUT R, V24, P23679, DOI 10.1007/s11356-017-9990-5
   Wang D, 2016, MATH PROBL ENG, V2016, P1, DOI 10.1155/2016/2064575,2064575
   Webster R., 2007, GEOSTATISTICS ENV SC, V0, P196
   Yeh HF, 2016, SUSTAIN ENVIRON RES, V26, P33, DOI 10.1016/j.serj.2015.09.005
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 52
TC 6
Z9 6
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-801X
EI 
J9 GROUNDWATER SUST DEV
JI Groundwater Sustain. Dev.
PD FEB 15
PY 2021
VL 12
IS 
BP 
EP 
DI 10.1016/j.gsd.2020.100529
PG 12
WC Engineering, Environmental; Environmental Sciences; Water Resources
SC Engineering; Environmental Sciences & Ecology; Water Resources
GA UO7BJ
UT WOS:000694847500043
DA 2023-04-26
ER

PT J
AU Xie, W
   Li, XS
   Jian, WB
   Yang, Y
   Liu, HW
   Robledo, LF
   Nie, W
AF Xie, Wei
   Li, Xiaoshuang
   Jian, Wenbin
   Yang, Yang
   Liu, Hongwei
   Robledo, Luis F.
   Nie, Wen
TI A Novel Hybrid Method for Landslide Susceptibility Mapping-Based GeoDetector and Machine Learning Cluster: A Case of Xiaojin County, China
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE landslide susceptibility mapping; GeoDetector; machine learning; GIS; support vector machines
AB Landslide susceptibility mapping (LSM) could be an effective way to prevent landslide hazards and mitigate losses. The choice of conditional factors is crucial to the results of LSM, and the selection of models also plays an important role. In this study, a hybrid method including GeoDetector and machine learning cluster was developed to provide a new perspective on how to address these two issues. We defined redundant factors by quantitatively analyzing the single impact and interactive impact of the factors, which was analyzed by GeoDetector, the effect of this step was examined using mean absolute error (MAE). The machine learning cluster contains four models (artificial neural network (ANN), Bayesian network (BN), logistic regression (LR), and support vector machines (SVM)) and automatically selects the best one for generating LSM. The receiver operating characteristic (ROC) curve, prediction accuracy, and the seed cell area index (SCAI) methods were used to evaluate these methods. The results show that the SVM model had the best performance in the machine learning cluster with the area under the ROC curve of 0.928 and with an accuracy of 83.86%. Therefore, SVM was chosen as the assessment model to map the landslide susceptibility of the study area. The landslide susceptibility map demonstrated fit with landslide inventory, indicated the hybrid method is effective in screening landslide influences and assessing landslide susceptibility.
C1 [Xie, Wei; Li, Xiaoshuang; Nie, Wen] Jiangxi Univ Sci & Technol, Sch Resources & Environm Engn, Ganzhou 341000, Peoples R China.
   [Xie, Wei; Yang, Yang] Southwest Petr Univ, Sch Earth Sci & Technol, Chengdu 610500, Peoples R China.
   [Li, Xiaoshuang] Guangxi Univ Sci & Technol, Coll Civil Engn & Architecture, Liuzhou 545006, Peoples R China.
   [Jian, Wenbin; Liu, Hongwei] Fuzhou Univ, Dept Geotech & Geol Engn, Fuzhou 350108, Peoples R China.
   [Robledo, Luis F.] Univ Andres Bello, Engn Sci Dept, Santiago 7500971, Chile.
   [Nie, Wen] Chinese Acad Sci, Haixi Inst, Quanzhou Inst Equipment Mfg, Quanzhou 362000, Peoples R China.
C3 Jiangxi University of Science & Technology; Southwest Petroleum University; Guangxi University of Science & Technology; Fuzhou University; Universidad Andres Bello; Chinese Academy of Sciences
RP Nie, W (corresponding author), Jiangxi Univ Sci & Technol, Sch Resources & Environm Engn, Ganzhou 341000, Peoples R China.; Nie, W (corresponding author), Chinese Acad Sci, Haixi Inst, Quanzhou Inst Equipment Mfg, Quanzhou 362000, Peoples R China.
EM 201822000072@stu.swpu.edu.cn; 1917212186@xauat.edu.cn; jwb@fzu.edu.cn; 201031010029@swpu.edu.cn; hliuan@connect.ust.hk; luis.robledo@unab.cl; wen.nie@fjirsm.ac.cn
FU National Natural Science Foundation of China [41867033, 41861134011, 51874268]
CR Bai L, 2019, J CLEAN PROD, V232, P692, DOI 10.1016/j.jclepro.2019.05.342
   Begueria S, 2006, GEOMORPHOLOGY, V74, P196, DOI 10.1016/j.geomorph.2005.07.018
   Begueria S, 2006, NAT HAZARDS, V37, P315, DOI 10.1007/s11069-005-5182-6
   Pham BT, 2016, ENVIRON MODELL SOFTW, V84, P240, DOI 10.1016/j.envsoft.2016.07.005
   Brenning A, 2005, NAT HAZARD EARTH SYS, V5, P853, DOI 10.5194/nhess-5-853-2005
   Budimir MEA, 2015, LANDSLIDES, V12, P419, DOI 10.1007/s10346-014-0550-5
   Chen W, 2019, GEOCARTO INT, V34, P1177, DOI 10.1080/10106049.2019.1588393
   Chen W, 2017, CATENA, V151, P147, DOI 10.1016/j.catena.2016.11.032
   Chi Y, 2018, SCI TOTAL ENVIRON, V634, P1445, DOI 10.1016/j.scitotenv.2018.04.085
   Dou J, 2020, LANDSLIDES, V17, P641, DOI 10.1007/s10346-019-01286-5
   Duric U, 2019, ENG GEOL, V256, P23, DOI 10.1016/j.enggeo.2019.05.007
   Fan XM, 2019, REV GEOPHYS, V57, P421, DOI 10.1029/2018RG000626
   Gariano SL, 2016, EARTH-SCI REV, V162, P227, DOI 10.1016/j.earscirev.2016.08.011
   Harmouzi H, 2019, ARAB J GEOSCI, V12, P0, DOI 10.1007/s12517-019-4892-0
   Huang FM, 2020, LANDSLIDES, V17, P217, DOI 10.1007/s10346-019-01274-9
   Hungr O, 2014, LANDSLIDES, V11, P167, DOI 10.1007/s10346-013-0436-y
   Ilia I, 2016, LANDSLIDES, V13, P379, DOI 10.1007/s10346-015-0576-3
   Jebur MN, 2014, REMOTE SENS ENVIRON, V152, P150, DOI 10.1016/j.rse.2014.05.013
   Ju HR, 2016, INT J GEOGR INF SCI, V30, P2188, DOI 10.1080/13658816.2016.1165228
   Kim JC, 2018, GEOCARTO INT, V33, P1000, DOI 10.1080/10106049.2017.1323964
   Lee JH, 2018, GEOMORPHOLOGY, V303, P284, DOI 10.1016/j.geomorph.2017.12.007
   Lee S, 2005, ENVIRON GEOL, V47, P982, DOI 10.1007/s00254-005-1228-z
   Lee S, 2004, ENVIRON MANAGE, V34, P223, DOI 10.1007/s00267-003-0077-3
   Lee S, 2007, LANDSLIDES, V4, P33, DOI 10.1007/s10346-006-0047-y
   Lee S, 2020, GEOCARTO INT, V35, P1665, DOI 10.1080/10106049.2019.1585482
   Lin Q, 2018, LANDSLIDES, V15, P2357, DOI 10.1007/s10346-018-1037-6
   Liu LN, 2019, LANDSLIDES, V16, P715, DOI 10.1007/s10346-018-01122-2
   Moayedi H, 2019, ENG COMPUT-GERMANY, V35, P967, DOI 10.1007/s00366-018-0644-0
   Nicu IC, 2018, GEOMORPHOLOGY, V314, P27, DOI 10.1016/j.geomorph.2018.04.010
   Paranunzio R, 2019, THEOR APPL CLIMATOL, V137, P1765, DOI 10.1007/s00704-018-2673-4
   Paranunzio R, 2015, NAT HAZARDS, V76, P1039, DOI 10.1007/s11069-014-1532-6
   Pawluszek K, 2017, NAT HAZARDS, V86, P919, DOI 10.1007/s11069-016-2725-y
   Pham BT, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11226323
   Piciullo L, 2018, EARTH-SCI REV, V179, P228, DOI 10.1016/j.earscirev.2018.02.013
   Poudyal CP, 2010, ENVIRON EARTH SCI, V61, P1049, DOI 10.1007/s12665-009-0426-5
   Pourghasemi HR, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3531-5
   Pourghasemi HR, 2018, CATENA, V162, P177, DOI 10.1016/j.catena.2017.11.022
   Qi XX, 2019, HABITAT INT, V94, P0, DOI 10.1016/j.habitatint.2019.102064
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Rossi M., 2013, GEOSCI MODEL DEV DIS, V6, P1367, DOI 10.5194/gmdd-6-1367-2013
   Shahri AA, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104225
   Sharma S, 2019, B ENG GEOL ENVIRON, V78, P2431, DOI 10.1007/s10064-018-1259-9
   Song YQ, 2012, COMPUT GEOSCI-UK, V42, P189, DOI 10.1016/j.cageo.2011.09.011
   Taalab K, 2018, BIG EARTH DATA, V2, P159, DOI 10.1080/20964471.2018.1472392
   Tehrany MS, 2019, THEOR APPL CLIMATOL, V137, P637, DOI 10.1007/s00704-018-2628-9
   Guerra AJT, 2017, PEDOSPHERE, V27, P27, DOI 10.1016/S1002-0160(17)60294-7
   Tsangaratos P, 2016, CATENA, V145, P164, DOI 10.1016/j.catena.2016.06.004
   Van Asch TWJ, 1999, GEOMORPHOLOGY, V30, P25, DOI 10.1016/S0169-555X(99)00042-2
   van Westen CJ, 2008, ENG GEOL, V102, P112, DOI 10.1016/j.enggeo.2008.03.010
   Wang JF, 2016, ECOL INDIC, V67, P250, DOI 10.1016/j.ecolind.2016.02.052
   Wang JF, 2012, ENVIRON MODELL SOFTW, V33, P114, DOI 10.1016/j.envsoft.2012.01.015
   Wang JF, 2010, INT J GEOGR INF SCI, V24, P107, DOI 10.1080/13658810802443457
   Wang ZT, 2020, SYMMETRY-BASEL, V12, P0, DOI 10.3390/sym12121954
   Waring J, 2020, ARTIF INTELL MED, V104, P0, DOI 10.1016/j.artmed.2020.101822
   Weiss A., 2001, P POSTER PRESENTATIO, V64, P227
   Xavier JC, 2020, THEOR COMPUT SCI, V805, P1, DOI 10.1016/j.tcs.2019.12.002
   Xiao LM, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18124436
   Xu Y, 2016, J GEOGR SCI, V26, P1349, DOI 10.1007/s11442-016-1331-y
   Yang JT, 2019, GEOMORPHOLOGY, V324, P62, DOI 10.1016/j.geomorph.2018.09.019
   Yang WT, 2019, LANDSLIDES, V16, P1313, DOI 10.1007/s10346-019-01178-8
   Yang Y, 2019, LANDSLIDES, V16, P1301, DOI 10.1007/s10346-019-01174-y
   Youssef AM, 2016, LANDSLIDES, V13, P839, DOI 10.1007/s10346-015-0614-1
   Zhao CY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020279
NR 63
TC 59
Z9 58
U1 30
U2 94
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. Geo-Inf.
PD FEB 15
PY 2021
VL 10
IS 2
BP 
EP 
DI 10.3390/ijgi10020093
PG 19
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA QN6VA
UT WOS:000622593200001
DA 2023-04-26
ER

PT J
AU Pang, JT
   Zhang, R
   Yu, B
   Liao, MJ
   Lv, JC
   Xie, LX
   Li, S
   Zhan, JY
AF Pang, Jiatai
   Zhang, Rui
   Yu, Bin
   Liao, Mingjie
   Lv, Jichao
   Xie, Lingxiao
   Li, Song
   Zhan, Junyu
TI Pixel-level rice planting information monitoring in Fujin City based on time-series SAR imagery
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Rice planting information; Phenological analysis; Sentinel-1A; Fully convolutional neural network; Fujin City
ID paddy rice; sentinel-1; extraction; southeast
AB As the core issues of agricultural remote sensing, the mapping of crop planting and dynamic monitoring of crop growth in the urban area have always been limited by complex climatic conditions that induced optical image shortages. Considering that the backscattering signals of SAR image data are sensitive to crop phenological period, the paper presents a fully convolutional neural network (FCN) model to realize the wide-area planting thematic mapping at the pixel level. Taking Fujin City of Heilongjiang province in China as a specific study area, we selected rice as the typical research object and obtained urban-scale rice planting thematic mapping using Sentinel-1A image data derived from April to October 2020. Based on the proposed FCN classification method, the rice extraction precision is up to 95.7%, and the kappa coefficient is 0.90. Comparative analysis indicated that the proposed model is superior to the traditional random forest classification model in extraction precision and kappa coefficient. Further analysis showed that the rice growth cycle in Fujin City was consistent with the time series of VH/VV polarization coefficient ratio and had prominent phenological cycle characteristics. Relevant research data and results proved that high-precision planting thematic mapping at an urban scale could be achieved based on time series SAR image data sets. And the proposed FCN classification model is helping to dynamic monitoring of crop growth and related phenological research.
C1 [Pang, Jiatai; Zhang, Rui; Yu, Bin; Liao, Mingjie; Lv, Jichao; Xie, Lingxiao; Li, Song; Zhan, Junyu] South West Jiaotong Univ, Fac Geosci & Environm Engn, Chengdu 610031, Sichuan, Peoples R China.
   [Zhang, Rui] Southwest Jiaotong Univ, State Prov Joint Engn Lab Spatial Informat Techno, Chengdu 610031, Sichuan, Peoples R China.
C3 Southwest Jiaotong University; Southwest Jiaotong University
RP Zhang, R (corresponding author), Southwest Jiaotong Univ, Chengdu, Peoples R China.
EM zhangrui@swjtu.edu.cn
FU National Natural Science Foundation of China [41771402]; Sichuan Scienceand Technology Program [2018JY0564, 2019ZDZX0042, 2020JDTD0003, 2020YJ0322]
CR Bachelet D, 1994, GEOCARTO INT, V10, P23, DOI 10.1080/10106049509354476
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Boschetti M, 2017, REMOTE SENS ENVIRON, V194, P347, DOI 10.1016/j.rse.2017.03.029
   Cai YT, 2019, ADV SPACE RES, V64, P2233, DOI 10.1016/j.asr.2019.08.042
   Carfagna E, 2005, INT STAT REV, V73, P389
   Chen HL, 2008, 2008 ISECS INTERNATIONAL COLLOQUIUM ON COMPUTING, V0, P0
   Choudhury I., 2007, ENVISAT S P, V0, P0
   Clauss K, 2018, INT J REMOTE SENS, V39, P1399, DOI 10.1080/01431161.2017.1404162
   Friesen J, 2012, IEEE T GEOSCI REMOTE, V50, P2595, DOI 10.1109/TGRS.2012.2193889
   Frolking S, 2002, GLOBAL BIOGEOCHEM CY, V16, P0, DOI 10.1029/2001GB001425
   Guan XD, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010019
   He YL, 2021, INT J APPL EARTH OBS, V101, P0, DOI 10.1016/j.jag.2021.102351
   Huang JingFeng, 2013, TRANSACTIONS OF THE CHINESE SOCIETY OF AGRICULTURAL ENGINEERING, V29, P166
   Kuenzer C, 2013, INT J REMOTE SENS, V34, P2101, DOI 10.1080/01431161.2012.738946
   Kurtz C, 2014, ISPRS J PHOTOGRAMM, V87, P122, DOI 10.1016/j.isprsjprs.2013.11.003
   Lasko K, 2018, IEEE J-STARS, V11, P498, DOI 10.1109/JSTARS.2017.2784784
   Liu JJ, 2018, INT CONF AGRO-GEOINF, V0, P211
   Oliphant AJ, 2019, INT J APPL EARTH OBS, V81, P110, DOI 10.1016/j.jag.2018.11.014
   Pan YQ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040374
   Park S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030447
   Raman M., 2019, ISPRS INT ARCH PHOTO, VXLII-3/W6, P141
   Schaufler S, 2018, REMOTE SENS LETT, V9, P799, DOI 10.1080/2150704X.2018.1480071
   Shwetank. J. Bhatia K., 2010, PROC 1, V0, P0
   Steele-Dunne SC, 2017, IEEE J-STARS, V10, P2249, DOI 10.1109/JSTARS.2016.2639043
   Tan LF, 2015, J APPL REMOTE SENS, V9, P0, DOI 10.1117/1.JRS.9.097091
   Torbick N, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9020119
   Veloso A, 2017, REMOTE SENS ENVIRON, V199, P415, DOI 10.1016/j.rse.2017.07.015
   Xiao XM, 2006, REMOTE SENS ENVIRON, V100, P95, DOI 10.1016/j.rse.2005.10.004
   Xu YH, 2020, IEEE T BIG DATA, V6, P492, DOI 10.1109/TBDATA.2019.2923243
   You NS, 2021, SCI DATA, V8, P0, DOI 10.1038/s41597-021-00827-9
   Zhou L, 2013, ECOL INFORM, V18, P69, DOI 10.1016/j.ecoinf.2013.05.003
NR 31
TC 8
Z9 8
U1 10
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 15
PY 2021
VL 104
IS 
BP 
EP 
DI 10.1016/j.jag.2021.102551
PG 11
WC Remote Sensing
SC Remote Sensing
GA WD0SC
UT WOS:000704656600001
DA 2023-04-26
ER

PT J
AU Yu, NG
   Yu, HJ
   Liao, YS
   Wang, ZX
   Sie, O
AF Yu, Naigong
   Yu, Hejie
   Liao, Yishen
   Wang, Zongxia
   Sie, Ouattara
TI A Model of Spatial Cell Development in Rat Hippocampus Based on Artificial Neural Network
SO JOURNAL OF HEALTHCARE ENGINEERING
LA English
DT Article
ID cognitive map; place cells; grid cells; field
AB Physiological studies have shown that the hippocampal structure of rats develops at different stages, in which the place cells continue to develop during the whole juvenile period of rats and mature after the juvenile period. As the main information source of place cells, grid cells should mature earlier than place cells. In order to make better use of the biological information exhibited by the rat brain hippocampus in the environment, we propose a position cognition model based on the spatial cell development mechanism of rat hippocampus. The model uses a recurrent neural network with parametric bias (RNNPB) to simulate changes in the discharge characteristics during the development of a single stripe cell. The oscillatory interference mechanism is able to fuse the developing stripe waves, thus indirectly simulating the developmental process of the grid cells. The output of the grid cells is then used as the information input of the place cells, whose development process is simulated by BP neural network. After the place cells matured, the position matrix generated by the place cell group was used to realize the position cognition of rats in a given spatial region. The experimental results show that this model can simulate the development process of grid cells and place cells, and it can realize high precision positioning in the given space area. Moreover, the experimental effect of cognitive map construction using this model is basically consistent with the effect of RatSLAM, which verifies the validity and accuracy of the model.
C1 [Yu, Naigong; Yu, Hejie; Liao, Yishen; Wang, Zongxia; Sie, Ouattara] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Yu, NG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing 100124, Peoples R China.
EM yunaigong@bjut.edu.cn; 1453251781@qq.com; 1060884338@qq.com; wzongxia@bjut.edu.cn; sie_chine@bjut.edu.cn
FU National Science Foundation of China [62076014]; Beijing Natural Science Foundation [4162012]
CR Ball D, 2013, AUTON ROBOT, V34, P149, DOI 10.1007/s10514-012-9317-9
   Bicanski A, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.33752
   Burgess N, 1996, HIPPOCAMPUS, V6, P749
   Byrne P, 2007, PSYCHOL REV, V114, P340, DOI 10.1037/0033-295X.114.2.340
   Castro L, 2014, BIOL CYBERN, V108, P133, DOI 10.1007/s00422-013-0581-3
   Chen Y, 2018, J SCI FOOD AGR, V98, P3022, DOI 10.1002/jsfa.8801
   Erdem UM, 2015, NEUROBIOL LEARN MEM, V117, P109, DOI 10.1016/j.nlm.2014.07.003
   Franz MO, 2000, ROBOT AUTON SYST, V30, P133, DOI 10.1016/S0921-8890(99)00069-X
   Gerlei K, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17500-1
   Giocomo LM, 2007, SCIENCE, V315, P1719, DOI 10.1126/science.1139207
   Gonner L, 2017, FRONT COMPUT NEUROSC, V11, P0, DOI 10.3389/fncom.2017.00084
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Heft H, 2013, J ENVIRON PSYCHOL, V33, P14, DOI 10.1016/j.jenvp.2012.09.002
   Kasac J, 2011, IEEE T CONTR SYST T, V19, P1587, DOI 10.1109/TCST.2010.2084088
   Krupic J, 2012, SCIENCE, V337, P853, DOI 10.1126/science.1222403
   Lyttle D, 2013, HIPPOCAMPUS, V23, P729, DOI 10.1002/hipo.22132
   Mhatre H, 2012, HIPPOCAMPUS, V22, P320, DOI 10.1002/hipo.20901
   Milford M, 2016, SPRINGER TRAC ADV RO, V114, P467, DOI 10.1007/978-3-319-28872-7_27
   Nakazawa K, 2004, NAT REV NEUROSCI, V5, P361, DOI 10.1038/nrn1385
   Neher T, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0181618
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKeefe J, 1996, NATURE, V381, P425, DOI 10.1038/381425a0
   Park JC, 2018, IEEE T COGN DEV SYST, V10, P545, DOI 10.1109/TCDS.2017.2679765
   Save E, 2000, HIPPOCAMPUS, V10, P64, DOI 10.1002/(SICI)1098-1063(2000)10:1<64::AID-HIPO7>3.3.CO;2-P
   Shipston-Sharman O, 2016, J PHYSIOL-LONDON, V594, P6547, DOI 10.1113/JP270630
   Solstad T, 2006, HIPPOCAMPUS, V16, P1026, DOI 10.1002/hipo.20244
   Tian B, 2013, IEEE INT C INT ROBOT, V0, PP1562, DOI 10.1109/IROS.2013.6696557
   Tocker G, 2015, HIPPOCAMPUS, V25, P1599, DOI 10.1002/hipo.22481
   Tolman E.C., 1932, AM J PSYCHOL, V63, P64
   Vantomme G, 2020, CELL REP, V31, P0, DOI 10.1016/j.celrep.2020.107747
   Wagatsuma H, 2007, COGN NEURODYNAMICS, V1, P119, DOI 10.1007/s11571-006-9013-6
   Weber SN, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.34560
   Welinder PE, 2008, HIPPOCAMPUS, V18, P1283, DOI 10.1002/hipo.20519
   Wills TJ, 2010, SCIENCE, V328, P1573, DOI 10.1126/science.1188224
   Yu FW, 2019, BIOL CYBERN, V113, P515, DOI 10.1007/s00422-019-00806-9
   Yu SM, 2020, FRONT NEUROROBOTICS, V14, P0, DOI 10.3389/fnbot.2020.568091
NR 36
TC 0
Z9 0
U1 3
U2 14
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2040-2295
EI 2040-2309
J9 J HEALTHC ENG
JI J. Healthc. Eng.
PD OCT 26
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/5607999
PG 14
WC Health Care Sciences & Services
SC Health Care Sciences & Services
GA XB5BU
UT WOS:000721345400004
PM 34745501
DA 2023-04-26
ER

PT J
AU Wang, YM
   Zhang, Z
   Feng, LW
   Ma, YC
   Du, QY
AF Wang, Yumiao
   Zhang, Zhou
   Feng, Luwei
   Ma, Yuchi
   Du, Qingyun
TI A new attention-based CNN approach for crop mapping using time series Sentinel-2 images
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
LA English
DT Article
DE Crop classification; Geographic heterogeneity; Attention-based CNN; Sentinel-2
ID red-edge bands; land-cover; neural-networks; classification; intensification; maize
AB Accurate crop mapping is of great importance for agricultural applications, and deep learning methods have been applied on multi-temporal remotely sensed images to classify crops. However, due to the geographic heterogeneity, the spectral profiles of the same crop can vary spatially, and thus using the spectral features alone can limit the model performance in mapping crops in large scales. Moreover, it is a challenge for traditional deep learning models to accurately capture the important information from a large number of features. To address these issues, in this study, we developed a novel attention-based convolutional neural network (CNN) approach (Geo-CBAM-CNN) for crop classification using time series Sentinel-2 images. Specifically, geographic information of crops was first integrated into an advanced attention module, Convolutional Block Attention Module (CBAM) to form a Geo-CBAM module which can help mitigate the impacts of geographic heterogeneity and restrain unnecessary information. Then, the developed Geo-CBAM module was embedded into a CNN model to boost the model?s attention both spectrally and spatially. The proposed Geo-CBAM-CNN model was validated on four main crops over six counties with different geographic environments in the U.S. Also, it was compared to three other state-of-the-art machine learning approaches, including CBAM-CNN, CNN and Random Forest (RF). The results showed that the proposed model achieved the best performance, reaching 97.82% overall accuracy, 96.82% Kappa coefficient and 96.96% Macro-average F1 score. Moreover, the developed Geo-CBAM-CNN model showed strong spatial adaptability, indicating its superior performance in large scale applications. Furthermore, by visualizing the structure of the Geo-CBAM-CNN, we found that the model automatically allocated different weights to the features, and generally, the red-edge features in the middle of the year obtained more attention.
C1 [Wang, Yumiao; Feng, Luwei; Du, Qingyun] Wuhan Univ, Sch Resources & Environm Sci, Wuhan 430079, Peoples R China.
   [Wang, Yumiao; Zhang, Zhou; Feng, Luwei; Ma, Yuchi] Univ Wisconsin, Biol Syst Engn, Madison, WI 53706 USA.
   [Du, Qingyun] Wuhan Univ, Key Lab Geog Informat Syst, Minist Educ, Wuhan 430079, Peoples R China.
   [Du, Qingyun] Wuhan Univ, Key Lab Digital Mapping & Land Informat Applicat, Minist Nat Resources, Wuhan 430079, Peoples R China.
C3 Wuhan University; University of Wisconsin System; University of Wisconsin Madison; Wuhan University; Ministry of Natural Resources of the People's Republic of China; Wuhan University
RP Zhang, Z (corresponding author), Univ Wisconsin, Biol Syst Engn, Madison, WI 53706 USA.
EM wymfrank@whu.edu.cn; zzhang347@wisc.edu; lwfeng@whu.edu.cn; ma286@wisc.edu; qydu@whu.edu.cn
FU University of Wisconsin-Madison, Office of the Vice Chancellor for Research and Graduate Education; Wisconsin Alumni Research Foundation
CR Abadi Martin, 2016, ARXIV, V0, P0
   Abdi AM, 2020, GISCI REMOTE SENS, V57, P1, DOI 10.1080/15481603.2019.1650447
   Adelabu S, 2014, ISPRS J PHOTOGRAMM, V95, P34, DOI 10.1016/j.isprsjprs.2014.05.013
   BADHWAR GD, 1984, REMOTE SENS ENVIRON, V14, P15, DOI 10.1016/0034-4257(84)90004-X
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bajzelj B, 2014, NAT CLIM CHANGE, V4, P924, DOI 10.1038/NCLIMATE2353
   Bargiel D, 2017, REMOTE SENS ENVIRON, V198, P369, DOI 10.1016/j.rse.2017.06.022
   Bijlsma S, 2006, ANAL CHEM, V78, P567, DOI 10.1021/ac051495j
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Bradley B., 2007, CURVE FITTING PROCED, V0, P0
   Carletto C, 2015, J AFR ECON, V24, P593, DOI 10.1093/jae/ejv011
   Claverie M., 2018, HARMONIZED LANDSAT S, V0, P0
   Clevers JGPW, 2013, INT J APPL EARTH OBS, V23, P344, DOI 10.1016/j.jag.2012.10.008
   Deng M, 2018, T GIS, V22, P183, DOI 10.1111/tgis.12302
   Dong JW, 2016, REMOTE SENS ENVIRON, V185, P142, DOI 10.1016/j.rse.2016.02.016
   Foley JA, 2005, SCIENCE, V309, P570, DOI 10.1126/science.1111772
   Forkuor G, 2018, GISCI REMOTE SENS, V55, P331, DOI 10.1080/15481603.2017.1370169
   Geerken RA, 2009, ISPRS J PHOTOGRAMM, V64, P422, DOI 10.1016/j.isprsjprs.2009.03.001
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Gourlay S., 2017, COULD DEBATE BE OVER, V0, P0
   Hao PY, 2020, SCI TOTAL ENVIRON, V733, P0, DOI 10.1016/j.scitotenv.2020.138869
   He K., 2015, PROC CVPR IEEE, V5, P6
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hou P, 2014, FIELD CROP RES, V158, P55, DOI 10.1016/j.fcr.2013.12.021
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jonsson P, 2002, IEEE T GEOSCI REMOTE, V40, P1824, DOI 10.1109/TGRS.2002.802519
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Li ZT, 2020, INFRARED PHYS TECHN, V105, P0, DOI 10.1016/j.infrared.2019.103152
   LICHTENTHALER HK, 1987, METHOD ENZYMOL, V148, P350
   Liu YE, 2013, FIELD CROP RES, V144, P192, DOI 10.1016/j.fcr.2013.01.003
   Mathur A, 2008, IEEE GEOSCI REMOTE S, V5, P241, DOI 10.1109/LGRS.2008.915597
   Matson PA, 1997, SCIENCE, V277, P504, DOI 10.1126/science.277.5325.504
   Moghimi A, 2020, COMPUT ELECTRON AGR, V172, P0, DOI 10.1016/j.compag.2020.105299
   OLSSON L, 1994, INT J REMOTE SENS, V15, P3735, DOI 10.1080/01431169408954355
   Pax-Lenney M, 1997, MONITORING AGR LANDS, V0, P0
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   REED BC, 1994, J VEG SCI, V5, P703, DOI 10.2307/3235884
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, V0, PP618, DOI 10.1109/ICCV.2017.74
   Tilman D, 2011, P NATL ACAD SCI USA, V108, P20260, DOI 10.1073/pnas.1116437108
   U. NASS, 2019, CROP PRODUCTION 2018, V0, P0
   USDA, 2020, JUNE AREA, V0, P0
   Vuolo F, 2018, INT J APPL EARTH OBS, V72, P122, DOI 10.1016/j.jag.2018.06.007
   Waldner F, 2015, REMOTE SENS-BASEL, V7, P7959, DOI 10.3390/rs70607959
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang HY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141639
   Wang Y., 2020, A HYBRID MODEL CONSI, V0, P0
   Wang Z, 2016, INT J PLANT PROD, V10, P509
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang CH, 2011, COMPUT ELECTRON AGR, V75, P347, DOI 10.1016/j.compag.2010.12.012
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhong LH, 2011, INT J REMOTE SENS, V32, P7777, DOI 10.1080/01431161.2010.527397
NR 59
TC 26
Z9 27
U1 26
U2 121
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0168-1699
EI 1872-7107
J9 COMPUT ELECTRON AGR
JI Comput. Electron. Agric.
PD MAY 15
PY 2021
VL 184
IS 
BP 
EP 
DI 10.1016/j.compag.2021.106090
EA MAR 2021
PG 12
WC Agriculture, Multidisciplinary; Computer Science, Interdisciplinary Applications
SC Agriculture; Computer Science
GA RO9HU
UT WOS:000641351000001
DA 2023-04-26
ER

PT J
AU Liu, B
   Yan, S
   Li, JQ
   Li, Y
   Lang, JL
   Qu, GZ
AF Liu, Bo
   Yan, Shuo
   Li, Jianqiang
   Li, Yong
   Lang, Jianlei
   Qu, Guangzhi
TI A Spatiotemporal Recurrent Neural Network for Prediction of Atmospheric PM2.5: A Case Study of Beijing
SO IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
LA English
DT Article
DE Air quality; environment pollution; prediction; recurrent neural network (RNN); spatiotemporal sequences
ID air-quality; memory; model
AB With rapid industrial development, air pollution problems, especially in urban and metropolitan centers, have become a serious societal problem and require our immediate attention and comprehensive solutions to protect human and animal health and the environment. Because bad air quality brings prominent effects on our daily life, how to forecast future air quality accurately and tenuously has emerged as a priority for guaranteeing the quality of human life in many urban areas worldwide. Existing models usually neglect the influence of wind and do not consider both distance and similarity to select the most related stations, which can provide significant information in prediction. Therefore, we propose a Geographic Self-Organizing Map (GeoSOM) spatiotemporal gated recurrent unit (GRU) model, which clusters all the monitor stations into several clusters by geographical coordinates and time-series features. For each cluster, we build a GRU model and weighted different models with the Gaussian vector weights to predict the target sequence. The experimental results on real air quality data in Beijing validate the superiority of the proposed method over a number of state-of-the-art ones in metrics, such as R-2, mean relative error (MRE), and mean absolute error (MAE). The MAE, MRE, and R-2 are 16.1, 0.79, and 035 at the Gucheng station and 19.53, 0.82, and 036 at the Dongsi station.
C1 [Liu, Bo; Li, Jianqiang; Li, Yong] Beijing Univ Technol, Fac Informat Technol, Sch Software Engn, Beijing, Peoples R China.
   [Liu, Bo] Univ Auckland, Sch Comp Sci, Beijing 1010, Peoples R China.
   [Yan, Shuo] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Lang, Jianlei] Beijing Univ Technol, Coll Environm & Energy Engn, Key Lab Beijing Reg Air Pollut Control, Beijing 100124, Peoples R China.
   [Qu, Guangzhi] Oakland Univ, Comp Sci & Engn Dept, Rochester, MI 48309 USA.
C3 Beijing University of Technology; Chinese Academy of Sciences; Institute of Automation, CAS; Beijing University of Technology; Oakland University
RP Yan, S (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
EM boliu@bjut.edu.cn; yanshuok@163.com; lijianqiang@bjut.edu.cn; li.yong@bjut.edu.cn; jllang@bjut.edu.cn; gqu@oakland.edu
FU National Natural Science Foundation of China [61702021]; Beijing Natural Science Foundation [4174082]; China Scholarship Council
CR [Anonymous], 2000, QUANTITATIVE GEOGRAP, V0, P0
   Athira V., 2018, INT C COMPUTATIONAL, V132, P1394
   Bao G, 2020, IEEE-CAA J AUTOMATIC, V7, P96, DOI 10.1109/JAS.2019.1911828
   Bi J, 2019, IEEE T AUTOM SCI ENG, V16, P1763, DOI 10.1109/TASE.2019.2895801
   Bui T., 2018, ARXIV180407891, V0, P0
   Chaudhary V, 2018, UDM, V0, P0
   Chen L, 2019, IEEE-CAA J AUTOMATIC, V6, P236, DOI 10.1109/JAS.2018.7511186
   Deng M, 2013, SCI CHINA INFORM SCI, V56, P0, DOI 10.1007/s11432-011-4391-8
   Dey R, 2017, MIDWEST SYMP CIRCUIT, V0, PP1597, DOI 10.1109/MWSCAS.2017.8053243
   Donnelly A, 2015, ATMOS ENVIRON, V103, P53, DOI 10.1016/j.atmosenv.2014.12.011
   Du S., 2018, ARXIV181204783, V0, P0
   Feng F, 2018, LECT NOTES COMPUT SC, V10987, P349, DOI 10.1007/978-3-319-96890-2_29
   Gao SC, 2019, IEEE T NEUR NET LEAR, V30, P601, DOI 10.1109/TNNLS.2018.2846646
   Henriques R, 2010, SECOND INTERNATIONAL CONFERENCE ON ADVANCED GEOGRAPHIC INFORMATION SYSTEMS, V0, P0
   Henriques R, 2009, LECT NOTES COMPUT SC, V5592, P453, DOI 10.1007/978-3-642-02454-2_32
   Huang CJ, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18072220
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kolehmainen M, 2001, ATMOS ENVIRON, V35, P815, DOI 10.1016/S1352-2310(00)00385-X
   Lal B, 2012, ATMOS POLLUT RES, V3, P211, DOI 10.5094/APR.2012.023
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P0, DOI 10.5555/303568.303704
   Li CD, 2019, IEEE-CAA J AUTOMATIC, V6, P1487, DOI 10.1109/JAS.2019.1911543
   Liang YX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3428
   Liu DR, 2021, COMPUTING, V103, P75, DOI 10.1007/s00607-020-00849-y
   Nejadkoorki F, 2012, INT J ENVIRON RES, V6, P277
   Ong BT, 2014, IEEE INT CONF BIG DA, V0, PP760, DOI 10.1109/BigData.2014.7004302
   Pardo E, 2017, LECT NOTES COMPUT SC, V10338, P232, DOI 10.1007/978-3-319-59773-7_24
   Pascanu R., 2013, ARXIV12115063, V0, P1310
   Reddy V., 2018, ENVIRON SCI-TOKYO, V0, P0
   Russo A, 2013, ATMOS ENVIRON, V79, P822, DOI 10.1016/j.atmosenv.2013.07.072
   Shi ZC, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8030112
   Soh PW, 2018, IEEE ACCESS, V6, P38186, DOI 10.1109/ACCESS.2018.2849820
   Sutskever I., 2014, ADV NEURAL INF PROCE, V2, P3104, DOI 10.48550/ARXIV.1409.3215
   Vardoulakis S, 2003, ATMOS ENVIRON, V37, P155, DOI 10.1016/S1352-2310(02)00857-9
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang B, 2018, LECT NOTES COMPUT SC, V11305, P93, DOI 10.1007/978-3-030-04221-9_9
   Wang F, 2017, IEEE T INTELL TRANSP, V18, P49, DOI 10.1109/TITS.2016.2521866
   Wang H., 2018, ARXIV180903964, V0, P0
   Wang JS, 2018, NEUROCOMPUTING, V314, P198, DOI 10.1016/j.neucom.2018.06.049
   Yang R., 2019, P 3 HIGH PERF COMP C, V0, P108
   Yi XW, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP965, DOI 10.1145/3219819.3219822
   Zhang Y, 2012, ATMOS ENVIRON, V60, P632, DOI 10.1016/j.atmosenv.2012.06.031
   Zhao JC, 2019, CHEMOSPHERE, V220, P486, DOI 10.1016/j.chemosphere.2018.12.128
   Zhao XD, 2020, IEEE-CAA J AUTOMATIC, V7, P965, DOI 10.1109/JAS.2020.1003228
   Zheng Y, 2015, KDD15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2267, DOI 10.1145/2783258.2788573
   Zhu JY, 2017, IEEE T BIG DATA, V3, P307, DOI 10.1109/TBDATA.2017.2651898
NR 45
TC 5
Z9 5
U1 4
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-924X
EI 
J9 IEEE T COMPUT SOC SY
JI IEEE Trans. Comput. Soc. Syst.
PD JUN 15
PY 2021
VL 8
IS 3
BP 578
EP 588
DI 10.1109/TCSS.2021.3056410
PG 11
WC Computer Science, Cybernetics; Computer Science, Information Systems
SC Computer Science
GA SJ9CB
UT WOS:000655822700005
DA 2023-04-26
ER

PT J
AU Choung, YJ
   Jung, D
AF Choung, Yun-Jae
   Jung, Donghwi
TI Comparison of Machine and Deep Learning Methods for Mapping Sea Farms Using High-Resolution Satellite Image
SO JOURNAL OF COASTAL RESEARCH
LA English
DT Article
DE Machine learning; deep learning; sea farm; satellite image
AB Previous research had shown that the supervised machine learning approach performed better than unsupervised machine learning for mapping sea farms using a high-resolution satellite image. The present work compares a support vector machine (SVM), which represents the supervised machine learning approach, and a deep neural network (DNN), which represents the deep learning approach, for mapping sea farms using KOMPSAT-3 satellite images acquired in the South Sea of South Korea. First, coastal maps were generated from the image source given by SVM and DNN. Next, the above-water and underwater farms were detected separately from both the maps based on the minimum and maximum thresholds. Finally, the detection accuracy of both the above-water and underwater farms from both coastal maps was assessed. Statistical results showed that deep learning (DNN) provided better performance than machine learning (SVM) for detecting above-water farms from the given high-resolution satellite image, while both DNN and SVM yielded the same performance for underwater farms. However, a few errors occurred in the detection because of the limitations of the pixel-based classification approaches. In future research, the deep learning algorithm combined with object-based classification, such as the convolutional neural network, can be used to detect sea farms from the given high-resolution image more accurately.
C1 [Choung, Yun-Jae] Geo C&I Co Ltd, Geospatial Res Ctr, Seoul, South Korea.
   [Jung, Donghwi] Korea Univ, Sch Civil Environm & Architectural Engn, Seoul, South Korea.
C3 Korea University
RP Choung, YJ (corresponding author), Geo C&I Co Ltd, Geospatial Res Ctr, Seoul, South Korea.
EM choung12osu@gmail.com
FU Ministry of Ocean and Fisheries, Korea
CR Choung YJ, 2020, INT J REMOTE SENS, V41, P5657, DOI 10.1080/01431161.2019.1701214
   Choung YJ, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/8245204
   DictionaryCom, 2020, MACH LEARN, V0, P0
   Expert System, 2020, WHAT IS MACH LEARN D, V0, P0
   National Oceanic and Atmospheric Administration, 2020, FARM WAT, V0, P0
   Oreilly, 2020, BAS ARCH DNN, V0, P0
   Satellite Imaging Corporation, 2020, KOMPSAT 3 SAT 0 7M, V0, P0
   Techopedia, 2020, ARTIFICIAL NEURAL NE, V0, P0
   Techopedia, 2020, DEEP NEURAL NETWORK, V0, P0
NR 9
TC 0
Z9 0
U1 0
U2 1
PU COASTAL EDUCATION & RESEARCH FOUNDATION
PI COCONUT CREEK
PA 5130 NW 54TH STREET, COCONUT CREEK, FL 33073 USA
SN 0749-0208
EI 1551-5036
J9 J COASTAL RES
JI J. Coast. Res.
PD FAL 15
PY 2021
VL 0
IS 
BP 420
EP 423
DI 10.2112/JCR-SI114-085.1
PG 4
WC Environmental Sciences; Geography, Physical; Geosciences, Multidisciplinary
SC Environmental Sciences & Ecology; Physical Geography; Geology
GA XE8YR
UT WOS:000723669300028
DA 2023-04-26
ER

PT J
AU Ha, TN
   Lubo-Robles, D
   Marfurt, KJ
   Wallet, BC
AF Ha, Thang N.
   Lubo-Robles, David
   Marfurt, Kurt J.
   Wallet, Bradley C.
TI An in-depth analysis of logarithmic data transformation and per-class normalization in machine learning: Application to unsupervised classification of a turbidite system in the Canterbury Basin, New Zealand, and supervised classification of salt in the Eugene Island minibasin, Gulf of Mexico
SO INTERPRETATION-A JOURNAL OF SUBSURFACE CHARACTERIZATION
LA English
DT Article
ID seismic facies classification; attributes
AB In a machine-learning workflow, data normalization is a crucial step that compensates for the large variation in data ranges and averages associated with different types of input measured with different units. However, most machine-learning implementations do not provide data normalization beyond the z-score algorithm, which subtracts the mean from the distribution and then scales the result by dividing by the standard deviation. Although the z-score converts data with Gaussian behavior to have the same shape and size, many of our seismic attribute volumes exhibit log-normal, or even more complicated, distributions. Because many machine-learning applications are based on Gaussian statistics, we have evaluated the impact of more sophisticated data normalization techniques on the resulting classification. To do so, we provide an in-depth analysis of data normalization in machine-learning classifications by formulating and applying a logarithmic data transformation scheme to the unsupervised classifications (including principal component analysis, independent component analysis, self-organizing maps, and generative topographic mapping) of a turbidite channel system in the Canterbury Basin, New Zealand, as well as implementing a per-class normalization scheme to the supervised probabilistic neural network (PNN) classification of salt in the Eugene Island minibasin, Gulf of Mexico. Compared to the simple z-score normalization, a single logarithmic transformation applied to each input attribute significantly increases the spread of the resulting clusters (and the corresponding color contrast), thereby enhancing subtle details in projection and unsupervised classification. However, this same uniform transformation produces less-confident results in supervised classification using PNNs. We find that more accurate supervised classifications can be found by applying class-dependent normalization for each input attribute.
C1 [Ha, Thang N.; Lubo-Robles, David; Marfurt, Kurt J.] Univ Oklahoma, Sch Geosci, Norman, OK 73019 USA.
   [Wallet, Bradley C.] Aramco Serv Co, Aramco Res Ctr, Houston, TX 77084 USA.
C3 University of Oklahoma System; University of Oklahoma - Norman; Aramco Services Company (ASC)
RP Ha, TN (corresponding author), Univ Oklahoma, Sch Geosci, Norman, OK 73019 USA.
EM Thang.N.Ha-1@ou.edu; davidlubo@ou.edu; kmarfurt@ou.edu; bwallet@reservoiranalyiics.com
CR ALEXANDER LL, 1995, AAPG BULL, V79, P1737
   Chopra S, 2014, 84 ANN INT M SEG, V0, PP2672, DOI 10.1190/segam2014-0235.1
   Chopra S., 2014, 84 ANN INT M SEG, V0, PP1390, DOI 10.1190/SEGAM2014-0233.1
   Cozens N., 2011, THESIS VICTORIA U WE, V0, P0
   DEMATOS MC, 2010, REV BRAS GEOFIS, V28, P631, DOI 10.1590/S0102-261X2010000400008
   Guo H, 2008, GEOPHYSICS, V73, PW7, DOI 10.1190/1.2903819
   Hardisty R., 2017, SEG TECHN PROGR 2017, V0, PP2289, DOI 10.1190/SEGAM2017-17794438.1
   Joshi A, 2016, MAR PETROL GEOL, V75, P1, DOI 10.1016/j.marpetgeo.2016.04.005
   Kim Y, 2019, INTERPRETATION-J SUB, V7, PSE281, DOI 10.1190/INT-2018-0246.1
   Lin A., 2019, WIKI J SCI, V2, P5, DOI 10.15347/wjs/2019.005
   Lubo-Robles D, 2021, INTERPRETATION-J SUB, V9, PT421, DOI 10.1190/INT-2020-0102.1
   Lubo-Robles D, 2019, INTERPRETATION-J SUB, V7, PSE19, DOI 10.1190/INT-2018-0109.1
   Masters T, 1995, ADV ALGORITHMS NEURA, V0, P0
   Meldahl P., 1999, 69 ANN INT M SEG, V1, P931, DOI 10.1190/1.1821262
   POUPON M, 1999, 69 ANN INT M SEG, V0, PP927, DOI 10.1190/1.1821260
   Qi J, 2020, GEOPHYSICS, V85, PO17, DOI 10.1190/GEO2019-0223.1
   Qi J, 2016, INTERPRETATION-J SUB, V4, PSB91, DOI 10.1190/INT-2015-0098.1
   Qi X., 2019, MISSISSIPPIAN RESERV, V122, P0
   Roden R., 2017, FIRST BREAK, V35, P0, DOI 10.3997/1365-2397.35.5.88069
   Roden R, 2015, INTERPRETATION-J SUB, V3, PSAE59, DOI 10.1190/INT-2015-0037.1
   Roy A, 2014, INTERPRETATION-J SUB, V2, PSA31, DOI 10.1190/INT-2013-0077.1
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Strecker U., 2005, SIPES 3 D S, V0, P0
   Strecker U., 2002, LEAD EDGE, V21, P1032, DOI 10.1190/1.1518442
   Sutherland R, 2003, OIL GAS J, V101, P45
   Torres E., 2018, GEOPHYSICAL SOC HOUS, V8, P13, DOI 10.15530/urtec-2017-2692737
   Verma S., 2012, 82 ANN INT M SEG, V0, P0, DOI DOI 10.1190/segam2012-1494.1
   Wallet B, 2019, DEEP LEARNING METHOD, V0, P0
   WEST BP, 2002, LEADING EDGE, V21, P1042, DOI 10.1190/1.1518444
   Honorio BCZ, 2014, INTERPRETATION-J SUB, V2, PSA21, DOI 10.1190/INT-2013-0074.1
   Zhao T., 2014, 84 ANN INT M, V0, PP1491, DOI 10.1190/SEGAM2014-1210.1
   Zhao T., 2017, 87 ANN INT M, V0, P2132
   Zhao T, 2018, GEOPHYSICS, V83, PO31, DOI 10.1190/GEO2017-0192.1
   Zhao T, 2017, INTERPRETATION-J SUB, V5, PT163, DOI 10.1190/INT-2016-0132.1
   Zhao T, 2016, INTERPRETATION-J SUB, V4, PSB79, DOI 10.1190/INT-2015-0094.1
   Zhao T, 2015, INTERPRETATION-J SUB, V3, PSAE29, DOI 10.1190/INT-2015-0044.1
NR 36
TC 4
Z9 4
U1 2
U2 4
PU SOC EXPLORATION GEOPHYSICISTS
PI TULSA
PA 8801 S YALE ST, TULSA, OK 74137 USA
SN 2324-8858
EI 2324-8866
J9 INTERPRETATION-J SUB
JI Interpretation
PD AUG 15
PY 2021
VL 9
IS 3
BP T685
EP T710
DI 10.1190/INT-2021-0008.1
PG 26
WC Geochemistry & Geophysics
SC Geochemistry & Geophysics
GA UW0IH
UT WOS:000699850500013
DA 2023-04-26
ER

PT J
AU Coelho, FF
   Giasson, E
   Campos, AR
   Silva, RGPDE
   Costa, JJF
AF Coelho, Fabricio Fernandes
   Giasson, Elvio
   Campos, Alcinei Ribeiro
   de Oliveira e Silva, Ryshardson Geovane Pereira
   Ferreira Costa, Jose Janderson
TI Geographic object-based image analysis and artificial neural networks for digital soil mapping
SO CATENA
LA English
DT Article
DE GEOBIA; Machine learning; Multilayer perceptron; Principal components analysis; Pedology
ID classification; prediction; landforms; pixel; area
AB The use of techniques to calibrate soil prediction models based on legacy maps is restricted to areas where conventional survey and soil mapping were performed. It is necessary to seek alternatives to calibrate soil predictive models without a legacy soil map. The problem is the difficulty to delineate polygons of soil classes based on soil sampling points. This paper presents a novel digital soil mapping strategy using only georeferenced points of soil profiles to delineate detailed polygons of soil classes by the Geographic Object-Based Image Analysis (GEOBIA) approach and Artificial Neural Networks (ANN) models. The main objective was to evaluate the integration of the GEOBIA approach at different segmentation levels with ANN's models and sampling points to produce a digital soil map of the Vale dos Vinhedos region, in Rio Grande do Sul, Brazil. From a Digital Terrain Model, 10 predictive variables were extracted. From the RapidEye remote sensing image the following spectral variables were extracted: Normalized Difference Vegetation Index and Normalized Difference Water Index. A new set of variables was produced using principal component analysis after standardization of the original variables. The multiresolution segmentation algorithm was used to create image objects at different segmentation levels. Four segmentation levels were tested with scale parameter (SP) 1, 2, 5 and 10; and the Cheesboard segmentation (CS) was used to transform the original pixels into polygons. Information on types of soil was obtained from 163 georeferenced soil profiles. Five ANN's structures were implemented: four for the segmented data (SP01, SP02, SP05 and SP10) and one for the per-pixel approach (CS); 16 repetitions of each ANN were performed. With the best models for each segmentation level, extrapolations of soil classes were performed for the entire study area and validated with a detailed legacy soil map. The per-pixel approach model obtained the worst result. The best result in the extrapolation of soil types found was with the object-based approach (SP1). In our understanding, the scientific community can profit from the proposed methodology particularly when it only has georeferenced points of soil classes and not a legacy map, i.e., immediately after a field survey without the need for photointerpretation for delineation of the soil mapping units. The use of GEOBIA for digital mapping of soil classes seems to be a promising approach for future research.
C1 [Coelho, Fabricio Fernandes; Giasson, Elvio; Campos, Alcinei Ribeiro; de Oliveira e Silva, Ryshardson Geovane Pereira; Ferreira Costa, Jose Janderson] Univ Fed Rio Grande do Sul UFRGS, Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Coelho, FF (corresponding author), Univ Fed Rio Grande do Sul UFRGS, Porto Alegre, RS, Brazil.
EM fabricio.coelho@ufrgs.br
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil (CAPES) [001]; CAPES; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq); CNPq
CR Arrouays D, 2020, GEODERMA REG, V20, P0, DOI 10.1016/j.geodrs.2020.e00255
   Bagheri Bodaghabadi M, 2015, PEDOSPHERE, V25, P580, DOI 10.1016/S1002-0160(15)30038-2
   Baker BA, 2013, INT J REMOTE SENS, V34, P1633, DOI 10.1080/01431161.2012.724540
   Behrens T, 2005, J PLANT NUTR SOIL SC, V168, P21, DOI 10.1002/jpln.200421414
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Brungard CW, 2015, GEODERMA, V239, P68, DOI 10.1016/j.geoderma.2014.09.019
   Calderano B, 2014, REV BRAS CIENC SOLO, V38, P1681, DOI 10.1590/S0100-06832014000600003
   Campos AR, 2019, REV BRAS CIENC AGRAR, V14, P0, DOI 10.5039/agraria.v14i2a5653
   Candel A., 2014, DEEP LEARNING H2O, V0, P1
   Chagas CD, 2017, GEODERMA REG, V9, P47, DOI 10.1016/j.geodrs.2017.03.004
   Chagas CD, 2013, REV BRAS CIENC SOLO, V37, P339, DOI 10.1590/S0100-06832013000200005
   Chen G, 2018, GISCI REMOTE SENS, V55, P159, DOI 10.1080/15481603.2018.1426092
   Collard F., 2014, GEODERMA REG, V1, P21, DOI 10.1016/j.geodrs.2014.07.001
   de Arruda GP, 2016, SCI AGR, V73, P266, DOI 10.1590/0103-9016-2015-0131
   Dornik A, 2018, PEDOSPHERE, V28, P913, DOI 10.1016/S1002-0160(17)60377-1
   Dragut L, 2006, GEOMORPHOLOGY, V81, P330, DOI 10.1016/j.geomorph.2006.04.013
   Dragut L, 2012, GEOMORPHOLOGY, V141, P21, DOI 10.1016/j.geomorph.2011.12.001
   El-naggar AM, 2018, ALEX ENG J, V57, P3089, DOI 10.1016/j.aej.2018.10.001
   Flores C. A., 2012, SOLOS VALE VINHEDOS, V0, P0
   Gedeon TD, 1997, INT J NEURAL SYST, V8, P209, DOI 10.1142/S0129065797000227
   Gercek D, 2011, INT J GEOGR INF SCI, V25, P1011, DOI 10.1080/13658816.2011.558845
   KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233
   Karakis S, 2006, SPRS WORKSH TOP MAPP, V0, P0
   Khaledian Y, 2020, APPL MATH MODEL, V81, P401, DOI 10.1016/j.apm.2019.12.016
   Martha TR, 2018, CURR SCI INDIA, V114, P1338, DOI 10.18520/cs/v114/i06/1338-1345
   Maxwell AE, 2015, INT J REMOTE SENS, V36, P954, DOI 10.1080/01431161.2014.1001086
   Meier M, 2018, REV BRAS CIENC SOLO, V42, P0, DOI 10.1590/18069657rbcs20170421
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Pelegrino MHP, 2016, CIENC AGROTEC, V40, P534, DOI 10.1590/1413-70542016405011416
   Prudente VHR, 2017, ENG AGR-JABOTICABAL, V37, P1015, DOI 10.1590/1809-4430-eng.agric.v37n5p1015-1027/2017
   Renno CD, 2008, REMOTE SENS ENVIRON, V112, P3469, DOI 10.1016/j.rse.2008.03.018
   Ross J.L.S., 1994, ANALISE EMPIRICA FRA, V0, PP63, DOI 10.7154/ RDG.1994.0008.0006
   ten Caten Alexandre, 2011, PESQ. AGROPEC. BRAS., V46, P553, DOI 10.1590/S0100-204X2011000500014
   Machado DFT, 2019, SCI AGR, V76, P243, DOI 10.1590/1678-992x-2017-0300
   Zhang GL, 2017, J INTEGR AGR, V16, P2871, DOI 10.1016/S2095-3119(17)61762-3
NR 36
TC 4
Z9 4
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0341-8162
EI 1872-6887
J9 CATENA
JI Catena
PD NOV 15
PY 2021
VL 206
IS 
BP 
EP 
DI 10.1016/j.catena.2021.105568
EA JUL 2021
PG 10
WC Geosciences, Multidisciplinary; Soil Science; Water Resources
SC Geology; Agriculture; Water Resources
GA UF3AI
UT WOS:000688449100075
DA 2023-04-26
ER

PT J
AU Wu, FM
   Wu, BF
   Zhang, M
   Zeng, HW
   Tian, FY
AF Wu, Fangming
   Wu, Bingfang
   Zhang, Miao
   Zeng, Hongwei
   Tian, Fuyou
TI Identification of Crop Type in Crowdsourced Road View Photos with Deep Convolutional Neural Network
SO SENSORS
LA English
DT Article
DE crop type; crowdsourced road view photo; deep convolutional neural network; automatic photo identification; ensemble classification
ID google street view; classification; cultivation
AB In situ ground truth data are an important requirement for producing accurate cropland type map, and this is precisely what is lacking at vast scales. Although volunteered geographic information (VGI) has been proven as a possible solution for in situ data acquisition, processing and extracting valuable information from millions of pictures remains challenging. This paper targets the detection of specific crop types from crowdsourced road view photos. A first large, public, multiclass road view crop photo dataset named iCrop was established for the development of crop type detection with deep learning. Five state-of-the-art deep convolutional neural networks including InceptionV4, DenseNet121, ResNet50, MobileNetV2, and ShuffleNetV2 were employed to compare the baseline performance. ResNet50 outperformed the others according to the overall accuracy (87.9%), and ShuffleNetV2 outperformed the others according to the efficiency (13 FPS). The decision fusion schemes major voting was used to further improve crop identification accuracy. The results clearly demonstrate the superior accuracy of the proposed decision fusion over the other non-fusion-based methods in crop type detection of imbalanced road view photos dataset. The voting method achieved higher mean accuracy (90.6-91.1%) and can be leveraged to classify crop type in crowdsourced road view photos.
C1 [Wu, Fangming; Wu, Bingfang; Zhang, Miao; Zeng, Hongwei; Tian, Fuyou] Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.
   [Wu, Bingfang; Zeng, Hongwei; Tian, Fuyou] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Wu, BF (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.; Wu, BF (corresponding author), Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
EM wufm@radi.ac.cn; wubf@radi.ac.cn; zhangmiao@radi.ac.cn; zenghw@radi.ac.cn; tianfy@radi.ac.cn
FU National Key Research & Development Program of China [2016YFA0600301, 2019YFE0126900]; National Natural Science Foundation of China [41561144013, 41861144019]
CR [Anonymous], 2017, AAAI CONF ARTIF INTE, V0, P0, DOI DOI 10.1609/AAAI.V31I1.11231
   [Anonymous], 2016, OVERVIEW GRADIENT DE, V0, P0
   Antoniou V, 2016, ISPRS INT J GEO-INF, V5, P0, DOI 10.3390/ijgi5050064
   Chebrolu N, 2017, INT J ROBOT RES, V36, P1045, DOI 10.1177/0278364917720510
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Deus E, 2016, ENVIRON MONIT ASSESS, V188, P0, DOI 10.1007/s10661-016-5555-1
   FAO, 2019, STAT FOOD AGR 2019 M, V0, P0
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fine T.L., 2006, FEEDFORWARD NEURAL N, V0, P0
   Fritz S, 2017, SCI DATA, V4, P0, DOI 10.1038/sdata.2017.75
   Hajdu A, 2013, IEEE T IMAGE PROCESS, V22, P4182, DOI 10.1109/TIP.2013.2271116
   Hall D, 2015, IEEE WINT CONF APPL, V0, PP797, DOI 10.1109/WACV.2015.111
   He K., 2015, PROC CVPR IEEE, V5, P6
   Hestness J., 2017, ARXIV171200409, V0, P0
   Hiroshi O., 2018, ARXIV180109454, V0, P0
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Hughes D.P., 2015, ARXIV, V0, P0
   Jorgensen R., 2017, P EFITA C MONTP FRAN, V0, P0
   Joulin A., 2015, ARXIV151102251, V0, P0
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leung D., 2012, PROC 2012 ACM MULTIM, V0, PP3, DOI 10.1145/2390790.2390794
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Ma N., 2018, LECT NOTES COMPUT SC, V0, P0, DOI DOI 10.1007/978-3-030-01264-9_8
   Mohanty SP, 2016, FRONT PLANT SCI, V7, P0, DOI 10.3389/fpls.2016.01419
   Montserrat D. M., 2017, ELECT IMAGING, V2017, P27, DOI 10.2352/ISSN.2470-1173.2017.10.IMAWM-163
   Mwebaze E., 2019, ARXIV190802900, V0, P0
   Nabil M, 2020, INT J APPL EARTH OBS, V85, P0, DOI 10.1016/j.jag.2019.102010
   Namin ST, 2018, PLANT METHODS, V14, P0, DOI 10.1186/s13007-018-0333-4
   Oliphant AJ, 2019, INT J APPL EARTH OBS, V81, P110, DOI 10.1016/j.jag.2018.11.014
   Olsen A, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-018-38343-3
   Rahman MS, 2019, AGRICULTURE-BASEL, V9, P0, DOI 10.3390/agriculture9010017
   Raja R, 2020, BIOSYST ENG, V192, P257, DOI 10.1016/j.biosystemseng.2020.02.002
   Ringland J, 2019, COMPUT ELECTRON AGR, V158, P36, DOI 10.1016/j.compag.2019.01.014
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, P0, DOI 10.1155/2016/3289801
   Sler M., 2019, PROC CVPR IEEE, V0, P0, DOI DOI 10.1109/CVPR.2018.00474
   Sridar P, 2019, ULTRASOUND MED BIOL, V45, P1259, DOI 10.1016/j.ultrasmedbio.2018.11.016
   Su Z., 2019, J NW A F U, V0, P0
   Sun C., 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.97
   Tian FY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060629
   Ueda K, 2020, INATURALIST RES GRAD, V0, P0, DOI DOI 10.15468/AB3S5X
   United Nations Development Programme, 2019, HUMAN DEV REPORT 201, V0, P0
   Waldner F, 2019, INT J APPL EARTH OBS, V80, P82, DOI 10.1016/j.jag.2019.01.002
   Wu BF, 2020, GEOGR SUSTAIN, V1, P25, DOI 10.1016/j.geosus.2020.03.006
   Wu BF, 2015, REMOTE SENS-BASEL, V7, P3907, DOI 10.3390/rs70403907
   Wu BF, 2014, INT J DIGIT EARTH, V7, P113, DOI 10.1080/17538947.2013.821185
   Wu BF, 2012, INT J APPL EARTH OBS, V16, P101, DOI 10.1016/j.jag.2011.12.006
   Xiong J, 2017, ISPRS J PHOTOGRAMM, V126, P225, DOI 10.1016/j.isprsjprs.2017.01.019
   Xue DX, 2016, J MED BIOL ENG, V36, P755, DOI 10.1007/s40846-016-0182-4
   Yan YL, 2021, ISPRS J PHOTOGRAMM, V171, P278, DOI 10.1016/j.isprsjprs.2020.11.022
   Zhang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081200
   Zheng YY, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19051058
NR 55
TC 12
Z9 13
U1 6
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD FEB 15
PY 2021
VL 21
IS 4
BP 
EP 
DI 10.3390/s21041165
PG 15
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA QQ6XC
UT WOS:000624665100001
PM 33562266
DA 2023-04-26
ER

PT J
AU Kim, HS
   Sun, CG
   Lee, MG
   Cho, HI
AF Kim, Han-Saem
   Sun, Chang-Guk
   Lee, Moon-Gyo
   Cho, Hyung-Ik
TI Terrain Proxy-Based Site Classification for Seismic Zonation in North Korea within a Geospatial Data-Driven Workflow
SO REMOTE SENSING
LA English
DT Article
DE digital terrain model; proxy; site classification; seismic site effect; V-S30; regression model; geographic information system; North Korea
ID shear-wave velocity; penetration resistance; regional assessment; neural-network; optimization; topography; coastal; slope; model; seoul
AB Numerous seismic activities occur in North Korea. However, it is difficult to perform seismic hazard assessment and obtain zonal data in the Korean Peninsula, including North Korea, when applying parametric or nonparametric methods. Remote sensing can be implemented for soil characterization or spatial zonation studies on irregular, surficial, and subsurface systems of inaccessible areas. Herein, a data-driven workflow for extracting the principal features using a digital terrain model (DTM) is proposed. In addition, geospatial grid information containing terrain features and the average shear wave velocity in the top 30 m of the subsurface (V-S(30)) are employed using geostatistical interpolation methods; machine learning (ML)-based regression models were optimized and V-S(30)-based seismic zonation in the test areas in North Korea were forecasted. The interrelationships between V-S(30) and terrain proxy (elevation, slope, and landform class) in the training area in South Korea were verified to define the input layer in regression models. The landform class represents a new proxy of V-S(30) and was subgrouped according to the correlation with grid-based V-S(30). The geospatial grid information was generated via the optimum geostatistical interpolation method (i.e., sequential Gaussian simulation (SGS)). The best-fitting model among four ML methods was determined by evaluating cost function-based prediction performance, performing uncertainty analysis for the empirical correlations of V-S(30), and studying spatial correspondence with the borehole-based V-S(30) map. Subsequently, the best-fitting regression models were designed by training the geospatial grid in South Korea. Then, DTM and its terrain features were constructed along with V-S(30) maps for three major cities (Pyongyang, Kaesong, and Nampo) in North Korea. A similar distribution of the V-S(30) grid obtained using SGS was shown in the multilayer perceptron-based V-S(30) map.
C1 [Kim, Han-Saem; Sun, Chang-Guk; Lee, Moon-Gyo; Cho, Hyung-Ik] Korea Inst Geosci & Mineral Resources, Earthquake Res Ctr, Daejeon 34132, South Korea.
C3 Korea Institute of Geoscience & Mineral Resources (KIGAM)
RP Sun, CG (corresponding author), Korea Inst Geosci & Mineral Resources, Earthquake Res Ctr, Daejeon 34132, South Korea.
EM adoogen@kigam.re.kr; pungsun@kigam.re.kr; mglee@kigam.re.kr; hicho@kigam.re.kr
FU Basic Research Project of the Korea Institute of Geoscience and Mineral Resources (KIGAM)
CR Ahdi SK, 2017, B SEISMOL SOC AM, V107, P1781, DOI 10.1785/0120160335
   Allen TI, 2009, B SEISMOL SOC AM, V99, P935, DOI 10.1785/0120080255
   [Anonymous], 2001, ESRI US C SAN DIEG C, V0, P0
   ASTM, 2002, 2002 ANN BOOK ASTM S, V04, P0
   Castellaro S, 2008, SEISMOL RES LETT, V79, P540, DOI 10.1785/gssrl.79.4.540
   Chiles J.P, 2009, GEOSTATISTICS MODELI, V497, P0
   Choi BY, 2005, ENVIRON GEOL, V48, P979, DOI 10.1007/s00254-004-1205-y
   Chousianitis K, 2016, B SEISMOL SOC AM, V106, P174, DOI 10.1785/0120150172
   De Reu J, 2013, J ARCHAEOL SCI, V40, P1108, DOI 10.1016/j.jas.2012.08.040
   Di Giacomo D, 2005, B SEISMOL SOC AM, V95, P2364, DOI 10.1785/0120040242
   Dibike YB, 2001, J COMPUT CIVIL ENG, V15, P208, DOI 10.1061/(ASCE)0887-3801(2001)15:3(208)
   Dikmen U, 2009, J GEOPHYS ENG, V6, P61, DOI 10.1088/1742-2132/6/1/007
   Dobry R., 2000, EARTHQ SPECTRA, V16, P41, DOI 10.1193/1.1586082
   Doucette J, 2015, POLIT GEOGR, V47, P53, DOI 10.1016/j.polgeo.2015.04.001
   Feurer M, 2019, SPRING SER CHALLENGE, V0, PP113, DOI 10.1007/978-3-030-05318-5_6
   Frankel AD, 2002, B SEISMOL SOC AM, V92, P2090, DOI 10.1785/0120010254
   Gholami H., 2000, SCI REP, V10, P1
   Gitis VG, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9070308
   Guisan A, 1999, PLANT ECOL, V143, P107, DOI 10.1023/A:1009841519580
   Hartzell S, 2001, B SEISMOL SOC AM, V91, P468, DOI 10.1785/0120000235
   Hasancebi N, 2007, B ENG GEOL ENVIRON, V66, P203, DOI 10.1007/s10064-006-0063-0
   Hengl T, 2004, GEODERMA, V120, P75, DOI 10.1016/j.geoderma.2003.08.018
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Imai T, 1982, P 2 EUR S PEN TEST A, V0, P57
   Iwahashi J, 2007, GEOMORPHOLOGY, V86, P409, DOI 10.1016/j.geomorph.2006.09.012
   JODOUIN JF, 1994, RESEAUX NEURONES PRI, V0, P0
   Karimzadeh S, 2019, ISPRS INT GEO-INF, V8, P0, DOI 10.3390/ijgi8120537
   Kim HS, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7090375
   Kim HS, 2017, ISPRS INT GEO-INF, V6, P0, DOI 10.3390/ijgi6060174
   Kim M, 2020, KSCE J CIV ENG, V24, P778, DOI 10.1007/s12205-020-1379-1
   Lee SJ, 2020, J SEISMOL, V24, P121, DOI 10.1007/s10950-019-09891-6
   Lin SW, 2008, EXPERT SYST APPL, V35, P1817, DOI 10.1016/j.eswa.2007.08.088
   Liong SY, 2002, J AM WATER RESOUR AS, V38, P173, DOI 10.1111/j.1752-1688.2002.tb01544.x
   Masood F, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111893
   Mcgaughey WJ, 2019, P 1 INT C MIN GEOM R, V0, PP219, DOI 10.36487/ACG_rep/1905_11_McGaughey
   Menafoglio A, 2013, ELECTRON J STAT, V7, P2209, DOI 10.1214/13-EJS843
   Michelini A, 2008, SEISMOL RES LETT, V79, P688, DOI 10.1785/gssrl.79.5.688
   Mignan A, 2016, DISASTER PREV MANAG, V25, P329, DOI 10.1108/DPM-06-2015-0137
   Ministry of Public Safety and Security (MPSS), 2016, REP 9 12 EARTHQ COUN, V0, P0
   MOLIT (Ministry of Land Infrastructure and Transport), 2018, KDS 17 10 00, V0, P0
   Mucciarelli M., 2006, 1 EUR C EARTHQ ENG S, V0, P270
   Ohsaki Y., 1973, SOIL FDN, V13, P61, DOI 10.3208/sandf1972.13.4_61
   OHTA Y, 1978, EARTHQUAKE ENG STRUC, V6, P167, DOI 10.1002/eqe.4290060205
   Okada G, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13071401
   Palka E. J., 2003, N KOREA GEOGRAPHICAL, V0, P0
   PEDERSEN HA, 1995, SOIL DYN EARTHQ ENG, V14, P289, DOI 10.1016/0267-7261(95)00001-B
   Raiyani K, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13020300
   Razavi-Termeh SV, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101689
   Schafer AM, 2019, FRONT EARTH SC-SWITZ, V7, P0, DOI 10.3389/feart.2019.00136
   Seif A., 2014, BULL ENVIRON PHARMAC, V3, P33
   Shantz T., 2012, GUIDELINES ESTIMATIO, V0, P0
   Skentos A., 2017, ANN VALAHIA U TARGOV, V17, P90, DOI 10.1515/avutgs-2017-0009
   Song XD, 2016, SOIL SCI, V181, P435, DOI 10.1097/SS.0000000000000180
   Stewart JP, 2014, B SEISMOL SOC AM, V104, P2827, DOI 10.1785/0120130331
   Sun CG, 2005, ENG GEOL, V81, P446, DOI 10.1016/j.enggeo.2005.08.002
   Sun CG, 2017, GEOMAT NAT HAZ RISK, V8, P1592, DOI 10.1080/19475705.2017.1364305
   Sun CG, 2016, B EARTHQ ENG, V14, P2161, DOI 10.1007/s10518-016-9908-5
   Sun CG, 2014, SOIL DYN EARTHQ ENG, V56, P44, DOI 10.1016/j.soildyn.2013.10.003
   Sun CG, 2013, PURE APPL GEOPHYS, V170, P271, DOI 10.1007/s00024-012-0516-2
   Taghizadeh-Mehrjardi R, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13051025
   Theodulidis N, 1996, B SEISMOL SOC AM, V86, P306
   Vapnik V, 1998, NONLINEAR MODELING, V0, P55
   Venkatesan P, 2006, CURR SCI INDIA, V91, P1195
   Vianello A, 2009, CATENA, V76, P97, DOI 10.1016/j.catena.2008.09.012
   Wald DJ, 2007, B SEISMOL SOC AM, V97, P1379, DOI 10.1785/0120060267
   Wald LA, 2000, B SEISMOL SOC AM, V90, PS32, DOI 10.1785/0119970170
   Walter WR, 2018, SEISMOL RES LETT, V89, P2131, DOI 10.1785/0220180128
   Yao ZZ, 2006, BMC BIOINFORMATICS, V7, P0, DOI 10.1186/1471-2105-7-S1-S11
   Zhai MG, 2020, J ASIAN EARTH SCI, V194, P0, DOI 10.1016/j.jseaes.2019.104169
   Zhai MG, 2019, EARTH-SCI REV, V194, P57, DOI 10.1016/j.earscirev.2019.04.025
   Zhao ZY, 2009, COMPUT ELECTRON AGR, V65, P36, DOI 10.1016/j.compag.2008.07.008
   Zuo RG, 2019, EARTH-SCI REV, V192, P1, DOI 10.1016/j.earscirev.2019.02.023
   조진철, 2006, THE KOREA SPATIAL PLANNING REVIEW 국토연구, V51, P3
NR 75
TC 2
Z9 2
U1 1
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY 15
PY 2021
VL 13
IS 9
BP 
EP 
DI 10.3390/rs13091844
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SC5YD
UT WOS:000650745300001
DA 2023-04-26
ER

PT J
AU Galvan, D
   Effting, L
   Neto, LT
   Conte, CA
AF Galvan, Diego
   Effting, Luciane
   Torres Neto, Luiz
   Conte-Junior, Carlos Adam
TI An overview of research of essential oils by self-organizing maps: A novel approach for meta-analysis study
SO COMPREHENSIVE REVIEWS IN FOOD SCIENCE AND FOOD SAFETY
LA English
DT Review
DE antibacterial; antifungal; antioxidant; artificial neural network (ANN); Kohonen Map; volatile oils
ID antibacterial activity; antimicrobial activity; chemical-composition; industrial hydrogenation; staphylococcus-aureus; antibiofilm activity; antioxidant; antifungal; constituents; mechanism
AB Essential oils (EOs) are commercially important products, sources of compounds with antioxidant and antimicrobial activities considered indispensable for several fields, such as the food industry, cosmetics, perfumes, pharmaceuticals, sanitary and agricultural industries. In this context, this systematic review and meta-analysis, a novel approach will be presented using chemometric tools to verify and recognize patterns of antioxidant, antibacterial, and antifungal activities of EOs according to their geographic, botanical, chemical, and microbiological distribution. Scientific papers were selected following the Preferred Reporting Items for Systematic Review and Meta-Analyses statement flow diagram, and the data were evaluated by the self-organizing map and hierarchical cluster analysis. Overall, this novel approach allowed us to draw an overview of antioxidants and antimicrobials activities of EOs reported in 2019, through 585 articles evaluated, obtaining a dataset with more than 10,000 data, distributed in more than 80 countries, 290 plant genera, 150 chemical compounds, 30 genera of bacteria, and 10 genera of fungi. The networks for geographic, botanical, chemical, and microbiological distribution indicated that Brazil, Asia, the botanical genus Thymus, species Thymus vulgaris L. "thyme," the Lamiaceae family, limonene, and the oxygenated monoterpene class were the most representative in the dataset, while the species Escherichia coli and Candida albicans were the most used to assess the antimicrobial activity of EOs. This work can be seen as a guide for the processing of metadata using a novel approach with non-conventional statistical methods. However, this preliminary approach with EOs can be extended to other sources or areas of food science.
C1 [Galvan, Diego; Torres Neto, Luiz] Univ Fed Rio de Janeiro, Technol Dev Support Lab LADETEC, Ctr Food Anal NAL, Cidade Univ, Rio De Janeiro, Brazil.
   [Galvan, Diego; Torres Neto, Luiz; Conte-Junior, Carlos Adam] Univ Fed Rio de Janeiro, Lab Adv Anal Biochem & Mol Biol, Dept Biochem, Cidade Univ, Rio De Janeiro, Brazil.
   [Galvan, Diego; Torres Neto, Luiz; Conte-Junior, Carlos Adam] Carlos Chagas Filho Res Support Fdn State Rio de, Nanotechnol Network, Rio De Janeiro, Brazil.
   [Effting, Luciane] State Univ Londrina UEL, Dept Chem, Londrina, Parana, Brazil.
   [Torres Neto, Luiz; Conte-Junior, Carlos Adam] Univ Fed Rio de Janeiro UFRJ, Grad Program Food Sci PPGCAL, Inst Chem IQ, Cidade Univ, Rio De Janeiro, Brazil.
C3 Universidade Federal do Rio de Janeiro; Universidade Federal do Rio de Janeiro; Universidade Estadual de Londrina; Universidade Federal do Rio de Janeiro
RP Galvan, D (corresponding author), Av Athos Silveira Ramos,149,Cidade Univ, BR-21941900 Rio De Janeiro, RJ, Brazil.
EM diegogalvann@gmail.com
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico [311422/2016-0]; Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior [88887.518752/2020-00, 001]; Fundacao Carlos Chagas Filho de Amparo a Pesquisa do Estado doRio de Janeiro [E-26/200.062/2020, E-26/203.049/2017, E-26/010.000.984/2019]
CR Ahmed J, 2019, FOOD PACKAGING SHELF, V21, P0, DOI 10.1016/j.fpsl.2019.100355
   Akhbari M, 2019, NAT PROD RES, V33, P1629, DOI 10.1080/14786419.2017.1423310
   [Anonymous], 2006, MACH LEARN, V0, P0
   Bakkali F, 2008, FOOD CHEM TOXICOL, V46, P446, DOI 10.1016/j.fct.2007.09.106
   Barbieri C, 2018, POTENTIAL OF ESSENTIAL OILS, V0, PP107, DOI 10.5772/intechopen.77725
   Baser K.H.C., 2015, HDB ESSENTIAL OILS S, V0, P0
   Baser K.H.C., 2015, HDB ESSENTIAL OILS S, V1st ed., P0
   Bassole IHN, 2012, MOLECULES, V17, P3989, DOI 10.3390/molecules17043989
   Bazargani MM, 2016, FOOD CONTROL, V61, P156, DOI 10.1016/j.foodcont.2015.09.036
   Beckett C., 2017, PHARM QUALITY DESIGN, V0, P0, DOI DOI 10.1002/9781118895238.ch8
   Benameur Q, 2019, NAT PROD RES, V33, P2647, DOI 10.1080/14786419.2018.1466124
   Benoua F. Z., 2019, JOURNAL OF BIOLOGICALLY ACTIVE PRODUCTS FROM NATURE, V9, P250, DOI 10.1080/22311866.2019.1666739
   Bhavaniramya S., 2019, GRAIN OIL SCI TECHNO, V2, P49?55, DOI 10.1016/J.GAOST.2019.03.001
   Bizzo HR, 2009, QUIM NOVA, V32, P588, DOI 10.1590/S0100-40422009000300005
   Bomfim ND, 2020, FOOD ADDIT CONTAM A, V37, P153, DOI 10.1080/19440049.2019.1678771
   Borges RS, 2019, J ETHNOPHARMACOL, V229, P29, DOI 10.1016/j.jep.2018.09.038
   Braga PC, 2006, PHARMACOLOGY, V76, P61, DOI 10.1159/000089719
   Camele I, 2019, FRONT MICROBIOL, V10, P0, DOI 10.3389/fmicb.2019.02619
   CBI-Ministry of Foreign Affairs, 2019, EXP ESS OILS FRAGR E, V0, P0
   Silva LRC, 2016, PLANT PHYSIOL BIOCH, V106, P264, DOI 10.1016/j.plaphy.2016.05.017
   Chua LYW, 2019, FOOD BIOPROCESS TECH, V12, P450, DOI 10.1007/s11947-018-2227-x
   Cremasco H, 2019, FOOD SCI TECH-BRAZIL, V39, P173, DOI 10.1590/fst.40917
   Cremasco H, 2016, J SCI FOOD AGR, V96, P306, DOI 10.1002/jsfa.7094
   Cui HY, 2019, IND CROP PROD, V139, P0, DOI 10.1016/j.indcrop.2019.111498
   da Silva JD, 2019, J DRUG DELIV SCI TEC, V53, P0, DOI 10.1016/j.jddst.2019.101173
   Dai JM, 2020, TRENDS FOOD SCI TECH, V105, P211, DOI 10.1016/j.tifs.2020.09.016
   Das A, 2019, J ESSENT OIL BEAR PL, V22, P1163, DOI 10.1080/0972060X.2019.1683080
   de Medeiros VM, 2017, MICROB PATHOGENESIS, V111, P468, DOI 10.1016/j.micpath.2017.09.034
   de Veras BO, 2020, NAT PROD RES, V34, P3013, DOI 10.1080/14786419.2019.1602832
   Deyno S, 2019, COMPLEMENT THER MED, V47, P0, DOI 10.1016/j.ctim.2019.102224
   Diekema DJ, 2001, CLIN INFECT DIS, V32, PS114, DOI 10.1086/320184
   do Evangelho JA, 2019, CARBOHYD POLYM, V222, P0, DOI 10.1016/j.carbpol.2019.114981
   Donato R, 2020, J ETHNOPHARMACOL, V249, P0, DOI 10.1016/j.jep.2019.112376
   dos Santos AL, 2019, J BRAZIL CHEM SOC, V30, P2691, DOI 10.21577/0103-5053.20190196
   Falleh H, 2020, FOOD CHEM, V330, P0, DOI 10.1016/j.foodchem.2020.127268
   FARAG RS, 1989, J FOOD PROTECT, V52, P665, DOI 10.4315/0362-028X-52.9.665
   Fattahi A, 2021, INT J DERMATOL, V60, P686, DOI 10.1111/ijd.15226
   Ferreira FD, 2013, FOOD CHEM, V136, P789, DOI 10.1016/j.foodchem.2012.08.003
   Ferreira M. M. C., 2015, QUIMIOMETRIA CONCEIT, V0, P0
   Gallucci MN, 2009, FLAVOUR FRAG J, V24, P348, DOI 10.1002/ffj.1948
   Galvan D, 2021, MEDICINA-LITHUANIA, V57, P0, DOI 10.3390/medicina57030235
   Galvan D, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17238921
   Galvan D, 2020, FUEL, V267, P0, DOI 10.1016/j.fuel.2020.117221
   Pereira JMG, 2018, FOOD ANAL METHOD, V11, P188, DOI 10.1007/s12161-017-0989-9
   Garcia-Mazcorro JF, 2020, ANIMAL, V14, P22, DOI 10.1017/S1751731119001599
   Garcia-Sotelo D, 2019, LWT-FOOD SCI TECHNOL, V111, P837, DOI 10.1016/j.lwt.2019.05.061
   Gaziano R, 2020, FRONT MICROBIOL, V11, P0, DOI 10.3389/fmicb.2020.00718
   Harkat-Madouri L, 2015, IND CROP PROD, V78, P148, DOI 10.1016/j.indcrop.2015.10.015
   Haykin S., 2001, NEURAL NETWORKS COMP, V0, P0
   Ju J, 2019, TRENDS FOOD SCI TECH, V92, P22, DOI 10.1016/j.tifs.2019.08.005
   Juliano C, 2019, SAUDI J BIOL SCI, V26, P897, DOI 10.1016/j.sjbs.2018.04.009
   Kalra K., 2019, INDIAN J PUBLIC HLTH, V10, P188, DOI 10.5958/0976-5506.2019.01264.6
   Kamsu N. P., 2019, INDIAN PHYTOPATHOLOGY, V72, P131, DOI 10.1007/s42360-018-0104-1
   Kang JM, 2019, LWT-FOOD SCI TECHNOL, V101, P639, DOI 10.1016/j.lwt.2018.11.093
   Khan MK, 2019, J FOOD QUALITY, V2019, P0, DOI 10.1155/2019/5916097
   Khomarlou N, 2018, ACTA BIOL HUNG, V69, P144, DOI 10.1556/018.69.2018.2.4
   Kimura M, 2021, BIOFUELS-UK, V12, P673, DOI 10.1080/17597269.2018.1519762
   Knobloch K., 1985, PROGR ESSENTIAL OIL, V0, P429
   Koh KJ, 2002, BRIT J DERMATOL, V147, P1212, DOI 10.1046/j.1365-2133.2002.05034.x
   Kohonen T, 2001, SELF ORG MAPS, V3rd, P0, DOI 10.1007/978-3-642-97966-8
   Kujur A, 2021, PESTIC BIOCHEM PHYS, V172, P0, DOI 10.1016/j.pestbp.2020.104755
   Kulisic-Bilusic T, 2012, FOOD CHEM, V132, P261, DOI 10.1016/j.foodchem.2011.10.074
   Langeveld WT, 2014, CRIT REV MICROBIOL, V40, P76, DOI 10.3109/1040841X.2013.763219
   Lawrence B. M., 2009, PERFUMER & FLAVORIST, V34, P38
   Liang JY, 2016, CHEM BIODIVERS, V13, P1053, DOI 10.1002/cbdv.201500377
   Lucia A, 2021, ADV COLLOID INTERFAC, V287, P0, DOI 10.1016/j.cis.2020.102330
   Makhuvele R, 2020, HELIYON, V6, P0, DOI 10.1016/j.heliyon.2020.e05291
   Martins IM, 2014, CHEM ENG J, V245, P191, DOI 10.1016/j.cej.2014.02.024
   Melin P, 2020, CHAOS SOLITON FRACT, V138, P0, DOI 10.1016/j.chaos.2020.109917
   Mittal RP, 2019, CURR DRUG TARGETS, V20, P605, DOI 10.2174/1389450119666181031122917
   Mohamed AA, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0060269
   Moher D, 2015, SYST REV-LONDON, V4, P0, DOI 10.1186/2046-4053-4-1
   Murphy PA, 2006, J FOOD SCI, V71, PR51, DOI 10.1111/j.1750-3841.2006.00052.x
   Nazzaro F, 2017, PHARMACEUTICALS-BASE, V10, P0, DOI 10.3390/ph10040086
   Nicolas-Chanoine MH, 2014, CLIN MICROBIOL REV, V27, P543, DOI 10.1128/CMR.00125-13
   Olagunju O, 2018, J FOOD SAFETY, V38, P0, DOI 10.1111/jfs.12515
   Oussalah M, 2006, J FOOD PROTECT, V69, P1046, DOI 10.4315/0362-028X-69.5.1046
   Pathirana HNKS, 2019, INDIAN J FISH, V66, P86, DOI 10.21077/ijf.2019.66.2.85023-12
   Piras A, 2021, NAT PROD RES, V35, P993, DOI 10.1080/14786419.2019.1610755
   Popovic-Djordjevic J, 2019, IND CROP PROD, V128, P162, DOI 10.1016/j.indcrop.2018.11.003
   Prins Cláudia L, 2010, BRAZ. J. PLANT PHYSIOL., V22, P91, DOI 10.1590/S1677-04202010000200003
   Pristov KE, 2019, CLIN MICROBIOL INFEC, V25, P792, DOI 10.1016/j.cmi.2019.03.028
   Rao JJ, 2019, ANNU REV FOOD SCI T, V10, P365, DOI 10.1146/annurev-food-032818-121727
   Reyes-Jurado F, 2020, CRIT REV FOOD SCI, V60, P1641, DOI 10.1080/10408398.2019.1586641
   Ridder M., 2020, ESSENTIAL OILS MARKE, V0, P0
   Sanchez JL, 2019, EMIR J FOOD AGR, V31, P779, DOI 10.9755/ejfa.2019.v31.i10.2019
   Sandri IG, 2007, FOOD CHEM, V103, P823, DOI 10.1016/j.foodchem.2006.09.032
   Saroj A, 2019, SN APPL SCI, V1, P0, DOI 10.1007/s42452-019-1207-8
   Selmi Slimen, 2017, PATHOPHYSIOLOGY, V24, P297, DOI 10.1016/j.pathophys.2017.08.002
   Shahrokh Z., 2019, BIOACT CARBOHYDR DIE, V19, P0, DOI 10.1016/j.bcdf.2019.100193
   Snoussi M, 2016, MICROB PATHOGENESIS, V90, P13, DOI 10.1016/j.micpath.2015.11.004
   Soares JC, 2011, INT J FOOD MICROBIOL, V146, P123, DOI 10.1016/j.ijfoodmicro.2011.02.008
   Spampinato C, 2013, BIOMED RES INT, V2013, P0, DOI 10.1155/2013/204237
   Statista, 2019, IMP VAL ESS OILS RES, V0, P0
   Tang YW, 2010, CLIN LAB MED, V30, P179, DOI 10.1016/j.cll.2010.01.005
   Tariq S, 2019, MICROB PATHOGENESIS, V134, P0, DOI 10.1016/j.micpath.2019.103580
   Teixeira SD, 2016, BRAZ ARCH BIOL TECHN, V59, P0, DOI 10.1590/1678-4324-2016150043
   Ultee A, 2002, APPL ENVIRON MICROB, V68, P1561, DOI 10.1128/AEM.68.4.1561-1568.2002
   Valdivieso-Ugarte M, 2019, NUTRIENTS, V11, P0, DOI 10.3390/nu11112786
   Vieira AJ, 2018, CHEM-BIOL INTERACT, V283, P97, DOI 10.1016/j.cbi.2018.02.007
   Wild CP, 2010, CARCINOGENESIS, V31, P71, DOI 10.1093/carcin/bgp264
   Winska K, 2019, MOLECULES, V24, P0, DOI 10.3390/molecules24112130
   Wojtunik KA, 2014, J AGR FOOD CHEM, V62, P9088, DOI 10.1021/jf502857s
   Wongkattiya Nalin, 2019, J COMPLEMENT INTEGR MED, V16, P0, DOI 10.1515/jcim-2018-0195
   Yu ZH, 2020, FITOTERAPIA, V140, P0, DOI 10.1016/j.fitote.2019.104433
   Zhang MR, 2019, BMC INFECT DIS, V19, P0, DOI 10.1186/s12879-019-4612-0
NR 106
TC 10
Z9 10
U1 4
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1541-4337
EI 
J9 COMPR REV FOOD SCI F
JI Compr. Rev. Food. Sci. Food Saf.
PD JUL 15
PY 2021
VL 20
IS 4
BP 3136
EP 3163
DI 10.1111/1541-4337.12773
EA JUN 2021
PG 28
WC Food Science & Technology
SC Food Science & Technology
GA TG6XQ
UT WOS:000661162600001
PM 34125485
DA 2023-04-26
ER

PT J
AU Jimenez, J
   Navarro, L
   Quintero, CG
   Pardo, M
AF Jimenez, Jamer
   Navarro, Loraine
   Quintero M, Christian G.
   Pardo, Mauricio
TI Multivariate Statistical Analysis for Training Process Optimization in Neural Networks-Based Forecasting Models
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE neural networks design; parameter optimization; multivariate statistical analysis
ID methodology
AB Data forecasting is very important for electrical analysis development, transport dimensionality, marketing strategies, etc. Hence, low error levels are required. However, in some cases data have dissimilar behaviors that can vary depending on such exogenous variables as the type of day, weather conditions, and geographical area, among others. Commonly, computational intelligence techniques (e.g., artificial neural networks) are used due to their generalization capabilities. In spite of the above, they do not have a unique way to reach optimal performance. For this reason, it is necessary to analyze the data's behavior and their statistical features in order to identify those significant factors in the training process to guarantee a better performance. In this paper is proposed an experimental method for identifying those significant factors in the forecasting model for time series data and measure their effects on the Akaike information criterion (AIC) and the Mean Absolute Percentage Error (MAPE). Additionally, we seek to establish optimal parameters for the proper selection of the artificial neural network model.
C1 [Jimenez, Jamer; Navarro, Loraine; Quintero M, Christian G.; Pardo, Mauricio] Univ Norte, Dept Elect & Elect Engn, Barranquilla 081007, Colombia.
C3 Universidad del Norte Colombia
RP Quintero, CG (corresponding author), Univ Norte, Dept Elect & Elect Engn, Barranquilla 081007, Colombia.
EM jmares@uninorte.edu.co; lorainen@uninorte.edu.co; christianq@uninorte.edu.co; mpardo@uninorte.edu.co
FU Colombian Ministry of Science and Technology [785]
CR Attar NF, 2018, COMPUT ELECTRON AGR, V153, P334, DOI 10.1016/j.compag.2018.08.029
   Bataineh M, 2017, NEURAL NETWORKS, V95, P1, DOI 10.1016/j.neunet.2017.07.018
   Broomhead D. S., 1988, COMPLEX SYSTEMS, V2, P321
   Chouikhi N, 2018, ARXIV, V0, P0
   Ding YS, 2018, ENERGY, V154, P328, DOI 10.1016/j.energy.2018.04.133
   Gu L, 2018, NEURAL COMPUT APPL, V29, P1445, DOI 10.1007/s00521-016-2669-x
   Hacibeyoglu M, 2018, SCI PROGRAMMING-NETH, V2018, P0, DOI 10.1155/2018/1435810
   Jimenez J, 2019, IEEE LAT AM T, V17, P93, DOI 10.1109/TLA.2019.8826700
   Jimenez J, 2017, IEEE LAT AM T, V15, P400, DOI 10.1109/TLA.2017.7867168
   Mares JJ, 2020, ENERGIES, V13, P0, DOI 10.3390/en13164040
   Li CH, 2014, INT J PARALLEL PROG, V42, P505, DOI 10.1007/s10766-013-0245-x
   Liang YX, 2019, IEEE ACCESS, V7, P68034, DOI 10.1109/ACCESS.2019.2919138
   Lin JW, 2018, IEEE ACCESS, V6, P52582, DOI 10.1109/ACCESS.2018.2870189
   Lopez FJM, 2016, J COMPUT SCI-NETH, V16, P59, DOI 10.1016/j.jocs.2016.04.002
   Montgomery D, 2005, DISE O AN LISIS EXPE, V2nd ed., P0
   Orosz T, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10196653
   Rani RHJ, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0196871
   Wang LN, 2017, NEURAL NETWORKS, V93, P219, DOI 10.1016/j.neunet.2017.06.003
   Zhang Q. J., 2000, ARTECH MICR, V0, P0
NR 19
TC 2
Z9 2
U1 1
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD APR 15
PY 2021
VL 11
IS 8
BP 
EP 
DI 10.3390/app11083552
PG 13
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA RS8IJ
UT WOS:000644016400001
DA 2023-04-26
ER

PT J
AU Nefeslioglu, HA
   Tavus, B
   Er, M
   Ertugrul, G
   Ozdemir, A
   Kaya, A
   Kocaman, S
AF Nefeslioglu, Hakan A.
   Tavus, Beste
   Er, Melahat
   Ertugrul, Gamze
   Ozdemir, Aybuke
   Kaya, Alperen
   Kocaman, Sultan
TI Integration of an InSAR and ANN for Sinkhole Susceptibility Mapping: A Case Study from Kirikkale-Delice (Turkey)
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE sinkhole; susceptibility; remote sensing; InSAR; machine learning; ANN; Kirikkale-Delice (Turkey)
ID artificial neural-networks; sar interferometry; dead-sea; logistic-regression; multitemporal insar; slope instability; radar; deformation; subsidence; area
AB Suitable route determination for linear engineering structures is a fundamental problem in engineering geology. Rapid evaluation of alternative routes is essential, and novel approaches are indispensable. This study aims to integrate various InSAR (Interferometric Synthetic Aperture Radar) techniques for sinkhole susceptibility mapping in the Kirikkale-Delice Region of Turkey, in which sinkhole formations have been observed in evaporitic units and a high-speed train railway route has been planned. Nine months (2019-2020) of ground deformations were determined using data from the European Space Agency's (ESA) Sentinel-1A/1B satellites. A sinkhole inventory was prepared manually using satellite optical imagery and employed in an ANN (Artificial Neural Network) model with topographic conditioning factors derived from InSAR digital elevation models (DEMs) and morphological lineaments. The results indicate that high deformation areas on the vertical displacement map and sinkhole-prone areas on the sinkhole susceptibility map (SSM) almost coincide. InSAR techniques are useful for long-term deformation monitoring and can be successfully associated in sinkhole susceptibility mapping using an ANN. Continuous monitoring is recommended for existing sinkholes and highly susceptible areas, and SSMs should be updated with new results. Up-to-date SSMs are crucial for the route selection, planning, and construction of important transportation elements, as well as settlement site selection, in such regions.
C1 [Nefeslioglu, Hakan A.; Er, Melahat; Ozdemir, Aybuke] Hacettepe Univ, Dept Geol Engn, TR-06800 Beytepe, Turkey.
   [Tavus, Beste; Ertugrul, Gamze; Kaya, Alperen; Kocaman, Sultan] Hacettepe Univ, Dept Geomat Engn, TR-06800 Beytepe, Turkey.
C3 Hacettepe University; Hacettepe University
RP Nefeslioglu, HA (corresponding author), Hacettepe Univ, Dept Geol Engn, TR-06800 Beytepe, Turkey.
EM hanefeslioglu@hacettepe.edu.tr; beste.tavus@hacettepe.edu.tr; melahat.er@hacettepe.edu.tr; gamzeertugrul@hacettepe.edu.tr; aybukeozdemir@hacettepe.edu.tr; alperenkaya@hacettepe.edu.tr; sultankocaman@hacettepe.edu.tr
CR Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   [Anonymous], 2020, SNAP TOOL SENTINEL A, V0, P0
   [Anonymous], 1997, ARTIFICIAL NEURAL NE, V0, P0
   [Anonymous], 2020, SAGA GIS TOOL LIB DO, V0, P0
   ASF, 2020, SOFTW U AL US AL SAT, V0, P0
   Atzori S, 2015, GEOPHYS RES LETT, V42, P8383, DOI 10.1002/2015GL066053
   Baer G, 2002, GEOL SOC AM BULL, V114, P12, DOI 10.1130/0016-7606(2002)114<0012:TLPOEI>2.0.CO;2
   Bakon M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111892
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Benson RC, 2003, GEOTECH SP, V0, P31
   Berardino P, 2003, ENG GEOL, V68, P31, DOI 10.1016/S0013-7952(02)00197-7
   Bovenga F, 2006, ENG GEOL, V88, P218, DOI 10.1016/j.enggeo.2006.09.015
   Bozzano F, 2020, J MAPS, V16, P126, DOI 10.1080/17445647.2019.1702596
   Bozzano F, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030267
   Braun A., 2020, GISCI REMOTE SENS, V0, P0
   Castaneda C, 2011, INT J REMOTE SENS, V32, P1861, DOI 10.1080/01431161003631584
   Castaneda C, 2009, EARTH SURF PROC LAND, V34, P1562, DOI 10.1002/esp.1848
   Chang L, 2014, REMOTE SENS ENVIRON, V147, P56, DOI 10.1016/j.rse.2014.03.002
   Chang TC, 2006, ENG GEOL, V85, P270, DOI 10.1016/j.enggeo.2006.02.007
   Closson D, 2005, ENVIRON GEOL, V47, P290, DOI 10.1007/s00254-004-1155-4
   Closson D, 2009, GEODIN ACTA, V22-23, P65, DOI 10.3166/ga.23.65-78
   De Zan F, 2006, IEEE T GEOSCI REMOTE, V44, P2352, DOI 10.1109/TGRS.2006.873853
   Derauw D., 1996, FRING 96 ESA WORKSH, V0, P0
   El Hajj M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010031
   Elmahdy SI, 2022, GEOCARTO INT, V37, P315, DOI 10.1080/10106049.2020.1716398
   ESA, 2013, EUROPEAN SPACE AGENC, V0, P0
   Fanos AM, 2019, CATENA, V172, P435, DOI 10.1016/j.catena.2018.09.012
   Ferretti A, 2001, IEEE T GEOSCI REMOTE, V39, P8, DOI 10.1109/36.898661
   Floris M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020165
   Galve JP, 2015, GEOMORPHOLOGY, V229, P30, DOI 10.1016/j.geomorph.2014.07.035
   Geudtner D, 2016, EUSAR PROC, V0, P65
   GOLDSTEIN RM, 1988, RADIO SCI, V23, P713, DOI 10.1029/RS023i004p00713
   Gruber S, 2009, DEV SOIL SCI, V33, P171, DOI 10.1016/S0166-2481(08)00007-X
   Guerrero J, 2004, ENG GEOL, V72, P309, DOI 10.1016/j.enggeo.2003.10.002
   Gutierrez F, 2008, ENVIRON GEOL, V53, P1007, DOI 10.1007/s00254-007-0728-4
   Gutierrez F, 2011, GEOMORPHOLOGY, V134, P144, DOI 10.1016/j.geomorph.2011.01.018
   Hao JM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11182126
   HECHT-NIELSEN R., 1990, NEUROCOMPUTING READI, V0, P0
   Intrieri E, 2015, GEOMORPHOLOGY, V241, P304, DOI 10.1016/j.geomorph.2015.04.018
   Kang Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101046
   Kara H., 1990, KIRSEHIR G17 PAFTASI, V0, P0
   Kim JW, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8040313
   Malinowska AA, 2019, ENG GEOL, V262, P0, DOI 10.1016/j.enggeo.2019.105336
   Mohammadi A, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20247214
   MOORE ID, 1986, WATER RESOUR RES, V22, P1350, DOI 10.1029/WR022i008p01350
   Nam BH, 2020, ENG GEOL, V271, P0, DOI 10.1016/j.enggeo.2020.105610
   Nefeslioglu HA, 2008, ENG GEOL, V97, P171, DOI 10.1016/j.enggeo.2008.01.004
   Negnevitsky M, 2002, ARTIF INTELL, V0, P394
   Nikolakopoulos K. G., 2015, EUR J GEOGR, V6, P52
   Nof RN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010089
   Olaya V, 2009, DEV SOIL SCI, V33, P293, DOI 10.1016/S0166-2481(08)00012-3
   Paine JG, 2012, J ENVIRON ENG GEOPH, V17, P75
   Pepe A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110911
   Plank S, 2014, REMOTE SENS-BASEL, V6, P4870, DOI 10.3390/rs6064870
   Ren HR, 2020, INT J APPL EARTH OBS, V92, P0, DOI 10.1016/j.jag.2020.102115
   Sefercik UG, 2018, PFG-J PHOTOGRAMM REM, V86, P141, DOI 10.1007/s41064-018-0054-3
   Subedi P, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-43705-6
   Sun WJ, 2020, NAT HAZARDS, V103, P2631, DOI 10.1007/s11069-020-04124-3
   Theron A, 2017, IEEE GEOSCI REMOTE S, V14, P871, DOI 10.1109/LGRS.2017.2684905
   Waltham T., 2005, SINKHOLES SUBSIDENCE, V0, P382
   Wasowski J, 2014, ENG GEOL, V174, P103, DOI 10.1016/j.enggeo.2014.03.003
   Wright TJ, 2004, GEOPHYS RES LETT, V31, P0, DOI 10.1029/2003GL018827
   Zhao JW, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090897
   Zheng MN, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091392
NR 64
TC 2
Z9 2
U1 7
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD MAR 15
PY 2021
VL 10
IS 3
BP 
EP 
DI 10.3390/ijgi10030119
PG 16
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RD8HK
UT WOS:000633711500001
DA 2023-04-26
ER

PT J
AU Tang, Y
   Shao, ZF
   Huang, X
   Cai, BW
AF Tang, Yun
   Shao, Zhenfeng
   Huang, Xiao
   Cai, Bowen
TI Mapping Impervious Surface Areas Using Time-Series Nighttime Light and MODIS Imagery
SO REMOTE SENSING
LA English
DT Article
DE impervious surface; nighttime light data; MODIS; spatiotemporal dynamics
ID electric-power consumption; remote-sensing images; pearl river delta; urban heat-island; dmsp-ols; spatiotemporal dynamics; large-scale; human settlement; integrated use; china
AB Mapping impervious surface area (ISA) dynamics at the regional and global scales is an important task that supports the management of the urban environment and urban ecological systems. In this study, we aimed to develop a new method for ISA percentage (ISA%) mapping using Nighttime Light (NTL) and MODIS products. The proposed method consists of three major steps. First, we calculated the Enhanced Vegetation Index (EVI)-adjusted NTL index (EANTLI) and performed intra-annual and inter-annual corrections on the DMSP-OLS data. Second, based on the geographically weighted regression (GWR) model, we built a consistent NTL product from 2000 to 2019 by performing an intercalibration between DMSP-OLS and VIIRS images. Third, we adopted a GA-BP neural network model to monitor ISA% dynamics using NTL imagery, MODIS imagery, and population data. Taking the Guangdong-Hong Kong-Macao Greater Bay as the study area, our results indicate that the ISA% in our study area increased from 7.97% in 2000 to 17.11% in 2019, with a mean absolute error (MAE) of 0.0647, root mean square error (RMSE) of 0.1003, Pearson's coefficient of 0.9613, and R-2 (R-squared) of 0.9239. Specifically, these results demonstrate the effectiveness of the proposed method in mapping ISA and investigating ISA dynamics using temporal features extracted from consistent NTL and MODIS products. The proposed method is feasible when generating ISA% at a large scale at high frequency, given the ease of implementation and the availability of input data sources.
C1 [Tang, Yun; Shao, Zhenfeng; Cai, Bowen] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Huang, Xiao] Univ Arkansas, Dept Geosci, Fayetteville, AR 72701 USA.
C3 Wuhan University; University of Arkansas System; University of Arkansas Fayetteville
RP Shao, ZF (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM tangyun23@whu.edu.cn; shaozhenfeng@whu.edu.cn; xh010@uark.edu; caibowen@whu.edu.cn
FU National Key Research and Development Program of China [2018YFB2100501]; Key Research and Development Program of Yunnan province in China [2018IB023]; National Natural Science Foundation of China [42090012, 41771452, 41771454, 41890820]
CR Agnew J, 2008, ENVIRON PLANN A, V40, P2285, DOI 10.1068/a41200
   Bennie J, 2014, SCI REP-UK, V4, P0, DOI 10.1038/srep03789
   Cao WP, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111730
   Cao X, 2014, INT J APPL EARTH OBS, V28, P193, DOI 10.1016/j.jag.2013.12.004
   Cao X, 2009, REMOTE SENS ENVIRON, V113, P2205, DOI 10.1016/j.rse.2009.06.001
   Chen ZQ, 2019, IEEE J-STARS, V12, P1143, DOI 10.1109/JSTARS.2019.2900457
   Chithra S. V., 2015, INT J ENG SCI INVENT, V4, P2319
   Cleveland R. B., 1990, J OFF STAT, V6, P3
   Cristina S, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060449
   Deng CB, 2013, REMOTE SENS ENVIRON, V131, P262, DOI 10.1016/j.rse.2012.12.020
   Ding SF, 2011, ARTIF INTELL REV, V36, P153, DOI 10.1007/s10462-011-9208-z
   Elvidge C.D., 2013, P ASIA PACIFIC ADV N, V35, P0, DOI 10.7125/APAN.35.7
   Elvidge CD, 1999, REMOTE SENS ENVIRON, V68, P77, DOI 10.1016/S0034-4257(98)00098-4
   Elvidge CD, 2007, SENSORS-BASEL, V7, P1962, DOI 10.3390/s7091962
   Garofalo D., 2001, REMOTE SENSING REV, V20, P227, DOI 10.1080/02757250109532436
   Gong P, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111510
   Gong P, 2019, SCI BULL, V64, P370, DOI 10.1016/j.scib.2019.03.002
   Guo W, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040375
   Guo W, 2015, REMOTE SENS-BASEL, V7, P12459, DOI 10.3390/rs70912459
   Haustein M.D., 2010, URBAN RURAL ENV EFFE, V0, P0
   He CY, 2010, REMOTE SENS LETT, V1, P213, DOI 10.1080/01431161.2010.481681
   Henderson M, 2003, INT J REMOTE SENS, V24, P595, DOI 10.1080/01431160304982
   Hu T, 2019, APPL ENERG, V240, P778, DOI 10.1016/j.apenergy.2019.02.062
   Huang X, 2019, NAT HAZARD EARTH SYS, V19, P2141, DOI 10.5194/nhess-19-2141-2019
   Imhoff ML, 1997, REMOTE SENS ENVIRON, V61, P361
   Jiang B, 2010, REMOTE SENS ENVIRON, V114, P1432, DOI 10.1016/j.rse.2010.01.026
   Kaufmann RK, 2007, J CLIMATE, V20, P2299, DOI 10.1175/JCLI4109.1
   Kuang WH, 2013, CHINESE SCI BULL, V58, P1691, DOI 10.1007/s11434-012-5568-2
   Levin N, 2017, REMOTE SENS ENVIRON, V190, P366, DOI 10.1016/j.rse.2017.01.006
   Leyk S, 2019, EARTH SYST SCI DATA, V11, P1385, DOI 10.5194/essd-11-1385-2019
   Li KN, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101650
   Li QT, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070578
   Li X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060858
   Li X, 2017, INT J REMOTE SENS, V38, P5934, DOI 10.1080/01431161.2017.1331476
   Li X, 2014, INT J REMOTE SENS, V35, P6648, DOI 10.1080/01431161.2014.971469
   Li XC, 2017, GLOBAL CHANGE BIOL, V23, P2818, DOI 10.1111/gcb.13562
   Liu C, 2017, IEEE GEOSCI REMOTE S, V14, P1017, DOI 10.1109/LGRS.2017.2692799
   Lu DS, 2008, REMOTE SENS ENVIRON, V112, P3668, DOI 10.1016/j.rse.2008.05.009
   Lu DS, 2011, ISPRS J PHOTOGRAMM, V66, P798, DOI 10.1016/j.isprsjprs.2011.08.004
   National Bureau of Statistics of China, 2020, HUBEI STAT YB, V0, P0
   Nations U., 2014, WORLD URB PROSP 2014, V32, P0
   Pok S, 2017, ISPRS J PHOTOGRAMM, V133, P104, DOI 10.1016/j.isprsjprs.2017.10.005
   Powell SL, 2008, REMOTE SENS ENVIRON, V112, P1895, DOI 10.1016/j.rse.2007.09.010
   Sexton JO, 2013, REMOTE SENS ENVIRON, V129, P42, DOI 10.1016/j.rse.2012.10.025
   Shao ZF, 2019, REMOTE SENS ENVIRON, V232, P0, DOI 10.1016/j.rse.2019.111338
   Shao ZF, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110945
   Shao ZF, 2014, REMOTE SENS-BASEL, V6, P9359, DOI 10.3390/rs6109359
   Shi KF, 2016, APPL ENERG, V184, P450, DOI 10.1016/j.apenergy.2016.10.032
   Shi KF, 2014, REMOTE SENS-BASEL, V6, P1705, DOI 10.3390/rs6021705
   Small C, 2005, REMOTE SENS ENVIRON, V96, P277, DOI 10.1016/j.rse.2005.02.002
   Small C, 2013, INT J APPL EARTH OBS, V22, P40, DOI 10.1016/j.jag.2012.02.009
   Srinivasan V, 2013, GLOBAL ENVIRON CHANG, V23, P229, DOI 10.1016/j.gloenvcha.2012.10.002
   Tatem AJ, 2017, SCI DATA, V4, P0, DOI 10.1038/sdata.2017.4
   Wang SX, 2016, RENEW ENERG, V94, P629, DOI 10.1016/j.renene.2016.03.103
   Wang YL, 2019, IEEE GEOSC REM SEN M, V7, P64, DOI 10.1109/MGRS.2019.2927260
   Weng QH, 2008, IEEE T GEOSCI REMOTE, V46, P2397, DOI 10.1109/TGRS.2008.917601
   Weng QH, 2008, INT J REMOTE SENS, V29, P3209, DOI 10.1080/01431160701469024
   Weng QH, 2012, REMOTE SENS ENVIRON, V117, P34, DOI 10.1016/j.rse.2011.02.030
   Wu CS, 2003, REMOTE SENS ENVIRON, V84, P493, DOI 10.1016/S0034-4257(02)00136-0
   Xie YH, 2016, REMOTE SENS ENVIRON, V187, P1, DOI 10.1016/j.rse.2016.10.002
   Yang G, 2020, SCI TOTAL ENVIRON, V715, P0, DOI 10.1016/j.scitotenv.2020.136763
   Yuan F, 2007, REMOTE SENS ENVIRON, V106, P375, DOI 10.1016/j.rse.2006.09.003
   Zhang L, 2017, REMOTE SENS ENVIRON, V201, P99, DOI 10.1016/j.rse.2017.08.036
   Zhang L, 2016, ISPRS J PHOTOGRAMM, V113, P86, DOI 10.1016/j.isprsjprs.2016.01.003
   Zhang QL, 2013, REMOTE SENS ENVIRON, V129, P32, DOI 10.1016/j.rse.2012.10.022
   Zheng QM, 2019, ISPRS J PHOTOGRAMM, V153, P36, DOI 10.1016/j.isprsjprs.2019.04.019
   Zhou YY, 2015, ENVIRON RES LETT, V10, P0, DOI 10.1088/1748-9326/10/5/054011
   Zhou YY, 2014, REMOTE SENS ENVIRON, V147, P173, DOI 10.1016/j.rse.2014.03.004
   Zhu Z, 2019, REMOTE SENS ENVIRON, V228, P164, DOI 10.1016/j.rse.2019.04.020
   Zhuo L, 2015, INT J REMOTE SENS, V36, P4114, DOI 10.1080/01431161.2015.1073861
NR 70
TC 10
Z9 10
U1 8
U2 36
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY 15
PY 2021
VL 13
IS 10
BP 
EP 
DI 10.3390/rs13101900
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA ST7KZ
UT WOS:000662619900001
DA 2023-04-26
ER

PT J
AU Ali, S
   Liu, D
   Fu, Q
   Cheema, MJM
   Pham, QB
   Rahaman, MM
   Dang, TD
   Anh, DT
AF Ali, Shoaib
   Liu, Dong
   Fu, Qiang
   Cheema, Muhammad Jehanzeb Masud
   Quoc Bao Pham
   Rahaman, Md Mafuzur
   Thanh Duc Dang
   Duong Tran Anh
TI Improving the Resolution of GRACE Data for Spatio-Temporal Groundwater Storage Assessment
SO REMOTE SENSING
LA English
DT Article
DE GRACE; GLDAS; terrestrial water storage; groundwater storage; random forest model; downscaling
ID water storage; indus basin; satellite; precipitation; depletion; china; irrigation; validation; products; rainfall
AB Groundwater has a significant contribution to water storage and is considered to be one of the sources for agricultural irrigation; industrial; and domestic water use. The Gravity Recovery and Climate Experiment (GRACE) satellite provides a unique opportunity to evaluate terrestrial water storage (TWS) and groundwater storage (GWS) at a large spatial scale. However; the coarse resolution of GRACE limits its ability to investigate the water storage change at a small scale. It is; therefore; needed to improve the resolution of GRACE data at a spatial scale applicable for regional-level studies. In this study; a machine-learning-based downscaling random forest model (RFM) and artificial neural network (ANN) model were developed to downscale GRACE data (TWS and GWS) from 1 degrees to a higher resolution (0.25 degrees). The spatial maps of downscaled TWS and GWS were generated over the Indus basin irrigation system (IBIS). Variations in TWS of GRACE in combination with geospatial variables; including digital elevation model (DEM), slope; aspect; and hydrological variables; including soil moisture; evapotranspiration; rainfall; surface runoff; canopy water; and temperature; were used. The geospatial and hydrological variables could potentially contribute to; or correlate with; GRACE TWS. The RFM outperformed the ANN model and results show Pearson correlation coefficient (R) (0.97), root mean square error (RMSE) (11.83 mm), mean absolute error (MAE) (7.71 mm), and Nash-Sutcliffe efficiency (NSE) (0.94) while comparing with the training dataset from 2003 to 2016. These results indicate the suitability of RFM to downscale GRACE data at a regional scale. The downscaled GWS data were analyzed; and we observed that the region has lost GWS of about -9.54 +/- 1.27 km(3) at the rate of -0.68 +/- 0.09 km(3)/year from 2003 to 2016. The validation results showed that R between downscaled GWS and observational wells GWS are 0.67 and 0.77 at seasonal and annual scales with a confidence level of 95%, respectively. It can; therefore; be concluded that the RFM has the potential to downscale GRACE data at a spatial scale suitable to predict GWS at regional scales.
C1 [Ali, Shoaib; Liu, Dong; Fu, Qiang] Northeast Agr Univ, Sch Water Conservancy & Civil Engn, Harbin 150030, Peoples R China.
   [Liu, Dong] Northeast Agr Univ, Minist Agr, Key Lab Effect Utilizat Agr Water Resources, Harbin 150030, Peoples R China.
   [Liu, Dong] Northeast Agr Univ, Heilongjiang Prov Key Lab Water Resources & Water, Harbin 150030, Peoples R China.
   [Liu, Dong] Northeast Agr Univ, Key Lab Water Saving Agr Ordinary Univ Heilongjia, Harbin 150030, Peoples R China.
   [Cheema, Muhammad Jehanzeb Masud] Pir Mehr Ali Shah Arid Agr Univ, Fac Agr Engn & Technol, Rawalpindi 46000, Pakistan.
   [Quoc Bao Pham] Thu Dau Mot Univ, Inst Appl Technol, Thu Dau Mot City 75000, Vietnam.
   [Rahaman, Md Mafuzur] AECOM, 2380 McGee St Suite 200, Kansas City, MO 64108 USA.
   [Thanh Duc Dang] Thuyloi Univ, Inst Water & Environm Res, Ho Chi Minh City 08084, Vietnam.
   [Duong Tran Anh] Univ S Florida, Dept Civil & Environm Engn, 4202 E Fowler Ave, Tampa, FL 33620 USA.
C3 Northeast Agricultural University - China; Ministry of Agriculture & Rural Affairs; Northeast Agricultural University - China; Northeast Agricultural University - China; Northeast Agricultural University - China; Arid Agriculture University; Thu Dau Mot University; Thuyloi University; State University System of Florida; University of South Florida
RP Liu, D (corresponding author), Northeast Agr Univ, Sch Water Conservancy & Civil Engn, Harbin 150030, Peoples R China.; Liu, D (corresponding author), Northeast Agr Univ, Minist Agr, Key Lab Effect Utilizat Agr Water Resources, Harbin 150030, Peoples R China.; Liu, D (corresponding author), Northeast Agr Univ, Heilongjiang Prov Key Lab Water Resources & Water, Harbin 150030, Peoples R China.; Liu, D (corresponding author), Northeast Agr Univ, Key Lab Water Saving Agr Ordinary Univ Heilongjia, Harbin 150030, Peoples R China.
EM engr.shoaib.ali@neau.edu.cn; liudong@neau.edu.cn; fuqiang@neau.edu.cn; mjm.cheema@uaar.edu.pk; phambaoquoc@tdmu.edu.vn; mafuzur.rahaman@aecom.com; ddt21@usf.edu; duonganhtran@usf.edu
FU National Key R&D Program of China [2017YFC0406002]; National Natural Science Foundation of China [51579044, 41071053]; National Science Fund for Distinguished Young Scholars [51825901]; Natural Science Foundation of Heilongjiang Province [E2017007]
CR Ahmad S., 2008, SCENARIOS SURFACE GR, V0, P0
   Ahmad S., 2008, P NAT C ORG AGR FDN, V0, P0
   Alley WM, 2015, GROUNDWATER, V53, P826, DOI 10.1111/gwat.12379
   [Anonymous], 2015, EC ANAL 2015 DROUGHT, V0, P0
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Castellazzi P, 2018, REMOTE SENS ENVIRON, V205, P408, DOI 10.1016/j.rse.2017.11.025
   Cheema MJM, 2014, GROUNDWATER, V52, P25, DOI 10.1111/gwat.12027
   Cheema MJM, 2012, INT J REMOTE SENS, V33, P2603, DOI 10.1080/01431161.2011.617397
   Chen L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242979
   Chen SD, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11071401
   Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1
   Davis JL, 2004, GEOPHYS RES LETT, V31, P0, DOI 10.1029/2004GL021435
   Dinku T, 2007, INT J REMOTE SENS, V28, P1503, DOI 10.1080/01431160600954688
   Duan Z, 2012, INT GEOSCI REMOTE SE, V0, PP3696, DOI 10.1109/IGARSS.2012.6350613
   Famiglietti JS, 2011, GEOPHYS RES LETT, V38, P0, DOI 10.1029/2010GL046442
   Feng W, 2013, WATER RESOUR RES, V49, P2110, DOI 10.1002/wrcr.20192
   Fukuda S, 2014, J FOOD ENG, V131, P7, DOI 10.1016/j.jfoodeng.2014.01.007
   Gemitzi A, 2017, P 15 INT C ENV SCI T, V0, P0
   Gholami V, 2018, CATENA, V163, P210, DOI 10.1016/j.catena.2017.12.027
   Greenman D.W., 1967, GROUND WATER HYDROLO, V0, P0
   Habib Z., 2004, THESIS ENGREF PARIS, V0, P0
   Iqbal N, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-5846-1
   Iqbal N, 2016, IEEE J-STARS, V9, P3524, DOI 10.1109/JSTARS.2016.2574378
   *IUCN, 2010, IND WAT TREAT GROUND, V0, P0
   Ji X, 2012, J MT SCI-ENGL, V9, P628, DOI 10.1007/s11629-012-2283-z
   Karaseva MO, 2012, THEOR APPL CLIMATOL, V108, P147, DOI 10.1007/s00704-011-0509-6
   KENDALL M. G., 1948, RANK CORRELATION METHODS., V0, P0
   Landerer FW, 2012, WATER RESOUR RES, V48, P0, DOI 10.1029/2011WR011453
   Li BL, 2012, J HYDROL, V446, P103, DOI 10.1016/j.jhydrol.2012.04.035
   Li W, 2019, IEEE J-STARS, V12, P2299, DOI 10.1109/JSTARS.2019.2896923
   [刘昌明 Liu Changming], 2012, 水科学进展 ADVANCES IN WATER SCIENCE, V23, P427
   [刘永和 Liu Yonghe], 2011, 地球科学进展 ADVANCE IN EARTH SCIENCES, V26, P837
   Lo MH, 2013, GEOPHYS RES LETT, V40, P301, DOI 10.1002/grl.50108
   Long D, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep24398
   Long D, 2015, REMOTE SENS ENVIRON, V168, P177, DOI 10.1016/j.rse.2015.07.003
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415
   Mann HB, 1945, ECONOMETRICA, V13, P245, DOI 10.2307/1907187
   Mekonnen D, 2016, INT J WATER RESOUR D, V32, P459, DOI 10.1080/07900627.2015.1133402
   Milewski AM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232756
   Miro ME, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010143
   Mohaghegi S, 2005, 2005 IEEE SWARM INTELLIGENCE SYMPOSIUM, V0, P381
   Muhammad Arshad, 2007, INTERNATIONAL JOURNAL OF AGRICULTURE AND BIOLOGY, V9, P143
   Ning S., 2014, J JPN SOC CIVIL ENG, V70, PI_133, DOI 10.2208/jscejhe.70.I_133
   Ojeh E, 2006, HYDROLOGY INDUS BASI, V0, P0
   PBS, 2014, PAK STAT YB, V0, P0
   Qureshi AS, 2008, AGR WATER MANAGE, V95, P1, DOI 10.1016/j.agwat.2007.09.014
   R CORE TEAM, 2017, R LANG ENV STAT COMP, V0, P0
   Rahaman MM, 2019, HYDROLOGY-BASEL, V6, P0, DOI 10.3390/hydrology6010019
   Ramillien G, 2005, EARTH PLANET SC LETT, V235, P283, DOI 10.1016/j.epsl.2005.04.005
   Reager JT, 2013, WATER RESOUR RES, V49, P3314, DOI 10.1002/wrcr.20264
   Rehman A., 2015, GLOB ADV RES J AGR S, V4, P827
   Richey AS, 2015, WATER RESOUR RES, V51, P5217, DOI 10.1002/2015WR017349
   Rodell M, 2018, NATURE, V557, P650, DOI 10.1038/s41586-018-0123-1
   Rodell M, 2004, B AM METEOROL SOC, V85, P381, DOI 10.1175/BAMS-85-3-381
   Rodell M, 2007, HYDROGEOL J, V15, P159, DOI 10.1007/s10040-006-0103-7
   Rodell M, 2009, NATURE, V460, P999, DOI 10.1038/nature08238
   Sahour H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030533
   Scanlon BR, 2012, WATER RESOUR RES, V48, P0, DOI 10.1029/2011WR011312
   Scanlon BR, 2018, P NATL ACAD SCI USA, V115, PE1080, DOI 10.1073/pnas.1704665115
   Schmidt R, 2006, GLOBAL PLANET CHANGE, V50, P112, DOI 10.1016/j.gloplacha.2004.11.018
   Seo JY, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11091953
   Seyoum WM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070824
   Seyoum WM, 2017, ADV WATER RESOUR, V110, P279, DOI 10.1016/j.advwatres.2017.10.021
   Shi YL, 2015, REMOTE SENS-BASEL, V7, P5849, DOI 10.3390/rs70505849
   Siebert S, 2010, J HYDROL, V384, P198, DOI 10.1016/j.jhydrol.2009.07.031
   Siridhar V, 2009, ECOHYDROLOGY, V2, P195, DOI 10.1002/eco.61
   Strassberg G, 2007, GEOPHYS RES LETT, V34, P0, DOI 10.1029/2007GL030139
   Sun AY, 2013, WATER RESOUR RES, V49, P5900, DOI 10.1002/wrcr.20421
   Sun AY, 2010, GEOPHYS RES LETT, V37, P0, DOI 10.1029/2010GL043231
   Swenson S, 2003, WATER RESOUR RES, V39, P0, DOI 10.1029/2002WR001808
   Syed TH, 2008, WATER RESOUR RES, V44, P0, DOI 10.1029/2006WR005779
   Tang Y, 2017, J HYDROL, V551, P397, DOI 10.1016/j.jhydrol.2017.06.021
   Tiwari VM, 2009, GEOPHYS RES LETT, V36, P0, DOI 10.1029/2009GL039401
   Turban E., 2008, BUSINESS INTELLIGENC, V0, P0
   Ullah M.K., 2001, SPATIAL DISTRIBUTION, V24, P0
   Wahr J, 1998, J GEOPHYS RES-SOL EA, V103, P30205, DOI 10.1029/98JB02844
   Wang LA, 2016, CROP J, V4, P212, DOI 10.1016/j.cj.2016.01.008
   Wang W, 2016, J HYDROMETEOROL, V17, P2815, DOI 10.1175/JHM-D-15-0191.1
   Wang Y., 2010, THESIS XINJIANG AGR, V0, P0
   Watto MA, 2016, INT J RIVER BASIN MA, V14, P447, DOI 10.1080/15715124.2016.1204154
   World Commission on Dams (WCD), 2000, WCD CASE STUDY, V0, P0
   Yang P, 2018, HYDROL RES, V49, P1594, DOI 10.2166/nh.2018.074
   [叶叔华 YE Shuhua], 2007, 地球物理学进展 PROGRESS IN GEOPHYSISCS, V22, P1030
   Yeh PJF, 2006, WATER RESOUR RES, V42, P0, DOI 10.1029/2006WR005374
   Yin WJ, 2018, J GEOPHYS RES-ATMOS, V123, P5973, DOI 10.1029/2017JD027468
   Zhang JX, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030523
   Zhang M.Y., 2013, WATER SCI TECHNOL, V11, P118
   Zolfaghari A, 2020, J PRESS VESS-T ASME, V142, P0, DOI 10.1115/1.4045729
NR 88
TC 23
Z9 23
U1 7
U2 47
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2021
VL 13
IS 17
BP 
EP 
DI 10.3390/rs13173513
PG 27
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UO1UW
UT WOS:000694488000001
DA 2023-04-26
ER

PT J
AU Gao, YH
   Gao, F
   Dong, JY
   Du, Q
   Li, HC
AF Gao, Yunhao
   Gao, Feng
   Dong, Junyu
   Du, Qian
   Li, Heng-Chao
TI Synthetic Aperture Radar Image Change Detection via Siamese Adaptive Fusion Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Radar polarimetry; Correlation; Synthetic aperture radar; Convolutional neural networks; Task analysis; Speckle; Attention mechanism; change detection; deep learning; siamese adaptive fusion network (SAFNet); synthetic aperture radar (SAR)
ID automatic change detection; unsupervised change detection
AB Synthetic aperture radar (SAR) image change detection is a critical yet challenging task in the field of remote sensing image analysis. The task is nontrivial due to the following challenges: First, intrinsic speckle noise of SAR images inevitably degrades the neural network because of error gradient accumulation. Furthermore, the correlation among various levels or scales of feature maps is difficult to be achieved through summation or concatenation. Toward this end, we proposed a siamese adaptive fusion (AF) network for SAR image change detection. To be more specific, two-branch CNN is utilized to extract high-level semantic features of multitemporal SAR images. Besides, an AF module is designed to adaptively combine multiscale responses in convolutional layers. Therefore, the complementary information is exploited, and feature learning in change detection is further improved. Moreover, a correlation layer is designed to further explore the correlation between multitemporal images. Thereafter, robust feature representation is utilized for classification through a fully connected layer with softmax. Experimental results on four real SAR datasets demonstrate that the proposed method exhibits superior performance against several state-of-the-art methods. Our codes are available at https://github.com/summitgao/SAR_CD_SAFNet.
C1 [Gao, Yunhao; Gao, Feng; Dong, Junyu] Ocean Univ China, Sch Informat Sci, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
   [Li, Heng-Chao] Southwest Jiaotong Univ, Sichuan Prov Key Lab Informat Coding & Transmiss, Chengdu 610031, Peoples R China.
C3 Ocean University of China; Mississippi State University; Southwest Jiaotong University
RP Gao, F (corresponding author), Ocean Univ China, Sch Informat Sci, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
EM 914283361@qq.com; gaofeng@ouc.edu.cn; dongjunyu@ouc.edu.cn; du@ece.msstate.edu; hcli@swjtu.edu.cn
FU National Key Research, and Development Program of China [2018AAA0100602]; National Natural Science Foundation of China [U1706218, 61871335]; Key Research, and Development Program of Shandong Province [2019GHY112048]
CR Bai XZ, 2010, PATTERN RECOGN, V43, P2145, DOI 10.1016/j.patcog.2009.12.023
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bengio Y., 2013, ARXIV13083432CS, V0, P0
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2019, NEUROCOMPUTING, V332, P56, DOI 10.1016/j.neucom.2018.11.077
   Dekker RJ, 1998, INT J REMOTE SENS, V19, P1133, DOI 10.1080/014311698215649
   Gao F, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.016010
   Gao F, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3097093
   Gao YH, 2019, IEEE J-STARS, V12, P4517, DOI 10.1109/JSTARS.2019.2953128
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T EVOLUT COMPUT, V21, P234, DOI 10.1109/TEVC.2016.2598858
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Jian MW, 2021, EXPERT SYST APPL, V168, P0, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li X, 2019, PROC CVPR IEEE, V0, PP510, DOI 10.1109/CVPR.2019.00060
   Li XL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030258
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Quin G, 2014, IEEE T GEOSCI REMOTE, V52, P5349, DOI 10.1109/TGRS.2013.2288271
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Wang Q, 2022, IEEE T NEUR NET LEAR, V33, P1414, DOI 10.1109/TNNLS.2020.3042276
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P5028, DOI 10.1109/TGRS.2020.3011002
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang SN, 2016, REMOTE SENS LETT, V7, P1043, DOI 10.1080/2150704X.2016.1212417
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Yang B, 2019, ADV NEUR IN, V32, P0
   Zhang HY, 2021, IEEE T NEUR NET LEAR, V0, P0, DOI DOI 10.1109/TNNLS.2021.3089332
   Zhang MY, 2022, IEEE T CYBERNETICS, V52, P2981, DOI 10.1109/TCYB.2020.3020540
NR 42
TC 7
Z9 7
U1 5
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10748
EP 10760
DI 10.1109/JSTARS.2021.3120381
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WR0MR
UT WOS:000714204000012
DA 2023-04-26
ER

PT J
AU Wang, HJ
   Zhang, LM
   Wang, L
   He, J
   Luo, HY
AF Wang, Haojie
   Zhang, Limin
   Wang, Lin
   He, Jian
   Luo, Hongyu
TI An Automated Snow Mapper Powered by Machine Learning
SO REMOTE SENSING
LA English
DT Article
DE automated snow mapping; snow cover; machine learning; multispectral image; object-based analysis; remote sensing; Sentinel-2
ID cover maps; modis; uncertainty
AB Snow preserves fresh water and impacts regional climate and the environment. Enabled by modern satellite Earth observations, fast and accurate automated snow mapping is now possible. In this study, we developed the Automated Snow Mapper Powered by Machine Learning (AutoSMILE), which is the first machine learning-based open-source system for snow mapping. It is built in a Python environment based on object-based analysis. AutoSMILE was first applied in a mountainous area of 1002 km(2) in Bome County, eastern Tibetan Plateau. A multispectral image from Sentinel-2B, a digital elevation model, and machine learning algorithms such as random forest and convolutional neural network, were utilized. Taking only 5% of the study area as the training zone, AutoSMILE yielded an extraordinarily satisfactory result over the rest of the study area: the producer's accuracy, user's accuracy, intersection over union and overall accuracy reached 99.42%, 98.78%, 98.21% and 98.76%, respectively, at object level, corresponding to 98.84%, 98.35%, 97.23% and 98.07%, respectively, at pixel level. The model trained in Bome County was subsequently used to map snow at the Qimantag Mountain region in the northern Tibetan Plateau, and a high overall accuracy of 97.22% was achieved. AutoSMILE outperformed threshold-based methods at both sites and exhibited superior performance especially in handling complex land covers. The outstanding performance and robustness of AutoSMILE in the case studies suggest that AutoSMILE is a fast and reliable tool for large-scale high-accuracy snow mapping and monitoring.
C1 [Wang, Haojie; Zhang, Limin; Wang, Lin; He, Jian; Luo, Hongyu] Hong Kong Univ Sci & Technol, Dept Civil & Environm Engn, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Zhang, LM (corresponding author), Hong Kong Univ Sci & Technol, Dept Civil & Environm Engn, Hong Kong, Peoples R China.
EM h.wang@connect.ust.hk; cezhangl@ust.hk; wangl@ust.hk; jhebl@connect.ust.hk; hluoae@connect.ust.hk
FU NSFC/RGC Joint Research Scheme [HKUST620/20]; National Natural Science Foundation of China [U20A20112]; Hong Kong SAR Government [16203720, 16205719]
CR Arino O., 2008, EUR SPACE AGENCY, V136, P25
   Biemans H, 2019, NAT SUSTAIN, V2, P594, DOI 10.1038/s41893-019-0305-3
   Brodu N, 2017, IEEE T GEOSCI REMOTE, V55, P4610, DOI 10.1109/TGRS.2017.2694881
   Cannistra AF, 2021, REMOTE SENS ENVIRON, V258, P0, DOI 10.1016/j.rse.2021.112399
   Croce P, 2018, CLIM RISK MANAG, V20, P138, DOI 10.1016/j.crm.2018.03.001
   Dedieu JP, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060481
   Gascoin S, 2019, EARTH SYST SCI DATA, V11, P493, DOI 10.5194/essd-11-493-2019
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Harer S, 2018, CRYOSPHERE, V12, P1629, DOI 10.5194/tc-12-1629-2018
   Hall D.K., 2006, MODIS SNOW PRODUCTS, V0, P0
   Hall D. K., 2001, ALGORITHM THEORETICA, V0, P0
   Hall DK, 2007, HYDROL PROCESS, V21, P1534, DOI 10.1002/hyp.6715
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hosseini SAA, 2020, GEORISK, V14, P142, DOI 10.1080/17499518.2019.1612526
   James G, 2013, SPRINGER TEXTS STAT, V103, P303, DOI 10.1007/978-1-4614-7138-7_8
   Keyport RN, 2018, INT J APPL EARTH OBS, V64, P1, DOI 10.1016/j.jag.2017.08.015
   Liu CY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060962
   Liu Y, 2020, J MT SCI-ENGL, V17, P884, DOI 10.1007/s11629-019-5723-1
   MOORE ID, 1991, HYDROL PROCESS, V5, P3, DOI 10.1002/hyp.3360050103
   Rahmati O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242995
   Rastegarmanesh A, 2021, GEORISK, V15, P152, DOI 10.1080/17499518.2020.1751208
   Rastner P, 2014, IEEE J-STARS, V7, P853, DOI 10.1109/JSTARS.2013.2274668
   Stumpf A, 2011, REMOTE SENS ENVIRON, V115, P2564, DOI 10.1016/j.rse.2011.05.013
   Tsai YLS, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080895
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wang HJ, 2019, ENG GEOL, V251, P71, DOI 10.1016/j.enggeo.2019.02.004
   Wang H.J., 2020, P 7 AS PAC S STRUCT, V0, P0
   Wang HJ, 2021, ENG GEOL, V288, P0, DOI 10.1016/j.enggeo.2021.106103
   Wang HJ, 2021, GEOSCI FRONT, V12, P351, DOI 10.1016/j.gsf.2020.02.012
   Wang L, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10111666
   Wang XC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030485
   Wilson EH, 2002, REMOTE SENS ENVIRON, V80, P385, DOI 10.1016/S0034-4257(01)00318-2
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Zhang HB, 2019, SCI TOTAL ENVIRON, V651, P2712, DOI 10.1016/j.scitotenv.2018.10.128
   Zhao J, 2015, J ARID LAND, V7, P285, DOI 10.1007/s40333-015-0044-x
NR 36
TC 2
Z9 2
U1 0
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 15
PY 2021
VL 13
IS 23
BP 
EP 
DI 10.3390/rs13234826
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XV8DS
UT WOS:000735166300001
DA 2023-04-26
ER

PT J
AU Liu, H
   Shen, X
   Cao, L
   Yun, T
   Zhang, ZN
   Fu, XY
   Chen, XX
   Liu, FZ
AF Liu, Hao
   Shen, Xin
   Cao, Lin
   Yun, Ting
   Zhang, Zhengnan
   Fu, Xiaoyao
   Chen, Xinxin
   Liu, Fangzhou
TI Deep Learning in Forest Structural Parameter Estimation Using Airborne LiDAR Data
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Deep learning; forest structural parameters; hyperparameter; LiDAR; volume distribution
ID neural-networks; satellite images; canopy structure; tree height; basal area; regression; inventory; stands; attributes; prediction
AB Accurately estimating and mapping forest structural parameters are essential for monitoring forest resources and understanding ecological processes. The novel deep learning algorithm has the potential to be a promising approach to improve the estimation accuracy while combining with advanced remote sensing technology. Airborne light detection and ranging (LiDAR) has the preferable capability to characterize 3-D canopy structure and estimate forest structural parameters. In this study, we developed a deep learning-based algorithm (Deep-RBN) that combined the fully connected network (FCN) deep learning algorithm with the optimized radial basis neural network (RBN) algorithm for forest structural parameter estimation using airborne LiDAR data. The multiple iterations were used to constantly update the internal weights to achieve the optimized accuracy of model fitting, and the optimized RBN algorithm was developed for the limited training sets. We assessed the efficiency and capability of the Deep-RBN in the estimation of forest structural parameters in a subtropical planted forest of southern China, by comparing the traditional FCN algorithm and multiple linear regression. We found that Deep-RBN had the strongest capability in estimates of forest structural parameters (R-2 = 0.67-0.86, rRMSE = 6.95%-20.34%). The sensitivity analysis of the key hyperparameters of Deep-RBN algorithm showed that the learning rate is one of the most important parameters that influence the performance of predictive models, and while its value equal is to 0.001, the predictive models had the highest accuracy (mean DBH: RMSE = 1.01, mean height: RMSE = 1.45, volume: RMSE = 26.49, stem density: RMSE = 121.06). With the increase of training samples added in Deep-RBN model, the predictive models performed better; however, no significant improvements of accuracy were observed while the number of training set is larger than 80. This study demonstrates the benefits of jointly using the Deep-RBN algorithm and airborne LiDAR data to improve the accuracy of forest structural parameter estimation and mapping, which provides a promising methodology for sustainable forest resources monitoring.
C1 [Liu, Hao; Shen, Xin; Cao, Lin; Zhang, Zhengnan; Fu, Xiaoyao] Nanjing Forestry Univ, Coinnovat Ctr Sustainable Forestry Southern China, Nanjing 210037, Peoples R China.
   [Yun, Ting; Chen, Xinxin; Liu, Fangzhou] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 210037, Peoples R China.
C3 Nanjing Forestry University; Nanjing Forestry University
RP Cao, L (corresponding author), Nanjing Forestry Univ, Coinnovat Ctr Sustainable Forestry Southern China, Nanjing 210037, Peoples R China.
EM liuhao_njfu@hotmail.com; shenxin1903@gmail.com; lincao@njfu.edu.cn; njyunting@gmail.com; zhangzhengnan_njfu@hotmail.com; fuxyrainlan@gmail.com; 15950569238@163.com; liufangzhou@njfu.edu.cn
FU National Key R&D Program of China [2017YFD0600904]; National Natural Science Foundation of China [31770590]; Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD)
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Agostinelli F, 2014, ARXIV14126830, V0, P0
   Baral H, 2016, ECOSYST SERV, V22, P260, DOI 10.1016/j.ecoser.2016.10.002
   Bataineh M, 2017, NEURAL NETWORKS, V95, P1, DOI 10.1016/j.neunet.2017.07.018
   Bechtold W.A., 2005, SRSGTR80 USDA FOR SE, V0, P0, DOI DOI 10.2737/SRS-GTR-80
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bengio Yoshua, 2012, NEURAL NETWORKS: TRICKS OF THE TRADE. SECOND EDITION: LNCS 7700, V0, PP437, DOI 10.1007/978-3-642-35289-8_26
   BIANCHINI M, 1995, IEEE T NEURAL NETWOR, V6, P749, DOI 10.1109/72.377979
   Bolton DK, 2015, REMOTE SENS ENVIRON, V163, P48, DOI 10.1016/j.rse.2015.03.004
   Cao L, 2016, REMOTE SENS ENVIRON, V178, P158, DOI 10.1016/j.rse.2016.03.012
   Carrio A, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/3296874
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chollet F., 2018, ASCL, V0, P0
   Coops NC, 2007, TREES-STRUCT FUNCT, V21, P295, DOI 10.1007/s00468-006-0119-6
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Diaz GI, 2017, IBM J RES DEV, V61, P0, DOI 10.1147/JRD.2017.2709578
   Ercanli I, 2020, FOR ECOSYST, V7, P0, DOI 10.1186/s40663-020-00226-3
   Garcia-Gutierrez J, 2015, NEUROCOMPUTING, V167, P24, DOI 10.1016/j.neucom.2014.09.091
   Gedeon TD, 1997, INT J NEURAL SYST, V8, P209, DOI 10.1142/S0129065797000227
   Golub G.H., 2013, MATRIX COMPUTATIONS, V4th, P0, DOI 10.56021/9781421407944
   Goodbody TRH, 2018, ISPRS J PHOTOGRAMM, V142, P1, DOI 10.1016/j.isprsjprs.2018.05.012
   Greenwell B.M, 2018, SIMPLE EFFECTIVE MOD, V0, P0
   Guan HY, 2015, REMOTE SENS LETT, V6, P864, DOI 10.1080/2150704X.2015.1088668
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Hannan S. A., 2010, INT J COMPUTER APPL, V7, P7, DOI 10.5120/1325-1799
   Holmgren J, 2004, SCAND J FOREST RES, V19, P543, DOI 10.1080/02827580410019472
   Hooper DU, 2002, BIODIVERSITY AND ECOSYSTEM FUNCTIONING: SYNTHESIS AND PERSPECTIVES, V0, P195
   Hu W, 2015, J SENSORS, V2015, P0, DOI 10.1155/2015/258619
   Hudak AT, 2006, CAN J REMOTE SENS, V32, P126, DOI 10.5589/m06-007
   Hudak AT, 2012, REMOTE SENS ENVIRON, V123, P25, DOI 10.1016/j.rse.2012.02.023
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Junttila V, 2015, IEEE T GEOSCI REMOTE, V53, P5600, DOI 10.1109/TGRS.2015.2425916
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lefsky MA, 1999, REMOTE SENS ENVIRON, V70, P339, DOI 10.1016/S0034-4257(99)00052-8
   Lefsky MA, 2002, BIOSCIENCE, V52, P19, DOI 10.1641/0006-3568(2002)052[0019:LRSFES]2.0.CO;2
   Li WK, 2012, PHOTOGRAMM ENG REM S, V78, P75, DOI 10.14358/PERS.78.1.75
   Liu B, 2019, IEEE T GEOSCI REMOTE, V57, P2290, DOI 10.1109/TGRS.2018.2872830
   Liu P, 2017, SOFT COMPUT, V21, P7053, DOI 10.1007/s00500-016-2247-2
   Liu WP, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19194188
   Liu ZL, 2018, ENVIRON REV, V26, P339, DOI 10.1139/er-2018-0034
   Makantasis K, 2015, INT GEOSCI REMOTE SE, V0, PP4959, DOI 10.1109/IGARSS.2015.7326945
   McRoberts R. E., 2005, SRS80 US FOR SERV GE, V0, P11
   Means JE, 2000, PHOTOGRAMM ENG REM S, V66, P1367
   Mehtatalo L, 2015, CAN J FOREST RES, V45, P826, DOI 10.1139/cjfr-2015-0054
   Messier C, 1999, FOREST CHRON, V75, P929, DOI 10.5558/tfc75929-6
   Mou L., 2018, ARXIV180502091, V0, P0
   Mou LC, 2018, IEEE T GEOSCI REMOTE, V56, P391, DOI 10.1109/TGRS.2017.2748160
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Naesset E, 2001, REMOTE SENS ENVIRON, V78, P328, DOI 10.1016/S0034-4257(01)00228-0
   Naesset E., 2004, INT ARCH PHOTOGRAMME, VXXXVI-8/W2, P145, DOI 10.1016/J.RSE.2008.03.004
   Naesset E, 2011, REMOTE SENS ENVIRON, V115, P3599, DOI 10.1016/j.rse.2011.08.021
   Norvig P., 2016, ARTIF INTELL, V0, P0
   Nunes MH, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0154738
   Osbourne J.W., 2002, PRACT ASSESS RES EVA, V8, P1, DOI 10.7275/r222-hv23
   Ozcelik R, 2013, FOREST ECOL MANAG, V306, P52, DOI 10.1016/j.foreco.2013.06.009
   Packalen P, 2007, REMOTE SENS ENVIRON, V109, P328, DOI 10.1016/j.rse.2007.01.005
   POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326
   Qi C. R., 2017, ADV NEURAL INFORM PR, V0, P5099
   Rostami M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111374
   Ruder S, 2017, ARXIV170605098, V0, P0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schmitt M, 2016, IEEE GEOSC REM SEN M, V4, P6, DOI 10.1109/MGRS.2016.2561021
   Schwegmann CP, 2016, INT GEOSCI REMOTE SE, V0, PP104, DOI 10.1109/IGARSS.2016.7729017
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su HJ, 2020, IEEE T GEOSCI REMOTE, V58, P3778, DOI 10.1109/TGRS.2019.2957135
   The S., 2014, DEEP LEARNING NEURAL, V0, P1
   Thomas JW, 1996, ECOL APPL, V6, P703, DOI 10.2307/2269465
   Vastaranta M, 2012, ISPRS J PHOTOGRAMM, V67, P73, DOI 10.1016/j.isprsjprs.2011.10.006
   Wang JM, 2019, FORESTS, V10, P0, DOI 10.3390/f10090793
   Wang YX, 2016, LECT NOTES COMPUT SC, V9910, P616, DOI 10.1007/978-3-319-46466-4_37
   Wei XH, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0089688
   White JC, 2016, CAN J REMOTE SENS, V42, P619, DOI 10.1080/07038992.2016.1207484
   White JC, 2013, FOREST CHRON, V89, P722, DOI 10.5558/tfc2013-132
   Woods M, 2011, FOREST CHRON, V87, P512, DOI 10.5558/tfc2011-050
   Wulder MA, 2008, FOREST CHRON, V84, P807, DOI 10.5558/tfc84807-6
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
   Zhao XQ, 2016, ISPRS J PHOTOGRAMM, V117, P79, DOI 10.1016/j.isprsjprs.2016.03.016
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhu M., 2019, INT J GEOSCIENCES, V10, P1, DOI 10.4236/IJG.2019.101001
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 83
TC 5
Z9 5
U1 9
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1603
EP 1618
DI 10.1109/JSTARS.2020.3046053
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PS3FD
UT WOS:000607810600013
DA 2023-04-26
ER

PT J
AU Bakhtavar, E
   Hosseini, S
   Hewage, K
   Sadiq, R
AF Bakhtavar, Ezzeddin
   Hosseini, Shahab
   Hewage, Kasun
   Sadiq, Rehan
TI Green blasting policy: Simultaneous forecast of vertical and horizontal distribution of dust emissions using artificial causality-weighted neural network
SO JOURNAL OF CLEANER PRODUCTION
LA English
DT Article
DE Dust emission; Air pollution; Green blasting policy; Fuzzy cognitive map; Multi-layer artificial neural network
ID fuzzy cognitive maps; rock fragmentation; air-quality; prediction; optimization; flyrock; model
AB The environmental impacts of the mining industry as well as reduction strategies are important issues that have been highlighted as a result of the environmentally-friendly policy of green mining. As part of that policy, this study developed an approach based on a multi-layer artificial neural network and fuzzy cognitive map to predict the vertical and horizontal distribution of blast-induced dust emissions, simultaneously. Hence, a fuzzy cognitive map based on the cause-and-effect analysis concept was first designed to extract inputs' weights. An optimal network with two hidden layers was then implemented to predict the vertical and horizontal dust distributions in a mine close to residential and agricultural areas. The performance evaluation of the approach indicated good results by the R-2 of 0.9933 and 0.9267 between the measured and predicted values for the horizontal and vertical distributions, respectively. Furthermore, the predicted and measured outputs over every blasting round were in accordance due to the slight mean absolute and root mean square errors of 0.009 and 0.018, respectively. A sensitivity analysis revealed that all inputs, excluding air humidity on the vertical distribution, had acceptable effects on the dust distribution outputs by the strength of higher than 0.7. Based on a reduction solution that we suggested, one round was blasted by taking water capsules together with stemming material in 40% of the whole blast holes. The results indicated that the maximum horizontal distribution of blast-induced dust was decreased about six times. The approach can be straightforwardly updated and used for other mining cases. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Bakhtavar, Ezzeddin] Urmia Univ Technol, Fac Min & Mat Engn, Band Rd, Orumiyeh, Iran.
   [Bakhtavar, Ezzeddin; Hewage, Kasun; Sadiq, Rehan] Univ British Columbia, Sch Engn, Okanagan Campus, Kelowna, BC, Canada.
   [Hosseini, Shahab] Tarbiat Modares Univ, Fac Engn, Tehran, Iran.
C3 Urmia University of Technology; University of British Columbia; Tarbiat Modares University
RP Bakhtavar, E (corresponding author), Urmia Univ Technol, Fac Min & Mat Engn, Band Rd, Orumiyeh, Iran.
EM e.bakhtavar@mie.uut.ac.ir
CR Abdollahisharif J, 2016, J MIN ENVIRON, V7, P109
   Abdollahisharif J, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4947-9
   Alvarado M, 2015, SENSORS-BASEL, V15, P19667, DOI 10.3390/s150819667
   Alvarez-Vigil AE, 2012, INT J ROCK MECH MIN, V55, P108, DOI 10.1016/j.ijrmms.2012.05.002
   [Anonymous], 1994, FUNDAMENTALS NEURAL, V0, P0
   [Anonymous], 1999, NEURAL NETWORKS COMP, V0, P0
   Badroddin M, 2013, ARAB J GEOSCI, V6, P3319, DOI 10.1007/s12517-012-0552-3
   Bakhtavar E, 2019, J S AFR I MIN METALL, V119, P855, DOI 10.17159/2411-9717/68/2019
   Bakhtavar E, 2019, INT J ENVIRON SCI TE, V16, P6065, DOI 10.1007/s13762-018-2008-0
   Bakhtavar E, 2019, J CLEAN PROD, V230, P253, DOI 10.1016/j.jclepro.2019.05.073
   Bakhtavar E, 2020, COMPUT OPER RES, V115, P0, DOI 10.1016/j.cor.2018.08.003
   Bakhtavar E, 2019, ENG COMPUT-GERMANY, V35, P35, DOI 10.1007/s00366-018-0581-y
   Bakhtavar E, 2020, J CLEAN PROD, V272, P0, DOI 10.1016/j.jclepro.2020.122886
   Bakhtavar E, 2018, STOCH ENV RES RISK A, V32, P3317, DOI 10.1007/s00477-018-1618-x
   Bakhtavar E, 2017, INT J MIN RECLAM ENV, V31, P333, DOI 10.1080/17480930.2016.1158964
   Bator R, 2006, INT J ENERG RES, V30, P1023, DOI 10.1002/er.1200
   Beale MH., 2010, NEURAL NETWORK TOOLB, V0, P77
   Binkowski F.S., 1996, CONF960127 AM MET SO, V0, P0
   Bose N. K., 1996, NEURAL NETWORK FUNDA, V0, P478
   Cohn RD, 2001, J APPL METEOROL, V40, P210, DOI 10.1175/1520-0450(2001)040<0210:DOAAAE>2.0.CO;2
   Dastoor AP, 1996, ATMOS ENVIRON, V30, P1501, DOI 10.1016/1352-2310(95)00243-X
   Dong LJ, 2018, J CLEAN PROD, V183, P319, DOI 10.1016/j.jclepro.2018.02.105
   Ebrahimi E, 2016, B ENG GEOL ENVIRON, V75, P27, DOI 10.1007/s10064-015-0720-2
   Ghosh M. K., 2002, INT J ENVIRON STUD, V59, P211, DOI 10.1080/00207230210927
   Han J., 2000, P 5 INT C GEOCOMPUTA, V0, P0
   Jahed Armaghani D., 2018, NEURAL COMPUT APPL, V29, P619, DOI 10.1007/s00521-016-2598-8
   Karunathilake H., 2020, METHODS CHEM PROCESS, V0, P0, DOI DOI 10.1016/bs.mcps.2020.02.004
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Lal B, 2012, ATMOS POLLUT RES, V3, P211, DOI 10.5094/APR.2012.023
   MCCULLOCH WS, 1990, B MATH BIOL, V52, P99, DOI 10.1016/S0092-8240(05)80006-0
   Monjezi M, 2008, INT J ROCK MECH MIN, V45, P1446, DOI 10.1016/j.ijrmms.2008.02.007
   Monjezi M, 2010, GEOTECH GEOL ENG, V28, P423, DOI 10.1007/s10706-010-9302-z
   Nazemi E, 2019, J NONDESTRUCT EVAL, V38, P0, DOI 10.1007/s10921-018-0542-9
   Papageorgiou EI, 2008, APPL SOFT COMPUT, V8, P820, DOI 10.1016/j.asoc.2007.06.006
   Papageorgiou EI, 2006, INT J HUM-COMPUT ST, V64, P727, DOI 10.1016/j.ijhcs.2006.02.009
   Papageorgiou EI, 2013, STUD COMPUT INTELL, V444, P281
   Priddy K. L., 2005, ARTIFICIAL NEURAL NE, V68, P0
   Rezaee MJ, 2017, NEUROCOMPUTING, V232, P69, DOI 10.1016/j.neucom.2016.10.069
   Rezaei M, 2014, NEURAL COMPUT APPL, V24, P233, DOI 10.1007/s00521-012-1221-x
   Roy S., 2011, JOURNAL OF ENVIRONMENTAL SCIENCE AND TECHNOLOGY, V4, P284
   Roy Surendra, 2010, JOURNAL OF ENVIRONMENTAL PROTECTION, V1, P346, DOI 10.4236/jep.2010.14041
   Saghatforoush A, 2016, ENG COMPUT-GERMANY, V32, P255, DOI 10.1007/s00366-015-0415-0
   Salmeron JL, 2019, KNOWL-BASED SYST, V163, P723, DOI 10.1016/j.knosys.2018.09.034
   Saltbones J, 1998, ATMOS ENVIRON, V32, P4277, DOI 10.1016/S1352-2310(98)00192-7
   Sangiorgio V, 2020, SAFETY SCI, V131, P0, DOI 10.1016/j.ssci.2020.104921
   Sayadi A, 2013, J ROCK MECH GEOTECH, V5, P318, DOI 10.1016/j.jrmge.2013.05.007
   Stylios CD, 2000, J INTELL FUZZY SYST, V8, P83
   Tecer LH, 2007, POL J ENVIRON STUD, V16, P633
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Torres N., 2019, P 27 INT S MIN PLANN, V0, P0
   Trivedi R, 2014, J ROCK MECH GEOTECH, V6, P447, DOI 10.1016/j.jrmge.2014.07.003
   Vardoulakis S, 2003, ATMOS ENVIRON, V37, P155, DOI 10.1016/S1352-2310(02)00857-9
   Viotti P, 2002, ECOL MODEL, V148, P27, DOI 10.1016/S0304-3800(01)00434-3
   Yang Y, 1997, ROCK MECH ROCK ENG, V30, P207, DOI 10.1007/BF01045717
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 55
TC 20
Z9 20
U1 2
U2 20
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0959-6526
EI 1879-1786
J9 J CLEAN PROD
JI J. Clean Prod.
PD FEB 10
PY 2021
VL 283
IS 
BP 
EP 
DI 10.1016/j.jclepro.2020.124562
EA JAN 2021
PG 12
WC Green & Sustainable Science & Technology; Engineering, Environmental; Environmental Sciences
SC Science & Technology - Other Topics; Engineering; Environmental Sciences & Ecology
GA PU0WX
UT WOS:000609031600003
DA 2023-04-26
ER

PT J
AU Ran, Q
   Wang, Q
   Zhao, BY
   Wu, YF
   Pu, SL
   Li, ZJ
AF Ran, Qiong
   Wang, Qing
   Zhao, Boya
   Wu, Yuanfeng
   Pu, Shengliang
   Li, Zijin
TI Lightweight Oriented Object Detection Using Multiscale Context and Enhanced Channel Attention in Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Object detection; Remote sensing; Training; Proposals; Detectors; Visualization; Channel attention; lightweight convolutional neural network (CNN); multiscale context; object detection; remote sensing
AB Object detection is a focal point in remote sensing applications. Remote sensing images typically contain a large number of small objects and a wide range of orientations across objects. This results in great challenges to small object detection approaches based on remote sensing images. Methods directly employ channel relations with equal weights to construct information features leads to inadequate feature representation in complex image small object detection tasks. Multiscale detection methods improve the speed and accuracy of detection, while small objects themselves contain limited information, and the features are easily lost following down-sampling. During the detection, the feature images are independent across scales, resulting in a discontinuity at the detection scale. In this article, we propose the multiscale context and enhanced channel attention (MSCCA) model. MSCCA employs PeleeNet as the backbone network. In particular, the feature image channel attention is enhanced and the multiscale context information is fused with multiscale detection methods to improve the characterization ability of the convolutional neural network. The proposed MSCCA method is evaluated on two real datasets. Results show that for 512 x 512 input images, MSCCA was able to achieve 80.4% and 94.4% mAP on the DOTA and NWPU VHR-10, respectively. Meanwhile, the model size of MSCCA is 21% smaller than that of its predecessor. MSCCA can be considered as a practical lightweight oriented object detection model in remote sensing images.
C1 [Ran, Qiong; Wang, Qing] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
   [Zhao, Boya; Wu, Yuanfeng; Pu, Shengliang; Li, Zijin] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Wu, Yuanfeng; Li, Zijin] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China.
C3 Beijing University of Chemical Technology; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Wu, YF (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.; Wu, YF (corresponding author), Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China.
EM ranqiong@mail.buct.edu.cn; 2019210520@mail.buct.edu.cn; zhaoby@aircas.ac.cn; wuyf@radi.ac.cn; pusl@aircas.ac.cn; 1700012409@pku.edu.cn
FU National Natural Science Foundation of China [41871245, 62001455]
CR Acatay O, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), V0, P163
   [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   Chen Yinpeng, 2020, IEEE C COMP VIS PATT, V0, P0
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu C.-Y., 2017, DSSD DECONVOLUTIONAL, V0, P0
   Fu K, 2021, IEEE T GEOSCI REMOTE, V59, P4370, DOI 10.1109/TGRS.2020.3020165
   Gao Z, 2019, IEEE J-STARS, V12, P3552, DOI 10.1109/JSTARS.2019.2933501
   Ghanbari H, 2021, IEEE J-STARS, V14, P3602, DOI 10.1109/JSTARS.2021.3065569
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   He, 2021, P IEEE AAAI, V0, P11207
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Hoang T. M., 2020, IEEE ACCESS, V8, P0
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2020, ISPRS J PHOTOGRAMM, V167, P12, DOI 10.1016/j.isprsjprs.2020.06.014
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Jeong J, 2017, BRIT MACH VIS C, V0, P0
   Kong T, 2016, PROC CVPR IEEE, V0, PP845, DOI 10.1109/CVPR.2016.98
   Lee YW, 2019, IEEE COMPUT SOC CONF, V0, PP752, DOI 10.1109/CVPRW.2019.00103
   Li YH, 2019, IEEE I CONF COMP VIS, V0, PP6053, DOI 10.1109/ICCV.2019.00615
   Li YY, 2021, IEEE J-STARS, V14, P2148, DOI 10.1109/JSTARS.2020.3046482
   Li Z., 2017, FSSD FEATURE FUSION, V0, P0
   LIN T, 2018, IEEE T PATTERN ANAL, V42, P2999
   Ma N., 2018, P EUR C COMP VIS ECC, V0, PP122, DOI 10.1007/978-3-030-01264-9_8
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, V0, PP89, DOI 10.1109/ICCV.2011.6126229
   Ming Q., 2020, ARXIV201204150, V0, P0
   Pan X., 2020, P IEEECVF C COMPUTER, V0, P11204
   Pang JM, 2019, PROC CVPR IEEE, V0, PP821, DOI 10.1109/CVPR.2019.00091
   Redmon J., 2016, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   REDMON J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Singh B, 2018, ADV NEUR IN, V31, P0
   Singh B, 2018, PROC CVPR IEEE, V0, PP3578, DOI 10.1109/CVPR.2018.00377
   Su JH, 2021, IEEE J-STARS, V14, P1389, DOI 10.1109/JSTARS.2020.3044733
   Tang HY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, V0, P1, DOI 10.1109/QRS.2016.11
   TIAN Z, 2017, IEEE I CONF COMP VIS, V0, P9627
   Tian ZZ, 2019, IEEE J-STARS, V12, P3480, DOI 10.1109/JSTARS.2019.2924086
   Triggs, 2005, PROC CVPR IEEE, V1, P886, DOI 10.1109/CVPR.2005.177
   Wang C, 2019, IEEE GEOSCI REMOTE S, V16, P310, DOI 10.1109/LGRS.2018.2872355
   Wang J, 2021, IEEE J-STARS, V14, P283, DOI 10.1109/JSTARS.2020.3041859
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wang RJ, 2018, ADV NEUR IN, V31, P0
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Xu CY, 2020, IEEE T GEOSCI REMOTE, V58, P4353, DOI 10.1109/TGRS.2019.2963243
   Yang X., 2020, ARXIV200413316, V0, P0
   Ye J, 2018, ARXIV190505055V1, V0, P0
   Zhang S, 2018, PROC CVPR IEEE, V0, PP4203, DOI 10.1109/CVPR.2018.00442
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, V0, P9259
NR 52
TC 5
Z9 5
U1 7
U2 43
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 5786
EP 5795
DI 10.1109/JSTARS.2021.3079968
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SV0RU
UT WOS:000663535500012
DA 2023-04-26
ER

PT J
AU Wang, Y
   Lee, DH
   Heo, J
   Park, J
AF Wang, Yooseung
   Lee, Donghyuk
   Heo, Jiseong
   Park, Jihun
TI One-Shot Summary Prototypical Network Toward Accurate Unpaved Road Semantic Segmentation
SO IEEE SIGNAL PROCESSING LETTERS
LA English
DT Article
DE Roads; Feature extraction; Semantics; Image segmentation; Training; Buildings; Prototypes; Semantic segmentation; road semantic segmentation; few-shot learning; convolutional neural network
AB Recent studies of driving scene understanding based on image semantic segmentation have achieved dramatic advances in speed and accuracy. Large-scale public datasets for semantic segmentation of paved road driving scenes have led the advances, but there is no large-scale public dataset for unpaved road environments. Building a large-scale image semantic segmentation dataset for unpaved roads is very expensive, and domain gaps between geographically distributed locations and those of seasonal changes hinder building a training dataset that is adequate to train a convolutional neural network model. In this paper, to resolve the data insufficiency problem, we use an one-shot learning setting in unpaved road driving scene understanding. Our One-shot Summary Prototypical Network (OSPNet) is trained with paved road driving scenes, and it identifies drivable regions in unpaved roads given only a single support image and unpaved road mask data. The OSPNet improves previous two branch few-shot segmentation approaches by introducing the summary branch which enables channel-wise weighting for important features in the feature map of support and query branches. Our experiments show that our model quantitatively and qualitatively outperforms recent supervised and few-shot segmentation models.
C1 [Wang, Yooseung; Lee, Donghyuk; Heo, Jiseong; Park, Jihun] Agcy Def Dev, Adv Def Technol Res Inst, Daejeon 34186, South Korea.
C3 Agency of Defense Development (ADD), Republic of Korea
RP Park, J (corresponding author), Agcy Def Dev, Adv Def Technol Res Inst, Daejeon 34186, South Korea.
EM yswang@add.re.kr; dhlee@add.re.kr; jsheo@add.re.kr; jhpark_a@add.re.kr
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Boyu Yang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12353), V0, PP763, DOI 10.1007/978-3-030-58598-3_45
   Chen BK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1504
   Chen L.-C., 2017, RETHINKING ATROUS CO, V0, P0
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Mingxing T., 2019, PR MACH LEARN RES, V0, P0
   Orsic M, 2019, PROC CVPR IEEE, V0, PP12599, DOI 10.1109/CVPR.2019.01289
   Rakelly K., 2018, P INT C LEARN REPR W, V0, P0
   Shaban A., 2017, P BRIT MACH VIS C, V0, P0
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Siam M, 2018, IEEE COMPUT SOC CONF, V0, PP700, DOI 10.1109/CVPRW.2018.00101
   Sun K, 2019, PROC CVPR IEEE, V0, PP5686, DOI 10.1109/CVPR.2019.00584
   Tian ZT, 2022, IEEE T PATTERN ANAL, V44, P1050, DOI 10.1109/TPAMI.2020.3013717
   Treml M, 2016, MLITS NEUR INF PROC, V2, P0
   Wang KX, 2019, IEEE I CONF COMP VIS, V0, PP9196, DOI 10.1109/ICCV.2019.00929
   Wang Y, 1900, V2021, V0, P6949
   [杨雪薇 Yang Xuewei], 2020, 高分子通报 POLYMER BULLETIN, V0, P1
   Yu F, 2020, PROC CVPR IEEE, V0, PP2633, DOI 10.1109/CVPR42600.2020.00271
   Yuhui Yuan, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12351), V0, PP173, DOI 10.1007/978-3-030-58539-6_11
   Zhang C, 2019, PROC CVPR IEEE, V0, PP5212, DOI 10.1109/CVPR.2019.00536
   Zhang Hang, 2022, 2022 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang ZY, 2016, PROC CVPR IEEE, V0, PP669, DOI 10.1109/CVPR.2016.79
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 28
TC 2
Z9 2
U1 3
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9908
EI 1558-2361
J9 IEEE SIGNAL PROC LET
JI IEEE Signal Process. Lett.
PD JUN 15
PY 2021
VL 28
IS 
BP 1200
EP 1204
DI 10.1109/LSP.2021.3087457
PG 5
WC Engineering, Electrical & Electronic
SC Engineering
GA SX1NX
UT WOS:000664979700010
DA 2023-04-26
ER

PT J
AU Chowdhuri, I
   Pal, SC
   Saha, A
   Chakrabortty, R
   Roy, P
AF Chowdhuri, Indrajit
   Pal, Subodh Chandra
   Saha, Asish
   Chakrabortty, Rabin
   Roy, Paramita
TI Evaluation of different DEMs for gully erosion susceptibility mapping using in-situ field measurement and validation
SO ECOLOGICAL INFORMATICS
LA English
DT Article
DE Geomorphic studies; Terrain attributes; Gully erosion susceptibility (GES); Digital elevation model (DEM); Deep learning neural network (DLNN)
ID machine learning-models; landslide susceptibility; soil-erosion; logistic-regression; neural-networks; basin; representation; performance; resolution; prediction
AB The spatial variability in any kind of geomorphic studies based on terrain attributes are the most important issues. This terrain attributes and their respective characteristics play a significant role in the formation and expansion of ephemeral gullies. Therefore, nowadays, the accuracy of terrain based geomorphic studies has been mostly dependent on the resolution and quality of the DEM (digital elevation model) data. As the rate of erosional power of water flow is dependent on the terrain characteristics, therefore the extraction of several terrain features from DEM data is necessary in the study of gully erosion. This case study investigates the scaledependence of DEM-derived terrain factors in gully erosion susceptibility (GES). This work on Garhbeta-I C.D. Block has focused on the comparison among the predicted GES maps through five types of DEM i.e. Shuttle Radar Topography Mission (SRTM), Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER), Cartosat-1, ALOS World 3D-30 m (AW3D30) and Advanced Land Observation satellite (ALOS) coupled with the machine learning modelling approach of artificial neural network (ANN), convolution neural network (CNN) and deep learning neural network (DLNN) algorithm. A total of sixteen conditioning factors were chosen for GES assessment based on the topographical, hydro-climatological conditions and multi-collinearity analysis. Here, importance variables are measured by mean decrease accuracy (MDA) method of random forest (RF) algorithm and the result is shown that elevation is the most important factor for gully occurrences. Validation result of receiver operating characteristics-area under curve (ROC-AUC) has been indicates that DLNN model in ALOS DEM (AUC = 0.958) gives the most optimal accuracy in GES assessment. The output maps can assist in identifying gully-prone risk areas, and several suitable with sustainable managements should be taken for conservation accordingly.
C1 [Chowdhuri, Indrajit; Pal, Subodh Chandra; Saha, Asish; Chakrabortty, Rabin; Roy, Paramita] Univ Burdwan, Dept Geog, Bardhaman 713104, W Bengal, India.
C3 University of Burdwan
RP Pal, SC (corresponding author), Univ Burdwan, Dept Geog, Bardhaman 713104, W Bengal, India.
EM geo.subodh@gmail.com
CR Alin A, 2010, WIRES COMPUT STAT, V2, P370, DOI 10.1002/wics.84
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203389
   Arabameri A, 2020, GEOMORPHOLOGY, V359, P0, DOI 10.1016/j.geomorph.2020.107136
   Band SS, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20195609
   Battineni G, 2019, MACHINES, V7, P0, DOI 10.3390/machines7040074
   Pham BT, 2020, GEOCARTO INT, V35, P1267, DOI 10.1080/10106049.2018.1559885
   Bryan RB, 1997, GEOMORPHOLOGY, V20, P209, DOI 10.1016/S0169-555X(97)00024-X
   Canziani A., 2017, COMPUTER VISION PATT, V0, P0
   Castillo C, 2016, EARTH-SCI REV, V160, P300, DOI 10.1016/j.earscirev.2016.07.009
   Chakrabortty R., 1900, P1, V0, P0
   Chakrabortty R, 2020, NAT HAZARDS, V104, P1259, DOI 10.1007/s11069-020-04213-3
   Chen Z, 2020, NAT HAZARDS, V101, P853, DOI 10.1007/s11069-020-03899-9
   Choi J, 2012, ENG GEOL, V124, P12, DOI 10.1016/j.enggeo.2011.09.011
   Choubin B, 2018, SCI TOTAL ENVIRON, V615, P272, DOI 10.1016/j.scitotenv.2017.09.293
   Chowdhuri I, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213620
   Chowdhuri I, 2020, ADV SPACE RES, V65, P1466, DOI 10.1016/j.asr.2019.12.003
   Coelho IM, 2017, APPL ENERG, V201, P412, DOI 10.1016/j.apenergy.2017.01.003
   Conforti M, 2011, NAT HAZARDS, V56, P881, DOI 10.1007/s11069-010-9598-2
   Conoscenti C, 2014, GEOMORPHOLOGY, V204, P399, DOI 10.1016/j.geomorph.2013.08.021
   Costache R, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12061549
   Deng QC, 2015, GEOMORPHOLOGY, V228, P703, DOI 10.1016/j.geomorph.2014.10.032
   Di Stefano C, 2011, HYDROL PROCESS, V25, P2221, DOI 10.1002/hyp.7977
   Bui DT, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104426
   Bui DT, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134413
   Domazetovic F, 2019, APPL GEOGR, V112, P0, DOI 10.1016/j.apgeog.2019.102083
   Du L, 2019, ISPRS J PHOTOGRAMM, V158, P63, DOI 10.1016/j.isprsjprs.2019.09.018
   El Maaoui MA, 2012, CATENA, V93, P97, DOI 10.1016/j.catena.2012.02.004
   Florinsky IV, 2016, DIGITAL TERRAIN ANALYSIS IN SOIL SCIENCE AND GEOLOGY, V0, P1
   Foster G. R., 1986, SOIL CONSERVATION AS, V2, P90, DOI 10.17226/648
   Fox GA, 2016, ENVIRON MANAGE, V57, P945, DOI 10.1007/s00267-016-0671-9
   Garosi Y, 2019, SCI TOTAL ENVIRON, V664, P1117, DOI 10.1016/j.scitotenv.2019.02.093
   Garosi Y, 2018, GEODERMA, V330, P65, DOI 10.1016/j.geoderma.2018.05.027
   Gholami H, 2020, ATMOS POLLUT RES, V11, P1303, DOI 10.1016/j.apr.2020.05.009
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Gomez-Gutierrez A, 2015, NAT HAZARDS, V79, PS291, DOI 10.1007/s11069-015-1703-0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007
   Han H, 2016, INT CONF SOFTW ENG, V0, PP219, DOI 10.1109/ICSESS.2016.7883053
   Hengl T, 2006, COMPUT GEOSCI-UK, V32, P1283, DOI 10.1016/j.cageo.2005.11.008
   Hosseinalizadeh M, 2019, GEOMORPHOLOGY, V329, P184, DOI 10.1016/j.geomorph.2019.01.006
   Hughes A., 2001, 2601 CSIRO, V0, P0
   Kheir RB, 2007, EARTH SURF PROC LAND, V32, P1770, DOI 10.1002/esp.1501
   Kim P., 2017, MATLAB DEEP LEARNING, V0, PP103, DOI 10.1007/978-1-4842-2845-6_5
   Krishnan S, 2016, PROC TECH, V24, P295, DOI 10.1016/j.protcy.2016.05.039
   Chang KT, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-48773-2
   Laflen J.M., 1986, P 4 FED INT SED C, V0, P0
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X
   Paulin GL, 2010, PHYS CHEM EARTH, V35, P137, DOI 10.1016/j.pce.2010.04.008
   Lewis N.D.C., 2016, DEEP LEARNING MADE E, V0, P0
   Li SJ, 2021, LAND DEGRAD DEV, V32, P2303, DOI 10.1002/ldr.3908
   Li SJ, 2020, GEOMORPHOLOGY, V354, P0, DOI 10.1016/j.geomorph.2020.107045
   Mafizul Haque Sk, 2019, QUATERNARY GEOMORPHO, V0, PP61, DOI 10.1007/978-3-319-90427-6_3
   Mallat S, 2016, PHILOS T R SOC A, V374, P0, DOI 10.1098/rsta.2015.0203
   Nayak PC, 2006, WATER RESOUR MANAG, V20, P77, DOI 10.1007/s11269-006-4007-z
   Okereke C, 2012, MAPPING GULLY EROSIO, V0, P0
   Oksanen J, 2005, COMPUT GEOSCI-UK, V31, P1015, DOI 10.1016/j.cageo.2005.02.014
   Ouedraogo I, 2019, HYDROGEOL J, V27, P1081, DOI 10.1007/s10040-018-1900-5
   Pal Subodh Chandra, 2021, GONDWANA RESEARCH, V94, P164, DOI 10.1016/j.gr.2021.02.021
   Pal SC, 2022, NAT HAZARDS, V110, P847, DOI 10.1007/s11069-021-04971-8
   Pal SC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223675
   Pal SC, 2019, ADV SPACE RES, V64, P352, DOI 10.1016/j.asr.2019.04.033
   Pal SC, 2019, MODEL EARTH SYST ENV, V5, P369, DOI 10.1007/s40808-018-0540-z
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
   Paudel U., 2016, INTERNATIONAL JOURNAL OF GEOSCIENCES, V7, P726, DOI 10.4236/ijg.2016.75056
   Poesen J, 2018, EARTH SURF PROC LAND, V43, P64, DOI 10.1002/esp.4250
   Pourghasemi HR, 2020, GEOSCI FRONT, V11, P2207, DOI 10.1016/j.gsf.2020.03.005
   Pourghasemi HR, 2018, CATENA, V162, P177, DOI 10.1016/j.catena.2017.11.022
   Pourghasemi HR, 2017, SCI TOTAL ENVIRON, V609, P764, DOI 10.1016/j.scitotenv.2017.07.198
   Pourghasemi HR, 2017, THEOR APPL CLIMATOL, V130, P609, DOI 10.1007/s00704-016-1919-2
   Pradhan B, 2010, ENVIRON MODELL SOFTW, V25, P747, DOI 10.1016/j.envsoft.2009.10.016
   Rahmati O, 2017, GEOMORPHOLOGY, V298, P118, DOI 10.1016/j.geomorph.2017.09.006
   Rahmati O, 2017, SCI TOTAL ENVIRON, V579, P913, DOI 10.1016/j.scitotenv.2016.10.176
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Roy J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232866
   Roy P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203284
   Saha A, 2021, J ENVIRON MANAGE, V287, P0, DOI 10.1016/j.jenvman.2021.112284
   Sbroglia RM, 2018, LANDSLIDES, V15, P2093, DOI 10.1007/s10346-018-1052-7
   Sen J, 2008, GEOMORPHOLOGY GARHBE, V0, P0
   Sena NC, 2020, GEODERMA REG, V21, P0, DOI 10.1016/j.geodrs.2020.e00268
   Shumack S, 2020, EARTH SURF PROC LAND, V45, P2417, DOI 10.1002/esp.4888
   Sidle RC, 2019, PROG PHYS GEOG, V43, P46, DOI 10.1177/0309133318819403
   Sinha D, 2012, J GEOL SOC INDIA, V80, P341, DOI 10.1007/s12594-012-0152-6
   Sirtoli A.E., 2008, GEOCIENCIAS SAO PAUL, V27, P63
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Valentin C, 2005, CATENA, V63, P132, DOI 10.1016/j.catena.2005.06.001
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Wechsler SP, 2007, HYDROL EARTH SYST SC, V11, P1481, DOI 10.5194/hess-11-1481-2007
   Williams G, 2011, USE R, V0, PP3, DOI 10.1007/978-1-4419-9890-3
   Youssef AM, 2016, LANDSLIDES, V13, P839, DOI 10.1007/s10346-015-0614-1
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang JX, 2008, INT J GEOGR INF SCI, V22, P925, DOI 10.1080/13658810701776817
   ZHANG WH, 1994, WATER RESOUR RES, V30, P1019, DOI 10.1029/93WR03553
   Zhou QM, 2004, COMPUT GEOSCI-UK, V30, P369, DOI 10.1016/j.cageo.2003.07.005
NR 95
TC 20
Z9 20
U1 6
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-9541
EI 1878-0512
J9 ECOL INFORM
JI Ecol. Inform.
PD NOV 15
PY 2021
VL 65
IS 
BP 
EP 
DI 10.1016/j.ecoinf.2021.101425
EA SEP 2021
PG 17
WC Ecology
SC Environmental Sciences & Ecology
GA WC8VE
UT WOS:000704529300003
DA 2023-04-26
ER

PT J
AU Prado-Rujas, II
   Garcia-Dopico, A
   Serrano, E
   Perez, MS
AF Prado-Rujas, Ignacio-Iker
   Garcia-Dopico, Antonio
   Serrano, Emilio
   Perez, Maria S.
TI A Flexible and Robust Deep Learning-Based System for Solar Irradiance Forecasting
SO IEEE ACCESS
LA English
DT Article
DE Forecasting; Sensors; Predictive models; Robustness; Task analysis; Data models; Solar panels; Convolutional long short-term memory (Conv-LSTM); deep learning; irradiance map; solar irradiance; time series forecasting
ID model
AB Most studies about the solar forecasting topic do not analyze and exploit the temporal and spatial components that are inherent to such a task. Furthermore, they mostly focus just on precision and not on other meaningful features, such as flexibility and robustness. With the current energy production trends, where many solar panels are distributed across city rooftops, there is a need to manage all this information simultaneously and to be able to add and remove sensors as needed. Likewise, robust models need to be able to cope with (inevitable) sensor failure and continue producing reliable predictions. Due to all of this, solar forecasting models need to be as decoupled as possible from the number of data sources that feed them and their geographical distribution, enabling also the reusability of the models. This article contributes with a family of Deep Learning models for solar irradiance forecasting complying with the aforementioned features, i.e. flexibility and robustness. In the first stage, several Artificial Neural Networks are trained as a basis for predicting solar irradiance on several locations at the same time. Thereupon, a family of models that work with irradiance maps thanks to Convolutional Long Short-Term Memory layers is presented, obtaining forecast skills between 7.4% and 41% (depending on the location and horizon) compared to the baseline. The latter family comes with flexibility and robustness features, which are required in large-scale Intelligent Environments, such as Smart Cities. Working with irradiance maps means that new sensors can be added (or removed) as needed, without requiring rebuilding the model. Experiments carried out show that sensor failures have a mild impact on the prediction error for several forecast horizons.
C1 [Prado-Rujas, Ignacio-Iker; Serrano, Emilio; Perez, Maria S.] Univ Politecn Madrid, ETSI Informat, Ontol Engn Grp, Madrid 28660, Spain.
   [Garcia-Dopico, Antonio] Univ Politecn Madrid, ETSI Informat, DATSI Comp Sci, Madrid 28660, Spain.
C3 Universidad Politecnica de Madrid; Universidad Politecnica de Madrid
RP Perez, MS (corresponding author), Univ Politecn Madrid, ETSI Informat, Ontol Engn Grp, Madrid 28660, Spain.
EM mperez@fi.upm.es
FU Autonomous Region of Madrid through the program CABAHLA-CM [P2018/TCS-4423]; Euratom Research and Training Programme 2019-2020 ENTENTE [900018]; R&D project Datos 4.0: Retos y soluciones [TIN2016-78011-C4-4-R]; Grant AEI/FEDER, UE
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Agrawal S., 2019, ARXIV191212132, V0, P0
   Alzahrani A, 2017, PROCEDIA COMPUT SCI, V114, P304, DOI 10.1016/j.procs.2017.09.045
   Silva RAE, 2018, SOL ENERGY, V163, P329, DOI 10.1016/j.solener.2018.01.095
   Andreas A, 2010, **DATA OBJECT**, V0, P0, DOI DOI 10.5439/1052451
   Arbizu-Barrena C, 2017, SOL ENERGY, V155, P1092, DOI 10.1016/j.solener.2017.07.045
   Ayet A, 2018, SOL ENERGY, V164, P301, DOI 10.1016/j.solener.2018.02.068
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Caldas M, 2019, RENEW ENERG, V143, P1643, DOI 10.1016/j.renene.2019.05.069
   Chollet F, 2015, KERAS, V0, P0
   Galicia A, 2019, KNOWL-BASED SYST, V163, P830, DOI 10.1016/j.knosys.2018.10.009
   Grodi R, 2016, IEEE SOUTHEASTCON, V0, P0
   Gruber I., 2017, COMPENDIUM WASTE MAN, V0, P0
   HAURWITZ B, 1945, J METEOROL, V2, P154, DOI 10.1175/1520-0469(1945)002<0154:IIRTCA>2.0.CO;2
   HAURWITZ B, 1946, J METEOROL, V3, P123, DOI 10.1175/1520-0469(1946)003<0123:IIRTCT>2.0.CO;2
   Hinkelman LM, 2013, SOL ENERGY, V88, P192, DOI 10.1016/j.solener.2012.11.011
   Holmgren W., 2018, **DATA OBJECT**, V3, P884, DOI 10.5281/zenodo.3585619
   Hontoria L, 2002, SOL ENERGY, V72, P441, DOI 10.1016/S0038-092X(02)00010-5
   Huang CJ, 2021, INT J ENERG RES, V45, P2511, DOI 10.1002/er.5945
   Huang CJ, 2019, IEEE ACCESS, V7, P74822, DOI 10.1109/ACCESS.2019.2921238
   Huang CJ, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18072220
   Li Q, 2019, ENRGY PROCED, V158, P3808, DOI 10.1016/j.egypro.2019.01.868
   Prado-Rujas I.-I., 2020, RESULTS GRAPHS DEEP, V0, P0
   Qing XY, 2018, ENERGY, V148, P461, DOI 10.1016/j.energy.2018.01.177
   Sergiou C, 2020, IEEE ACCESS, V8, P89007, DOI 10.1109/ACCESS.2020.2993527
   Shi XJ, 2015, ADV NEUR IN, V28, P0
   Wan HY, 2020, KNOWL-BASED SYST, V191, P0, DOI 10.1016/j.knosys.2019.105239
   Wang YS, 2018, ENERGIES, V11, P0, DOI 10.3390/en11082163
   Yang DZ, 2019, J RENEW SUSTAIN ENER, V11, P0, DOI 10.1063/1.5087462
NR 29
TC 11
Z9 11
U1 1
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2021
VL 9
IS 
BP 12348
EP 12361
DI 10.1109/ACCESS.2021.3051839
PG 14
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA PY1GH
UT WOS:000611796400001
DA 2023-04-26
ER

PT J
AU Wu, JS
   Li, XC
   Luo, YH
   Zhang, DN
AF Wu, Jiansheng
   Li, Xuechen
   Luo, Yuhang
   Zhang, Danni
TI Spatiotemporal effects of urban sprawl on habitat quality in the Pearl River Delta from 1990 to 2018
SO SCIENTIFIC REPORTS
LA English
DT Article
ID land-use; landscape patterns; ecosystem services; model; impact; china; urbanization; terrestrial
AB Since the implementation of the Chinese economic reforms. The habitat quality of coastal has gradually deteriorated with economic development, but the concept of "ecological construction" has slowed the negative trend. For quantitative analysis of the correlation between the Pearl River Delta urban expansion and changes in habitat quality under the influence of the policy, we first analyzed the habitat quality change based on the InVEST model and then measured the impact of construction land expansion on the habitat quality through habitat quality change index (HQCI) and contribution index (CI) indicators. Finally, the correlation between urbanization level and habitat quality was evaluated using geographically weighted regression (GWR) and the Self-organizing feature mapping neural network (SOFM). The results indicated that: (1) during the study period from 2000 to 2020, habitat quality declined due to urban sprawl, indicating a deterioration of ecological structure and function, and the decrease was most significant from 2000 to 2010. (2) The urbanization index had a negative effect on the habitat quality, but the negative effect have improved after 2000, reflecting the positive effect of policies such as "ecological civilization construction" (3) The implementation degree of ecological civilization varies greatly among cities in the study area: Shenzhen, Dongguan, Foshan, and Zhongshan have the best level of green development. These results reflect the positive role of policies in the prevention of damage to habitat quality caused by economic development and provide a reference for the formulation of sustainable urban development policies with spatial differences.
C1 [Wu, Jiansheng; Li, Xuechen; Luo, Yuhang; Zhang, Danni] Peking Univ, Sch Urban Planning & Design, Key Lab Urban Habitat Environm Sci & Technol, Shenzhen 518055, Peoples R China.
   [Wu, Jiansheng] Peking Univ, Coll Urban & Environm Sci, Key Lab Earth Surface Proc, Minist Educ, Beijing 100871, Peoples R China.
C3 Peking University; Peking University
RP Wu, JS (corresponding author), Peking Univ, Sch Urban Planning & Design, Key Lab Urban Habitat Environm Sci & Technol, Shenzhen 518055, Peoples R China.; Wu, JS (corresponding author), Peking Univ, Coll Urban & Environm Sci, Key Lab Earth Surface Proc, Minist Educ, Beijing 100871, Peoples R China.
EM wujs@pkusz.edu.cn
CR Adnan MSG, 2020, LAND USE POLICY, V99, P0, DOI 10.1016/j.landusepol.2020.104868
   Alkemade R, 2009, ECOSYSTEMS, V12, P374, DOI 10.1007/s10021-009-9229-5
   Bai LM, 2019, HABITAT INT, V93, P0, DOI 10.1016/j.habitatint.2019.102042
   Beumer LT, 2019, GLOB ECOL CONSERV, V18, P0, DOI 10.1016/j.gecco.2019.e00647
   Brunsdon C, 1996, GEOGR ANAL, V28, P281, DOI 10.1111/j.1538-4632.1996.tb00936.x
   Chen LS, 2021, LAND-BASEL, V10, P0, DOI 10.3390/land10020167
   Chen WX, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134690
   Chu Lin, 2018, YINGYONG SHENGTAI XUEBAO, V29, P4106, DOI 10.13287/j.1001-9332.201812.013
   Deng Y., 2018, ACTA ECOL SIN, V38, P4516, DOI 10.5846/stxb201712062200
   Fabris L, 2019, SCI TOTAL ENVIRON, V696, P0, DOI 10.1016/j.scitotenv.2019.133857
   Foody GM, 1999, ECOL MODEL, V120, P97, DOI 10.1016/S0304-3800(99)00094-0
   Hall LS, 1997, WILDLIFE SOC B, V25, P173
   Han YW, 2019, URBAN FOR URBAN GREE, V41, P354, DOI 10.1016/j.ufug.2019.04.015
   He JH, 2017, ECOL MODEL, V366, P58, DOI 10.1016/j.ecolmodel.2017.10.001
   Horcajada-Sanchez F., 2019, SCI REP, V9, P1
   Huang JL, 2020, LAND USE POLICY, V97, P0, DOI 10.1016/j.landusepol.2020.104772
   Jia ZM, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10041299
   Krauss J, 2010, ECOL LETT, V13, P597, DOI 10.1111/j.1461-0248.2010.01457.x
   Li FX, 2018, J ENVIRON MANAGE, V217, P486, DOI 10.1016/j.jenvman.2018.03.109
   Li HL, 2017, ECOL INDIC, V82, P50, DOI 10.1016/j.ecolind.2017.06.032
   Li X, 2018, J GEOD SCI, V8, P1, DOI 10.1515/jogs-2018-0001
   Li X, 2021, SCI TOTAL ENVIRON, V762, P0, DOI 10.1016/j.scitotenv.2020.143167
   Lin JY, 2021, SCI TOTAL ENVIRON, V763, P0, DOI 10.1016/j.scitotenv.2020.143012
   Liu YX, 2019, J ENVIRON MANAGE, V249, P0, DOI 10.1016/j.jenvman.2019.109315
   Luo YH, 2020, SCI TOTAL ENVIRON, V715, P0, DOI 10.1016/j.scitotenv.2020.136829
   McDonald RI, 2018, BIOL CONSERV, V224, P290, DOI 10.1016/j.biocon.2018.06.010
   Mocq J, 2013, ECOL MODEL, V265, P14, DOI 10.1016/j.ecolmodel.2013.05.020
   Moreira M, 2018, LAND USE POLICY, V78, P637, DOI 10.1016/j.landusepol.2018.07.015
   Morris Douglas W., 2020, ECOLOGY (WASHINGTON D C), V101, P03036
   Peng J, 2020, ECOSYST SERV, V44, P0, DOI 10.1016/j.ecoser.2020.101139
   Sharp R., 2018, INVEST 3 7 USERS GUI, V0, P0
   Simonit S, 2013, P NATL ACAD SCI USA, V110, P9326, DOI 10.1073/pnas.1112242110
   Song SX, 2020, ECOL INDIC, V112, P0, DOI 10.1016/j.ecolind.2020.106071
   Srivastava V, 2018, ECOL MODEL, V385, P35, DOI 10.1016/j.ecolmodel.2018.07.001
   Stankiewicz A, 2009, ACTA SOC BOT POL, V78, P167, DOI 10.5586/asbp.2009.021
   Sun X., 2019, ECOL INDIC, V102, P716
   Sun Xiaoping, 2019, BIODIVERSITY SCIENCE, V27, P51, DOI 10.17520/biods.2018182
   Tang F, 2020, ECOL INDIC, V117, P0, DOI 10.1016/j.ecolind.2020.106719
   Tang XG, 2016, SCI TOTAL ENVIRON, V557, P296, DOI 10.1016/j.scitotenv.2016.03.108
   Terrado M, 2016, SCI TOTAL ENVIRON, V540, P63, DOI 10.1016/j.scitotenv.2015.03.064
   Wang C, 2020, LAND USE POLICY, V90, P0, DOI 10.1016/j.landusepol.2019.104269
   Wilson MC, 2016, LANDSCAPE ECOL, V31, P229, DOI 10.1007/s10980-015-0322-1
   Wu Dan, 2020, ZHONGGUO SHENGTAI NONGYE XUEBAO / CHINESE JOURNAL OF ECO-AGRICULTURE, V28, P1969, DOI 10.13930/j.cnki.cjea.200221
   Wu LL, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13051008
   Xie YJ, 2013, APPL GEOGR, V39, P140, DOI 10.1016/j.apgeog.2013.01.001
   Xu XB, 2018, LAND USE POLICY, V79, P447, DOI 10.1016/j.landusepol.2018.08.037
   Zhang H, 2020, TRANSPORT RES D-TR E, V87, P0, DOI 10.1016/j.trd.2020.102551
   Zhang XR, 2020, LAND USE POLICY, V99, P0, DOI 10.1016/j.landusepol.2020.104957
   Zhao HZ, 2021, ECOL INDIC, V124, P0, DOI 10.1016/j.ecolind.2021.107414
   Zhao MY, 2018, ECOL ECON, V152, P106, DOI 10.1016/j.ecolecon.2018.04.023
   Zhou DY, 2018, ECOL INDIC, V95, P152, DOI 10.1016/j.ecolind.2018.07.007
   Zhu CM, 2020, ECOL INDIC, V117, P0, DOI 10.1016/j.ecolind.2020.106654
   ZHU JF, 2020, SUSTAINABILITY BASEL, V0012, P0, DOI 10.3390/SU12020669
NR 53
TC 19
Z9 19
U1 23
U2 97
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
EI 
J9 SCI REP-UK
JI Sci Rep
PD JUL 7
PY 2021
VL 11
IS 1
BP 
EP 
DI 10.1038/s41598-021-92916-3
PG 15
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA TL0IW
UT WOS:000674539400021
PM 34234165
DA 2023-04-26
ER

PT J
AU Shen, SY
   Chen, JS
   Zhang, SY
   Cheng, DB
   Wang, ZG
   Zhang, T
AF Shen, Shengyu
   Chen, Jiasheng
   Zhang, Shaoyi
   Cheng, Dongbing
   Wang, Zhigang
   Zhang, Tong
TI Deep Fusion of DOM and DSM Features for Benggang Discovery
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE benggang; deep learning; fusion; CNN; DOM; DSM
ID erosion; calanchi; network; scale
AB Benggang is a typical erosional landform in southern and southeastern China. Since benggang poses significant risks to local ecological environments and economic infrastructure, it is vital to accurately detect benggang-eroded areas. Relying only on remote sensing imagery for benggang detection cannot produce satisfactory results. In this study, we propose integrating high-resolution Digital Orthophoto Map (DOM) and Digital Surface Model (DSM) data for efficient and automatic benggang discovery. The fusion of complementary rich information hidden in both DOM and DSM data is realized by a two-stream convolutional neural network (CNN), which integrates aggregated terrain and activation image features that are both extracted by supervised deep learning. We aggregate local low-level geomorphic features via a supervised diffusion-convolutional embedding branch for expressive representations of benggang terrain variations. Activation image features are obtained from an image-oriented convolutional neural network branch. The two sources of information (DOM and DSM) are fused via a gated neural network, which learns the most discriminative features for the detection of benggang. The evaluation of a challenging benggang dataset demonstrates that our method exceeds several baselines, even with limited training examples. The results show that the fusion of DOM and DSM data is beneficial for benggang detection via supervised convolutional and deep fusion networks.
C1 [Shen, Shengyu; Cheng, Dongbing; Wang, Zhigang] Changjiang River Sci Res Inst CRSRI, Dept Soil & Water Conservat, Wuhan 430010, Peoples R China.
   [Shen, Shengyu; Cheng, Dongbing; Wang, Zhigang] Minist Water Resources, Res Ctr Mt Torrent & Geol Disaster Prevent, Wuhan 430010, Peoples R China.
   [Chen, Jiasheng; Zhang, Tong] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Zhang, Shaoyi] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
C3 Ministry of Water Resources; Wuhan University; Wuhan University
RP Zhang, T (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM shenshengyu@mail.crsri.cn; chenjs@whu.edu.cn; sy.zhang@whu.edu.cn; chengdb@mail.crsri.cn; wangzg@mail.crsri.cn; zhangt@whu.edu.cn
FU National Natural Science Foundation of China [41601298, 41871308]; Basic Scientific Research Operations Fund of Central Public Welfare Institutions [CKSF2014024/TB]; National Key R&D Program of China (International Scientific & Technological Cooperation Program) [2019YFE0106500]; Fundamental Research Funds for the Central Universities
CR [Anonymous], 2015, ICLR, V0, P0
   Arevalo J., 2017, P ICLR 2017 TOUL FRA, V0, P0
   Atwood J, 2016, P THEADVANCES NEURAL, V0, P1993
   Bacellar LDP, 2005, EARTH SURF PROC LAND, V30, P1369, DOI 10.1002/esp.1193
   Bragagnolo L, 2021, CATENA, V201, P0, DOI 10.1016/j.catena.2021.105189
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cox R, 2010, GEOLOGY, V38, P179, DOI 10.1130/G30670.1
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11172046
   Gu YT, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9102110
   Kingma D. P, 2015, PROC INT C LEARN REP, V0, P0
   Lin JS, 2015, CATENA, V129, P9, DOI 10.1016/j.catena.2015.02.012
   Liu HH, 2020, INT SOIL WATER CONSE, V8, P173, DOI 10.1016/j.iswcr.2020.03.004
   Liu HH, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104218
   Liu P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050894
   Luk SH, 1997, CATENA, V29, P97, DOI 10.1016/S0341-8162(96)00049-5
   Moretti S, 2000, CATENA, V40, P217, DOI 10.1016/S0341-8162(99)00086-7
   Neugirg F, 2016, GEOMORPHOLOGY, V269, P8, DOI 10.1016/j.geomorph.2016.06.027
   Prakash N, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-89015-8
   Prakash N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030346
   Shen S., 2020, ISPRS ANN PHOTOGRAMM, V5, P331, DOI 10.5194/isprs-annals-V-3-2020-331-2020
   Spinoulas L, 2015, IEEE COMPUT SOC CONF, V0, P0
   Tavakkoli Piralilou S, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212575
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030225
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   WELLS NA, 1991, EARTH SURF PROC LAND, V16, P189, DOI 10.1002/esp.3290160302
   Xie J, 2019, IEEE T GEOSCI REMOTE, V57, P6916, DOI 10.1109/TGRS.2019.2909695
   Xu JX, 1996, CATENA, V27, P249, DOI 10.1016/0341-8162(96)00014-8
   Yang JX, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050800
   Ye CM, 2019, IEEE J-STARS, V12, P5047, DOI 10.1109/JSTARS.2019.2951725
   Yi YN, 2020, IEEE J-STARS, V13, P6166, DOI 10.1109/JSTARS.2020.3028855
   Zeng Z., 1960, TOPOGRAPHIC PRINCIPL, V0, P0
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
NR 37
TC 0
Z9 0
U1 7
U2 24
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD AUG 15
PY 2021
VL 10
IS 8
BP 
EP 
DI 10.3390/ijgi10080556
PG 16
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA UG5DM
UT WOS:000689272900001
DA 2023-04-26
ER

PT J
AU Avand, M
   Moradi, H
   Lasboyee, MR
AF Avand, Mohammadtaghi
   Moradi, Hamidreza
   Lasboyee, Mehdi Ramazanzadeh
TI Spatial modeling of flood probability using geo-environmental variables and machine learning models, case study: Tajan watershed, Iran
SO ADVANCES IN SPACE RESEARCH
LA English
DT Article
DE Artificial neural network; Flood susceptibility; Machine learning; ROC curve; RFD approach; Tajan watershed
ID landslide susceptibility; discriminant-analysis; sensitivity-analysis; prediction; classification; optimization; algorithms; regression; framework; system
AB The main objective of this study was to produce flood susceptibility maps for Tajan watershed, Sari, Iran using three machine learning (ML) models including Self-Organization Map (SOM), Radial Basis Function Neural Network (RBFNN), and Multi-layers Perceptron (MLP). To reach such a goal, different physical-geographical factors (criteria) were integrated and mapped. 212 flood inventory map was randomly divided into training and testing datasets, where 148 flood locations (70%) were used for training and the remaining 64 locations (30%) were employed for testing. Model validation was performed using several statistical indices and the area under the curve (AUC). The results of the correlation matrix showed, three factors slope (0.277), distance from river (0.263), and altitude (0.223) were the most important factors affecting flood. The accuracy evaluation of the flood susceptibility maps through the AUC method and K-index shows that in the validation phase RBFNN (AUC = 0.90) outperform the MLP (AUC = 0.839) and SOM (AUC = 0.882) models. The highest percentage flood susceptibility of the area in MLP, SOM and RBFNN models is related to moderate (28.7%), very low (40%) and low (37%), respectively. Also, the validation results of the models using the Relative Flood Density (RFD) approach showed that very high class had the highest RFD value. (C) 2021 COSPAR. Published by Elsevier B.V. All rights reserved.
C1 [Avand, Mohammadtaghi; Moradi, Hamidreza] Tarbiat Modares Univ, Dept Watershed Management Engn, Coll Nat Resources & Marine Sci, Noor 46414356, Iran.
   [Lasboyee, Mehdi Ramazanzadeh] Mazandaran Univ, Dept Tourism Management, Fac Humanities & Social Sci, Babolsar, Mazandaran, Iran.
C3 Tarbiat Modares University; University of Mazandaran
RP Avand, M (corresponding author), Tarbiat Modares Univ, Dept Watershed Management Engn, Coll Nat Resources & Marine Sci, Noor 46414356, Iran.
EM mt.avand@modares.ac.ir; hrmoradi@modares.ac.ir; M.ramazanzadeh@umz.ac.ir
CR Ahmadlou M, 2019, GEOCARTO INT, V34, P1252, DOI 10.1080/10106049.2018.1474276
   Al-Juaidi AEM, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-4095-0
   Allison P.D., 1999, MULTIPLE REGRESSION, V0, P0
   [Anonymous], 2010, CLUSTER ANAL MULTIVA, V0, P0
   [Anonymous], 1975, ASSESSMENT RES NATUR, V0, P0
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203423
   Avand M, 2021, J HYDROL, V595, P0, DOI 10.1016/j.jhydrol.2020.125663
   Avand M, 2021, GEOSCIENCES, V11, P0, DOI 10.3390/geosciences11010025
   Azareh A, 2021, GEOCARTO INT, V36, P2345, DOI 10.1080/10106049.2019.1695958
   Baeza C, 2001, EARTH SURF PROC LAND, V26, P1251, DOI 10.1002/esp.263
   Band SS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213568
   Bolt B.A., 2013, GEOLOGICAL HAZARDS E, V0, P0
   Chapi K, 2017, ENVIRON MODELL SOFTW, V95, P229, DOI 10.1016/j.envsoft.2017.06.012
   Chen H, 2020, FUTURE GENER COMP SY, V111, P175, DOI 10.1016/j.future.2020.04.008
   Chen JJ, 2004, I C CONT AUTOMAT ROB, V0, P1365
   Chen W, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12233854
   Chen W, 2021, GEOSCI FRONT, V12, P93, DOI 10.1016/j.gsf.2020.07.012
   Chen W, 2020, CATENA, V195, P0, DOI 10.1016/j.catena.2020.104777
   Chen W, 2020, J HYDROL, V583, P0, DOI 10.1016/j.jhydrol.2020.124602
   Chen W, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134979
   Choubin B, 2019, SCI TOTAL ENVIRON, V651, P2087, DOI 10.1016/j.scitotenv.2018.10.064
   Coldewey W.G., 2019, HYDROGEOLOGY, V0, P0
   Constantin M, 2011, ENVIRON EARTH SCI, V63, P397, DOI 10.1007/s12665-010-0724-y
   Correia FN, 1998, WATER RESOUR MANAG, V12, P209
   Costache R, 2020, HYDROLOG SCI J, V65, P2816, DOI 10.1080/02626667.2020.1842412
   Costache R, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010106
   Costache R, 2019, WATER RESOUR MANAG, V33, P3239, DOI 10.1007/s11269-019-02301-z
   Dammalage TL, 2019, ENG TECHNOL APPL SCI, V9, P3887
   Darabi H, 2019, J HYDROL, V569, P142, DOI 10.1016/j.jhydrol.2018.12.002
   Delrieu G., 2009, 11 PLIN C MED STORMS, V0, P0
   Dhanalakshmi P, 2009, EXPERT SYST APPL, V36, P6069, DOI 10.1016/j.eswa.2008.06.126
   Diakakis M, 2012, NAT HAZARDS, V62, P485, DOI 10.1007/s11069-012-0090-z
   Bui DT, 2017, GEOSCI MODEL DEV, V10, P3391, DOI 10.5194/gmd-10-3391-2017
   Bui DT, 2016, J HYDROL, V540, P317, DOI 10.1016/j.jhydrol.2016.06.027
   Dodangeh E, 2020, SCI TOTAL ENVIRON, V705, P0, DOI 10.1016/j.scitotenv.2019.135983
   Gaillard JC, 2010, RELIGION, V40, P81, DOI 10.1016/j.religion.2009.12.001
   Gul GO, 2013, NAT HAZARDS, V69, P403, DOI 10.1007/s11069-013-0717-8
   Haddad EA, 2015, HABITAT INT, V45, P106, DOI 10.1016/j.habitatint.2014.06.023
   Hong HY, 2018, SCI TOTAL ENVIRON, V621, P1124, DOI 10.1016/j.scitotenv.2017.10.114
   Hosseini FS, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.135161
   Hudson P, 2014, NAT HAZARD EARTH SYS, V14, P1731, DOI 10.5194/nhess-14-1731-2014
   Ibrahim S, 2019, ADV ENG INFORM, V39, P278, DOI 10.1016/j.aei.2019.02.004
   Khosravi K, 2018, SCI TOTAL ENVIRON, V627, P744, DOI 10.1016/j.scitotenv.2018.01.266
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Lee G, 2013, NAT HAZARD EARTH SYS, V13, P1293, DOI 10.5194/nhess-13-1293-2013
   Lee S, 2017, GEOMAT NAT HAZ RISK, V8, P1185, DOI 10.1080/19475705.2017.1308971
   Lei XX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152478
   Li CY, 2018, COMPUT METH PROG BIO, V153, P211, DOI 10.1016/j.cmpb.2017.10.022
   Moradi H, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, V0, PP259, DOI 10.1016/B978-0-12-815226-3.00011-9
   Mori T, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-49031-1
   Mosavi A, 2022, GEOCARTO INT, V37, P2541, DOI 10.1080/10106049.2020.1829101
   Nachappa TG, 2020, J HYDROL, V590, P0, DOI 10.1016/j.jhydrol.2020.125275
   Nachappa TG, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172757
   Nachappa TG, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9245393
   Naghibi SA, 2017, J HYDROL, V548, P471, DOI 10.1016/j.jhydrol.2017.03.020
   Pal SC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223675
   Papaioannou G, 2015, WATER RESOUR MANAG, V29, P399, DOI 10.1007/s11269-014-0817-6
   Pourghasemi HR, 2012, CATENA, V97, P71, DOI 10.1016/j.catena.2012.05.005
   Pradhan B., 2010, J SPAT HYDROL, V9, P0
   Rahmati O, 2016, GEOCARTO INT, V31, P42, DOI 10.1080/10106049.2015.1041559
   Rajaei F, 2017, PADDY WATER ENVIRON, V15, P541, DOI 10.1007/s10333-016-0570-y
   Riley SJ, 1999, INTERMT J SCI, VSci5, P23, DOI 10.1016/j.geomorph.2010.11.003
   Rogan J, 2008, REMOTE SENS ENVIRON, V112, P2272, DOI 10.1016/j.rse.2007.10.004
   Rozalis S, 2010, J HYDROL, V394, P245, DOI 10.1016/j.jhydrol.2010.03.021
   Saadatdoost R., 2011, P INT C IEEE RES INN, V0, P1
   Saha S, 2021, SCI TOTAL ENVIRON, V764, P0, DOI 10.1016/j.scitotenv.2020.142928
   Samanta RK, 2018, MODEL EARTH SYST ENV, V4, P395, DOI 10.1007/s40808-018-0427-z
   Samanta S, 2016, HYDROLOGY-BASEL, V3, P0, DOI 10.3390/hydrology3030029
   Sepehri M, 2020, ACTA GEOPHYS, V68, P477, DOI 10.1007/s11600-019-00398-9
   Shirzadi A, 2020, ENG APPL ARTIF INTEL, V96, P0, DOI 10.1016/j.engappai.2020.103971
   Talukdar S, 2020, STOCH ENV RES RISK A, V34, P2277, DOI 10.1007/s00477-020-01862-5
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Tehrany MS, 2019, PEERJ, V7, P0, DOI 10.7717/peerj.7653
   Tehrany MS, 2015, STOCH ENV RES RISK A, V29, P1149, DOI 10.1007/s00477-015-1021-9
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Tehrany MS, 2014, J HYDROL, V512, P332, DOI 10.1016/j.jhydrol.2014.03.008
   Termeh SVR, 2018, SCI TOTAL ENVIRON, V615, P438, DOI 10.1016/j.scitotenv.2017.09.262
   Ultsch A, 2007, INT WORKSH SELF ORG, V0, P0
   Vojtek M, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11020364
   Xu X, 2014, SOFT COMPUT, V18, P797, DOI 10.1007/s00500-013-1089-4
   Xu YT, 2019, INFORM SCIENCES, V492, P181, DOI 10.1016/j.ins.2019.04.022
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3298981
   Yariyan P, 2020, GEOMAT NAT HAZ RISK, V11, P2282, DOI 10.1080/19475705.2020.1836036
   Yariyan P, 2020, SCI TOTAL ENVIRON, V745, P0, DOI 10.1016/j.scitotenv.2020.141008
   Yousefi S, 2020, ECOL INDIC, V117, P0, DOI 10.1016/j.ecolind.2020.106591
   Zare M, 2013, ARAB J GEOSCI, V6, P2873, DOI 10.1007/s12517-012-0610-x
   Zeng XQ, 2001, IEEE T NEURAL NETWOR, V12, P1358, DOI 10.1109/72.963772
   Zhang YN, 2021, ENG COMPUT-GERMANY, V37, P3741, DOI 10.1007/s00366-020-01028-5
   Zhao D, 2021, KNOWL-BASED SYST, V216, P0, DOI 10.1016/j.knosys.2020.106510
   Zhao X, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142180
NR 90
TC 24
Z9 24
U1 1
U2 15
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0273-1177
EI 1879-1948
J9 ADV SPACE RES
JI Adv. Space Res.
PD MAY 15
PY 2021
VL 67
IS 10
BP 3169
EP 3186
DI 10.1016/j.asr.2021.02.011
EA APR 2021
PG 18
WC Engineering, Aerospace; Astronomy & Astrophysics; Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences
SC Engineering; Astronomy & Astrophysics; Geology; Meteorology & Atmospheric Sciences
GA RO6FG
UT WOS:000641137900010
DA 2023-04-26
ER

PT J
AU Polykretis, C
   Grillakis, MG
   Argyriou, AV
   Papadopoulos, N
   Alexakis, DD
AF Polykretis, Christos
   Grillakis, Manolis G.
   Argyriou, Athanasios V.
   Papadopoulos, Nikos
   Alexakis, Dimitrios D.
TI Integrating Multivariate (GeoDetector) and Bivariate (IV) Statistics for Hybrid Landslide Susceptibility Modeling: A Case of the Vicinity of Pinios Artificial Lake, Ilia, Greece
SO LAND
LA English
DT Article
DE landslides; susceptibility; hybrid modeling; Geographical Detector; information value; Greece
ID logistic-regression; hierarchy process; frequency ratio; neural-network; region; prediction; province; basin
AB Over the last few years, landslides have occurred more and more frequently worldwide, causing severe effects on both natural and human environments. Given that landslide susceptibility (LS) assessments and mapping can spatially determine the potential for landslides in a region, it constitutes a basic step in effective risk management and disaster response. Nowadays, several LS models are available, with each one having its advantages and disadvantages. In order to enhance the benefits and overcome the weaknesses of individual modeling, the present study proposes a hybrid LS model based on the integration of two different statistical analysis models, the multivariate Geographical Detector (GeoDetector) and the bivariate information value (IV). In a GIS-based framework, the hybrid model named GeoDIV was tested to generate a reliable LS map for the vicinity of the Pinios artificial lake (Ilia, Greece), a Greek wetland. A landslide inventory of 60 past landslides and 14 conditioning (morphological, hydro-lithological and anthropogenic) factors was prepared to compose the spatial database. An LS map was derived from the GeoDIV model, presenting the different zones of potential landslides (probability) for the study area. This map was then validated by success and prediction rates-which translate to the accuracy and prediction ability of the model, respectively. The findings confirmed that hybrid modeling can outperform individual modeling, as the proposed GeoDIV model presented better validation results than the IV model.
C1 [Polykretis, Christos; Grillakis, Manolis G.; Argyriou, Athanasios V.; Papadopoulos, Nikos; Alexakis, Dimitrios D.] Fdn Res & TechnologyHellas FORTH, Inst Mediterranean Stud IMS, Lab Geophysical, Satellite Remote Sensing & ArchaeoEnvironment Ge, Rethimnon 74100, Greece.
RP Polykretis, C (corresponding author), Fdn Res & TechnologyHellas FORTH, Inst Mediterranean Stud IMS, Lab Geophysical, Satellite Remote Sensing & ArchaeoEnvironment Ge, Rethimnon 74100, Greece.
EM polykretis@ims.forth.gr; grillakis@hydrogaia.gr; nasos@ims.forth.gr; nikos@ims.forth.gr; dalexakis@ims.forth.gr
CR Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   [Anonymous], 1977, U KANSAS OCCASIONAL, V0, P0
   Arabameri A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11090999
   Baeza C, 2001, EARTH SURF PROC LAND, V26, P1251, DOI 10.1002/esp.263
   Balogun AL, 2021, GEOSCI FRONT, V12, P0, DOI 10.1016/j.gsf.2020.10.009
   Barella CF, 2019, B ENG GEOL ENVIRON, V78, P3205, DOI 10.1007/s10064-018-1341-3
   Borrelli L, 2018, LANDSLIDES, V15, P1127, DOI 10.1007/s10346-018-0947-7
   Brabb EE, 1984, P 4 INT S LANDSLIDES, V1, P307
   Calvello M, 2016, LANDSLIDES AND ENGINEERED SLOPES: EXPERIENCE, V0, P0
   Centre for Research on the Epidemiology of Disasters-CRED, 2021, DIS YEAR REV 2020 GL, V62, P2
   Centre for Research on the Epidemiology of Disasters-CRED United Nations International Strategy for Disaster Reduction-UNISDR, 2018, EC LOSS POV DIS 1998, V0, P33
   Chalkias C, 2016, GEOSCIENCES, V6, P0, DOI 10.3390/geosciences6010014
   Chen W, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9010171
   Chowdhuri I, 2020, ENVIRON EARTH SCI, V79, P0, DOI 10.1007/s12665-020-09227-5
   Chung CJF, 1999, PHOTOGRAMM ENG REM S, V65, P1389
   Ciurleo M, 2021, LANDSLIDES, V18, P2073, DOI 10.1007/s10346-021-01630-8
   Ciurleo M, 2017, ENG GEOL, V223, P71, DOI 10.1016/j.enggeo.2017.04.023
   Dagdelenler G, 2016, B ENG GEOL ENVIRON, V75, P575, DOI 10.1007/s10064-015-0759-0
   Dimitriadou S, 2018, GEOSCIENCES, V8, P0, DOI 10.3390/geosciences8040108
   Du GL, 2017, J MT SCI-ENGL, V14, P249, DOI 10.1007/s11629-016-4126-9
   Gorsevski PV, 2016, LANDSLIDES, V13, P467, DOI 10.1007/s10346-015-0587-0
   Kavoura K, 2020, LANDSLIDES, V17, P127, DOI 10.1007/s10346-019-01271-y
   Kayastha P, 2015, ARAB J GEOSCI, V8, P8601, DOI 10.1007/s12517-015-1831-6
   Lainas S, 2016, B ENG GEOL ENVIRON, V75, P883, DOI 10.1007/s10064-015-0762-5
   Li RW, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11060762
   Luo W, 2018, LANDSLIDES, V15, P465, DOI 10.1007/s10346-017-0893-9
   Luo XG, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-51941-z
   Mondal S, 2018, GEORISK, V12, P29, DOI 10.1080/17499518.2017.1347949
   Paryani S, 2020, NAT HAZARDS, V103, P1961, DOI 10.1007/s11069-020-04067-9
   Polykretis C, 2021, APPL GEOGR, V127, P0, DOI 10.1016/j.apgeog.2020.102384
   Polykretis C, 2018, NAT HAZARDS, V93, P249, DOI 10.1007/s11069-018-3299-7
   Popescu ME, 2002, P 3 INT C LANDSL SLO, V0, P61
   Pourghasemi HR, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3531-5
   Pradhan AMS, 2014, NAT HAZARDS, V72, P1189, DOI 10.1007/s11069-014-1065-z
   Psomiadis E, 2020, LAND-BASEL, V9, P0, DOI 10.3390/land9050133
   Rabby YW, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10120483
   Regmi AD, 2014, ARAB J GEOSCI, V7, P725, DOI 10.1007/s12517-012-0807-z
   Rong GZ, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12092572
   Roy J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232866
   Sabatakakis N, 2013, NAT HAZARDS, V65, P523, DOI 10.1007/s11069-012-0381-4
   Saha S, 2021, SCI TOTAL ENVIRON, V764, P0, DOI 10.1016/j.scitotenv.2020.142928
   Sakkas G, 2016, NAT HAZARDS, V84, P1873, DOI 10.1007/s11069-016-2523-6
   Schuster R.J., 1978, 176 TRB NAT RES COUN, V0, P11
   Shirzadi A, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-016-6374-y
   Su C, 2015, NAT HAZARDS, V76, P1759, DOI 10.1007/s11069-014-1562-0
   Taalab K, 2018, BIG EARTH DATA, V2, P159, DOI 10.1080/20964471.2018.1472392
   Tsangaratos P, 2016, LANDSLIDES, V13, P305, DOI 10.1007/s10346-015-0565-6
   Van Westen C.J., 1993, ITC PUBLICATION, V15, P245
   Varnes D.J., 1984, LANDSLIDE HAZARD ZON, V0, P0
   Vieira BC, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7436-0
   Wang JF, 2016, ECOL INDIC, V67, P250, DOI 10.1016/j.ecolind.2016.02.052
   Wang JF, 2010, INT J GEOGR INF SCI, V24, P107, DOI 10.1080/13658810802443457
   Xie W, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10020093
   Xing Y, 2021, FRONT EARTH SC-SWITZ, V9, P0, DOI 10.3389/feart.2021.722491
   Xiong JN, 2020, ISPRS INT GEO-INF, V9, P0, DOI 10.3390/ijgi9020133
   Yan F, 2019, GEOMORPHOLOGY, V327, P170, DOI 10.1016/j.geomorph.2018.10.024
   Yang JT, 2019, GEOMORPHOLOGY, V324, P62, DOI 10.1016/j.geomorph.2018.09.019
   Yang Y, 2019, LANDSLIDES, V16, P1301, DOI 10.1007/s10346-019-01174-y
   YIN KL, 1988, LANDSLIDES VOLS 13, V0, P1269
   Zhang GF, 2016, CATENA, V142, P233, DOI 10.1016/j.catena.2016.03.028
   Zhou C, 2020, ATMOSPHERE-BASEL, V11, P0, DOI 10.3390/atmos11010032
NR 64
TC 11
Z9 11
U1 5
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2073-445X
J9 LAND-BASEL
JI Land
PD SEP 15
PY 2021
VL 10
IS 9
BP 
EP 
DI 10.3390/land10090973
PG 23
WC Environmental Studies
SC Environmental Sciences & Ecology
GA UW0BC
UT WOS:000699831800001
DA 2023-04-26
ER

PT J
AU Wang, WJ
   Ma, L
   Chen, M
   Du, Q
AF Wang, Wenjin
   Ma, Li
   Chen, Min
   Du, Qian
TI Joint Correlation Alignment-Based Graph Neural Network for Domain Adaptation of Multitemporal Hyperspectral Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Hyperspectral imaging; Feature extraction; Correlation; Graph neural networks; Knowledge engineering; Geology; Deep learning; Classification; domain adaptation; graph neural network (GNN); hyperspectral remote sensing
ID convolutional networks; classification
AB In this article, we propose a novel deep domain adaptation method based on graph neural network (GNN) for multitemporal hyperspectral remote sensing images. In GNN, graphs are constructed for source and target data, respectively. Then the graphs are utilized in each hidden layer to obtain features. GNN operates on graph structure and the relations between data samples can be exploited. It aggregates features and propagate information through graph nodes. Thus, the extracted features have an improved smoothness in each spectral neighborhood which is beneficial to classification. Furthermore, the domain-wise correlation alignment (CORAL) and class-wise CORAL are jointly embedded in GNN network to achieve a joint distribution adaptation performance. By introducing the joint CORAL strategy in GNN, the extracted features can not only be aligned between domains but also have a superior discriminability in each domain. This domain adaptation network is named as joint CORAL-based graph neural network. Experiments using multitemporal Hyperion and NSF-funded center for airborne laser mapping datasets demonstrate the effectiveness of the proposed method.
C1 [Wang, Wenjin; Ma, Li; Chen, Min] China Univ Geosci, Sch Mech Engn & Elect Informat, Wuhan 430074, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Mississippi State, MS 39762 USA.
C3 China University of Geosciences; Mississippi State University
RP Ma, L (corresponding author), China Univ Geosci, Sch Mech Engn & Elect Informat, Wuhan 430074, Peoples R China.
EM crazyjin1996@cug.edu.cn; mali@cug.edu.cn; suprecm7@cug.edu.cn; du@ece.msstate.edu
FU National Natural Science Foundations of China [61771437, 61102104, 91442201]
CR Bachmann CM, 2005, IEEE T GEOSCI REMOTE, V43, P441, DOI 10.1109/TGRS.2004.842292
   Bahirat K, 2012, IEEE T GEOSCI REMOTE, V50, P2810, DOI 10.1109/TGRS.2011.2174154
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bruna J., 2014, 2 INT C LEARNING REP, V0, P1
   Bruzzone L, 2001, IEEE T GEOSCI REMOTE, V39, P456, DOI 10.1109/36.905255
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Chen M, 2020, IEEE J-STARS, V13, P6236, DOI 10.1109/JSTARS.2020.3030304
   Defferrard M, 2016, ADV NEUR IN, V29, P0
   Donahue J., 2013, ARXIV13101531, V0, P0
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Ge CR, 2019, 2019 10TH INTERNATIONAL WORKSHOP ON THE ANALYSIS OF MULTITEMPORAL REMOTE SENSING IMAGES (MULTITEMP), V0, P0
   Gong B., 2013, P INT C MACH LEARN, V0, P222
   Goodfellowet I., 2014, ARXIV14062661, V0, P0
   Gori M, 2005, IEEE IJCNN, V0, P729
   Gross W, 2019, IEEE T GEOSCI REMOTE, V57, P5975, DOI 10.1109/TGRS.2019.2903719
   Henaff M., 2015, ABS150605163 CORR, V0, P0
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Jiang B, 2018, IEEE CONF COMM NETW, V0, P0
   Kim W, 2010, IEEE T GEOSCI REMOTE, V48, P4110, DOI 10.1109/TGRS.2010.2076287
   Kipf T. N., 2017, ICLR, V0, P0
   Liu ZX, 2021, IEEE T GEOSCI REMOTE, V59, P508, DOI 10.1109/TGRS.2020.2997863
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2014, PROC CVPR IEEE, V0, PP1410, DOI 10.1109/CVPR.2014.183
   Ma L, 2019, IEEE T GEOSCI REMOTE, V57, P2305, DOI 10.1109/TGRS.2018.2872850
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P8246, DOI 10.1109/TGRS.2020.2973363
   Neuenschwander A. L., 2007, REMOTE SENSING VEGET, V0, P0
   Peng JT, 2019, IEEE T GEOSCI REMOTE, V57, P1183, DOI 10.1109/TGRS.2018.2865102
   Persello C, 2016, IEEE T GEOSCI REMOTE, V54, P2615, DOI 10.1109/TGRS.2015.2503885
   Rajan S, 2006, IEEE T GEOSCI REMOTE, V44, P3408, DOI 10.1109/TGRS.2006.878442
   Saha S, 2019, INT GEOSCI REMOTE SE, V0, PP5033, DOI 10.1109/IGARSS.2019.8900173
   Song L., 2018, UNSUPERVISED DOMAIN, V0, P0
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   Tzeng E., 2014, COMPUT SCI, V0, P0
   Wan S, 2021, IEEE T GEOSCI REMOTE, V59, P597, DOI 10.1109/TGRS.2020.2994205
   Wan S, 2020, IEEE T GEOSCI REMOTE, V58, P3162, DOI 10.1109/TGRS.2019.2949180
   Wang C., 2019, P IEEE INT GEOSC REM, V0, P1
   Wang ZM, 2019, IEEE GEOSCI REMOTE S, V16, P1155, DOI 10.1109/LGRS.2018.2889967
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie SA, 2018, PR MACH LEARN RES, V80, P0
   Xinyi Tong, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP), V0, PP1686, DOI 10.1109/ICIP40778.2020.9190752
   Zhong EH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P1027
   Zhu L, 2016, PATTERN RECOGN LETT, V83, P124, DOI 10.1016/j.patrec.2015.12.015
NR 43
TC 15
Z9 15
U1 9
U2 44
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3170
EP 3184
DI 10.1109/JSTARS.2021.3063460
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RE9UV
UT WOS:000634496000006
DA 2023-04-26
ER

PT J
AU Song, W
   Li, MH
   Gao, W
   Huang, DM
   Ma, ZL
   Liotta, A
   Perra, C
AF Song, Wei
   Li, Minghui
   Gao, Wen
   Huang, Dongmei
   Ma, Zhenling
   Liotta, Antonio
   Perra, Cristian
TI Automatic Sea-Ice Classification of SAR Images Based on Spatial and Temporal Features Learning
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Sea ice; Ice; Radar polarimetry; Synthetic aperture radar; Feature extraction; Sea surface; Surface roughness; Ice charts; long short-term memory (LSTM); residual convolution network; sea-ice classification; synthetic aperture radar (SAR)
ID x-band sar; texture analysis; neural-network; cooccurrence; water; segmentation; fusion; full
AB Sea ice has a significant effect on climate change and ship navigation. Hence, it is crucial to draw sea-ice maps that reflect the geographical distribution of different types of sea ice. Many automatic sea-ice classification methods using synthetic aperture radar (SAR) images are based on the polarimetric characteristics or image texture features of sea ice. They either require professional knowledge to design the parameters and features or are sensitive to noise and condition changes. Moreover, ice changes over time are often ignored. In this article, we propose a new SAR sea-ice image classification method based on a combined learning of spatial and temporal features, derived from residual convolutional neural networks (ResNet) and long short-term memory (LSTM) networks. In this way, we achieve automatic and refined classification of sea-ice types. First, we construct a seven-type ice data set according to the Canadian Ice Service ice charts. We extract spatial feature vectors of a time series of sea-ice samples using a trained ResNet network. Then, using the feature vectors as inputs, the LSTM network further learns the variation of the set of sea-ice samples with time. Finally, the extracted high-level features are fed into a softmax classifier to output the most recent ice type. Taking both spatial features and time variation into consideration, our method can achieve a high classification accuracy of 95.7% for seven ice types. Our method can automatically produce more objective sea-ice interpretation maps, allowing detailed sea-ice distribution and improving the efficiency of sea-ice monitoring tasks.
C1 [Song, Wei; Li, Minghui; Gao, Wen; Ma, Zhenling] Shanghai Ocean Univ, Coll Informat Technol, Shanghai 2013016, Peoples R China.
   [Huang, Dongmei] Shanghai Univ Elect Power, Shanghai 201306, Peoples R China.
   [Liotta, Antonio] Free Univ Bozen Bolzano, Fac Comp Sci, I-39100 Bolzano, Italy.
   [Perra, Cristian] Univ Cagliari, CNIT Lab, Dept Elect & Elect Engn, I-09124 Cagliari, Italy.
C3 Shanghai Ocean University; Shanghai University of Electric Power; Free University of Bozen-Bolzano; University of Cagliari
RP Song, W; Ma, ZL (corresponding author), Shanghai Ocean Univ, Coll Informat Technol, Shanghai 2013016, Peoples R China.
EM wsong@shou.edu.cn; zlma@shou.edu.cn; antonio.liotta@unibz.it; cperra@ieee.org
FU National Key Research and Development Program [2016YFC1400304]; National Natural Science Foundation of China [61972240]; Capacity Development for Shanghai Local College [20050501900]
CR Aldenhoff W, 2020, IEEE J-STARS, V13, P1540, DOI 10.1109/JSTARS.2020.2977506
   Arkett M, 2015, CAN J REMOTE SENS, V41, P380, DOI 10.1080/07038992.2015.1104631
   Asadi N, 2021, IEEE T GEOSCI REMOTE, V59, P247, DOI 10.1109/TGRS.2020.2992454
   Buono A, 2016, IEEE GEOSCI REMOTE S, V13, P1527, DOI 10.1109/LGRS.2016.2595058
   Carsey F.D., 1992, MICROWAVE REMOTE SEN, V0, P0
   Chen SZ, 2016, IEEE T GEOSCI REMOTE, V54, P4806, DOI 10.1109/TGRS.2016.2551720
   Chi J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121305
   Cho K, 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/V1/D14-1179
   Clausi DA, 2004, IEEE T GEOSCI REMOTE, V42, P215, DOI 10.1109/TGRS.2003.817218
   Clausi DA, 2001, ATMOS OCEAN, V39, P183, DOI 10.1080/07055900.2001.9649675
   Dabboor M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040594
   Dabboor M, 2013, ISPRS J PHOTOGRAMM, V84, P1, DOI 10.1016/j.isprsjprs.2013.06.010
   Deng H, 2005, IEEE T GEOSCI REMOTE, V43, P528, DOI 10.1109/TGRS.2004.839589
   Dierking W, 2004, REMOTE SENSING IN TRANSITION, V0, P203
   Dierking W., 2003, P WORKSH POL INT, V0, P1
   Du YL, 2019, INFORM FUSION, V49, P89, DOI 10.1016/j.inffus.2018.09.006
   Filipponi F., 2019, PROCEEDINGS, V18, P11, DOI 10.3390/ECRS-3-06201
   Geldsetzer T, 2009, CAN J REMOTE SENS, V35, P73, DOI 10.5589/m08-075
   Geldsetzer T, 2015, CAN J REMOTE SENS, V41, P485, DOI 10.1080/07038992.2015.1120661
   Ghanbari M, 2019, IEEE T GEOSCI REMOTE, V57, P7476, DOI 10.1109/TGRS.2019.2913796
   Graves A, 2012, STUD COMPUT INTELL, V385, P37
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Howell SEL, 2018, REMOTE SENS ENVIRON, V204, P380, DOI 10.1016/j.rse.2017.10.017
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   LEE JS, 1994, INT J REMOTE SENS, V15, P2299, DOI 10.1080/01431169408954244
   Leigh S, 2014, IEEE T GEOSCI REMOTE, V52, P5529, DOI 10.1109/TGRS.2013.2290231
   Li JX, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017), V0, P0
   Liu HY, 2016, IEEE J-STARS, V9, P1187, DOI 10.1109/JSTARS.2015.2497355
   Liu HY, 2015, IEEE J-STARS, V8, P1601, DOI 10.1109/JSTARS.2014.2365215
   Moen MAN, 2013, CRYOSPHERE, V7, P1693, DOI 10.5194/tc-7-1693-2013
   Nair V, 2010, ICML, V27, P807
   Ochilov S, 2012, IEEE T GEOSCI REMOTE, V50, P4397, DOI 10.1109/TGRS.2012.2192278
   Park JW, 2018, IEEE T GEOSCI REMOTE, V56, P1555, DOI 10.1109/TGRS.2017.2765248
   Partington KC, 2010, IEEE T GEOSCI REMOTE, V48, P2685, DOI 10.1109/TGRS.2009.2039577
   Petrou ZI, 2017, INT GEOSCI REMOTE SE, V0, PP5422, DOI 10.1109/IGARSS.2017.8128230
   Poliyapram V, 2019, INT GEOSCI REMOTE SE, V0, PP3884, DOI 10.1109/IGARSS.2019.8900323
   Ressel R, 2016, INT GEOSCI REMOTE SE, V0, PP4835, DOI 10.1109/IGARSS.2016.7730261
   Ressel R, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030198
   Ressel R, 2015, IEEE J-STARS, V8, P3672, DOI 10.1109/JSTARS.2015.2436993
   Scheuchl B, 2002, INT GEOSCI REMOTE SE, V0, PP1914, DOI 10.1109/IGARSS.2002.1026298
   Singha S, 2018, IEEE T GEOSCI REMOTE, V56, P3715, DOI 10.1109/TGRS.2018.2809504
   Singha S, 2017, IEEE J-STARS, V10, P3504, DOI 10.1109/JSTARS.2017.2691258
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Song W, 2018, INT CONF DAT MIN WOR, V0, PP795, DOI 10.1109/ICDMW.2018.00119
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Touzi R, 2009, P 4 INT WORKSH SCI A, V0, P9
   Vihma T, 2014, SURV GEOPHYS, V35, P1175, DOI 10.1007/s10712-014-9284-0
   Wakabayashi H, 2004, IEEE T GEOSCI REMOTE, V42, P2412, DOI 10.1109/TGRS.2004.836259
   Wang L, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050408
   Wang L, 2016, IEEE T GEOSCI REMOTE, V54, P4524, DOI 10.1109/TGRS.2016.2543660
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Yu QY, 2007, IEEE T GEOSCI REMOTE, V45, P3919, DOI 10.1109/TGRS.2007.908876
   Yu QY, 2002, INT GEOSCI REMOTE SE, V0, PP3041, DOI 10.1109/IGARSS.2002.1026863
   Zakhvatkina N, 2017, CRYOSPHERE, V11, P0, DOI 10.5194/tc-11-33-2017
   Zhang X., 2015, J PHYS CHEM LETT, V9, P5445
   Zhao ZQ, 2017, PATTERN RECOGN, V61, P686, DOI 10.1016/j.patcog.2016.05.028
   Zhu TT, 2016, IEEE J-STARS, V9, P2451, DOI 10.1109/JSTARS.2016.2551318
NR 59
TC 10
Z9 11
U1 13
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD DEC 15
PY 2021
VL 59
IS 12
BP 9887
EP 9901
DI 10.1109/TGRS.2020.3049031
PG 15
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology
GA XC7DV
UT WOS:000722170500011
DA 2023-04-26
ER

PT J
AU Gameiro, S
   Riffel, ES
   de Oliveira, GG
   Guasselli, LA
AF Gameiro, Samuel
   Riffel, Eduardo Samuel
   de Oliveira, Guilherme Garcia
   Guasselli, Laurindo Antonio
TI Artificial neural networks applied to landslide susceptibility: The effect of sampling areas on model capacity for generalization and extrapolation
SO APPLIED GEOGRAPHY
LA English
DT Article
DE Sampling; Machine learning; Natural hazards; Predictive attributes
ID support vector machine; logistic-regression; random forest; river-basin; absence data; prediction; classification; county; maps; svm
AB Artificial neural networks (ANNs) have been used to identify areas susceptible to landslides and constitute one of the most widely used methods for this purpose. Several factors can interfere in the performance of the models and their resulting maps (especially sampling). This research evaluated the influence of sampling areas on landslide susceptibility modelling and the capacity for generalization and spatial extrapolation of data. Based on an inventory of landslide scars, distributed in five areas of southern Brazil, non-occurrence samples were defined by means of different buffers (2-40 km) in relation to the landslides in order to test the effect of the spatial distribution of the non-occurrence samples on the modeling results. A total of 16 morphometric attributes of the terrain (extracted from a digital elevation model) were used as input variables of the model. Multilayered network training was carried out using a backpropagation algorithm and accuracy was calculated by means of the Area Under the Receiver Operating Characteristic Curve (AUROC). Model accuracy was between 0.739 and 0.931. This variation was explained mainly by the buffer used. The susceptibility map resulting from the model of greater accuracy was obtained with a 40-km buffer in order to collect non-occurrence samples. The great distance between the occurrence and non-occurrence samples facilitates the modelling, since it increases the morphometric differences between the sampling groups. When we used samples from only one of the sample areas, the spatial extrapolation of the susceptibility map to the other areas showed high performance. We conclude that the ANN model for landslides susceptibility mapping can be extrapolated spatially, considering the limits of the geomorphological unit or numerical domain of the data.
C1 [Gameiro, Samuel; Riffel, Eduardo Samuel; de Oliveira, Guilherme Garcia; Guasselli, Laurindo Antonio] Univ Fed Rio Grande do Sul, Av Bento Goncalves 9500-44202, BR-91501970 Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Gameiro, S (corresponding author), Univ Fed Rio Grande do Sul, Av Bento Goncalves 9500-44202, BR-91501970 Porto Alegre, RS, Brazil.
EM samuel_gameiro@outlook.com; edriffel@gmail.com; g.g.oliveira10@gmail.com; laurindo.guasselli@ufrgs.br
FU CAPES [88882.438888/2011-01]; Fundacao de Amparo a Pesquisa do Estado do Rio Grande do Sul (FAPERGS) [17/2551-0000894-4]
CR Al-Najjar HAH, 2019, PROC SPIE, V11156, P0, DOI 10.1117/12.2532687
   Araujo T. M. A., 2015, THESIS U FEDERAL ALA, V0, P91
   Betiollo L. M., 2006, THESIS U FEDERAL RIO, V0, P117
   Bock M., 2008, HAMBURGER BEITRAGE P, V19, P13
   Bokwa A, 2013, ENCY NATURAL HAZARDS, V0, PP711, DOI 10.1007/978-1-4020-4399-4_248
   Cantarino I, 2019, LANDSLIDES, V16, P265, DOI 10.1007/s10346-018-1063-4
   Catani F, 2013, NAT HAZARD EARTH SYS, V13, P2815, DOI 10.5194/nhess-13-2815-2013
   Chen W, 2018, SCI TOTAL ENVIRON, V626, P1121, DOI 10.1016/j.scitotenv.2018.01.124
   Chen W, 2017, GEODERMA, V305, P314, DOI 10.1016/j.geoderma.2017.06.020
   Chen W, 2017, CATENA, V151, P147, DOI 10.1016/j.catena.2016.11.032
   de Oliveira GG, 2019, NAT HAZARDS, V99, P1049, DOI 10.1007/s11069-019-03795-x
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Fang ZC, 2020, COMPUT GEOSCI-UK, V139, P0, DOI 10.1016/j.cageo.2020.104470
   Fernandes NF, 2004, CATENA, V55, P163, DOI 10.1016/S0341-8162(03)00115-2
   Galli M, 2008, GEOMORPHOLOGY, V94, P268, DOI 10.1016/j.geomorph.2006.09.023
   Gameiro S., 2019, S BRASILEIRO SENSORI, V0, PXIX
   Goetz JN, 2015, COMPUT GEOSCI-UK, V81, P1, DOI 10.1016/j.cageo.2015.04.007
   Gordo C, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9060268
   Gpden/Iph/Ufrgs Diagnostico preliminar, 2017, DEP REC HIDR SEMA GR, V0, P26
   Greco R, 2013, NAT HAZARD EARTH SYS, V13, P2209, DOI 10.5194/nhess-13-2209-2013
   Guisan A, 1999, PLANT ECOL, V143, P107, DOI 10.1023/A:1009841519580
   Hartmann L. A., 2014, HIST NATURAL GRUPO S, V36, P0
   He QF, 2019, SCI TOTAL ENVIRON, V663, P1, DOI 10.1016/j.scitotenv.2019.01.329
   Heckmann T, 2014, NAT HAZARD EARTH SYS, V14, P259, DOI 10.5194/nhess-14-259-2014
   HIGHLAND L.M., 2008, LANDSLIDE HDB GUID U, V1325, P129
   Hong HY, 2019, CATENA, V176, P45, DOI 10.1016/j.catena.2018.12.035
   Hong HY, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-017-6981-2
   Hong HY, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2094-y
   Huang Y, 2018, CATENA, V165, P520, DOI 10.1016/j.catena.2018.03.003
   Kalantar B, 2018, GEOMAT NAT HAZ RISK, V9, P49, DOI 10.1080/19475705.2017.1407368
   Kavzoglu T, 2014, LANDSLIDES, V11, P425, DOI 10.1007/s10346-013-0391-7
   Kothe R., 1993, Z ANGEW GEOGR, V4, P11
   Kumar D, 2017, GEOMORPHOLOGY, V295, P115, DOI 10.1016/j.geomorph.2017.06.013
   Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X
   Lee S, 2001, ENVIRON GEOL, V40, P1095, DOI 10.1007/s002540100310
   Losasso L, 2018, GEOMAT NAT HAZ RISK, V9, P737, DOI 10.1080/19475705.2018.1476413
   Machado F. B., 2005, THESIS U ESTADUAL PA, V0, P0
   Moller M, 2008, J PLANT NUTR SOIL SC, V171, P419, DOI 10.1002/jpln.200625039
   Moller M, 2012, CATENA, V88, P57, DOI 10.1016/j.catena.2011.08.002
   Moosavi V, 2016, LANDSLIDES, V13, P97, DOI 10.1007/s10346-014-0547-0
   Neto O. F., 2006, S BRAS JOV GEOT GEOJ, V0, P0
   Nourani V, 2014, NAT HAZARDS, V71, P523, DOI 10.1007/s11069-013-0932-3
   Oliveira G. G., 2014, REV BRASILEIRA RECUR, V19, P251, DOI 10.21168/rbrh.v19n2.p251-265
   Oliveira G. G., 1900, P10, V0, P0
   Oliveira GG, 2015, ENG APPL ARTIF INTEL, V40, P47, DOI 10.1016/j.engappai.2015.01.001
   Petschko H, 2014, NAT HAZARD EARTH SYS, V14, P95, DOI 10.5194/nhess-14-95-2014
   Nguyen PT, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9142824
   Pradhan B, 2010, LANDSLIDES, V7, P13, DOI 10.1007/s10346-009-0183-2
   Quan HC, 2012, KSCE J CIV ENG, V16, P1258, DOI 10.1007/s12205-012-1242-0
   Quevedo R. P., 2019, GEOCIENCIAS, V38, P0
   Quevedo R. P., 2019, THESIS U FEDERAL RIO, V0, P0
   Rahmati O, 2017, GEOMORPHOLOGY, V298, P118, DOI 10.1016/j.geomorph.2017.09.006
   Roisenberg A., 2000, GEOLOGIA RIO GRANDE, V0, P355
   Rossato M. S., 2011, THESIS U FED RIO GRA, V0, P0
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sameen MI, 2020, CATENA, V186, P0, DOI 10.1016/j.catena.2019.104249
   Samia J., 2019, NAT HAZARDS EARTH SY, V0, PP1, DOI 10.5194/NHESS-2019-125
   Samia J, 2017, GEOMORPHOLOGY, V292, P16, DOI 10.1016/j.geomorph.2017.04.039
   Shahabi H, 2015, SCI REP-UK, V5, P0, DOI 10.1038/srep09899
   Steger S, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, V0, PP519, DOI 10.1016/B978-0-12-815226-3.00024-7
   Steger S, 2016, NAT HAZARD EARTH SYS, V16, P2729, DOI 10.5194/nhess-16-2729-2016
   Tarini M, 2006, IEEE T VIS COMPUT GR, V12, P1237, DOI 10.1109/TVCG.2006.115
   Tominaga LK., 2009, DESASTRES NATURAIS C, V0, P0
   UNISDR CRED, 2015, HUM COST WEATH REL D, V0, P0
   den Eeckhaut M, 2006, GEOMORPHOLOGY, V76, P392, DOI 10.1016/j.geomorph.2005.12.003
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Wang YM, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104425
   Weiss A.D., 2001, ESRI USER C, V0, P227
   Xiao CC, 2010, SCI CHINA TECHNOL SC, V53, P75, DOI 10.1007/s11431-010-3219-x
   Xie P, 2018, GEOMAT NAT HAZ RISK, V9, P501, DOI 10.1080/19475705.2018.1451399
   Xu C, 2014, NAT HAZARD EARTH SYS, V14, P1789, DOI 10.5194/nhess-14-1789-2014
   Yao X, 2008, GEOMORPHOLOGY, V101, P572, DOI 10.1016/j.geomorph.2008.02.011
   Zanin PR, 2017, REV BRAS GEOMORFOL, V18, P19, DOI 10.20502/rbg.v18i1.1023
   ZEVENBERGEN LW, 1987, EARTH SURF PROCESSES, V12, P47, DOI 10.1002/esp.3290120107
   Zhu AX, 2018, CATENA, V171, P222, DOI 10.1016/j.catena.2018.07.012
NR 75
TC 7
Z9 7
U1 4
U2 19
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0143-6228
EI 1873-7730
J9 APPL GEOGR
JI Appl. Geogr.
PD DEC 15
PY 2021
VL 137
IS 
BP 
EP 
DI 10.1016/j.apgeog.2021.102598
EA NOV 2021
PG 13
WC Geography
SC Geography
GA XA2HA
UT WOS:000720473700005
DA 2023-04-26
ER

PT J
AU Lai, YQ
   Wang, HL
   Sun, XL
AF Lai, Yu-Qing
   Wang, Hui-Li
   Sun, Xiao-Lin
TI A comparison of importance of modelling method and sample size for mapping soil organic matter in Guangdong, China
SO ECOLOGICAL INDICATORS
LA English
DT Article
DE Digital soil mapping; Modelling method; Sample size; Soil organic matter
ID geographically weighted regression; spatial prediction; neural-network; carbon; interpolation; indicators; variables; density; error
AB Digital soil mapping (DSM) is the most widely used method for producing spatial information of soil organic matter (SOM). Accuracy of the information is generally determined by modelling methods and sample sizes used for DSM. However, different studies present different importance of modelling method and sample size on accuracy of DSM, while they do not explore various combinations of modelling method and sample size. Based on the studies, it is supposed that there exists an optimal combination of modelling method and sample size for producing information of SOM accurately and economically. With SOM data of 1861 soil samples collected in Guangdong, China, the present study first assessed importance of modelling method and sample size and then examined if an optimal combination of modelling method and sample size existed for the area. Six modelling methods were explored, while 12 sample sizes were used, ranging from 100 to 1200 with an interval of 100. For each size, 10 repeated samples were randomly taken from a data of 1311 samples which were randomly selected from all the 1861 soil samples based on the probability distribution of the SOM data. The results showed that, for small sample sizes, the modelling methods have a greater impact on accuracy of DSM. However, for large sample sizes, e.g., more than 1000, the sample sizes have a much greater impact. Due to the varying importance of modelling method and sample size, there exists an optimal combination of modelling method and sample size for spatial prediction of SOM in the area, i.e., the combination of regression kriging and a sample size of 800. Thus, for economically producing detailed and accurate information on spatial distribution of SOM, it is recommended that a series of modelling methods and sample sizes are tried to identify an optimal combination of modelling method and sample size.
C1 [Lai, Yu-Qing; Sun, Xiao-Lin] Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
   [Wang, Hui-Li] Guangxi Forestry Res Inst, Nanning 530002, Peoples R China.
C3 Sun Yat Sen University
RP Sun, XL (corresponding author), Sun Yat Sen Univ, Rm D303-1,Dihuan Bldg,135 Xingang West Rd, Guangzhou 510275, Peoples R China.
EM sxiaolin@mail.sysu.edu.cn
FU National Natural Science Foundation of China [41771246, 42071062]
CR Agricultural Chemistry Committee of China, 1983, CONV METH SOIL AGR C, V0, P70
   Bohner J., 2006, SAGA ANAL MODELLING, V115, P13
   Boubehziz S, 2020, CATENA, V190, P0, DOI 10.1016/j.catena.2020.104539
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Broomhead D. S., 1988, COMPLEX SYSTEMS, V2, P321
   Brunsdon C, 1996, GEOGR ANAL, V28, P281, DOI 10.1111/j.1538-4632.1996.tb00936.x
   Conrad O, 2015, GEOSCI MODEL DEV, V8, P1991, DOI 10.5194/gmd-8-1991-2015
   Dharumarajan S, 2019, GEODERMA REG, V16, P0, DOI 10.1016/j.geodrs.2019.e00204
   Ellinger M, 2019, SOIL-GERMANY, V5, P275, DOI 10.5194/soil-5-275-2019
   Forkuor G, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0170478
   Fotheringham A. S., 2002, GEOGRAPHICALLY WEIGH, V0, P0
   Gautam R, 2011, BIOSYST ENG, V110, P20, DOI 10.1016/j.biosystemseng.2011.06.002
   Guo PT, 2013, NUTR CYCL AGROECOSYS, V95, P333, DOI 10.1007/s10705-013-9566-9
   Hengl T, 2004, GEODERMA, V120, P75, DOI 10.1016/j.geoderma.2003.08.018
   Hijmans RJ, 2005, INT J CLIMATOL, V25, P1965, DOI 10.1002/joc.1276
   Ihaka R., 1996, J COMPUTNL GRAPH STA, V5, P299, DOI 10.2307/1390807
   Ishwaran H, 2008, ANN APPL STAT, V2, P841, DOI 10.1214/08-AOAS169
   IUSS Working Group WRB, 2015, WORLD REFERENCE BASE, V0, P0
   Khaledian Y, 2020, APPL MATH MODEL, V81, P401, DOI 10.1016/j.apm.2019.12.016
   Kravchenko AN, 2007, AGRON J, V99, P12, DOI 10.2134/agronj2005.0251
   Kuang B, 2012, EUR J SOIL SCI, V63, P421, DOI 10.1111/j.1365-2389.2012.01456.x
   Lagacherie P, 2020, GEODERMA, V375, P0, DOI 10.1016/j.geoderma.2020.114503
   Lamichhane S, 2019, GEODERMA, V352, P395, DOI 10.1016/j.geoderma.2019.05.031
   Lark RM, 2006, EUR J SOIL SCI, V57, P787, DOI 10.1111/j.1365-2389.2005.00768.x
   Li N, 2019, CATENA, V181, P0, DOI 10.1016/j.catena.2019.04.034
   Li Y, 2010, GEODERMA, V159, P63, DOI 10.1016/j.geoderma.2010.06.017
   Long J, 2020, ECOL INDIC, V110, P0, DOI 10.1016/j.ecolind.2019.105926
   Long J, 2018, ECOL INDIC, V93, P562, DOI 10.1016/j.ecolind.2018.05.044
   Mahmoudzadeh H, 2020, GEODERMA REG, V21, P0, DOI 10.1016/j.geodrs.2020.e00260
   Manlay RJ, 2007, AGR ECOSYST ENVIRON, V119, P217, DOI 10.1016/j.agee.2006.07.011
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   Meinshausen N, 2006, J MACH LEARN RES, V7, P983
   Minasny B, 2007, GEODERMA, V140, P324, DOI 10.1016/j.geoderma.2007.04.028
   Mishra U, 2010, SOIL TILL RES, V107, P88, DOI 10.1016/j.still.2010.02.005
   Morgan J., 2003, ACAD INFORM MANAGEME, V6, P77
   Pang S, 2009, AGR SCI CHINA, V8, P1369, DOI 10.1016/S1671-2927(08)60349-1
   Pebesma EJ, 1998, COMPUT GEOSCI-UK, V24, P17, DOI 10.1016/S0098-3004(97)00082-4
   Somarathna PDSN, 2017, SOIL SCI SOC AM J, V81, P1413, DOI 10.2136/sssaj2016.11.0376
   Song XD, 2016, GEODERMA, V261, P11, DOI 10.1016/j.geoderma.2015.06.024
   Sun XL, 2019, CATENA, V181, P0, DOI 10.1016/j.catena.2019.104092
   Sun XL, 2019, PEDOSPHERE, V29, P577, DOI 10.1016/S1002-0160(19)60801-5
   Tziachris P, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040276
   Wadoux AMJC, 2020, EARTH-SCI REV, V210, P0, DOI 10.1016/j.earscirev.2020.103359
   Wadoux AMJC, 2019, GEODERMA, V355, P0, DOI 10.1016/j.geoderma.2019.113913
   Webster R, 2007, GEOSTATISTICS ENV SC, V0, P0
   Webster R., 1993, GEOSTATISTICS TROIA, V1, P0
   Wiesmeier M, 2019, GEODERMA, V333, P149, DOI 10.1016/j.geoderma.2018.07.026
   Zhang SW, 2012, GEODERMA, V171, P35, DOI 10.1016/j.geoderma.2011.07.012
   Zhang ZQ, 2015, ENVIRON EARTH SCI, V73, P2287, DOI 10.1007/s12665-014-3580-3
NR 49
TC 6
Z9 6
U1 7
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1470-160X
EI 1872-7034
J9 ECOL INDIC
JI Ecol. Indic.
PD JUL 15
PY 2021
VL 126
IS 
BP 
EP 
DI 10.1016/j.ecolind.2021.107618
EA MAR 2021
PG 11
WC Biodiversity Conservation; Environmental Sciences
SC Biodiversity & Conservation; Environmental Sciences & Ecology
GA RY3GG
UT WOS:000647803200006
DA 2023-04-26
ER

PT J
AU Yoon, JH
   Raychowdhury, A
AF Yoon, Jong-Hyeok
   Raychowdhury, Arijit
TI NeuroSLAM: A 65-nm 7.25-to-8.79-TOPS/W Mixed-Signal Oscillator-Based SLAM Accelerator for Edge Robotics
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
LA English
DT Article
DE Simultaneous localization and mapping; Computer architecture; Rodents; Microprocessors; Visualization; Visual odometry; Accelerator; continuous attractor network; edge intelligence; experience map; simultaneous localization and mapping (SLAM); spiking neural network (SNN); topological map; visual odometry; visual template (VT)
AB Simultaneous localization and mapping (SLAM) is a quintessential problem in autonomous navigation, augmented reality, and virtual reality. In particular, low-power SLAM has gained increasing importance for its applications in power-limited edge devices such as unmanned aerial vehicles (UAVs) and small-sized cars that constitute devices with edge intelligence. This article presents a 7.25-to-8.79-TOPS/W mixed-signal oscillator-based SLAM accelerator for applications in edge robotics. This study proposes a neuromorphic SLAM IC, called NeuroSLAM, employing oscillator-based pose-cells and a digital head direction cell to mimic place cells and head direction cells that have been discovered in a rodent brain. The oscillatory network emulates a spiking neural network and its continuous attractor property achieves spatial cognition with a sparse energy distribution, similar to the brains of rodents. Furthermore, a lightweight vision system with a max-pooling is implemented to support low-power visual odometry and re-localization. The test chip fabricated in a 65-nm CMOS exhibits a peak energy efficiency of 8.79 TOPS/W with a power consumption of 23.82 mW.
C1 [Yoon, Jong-Hyeok; Raychowdhury, Arijit] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Yoon, JH (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM jonghyeok.yoon@gatech.edu
FU Semiconductor Research Corporation under the Center for Brain Inspired Computing (C-BRIC) [2777.005, 2777.006]
CR Amaravati A, 2019, IEEE J SOLID-ST CIRC, V54, P75, DOI 10.1109/JSSC.2018.2881288
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bloesch M, 2015, IEEE INT C INT ROBOT, V0, PP298, DOI 10.1109/IROS.2015.7353389
   Cao, 2020, P IEEE S VLSI CIRC J, V0, PP1, DOI 10.1109/VLSICIRCUITS18222.2020
   Cao NY, 2020, IEEE J SOLID-ST CIRC, V55, P49, DOI 10.1109/JSSC.2019.2935533
   Choi JY, 2008, IEEE RAD FREQ INTEGR, V0, P355
   Dryanovski I, 2013, IEEE INT CONF ROBOT, V0, PP2305, DOI 10.1109/ICRA.2013.6630889
   Engel J, 2015, IEEE INT C INT ROBOT, V0, PP1935, DOI 10.1109/IROS.2015.7353631
   Fung CCA, 2015, NEURAL COMPUT, V27, P507, DOI 10.1162/NECO_a_00711
   Garcia S, 2016, IEEE INT CONF AUTON, V0, PP205, DOI 10.1109/ICARSC.2016.46
   Hong I, 2015, IEEE J SOLID-ST CIRC, V50, P2513, DOI 10.1109/JSSC.2015.2463074
   Hsiao M, 2017, 2017 IEEE INT C ROB, V0, P5110
   La HM, 2015, IEEE T CONTR SYST T, V23, P52, DOI 10.1109/TCST.2014.2312392
   Li ZY, 2019, ISSCC DIG TECH PAP I, V62, P134, DOI 10.1109/ISSCC.2019.8662397
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meilland M., 2011, AUSTR C ROB AUT, V0, P0
   Milford MJ, 2008, IEEE T ROBOT, V24, P1038, DOI 10.1109/TRO.2008.2004520
   Milford MJ, 2004, IEEE INT CONF ROBOT, V0, PP403, DOI 10.1109/ROBOT.2004.1307183
   Mourikis AI, 2007, IEEE INT CONF ROBOT, V0, PP3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   OKeefe J, 1996, NATURE, V381, P425, DOI 10.1038/381425a0
   Piao JC, 2019, IEEE T MULTIMEDIA, V21, P2827, DOI 10.1109/TMM.2019.2913324
   Rehman NU, 2018, 2018 INTERNATIONAL CONFERENCE ON ENGINEERING & EMERGING TECHNOLOGIES (ICEET), V0, P12
   Rublee E, 2011, IEEE I CONF COMP VIS, V0, PP2564, DOI 10.1109/ICCV.2011.6126544
   Song KT, 2018, IEEE SYS MAN CYBERN, V0, PP1833, DOI 10.1109/SMC.2018.00317
   Stalbaum J, 2013, INT CONF UBIQ ROBOT, V0, PP391, DOI 10.1109/URAI.2013.6677295
   Suleiman A, 2019, IEEE J SOLID-ST CIRC, V54, P1106, DOI 10.1109/JSSC.2018.2886342
   Wu S, 2008, NEURAL COMPUT, V20, P994, DOI 10.1162/neco.2008.10-06-378
   Yoon JS, 2013, IEEE T VLSI SYST, V21, P206, DOI 10.1109/TVLSI.2012.2186157
   Yoon JH, 2020, ISSCC DIG TECH PAP I, V0, PP478, DOI 10.1109/ISSCC19947.2020.9063142
   Younes G, 2017, ROBOT AUTON SYST, V98, P67, DOI 10.1016/j.robot.2017.09.010
   Yousif K., 2015, INTELL IND SYST, V1, P289
   Zhu QD, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P622
NR 33
TC 7
Z9 7
U1 2
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9200
EI 1558-173X
J9 IEEE J SOLID-ST CIRC
JI IEEE J. Solid-State Circuit
PD JAN 15
PY 2021
VL 56
IS 1
BP 66
EP 78
DI 10.1109/JSSC.2020.3028298
PG 13
WC Engineering, Electrical & Electronic
SC Engineering
GA PK8PT
UT WOS:000602700400007
DA 2023-04-26
ER

PT J
AU Xu, D
   Huang, X
   Mango, J
   Li, X
   Li, ZL
AF Xu, Dong
   Huang, Xiao
   Mango, Joseph
   Li, Xiang
   Li, Zhenlong
TI Simulating multi-exit evacuation using deep reinforcement learning
SO TRANSACTIONS IN GIS
LA English
DT Article
ID social force model; pedestrian evacuation; collision-avoidance; route choice; selection; dynamics; behavior; game; movement; networks
AB Conventional simulations on multi-exit indoor evacuation focus primarily on how to determine a reasonable exit based on numerous factors in a changing environment. Results commonly include some congested and other under-utilized exits, especially with large numbers of pedestrians. We propose a multi-exit evacuation simulation based on deep reinforcement learning (DRL), referred to as the MultiExit-DRL, which involves a deep neural network (DNN) framework to facilitate state-to-action mapping. The DNN framework applies Rainbow Deep Q-Network (DQN), a DRL algorithm that integrates several advanced DQN methods, to improve data utilization and algorithm stability and further divides the action space into eight isometric directions for possible pedestrian choices. We compare MultiExit-DRL with two conventional multi-exit evacuation simulation models in three separate scenarios: varying pedestrian distribution ratios; varying exit width ratios; and varying open schedules for an exit. The results show that MultiExit-DRL presents great learning efficiency while reducing the total number of evacuation frames in all designed experiments. In addition, the integration of DRL allows pedestrians to explore other potential exits and helps determine optimal directions, leading to a high efficiency of exit utilization.
C1 [Xu, Dong; Mango, Joseph; Li, Xiang] East China Normal Univ, Sch Geog Sci, Key Lab Geog Informat Sci, Minist Educ, Shanghai, Peoples R China.
   [Xu, Dong; Li, Zhenlong] Univ South Carolina, Dept Geog, Geoinformat & Big Data Res Lab, 709 Bull St, Columbia, SC 29208 USA.
   [Huang, Xiao] Univ Arkansas, Dept Geosci, Fayetteville, AR 72701 USA.
C3 East China Normal University; University of South Carolina System; University of South Carolina Columbia; University of Arkansas System; University of Arkansas Fayetteville
RP Li, X (corresponding author), East China Normal Univ, Sch Geog Sci, Key Lab Geog Informat Sci, Minist Educ, Shanghai, Peoples R China.; Li, ZL (corresponding author), Univ South Carolina, Dept Geog, Geoinformat & Big Data Res Lab, 709 Bull St, Columbia, SC 29208 USA.
EM xli@geo.ecnu.edu.cn; zhenlong@sc.edu
FU National Natural Science Foundation of China [41771410]; Ministry of Education of China [19JZD023]
CR Alonso-Mora J, 2013, SPRINGER TRAC ADV RO, V83, P203
   Bareiss D, 2015, INT J ROBOT RES, V34, P1501, DOI 10.1177/0278364915576234
   Bellemare MG, 2017, PR MACH LEARN RES, V70, P0
   Ben XY, 2013, IET INTELL TRANSP SY, V7, P55, DOI 10.1049/iet-its.2011.0236
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bode NWF, 2013, ANIM BEHAV, V86, P347, DOI 10.1016/j.anbehav.2013.05.025
   Burstedde C, 2001, PHYSICA A, V295, P507, DOI 10.1016/S0378-4371(01)00141-8
   Cao KC, 2016, IEEE-CAA J AUTOMATIC, V3, P261, DOI 10.1109/JAS.2016.7508801
   Cao SC, 2018, APPL MATH COMPUT, V332, P136, DOI 10.1016/j.amc.2018.03.048
   Chen PH, 2009, FIRE SAFETY J, V44, P732, DOI 10.1016/j.firesaf.2009.02.005
   Choi J, 2014, AUTOMAT CONSTR, V46, P38, DOI 10.1016/j.autcon.2013.12.005
   Chopard B, 1998, CELLULAR AUTOMATA, V0, P0
   Curtis S., 2014, PEDESTRIAN EVACUATIO, V0, PP875, DOI 10.1007/978-3-319-02447-9_73
   Davidich M, 2013, TRANSPORT RES C-EMER, V37, P210, DOI 10.1016/j.trc.2013.02.016
   Dijkstra J, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, V0, P173
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   Fortunato M., 2017, PREPRINT, V0, P0
   Frank GA, 2011, PHYSICA A, V390, P2135, DOI 10.1016/j.physa.2011.01.015
   Geraerts R, 2010, IEEE INT CONF ROBOT, V0, PP1997, DOI 10.1109/ROBOT.2010.5509263
   Godoy J, 2016, AAAI CONF ARTIF INTE, V0, P2487
   Guckiran K, 2019, 2019 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS CONFERENCE (ASYU), V0, P329
   Guo RY, 2012, TRANSPORT RES B-METH, V46, P669, DOI 10.1016/j.trb.2012.01.002
   Guo RY, 2010, CHINESE PHYS B, V19, P0, DOI 10.1088/1674-1056/19/3/030501
   Gupta S, 2017, PROC CVPR IEEE, V0, PP7272, DOI 10.1109/CVPR.2017.769
   Haarnoja T, 2018, PR MACH LEARN RES, V80, P0
   Haghani M, 2016, FIRE SAFETY J, V85, P1, DOI 10.1016/j.firesaf.2016.07.003
   Haghani M, 2015, TRANSPORT RES REC, V0, PP84, DOI 10.3141/2490-10
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Heliovaara S, 2012, SAFETY SCI, V50, P221, DOI 10.1016/j.ssci.2011.08.020
   Hessel M, 2018, AAAI CONF ARTIF INTE, V0, P3215
   Horgan D., 2018, PREPRINT, V0, P0
   Hou L, 2014, PHYSICA A, V400, P93, DOI 10.1016/j.physa.2013.12.049
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Kahn G, 2018, IEEE INT CONF ROBOT, V0, P5129
   Kallmann M, 2014, ACM T GRAPHIC, V33, P0, DOI 10.1145/2580947
   Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761
   Karamouzas I, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3072959.3073705
   Kinateder M, 2018, SAFETY SCI, V106, P170, DOI 10.1016/j.ssci.2018.03.015
   Kinateder M, 2014, TRANSPORT RES F-TRAF, V26, P116, DOI 10.1016/j.trf.2014.06.003
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kuffner J. J. Jr., 2000, PROCEEDINGS 2000 ICRA. MILLENNIUM CONFERENCE. IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION. SYMPOSIA PROCEEDINGS (CAT. NO.00CH37065), V0, PP995, DOI 10.1109/ROBOT.2000.844730
   Lee J, 2022, BRIT J EDUC TECHNOL, V53, P211, DOI 10.1111/bjet.12717
   Li XA, 2010, COMPUT ENVIRON URBAN, V34, P532, DOI 10.1016/j.compenvurbsys.2010.07.006
   Lillicrap TP, 2015, ARXIV PREPRINT, V0, P0
   Lo SM, 2006, FIRE SAFETY J, V41, P364, DOI 10.1016/j.firesaf.2006.02.003
   Long PX, 2018, IEEE INT CONF ROBOT, V0, P6252
   Mehran R, 2009, PROC CVPR IEEE, V0, PP935, DOI 10.1109/CVPRW.2009.5206641
   Mnih V., 2013, ARXIV, V0, P0
   Nair V, 2010, ICML, V27, P807
   Nawar Mahmoud, 2019, 2019 7TH INTERNATIONAL JAPAN-AFRICA CONFERENCE ON ELECTRONICS, V0, P80, DOI 10.1109/JAC-ECC48896.2019.9051262
   Parisi DR, 2005, PHYSICA A, V354, P606, DOI 10.1016/j.physa.2005.02.040
   Pelechano N, 2008, AUTOMAT CONSTR, V17, P377, DOI 10.1016/j.autcon.2007.06.005
   Schaul T., 2015, PREPRINT, V0, P0
   Schulman J., 2017, P C WORKSH NEUR INF, V0, P0
   Seyfried A, 2009, TRANSPORT SCI, V43, P395, DOI 10.1287/trsc.1090.0263
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sun J, 2013, INT J COMPUT INTEG M, V26, P897, DOI 10.1080/0951192X.2011.608727
   Sutskever I., 2014, ADV NEURAL INFORM PR, V27, P3104
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Tashakkori H, 2015, BUILD ENVIRON, V89, P170, DOI 10.1016/j.buildenv.2015.02.036
   Torrens PM, 2012, ANN ASSOC AM GEOGR, V102, P35, DOI 10.1080/00045608.2011.595658
   Tryfona N, 2003, LECT NOTES COMPUT SC, V2520, P79
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, V0, P2094
   Wagoum AUK, 2017, ROY SOC OPEN SCI, V4, P0, DOI 10.1098/rsos.160896
   Wang JH, 2015, PHYSICA A, V428, P396, DOI 10.1016/j.physa.2015.01.057
   Wang Z., 2015, PREPRINT, V0, P0
   Wu H., 2007, 2 IEEE INT C INT MON, V0, PP38, DOI 10.1109/ICIMP.2007.312-s2.0-35348908878
   Xiao GW, 2019, IEEE T COGN COMMUN, V5, P1167, DOI 10.1109/TCCN.2019.2938947
   Xu D, 2020, T GIS, V24, P756, DOI 10.1111/tgis.12620
   Xu JQ, 2013, GEOINFORMATICA, V17, P125, DOI 10.1007/s10707-012-0158-7
   Yue H, 2014, CHINESE PHYS B, V23, P0, DOI 10.1088/1674-1056/23/5/050512
   Zhang JW, 2017, IEEE INT C INT ROBOT, V0, P2371
   Zhang X, 2017, NAT COMMUN, V8, P0, DOI 10.1038/ncomms14675
   Zheng X, 2015, J CENT SOUTH UNIV, V22, P4490, DOI 10.1007/s11771-015-2997-5
   Zheng Y, 2017, SAFETY SCI, V92, P180, DOI 10.1016/j.ssci.2016.10.009
   Zheni D, 2009, LECT NOTES COMPUT SC, V5833, P347, DOI 10.1007/978-3-642-04947-7_41
   Zhou M, 2019, IEEE T INTELL TRANSP, V20, P4476, DOI 10.1109/TITS.2018.2886415
   Zia K, 2009, IEEE ACM DIS SIM, V0, PP235, DOI 10.1109/DS-RT.2009.13
NR 80
TC 5
Z9 5
U1 15
U2 60
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1361-1682
EI 1467-9671
J9 T GIS
JI Trans. GIS
PD JUN 15
PY 2021
VL 25
IS 3
BP 1542
EP 1564
DI 10.1111/tgis.12738
EA MAR 2021
PG 23
WC Geography
SC Geography
GA TF2GX
UT WOS:000627600100001
DA 2023-04-26
ER

PT J
AU Qu, L
   Zhu, XL
   Zheng, JN
   Zou, L
AF Qu, Lei
   Zhu, Xingliang
   Zheng, Jiannan
   Zou, Liang
TI Triple-Attention-Based Parallel Network for Hyperspectral Image Classification
SO REMOTE SENSING
LA English
DT Article
DE hyperspectral image classification; parallel network; channel&#8211; spectral&#8211; spatial attention; feature reuse
ID convolutional neural-network
AB Convolutional neural networks have been highly successful in hyperspectral image classification owing to their unique feature expression ability. However, the traditional data partitioning strategy in tandem with patch-wise classification may lead to information leakage and result in overoptimistic experimental insights. In this paper, we propose a novel data partitioning scheme and a triple-attention parallel network (TAP-Net) to enhance the performance of HSI classification without information leakage. The dataset partitioning strategy is simple yet effective to avoid overfitting, and allows fair comparison of various algorithms, particularly in the case of limited annotated data. In contrast to classical encoder-decoder models, the proposed TAP-Net utilizes parallel subnetworks with the same spatial resolution and repeatedly reuses high-level feature maps of preceding subnetworks to refine the segmentation map. In addition, a channel-spectral-spatial-attention module is proposed to optimize the information transmission between different subnetworks. Experiments were conducted on three benchmark hyperspectral datasets, and the results demonstrate that the proposed method outperforms state-of-the-art methods with the overall accuracy of 90.31%, 91.64%, and 81.35% and the average accuracy of 93.18%, 87.45%, and 78.85% over Salinas Valley, Pavia University and Indian Pines dataset, respectively. It illustrates that the proposed TAP-Net is able to effectively exploit the spatial-spectral information to ensure high performance.
C1 [Qu, Lei; Zhu, Xingliang] Anhui Univ, Sch Elect & Informat Engn, Hefei 236601, Peoples R China.
   [Zheng, Jiannan] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada.
   [Zou, Liang] China Univ Min & Technol, Sch Informat & Elect Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
C3 Anhui University; University of British Columbia; China University of Mining & Technology
RP Zou, L (corresponding author), China Univ Min & Technol, Sch Informat & Elect Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM qulei@ahu.edu.cn; p18201080@stu.ahu.edu.cn; jiannanz@ece.ubc.ca; liangzou@ece.ubc.ca
FU National Natural Science Foundation of China [61901003, 61871411]; Natural Science Foundation of Jiangsu Province [BK20190623]; University Synergy Innovation Program of Anhui Province [GXXT-2019-008]
CR Chen X, 2021, IEEE J BIOMED HEALTH, V25, P1292, DOI 10.1109/JBHI.2020.3009383
   Chen YS, 2019, IEEE T GEOSCI REMOTE, V57, P7048, DOI 10.1109/TGRS.2019.2910603
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Fang B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020159
   Fang X, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20236784
   Fang X, 2019, INT CONF ACOUST SPEE, V0, PP6221, DOI 10.1109/ICASSP.2019.8682327
   Fauvel M, 2012, PATTERN RECOGN, V45, P381, DOI 10.1016/j.patcog.2011.03.035
   Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Ghamisi P, 2018, IEEE GEOSC REM SEN M, V6, P10, DOI 10.1109/MGRS.2018.2854840
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu W, 2015, J SENSORS, V2015, P0, DOI 10.1155/2015/258619
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Li HC, 2019, PROC CVPR IEEE, V0, PP9514, DOI 10.1109/CVPR.2019.00975
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010067
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lorenzo PR, 2020, IEEE ACCESS, V8, P42384, DOI 10.1109/ACCESS.2020.2977454
   Ma WP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111307
   Ma XR, 2018, IEEE T GEOSCI REMOTE, V56, P4781, DOI 10.1109/TGRS.2018.2837142
   McNeely-White D, 2020, COGN SYST RES, V59, P312, DOI 10.1016/j.cogsys.2019.10.004
   Mei XG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080963
   Nalepa J, 2020, IEEE GEOSCI REMOTE S, V17, P292, DOI 10.1109/LGRS.2019.2921011
   Nalepa J, 2019, IEEE GEOSCI REMOTE S, V16, P1264, DOI 10.1109/LGRS.2019.2895697
   Pan B, 2020, IEEE GEOSCI REMOTE S, V17, P1968, DOI 10.1109/LGRS.2019.2960528
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Pan ET, 2019, INT GEOSCI REMOTE SE, V0, PP413, DOI 10.1109/IGARSS.2019.8898758
   Ren FJ, 2019, IEEE ACCESS, V7, P122758, DOI 10.1109/ACCESS.2019.2938194
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P3232, DOI 10.1109/TGRS.2019.2951160
   Sun K, 2019, PROC CVPR IEEE, V0, PP5686, DOI 10.1109/CVPR.2019.00584
   Sun L, 2015, IEEE T GEOSCI REMOTE, V53, P1490, DOI 10.1109/TGRS.2014.2344442
   Tao W, 2023, IEEE T AFFECT COMPUT, V14, P382, DOI 10.1109/TAFFC.2020.3025777
   Tarabalka Y, 2010, IEEE GEOSCI REMOTE S, V7, P736, DOI 10.1109/LGRS.2010.2047711
   Tinghuai Wang, 2020, ADVANCES IN VISUAL COMPUTING. 15TH INTERNATIONAL SYMPOSIUM, V0, P707, DOI 10.1007/978-3-030-64556-4_55
   van Ruitenbeek FJA, 2019, REMOTE SENS ENVIRON, V220, P94, DOI 10.1016/j.rse.2018.10.030
   Wang CX, 2019, ADV SPACE RES, V64, P886, DOI 10.1016/j.asr.2019.05.005
   Wang DZ, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), V0, P1063
   Wei LQ, 2017, INFRARED PHYS TECHN, V86, P90, DOI 10.1016/j.infrared.2017.08.023
   Wu F, 2020, NEUROCOMPUTING, V384, P182, DOI 10.1016/j.neucom.2019.12.042
   Xi JN, 2020, BIOINFORMATICS, V36, P1855, DOI 10.1093/bioinformatics/btz793
   Xing ZM, 2012, SIAM J IMAGING SCI, V5, P33, DOI 10.1137/110837486
   Yang H, 2020, PROCEEDINGS OF 2020 IEEE 2ND INTERNATIONAL CONFERENCE ON CIVIL AVIATION SAFETY AND INFORMATION TECHNOLOGY (ICCASIT), V0, PP1, DOI 10.1109/ICCASIT50869.2020.9368594
   Yang JX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131557
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zhong P., 2017, STAT OPTIMIZATION IN, V5, P75, DOI 10.19139/SOIC.V5I2.309
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zou L, 2017, IEEE ACCESS, V5, P23626, DOI 10.1109/ACCESS.2017.2762703
   Zou L, 2020, IEEE J-STARS, V13, P659, DOI 10.1109/JSTARS.2020.2968179
   Zurqani HA, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-69743-z
NR 51
TC 15
Z9 15
U1 3
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN 15
PY 2021
VL 13
IS 2
BP 
EP 
DI 10.3390/rs13020324
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PX7RM
UT WOS:000611551600001
DA 2023-04-26
ER

PT J
AU Shadrach, FD
   Kandasamy, G
AF Shadrach, Finney Daniel
   Kandasamy, Gunavathi
TI Neutrosophic Cognitive Maps (NCM) based feature selection approach for early leaf disease diagnosis
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Feature selection; Leaf disease; Neutrosophic cognitive maps; GLCM features; Neural network
ID classification
AB Early diagnosis of leaf ailments is the most necessary and prominent way to increase agriculture production. In this paper, a computer-aided approach for classifying the ailments in plant leaf is proposed using the neutrosophic logic-based feature selection algorithm. Feature selection leads to better learning performance and lowers computational cost by choosing a small subset of features by eliminating noisy and redundant features thereby acting as a dimensionality reduction technique. Leaf disease classification is similar to other classification problems but varies significantly in the features that contribute to classification. In the proposed method, Neutrosophic Cognitive Maps (NCM) is used to select the best subsets from GLCM and statistical features that can effectively characterize the leaf ailments. Eight existing state-of-the-art feature selection techniques are compared with the proposed method in order to prove the ability of the proposed method on publicly available images from the PlantVillage repository. Further, the leaf diagnosis can be incorporated in a mobile computing system if needed using appropriate methods thereby enabling user-friendliness. The proposed feature selection method provides an overall classification accuracy of 99.8% while selecting just 11 features for leaf disease diagnosis
C1 [Shadrach, Finney Daniel] KPR Inst Engn & Technol, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Kandasamy, Gunavathi] PSG Coll Technol, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
C3 PSG College Technology
RP Shadrach, FD (corresponding author), KPR Inst Engn & Technol, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
EM finneydaniels@gmail.com; kgunavathi2000@yahoo.com
CR Anitha R, 2017, INT J FUZZY SYST, V19, P1603, DOI 10.1007/s40815-016-0250-5
   Ashbacher C, 2002, INTRO NEUTROSOPHIC L, V0, P1
   Babatunde O., 2014, BRIT J MATH COMPUTER, V4, P2217, DOI 10.9734/BJMCS/2014/10931
   Babatunde O., 2014, INT J ELECT COMMUN C, V5, P899
   Bolon-Canedo V, 2013, KNOWL INF SYST, V34, P483, DOI 10.1007/s10115-012-0487-8
   Cai D., 2010, PROC 16 ACM SIGKDD I, V0, PP333, DOI 10.1145/1835804.1835848
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008
   Drotar P, 2015, COMPUT BIOL MED, V66, P1, DOI 10.1016/j.compbiomed.2015.08.010
   GOTLIEB CC, 1990, COMPUT VISION GRAPH, V51, P70, DOI 10.1016/S0734-189X(05)80063-5
   Gu Q., 2011, P 27 C UNC ART INT, V0, P266
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He X, 2005, P ADV NEUR INF PROC, V18, P0, DOI 10.1007/978-3-642-33506-8_11
   Hughes D Marcel., 2015, OPEN ACCESS REPOSITO, V0, P1
   Kandasamy WV, 2003, ARXIVMATH0311063V1, V0, P0
   Khaire U.M., 2019, J KING SAUD U COMPUT, V0, P0
   Kumar A, 2016, PROCEDIA COMPUT SCI, V89, P324, DOI 10.1016/j.procs.2016.06.079
   Kumar S, 2018, SUSTAIN COMPUT INF S, V0, P0
   Kumar V., 2014, SMART COMPUTING REV, V4, P211, DOI 10.6029/SMARTCR.2014.03.007
   Liu H., 1996, ML P 13 ICML, V0, P319
   Phadikar S, 2013, COMPUT ELECTRON AGR, V90, P76, DOI 10.1016/j.compag.2012.11.001
   Roffo G, 2016, FEATURE SELECTION LI, V0, P1
   Roffo G, 2017, IEEE I CONF COMP VIS, V0, PP1407, DOI 10.1109/ICCV.2017.156
   Roffo G, 2015, IEEE I CONF COMP VIS, V0, PP4202, DOI 10.1109/ICCV.2015.478
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Smarandache, 2016, SSRN ELECT J, V0, P0, DOI DOI 10.2139/ssrn.2725499
   Turkoglu M, 2019, J AMB INTEL HUM COMP, V0, P0, DOI DOI 10.1007/s12652-019-01591-w
   Valliammal N, 2012, INT J COMPUT COMMUN, V0, P0
   Wu M, 2007, ADV NEURAL INF PROCE, V0, P0
   Xin B, 2015, AAAI CONF ARTIF INTE, V0, P1910
   XU Y, 2007, BIOL MED PHYS BIOMED, V0, P1
   Zeng H, 2011, IEEE T PATTERN ANAL, V33, P1532, DOI 10.1109/TPAMI.2010.215
   Zhang Z, 2018, J AMBIENT INTELL HUM, V0, P0
NR 33
TC 2
Z9 2
U1 3
U2 7
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD MAY 15
PY 2021
VL 12
IS 5
BP 5627
EP 5638
DI 10.1007/s12652-020-02070-3
EA MAY 2020
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA SH1JN
UT WOS:000533052300001
DA 2023-04-26
ER

PT J
AU Reich, J
   Steiner, P
   Ballmer, A
   Emmenegger, L
   Hostettler, M
   Staheli, C
   Naumov, G
   Taneski, B
   Todoroska, V
   Schindler, K
   Hafner, A
AF Reich, Johannes
   Steiner, Philipp
   Ballmer, Ariane
   Emmenegger, Lea
   Hostettler, Marco
   Staeheli, Corinne
   Naumov, Goce
   Taneski, Bojan
   Todoroska, Valentina
   Schindler, Konrad
   Hafner, Albert
TI A novel Structure from Motion-based approach to underwater pile field documentation
SO JOURNAL OF ARCHAEOLOGICAL SCIENCE-REPORTS
LA English
DT Article
DE Underwater archaeology; Prehistoric lakeside settlements; Pile fields; 3D-documentation; Photogrammetry; Structure from Motion (SfM); Deep Convolutional Neural Network
ID photogrammetry
AB This article presents a novel methodology to the underwater documentation of pile fields in archaeological lakeside settlement sites using Structure from Motion (SfM). Mapping the piles of such sites is an indispensable basis to the exploitation of the high resolution absolute chronological data gained through dendrochronology. In a case study at the underwater site of Plo.ca, Mi.cov Grad at Lake Ohrid, North Macedonia, nine consecutive 10 m(2) strips and a 6 m(2) excavation section were uncovered, the situation documented, and the wood piles sampled. The gained data was vectorized in a geographic information system. During two field campaigns, a total of 794 wooden elements on a surface of 96 m(2) could be documented three-dimensionally with a residual error of less than 2 cm. The exceptionally high number of fishes in the 5 m deep water resulted in a significant covering of potentially important information on the relevant photos. We present a machine learning approach, especially developed and successfully applied to the automatic detection and masking of these fishes in order to eliminate them from the images. The discussed documentation workflow enables an efficient, cost-effective, accurate and reproducible mapping of pile fields. So far, no other method applied to the recording of pile fields has allowed for a comparably high resolution of spatial information.
C1 [Reich, Johannes; Ballmer, Ariane; Emmenegger, Lea; Hostettler, Marco; Staeheli, Corinne; Hafner, Albert] Univ Bern, Inst Archaeol Sci, Mittelstr 43, CH-3012 Bern, Switzerland.
   [Steiner, Philipp; Schindler, Konrad] Swiss Fed Inst Technol, Inst Geodesy & Photogrammetry, Zurich, Switzerland.
   [Ballmer, Ariane; Hafner, Albert] Univ Bern, Oeschger Ctr Climate Change Res OCCR, Bern, Switzerland.
   [Naumov, Goce] Ctr Prehist Res, Skopje, North Macedonia.
   [Taneski, Bojan] Inst Protect Monuments & Museum Ohrid, Ohrid, North Macedonia.
C3 University of Bern; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Bern
RP Reich, J; Hafner, A (corresponding author), Univ Bern, Inst Archaeol Sci, Mittelstr 43, CH-3012 Bern, Switzerland.
EM johannes.reich@iaw.unibe.ch; albert.hafner@iaw.unibe.ch
FU Institute of Archaeological Sciences, University of Bern; Association of Swiss Underwater Archaeology; Foundation Johanna Durmuller-Bol, Muri b. Bern; European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (EXPLO project) [810856]; 2018 and 2019: Association of Swiss Underwater Archaeology; Center for Prehistoric Research, Skopje; Department of Underwater Archaeology and Dendroarchaeology, Office for Urbanism Zurich; Diving Center AMFORA, Ohrid; Institute of Geodesy and Photogrammetry of the Swiss Federal Institute of Technology Zurich; Institute for Protection of Monuments and Museum Ohrid; Space Research & Planetary Sciences, Physics Institute, University of Bern
CR Abdelaziz M, 2019, INT ARCH PHOTOGRAMM, V42-2, P1, DOI 10.5194/isprs-archives-XLII-2-W10-1-2019
   ader A., 2013, ARCHAOL SCHWEIZ, V36, P34, DOI 10.5169/seals-391353
   ader A, 2020, ANFANGE PFAHLBAUARCH, V0, P8
   Agisoft LLC, 2020, AG MET 1 6 3, V0, P0
   [Anonymous], 2016, USING COMPUTER VISIO, V0, P0
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Arnold B., 1986, FOUILLE SUBAQUATIQUE, V0, P178
   Barbasiewicz A, 2018, E3S WEB CONF, V26, P0, DOI 10.1051/e3sconf/20182600012
   Block M., 2017, STUD DIGITAL HERITAG, V1, P547
   Bruno Fabio, 2013, 2013 DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE). FEDERATING THE 19TH INTI VSMM, V0, P105
   Bukowski Z., 1965, ARCHAEOL POLONA, V8, P105
   Chrysostomou P., 2015, ARCHAOLOGIE SCHWEIZ, V38, P24
   De Reu J, 2014, J ARCHAEOL SCI, V41, P251, DOI 10.1016/j.jas.2013.08.020
   De Reu J, 2013, J ARCHAEOL SCI, V40, P1108, DOI 10.1016/j.jas.2012.08.040
   Degel C., 2019, OCEANS 2019, V0, P1
   Doneus M., 2011, GEOINFORMATICS FACUL, V6, P81, DOI 10.14311/gi.6.11
   Eberschweiler B., 2006, NEW VIEW UNDERWATER, V0, P24
   etrequin P., 2013, OXFORD HDB WETLAND A, V0, PP253, DOI 10.1093/oxfordhb/9780199573493.013.0016
   Facorellis Y, 2014, RADIOCARBON, V56, P511, DOI 10.2458/56.17456
   Fandr e M. -J, 2020, THESIS ETH ZURICH, V0, P0
   Fouache E, 2010, J ARCHAEOL SCI, V37, P525, DOI 10.1016/j.jas.2009.10.017
   Green S, 2014, J ARCHAEOL SCI, V46, P173, DOI 10.1016/j.jas.2014.02.030
   Hafner A., 2004, 5000 JAHRE ABGETAUCH, V0, P0
   Hafner A, 2012, FRUHE FORSCHUNGEN AK, V0, P237
   Hafner A., 1992, LATTRIGEN 6 RIEDSTAT, V0, P0
   Hafner A, 2021, J ARCHAEOL SCI-REP, V38, P0, DOI 10.1016/j.jasrep.2021.103107
   Hafner Albert, 2000, 3400 ENTWICKLUNG BAU, V0, P0
   Henderson J, 2013, INT J NAUT ARCHAEOL, V42, P243, DOI 10.1111/1095-9270.12016
   Kaeser M. -A, 2017, AS ARCHAOLOGIE SCHWE, V40, P16
   Kapit an G, 1961, NACHRICHTENBLATT VOR, V6, P205
   Kuzman P., 2013, MAKEDONIJA MILENIUMS, V0, P297
   Luhmann T., 2020, CLOSE RANGE PHOTOGRA, V3rd, P0
   McCarthy JK., 2019, 3D RECORDING INTERPR, V0, P0
   McCarthy J, 2014, J MARIT ARCHAEOL, V9, P95, DOI 10.1007/s11457-014-9127-7
   Menna F, 2017, INT ARCH PHOTOGRAMM, V42-2, P481, DOI 10.5194/isprs-archives-XLII-2-W3-481-2017
   Menna F, 2018, J CULT HERIT, V33, P231, DOI 10.1016/j.culher.2018.02.017
   Menotti F., 2015, OXFORD HDB NEOLITHIC, V0, P0
   Naumov G, 2015, PLATTFORM, V23, P10
   Pacheco-Ruiz R, 2018, J ARCHAEOL SCI, V100, P120, DOI 10.1016/j.jas.2018.10.005
   Pohl H., 2016, POS REICH 21 INT TAG, V0, P0
   Pohl H., 2007, DENKMALGERECHTES TAU, V0, P65
   QGIS.org, 2020, 310 QGIS, V0, P0
   Reich J., 2020, 3 AMT STADT STADT ZU, V0, P36
   Reinfeld M., 2019, P 23 INT C CULT HER, V0, P0
   Reinhard J, 2013, TUGIUM, V29, P177, DOI 10.5169/seals-526824
   Remondino F, 2011, REMOTE SENS-BASEL, V3, P1104, DOI 10.3390/rs3061104
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Ruoff U, 1971, Z SCHWEIZERISCHE ARC, V28, P86, DOI 10.5169/seals-165630
   Ruoff U., 2006, NEW VIEW UNDERWATER, V0, P14
   Ruoff U, 1981, HELVETIA ARCHAEOL, V12, P62
   Sapirstein P, 2017, J FIELD ARCHAEOL, V42, P337, DOI 10.1080/00934690.2017.1338513
   Sch arer L., 2020, 3 AMT STADT STADT ZU, V0, P68
   Steiner P, 2020, THESIS I GEODESY PHO, V0, P0
   Szeliski R, 2011, TEXTS COMPUT SCI, V0, PP1, DOI 10.1007/978-1-84882-935-0
   Touchais G., 2007, ENVIRONNEMENTS CULTU, V0, P375
   Verhoeven G, 2012, ARCHAEOMETRY, V54, P1114, DOI 10.1111/j.1475-4754.2012.00667.x
   Verhoeven G, 2011, ARCHAEOL PROSPECT, V18, P67, DOI 10.1002/arp.399
   Wu Y., 2019, DETECTRON 2, V0, P0
   Yamafune K, 2017, J ARCHAEOL METHOD TH, V24, P703, DOI 10.1007/s10816-016-9283-1
NR 59
TC 1
Z9 1
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-409X
EI 
J9 J ARCHAEOL SCI-REP
JI J. Archaeol. Sci.-Rep.
PD OCT 15
PY 2021
VL 39
IS 
BP 
EP 
DI 10.1016/j.jasrep.2021.103120
EA JUL 2021
PG 14
WC Archaeology
SC Archaeology
GA US6SV
UT WOS:000697557400001
DA 2023-04-26
ER

PT J
AU Li, XG
   Men, FF
   Lv, SS
   Jiang, X
   Pan, MA
   Ma, Q
   Yu, HB
AF Li, Xungen
   Men, Feifei
   Lv, Shuaishuai
   Jiang, Xiao
   Pan, Mian
   Ma, Qi
   Yu, Haibin
TI Vehicle Detection in Very-High-Resolution Remote Sensing Images Based on an Anchor-Free Detection Model with a More Precise Foveal Area
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE vehicle detection; remote sensing image; convolutional neural network; anchor-free
ID aerial imagery; network
AB Vehicle detection in aerial images is a challenging task. The complexity of the background information and the redundancy of the detection area are the main obstacles that limit the successful operation of vehicle detection based on anchors in very-high-resolution (VHR) remote sensing images. In this paper, an anchor-free target detection method is proposed to solve the problems above. First, a multi-attention feature pyramid network (MA-FPN) was designed to address the influence of noise and background information on vehicle target detection by fusing attention information in the feature pyramid network (FPN) structure. Second, a more precise foveal area (MPFA) is proposed to provide better ground truth for the anchor-free method by determining a more accurate positive sample selection area. The proposed anchor-free model with MA-FPN and MPFA can predict vehicles accurately and quickly in VHR remote sensing images through direct regression and predict the pixels in the feature map. A detailed evaluation based on remote sensing image (RSI) and vehicle detection in aerial imagery (VEDAI) data sets for vehicle detection shows that our detection method performs well, the network is simple, and the detection is fast.
C1 [Li, Xungen; Men, Feifei; Lv, Shuaishuai; Pan, Mian; Ma, Qi; Yu, Haibin] Hangzhou Dianzi Univ, Sch Elect & Informat Engn, Hangzhou 310018, Peoples R China.
   [Li, Xungen; Lv, Shuaishuai] Hangzhou Dianzi Univ, Pujiang Microelect & Intelligent Mfg Res Inst, Jinhua 322200, Zhejiang, Peoples R China.
   [Jiang, Xiao] Hangzhou Dianzi Univ, Sch Mech Engn, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; Hangzhou Dianzi University
RP Lv, SS (corresponding author), Hangzhou Dianzi Univ, Sch Elect & Informat Engn, Hangzhou 310018, Peoples R China.; Lv, SS (corresponding author), Hangzhou Dianzi Univ, Pujiang Microelect & Intelligent Mfg Res Inst, Jinhua 322200, Zhejiang, Peoples R China.
EM lixg@hdu.edu.cn; menff@hdu.edu.cn; lvshuai@hdu.edu.cn; jx@hdu.edu.cn; ai@hdu.edu.cn; maqi@hdu.edu.cn; shoreyhb@hdu.edu.cn
FU National Key Research and Development Project of China [2016YFC1400302]; National Natural Science Foundation of China [61501155, 61871164]; National Defense Science and Technology Key Laboratory Fund [6142401200201]; Zhejiang Provincial Natural Science Foundation of China [LQ19E070003]
CR [Anonymous], 2015, ICLR, V0, P0
   Audebert N, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040368
   Bottou L, 2010, COMPSTAT2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, V0, PP177, DOI 10.1007/978-3-7908-2604-3_16
   Chen C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11182176
   Dai JF, 2016, ADV NEUR IN, V29, P0
   Deng ZP, 2017, IEEE J-STARS, V10, P3652, DOI 10.1109/JSTARS.2017.2694890
   Dumoulin V., 2018, DISTILL, V3, P0
   Gomez-Candon D, 2014, PRECIS AGRIC, V15, P44, DOI 10.1007/s11119-013-9335-4
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Javadi S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091404
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Leitloff J, 2014, REMOTE SENS-BASEL, V6, P11315, DOI 10.3390/rs61111315
   Li QP, 2019, IEEE T GEOSCI REMOTE, V57, P5028, DOI 10.1109/TGRS.2019.2895362
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu CY, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19153294
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu XF, 2018, ELECTRONICS-SWITZ, V7, P0, DOI 10.3390/electronics7060078
   Lowe D. G., 1999, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, V0, PP1150, DOI 10.1109/ICCV.1999.790410
   Mandal M, 2020, IEEE GEOSCI REMOTE S, V17, P494, DOI 10.1109/LGRS.2019.2923564
   Mesquita DB, 2020, IEEE GEOSCI REMOTE S, V17, P1455, DOI 10.1109/LGRS.2019.2945906
   Moranduzzo T, 2014, IEEE T GEOSCI REMOTE, V52, P1635, DOI 10.1109/TGRS.2013.2253108
   Mou LC, 2018, IEEE T GEOSCI REMOTE, V56, P6699, DOI 10.1109/TGRS.2018.2841808
   Ok AO, 2013, IEEE T GEOSCI REMOTE, V51, P1701, DOI 10.1109/TGRS.2012.2207123
   Park, 2018, BRIT MACH VIS C, V0, P0
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao W, 2012, INT GEOSCI REMOTE SE, V0, PP4379, DOI 10.1109/IGARSS.2012.6350403
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shi FR, 2021, IEEE T GEOSCI REMOTE, V59, P5221, DOI 10.1109/TGRS.2020.3011418
   Tang TY, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111170
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Tian Z, 2019, IEEE I CONF COMP VIS, V0, PP9626, DOI 10.1109/ICCV.2019.00972
   Triggs, 2005, PROC CVPR IEEE, V1, P886, DOI 10.1109/CVPR.2005.177
   Viola P., 2001, IEEE COMPUT SOC C CO, V0, P0, DOI DOI 10.1109/CVPR.2001.990517
   Wang CL, 2017, IEEE GEOSCI REMOTE S, V14, P529, DOI 10.1109/LGRS.2017.2654450
   [王思雨 Wang Siyu], 2017, 雷达学报 JOURNAL OF RADARS, V6, P195
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yin JL, 2016, INFRARED PHYS TECHN, V77, P302, DOI 10.1016/j.infrared.2016.06.004
   Yu YT, 2019, IEEE GEOSCI REMOTE S, V16, P1894, DOI 10.1109/LGRS.2019.2912582
   Zhaowei Cai, 2018, 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION. PROCEEDINGS, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Zhong JD, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17122720
   Zhou K, 2016, DESTECH TRANS COMP, V0, P0
NR 47
TC 5
Z9 6
U1 5
U2 32
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD AUG 15
PY 2021
VL 10
IS 8
BP 
EP 
DI 10.3390/ijgi10080549
PG 22
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA UG3BT
UT WOS:000689133000001
DA 2023-04-26
ER

PT J
AU Kimura, M
   Savada, FY
   Tashima, DLM
   Romagnoli, ES
   Chendynski, LT
   Silva, LRC
   Borsato, D
AF Kimura, Marissa
   Savada, Felipe Y.
   Tashima, Daniele L. M.
   Romagnoli, Erica S.
   Chendynski, Leticia T.
   Silva, Livia R. C.
   Borsato, Dionisio
TI Application of the self-organizing map in the classification of natural antioxidants in commercial biodiesel
SO BIOFUELS-UK
LA English
DT Article
DE Topological map; map of weights; biofuel
ID oxidative stability; network; oil; som
AB The parameters relative protection factor, induction period, rate constant, density, acidity number, water content, flash point, viscosity, cloud point and pour point of 47 biodiesel samples containing the antioxidants of extracts of senna leaves, hibiscus flowers and blackberries were determined. The objective of this research was to apply the self-organizable map (SOM)-type network, using data on the physicochemical properties of biodiesel. SOM is a neural network built on a uni- or two-dimensional grid of neurons to capture the important characteristics in the data contained in a large amount of input. The results were tabulated and presented to the SOM neural network for the classification of antioxidants according to efficiency. A network with 35 x 35 topology was used for the segmentation of the samples. By analyzing the weight maps, it was possible to verify that the most adequate parameter in the classification was the relative protection factor. The analysis showed that two distinct clusters were formed, one for the senna extract and the other including extracts of blackberries and hibiscus flowers. This type of methodology proved to be effective in the selection of natural antioxidants according to regional availability by classification mainly according to the efficiency of protection of the oxidation process in biodiesel, since natural antioxidants with similar properties in the SOMs can be easily substituted for one another in order to minimize costs.
C1 [Kimura, Marissa; Savada, Felipe Y.; Tashima, Daniele L. M.; Romagnoli, Erica S.; Silva, Livia R. C.; Borsato, Dionisio] Univ Estadual Londrina, Chem Dept, Fuels Anal & Res Lab LPAC, Londrina, Parana, Brazil.
   [Chendynski, Leticia T.] Fed Inst Parana, Londrina, Parana, Brazil.
C3 Universidade Estadual de Londrina; Instituto Federal do Parana
RP Kimura, M (corresponding author), Univ Estadual Londrina, Chem Dept, Fuels Anal & Res Lab LPAC, Londrina, Parana, Brazil.
EM kimura.marissa@hotmail.com
CR [Anonymous], 2003, 14112 EN, V0, P0
   [Anonymous], 1997, SERIES INFORM SCI, V0, P0
   Asolini F. C., 2006, BRAZILIAN JOURNAL OF FOOD TECHNOLOGY, V9, P209
   ASTM International, 2001, D9310A ASTM INT, V0, P0
   ASTM International, 2002, D405209 ASTM INT, V0, P0
   ASTM International, 2001, D66411 ASTM INT, V0, P0
   ASTM International, 2000, D44506 ASTM INT, V0, P0
   ASTM International, 2005, D250005 ASTM INT, V0, P0
   ASTM International, 2004, D630407 ASTM INT, V0, P0
   Borsato D, 2014, FUEL PROCESS TECHNOL, V127, P111, DOI 10.1016/j.fuproc.2014.05.033
   Chendynski LT, 2017, ENERG FUEL, V31, P9613, DOI 10.1021/acs.energyfuels.7b01911
   Coppo RL, 2014, J BIOBASED MATER BIO, V8, P545, DOI 10.1166/jbmb.2014.1468
   Cordeiro AMTM, 2013, J THERM ANAL CALORIM, V114, P827, DOI 10.1007/s10973-013-3036-0
   Cremasco H, 2016, J SCI FOOD AGR, V96, P306, DOI 10.1002/jsfa.7094
   Damasceno SS, 2013, FUEL, V107, P641, DOI 10.1016/j.fuel.2012.11.045
   de Almeida VF, 2015, FUEL PROCESS TECHNOL, V133, P152, DOI 10.1016/j.fuproc.2015.01.041
   de Boishebert V, 2006, CHEMOMETR INTELL LAB, V80, P13, DOI 10.1016/j.chemolab.2005.05.003
   de Sousa LS, 2014, FUEL, V134, P420, DOI 10.1016/j.fuel.2014.06.007
   Del Re V., 2012, REV BRAS PLANTAS MED, V14, P389, DOI 10.1590/S1516-05722012000200021
   Galvan D, 2014, QUIM NOVA, V37, P244, DOI 10.5935/0100-4042.20140042
   Hair JF., 2006, MULTIVARIATED DATA A, V6, P0
   Haykin S., 2001, BOOKMAN, V1, P900
   Huang DW, 2015, NEURAL NETWORKS, V63, P208, DOI 10.1016/j.neunet.2014.12.003
   Jiang XY, 2012, PHYSCS PROC, V33, P1093, DOI 10.1016/j.phpro.2012.05.179
   Kohonen T, 2013, NEURAL NETWORKS, V37, P52, DOI 10.1016/j.neunet.2012.09.018
   Kumar N, 2017, FUEL, V190, P328, DOI 10.1016/j.fuel.2016.11.001
   Kumazawa S, 2004, FOOD CHEM, V84, P329, DOI 10.1016/S0308-8146(03)00216-4
   Martins GI, 2015, RENEW SUST ENERG REV, V42, P154, DOI 10.1016/j.rser.2014.10.024
   Oroian M, 2015, FOOD RES INT, V74, P10, DOI 10.1016/j.foodres.2015.04.018
   Paloma EJ, 2012, NEURAL NETWORKS, V32, P275, DOI 10.1016/j.neunet.2012.02.021
   Teruel MR, 2015, FOOD CHEM, V172, P40, DOI 10.1016/j.foodchem.2014.09.018
   Romagnoli ES., 2017, BIOFUELS-UK, V0, PP1, DOI 10.1080/17597269.2017.1418569
   Spacino KR, 2016, IND CROP PROD, V80, P109, DOI 10.1016/j.indcrop.2015.11.034
NR 33
TC 2
Z9 2
U1 1
U2 3
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1759-7269
EI 1759-7277
J9 BIOFUELS-UK
JI Biofuels-UK
PD JUL 3
PY 2021
VL 12
IS 6
BP 673
EP 678
DI 10.1080/17597269.2018.1519762
PG 6
WC Energy & Fuels
SC Energy & Fuels
GA SR4EJ
UT WOS:000660994000008
DA 2023-04-26
ER

PT J
AU Chen, XW
   Huang, WM
   Haller, MC
AF Chen, Xinwei
   Huang, Weimin
   Haller, Merrick C.
TI A Novel Scheme for Extracting Sea Surface Wind Information From Rain-Contaminated X-Band Marine Radar Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Radar; Radar imaging; Rain; Feature extraction; Radar measurements; Radar remote sensing; Estimation; Image dehazing; rain; wind; X-band marine radar
ID wave measurement; vector; support; algorithms; retrieval
AB The presence of rain degrades the performance of sea surface parameter estimation using X-band marine radar. In this article, a novel scheme is proposed to improve wind measurement accuracy from rain-contaminated X-band marine radar data. After extracting texture features from each image pixel, the rain-contaminated regions with blurry wave signatures are first identified using a self-organizing map (SOM)-based clustering model. Then, a convolutional neural network used for image haze removal, i.e., DehazeNet is introduced and incorporated into the proposed scheme for correcting the influence of rain on radar images. In order to obtain wind direction information, curve fitting is conducted on the average azimuthal intensities of rain-corrected radar images. On the other hand, wind speed is estimated from rain-corrected images by training a support vector regression-based model. Experiments conducted using datasets from both shipborne and onshore marine radar show that compared to results obtained from images without rain correction, the proposed method achieves relatively high estimation accuracy by reducing measurement errors significantly.
C1 [Chen, Xinwei; Huang, Weimin] Mem Univ Newfoundland, Fac Engn & Appl Sci, St John, NF A1B 3X5, Canada.
   [Haller, Merrick C.] Oregon State Univ, Sch Civil & Construct Engn, Corvallis, OR 97331 USA.
C3 Memorial University Newfoundland; Oregon State University
RP Chen, XW; Huang, WM (corresponding author), Mem Univ Newfoundland, Fac Engn & Appl Sci, St John, NF A1B 3X5, Canada.
EM xinweic@mun.ca; weimin@mun.ca; merrick.haller@oregonstate.edu
FU NANOOS (NOAA)
CR An JQ, 2015, IEEE T GEOSCI REMOTE, V53, P567, DOI 10.1109/TGRS.2014.2325782
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen XW, 2019, OCEANS-IEEE, V0, P0, DOI DOI 10.23919/OCEANS40490.2019.8962617
   Chen XW, 2020, IEEE T GEOSCI REMOTE, V58, P4225, DOI 10.1109/TGRS.2019.2961807
   Chen XW, 2020, IEEE T GEOSCI REMOTE, V58, P2115, DOI 10.1109/TGRS.2019.2953143
   Chen XW, 2018, OCEANS 2018 MTS/IEEE CHARLESTON, V0, P0
   Chen XW, 2018, IEEE GEOSCI REMOTE S, V15, P1312, DOI 10.1109/LGRS.2018.2845698
   Chen ZB, 2017, IEEE ACCESS, V5, P25576, DOI 10.1109/ACCESS.2017.2772784
   Chen ZB, 2015, OCEAN ENG, V96, P79, DOI 10.1016/j.oceaneng.2014.12.019
   Cheng HY, 2017, REMOTE SENS ENVIRON, V188, P85, DOI 10.1016/j.rse.2016.10.042
   Chernyshov P, 2020, REMOTE SENS ENVIRON, V240, P0, DOI 10.1016/j.rse.2020.111688
   Cornejo-Bueno L, 2016, COAST ENG, V114, P233, DOI 10.1016/j.coastaleng.2016.04.007
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dankert H, 2005, IEEE J OCEANIC ENG, V30, P534, DOI 10.1109/JOE.2005.857524
   Dankert H, 2007, J ATMOS OCEAN TECH, V24, P1629, DOI 10.1175/JTECH2083.1
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Fattal R, 2008, ACM T GRAPHIC, V27, P0, DOI 10.1145/1360612.1360671
   Gangeskar R, 2018, IEEE T GEOSCI REMOTE, V56, P4845, DOI 10.1109/TGRS.2018.2840133
   Hall MS, 2021, PHYSIOTHER THEOR PR, V37, P1456, DOI 10.1080/09593985.2019.1692395
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang W., 2015, COASTAL OCEAN OBSERV, V0, P248
   Huang WM, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121261
   Huang WM, 2017, IEEE T GEOSCI REMOTE, V55, P6218, DOI 10.1109/TGRS.2017.2723431
   Huang WM, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9020166
   Huang WM, 2016, IEEE GEOSCI REMOTE S, V13, P701, DOI 10.1109/LGRS.2016.2539099
   Lee PHY, 1996, IEEE T ANTENN PROPAG, V44, P333, DOI 10.1109/8.486302
   Liu X., 2015, P MTS IEEE OC WASH U, V0, P1
   Liu Y, 2015, IEEE J-STARS, V8, P896, DOI 10.1109/JSTARS.2014.2357426
   Lund B, 2012, IEEE T GEOSCI REMOTE, V50, P3800, DOI 10.1109/TGRS.2012.2186457
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   NG I, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, V0, P0
   PHILLIPS OM, 1960, J FLUID MECH, V9, P193, DOI 10.1017/S0022112060001043
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Tan RT, 2008, PROC CVPR IEEE, V0, PP2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, V0, PP2995, DOI 10.1109/CVPR.2014.383
   Trizna DB, 1996, IEEE T GEOSCI REMOTE, V34, P747, DOI 10.1109/36.499754
   Vicen-Bueno R, 2013, J ATMOS OCEAN TECH, V30, P127, DOI 10.1175/JTECH-D-12-00027.1
   Wang YL, 2016, IEEE GEOSCI REMOTE S, V13, P252, DOI 10.1109/LGRS.2015.2508284
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 40
TC 5
Z9 5
U1 3
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 5220
EP 5234
DI 10.1109/JSTARS.2021.3078902
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SN5PE
UT WOS:000658340600007
DA 2023-04-26
ER

PT J
AU Shahabi, H
   Rahimzad, M
   Piralilou, ST
   Ghorbanzadeh, O
   Homayouni, S
   Blaschke, T
   Lim, S
   Ghamisi, P
AF Shahabi, Hejar
   Rahimzad, Maryam
   Piralilou, Sepideh Tavakkoli
   Ghorbanzadeh, Omid
   Homayouni, Saied
   Blaschke, Thomas
   Lim, Samsung
   Ghamisi, Pedram
TI Unsupervised Deep Learning for Landslide Detection from Multispectral Sentinel-2 Imagery
SO REMOTE SENSING
LA English
DT Article
DE landslide mapping; remote sensing; unsupervised feature learning; convolutional auto-encoder (CAE); mini-batch K-means
ID artificial neural-networks; support vector machine; susceptibility; ensemble; transformation; recognition; algorithm; selection; forest
AB This paper proposes a new approach based on an unsupervised deep learning (DL) model for landslide detection. Recently, supervised DL models using convolutional neural networks (CNN) have been widely studied for landslide detection. Even though these models provide robust performance and reliable results, they depend highly on a large labeled dataset for their training step. As an alternative, in this paper, we developed an unsupervised learning model by employing a convolutional auto-encoder (CAE) to deal with the problem of limited labeled data for training. The CAE was used to learn and extract the abstract and high-level features without using training data. To assess the performance of the proposed approach, we used Sentinel-2 imagery and a digital elevation model (DEM) to map landslides in three different case studies in India, China, and Taiwan. Using minimum noise fraction (MNF) transformation, we reduced the multispectral dimension to three features containing more than 80% of scene information. Next, these features were stacked with slope data and NDVI as inputs to the CAE model. The Huber reconstruction loss was used to evaluate the inputs. We achieved reconstruction losses ranging from 0.10 to 0.147 for the MNF features, slope, and NDVI stack for all three study areas. The mini-batch K-means clustering method was used to cluster the features into two to five classes. To evaluate the impact of deep features on landslide detection, we first clustered a stack of MNF features, slope, and NDVI, then the same ones plus with the deep features. For all cases, clustering based on deep features provided the highest precision, recall, F1-score, and mean intersection over the union in landslide detection.
C1 [Shahabi, Hejar; Rahimzad, Maryam; Homayouni, Saied] Inst Natl Rech Sci INRS, Ctr Eau Terre Environm, Quebec City, PQ G1K 9A9, Canada.
   [Piralilou, Sepideh Tavakkoli; Blaschke, Thomas] Univ Salzburg, Dept Geoinformat Z GIS, A-5020 Salzburg, Austria.
   [Ghorbanzadeh, Omid; Ghamisi, Pedram] Inst Adv Res Artificial Intelligence IARAI, Landstr Hauptstr 5, A-1030 Vienna, Austria.
   [Lim, Samsung] Univ New South Wales, Sch Civil & Environm Engn, Sydney, NSW 2032, Australia.
   [Ghamisi, Pedram] Helmholtz Inst Freiberg Resource Technol, Machine Learning Grp, Helmholtz Zentrum Dresden Rossendorf, Chemnitzer Str 40, D-09599 Freiberg, Germany.
C3 University of Quebec; Institut national de la recherche scientifique (INRS); Salzburg University; University of New South Wales Sydney; Helmholtz Association; Helmholtz-Zentrum Dresden-Rossendorf (HZDR)
RP Ghorbanzadeh, O (corresponding author), Inst Adv Res Artificial Intelligence IARAI, Landstr Hauptstr 5, A-1030 Vienna, Austria.
EM hejar.shahabi@inrs.ca; maryam.rahimzad@inrs.ca; sepideh.tavakkoli-piralilou@stud.sbg.ac.at; omid.ghorbanzadeh@iarai.ac.at; saeid.homayouni@ete.inrs.ca; thomas.blaschke@sbg.ac.at; s.lim@unsw.edu.au; pedram.ghamisi@iarai.ac.at
FU Institute of Advanced Research in Artificial Intelligence (IARAI) GmbH
CR Abbas A.W., 2016, SINDH U RES J SCI SE, V48, P0
   Affeldt S, 2020, PATTERN RECOGN, V108, P0, DOI 10.1016/j.patcog.2020.107522
   Ahmad M, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, V0, P0
   Ambrosi C, 2018, ENG GEOL, V237, P217, DOI 10.1016/j.enggeo.2018.02.020
   [Anonymous], 2009, MULTIVARIATE OBSERVA, V0, P0
   ASF DAAC .., 2007, ALOS PALSAR RAD TERR, V0, P0
   Azarang A, 2019, IEEE ACCESS, V7, P35673, DOI 10.1109/ACCESS.2019.2905511
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barbareschi M, 2020, PATHOLOGICA, V112, P57, DOI 10.32074/1591-951X-15-20
   Borghuis AM, 2007, INT J REMOTE SENS, V28, P1843, DOI 10.1080/01431160600935638
   Chang SZ, 2019, INT GEOSCI REMOTE SE, V0, PP5488, DOI 10.1109/IGARSS.2019.8898697
   Chen W, 2018, SCI TOTAL ENVIRON, V644, P1006, DOI 10.1016/j.scitotenv.2018.06.389
   Chen Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172767
   Chen YS, 2019, IEEE J-STARS, V12, P1882, DOI 10.1109/JSTARS.2019.2915259
   CIHLAR J, 1991, REMOTE SENS ENVIRON, V35, P279, DOI 10.1016/0034-4257(91)90018-2
   Dou J, 2020, LANDSLIDES, V17, P641, DOI 10.1007/s10346-019-01286-5
   Ghorbanzadeh O., 2019, P 39 ANN EARSEL S SA, V0, P0
   Ghorbanzadeh O, 2021, IEEE J-STARS, V14, P452, DOI 10.1109/JSTARS.2020.3043836
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001
   Guan LX, 2015, PATTERN RECOGN, V48, P3216, DOI 10.1016/j.patcog.2015.04.013
   He G, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222691
   Hu XD, 2019, ENG GEOL, V256, P57, DOI 10.1016/j.enggeo.2019.05.004
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kalantar B, 2018, GEOMAT NAT HAZ RISK, V9, P49, DOI 10.1080/19475705.2017.1407368
   Kalinicheva E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111816
   Khan SU, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-27515-w
   Kornejady A, 2019, ADV NAT TECH HAZ RES, V50, P123, DOI 10.1007/978-3-319-77377-3_7
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X
   Li FF, 2018, PATTERN RECOGN, V83, P161, DOI 10.1016/j.patcog.2018.05.019
   Li LF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11182142
   Lin CW, 2013, J ASIAN EARTH SCI, V62, P389, DOI 10.1016/j.jseaes.2012.10.022
   Lin CW, 2011, ENG GEOL, V123, P3, DOI 10.1016/j.enggeo.2011.06.007
   Lobry S, 2019, JOINT URB REMOTE SEN, V0, P0
   Luo GC, 2016, CAN J REMOTE SENS, V42, P106, DOI 10.1080/07038992.2016.1160772
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Main-Knorn M, 2017, PROC SPIE, V10427, P0, DOI 10.1117/12.2278218
   Makarau A, 2017, IEEE GEOSCI REMOTE S, V14, P227, DOI 10.1109/LGRS.2016.2635942
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Maxwell AE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030486
   Mesquita DB, 2020, IEEE GEOSCI REMOTE S, V17, P1455, DOI 10.1109/LGRS.2019.2945906
   Mezaal MR, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7070730
   Min EX, 2018, IEEE ACCESS, V6, P39501, DOI 10.1109/ACCESS.2018.2855437
   Mohbat, 2019, LECT NOTES COMPUT SC, V11751, P499, DOI 10.1007/978-3-030-30642-7_45
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Mousavi SM, 2019, IEEE GEOSCI REMOTE S, V16, P1693, DOI 10.1109/LGRS.2019.2909218
   Movia A, 2016, ISPRS J PHOTOGRAMM, V119, P485, DOI 10.1016/j.isprsjprs.2016.05.004
   Nalepa J, 2020, IEEE GEOSCI REMOTE S, V17, P1948, DOI 10.1109/LGRS.2019.2960945
   OMalley T, 2020, KERAS TUNER, V0, P0
   Othmana E, 2016, INT J REMOTE SENS, V37, P2149, DOI 10.1080/01431161.2016.1171928
   Pettorelli N, 2013, NORMALIZED DIFFERENCE VEGETATION INDEX, V0, PP1, DOI 10.1093/acprof:osobl/9780199693160.001.0001
   Ngo PTT, 2021, GEOSCI FRONT, V12, P505, DOI 10.1016/j.gsf.2020.06.013
   Pourghasemi HR, 2018, CATENA, V162, P177, DOI 10.1016/j.catena.2017.11.022
   Poursanidis D, 2019, INT J APPL EARTH OBS, V80, P58, DOI 10.1016/j.jag.2019.03.012
   Rahimzad M, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13132501
   Ramos-Bernal RN, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121987
   Rasti Behnood, 2021, 2021 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM IGARSS, V0, PP3829, DOI 10.1109/IGARSS47720.2021.9553425
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Sachin Kumar M., 2012, INT J ENV SCI, V1, P168
   Sculley D, 2010, P 19 INT C WORLD WID, V0, PP1177, DOI 10.1145/1772690.1772862
   Sentinel E.., 2015, USER HDB, V0, P0
   Shahabi H, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19224893
   Shao ZM, 2020, IEEE GEOSCI REMOTE S, V17, P1573, DOI 10.1109/LGRS.2019.2949745
   Shreyas R., 2020, INT J CURR MICROBIOL, V9, P2972
   Soares L.P., 1900, P2020, V0, P0
   Solano-Correa YT, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040533
   Song CF, 2014, INTELL DATA ANAL, V18, PS65, DOI 10.3233/IDA-140709
   Song Chunfeng, 2013, IBEROAMERICAN C PATT, V0, P117
   Stumpf A, 2011, REMOTE SENS ENVIRON, V115, P2564, DOI 10.1016/j.rse.2011.05.013
   Su ZY, 2021, LANDSLIDES, V18, P1421, DOI 10.1007/s10346-020-01557-6
   Tang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081243
   Tao C, 2015, IEEE GEOSCI REMOTE S, V12, P2438, DOI 10.1109/LGRS.2015.2482520
   Tavakkoli Piralilou S, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212575
   Team P., 2018, PLAN IM PROD SPEC, V0, P0
   Tharani M., 2018, ARXIV181006470, V0, P0
   Thomas JJ, 2021, CLIN EPIDEMIOL GLOB, V9, P245, DOI 10.1016/j.cegh.2020.09.006
   Tran CJ, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9050221
   Viet-Ha Nhu, 2020, FORESTS, V11, P0, DOI 10.3390/f11080830
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wan S.., 2018, J CHIN SOIL WATER CO, V49, P187
   Wang L, 2004, REMOTE SENS ENVIRON, V91, P432, DOI 10.1016/j.rse.2004.04.005
   Xiao B, 2018, CMC-COMPUT MATER CON, V56, P365, DOI 10.3970/cmc.2018.01830
   Xu Y, 2013, PROC SPIE, V8919, P0, DOI 10.1117/12.2031104
   Yang MD, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142327
   Yu B, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13163158
   Zhang RN, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.038501
   Zhao B, 2018, ROY SOC OPEN SCI, V5, P0, DOI 10.1098/rsos.171418
   Zhao CH, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042605
   Zhao WZ, 2015, INT J REMOTE SENS, V36, P3368, DOI 10.1080/2150704X.2015.1062157
NR 90
TC 15
Z9 15
U1 9
U2 23
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV 15
PY 2021
VL 13
IS 22
BP 
EP 
DI 10.3390/rs13224698
PG 27
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA ZX5TH
UT WOS:000771958500022
DA 2023-04-26
ER

PT J
AU Ponciano, JJ
   Roetner, M
   Reiterer, A
   Boochs, F
AF Ponciano, Jean-Jacques
   Roetner, Moritz
   Reiterer, Alexander
   Boochs, Frank
TI Object Semantic Segmentation in Point Clouds-Comparison of a Deep Learning and a Knowledge-Based Method
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE point cloud; deep learning; knowledge-based; SPARQL; segmentation; 3D; semantic segmentation; classification
ID automatic detection; system
AB Through the power of new sensing technologies, we are increasingly digitizing the real world. However, instruments produce unstructured data, mainly in the form of point clouds for 3D data and images for 2D data. Nevertheless, many applications (such as navigation, survey, infrastructure analysis) need structured data containing objects and their geometry. Various computer vision approaches have thus been developed to structure the data and identify objects therein. They can be separated into model-driven, data-driven, and knowledge-based approaches. Model-driven approaches mainly use the information on the objects contained in the data and are thus limited to objects and context. Among data-driven approaches, we increasingly find deep learning strategies because of their autonomy in detecting objects. They identify reliable patterns in the data and connect these to the object of interest. Deep learning approaches have to learn these patterns in a training stage. Knowledge-based approaches use characteristic knowledge from different domains allowing the detection and classification of objects. The knowledge must be formalized and substitutes the training for deep learning. Semantic web technologies allow the management of such human knowledge. Deep learning and knowledge-based approaches have already shown good results for semantic segmentation in various examples. The common goal but the different strategies of the two approaches engaged our interest in doing a comparison to get an idea of their strengths and weaknesses. To fill this knowledge gap, we applied two implementations of such approaches to a mobile mapping point cloud. The detected object categories are car, bush, tree, ground, streetlight and building. The deep learning approach uses a convolutional neural network, whereas the knowledge-based approach uses standard semantic web technologies such as SPARQL and OWL2to guide the data processing and the subsequent classification as well. The LiDAR point cloud used was acquired by a mobile mapping system in an urban environment and presents various complex scenes, allowing us to show the advantages and disadvantages of these two types of approaches. The deep learning and knowledge-based approaches produce a semantic segmentation with an average F1 score of 0.66 and 0.78, respectively. Further details are given by analyzing individual object categories allowing us to characterize specific properties of both types of approaches.
C1 [Ponciano, Jean-Jacques; Boochs, Frank] Mainz Univ Appl Sci, Inst Spatial Informat & Surveying Technol, i3mainz, D-55128 Mainz, Germany.
   [Roetner, Moritz; Reiterer, Alexander] Fraunhofer Inst Phys Measurement Tech IPM, D-79110 Freiburg, Germany.
   [Reiterer, Alexander] Univ Freiburg, Dept Sustainable Syst Engn INATECH, D-79110 Freiburg, Germany.
C3 Fraunhofer Gesellschaft; University of Freiburg
RP Ponciano, JJ (corresponding author), Mainz Univ Appl Sci, Inst Spatial Informat & Surveying Technol, i3mainz, D-55128 Mainz, Germany.
EM jean-jacques.ponciano@hs-mainz.de; moritz.roetner@ipm.fraunhofer.de; alexander.reiterer@ipm.fraunhofer.de; frank.boochs@hs-mainz.de
CR Anagnostopoulos I, 2016, CONSTRUCTION RESEARCH CONGRESS 2016: OLD AND NEW CONSTRUCTION TECHNOLOGIES CONVERGE IN HISTORIC SAN JUAN, V0, P2302
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, V0, P225, DOI 10.1109/RAM.2013.6758588
   Belgiu M, 2014, REMOTE SENS-BASEL, V6, P1347, DOI 10.3390/rs6021347
   Ben Hmida H, 2011, KEOD 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON KNOWLEDGE ENGINEERING AND ONTOLOGY DEVELOPMENT, V0, P255
   Diaz-Vilarino L, 2015, REMOTE SENS-BASEL, V7, P15651, DOI 10.3390/rs71115651
   Dietenbeck T, 2017, STUD COMPUT INTELL, V665, P181, DOI 10.1007/978-3-319-45763-5_10
   Drost B, 2010, PROC CVPR IEEE, V0, PP998, DOI 10.1109/CVPR.2010.5540108
   Durand N, 2007, PROC INT C TOOLS ART, V0, PP472, DOI 10.1109/ICTAI.2007.111
   Engelmann F, 2020, IEEE INT CONF ROBOT, V0, PP9463, DOI 10.1109/ICRA40945.2020.9197503
   Florkova Z, 2018, MATEC WEB CONF, V196, P0, DOI 10.1051/matecconf/201819604082
   Grau BC, 2008, J WEB SEMANT, V6, P309, DOI 10.1016/j.websem.2008.05.001
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hackel T., 2017, P ISPRS ANN PHOT REM, VIV-1/W1, P91, DOI 10.5194/ISPRS-ANNALS-IV-1-W1-91-2017
   Hu P, 2018, ISPRS ARCH, VXLII-2, P449, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-449-2018
   Jia Y., 2014, CORR, V0, P0
   Karmacharya A, 2015, PROC SPIE, V9528, P0, DOI 10.1117/12.2184801
   Lari Z, 2012, INT ARCH PHOTOGRAMM, V39-B3, P127
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Liu JX, 2019, IEEE I CONF COMP VIS, V0, PP7545, DOI 10.1109/ICCV.2019.00764
   Maillot N, 2004, PROC INT C TOOLS ART, V0, P620
   Milioto A, 2019, IEEE INT C INT ROBOT, V0, PP4213, DOI 10.1109/IROS40897.2019.8967762
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Ponciano J.J., 2020, PHOTOGRAMMETRIE LASE, V0, P1
   Ponciano J.J., 2019, OLDENBURGER 3D TAGE, V0, P98
   Ponciano J.J., 2019, THESIS U LYON LYON, V0, P0
   Ponciano J.J., 2019, STRUCTURAL ANAL HIST, V0, P297
   Ponciano J.J., 2017, GIS SCI Z GEOINFORM, V3, P97
   Ponciano JJ, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8100442
   Poux F., 2020, INT ARCH PHOTOGRAMME, V43, P309, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2020-309-2020
   Prud Hommeaux E., 2008, SPARQL QUERY LANGUAG, V0, P0
   Qi CR, 2017, ADV NEUR IN, V30, P0
   Qi CR, 2017, PROC CVPR IEEE, V0, PP77, DOI 10.1109/CVPR.2017.16
   Reiterer A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162530
   Rethage D., 2018, FULLY CONVOLUTIONAL, V0, P0
   Rosu R.A., 2019, LATTICENET FAST POIN, V0, P0
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Steder B, 2011, IEEE INT CONF ROBOT, V0, PP2601, DOI 10.1109/ICRA.2011.5980187
   Streiffer C, 2017, MIDDLEWARE17: PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (INDUSTRIAL TRACK), V0, PP22, DOI 10.1145/3154448.3154452
   Tatarchenko M, 2018, PROC CVPR IEEE, V0, PP3887, DOI 10.1109/CVPR.2018.00409
   Tombari F, 2011, IEEE IMAGE PROC, V0, PP809, DOI 10.1109/ICIP.2011.6116679
   Tonietto L, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-51545-7
   Tsarkov D, 2006, LECT NOTES ARTIF INT, V4130, P292
   Wang JL, 2019, AAAI CONF ARTIF INTE, V0, P8949
   Xu B, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010005
   Zhang X., 2008, PROC ASIAGRAPH, V8, P23
NR 46
TC 8
Z9 8
U1 3
U2 19
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD APR 15
PY 2021
VL 10
IS 4
BP 
EP 
DI 10.3390/ijgi10040256
PG 21
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RR4UM
UT WOS:000643095200001
DA 2023-04-26
ER

PT J
AU Wan, SA
   Yeh, ML
   Ma, HL
AF Wan, Shiuan
   Yeh, Mei-Ling
   Ma, Hong-Lin
TI An Innovative Intelligent System with Integrated CNN and SVM: Considering Various Crops through Hyperspectral Image Data
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE image classification; support vector machine; convolution neural network
AB Generation of a thematic map is important for scientists and agriculture engineers in analyzing different crops in a given field. Remote sensing data are well-accepted for image classification on a vast area of crop investigation. However, most of the research has currently focused on the classification of pixel-based image data for analysis. The study was carried out to develop a multi-category crop hyperspectral image classification system to identify the major crops in the Chiayi Golden Corridor. The hyperspectral image data from CASI (Compact Airborne Spectrographic Imager) were used as the experimental data in this study. A two-stage classification was designed to display the performance of the image classification. More specifically, the study used a multi-class classification by support vector machine (SVM) + convolutional neural network (CNN) for image classification analysis. SVM is a supervised learning model that analyzes data used for classification. CNN is a class of deep neural networks that is applied to analyzing visual imagery. The image classification comparison was made among four crops (paddy rice, potatoes, cabbages, and peanuts), roads, and structures for classification. In the first stage, the support vector machine handled the hyperspectral image classification through pixel-based analysis. Then, the convolution neural network improved the classification of image details through various blocks (cells) of segmentation in the second stage. A series of discussion and analyses of the results are presented. The repair module was also designed to link the usage of CNN and SVM to remove the classification errors.
C1 [Wan, Shiuan] Ling Tung Univ, Dept Informat Technol, Taichung 40851, Taiwan.
   [Yeh, Mei-Ling; Ma, Hong-Lin] Feng Chia Univ, GIS Res Ctr, Taichung 40724, Taiwan.
C3 Feng Chia University
RP Yeh, ML (corresponding author), Feng Chia Univ, GIS Res Ctr, Taichung 40724, Taiwan.
EM shiuan123@teamail.ltu.edu.tw; milly@gis.tw; elmer@gis.tw
FU [MOST 108-2621-M-275-002]
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Nguyen A, 2015, PROC CVPR IEEE, V0, PP427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], 2002, SURV LAND INF SYST, V0, P0
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Bertels L, 2008, INT J REMOTE SENS, V29, P2359, DOI 10.1080/01431160701408469
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao JJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010089
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Cheriyadat A, 2003, INT GEOSCI REMOTE SE, V0, P3420
   Du PJ, 2012, OPT COMMUN, V285, P3054, DOI 10.1016/j.optcom.2012.02.092
   Espindola GM, 2006, INT J REMOTE SENS, V27, P3035, DOI 10.1080/01431160600617194
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Gong YH, 1999, MULTIMEDIA SYST, V7, P449, DOI 10.1007/s005300050145
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Kim S, 2017, IEEE COMPUT SOC CONF, V0, PP195, DOI 10.1109/CVPRW.2017.30
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Lei TC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213666
   Lu D, 2005, INT J REMOTE SENS, V26, P101, DOI 10.1080/01431160410001720748
   Lu H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050752
   Muhammed HH, 2005, BIOSYST ENG, V91, P9, DOI 10.1016/j.biosystemseng.2005.02.007
   Pang YW, 2018, IEEE T NEUR NET LEAR, V29, P1587, DOI 10.1109/TNNLS.2017.2676130
   Pradhan B, 2013, COMPUT GEOSCI-UK, V51, P350, DOI 10.1016/j.cageo.2012.08.023
   Prasad S, 2008, IEEE GEOSCI REMOTE S, V5, P625, DOI 10.1109/LGRS.2008.2001282
   Senthilnath J, 2013, IEEE J-STARS, V6, P861, DOI 10.1109/JSTARS.2012.2217941
   Sivakumar D., 2019, J COMPUT THEOR NANOS, V16, P1528
   Tuia D, 2011, REMOTE SENS ENVIRON, V115, P2232, DOI 10.1016/j.rse.2011.04.022
   Wan S, 2020, AGRICULTURE-BASEL, V10, P0, DOI 10.3390/agriculture10100465
   Wan SA, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11112414
   Wan SA, 2019, INT J REMOTE SENS, V40, P8076, DOI 10.1080/01431161.2018.1539275
   Wan SA, 2014, ARAB J GEOSCI, V7, P2059, DOI 10.1007/s12517-013-0952-z
   Wu QS, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20123504
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhou QT, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0180239
NR 36
TC 7
Z9 7
U1 1
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD APR 15
PY 2021
VL 10
IS 4
BP 
EP 
DI 10.3390/ijgi10040242
PG 17
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RR4HR
UT WOS:000643061900001
DA 2023-04-26
ER

PT J
AU Alizadeh, M
   Zabihi, H
   Rezaie, F
   Asadzadeh, A
   Wolf, ID
   Langat, PK
   Khosravi, I
   Pour, AB
   Nataj, MM
   Pradhan, B
AF Alizadeh, Mohsen
   Zabihi, Hasan
   Rezaie, Fatemeh
   Asadzadeh, Asad
   Wolf, Isabelle D.
   Langat, Philip K.
   Khosravi, Iman
   Pour, Amin Beiranvand
   Nataj, Milad Mohammad
   Pradhan, Biswajeet
TI Earthquake Vulnerability Assessment for Urban Areas Using an ANN and Hybrid SWOT-QSPM Model
SO REMOTE SENSING
LA English
DT Article
DE earthquake; vulnerability assessment; urban areas; ANN; SWOT; QSPM; Tabriz
ID neural-networks; natural disasters; economic-losses; classification; hazard; resilience; risk; community; adaptation; prediction
AB Tabriz city in NW Iran is a seismic-prone province with recurring devastating earthquakes that have resulted in heavy casualties and damages. This research developed a new computational framework to investigate four main dimensions of vulnerability (environmental, social, economic and physical). An Artificial Neural Network (ANN) Model and a SWOT-Quantitative Strategic Planning Matrix (QSPM) were applied. Firstly, a literature review was performed to explore indicators with significant impact on aforementioned dimensions of vulnerability to earthquakes. Next, the twenty identified indicators were analyzed in ArcGIS, a geographic information system (GIS) software, to map earthquake vulnerability. After classification and reclassification of the layers, standardized maps were presented as input to a Multilayer Perceptron (MLP) and Self-Organizing Map (SOM) neural network. The resulting Earthquake Vulnerability Maps (EVMs) showed five categories of vulnerability ranging from very high, to high, moderate, low and very low. Accordingly, out of the nine municipality zones in Tabriz city, Zone one was rated as the most vulnerable to earthquakes while Zone seven was rated as the least vulnerable. Vulnerability to earthquakes of residential buildings was also identified. To validate the results data were compared between a Multilayer Perceptron (MLP) and a Self-Organizing Map (SOM). The scatter plots showed strong correlations between the vulnerability ratings of the different zones achieved by the SOM and MLP. Finally, the hybrid SWOT-QSPM paradigm was proposed to identify and evaluate strategies for hazard mitigation of the most vulnerable zone. For hazard mitigation in this zone we recommend to diligently account for environmental phenomena in designing and locating of sites. The findings are useful for decision makers and government authorities to reconsider current natural disaster management strategies.
C1 [Alizadeh, Mohsen; Zabihi, Hasan] Univ Teknol Malaysia, Fac Built Environm & Surveying, Skudai 81310, Johor, Malaysia.
   [Rezaie, Fatemeh] Korea Inst Geosci & Mineral Resources KIGAM, Geosci Platform Div, 124 Gwahak Ro, Daejeon 34132, South Korea.
   [Rezaie, Fatemeh] Korea Univ Sci & Technol, Dept Geophys Explorat, 217 Gajeong Ro, Daejeon 34113, South Korea.
   [Asadzadeh, Asad] Univ Bonn, Inst Geodesy & Geoinformat IGG, Dept Urban Planning & Land Management, Nussallee 1, D-53115 Bonn, Germany.
   [Wolf, Isabelle D.] Univ Wollongong, Sch Geog & Sustainable Communities, Northfields Ave, Wollongong, NSW 2522, Australia.
   [Wolf, Isabelle D.] Univ New South Wales, Ctr Ecosyst Sci, Sydney, NSW 2052, Australia.
   [Langat, Philip K.] Univ New England, Dept Ecosyst Management, Armidale, NSW 2351, Australia.
   [Khosravi, Iman] Univ Isfahan, Fac Civil Engn & Transportat, Dept Geomat Engn, Esfahan 8174673441, Iran.
   [Pour, Amin Beiranvand] Univ Malaysia Terengganu UMT, Inst Oceanog & Environm INOS, Kuala Nerus 21030, Terengganu, Malaysia.
   [Nataj, Milad Mohammad] Sharif Univ Technol, Dept Civil Engn, Azadi Ave, Tehran 1136511155, Iran.
   [Pradhan, Biswajeet] Univ Technol Sydney, Fac Engn & Informat Technol, Ctr Adv Modelling & Geospatial Informat Syst CAMG, Ultimo, NSW 2007, Australia.
   [Pradhan, Biswajeet] King Abdulaziz Univ, Ctr Excellence Climate Change Res, POB 80234, Jeddah 21589, Saudi Arabia.
   [Pradhan, Biswajeet] Univ Kebangsaan Malaysia, Earth Observat Ctr, Inst Climate Change, Bangi 43600, Selangor, Malaysia.
C3 Universiti Teknologi Malaysia; Korea Institute of Geoscience & Mineral Resources (KIGAM); University of Science & Technology (UST); University of Bonn; University of Wollongong; University of New South Wales Sydney; University of New England; University of Isfahan; Universiti Malaysia Terengganu; Sharif University of Technology; University of Technology Sydney; King Abdulaziz University; Universiti Kebangsaan Malaysia
RP Pour, AB (corresponding author), Univ Malaysia Terengganu UMT, Inst Oceanog & Environm INOS, Kuala Nerus 21030, Terengganu, Malaysia.
EM alizadeh.mohsen2003@yahoo.com; hassan.zabihi@gmail.com; rezaie@kigam.re.kr; asad.asadzadeh@uni.bonn.de; iwolf@uow.edu.au; plangat@myune.edu.au; i.khosravi@cet.ui.ac.ir; beiranvand.pour@umt.edu.my; mmn81@msstate.edu; Biswajeet.pradhan@uts.edu.au
FU Universti TeknologiMalaysia (UTM)
CR Abraham A., 2004, HDB MEASURING SYSTEM, V0, P901
   Alizadeh M, 2018, ISPRS INT GEO-INF, V7, P0, DOI 10.3390/ijgi7110444
   Alizadeh M, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10103376
   Aradag S, 2017, ENG APPL COMP FLUID, V11, P467, DOI 10.1080/19942060.2017.1314870
   Armas I, 2017, INT J DISAST RISK SC, V8, P182, DOI 10.1007/s13753-017-0132-y
   Armas I, 2014, ENVIRON EARTH SCI, V71, P4637, DOI 10.1007/s12665-013-2854-5
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Bai YB, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12244055
   Berberian M., 1976, CONTRIBUTION SEISMOT, V39, P397
   Beroya-Eitner MA, 2016, ECOL INDIC, V60, P329, DOI 10.1016/j.ecolind.2015.07.001
   Birkmann J., 2007, ENVIRONMENTAL HAZARDS, V7, P20, DOI 10.1016/j.envhaz.2007.04.002
   Bohari A.M., 2017, GEOGR MALAYS J SOC S, V9, P145
   Bull JW, 2016, ECOSYST SERV, V17, P99, DOI 10.1016/j.ecoser.2015.11.012
   Caballero-Aguila R, 2017, INFORM FUSION, V34, P70, DOI 10.1016/j.inffus.2016.06.008
   Cardona OD, 2012, P 15 WORLD C EARTHQ, V0, P0
   Cariolet JM, 2019, SUSTAIN CITIES SOC, V51, P0, DOI 10.1016/j.scs.2019.101746
   Castillo O, 2012, EXPERT SYST APPL, V39, P2947, DOI 10.1016/j.eswa.2011.08.156
   Dahmani K, 2014, ENERGY, V70, P374, DOI 10.1016/j.energy.2014.04.011
   Dragovic N, 2019, OPEN GEOSCI, V11, P352, DOI 10.1515/geo-2019-0028
   ESRI, 2005, ARC GIS GIS MAPP SOF, V0, P0
   Estrada F, 2015, NAT GEOSCI, V8, P880, DOI 10.1038/ngeo2560
   Fakhruddin B, 2019, PROG DISASTER SCI, V2, P0, DOI 10.1016/j.pdisas.2019.100017
   Aceves-Quesada JF, 2007, NAT HAZARDS, V40, P339, DOI 10.1007/s11069-006-0018-6
   Frigerio I, 2016, ENVIRON SCI POLICY, V63, P187, DOI 10.1016/j.envsci.2016.06.001
   Galbusera L, 2018, INT J DISAST RISK RE, V30, P186, DOI 10.1016/j.ijdrr.2018.04.030
   Geravand S, 2013, COMPUT NETW, V57, P4047, DOI 10.1016/j.comnet.2013.09.003
   Gergel SE, 2005, LANDSCAPE ECOL, V20, P177, DOI 10.1007/s10980-004-2263-y
   Ghajari YE, 2018, CITIES, V72, P102, DOI 10.1016/j.cities.2017.08.006
   Ghayamghamian M, 2012, P 15 WORLD C EARTHQ, V0, P0
   Ghorbani A, 2015, TOUR MANAG PERSPECT, V16, P290, DOI 10.1016/j.tmp.2015.09.005
   Gong P, 1996, PHOTOGRAMM ENG REM S, V62, P513
   Gordan B, 2016, ENG COMPUT-GERMANY, V32, P85, DOI 10.1007/s00366-015-0400-7
   Gupta AK, 2019, ECOL INDIC, V106, P0, DOI 10.1016/j.ecolind.2019.105512
   Hajihassani M, 2015, B ENG GEOL ENVIRON, V74, P873, DOI 10.1007/s10064-014-0657-x
   Hakala E, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11082228
   Harfst J., 2010, STRENGTHS WEAKNESSES, V0, P103
   Harirchian Ehsan, 2020, IOP CONFERENCE SERIES: MATERIALS SCIENCE AND ENGINEERING, V897, P0, DOI 10.1088/1757-899X/897/1/012014
   Harirchian E., 2018, EARTHQUAKE HAZARD SA, V0, PP289, DOI 10.25643/BAUHAUS-UNIVERSITAET
   Harirchian E, 2021, J BUILD ENG, V43, P0, DOI 10.1016/j.jobe.2021.102536
   Harirchian E, 2022, EUR J ENVIRON CIV EN, V26, P5279, DOI 10.1080/19648189.2021.1892829
   Harirchian E, 2020, STRUCTURES, V28, P1384, DOI 10.1016/j.istruc.2020.09.048
   Harirchian E, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10207153
   Harirchian E, 2020, ENERGIES, V13, P0, DOI 10.3390/en13133340
   Hoffmann S, 2020, DIVERS DISTRIB, V26, P1496, DOI 10.1111/ddi.13136
   Islam MS, 2017, NEURAL COMPUT APPL, V28, P2351, DOI 10.1007/s00521-016-2373-x
   JACKSON J, 1992, J GEOPHYS RES-SOL EA, V97, P12471, DOI 10.1029/92JB00944
   Jena R, 2020, GEOSCI FRONT, V11, P613, DOI 10.1016/j.gsf.2019.07.006
   Jenkins K, 2013, NAT HAZARDS, V69, P1967, DOI 10.1007/s11069-013-0788-6
   Karimzadeh S, 2014, SOIL DYN EARTHQ ENG, V66, P263, DOI 10.1016/j.soildyn.2014.06.026
   Kheirizadeh Aroq M., 2020, ENVIRON EARTH SCI, V79, P1
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Krosnick JA, 1999, ANNU REV PSYCHOL, V50, P537, DOI 10.1146/annurev.psych.50.1.537
   Kumar P, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-6267-x
   Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X
   Lee S, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9173495
   Puertas OL, 2013, REMOTE SENS ENVIRON, V137, P112, DOI 10.1016/j.rse.2013.06.003
   Maikhuri RK, 2017, INT J DISAST RISK RE, V25, P111, DOI 10.1016/j.ijdrr.2017.09.002
   Majhi SK, 2020, EVOL SYST-GER, V11, P45, DOI 10.1007/s12530-019-09293-6
   Masozera M, 2007, ECOL ECON, V63, P299, DOI 10.1016/j.ecolecon.2006.06.013
   Mishra A, 2017, INT J DISAST RISK RE, V22, P167, DOI 10.1016/j.ijdrr.2017.03.008
   Monavari M., 2007, ENV STRATEGIC MANAGE, V0, P0
   Moosavi S. G., 2013, INTERNATIONAL RESEARCH JOURNAL OF APPLIED AND BASIC SCIENCES, V5, P1238
   Moradi M, 2017, NAT HAZARDS, V87, P1377, DOI 10.1007/s11069-017-2822-6
   Naik SP, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9040173
   Nazmfar H, 2019, HUM ECOL RISK ASSESS, V25, P455, DOI 10.1080/10807039.2018.1556086
   Nourani V, 2013, J HYDROL, V476, P228, DOI 10.1016/j.jhydrol.2012.10.054
   Noy I, 2010, J ASIAN ECON, V21, P345, DOI 10.1016/j.asieco.2010.03.002
   Oulahen G, 2019, CLIMATIC CHANGE, V153, P41, DOI 10.1007/s10584-019-02386-w
   Pagano A, 2017, SUSTAIN CITIES SOC, V28, P435, DOI 10.1016/j.scs.2016.09.005
   Pandit A, 2019, EARTH SCI INFORM, V12, P513, DOI 10.1007/s12145-019-00397-w
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
   Pelling M, 2005, GLOBAL ENVIRON CHANG, V15, P308, DOI 10.1016/j.gloenvcha.2005.02.001
   Phadermrod B, 2019, INT J INFORM MANAGE, V44, P194, DOI 10.1016/j.ijinfomgt.2016.03.009
   Duy PN, 2019, TRAVEL BEHAV SOC, V15, P28, DOI 10.1016/j.tbs.2018.11.001
   Pingoud K, 2012, MITIG ADAPT STRAT GL, V17, P369, DOI 10.1007/s11027-011-9331-9
   Pradhan B, 2009, APPL GEOMAT, V1, P3, DOI 10.1007/s12518-009-0001-5
   Reihanian A, 2012, TOUR MANAG PERSPECT, V4, P223, DOI 10.1016/j.tmp.2012.08.005
   Reza H, 2013, COMPUT GEOSCI-UK, V51, P324, DOI 10.1016/j.cageo.2012.08.016
   Rus K, 2018, INT J DISAST RISK RE, V31, P311, DOI 10.1016/j.ijdrr.2018.05.015
   Sadrykia M, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6040119
   Sarkissian RD, 2019, APPL GEOGR, V111, P0, DOI 10.1016/j.apgeog.2019.102075
   Schilling J, 2020, REG ENVIRON CHANGE, V20, P0, DOI 10.1007/s10113-020-01597-7
   Scolozzi R, 2014, J ENVIRON MANAGE, V146, P543, DOI 10.1016/j.jenvman.2014.05.040
   Shah AA, 2018, NAT HAZARDS, V93, P147, DOI 10.1007/s11069-018-3293-0
   Sharma M, 2018, LECT NOTE DATA ENG, V4, P145, DOI 10.1007/978-981-10-4600-1_14
   Shash A.A., 1993, CONSTR MANAG ECON, V11, P111, DOI 10.1080/01446199300000004
   Shen S, 2018, NAT HAZARDS, V92, P1809, DOI 10.1007/s11069-018-3279-y
   Singh R, 2015, GEOPHYS RES LETT, V42, P9799, DOI 10.1002/2015GL066363
   Singh S.J., 2018, ASIAN TSUNAMI POSTDI, V0, PP143, DOI 10.1007/978-981-13-0182-7_8
   Smith Keith, 2004, ENV HAZARDS ASSESSIN, Vfourth, P0
   Su JH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223808
   Suhrabi Z, 2012, INT J BURNS TRAUMA, V2, P93
   Taormina R, 2015, J HYDROL, V529, P1788, DOI 10.1016/j.jhydrol.2015.08.008
   Tziavou O, 2018, ENG GEOL, V232, P12, DOI 10.1016/j.enggeo.2017.11.004
   Valentijn T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172839
   Varis O, 2012, APPL GEOGR, V32, P441, DOI 10.1016/j.apgeog.2011.05.003
   Wang QL, 2020, IEEE T EMERG TOP COM, V8, P148, DOI 10.1109/TETC.2017.2699169
   Weller AF, 2006, REV PALAEOBOT PALYNO, V141, P287, DOI 10.1016/j.revpalbo.2006.06.001
   [吴剑 WU Jian], 2006, 地理科学进展 PROGRESS IN GEOGRAPHY, V25, P131
   Wu JD, 2019, J ENVIRON MANAGE, V231, P321, DOI 10.1016/j.jenvman.2018.10.050
   Yariyan P, 2020, INT J DISAST RISK RE, V50, P0, DOI 10.1016/j.ijdrr.2020.101705
   Zabihi H, 2020, TOUR MANAG PERSPECT, V36, P0, DOI 10.1016/j.tmp.2020.100726
   Zhang XR, 2014, INT GEOSCI REMOTE SE, V0, P0, DOI DOI 10.1109/IGARSS.2014.6947075
   Zharan K., 2017, J SUSTAIN MIN, V16, P162
NR 104
TC 2
Z9 2
U1 7
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV 15
PY 2021
VL 13
IS 22
BP 
EP 
DI 10.3390/rs13224519
PG 31
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XG6PF
UT WOS:000724871900001
DA 2023-04-26
ER

PT J
AU Shi, WZ
   Liu, ZW
   An, ZL
   Chen, PF
AF Shi, Wenzhong
   Liu, Zhewei
   An, Zhenlin
   Chen, Pengfei
TI RegNet: a neural network model for predicting regional desirability with VGI data
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Regional desirability prediction; volunteered geographic information; location-based social network
ID recommendations; system
AB Volunteered geographic information can be used to predict regional desirability. A common challenge regarding previous works is that intuitive empirical models, which are inaccurate and bring in perceptual bias, are traditionally used to predict regional desirability. This results from the fact that the hidden interactions between user online check-ins and regional desirability have not been revealed and clearly modelled yet. To solve the problem, a novel neural network model 'RegNet' is proposed. The user check-in history is input into a neural network encoder structure firstly for redundancy reduction and feature learning. The encoded representation is then fed into a hidden-layer structure and the regional desirability is predicted. The proposed RegNet is data-driven and can adaptively model the unknown mappings from input to output, without presumed bias and prior knowledge. We conduct experiments with real-world datasets and demonstrate RegNet outperforms state-of-the-art methods in terms of ranking quality and prediction accuracy of rating. Additionally, we also examine how the structure of encoder affects RegNet performance and suggest on choosing proper sizes of encoded representation. This work demonstrates the effectiveness of data-driven methods in modelling the hidden unknown relationships and achieving a better performance over traditional empirical methods.
C1 [Shi, Wenzhong; Liu, Zhewei; Chen, Pengfei] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Hong Kong, Peoples R China.
   [An, Zhenlin] Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China.
   [Chen, Pengfei] Sun Yat Sen Univ, Sch Geospatial Engn & Sci, Guangzhou, Guangdong, Peoples R China.
C3 Hong Kong Polytechnic University; Hong Kong Polytechnic University; Sun Yat Sen University
RP Liu, ZW (corresponding author), Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Hong Kong, Peoples R China.
EM jackie.zw.liu@connect.polyu.hk
FU Ministry of Science and Technology of the People's Republic of China [2017YFB0503604]
CR Bao J, 2015, GEOINFORMATICA, V19, P525, DOI 10.1007/s10707-014-0220-8
   Bottou Leon, 2008, ADV NEURAL INFORM PR, V0, PP161, DOI 10.7751/mitpress/8996.003.0015
   Cai L, 2018, INT J GEOGR INF SCI, V32, P524, DOI 10.1080/13658816.2017.1400550
   Cheng B, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), V0, PP4584, DOI 10.1109/WCICA.2010.5554118
   Cheng C., 2012, PROC AAAI C ARTIF IN, V0, P17
   Cheng H-T, 2016, WIDE DEEP LEARNING R, V0, P0
   Cranshaw Justin, 2012, P INT AAAI C WEB SOC, V0, P0
   Ding RF, 2018, INT J GEOGR INF SCI, V32, P1631, DOI 10.1080/13658816.2018.1447671
   Ester M, 1996, P 2 INT C KNOWL DISC, V96, P226
   Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP173, DOI 10.1145/3038912.3052569
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   HOROZOV T, 2006, INT S APPL INT SAINT, V0, P0
   Hu Xia, 2013, P 7 ACM C RECOMMENDE, V0, PP93, DOI 10.1145/2507157.2507182
   JAFARKARIMI H, 2012, INT J INF ED TECHNOL, V2, P216
   JARVELIN K, 2000, P 23 ANN INT ACM SIG, V0, PP41, DOI 10.1145/345508.345545
   Kurashima T., 2010, P CIKM, V0, PP579, DOI 10.1145/1871437.1871513
   Lee I, 2014, EXPERT SYST APPL, V41, P397, DOI 10.1016/j.eswa.2013.07.065
   Lemire D, 2005, SIAM PROC S, V0, P471
   Li SN, 2016, ISPRS J PHOTOGRAMM, V115, P119, DOI 10.1016/j.isprsjprs.2015.10.012
   Liou CY, 2008, NEUROCOMPUTING, V71, P3150, DOI 10.1016/j.neucom.2008.04.030
   Liou CY, 2014, NEUROCOMPUTING, V139, P84, DOI 10.1016/j.neucom.2013.09.055
   Liu YQ, 2015, INT J GEOGR INF SCI, V29, P953, DOI 10.1080/13658816.2015.1005094
   Liu ZW, 2019, INT J GEOGR INF SCI, V33, P1520, DOI 10.1080/13658816.2018.1563298
   Longley PA, 2016, INT J GEOGR INF SCI, V30, P369, DOI 10.1080/13658816.2015.1089441
   Odom M., 1990, P 1990 IJCNN INT JOI, V2, P163, DOI 10.1109/IJCNN.1990.137710
   Park MH, 2007, LECT NOTES COMPUT SC, V4611, P1130
   Ramaswamy L, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, V0, PP338, DOI 10.1109/MDM.2009.66
   Raymond Rudy, 2011, P 19 ACM SIGSPATIAL, V0, P377
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Sun YR, 2015, COMPUT ENVIRON URBAN, V53, P110, DOI 10.1016/j.compenvurbsys.2013.07.006
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wan L, 2018, INT J GEOGR INF SCI, V32, P2225, DOI 10.1080/13658816.2018.1458988
   Wang HZ, 2012, ADV DATA MIN DATABAS, V0, PP142, DOI 10.4018/978-1-61350-053-8.ch007
   YANG D, 2013, P 24 ACM C HYP SOC M, V0, P119
   YANG S, 2016, P TRACK 10 ACM C REC, V0, P9
   Yang WS, 2008, EXPERT SYST APPL, V34, P437, DOI 10.1016/j.eswa.2006.09.033
   Ye M, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR11), V0, P325
   Yuan Q, 2013, SIGIR13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P363
   Zheng Y., 2009, P 18 INT C WORLD WID, V0, P791
   Zheng Y, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1889681.1889683
NR 43
TC 6
Z9 6
U1 3
U2 13
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD JAN 2
PY 2021
VL 35
IS 1
BP 175
EP 192
DI 10.1080/13658816.2020.1768261
EA MAY 2020
PG 18
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA PC3CS
UT WOS:000535110000001
DA 2023-04-26
ER

PT J
AU Fu, TY
   Lee, WC
AF Fu, Tao-yang
   Lee, Wang-Chien
TI ProgRPGAN: Progressive GAN for Route Planning
SO KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING
LA English
DT Proceedings Paper
DE route planning; generative adversarial networks; neural networks
AB Learning to route has received significant research momentum as a new approach for the route planning problem in intelligent transportation systems. By exploring global knowledge of geographical areas and topological structures of road networks to facilitate route planning, in this work, we propose a novel Generative Adversarial Network (GAN) framework, namely Progressive Route Planning GAN (ProgRPGAN), for route planning in road networks. The novelty of ProgRPGAN lies in the following aspects: 1) we propose to plan a route with levels of increasing map resolution, starting on a low-resolution grid map, gradually refining it on higher-resolution grid maps, and eventually on the road network in order to progressively generate various realistic paths; 2) we propose to transfer parameters of the previous-level generator and discriminator to the subsequent generator and discriminator for parameter initialization in order to improve the efficiency and stability in model learning; and 3) we propose to pre-train embeddings of grid cells in grid maps and intersections in the road network by capturing the network topology and external factors to facilitate effective model learning. Empirical result shows that ProgRPGAN soundly outperforms the state-of-the-art learning to route methods, especially for long routes, by 9.46% to 13.02% in F1-measure on multiple large-scale real-world datasets. ProgRPGAN, moreover, effectively generates various realistic routes for the same query.
C1 [Fu, Tao-yang; Lee, Wang-Chien] Penn State Univ, University Pk, PA 16802 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park
RP Fu, TY (corresponding author), Penn State Univ, University Pk, PA 16802 USA.
EM txf225@cse.psu.edu; wlee@cse.psu.edu
FU National Science Foundation [IIS-1717084]
CR [Anonymous], 2012, P 18 ACM SIGKDD INT, V0, P0, DOI DOI 10.1145/2339530.2339562
   Ceikute V, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 1, P97, DOI 10.1109/MDM.2013.20
   Chen DW, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP2227, DOI 10.1145/2983323.2983672
   Chen ZB, 2011, PROC INT CONF DATA, V0, PP900, DOI 10.1109/ICDE.2011.5767890
   Dai J, 2015, PROC INT CONF DATA, V0, PP543, DOI 10.1109/ICDE.2015.7113313
   Ericsson E, 2006, TRANSPORT RES C-EMER, V14, P369, DOI 10.1016/j.trc.2006.10.001
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Guo CJ, 2018, PROC INT CONF DATA, V0, PP1073, DOI 10.1109/ICDE.2018.00100
   Karras T., 2017, 6 INT C LEARNING REP, V0, P0
   Kong JT, 2019, NEUROCOMPUTING, V338, P307, DOI 10.1016/j.neucom.2019.02.012
   Kriegel HP, 2010, PROC INT CONF DATA, V0, PP261, DOI 10.1109/ICDE.2010.5447845
   Liu Q, 2016, AAAI CONF ARTIF INTE, V0, P194
   Luo W., 2013, P 2013 ACM SIGMOD IN, V0, P713
   Mahasseni B, 2017, PROC CVPR IEEE, V0, PP2077, DOI 10.1109/CVPR.2017.224
   Newson P., 2009, P 17 ACM SIGSPATIAL, V0, PP336, DOI 10.1145/1653771.1653818
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD14), V0, PP701, DOI 10.1145/2623330.2623732
   Pinedo ML, 2012, SCHEDULING: THEORY, V0, P0
   Shafique S., 2016, PROC 5 ACM SIGSPATIA, V0, P2
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Wang JY, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP539, DOI 10.1145/3292500.3330824
   Wu H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3083
   Xia T., 2006, ICDE 2006, V0, P0
   Yang B, 2018, VLDB J, V27, P153, DOI 10.1007/s00778-017-0491-4
   Yang B, 2013, PROC VLDB ENDOW, V6, P769, DOI 10.14778/2536360.2536375
   Yu LT, 2017, AAAI CONF ARTIF INTE, V0, P2852
   Yuan J., 2010, PROC 18 SIGSPATIAL I, V0, P99
   Zheng S., 2016, ADV NEURAL INFORM PR, V0, P1543
NR 29
TC 0
Z9 0
U1 3
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 393
EP 403
DI 10.1145/3447548.3467406
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA BS6LU
UT WOS:000749556800039
DA 2023-04-26
ER

PT J
AU Fadhillah, MF
   Lee, S
   Lee, CW
   Park, YC
AF Fadhillah, Muhammad Fulki
   Lee, Saro
   Lee, Chang-Wook
   Park, Yu-Chul
TI Application of Support Vector Regression and Metaheuristic Optimization Algorithms for Groundwater Potential Mapping in Gangneung-si, South Korea
SO REMOTE SENSING
LA English
DT Article
DE Gangneung-si; groundwater potential mapping; SVR; GIS; machine learning; metaheuristic algorithm
ID evidential belief function; artificial neural-network; logistic-regression; frequency ratio; spatial prediction; landslide hazard; function model; decision-tree; random forest; fuzzy system
AB The availability of groundwater is of concern. The demand for groundwater in Korea increased by more than 100% during the period 1994-2014. This problem will increase with population growth. Thus, a reliable groundwater analysis model for regional scale studies is needed. This study used the geographical information system (GIS) data and machine learning to map groundwater potential in Gangneung-si, South Korea. A spatial correlation performed using the frequency ratio was applied to determine the relationships between groundwater productivity (transmissivity data from 285 wells) and various factors. This study used four topography factors, four hydrological factors, and three geological factors, along with the normalized difference wetness index and land use and soil type. Support vector regression (SVR) and metaheuristic optimization algorithms-namely, grey wolf optimization (GWO), and particle swarm optimization (PSO), were used in the construction of the groundwater potential map. Model validation based on the area under the receiver operating curve (AUC) was used to determine model accuracy. The AUC values of groundwater potential maps made using the SVR, SVR_GWO, and SVR_PSO algorithms were 0.803, 0.878, and 0.814, respectively. Thus, the application of optimization algorithms increased model accuracy compared to the standard SVR algorithm. The findings of this study improve our understanding of groundwater potential in a given area and could be useful for policymakers aiming to manage water resources in the future.
C1 [Fadhillah, Muhammad Fulki; Lee, Chang-Wook] Kangwon Natl Univ, Dept Smart Reg Innovat, Chuncheon Si 24341, Gangwon Do, South Korea.
   [Lee, Saro] Korea Inst Geosci & Mineral Resources KIGAM, Geosci Platform Res Div, 124 Gwahak Ro, Daejeon 34132, South Korea.
   [Lee, Saro] Korea Univ Sci & Technol, Dept Geophys Explorat, 217 Gajeong Ro, Daejeon 34113, South Korea.
   [Lee, Chang-Wook] Kangwon Natl Univ, Dept Sci Educ, Chuncheon Si 24341, Gangwon Do, South Korea.
   [Park, Yu-Chul] Kangwon Natl Univ, Dept Geophys, Chuncheon Si 24341, Gangwon Do, South Korea.
C3 Kangwon National University; Korea Institute of Geoscience & Mineral Resources (KIGAM); University of Science & Technology (UST); Kangwon National University; Kangwon National University
RP Park, YC (corresponding author), Kangwon Natl Univ, Dept Geophys, Chuncheon Si 24341, Gangwon Do, South Korea.
EM fulkifadhillah@kangwon.ac.kr; leesaro@kigam.re.kr; cwlee@kangwon.ac.kr; parkyc@kangwon.ac.kr
FU National Research Foundation of Korea by the government of Korea [2019R1A2C1085686]; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education [2019R1A6A1A03033167]; Basic Research Project of the Korea Institute of Geoscience and Mineral Resources (KIGAM); National Research Foundation of Korea [2019R1A6A1A03033167] Funding Source: Korea Institute of Science & Technology Information (KISTI), National Science & Technology Information Service (NTIS)
CR Abd Manap M, 2014, ARAB J GEOSCI, V7, P711, DOI 10.1007/s12517-012-0795-z
   Achmad AR, 2020, GEOSCI J, V24, P755, DOI 10.1007/s12303-020-0032-9
   Adeyeye OA, 2019, EGYPT J REMOTE SENS, V22, P175, DOI 10.1016/j.ejrs.2018.04.003
   Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   Al-fugara Akif, 2022, GEOCARTO INTERNATIONAL, V37, P2627, DOI 10.1080/10106049.2020.1831622
   Al-Fugara A, 2022, GEOCARTO INT, V37, P2627, DOI 10.1080/10106049.2020.1831622
   Ali A, 2016, GEOSCI J, V20, P781, DOI 10.1007/s12303-016-0013-1
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172833
   Arabameri A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11243015
   Arabameri A, 2019, SCI TOTAL ENVIRON, V660, P443, DOI 10.1016/j.scitotenv.2019.01.021
   Azeez OS, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10103434
   Benjmel K, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12020471
   Biswas S, 2020, ENVIRON EARTH SCI, V79, P0, DOI 10.1007/s12665-020-09053-9
   Chen W, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9183755
   Chen W, 2019, SCI TOTAL ENVIRON, V684, P31, DOI 10.1016/j.scitotenv.2019.05.312
   Chen W, 2019, CATENA, V172, P212, DOI 10.1016/j.catena.2018.08.025
   Chen W, 2018, SCI TOTAL ENVIRON, V634, P853, DOI 10.1016/j.scitotenv.2018.04.055
   Condon LE, 2015, WATER RESOUR RES, V51, P6602, DOI 10.1002/2014WR016774
   Costall AR, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-66516-6
   Dadgar MA, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2910-7
   Das S, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3522-6
   Diaz-Alcaide S, 2019, HYDROGEOL J, V27, P2307, DOI 10.1007/s10040-019-02001-3
   Bui DT, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11102013
   Bui DT, 2017, AGR FOREST METEOROL, V233, P32, DOI 10.1016/j.agrformet.2016.11.002
   Duan HJ, 2016, MATH PROBL ENG, V2016, P0, DOI 10.1155/2016/2064575
   Duan HJ, 2016, INT GEOSCI REMOTE SE, V0, PP890, DOI 10.1109/IGARSS.2016.7729225
   Elmahdy SI, 2015, ARAB J GEOSCI, V8, P2405, DOI 10.1007/s12517-014-1327-9
   Falah F, 2019, WATER RESOUR+, V46, P679, DOI 10.1134/S0097807819050051
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Floris M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020165
   Hakim WL, 2020, KOREAN J REMOTE SENS, V36, P1303, DOI 10.7780/kjrs.2020.36.6.1.3
   Hakim WL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213627
   Hong HY, 2015, CATENA, V133, P266, DOI 10.1016/j.catena.2015.05.019
   Hounsinou SP, 2020, HELIYON, V6, P0, DOI 10.1016/j.heliyon.2020.e03173
   Jaafari A, 2019, AGR FOREST METEOROL, V266, P198, DOI 10.1016/j.agrformet.2018.12.015
   Jasechko S, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17038-2
   Jothibasu A, 2017, MODEL EARTH SYST ENV, V3, P0, DOI 10.1007/s40808-017-0283-2
   Kavousi-Fard A, 2014, EXPERT SYST APPL, V41, P6047, DOI 10.1016/j.eswa.2014.03.053
   Khoshtinat S, 2019, J EARTH SYST SCI, V128, P0, DOI 10.1007/s12040-019-1155-0
   Kim JC, 2018, J HYDROINFORM, V20, P1436, DOI 10.2166/hydro.2018.120
   Kim MG, 2017, J GEOL SOC KOREA, V53, P321, DOI 10.14770/jgsk.2017.53.2.321
   Kumar PKD, 2007, INT J REMOTE SENS, V28, P5583, DOI 10.1080/01431160601086050
   Lee S, 2018, GEOCARTO INT, V33, P847, DOI 10.1080/10106049.2017.1303091
   Lee S, 2015, SUSTAINABILITY-BASEL, V7, P13416, DOI 10.3390/su71013416
   Lee S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071200
   Lee S, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11061678
   Lerner DN, 2009, LAND USE POLICY, V26, PS265, DOI 10.1016/j.landusepol.2009.09.005
   Mandal U, 2016, WATER RESOUR MANAG, V30, P4293, DOI 10.1007/s11269-016-1421-8
   Maskooni EK, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172742
   Ministry for Food Agriculture, 2010, FOR FISH RUR GROUNDW, V0, P0
   Ministry of Land, 2016, TRANSP MAR AFF NAT G, V0, P0
   Miraki S, 2019, WATER RESOUR MANAG, V33, P281, DOI 10.1007/s11269-018-2102-6
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohamaden M.I.I., 2019, NRIAG J ASTRON GEOPH, V0, PP201, DOI 10.1016/j.nrjag.2017.01.0016
   Moung-Jin L, 2014, GEOCARTO INT, V29, P639, DOI 10.1080/10106049.2013.826739
   Muchingami I, 2019, HYDROGEOL J, V27, P915, DOI 10.1007/s10040-019-01924-1
   Naghibi SA, 2017, WATER RESOUR MANAG, V31, P2761, DOI 10.1007/s11269-017-1660-3
   Nampak H, 2014, J HYDROL, V513, P283, DOI 10.1016/j.jhydrol.2014.02.053
   Notti D, 2016, HYDROL PROCESS, V30, P2317, DOI 10.1002/hyp.10793
   Oh HJ, 2011, J HYDROL, V399, P158, DOI 10.1016/j.jhydrol.2010.12.027
   Oikonomidis D, 2015, J HYDROL, V525, P197, DOI 10.1016/j.jhydrol.2015.03.056
   Panahi M, 2020, J HYDROL, V588, P0, DOI 10.1016/j.jhydrol.2020.125033
   Panahi M, 2020, SCI TOTAL ENVIRON, V741, P0, DOI 10.1016/j.scitotenv.2020.139937
   Park S, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9071157
   Pourghasemi HR, 2015, GEOCARTO INT, V30, P662, DOI 10.1080/10106049.2014.966161
   Pradhan B, 2014, NAT HAZARDS, V73, P1019, DOI 10.1007/s11069-014-1128-1
   Pradhan M, 2018, AIN SHAMS ENG J, V9, P2015, DOI 10.1016/j.asej.2016.08.023
   Preeja KR, 2011, J INDIAN SOC REMOTE, V39, P83, DOI 10.1007/s12524-011-0075-5
   Rahmati O, 2016, CATENA, V137, P360, DOI 10.1016/j.catena.2015.10.010
   RAZACK M, 1991, GROUND WATER, V29, P856, DOI 10.1111/j.1745-6584.1991.tb00572.x
   Razandi Y, 2015, EARTH SCI INFORM, V8, P867, DOI 10.1007/s12145-015-0220-8
   Rizeei HM, 2019, J HYDROL, V579, P0, DOI 10.1016/j.jhydrol.2019.124172
   Sander P, 2007, HYDROGEOL J, V15, P71, DOI 10.1007/s10040-006-0138-9
   Serele C, 2020, GEOSCI FRONT, V11, P1403, DOI 10.1016/j.gsf.2019.11.012
   Singh KV, 2015, GEOCARTO INT, V30, P650, DOI 10.1080/10106049.2014.965757
   Snowdon AP, 2020, J HYDROL, V585, P0, DOI 10.1016/j.jhydrol.2020.124772
   Sokeng C.J., 2016, INT J INNOV APPL STU, V15, P747
   Soleimani H, 2015, APPL MATH MODEL, V39, P3990, DOI 10.1016/j.apm.2014.12.016
   Sorensen R, 2006, HYDROL EARTH SYST SC, V10, P101, DOI 10.5194/hess-10-101-2006
   Statistics Korea, 2011, STAT KOREA COMPLETE, V0, P0
   Stocker TF, 2014, CLIMATE CHANGE 2013: THE PHYSICAL SCIENCE BASIS, V0, PP1, DOI 10.1017/cbo9781107415324
   Tahmassebipoor N, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2166-z
   Thapa R, 2017, APPL WATER SCI, V7, P4117, DOI 10.1007/s13201-017-0571-z
   Tikhamarine Y, 2020, J HYDROL, V582, P0, DOI 10.1016/j.jhydrol.2019.124435
   Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9
   Viet-Ha Nhu, 2020, FORESTS, V11, P0, DOI 10.3390/f11080830
   Wu WC, 2018, LAND DEGRAD DEV, V29, P4005, DOI 10.1002/ldr.3148
   WWDR, 2017, UN WORLD WAT DEV REP, V0, P0
   Yeh HF, 2016, SUSTAIN ENVIRON RES, V26, P33, DOI 10.1016/j.serj.2015.09.005
   Yin HY, 2018, J HYDROL, V557, P434, DOI 10.1016/j.jhydrol.2017.12.043
   Zandi J, 2016, WATER RESOUR+, V43, P48, DOI 10.1134/S0097807816010097
NR 92
TC 22
Z9 22
U1 4
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR 15
PY 2021
VL 13
IS 6
BP 
EP 
DI 10.3390/rs13061196
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SE3PM
UT WOS:000651982700001
DA 2023-04-26
ER

PT J
AU Mohammadifar, A
   Gholami, H
   Golzari, S
   Collins, AL
AF Mohammadifar, Aliakbar
   Gholami, Hamid
   Golzari, Shahram
   Collins, Adrian L.
TI Spatial modelling of soil salinity: deep or shallow learning models?
SO ENVIRONMENTAL SCIENCE AND POLLUTION RESEARCH
LA English
DT Article
DE Deep learning models; Shallow machine learning models; Soil salinity spatial maps; Deep convolutional neural networks
ID leaf-area index; neural-networks; regression trees; ridge-regression; random forests; classification; decomposition; susceptibility; algorithms; cubist
AB Understanding the spatial distribution of soil salinity is required to conserve land against degradation and desertification. Against this background, this study is the first attempt to predict soil salinity in the Jaghin basin, in southern Iran, by applying and comparing the performance of four deep learning (DL) models (deep convolutional neural networks-DCNNs, dense connected deep neural networks-DenseDNNs, recurrent neural networks-long short-term memory-RNN-LSTM and recurrent neural networks-gated recurrent unit-RNN-GRU) and six shallow machine learning (ML) models (bagged classification and regression tree-BCART, cforest, cubist, quantile regression with LASSO penalty-QR-LASSO, ridge regression-RR and support vectore machine-SVM). To do this, 49 environmental landsat8-derived variables including digital elevation model (DEM)-extracted covariates, soil-salinity indices, and other variables (e.g., soil order, lithology, land use) were mapped spatially. For assessing the relationships between soil salinity (EC) and factors controlling EC, we collected 319 surficial (0-5 cm depth) soil samples for measuring soil salinity on the basis of electrical conductivity (EC). We then selected the most important features (covariates) controlling soil salinity by applying a MARS model. The performance of the DL and shallow ML models for generating soil salinity spatial maps (SSSMs) was assessed using a Taylor diagram and the Nash Sutcliff coefficient (NSE). Among all 10 predictive models, DL models with NSE >= 0.9 (DCNNs was the most accurate model with NSE = 0.96) were selected as the four best models, and performed better than the six shallow ML models with NSE <= 0.83 (QR-LASSO was the weakest predictive model with NSE = 0.50). Based on DCNNs-, the values of the EC ranged between 0.67 and 14.73 dS/m, whereas for QR-LASSO the corresponding EC values were 0.37 to 19.6 dS/m. Overall, DL models performed better than shallow ML models for production of the SSSMs and therefore we recommend applying DL models for prediction purposes in environmental sciences.
C1 [Mohammadifar, Aliakbar; Gholami, Hamid] Univ Hormozgan, Dept Nat Resources Engn, Bandar Abbas, Hormozgan, Iran.
   [Golzari, Shahram] Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Hormozgan, Iran.
   [Golzari, Shahram] Univ Hormozgan, Deep Learning Res Grp, Bandar Abbas, Hormozgan, Iran.
   [Collins, Adrian L.] Rothamsted Res, Sustainable Agr Sci Dept, Okehampton EX20 2SB, Devon, England.
C3 University of Hormozgan; University of Hormozgan; University of Hormozgan; UK Research & Innovation (UKRI); Biotechnology and Biological Sciences Research Council (BBSRC); Rothamsted Research
RP Gholami, H (corresponding author), Univ Hormozgan, Dept Nat Resources Engn, Bandar Abbas, Hormozgan, Iran.
EM hgholami@hormozgan.ac.ir
FU Faculty of Agriculture and Natural Resources, University of Hormozgan, Iran; UK-BBSRC (UK Research and Innovation-Biotechnology and Biological Sciences Research Council);  [BBS/E/C/000I0330]
CR Ali M, 2019, J HYDROL, V576, P164, DOI 10.1016/j.jhydrol.2019.06.032
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8030292
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Azareh A, 2019, SCI TOTAL ENVIRON, V655, P684, DOI 10.1016/j.scitotenv.2018.11.235
   Azizi A, 2020, SOIL TILL RES, V199, P0, DOI 10.1016/j.still.2020.104586
   Boettinger JL, 2008, DIGITAL SOIL MAPPING WITH LIMITED DATA, V0, PP193, DOI 10.1007/978-1-4020-8592-5_16
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Carranza EJM, 2019, EARTH-SCI REV, V0, P0
   Cerda A, 2018, LAND USE POLICY, V75, P734, DOI 10.1016/j.landusepol.2017.12.052
   Cerda A, 2018, PROG PHYS GEOG, V42, P202, DOI 10.1177/0309133318758521
   Chen HongYan, 2015, TRANSACTIONS OF THE CHINESE SOCIETY OF AGRICULTURAL ENGINEERING, V31, P107
   Cho K, 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/V1/D14-1179
   CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188
   Bui DT, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104426
   Douaoui AEK, 2006, GEODERMA, V134, P217, DOI 10.1016/j.geoderma.2005.10.009
   Eishoeei E, 2019, CATENA, V176, P306, DOI 10.1016/j.catena.2019.01.017
   Felicisimo A, 2013, LANDSLIDES, V10, P175, DOI 10.1007/s10346-012-0320-1
   Gammerman A., 1998, RIDGE REGRESSION LEA, V0, P0, DOI DOI 10.1016/J.DSP.2021.103031
   Gholami H, 2021, AEOLIAN RES, V50, P0, DOI 10.1016/j.aeolia.2021.100682
   Gholami H, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-77567-0
   Gholami H, 2020, ATMOS POLLUT RES, V11, P1303, DOI 10.1016/j.apr.2020.05.009
   Gholami H, 2020, ENVIRON SCI POLLUT R, V27, P42022, DOI 10.1007/s11356-020-10168-6
   Gholami H, 2020, ATMOS RES, V233, P0, DOI 10.1016/j.atmosres.2019.104716
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Hagenauer J, 2019, INT J GEOGR INF SCI, V33, P1399, DOI 10.1080/13658816.2019.1579333
   Hastie T., 2009, ELEMENTS STAT LEARNI, V2, P0
   He FF, 2019, APPL ENERG, V237, P103, DOI 10.1016/j.apenergy.2019.01.055
   Heung B, 2016, GEODERMA, V265, P62, DOI 10.1016/j.geoderma.2015.11.014
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hoffman GJ, 2007, DEV AGR ENG, V13, P131, DOI 10.1016/S0167-4137(07)80007-2
   Houborg R, 2018, ISPRS J PHOTOGRAMM, V135, P173, DOI 10.1016/j.isprsjprs.2017.10.004
   Hu JY, 2019, STOCH ENV RES RISK A, V33, P1117, DOI 10.1007/s00477-019-01691-1
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Ivushkin K, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111260
   JORDAN CF, 1969, ECOLOGY, V50, P663, DOI 10.2307/1936256
   Kakeh J, 2020, SCI TOTAL ENVIRON, V732, P0, DOI 10.1016/j.scitotenv.2020.139168
   Khan NM, 2005, AGR WATER MANAGE, V77, P96, DOI 10.1016/j.agwat.2004.09.038
   King DB, 2015, ACS SYM SER, V1214, P1
   KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643
   Kubicz J, 2021, CHEMOSPHERE, V263, P0, DOI 10.1016/j.chemosphere.2020.128145
   Lodhi B, 2019, INFORM SCIENCES, V482, P63, DOI 10.1016/j.ins.2019.01.012
   Metternicht GI, 2003, REMOTE SENS ENVIRON, V85, P1, DOI 10.1016/S0034-4257(02)00188-8
   Milborrow S., 2014, NOTES EARTH PACKAGE, V0, P0
   Mohammadifar A, 2021, CATENA, V200, P0, DOI 10.1016/j.catena.2021.105178
   Pan ET, 2020, NEUROCOMPUTING, V387, P150, DOI 10.1016/j.neucom.2020.01.029
   Panahi M, 2021, GEOSCI FRONT, V12, P0, DOI 10.1016/j.gsf.2020.09.007
   Pouladi N, 2019, GEODERMA, V342, P85, DOI 10.1016/j.geoderma.2019.02.019
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Pyo J, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111350
   Quinlan J. R., 1992, PROCEEDINGS OF THE 5TH AUSTRALIAN JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE. AI 92, V0, P343
   Rahman M., 2019, BIORXIV, V0, P0
   Rodrigo-Comino J, 2018, PEDOSPHERE, V28, P617, DOI 10.1016/S1002-0160(17)60441-7
   Rodriguez-Galiano V, 2015, ORE GEOL REV, V71, P804, DOI 10.1016/j.oregeorev.2015.01.001
   Rouse J.W., 1974, NASA SPECIAL PUBLICA, V0, P309
   Saggi MK, 2019, COMPUT ELECTRON AGR, V156, P387, DOI 10.1016/j.compag.2018.11.031
   Scudiero E, 2015, REMOTE SENS ENVIRON, V169, P335, DOI 10.1016/j.rse.2015.08.026
   Shamsolmoali P, 2019, SIGNAL PROCESS-IMAGE, V79, P13, DOI 10.1016/j.image.2019.08.008
   Shao ZF, 2019, REMOTE SENS ENVIRON, V235, P0, DOI 10.1016/j.rse.2019.111425
   Shen RP, 2019, INT J APPL EARTH OBS, V79, P48, DOI 10.1016/j.jag.2019.03.006
   Sidike P, 2019, REMOTE SENS ENVIRON, V221, P756, DOI 10.1016/j.rse.2018.11.031
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Taghizadeh-Mehrjardi R, 2014, GEODERMA, V213, P15, DOI 10.1016/j.geoderma.2013.07.020
   Tang R, 2020, COLD REG SCI TECHNOL, V170, P0, DOI 10.1016/j.coldregions.2019.102943
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Tieleman T., 2012, LECT 6 5 RMSPROP NEU, V0, P0
   Tipping ME, 2000, ADV NEUR IN, V12, P652
   Vapnik VN., 1995, NATURE STAT LEARNING, V0, P0, DOI DOI 10.1007/978-1-4757-2440-0
   Vazquez JCG, 2005, WATER RESOUR MANAG, V19, P1, DOI 10.1007/s11269-005-0129-y
   Nhu VH, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2020.104458
   Wang F, 2019, EUR J REMOTE SENS, V52, P256, DOI 10.1080/22797254.2019.1596756
   Wang JZ, 2020, SCI TOTAL ENVIRON, V707, P0, DOI 10.1016/j.scitotenv.2019.136092
   Wang Y, 2019, RENEW ENERG, V132, P43, DOI 10.1016/j.renene.2018.07.083
   Wang Z, 2020, APPL ENERG, V263, P0, DOI 10.1016/j.apenergy.2020.114683
   Xu YM, 2018, ENVIRON POLLUT, V242, P1417, DOI 10.1016/j.envpol.2018.08.029
   Yao ZJ, 2020, NEURAL NETWORKS, V123, P299, DOI 10.1016/j.neunet.2019.11.005
   Yu X, 2020, J HYDROL, V582, P0, DOI 10.1016/j.jhydrol.2019.124293
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhang TT, 2015, ECOL INDIC, V52, P480, DOI 10.1016/j.ecolind.2015.01.004
   Zheng Q, 2013, J STAT PLAN INFER, V143, P1029, DOI 10.1016/j.jspi.2012.12.009
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhou J, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9081621
   Zhou J, 2016, T NONFERR METAL SOC, V26, P1938, DOI 10.1016/S1003-6326(16)64312-1
NR 85
TC 13
Z9 13
U1 5
U2 36
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0944-1344
EI 1614-7499
J9 ENVIRON SCI POLLUT R
JI Environ. Sci. Pollut. Res.
PD AUG 15
PY 2021
VL 28
IS 29
BP 39432
EP 39450
DI 10.1007/s11356-021-13503-7
EA MAR 2021
PG 19
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA TR4HO
UT WOS:000631811800004
PM 33759096
DA 2023-04-26
ER

PT J
AU Nayak, KR
   Skupin, A
   Schempp, T
   Garberich, R
   Bhavnani, SP
   Henry, T
AF Nayak, Keshav R.
   Skupin, Andre
   Schempp, Timothy
   Garberich, Ross
   Bhavnani, Sanjeev P.
   Henry, Timothy
TI Machine learning for holistic visualization of STEMI registry data
SO JOURNAL OF BIOMEDICAL INFORMATICS
LA English
DT Article
DE Machine learning; Data visualization; STEMI outcomes; Artificial neural network; Self-organizing maps
ID map; system; care
AB Background: Widespread adoption of evidence-based guidelines and treatment pathways in ST-Elevation Myocardial Infarction (STEMI) patients has considerably improved cardiac survival and decreased the risk of recurrent myocardial infarction. However, survival outcomes appear to have plateaued over the last decade. The hope underpinning the current study is to engage data visualization to develop a more holistic understanding of the patient space, supported by principles and techniques borrowed from traditionally disparate disciplines, like cartography and machine learning. Methods and Results: The Minnesota Heart Institute Foundation (MHIF) STEMI database is a large prospective regional STEMI registry consisting of 180 variables of heterogeneous data types on more than 5000 patients spanning 15 years. Initial assessment and preprocessing of the registry database was undertaken, followed by a first proof-of-concept implementation of an analytical workflow that involved machine learning, dimensionality reduction, and data visualization. 38 pre-admission variables were analyzed in an all-encompassing representation of pre-index STEMI event data. We aim to generate a holistic visual representation - a map of the multivariate patient space - by training a high-resolution self-organizing neural network consisting of several thousand neurons. The resulting 2-D lattice arrangement of n-dimensional neuron vectors allowed patients to be represented as point locations in a 2-D display space. Patient attributes were then visually examined and contextualized in the same display space, from demographics to pre-existing conditions, event-specific procedures, and STEMI outcomes. Data visualizations implemented in this study include a small-multiple display of neural component planes, composite visualization of the multivariate patient space, and overlay visualization of non-training attributes. Conclusion: Our study represents the first known marriage of cartography and machine learning techniques to obtain visualizations of the multivariate space of a regional STEMI registry. Combining cartographic mapping techniques and artificial neural networks permitted the transformation of the STEMI database into novel, twodimensional visualizations of patient characteristics and outcomes. Notably, these visualizations also drive the discovery of anomalies in the data set, informing corrections applied to detected outliers, thereby further refining the registry for integrity and accuracy. Building on these advances, future efforts will focus on supporting further understanding of risk factors and predictors of outcomes in STEMI patients. More broadly, the thorough visual exploration of display spaces generated through a conjunction of dimensionality reduction with the mature technology base of geographic information systems appears a promising direction for biomedical research.
C1 [Nayak, Keshav R.] Scripps Mercy Hosp, Dept Cardiol, San Diego, CA 92103 USA.
   [Skupin, Andre; Schempp, Timothy] San Diego State Univ, Ctr Informat Convergence & Strategy, San Diego, CA 92182 USA.
   [Garberich, Ross] Minnesota Heart Inst Fdn, Minneapolis, MN USA.
   [Bhavnani, Sanjeev P.] Scripps Clin, Div Cardiol, Healthcare Innovat & Practice Transformat Lab, San Diego, CA USA.
   [Henry, Timothy] Christ Hosp, Carl & Edyth Lindner Ctr Res & Educ, Cincinnati, OH 45219 USA.
C3 California State University System; San Diego State University; Minneapolis Heart Institute Foundation; Scripps Research Institute; Christ Hospital - Ohio
RP Nayak, KR (corresponding author), Scripps Mercy Hosp, Dept Cardiol, San Diego, CA 92103 USA.
EM nayak.keshav@scrippshealth.org; skupin@sdsu.edu; tschempp@sdsu.edu; ross.garberich@allina.com; bhavnani.sanjeev@scrippshealth.org; tim.henry@thechristhospital.com
FU Scripps Clinic Medical Group [90105000008312]
CR BAXT WG, 1991, ANN INTERN MED, V115, P843, DOI 10.7326/0003-4819-115-11-843
   Beck J R, 1980, J MED SYST, V4, P237, DOI 10.1007/BF02222466
   Biuk-Aghai R.P., 2017, P 10 INT S VIS INF C, V0, P113
   Ebinger JE, 2018, CIRC-CARDIOVASC QUAL, V11, P0, DOI 10.1161/CIRCOUTCOMES.118.004553
   FABRIKANT S. I., 2005, EXPLORING GEOVISUALI, V0, PP667, DOI 10.1016/B978-008044531-1/50453-X
   Friendly M, 2008, HDB DATA VISUALIZATI, V0, PP15, DOI 10.1007/978-3-540-33037-0_2
   Frobert O, 2013, NEW ENGL J MED, V369, P1587, DOI 10.1056/NEJMoa1308789
   Frye C., 2006, CARTOGRAPHIC PERSPEC, V54, P69
   Gotz DH, 2012, IBM J RES DEV, V56, P0, DOI 10.1147/JRD.2012.2199170
   Henry TD, 2007, CIRCULATION, V116, P721, DOI 10.1161/CIRCULATIONAHA.107.694141
   Hillier Amy, 2017, MAPPING ACAD, V0, PP45, DOI 10.1007/978-94-024-1011-2_3
   Hografer M, 2020, COMPUT GRAPH FORUM, V39, P647, DOI 10.1111/cgf.14031
   Holzinger Andreas, 2016, BRAIN INFORM, V3, P119, DOI 10.1007/s40708-016-0042-6
   Huber TC, 2018, J DIGIT IMAGING, V31, P640, DOI 10.1007/s10278-018-0065-z
   Dorado-Diaz PI, 2019, REV ESP CARDIOL, V72, P1065, DOI 10.1016/j.rec.2019.05.014
   Imhof E., 1975, AM CARTOGRAPHER, V2, P128, DOI 10.1559/152304075784313304
   Itchhaporia D, 1996, J AM COLL CARDIOL, V28, P515, DOI 10.1016/0735-1097(96)00174-X
   Jolly SS, 2017, CIRCULATION, V135, P143, DOI 10.1161/CIRCULATIONAHA.116.025371
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kohonen T., 2001, SELF ORG MAPS, V0, P0, DOI DOI 10.1007/978-3-642-56927-2
   Kruskal J, 1978, MULTIDIMENSIONAL SCA, V0, P0
   Kuhn W., 1996, C COMP HUM FACT COMP, V0, P346
   Le T, 2013, METHOD INFORM MED, V52, P250, DOI 10.3414/ME12-01-0073
   Levine GN, 2016, CATHETER CARDIO INTE, V87, P1001, DOI 10.1002/ccd.26325
   Lopez-Jimenez F, 2020, MAYO CLIN PROC, V95, P1015, DOI 10.1016/j.mayocp.2020.01.038
   MATHEWS JD, 1974, AUST NZ J MED, V4, P509, DOI 10.1111/j.1445-5994.1974.tb03226.x
   MILLER AS, 1992, MED BIOL ENG COMPUT, V30, P449, DOI 10.1007/BF02457822
   Monsen KA, 2015, CIN-COMPUT INFORM NU, V33, P417, DOI 10.1097/CIN.0000000000000190
   Patel BN, 2019, NPJ DIGIT MED, V2, P0, DOI 10.1038/s41746-019-0189-7
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Penny W, 1996, MED DECIS MAKING, V16, P386, DOI 10.1177/0272989X9601600409
   Preim B, 2007, VISUALIZATION MED TH, V0, P0
   Secemsky EA, 2019, JAMA CARDIOL, V4, P110, DOI 10.1001/jamacardio.2018.4472
   Skupin A, 2004, P NATL ACAD SCI USA, V101, P5274, DOI 10.1073/pnas.0307654100
   Skupin A, 2002, LECT NOTES COMPUT SC, V2539, P161
   Skupin A, 2011, GLIMPSE ART SCI SEEI, V3, P0
   Skupin A, 2008, GEOGRAPHIC VISUALIZA, V0, P0
   Skupin A., 2003, CARTOGR GEOGR INF SC, V30, P99, DOI 10.1559/152304003100011081
   Skupin A., 2008, SELF ORG MAPS APPL G, V0, PP1, DOI 10.1002/9780470021699.CH1
   Skupin A, 2007, HDB GEOGRAPHIC INFOR, V0, PP61, DOI 10.1002/9780470690819.ch4
   Skupin A, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0058779
   Skupin A, 2011, J VISUAL LANG COMPUT, V22, P290, DOI 10.1016/j.jvlc.2011.03.004
   STUBBS DF, 1990, P SOC PHOTO-OPT INS, V1294, P433, DOI 10.1117/12.21195
   Svilaas T, 2008, NEW ENGL J MED, V358, P557, DOI 10.1056/NEJMoa0706416
   Szummer K, 2017, EUR HEART J, V38, P3056, DOI 10.1093/eurheartj/ehx515
   Talbi ML, 2009, COMPUT METH PROG BIO, V94, P223, DOI 10.1016/j.cmpb.2008.12.009
   Tufte E.R., 1991, ENVISIONING INFORM, V0, P0
   Van Tuc Nguyen, 2016, AI 2016: ADVANCES IN ARTIFICIAL INTELLIGENCE. 29TH AUSTRALASIAN JOINT CONFERENCE. PROCEEDINGS: LNAI 9992, V0, PP441, DOI 10.1007/978-3-319-50127-7_38
   Villmann T, 1998, NEUROCOMPUTING, V21, P91, DOI 10.1016/S0925-2312(98)00037-X
   Wei J, 2017, AM HEART J, V191, P30, DOI 10.1016/j.ahj.2017.06.005
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Zhang ZY, 2013, IEEE T VIS COMPUT GR, V19, P1895, DOI 10.1109/TVCG.2013.89
NR 52
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1532-0464
EI 1532-0480
J9 J BIOMED INFORM
JI J. Biomed. Inform.
PD SEP 15
PY 2021
VL 121
IS 
BP 
EP 
DI 10.1016/j.jbi.2021.103869
EA AUG 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Medical Informatics
SC Computer Science; Medical Informatics
GA UO5DW
UT WOS:000694715700006
PM 34298156
DA 2023-04-26
ER

PT J
AU Wu, AN
   Biljecki, F
AF Wu, Abraham Noah
   Biljecki, Filip
TI Roofpedia: Automatic mapping of green and solar roofs for an open roofscape registry and evaluation of urban sustainability
SO LANDSCAPE AND URBAN PLANNING
LA English
DT Article
DE Sustainable development; Convolutional Neural Network; Computer vision; Carbon neutrality; Building data; OpenStreetMap
ID cost-benefit-analysis; heat-island; street-view; impact; performance; technology; temperature; expansion; framework; garden
AB Sustainable roofs, such as those with greenery and photovoltaic panels, contribute to the roadmap for reducing the carbon footprint of cities. However, research on sustainable urban roofscapes is rather focused on their potential and it is hindered by the scarcity of data, limiting our understanding of their current content, spatial distribution, and temporal evolution. To tackle this issue, we introduce Roofpedia, a set of three contributions: (i) automatic mapping of relevant urban roof typology from satellite imagery; (ii) an open roof registry mapping the spatial distribution and area of solar and green roofs of more than one million buildings across 17 cities; and (iii) the Roofpedia Index, a derivative of the registry, to benchmark the cities by the extent of sustainable roofscape in term of solar and green roof penetration. This project, partly inspired by its street greenery counterpart 'Treepedia', is made possible by a multi-step pipeline that combines deep learning and geospatial techniques, demonstrating the feasibility of an automated methodology that generalises successfully across cities with an accuracy of detecting sustainable roofs of up to 100% in some cities. We offer our results as an interactive map and open dataset so that our work could aid researchers, local governments, and the public to uncover the pattern of sustainable rooftops across cities, track and monitor the current use of rooftops, complement studies on their potential, evaluate the effectiveness of existing incentives, verify the use of subsidies and fulfilment of climate pledges, estimate carbon offset capacities of cities, and ultimately support better policies and strategies to increase the adoption of instruments contributing to the sustainable development of cities.
C1 [Wu, Abraham Noah; Biljecki, Filip] Natl Univ Singapore, Dept Architecture, Singapore, Singapore.
   [Biljecki, Filip] Natl Univ Singapore, Dept Real Estate, Singapore, Singapore.
C3 National University of Singapore; National University of Singapore
RP Biljecki, F (corresponding author), Natl Univ Singapore, Dept Architecture, Singapore, Singapore.
EM filip@nus.edu.sg
FU National University of Singapore [R-295000-171-133]
CR Ahrendt J., 2007, THESIS TU BERLIN, V0, P0
   Ang YQ, 2020, APPL ENERG, V279, P0, DOI 10.1016/j.apenergy.2020.115738
   Arcadis, 2016, SUST CIT IND 2016, V0, P0
   Astee LY, 2010, J GREEN BUILD, V5, P105, DOI 10.3992/jgb.5.2.105
   Barron-Gafford GA, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep35070
   Basu S, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), V0, P0, DOI DOI 10.1145/2820783.2820816
   Beacham AM, 2019, J HORTIC SCI BIOTECH, V94, P277, DOI 10.1080/14620316.2019.1574214
   Bellini OE, 2019, TECHNE, V17, P264, DOI 10.13128/Techne-24021
   Benson-Lira V, 2016, J GEOPHYS RES-ATMOS, V121, P3079, DOI 10.1002/2015JD024102
   Bianchini F, 2012, BUILD ENVIRON, V58, P152, DOI 10.1016/j.buildenv.2012.07.005
   Biljecki F, 2020, ISPRS ANN PHOTO REM, V6-4, P37, DOI 10.5194/isprs-annals-VI-4-W1-2020-37-2020
   Biljecki F, 2021, AUTOMAT CONSTR, V121, P0, DOI 10.1016/j.autcon.2020.103440
   Bodis K, 2019, RENEW SUST ENERG REV, V114, P0, DOI 10.1016/j.rser.2019.109309
   Brenneisen Stephan, 2006, URBAN HABITATS, V4, P27
   Brito MC, 2021, TRANSPORT RES D-TR E, V94, P0, DOI 10.1016/j.trd.2021.102810
   Bundgaard J., 2011, TAX NOTES INT, V61, P515
   Carter T, 2008, J ENVIRON MANAGE, V87, P350, DOI 10.1016/j.jenvman.2007.01.024
   Castello R, 2019, J PHYS CONF SER, V1343, P0, DOI 10.1088/1742-6596/1343/1/012034
   Castleton HF, 2010, ENERG BUILDINGS, V42, P1582, DOI 10.1016/j.enbuild.2010.05.004
   Cerri M, 2021, NAT HAZARD EARTH SYS, V21, P643, DOI 10.5194/nhess-21-643-2021
   Chen CF, 2013, ECOL ENG, V52, P51, DOI 10.1016/j.ecoleng.2012.12.083
   Chen J., 1900, P161, V0, P0
   Chen M., 2019, ARXIV, V0, P0
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Ciriminna R, 2019, ENERGY TECHNOL-GER, V7, P0, DOI 10.1002/ente.201900128
   City of Melbourne, 2016, MAPPING OUR ROOFS CI, V0, P0
   City of Vancouver, 2015, REN CIT STRAT, V0, P0
   Clark C, 2008, ENVIRON SCI TECHNOL, V42, P2155, DOI 10.1021/es0706652
   Claus K, 2012, URBAN FOR URBAN GREE, V11, P417, DOI 10.1016/j.ufug.2012.07.003
   Corbusier Le, 1927, NEW ARCHITECTURE, V0, P0
   Coutts AM, 2013, BUILD ENVIRON, V70, P266, DOI 10.1016/j.buildenv.2013.08.021
   de Garis Davies N., 1929, METROPOLITAN MUSEUM, V1, P233, DOI 10.2307/1522726
   Ding X, 2021, COMPUT ENVIRON URBAN, V88, P0, DOI 10.1016/j.compenvurbsys.2021.101632
   Du Y, 2007, J GEOGR SCI, V17, P387, DOI 10.1007/s11442-007-0387-0
   Dubey M., 2018, THESIS U CINCINNATI, V0, P0
   Fan HC, 2014, INT J GEOGR INF SCI, V28, P700, DOI 10.1080/13658816.2013.867495
   Feldmeyer D, 2021, SCI TOTAL ENVIRON, V774, P0, DOI 10.1016/j.scitotenv.2021.145734
   Getter KL, 2009, ENVIRON SCI TECHNOL, V43, P7564, DOI 10.1021/es901539x
   Goldstein BP, 2017, ENVIRON SCI TECHNOL, V51, P7340, DOI 10.1021/acs.est.7b01011
   Hachem C, 2011, SOL ENERGY, V85, P1864, DOI 10.1016/j.solener.2011.04.027
   Han MJN, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11174768
   Happle G, 2019, J PHYS CONF SER, V1343, P0, DOI 10.1088/1742-6596/1343/1/012077
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hien WN, 2008, LANDSCAPE URBAN PLAN, V84, P166, DOI 10.1016/j.landurbplan.2007.07.005
   Hong Kong Buildings Department, 2019, GREEN INN BUILD, V0, P0
   Huang ZY, 2021, BUILD ENVIRON, V196, P0, DOI 10.1016/j.buildenv.2021.107735
   Hui SCM, 2011, P JOINT S 2011 INTEG, V0, P1
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Jaffal I, 2012, RENEW ENERG, V43, P157, DOI 10.1016/j.renene.2011.12.004
   Jarrett A., 2016, GREEN ROOFS STORMWAT, V0, P0
   Johari F, 2020, RENEW SUST ENERG REV, V128, P0, DOI 10.1016/j.rser.2020.109902
   Joshi M.Y., 2020, ISPRS ANN PHOTOGRAMM, V6, P87, DOI 10.5194/isprs-annalsVI-4-W2-2020-87-2020
   Jungels J, 2013, LANDSCAPE URBAN PLAN, V117, P13, DOI 10.1016/j.landurbplan.2013.04.013
   Kosareo L, 2007, BUILD ENVIRON, V42, P2606, DOI 10.1016/j.buildenv.2006.06.019
   Langemeyer J, 2021, LANDSCAPE URBAN PLAN, V210, P0, DOI 10.1016/j.landurbplan.2021.104055
   Lee S, 2019, KDD19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP2105, DOI 10.1145/3292500.3330741
   Li XJ, 2015, URBAN FOR URBAN GREE, V14, P675, DOI 10.1016/j.ufug.2015.06.006
   Liang TC, 2014, LANDSCAPE URBAN PLAN, V127, P52, DOI 10.1016/j.landurbplan.2014.04.005
   Malof JM, 2016, APPL ENERG, V183, P229, DOI 10.1016/j.apenergy.2016.08.191
   Masson V, 2014, FRONT ENV SCI-SWITZ, V2, P0, DOI 10.3389/fenvs.2014.00014
   Middel A, 2019, LANDSCAPE URBAN PLAN, V183, P122, DOI 10.1016/j.landurbplan.2018.12.001
   Mountain B., 2014, AUSTR MILLION SOLAR, V0, PP75, DOI 10.1016/b978-0-12-800240-7.00004-7
   Murshed SM, 2019, URBAN SCI, V3, P0, DOI 10.3390/urbansci3010004
   National Parks Board, 2009, SING SKYR GREEN INC, V0, P0
   Nelms CE, 2007, BUILD RES INF, V35, P237, DOI 10.1080/09613210601058139
   Ng E, 2012, BUILD ENVIRON, V47, P256, DOI 10.1016/j.buildenv.2011.07.014
   Ng V., 2018, P 17 PYTH SCI C SCIP, V0, PP145, DOI 10.25080/MAJORA-4AF1F417-015
   Nosrati MS, 2009, IEEE IMAGE PROC, V0, PP1709, DOI 10.1109/ICIP.2009.5413641
   Palliwal A, 2021, COMPUT ENVIRON URBAN, V86, P0, DOI 10.1016/j.compenvurbsys.2020.101584
   Partridge DR, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0202298
   Paszke A., 2019, ADV NEURAL INFORM PR, V0, P0, DOI DOI 10.48550/ARXIV.1912.01703
   Phillis YA, 2017, COMPUT ENVIRON URBAN, V64, P254, DOI 10.1016/j.compenvurbsys.2017.03.002
   Rodriguez LR, 2017, SOL ENERGY, V146, P264, DOI 10.1016/j.solener.2017.02.043
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salamanca F, 2014, J GEOPHYS RES-ATMOS, V119, P5949, DOI 10.1002/2013JD021225
   Santamouris M, 2014, SOL ENERGY, V103, P682, DOI 10.1016/j.solener.2012.07.003
   Santos T., 2021, METHODS APPL GEOSPAT, V0, PP251, DOI 10.4018/978-1-7998-2249-3.ch009
   Santos T, 2016, SUSTAINABILITY-BASEL, V8, P0, DOI 10.3390/su8121247
   Saretta E, 2020, SUSTAIN CITIES SOC, V62, P0, DOI 10.1016/j.scs.2020.102410
   Schrader S, 2006, PEDOBIOLOGIA, V50, P347, DOI 10.1016/j.pedobi.2006.06.003
   Seiferling I, 2017, LANDSCAPE URBAN PLAN, V165, P93, DOI 10.1016/j.landurbplan.2017.05.010
   Senate Department for Urban Development and Housing, 2017, GREEN ROOFS ED 2017, V0, P0
   Shafique M, 2018, RENEW SUST ENERG REV, V90, P757, DOI 10.1016/j.rser.2018.04.006
   Shao HM, 2021, URBAN FOR URBAN GREE, V57, P0, DOI 10.1016/j.ufug.2020.126954
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shukri FAB, 2018, WIT TRANS ECOL ENVIR, V226, P39, DOI 10.2495/SDP170041
   Solar Victoria, 2020, SOL PAN PV REB, V0, P0
   Song XP, 2018, URBAN FOR URBAN GREE, V29, P49, DOI 10.1016/j.ufug.2017.11.004
   Sood T, 2019, J PHYS CONF SER, V1343, P0, DOI 10.1088/1742-6596/1343/1/012141
   Sproul J, 2014, ENERG BUILDINGS, V71, P20, DOI 10.1016/j.enbuild.2013.11.058
   Stovin V, 2010, WATER ENVIRON J, V24, P192, DOI 10.1111/j.1747-6593.2009.00174.x
   Stowell D, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-00739-0
   Tablada A, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10103762
   Tang JX, 2019, LANDSCAPE URBAN PLAN, V191, P0, DOI 10.1016/j.landurbplan.2018.09.015
   Theodosiou TG, 2003, ENERG BUILDINGS, V35, P909, DOI 10.1016/S0378-7788(03)00023-9
   Tiefbau und Entsorgungsdepartement, 2020, DACHB, V0, P0
   U.S. Department of Energy, 2020, GRID CONN REN EN SYS, V0, P0
   Van Renterghem T, 2009, BUILD ENVIRON, V44, P1081, DOI 10.1016/j.buildenv.2008.07.013
   VanWoert ND, 2005, J ENVIRON QUAL, V34, P1036, DOI 10.2134/jeq2004.0364
   Verberne G., 2014, EUR PHOT SOL EN C EX, V0, P3630
   Villarreal EL, 2005, ECOL ENG, V25, P1, DOI 10.1016/j.ecoleng.2004.11.008
   Walch A, 2020, APPL ENERG, V262, P0, DOI 10.1016/j.apenergy.2019.114404
   Wang CK, 2020, J BUILD PERFORM SIMU, V13, P347, DOI 10.1080/19401493.2020.1729862
   Wang YP, 2006, J SOL ENERG-T ASME, V128, P168, DOI 10.1115/1.2188533
   Wentz EA, 2015, 2015 JOINT URBAN REMOTE SENSING EVENT (JURSE), V0, P0
   Whittinghill LJ, 2012, RENEW AGR FOOD SYST, V27, P314, DOI 10.1017/S174217051100038X
   Wilkinson SJ, 2009, PROP MANAG, V27, P284, DOI 10.1108/02637470910998456
   Wong D., 2019, NUS LAUNCHES SINGAPO, V0, P0
   Wong NH, 2003, ENERG BUILDINGS, V35, P353, DOI 10.1016/S0378-7788(02)00108-1
   Wong NH, 2003, BUILD ENVIRON, V38, P261, DOI 10.1016/S0360-1323(02)00066-5
   Wong NH, 2021, NAT REV EARTH ENV, V2, P166, DOI 10.1038/s43017-020-00129-5
   Yang HS, 2012, BUILD ENVIRON, V50, P44, DOI 10.1016/j.buildenv.2011.10.004
   Yang J, 2008, ATMOS ENVIRON, V42, P7266, DOI 10.1016/j.atmosenv.2008.07.003
   Yang JJ, 2018, SOL ENERGY, V173, P597, DOI 10.1016/j.solener.2018.08.006
   Yu JF, 2018, JOULE, V2, P2605, DOI 10.1016/j.joule.2018.11.021
   Zamperini E., 2014, REHAB 2014, V0, PP1203, DOI 10.14575/gl/rehab2014/121
   Zhang J, 2019, APPL ENERG, V240, P513, DOI 10.1016/j.apenergy.2019.02.033
   Zhao QS, 2015, REMOTE SENS-BASEL, V7, P12135, DOI 10.3390/rs70912135
   Zhong T, 2021, RENEW ENERG, V168, P181, DOI 10.1016/j.renene.2020.12.044
NR 122
TC 25
Z9 25
U1 6
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-2046
EI 1872-6062
J9 LANDSCAPE URBAN PLAN
JI Landsc. Urban Plan.
PD OCT 15
PY 2021
VL 214
IS 
BP 
EP 
DI 10.1016/j.landurbplan.2021.104167
PG 16
WC Ecology; Environmental Studies; Geography; Geography, Physical; Regional & Urban Planning; Urban Studies
SC Environmental Sciences & Ecology; Geography; Physical Geography; Public Administration; Urban Studies
GA TU6DB
UT WOS:000681123700004
DA 2023-04-26
ER

PT J
AU Chen, YJ
   Wu, SS
   Wang, YY
   Zhang, F
   Liu, RY
   Du, ZH
AF Chen, Yijun
   Wu, Sensen
   Wang, Yuanyuan
   Zhang, Feng
   Liu, Renyi
   Du, Zhenhong
TI Satellite-Based Mapping of High-Resolution Ground-Level PM2.5 with VIIRS IP AOD in China through Spatially Neural Network Weighted Regression
SO REMOTE SENSING
LA English
DT Article
DE PM2.5; VIIRS IP AOD; high accuracy; high-resolution; China; geographically neural network weighted regression
ID aerosol optical depth; modis; retrievals; pollution; particles; products; models; region
AB Satellite-retrieved aerosol optical depth (AOD) data are extensively integrated with ground-level measurements to achieve spatially continuous fine particulate matters (PM2.5). Current satellite-based methods however face challenges in obtaining highly accurate and reasonable PM2.5 distributions due to the inability to handle both spatial non-stationarity and complex non-linearity in the PM2.5-AOD relationship. High-resolution (<1 km) PM2.5 products over the whole of China for fine exposure assessment and health research are also lacking. This study aimed to predict 750 m resolution ground-level PM2.5 in China with the high-resolution Visible Infrared Imaging Radiometer Suite (VIIRS) intermediate product (IP) AOD data using a newly developed geographically neural network weighted regression (GNNWR) model. The performance evaluations demonstrated that GNNWR achieved higher prediction accuracy than the widely used methods with cross-validation and predictive R-2 of 0.86 and 0.85. Satellite-derived monthly 750 m resolution PM2.5 data in China were generated with robust prediction accuracy and almost complete coverage. The PM2.5 pollution was found to be greatly improved in 2018 in China with annual mean concentration of 31.07 +/- 17.52 mu g/m(3). Nonetheless, fine-scale PM2.5 exposures at multiple administrative levels suggested that PM2.5 pollution in most urban areas needed further control, especially in southern Hebei Province. This work is the first to evaluate the potential of VIIRS IP AOD in modeling high-resolution PM2.5 over large-scale. The newly satellite-derived PM2.5 data with high spatial resolution and high prediction accuracy at the national scale are valuable to advance environmental and health researches in China.
C1 [Chen, Yijun; Wu, Sensen; Zhang, Feng; Liu, Renyi; Du, Zhenhong] Zhejiang Univ, Sch Earth Sci, 38 Zheda Rd, Hangzhou 310027, Peoples R China.
   [Wu, Sensen; Zhang, Feng; Liu, Renyi; Du, Zhenhong] Zhejiang Prov Key Lab Geog Informat Sci, 148 Tianmushan Rd, Hangzhou 310028, Peoples R China.
   [Wang, Yuanyuan] Zhejiang Univ, Ocean Acad, Zhoushan 316022, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Wu, SS (corresponding author), Zhejiang Univ, Sch Earth Sci, 38 Zheda Rd, Hangzhou 310027, Peoples R China.; Wu, SS (corresponding author), Zhejiang Prov Key Lab Geog Informat Sci, 148 Tianmushan Rd, Hangzhou 310028, Peoples R China.
EM yijunchen@zju.edu.cn; wusensengis@zju.edu.cn; wangyuanyuanxy@zju.edu.cn; zfcarnation@zju.edu.cn; liurenyi@zju.edu.cn; duzhenhong@zju.edu.cn
FU National Natural Science Foundation of China [41922043, 41871287, 42001323]; National Key Research and Development Program of China [2018YFB0505000]
CR Bartell SM, 2013, ENVIRON HEALTH PERSP, V121, P1135, DOI 10.1289/ehp.1205914
   Beckers JM, 2003, J ATMOS OCEAN TECH, V20, P1839, DOI 10.1175/1520-0426(2003)020<1839:ECADFF>2.0.CO;2
   Benas N, 2013, ATMOS ENVIRON, V79, P448, DOI 10.1016/j.atmosenv.2013.07.012
   Brauer M, 2012, ENVIRON SCI TECHNOL, V46, P652, DOI 10.1021/es2025752
   Cao CY, 2013, J GEOPHYS RES-ATMOS, V118, P11664, DOI 10.1002/2013JD020418
   Cao CY, 2014, IEEE T GEOSCI REMOTE, V52, P1142, DOI 10.1109/TGRS.2013.2247768
   Ceylan Z, 2018, GLOBAL NEST J, V20, P281, DOI 10.30955/gnj.002522
   Chang YH, 2012, ENVIRON SCI TECHNOL, V46, P7069, DOI 10.1021/es3022705
   Chen GB, 2018, SCI TOTAL ENVIRON, V636, P52, DOI 10.1016/j.scitotenv.2018.04.251
   Chen J, 2019, ENVIRON INT, V130, P0, DOI 10.1016/j.envint.2019.104934
   Chen L, 2018, ENVIRON INT, V116, P300, DOI 10.1016/j.envint.2018.03.047
   Chen WQ, 2020, SCI TOTAL ENVIRON, V746, P0, DOI 10.1016/j.scitotenv.2020.141093
   Chen YG, 2018, COMPUTING, V100, P825, DOI 10.1007/s00607-018-0628-3
   Dominici F, 2006, JAMA-J AM MED ASSOC, V295, P1127, DOI 10.1001/jama.295.10.1127
   Du ZH, 2021, ENVIRON SCI TECHNOL, V55, P2553, DOI 10.1021/acs.est.0c05928
   Du ZH, 2020, INT J GEOGR INF SCI, V34, P1353, DOI 10.1080/13658816.2019.1707834
   Fotheringham A. S., 2002, GEOGRAPHICALLY WEIGH, V0, P0
   Guo YX, 2017, REMOTE SENS ENVIRON, V198, P140, DOI 10.1016/j.rse.2017.06.001
   Gupta P, 2009, J GEOPHYS RES-ATMOS, V114, P0, DOI 10.1029/2008JD011496
   Han YX, 2009, ATMOS ENVIRON, V43, P568, DOI 10.1016/j.atmosenv.2008.10.018
   He QQ, 2018, REMOTE SENS ENVIRON, V206, P72, DOI 10.1016/j.rse.2017.12.018
   He QQ, 2018, ENVIRON POLLUT, V236, P1027, DOI 10.1016/j.envpol.2018.01.053
   Hu XF, 2013, ENVIRON RES, V121, P1, DOI 10.1016/j.envres.2012.11.003
   Hu ZY, 2009, INT J HEALTH GEOGR, V8, P0, DOI 10.1186/1476-072X-8-27
   Li JM, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16030454
   Li LF, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020264
   Li LF, 2018, REMOTE SENS ENVIRON, V217, P573, DOI 10.1016/j.rse.2018.09.001
   Li TW, 2017, ATMOS ENVIRON, V152, P477, DOI 10.1016/j.atmosenv.2017.01.004
   Lin CQ, 2016, REMOTE SENS ENVIRON, V179, P13, DOI 10.1016/j.rse.2016.03.023
   Liu M, 2019, ISPRS J PHOTOGRAMM, V158, P90, DOI 10.1016/j.isprsjprs.2019.10.010
   Lv BL, 2016, ENVIRON SCI TECHNOL, V50, P4752, DOI 10.1021/acs.est.5b05940
   Lyu H, 2018, SOLA, V14, P14, DOI 10.2151/sola.2018-003
   Ma YY, 2019, ATMOS POLLUT RES, V10, P2063, DOI 10.1016/j.apr.2019.09.014
   Ma ZW, 2014, ENVIRON SCI TECHNOL, V48, P7436, DOI 10.1021/es5009399
   Memarianfard M, 2017, GLOB J ENVIRON SCI M, V3, P333, DOI 10.22034/gjesm.2017.03.03.010
   Mirzaei M, 2019, AIR QUAL ATMOS HLTH, V12, P1215, DOI 10.1007/s11869-019-00739-z
   Peng J, 2016, REMOTE SENS ENVIRON, V174, P109, DOI 10.1016/j.rse.2015.12.008
   Shen HF, 2018, J GEOPHYS RES-ATMOS, V123, P13875, DOI 10.1029/2018JD028759
   Song WZ, 2014, REMOTE SENS ENVIRON, V154, P1, DOI 10.1016/j.rse.2014.08.008
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Wang DD, 2011, IEEE T GEOSCI REMOTE, V49, P1513, DOI 10.1109/TGRS.2010.2086463
   Wang WL, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-50177-1
   Wang XM, 2004, J ARID ENVIRON, V58, P559, DOI 10.1016/j.jaridenv.2003.11.009
   Wei J, 2020, ATMOS CHEM PHYS, V20, P3273, DOI 10.5194/acp-20-3273-2020
   Wei J, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111221
   Wu JS, 2016, REMOTE SENS ENVIRON, V184, P316, DOI 10.1016/j.rse.2016.07.015
   Wu SS, 2020, SCI TOTAL ENVIRON, V709, P0, DOI 10.1016/j.scitotenv.2019.136097
   Xiao L, 2018, ATMOS ENVIRON, V173, P295, DOI 10.1016/j.atmosenv.2017.10.062
   Xiao Q, 2016, ATMOS CHEM PHYS, V16, P1255, DOI 10.5194/acp-16-1255-2016
   Xue T, 2019, ENVIRON INT, V123, P345, DOI 10.1016/j.envint.2018.11.075
   Xue WH, 2020, SCI TOTAL ENVIRON, V712, P0, DOI 10.1016/j.scitotenv.2019.134577
   Yao F, 2019, ISPRS J PHOTOGRAMM, V151, P263, DOI 10.1016/j.isprsjprs.2019.03.011
   Yao F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070841
   Yao F, 2018, SCI TOTAL ENVIRON, V618, P819, DOI 10.1016/j.scitotenv.2017.08.209
   You W, 2016, ENVIRON SCI POLLUT R, V23, P8327, DOI 10.1007/s11356-015-6027-9
   You W, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030184
   Yu WX, 2017, SCI REP-UK, V7, P0, DOI 10.1038/s41598-017-07478-0
   Yu Y, 2011, J ENVIRON MONITOR, V13, P334, DOI 10.1039/c0em00467g
   Zang L, 2018, ENVIRON POLLUT, V241, P654, DOI 10.1016/j.envpol.2018.05.100
   Zhai L, 2018, ATMOS ENVIRON, V181, P145, DOI 10.1016/j.atmosenv.2018.03.017
   Zhao CS, 2006, GEOPHYS RES LETT, V33, P0, DOI 10.1029/2006GL025959
   Zhou W, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090959
   Zhu JL, 2012, GEOPHYS RES LETT, V39, P0, DOI 10.1029/2012GL051428
NR 63
TC 1
Z9 3
U1 7
U2 46
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY 15
PY 2021
VL 13
IS 10
BP 
EP 
DI 10.3390/rs13101979
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA ST6YA
UT WOS:000662586000001
DA 2023-04-26
ER

PT J
AU Zha, B
   Yilmaz, A
AF Zha, Bing
   Yilmaz, Alper
TI Map-Based Temporally Consistent Geolocalization through Learning Motion Trajectories
SO 2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
LA English
DT Proceedings Paper
ID simultaneous localization; spatial map; hippocampus; perception; navigation; model
AB In this paper, we propose a novel trajectory learning method that exploits motion trajectories on topological map using recurrent neural network for temporally consistent geolocalization of object. Inspired by human's ability to both be aware of distance and direction of self-motion in navigation, our trajectory learning method learns a pattern representation of trajectories encoded as a sequence of distances and turning angles to assist self-localization. We pose the learning process as a conditional sequence prediction problem in which each output locates the object on a traversable edge in a map. Considering the prediction sequence ought to be topologically connected in the graph-structured map, we adopt two different hypotheses generation and elimination strategies to eliminate disconnected sequence prediction. We demonstrate our approach on the KITTI stereo visual odometry dataset which is a city-scale environment. The key benefits of our approach to geolocalization are that 1) we take advantage of powerful sequence modeling ability of recurrent neural network and its robustness to noisy input, 2) only require a map in the form of a graph and 3) simply use an affordable sensor that generates motion trajectory. The experiments show that the motion trajectories can be learned by training an recurrent neural network, and temporally consistent geolocation can be predicted with both of the proposed strategies.
C1 [Zha, Bing; Yilmaz, Alper] Ohio State Univ, Photogrammetr Comp Vis Lab, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Zha, B (corresponding author), Ohio State Univ, Photogrammetr Comp Vis Lab, Columbus, OH 43210 USA.
EM zha.44@osu.edu; yilmaz.15@osu.edu
CR Barry C, 2006, REV NEUROSCIENCE, V17, P71
   Boal J, 2014, ROBOTICA, V32, P803, DOI 10.1017/S0263574713001070
   Brubaker MA, 2016, IEEE T PATTERN ANAL, V38, P652, DOI 10.1109/TPAMI.2015.2453975
   Bush D, 2015, NEURON, V87, P507, DOI 10.1016/j.neuron.2015.07.006
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Edvardsen V, 2020, HIPPOCAMPUS, V30, P220, DOI 10.1002/hipo.23147
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Erdem UM, 2012, EUR J NEUROSCI, V35, P916, DOI 10.1111/j.1460-9568.2012.08015.x
   Fox D, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), V0, P343
   Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901
   Geiger A., 2012, C COMP VIS PATT REC, V0, P0
   Gupta A, 2016, ISPRS ANN PHOTO REM, V3, P263, DOI 10.5194/isprsannals-III-3-263-2016
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Hofmann-Wellenhof B., 2012, GLOBAL POSITIONING S, V0, P0
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592
   Milford MJ, 2004, IEEE INT CONF ROBOT, V0, PP403, DOI 10.1109/ROBOT.2004.1307183
   Newson P., 2009, P 17 ACM SIGSPATIAL, V0, PP336, DOI 10.1145/1653771.1653818
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKEEFE J, 1976, EXP NEUROL, V51, P78, DOI 10.1016/0014-4886(76)90055-8
   Sattler T, 2011, IEEE I CONF COMP VIS, V0, PP667, DOI 10.1109/ICCV.2011.6126302
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Tomatis N, 2003, ROBOT AUTON SYST, V44, P3, DOI 10.1016/S0921-8890(03)00006-X
   Walch F, 2017, IEEE I CONF COMP VIS, V0, PP627, DOI 10.1109/ICCV.2017.75
NR 25
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1051-4651
EI 
J9 INT C PATT RECOG
PD JUN 15
PY 2021
VL 0
IS 
BP 2296
EP 2303
DI 10.1109/ICPR48806.2021.9412398
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA BR9MO
UT WOS:000678409202053
DA 2023-04-26
ER

PT J
AU McGlinchy, J
   Muller, B
   Johnson, B
   Joseph, M
   Diaz, J
AF McGlinchy, Joseph
   Muller, Brian
   Johnson, Brian
   Joseph, Maxwell
   Diaz, Jeremy
TI Fully Convolutional Neural Network for Impervious Surface Segmentation in Mixed Urban Environment
SO PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING
LA English
DT Article
AB The urgency of creating appropriate, high-resolution data products such as impervious cover information has increased as cities face rapid growth as well as climate change and other environmental challenges. This work explores the use of fully convolutional neural networks (FCNNs)-specifically UNet with a ResNet-152 encoder-in mapping impervious surfaces at the pixel level from World View-2 in a mixed urban/residential environment. We investigate three-, four-, and eight-band multispectral inputs to the FCNN. Resulting maps are promising in both qualitative and quantitative assessment when compared to automated land use/land cover products. Accuracy was assessed by F1 and average precision (AP) scores, as well as receiver operating characteristic curves, with area under the curve (AUC) used as an additional accuracy metric. The four-band model shows the highest average test-set accuracies (F1, Al, and AUC of 0.709, 0.82, and 0.807, respectively), with higher AP and AUG than the automated land use/land cover products, indicating the utility of the blue-green-red-infrared channels for the FCNN. Improved performance was seen in residential areas, with worse performance in more densely developed areas.
C1 [McGlinchy, Joseph; Johnson, Brian; Joseph, Maxwell; Diaz, Jeremy] Univ Colorado, Earth Lab, CIRES, Boulder, CO 80303 USA.
   [Muller, Brian] Univ Colorado, Environm Sci, Boulder, CO 80303 USA.
   [Johnson, Brian] Aerosp Corp, Longmont, CO USA.
   [Diaz, Jeremy] Penn State Univ, State Coll, PA USA.
C3 University of Colorado System; University of Colorado Boulder; University of Colorado System; University of Colorado Boulder; Aerospace Corporation - USA; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University
RP McGlinchy, J (corresponding author), Univ Colorado, Earth Lab, CIRES, Boulder, CO 80303 USA.
EM joseph.mcglinchy@colorado.edu
FU Earth Lab through the University of Colorado Boulder's Grand Challenge Initiative
CR DigitalGlobe, 2016, BUILT EXT, V0, P0
   DigitalGlobe, 2016, AUT LAND COV CLASS, V0, P0
   Iglovikov V., 2018, ARXIV180105746, V0, P1
   Kokaly R.F., 2017, USGS SPECTRAL LIB VE, V1035, P0
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   McGlinchy J., 2019, IGARSS 2019, V0, PPP
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shao ZF, 2019, REMOTE SENS ENVIRON, V232, P0, DOI 10.1016/j.rse.2019.111338
   Shvets AA, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP624, DOI 10.1109/ICMLA.2018.00100
   Wang YL, 2019, IEEE GEOSC REM SEN M, V7, P64, DOI 10.1109/MGRS.2019.2927260
   Weng QH, 2012, REMOTE SENS ENVIRON, V117, P34, DOI 10.1016/j.rse.2011.02.030
   Wieland M, 2014, REMOTE SENS-BASEL, V6, P2912, DOI 10.3390/rs6042912
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 15
TC 4
Z9 4
U1 1
U2 17
PU AMER SOC PHOTOGRAMMETRY
PI BETHESDA
PA 5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA
SN 0099-1112
EI 2374-8079
J9 PHOTOGRAMM ENG REM S
JI Photogramm. Eng. Remote Sens.
PD FEB 15
PY 2021
VL 87
IS 2
BP 117
EP 123
DI 10.14358/PERS.87.2.117
PG 7
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QA1AL
UT WOS:000613182400007
DA 2023-04-26
ER

PT J
AU Scepanovic, S
   Antropov, O
   Laurila, P
   Rauste, Y
   Ignatenko, V
   Praks, J
AF Scepanovic, Sanja
   Antropov, Oleg
   Laurila, Pekka
   Rauste, Yrjo
   Ignatenko, Vladimir
   Praks, Jaan
TI Wide-Area Land Cover Mapping With Sentinel-1 Imagery Using Deep Learning Semantic Segmentation Models
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Synthetic aperture radar; Deep learning; Satellites; Radar polarimetry; Optical imaging; Feature extraction; Biological system modeling; C-band; CORINE; deep learning; image classification; land cover (LC) mapping; semantic segmentation; sentinel-1 data; synthetic aperture radar (SAR)
ID polarimetric sar data; accuracy assessment; neural-network; l-band; classification; radarsat-2; polsar; support; amazon; forest
AB Land cover (LC) mapping is essential for monitoring the environment and understanding the effects of human activities on it. Recent studies demonstrated successful applications of specific deep learning models to small-scale LC mapping tasks (e.g., wetland mapping). However, it is not readily clear which of the existing state-of-the-art models for natural images are the best candidates to be taken for the particular remote sensing task and data. In this article, we answer that question for mapping the fundamental LC classes using the satellite imaging radar data. We took ESA Sentinel-1 C-band SAR images acquired during the whole summer season of 2018 in Finland, which are representative of the land cover in the country. CORINE LC map was used as a reference, and the models were trained to distinguish between the five major CORINE-based classes. We selected seven among the state-of-the-art semantic segmentation models so that they cover a diverse set of approaches: U-Net, DeepLabV3+, PSPNet, BiSeNet, SegNet, FC-DenseNet, and FRRN-B, and further fine-tuned them. Upon evaluation and benchmarking, all the models demonstrated solid performance with overall accuracy between 87.9% and 93.1%, with good to a very good agreement (Kappa statistic between 0.75 and 0.86). The two best models were fully convolutional DenseNets (FC-DenseNet) and SegNet (encoder-decoder-skip), with the latter having a much shorter inference time. Overall, our results indicate that the semantic segmentation models are suitable for efficient wide-area mapping using satellite SAR imagery and provide baseline accuracy against which the newly proposed models should be evaluated.
C1 [Scepanovic, Sanja; Laurila, Pekka; Ignatenko, Vladimir] ICEYE Oy, Espoo 02150, Finland.
   [Antropov, Oleg; Rauste, Yrjo] VTT Tech Res Ctr Finland, Espoo 02044, Finland.
   [Praks, Jaan] Aalto Univ, Espoo 02150, Finland.
C3 VTT Technical Research Center Finland; Aalto University
RP Antropov, O (corresponding author), VTT Tech Res Ctr Finland, Espoo 02044, Finland.
EM sanjascepanovic@gmail.com; oleg.antropov@vtt.fi; pekka.laurila@iceye.fi; yrjo.rauste@vtt.fi; vladimirignatenko@iceye.fi; jaan.praks@aalto.fi
FU ICEYE Oy; EIT Digital; Aalto University; VTT
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Ahishali M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111340
   [Anonymous], 2017, ARXIV171003959, V0, P0
   [Anonymous], 2004, EARSEL EPROCEEDINGS, V0, P0
   [Anonymous], 2012, P MACHINE LEARNING R, V0, P0
   Antropov O, 2014, IEEE T GEOSCI REMOTE, V52, P5256, DOI 10.1109/TGRS.2013.2287712
   Antropov O, 2012, IEEE GEOSCI REMOTE S, V9, P1074, DOI 10.1109/LGRS.2012.2190263
   Antropov O, 2011, IEEE T GEOSCI REMOTE, V49, P3838, DOI 10.1109/TGRS.2011.2138146
   Atzberger C, 2013, REMOTE SENS-BASEL, V5, P949, DOI 10.3390/rs5020949
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balzter H, 2015, REMOTE SENS-BASEL, V7, P14876, DOI 10.3390/rs71114876
   Ban YF, 2010, INT J REMOTE SENS, V31, P1391, DOI 10.1080/01431160903475415
   Bojinski S, 2014, B AM METEOROL SOC, V95, P1431, DOI 10.1175/BAMS-D-13-00047.1
   Bruzzone L, 2004, IEEE T GEOSCI REMOTE, V42, P1321, DOI 10.1109/TGRS.2004.826821
   Buttner G, 2014, REMOTE SENS DIGIT IM, V18, P55, DOI 10.1007/978-94-007-7969-3_5
   Cable JW, 2014, REMOTE SENS-BASEL, V6, P2372, DOI 10.3390/rs6032372
   Castaneda C, 2009, J ENVIRON MANAGE, V90, P2270, DOI 10.1016/j.jenvman.2007.06.030
   Chen J, 2015, ISPRS J PHOTOGRAMM, V103, P7, DOI 10.1016/j.isprsjprs.2014.09.002
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Clerici N, 2017, J MAPS, V13, P718, DOI 10.1080/17445647.2017.1372316
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cohen WB, 2004, BIOSCIENCE, V54, P535, DOI 10.1641/0006-3568(2004)054[0535:LRIEAO]2.0.CO;2
   Costa H, 2018, REMOTE SENS ENVIRON, V205, P338, DOI 10.1016/j.rse.2017.11.024
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.32
   De Alban JDT, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020306
   de Almeida CA, 2016, ACTA AMAZON, V46, P291, DOI 10.1590/1809-4392201505504
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Nguyen DB, 2016, REMOTE SENS LETT, V7, P1209, DOI 10.1080/2150704X.2016.1225172
   Esch T, 2011, IEEE T GEOSCI REMOTE, V49, P1911, DOI 10.1109/TGRS.2010.2091644
   Evans TL, 2010, IEEE J-STARS, V3, P560, DOI 10.1109/JSTARS.2010.2089042
   Freitas CD, 2008, IEEE T GEOSCI REMOTE, V46, P2956, DOI 10.1109/TGRS.2008.2000630
   García Herrera Arístides Lázaro, 2017, REV.MED.ELECTRÓN., V0, P1
   Ge SJ, 2019, INT GEOSCI REMOTE SE, V0, PP473, DOI 10.1109/IGARSS.2019.8900088
   Goetz Scott J, 2009, CARBON BALANCE MANAG, V4, P2, DOI 10.1186/1750-0680-4-2
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Griffiths P, 2019, REMOTE SENS ENVIRON, V220, P135, DOI 10.1016/j.rse.2018.10.031
   Hame T, 2013, IEEE J-STARS, V6, P74, DOI 10.1109/JSTARS.2013.2241019
   Harma P, 2004, P 20 INT ARCH PHOT R, V0, P1330
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Homer C, 2015, PHOTOGRAMM ENG REM S, V81, P345, DOI 10.14358/PERS.81.5.345
   Howard A. G., 2017, CORR, V0, P0, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jacob AW, 2020, IEEE J-STARS, V13, P535, DOI 10.1109/JSTARS.2019.2958847
   Jegou S, 2017, IEEE COMPUT SOC CONF, V0, PP1175, DOI 10.1109/CVPRW.2017.156
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Laurin GV, 2013, INT J APPL EARTH OBS, V21, P7, DOI 10.1016/j.jag.2012.08.002
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P0, DOI 10.5555/303568.303704
   Li GY, 2012, ISPRS J PHOTOGRAMM, V70, P26, DOI 10.1016/j.isprsjprs.2012.03.010
   Li ZG, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTERS, V0, P0
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Longepe N, 2011, IEEE T GEOSCI REMOTE, V49, P2135, DOI 10.1109/TGRS.2010.2102041
   Lonnqvist A, 2010, IEEE T GEOSCI REMOTE, V48, P3652, DOI 10.1109/TGRS.2010.2048115
   Lumsdon P, 2005, IEE P-RADAR SON NAV, V152, P404, DOI 10.1049/ip-rsn:20041313
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   Mohammadimanesh F, 2019, ISPRS J PHOTOGRAMM, V151, P223, DOI 10.1016/j.isprsjprs.2019.03.015
   Niu X, 2013, INT J REMOTE SENS, V34, P1, DOI 10.1080/01431161.2012.700133
   Otahel J, 2000, 40 EUR ENV AG, V0, P0
   Park NW, 2008, INT J REMOTE SENS, V29, P4667, DOI 10.1080/01431160801947341
   Park SE, 2015, REMOTE SENS-BASEL, V7, P17135, DOI 10.3390/rs71215874
   Pohlen T, 2017, PROC CVPR IEEE, V0, PP3309, DOI 10.1109/CVPR.2017.353
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sainath TN, 2013, INT CONF ACOUST SPEE, V0, PP8614, DOI 10.1109/ICASSP.2013.6639347
   Satalino G, 2014, IEEE GEOSCI REMOTE S, V11, P384, DOI 10.1109/LGRS.2013.2263034
   Simonyan K, 2015, ARXIV, V0, P0
   Small D, 2011, CAN J REMOTE SENS, V37, P493
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Thiel C, 2009, INT GEOSCI REMOTE SE, V0, PP1620, DOI 10.1109/IGARSS.2009.5417764
   Tomppo E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212480
   Torma M, 2015, BOREAL ENVIRON RES, V20, P243
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   Tuia D, 2015, ISPRS J PHOTOGRAMM, V105, P272, DOI 10.1016/j.isprsjprs.2015.01.006
   Ullmann T, 2014, REMOTE SENS-BASEL, V6, P8565, DOI 10.3390/rs6098565
   Veloso A, 2017, REMOTE SENS ENVIRON, V199, P415, DOI 10.1016/j.rse.2017.07.015
   Wang J, 2015, INT GEOSCI REMOTE SE, V0, PP4320, DOI 10.1109/IGARSS.2015.7326782
   Wang L, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18030769
   Waske B, 2009, ISPRS J PHOTOGRAMM, V64, P450, DOI 10.1016/j.isprsjprs.2009.01.003
   Wu GM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030407
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zhang J, 2014, IEEE T GEOSCI REMOTE, V52, P2617, DOI 10.1109/TGRS.2013.2263933
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhao YY, 2016, REMOTE SENS ENVIRON, V183, P170, DOI 10.1016/j.rse.2016.05.016
NR 95
TC 7
Z9 7
U1 11
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10357
EP 10374
DI 10.1109/JSTARS.2021.3116094
PG 18
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WN2ZC
UT WOS:000711641000010
DA 2023-04-26
ER

PT J
AU Vargas-Munoz, JE
   Srivastava, S
   Tuia, D
   Falcao, AX
AF Vargas-Munoz, John E.
   Srivastava, Shivangi
   Tuia, Devis
   Falcao, Alexandre X.
TI OpenStreetMap: Challenges and Opportunities in Machine Learning and Remote Sensing
SO IEEE GEOSCIENCE AND REMOTE SENSING MAGAZINE
LA English
DT Article
DE Roads; Buildings; Annotations; Feature extraction; Urban areas; Machine learning; Remote sensing
ID quality assessment; neural-networks; classification; information; patterns; points; models
AB OpenStreetMap (OSM) is a community-based, freely available, editable map service created as an alternative to authoritative sources. Given that it is edited mainly by volunteers with different mapping skills, the completeness and quality of its annotations are heterogeneous across different geographical locations. Despite that, OSM has been widely used in several applications in geosciences, Earth observation, and environmental sciences. In this article, we review recent methods based on machine learning to improve and use OSM data. Such methods aim to either 1) improve the coverage and quality of OSM layers, typically by using geographic information systems (GISs) and remote sensing technologies, or 2) use the existing OSM layers to train models based on image data to serve applications such as navigation and land use classification. We believe that OSM (as well as other sources of open land maps) can change the way we interpret remote sensing data and that the synergy with machine learning can scale participatory mapmaking and its quality to the level needed for global and up-to-date land mapping. A preliminary version of this manuscript was presented in [120].
C1 [Vargas-Munoz, John E.] Univ Estadual Campinas, Campinas, SP, Brazil.
   [Srivastava, Shivangi; Tuia, Devis] Univ Zurich, Zurich, Switzerland.
   [Srivastava, Shivangi] Wageningen Univ & Res, Wageningen, Netherlands.
   [Tuia, Devis] Univ Valencia, Valencia, Spain.
   [Tuia, Devis] Univ Colorado, Boulder, CO 80309 USA.
   [Tuia, Devis] EPFL Lausanne, Lausanne, Switzerland.
   [Tuia, Devis] Wageningen Univ & Res, Geoinformat Sci & Remote Sensing Lab, Wageningen, Netherlands.
   [Falcao, Alexandre X.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
   [Falcao, Alexandre X.] Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA.
C3 Universidade Estadual de Campinas; University of Zurich; Wageningen University & Research; University of Valencia; University of Colorado System; University of Colorado Boulder; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Wageningen University & Research; Universidade Estadual de Campinas; University of Pennsylvania
RP Vargas-Munoz, JE (corresponding author), Univ Estadual Campinas, Campinas, SP, Brazil.
EM john.vargas@ic.unicamp.br; shivangi.srivastava@wur.nl; devis.tuia@wur.nl; afalcao@ic.unicamp.br
FU Fundacao de Amparo a Pesquisa do Estado de Sao Paulo [2016/14760-5, 2014/12236-1]; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico [303808/2018-7]; Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brasil [001]
CR Agrawal R., 1994, PROC 20 INT C VERY L, V0, P487
   Ali A.L., 2014, P 22 ACM SIGSPATIAL, V0, PP143, DOI https://doi.org/10.1145/2666310.2666392
   Ali AL, 2017, ISPRS J PHOTOGRAMM, V127, P3, DOI 10.1016/j.isprsjprs.2016.06.003
   Andreas Jacob, 2013, P 51 ANN M ASS COMP, V2, P47
   Arsanjani JJ, 2015, T GIS, V19, P896, DOI 10.1111/tgis.12139
   Arsanjani JJ, 2015, INT J APPL EARTH OBS, V35, P329, DOI 10.1016/j.jag.2014.09.009
   Audebert N, 2017, IEEE COMPUT SOC CONF, V0, PP1552, DOI 10.1109/CVPRW.2017.199
   Bakillah M, 2014, INT J GEOGR INF SCI, V28, P1940, DOI 10.1080/13658816.2014.909045
   Ballatore A, 2013, KNOWL INF SYST, V37, P61, DOI 10.1007/s10115-012-0571-0
   Barrington-Leigh C, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0180698
   Basiri A, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16091510
   Basiri A, 2016, GEO-SPAT INF SCI, V19, P56, DOI 10.1080/10095020.2016.1151213
   Bastani F, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), V0, PP23, DOI 10.1145/3274895.3274927
   Bastani F, 2018, PROC CVPR IEEE, V0, PP4720, DOI 10.1109/CVPR.2018.00496
   Berriel RF, 2017, COMPUT GRAPH-UK, V68, P32, DOI 10.1016/j.cag.2017.08.004
   Bing Blogs, 2018, MICROSOFT RELEASES 1, V0, P0
   Bojanowski P., 2017, T ASSOC COMPUT LING, V0, P0, DOI DOI 10.1162/TACL
   Chen, 2008, P 28 INCA INT C COLL, V0, P1
   Chen JY, 2019, IEEE T GEOSCI REMOTE, V57, P1713, DOI 10.1109/TGRS.2018.2868748
   Chen JY, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP771, DOI 10.1145/3041021.3054250
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Copernicus, 2020, URBAN ATLAS, V0, P0
   Crawford MM, 2013, P IEEE, V101, P593, DOI 10.1109/JPROC.2012.2231951
   EGENHOFER MJ, 1995, INT J GEOGR INF SYST, V9, P133, DOI 10.1080/02693799508902030
   Ertler C., 2019, ARXIV190904422, V0, P0
   Fan HC, 2014, INT J GEOGR INF SCI, V28, P700, DOI 10.1080/13658816.2013.867495
   Floros G, 2013, IEEE INT CONF ROBOT, V0, PP1054, DOI 10.1109/ICRA.2013.6630703
   Fonte CC, 2015, INT J GEOGR INF SCI, V29, P1269, DOI 10.1080/13658816.2015.1018266
   Funke S, 2015, P 2 INT C MIN URB DA, V1392, P27
   Funke S, 2017, LECT NOTES COMPUT SC, V10181, P3, DOI 10.1007/978-3-319-55998-8_1
   Gervasoni L, 2018, PR INT CONF DATA SC, V0, PP594, DOI 10.1109/DSAA.2018.00076
   Girres JF, 2010, T GIS, V14, P435, DOI 10.1111/j.1467-9671.2010.01203.x
   Goetz M, 2012, ISPRS INT J GEO-INF, V1, P186, DOI 10.3390/ijgi1020186
   Gomes R. G., 2011, P 25 ANN C NEUR INF, V0, P558
   Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y
   Graser A., 2016, GI FORUM, V4, P217, DOI 10.1553/giscience2016_01_s217
   Haas Carolin, 2016, P 2016 C N AM CHAPT, V0, PP740, DOI 10.18653/V1/N16-1088
   Haberle M, 2019, INT GEOSCI REMOTE SE, V0, PP10047, DOI 10.1109/IGARSS.2019.8898836
   Haberle M, 2019, EUR J REMOTE SENS, V52, P2, DOI 10.1080/22797254.2019.1586451
   Hahmann S, 2018, GEO-SPAT INF SCI, V21, P247, DOI 10.1080/10095020.2017.1399675
   Haklay M, 2010, ENVIRON PLANN B, V37, P682, DOI 10.1068/b35097
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang R, 2018, INT GEOSCI REMOTE SE, V0, P6408
   Ilisei A., 2018, GRAB, V0, P0
   Jepsen TS, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), V0, PP460, DOI 10.1145/3347146.3359094
   Jilani M., 2019, GEOSPATIAL INTELLIGE, V0, P469
   Jilani M., 2013, P 6 ACM SIGSPATIAL I, V0, P19
   Jilani M., 2014, P 22 ACM SIGSPATIAL, V0, PP449, DOI 10.1145/2666310.2666476
   Jilani M., 2013, AG WORKSH ACT INT VO, V0, P0
   Jilani M, 2018, PROCEEDINGS OF THE 11TH ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON COMPUTATIONAL TRANSPORTATION SCIENCE (IWCTS 2018), V0, PP29, DOI 10.1145/3283207.3283210
   Jilani M, 2016, ADV INTELL SYST COMP, V385, P213, DOI 10.1007/978-3-319-23258-4_19
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Karagiannakis N., 2015, P 9 ACM C REC SYST, V0, PP337, DOI 10.1145/2792838.2796555
   Kashian A, 2019, INT J GEOGR INF SCI, V33, P1420, DOI 10.1080/13658816.2019.1584803
   Koukoletsos T, 2012, T GIS, V16, P477, DOI 10.1111/j.1467-9671.2012.01304.x
   Kuntzsch C, 2016, INT J GEOGR INF SCI, V30, P1012, DOI 10.1080/13658816.2015.1092151
   Lawrence C., 2016, P INT C COMP LING CO, V0, P6
   Lawrence C, 2020, OVERPASS NL MAPS, V0, P0
   Lawrence C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1820
   Li QP, 2014, INT J GEOGR INF SCI, V28, P2200, DOI 10.1080/13658816.2014.915401
   Lin B.Y., 2018, P WORKSH 32 AAAI C A, V0, P174
   Lobry S, 2019, INT GEOSCI REMOTE SE, V0, PP4951, DOI 10.1109/IGARSS.2019.8898891
   Luxen C. Vetter, 2011, P 19 ACM SIGSPATIAL, V0, PP513, DOI 10.1145/2093973.2094062
   Maggiori E, 2017, IEEE IMAGE PROC, V0, P560
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P4962, DOI 10.1109/TGRS.2017.2697453
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   MAJIC I, 2017, P 1 WORKSH ART INT D, V0, PP24, DOI 10.1145/3149808.3149813
   Mapillary, 2020, MAPILLARY TRAFFIC SI, V0, P0
   Marcos D, 2018, PROC CVPR IEEE, V0, PP8877, DOI 10.1109/CVPR.2018.00925
   Mattyus G, 2017, IEEE I CONF COMP VIS, V0, PP3458, DOI 10.1109/ICCV.2017.372
   Mattyus G, 2016, PROC CVPR IEEE, V0, PP3611, DOI 10.1109/CVPR.2016.393
   Mattyus G, 2015, IEEE I CONF COMP VIS, V0, PP1689, DOI 10.1109/ICCV.2015.197
   Mnih V., 2012, P 29 INT C MACH LEAR, V0, P567
   Mooney P, 2012, T GIS, V16, P561, DOI 10.1111/j.1467-9671.2012.01306.x
   Neis P, 2015, T GIS, V19, P188, DOI 10.1111/tgis.12087
   Neis P, 2014, FUTURE INTERNET, V6, P76, DOI 10.3390/fi6010076
   Neis P, 2012, ISPRS INT GEO-INF, V1, P146, DOI 10.3390/ijgi1020146
   Neis P, 2012, ISPRS INT GEO-INF, V1, P315, DOI 10.3390/ijgi1030315
   Neis P, 2012, FUTURE INTERNET, V4, P1, DOI 10.3390/fi4010001
   Over M, 2010, COMPUT ENVIRON URBAN, V34, P496, DOI 10.1016/j.compenvurbsys.2010.05.001
   Ren YB, 2019, INT J GEOGR INF SCI, V33, P1894, DOI 10.1080/13658816.2019.1599895
   Ruta M, 2014, TRANSP RES PROC, V3, P479, DOI 10.1016/j.trpro.2014.10.029
   Schilling A., 2009, P URB REH DAT MAN, V0, P75
   Senaratne H, 2017, INT J GEOGR INF SCI, V31, P139, DOI 10.1080/13658816.2016.1189556
   Settles B., 2009, 1648 U WISC, V0, P0
   Severinsen J, 2019, INT J GEOGR INF SCI, V33, P1683, DOI 10.1080/13658816.2019.1572893
   Srivastava S., 2018, P 21 AGILE INT C GE, V0, P1
   Srivastava S, 2020, INT J GEOGR INF SCI, V34, P1117, DOI 10.1080/13658816.2018.1542698
   Srivastava S, 2019, REMOTE SENS ENVIRON, V228, P129, DOI 10.1016/j.rse.2019.04.014
   Suger Benjamin, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP1417, DOI 10.1109/ICRA.2017.7989169
   Tasar O, 2018, INT GEOSCI REMOTE SE, V0, P6404
   Touya G, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6030080
   Truong Q.T., 2018, P 10 INT C GEOGR INF, V0, P0, DOI DOI 10.4230/LIPIcs.GIScience.2018.61
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Tuia D, 2017, JOINT URB REMOTE SEN, V0, P0
   Tuia D, 2013, IEEE T GEOSCI REMOTE, V51, P872, DOI 10.1109/TGRS.2012.2203605
   Vandecasteele A, 2015, LECT NOTES GEOINF CA, V0, PP59, DOI 10.1007/978-3-319-14280-7_4
   Vargas-Munoz J. E., 2019, THESIS U COMPNAS BRA, V0, P0
   Vargas-Munoz JE, 2019, ISPRS J PHOTOGRAMM, V147, P283, DOI 10.1016/j.isprsjprs.2018.11.010
   Ventura Carles, 2018, ARXIV180809814, V0, P0
   Wikipedia, 2020, GAMIFICATION, V0, P0
   Wikipedia, 2020, FACEBOOK AI ASSISTED, V0, P0
   Work Research Group, 2020, OPEN DATA, V0, P0
   Workman S, 2017, IEEE I CONF COMP VIS, V0, PP2707, DOI 10.1109/ICCV.2017.293
   Xu FF, 2016, PROCEEDINGS OF THE 9TH ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON COMPUTATIONAL TRANSPORTATION SCIENCE (IWCTS 2016), V0, PP37, DOI 10.1145/3003965.3003972
   Xu YY, 2019, T GIS, V23, P224, DOI 10.1111/tgis.12514
   Xu YY, 2017, INT J GEOGR INF SCI, V31, P1929, DOI 10.1080/13658816.2017.1341632
   Yao Y., 1900, V31, V0, P1220
   Yuan JY, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2018.217
   Zhang GC, 2019, IEEE T GEOSCI REMOTE, V57, P7623, DOI 10.1109/TGRS.2019.2914967
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zhuo XY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040624
NR 113
TC 30
Z9 30
U1 16
U2 44
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2473-2397
EI 2168-6831
J9 IEEE GEOSC REM SEN M
JI IEEE Geosci. Remote Sens. Mag.
PD MAR 15
PY 2021
VL 9
IS 1
BP 184
EP 199
DI 10.1109/MGRS.2020.2994107
PG 16
WC Geochemistry & Geophysics; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Remote Sensing; Imaging Science & Photographic Technology
GA RP5JJ
UT WOS:000641764700010
DA 2023-04-26
ER

PT J
AU Afaifia, M
   Djiar, KA
   Bich-Ngoc, N
   Teller, J
AF Afaifia, Marwa
   Djiar, Kahina Amal
   Bich-Ngoc, Nguyen
   Teller, Jacques
TI An energy consumption model for the Algerian residential building's stock, based on a triangular approach: Geographic Information System (GIS), regression analysis and hierarchical cluster analysis
SO SUSTAINABLE CITIES AND SOCIETY
LA English
DT Article
DE Residential energy consumption (REC); Housing stock; Energy modelling; Multiple Linear Regression (MLR); Spatialisation; Clustering; Algeria
ID electricity consumption; supporting method; neural-network; prediction; demand; sector; policy; savings; trends; heat
AB Modelling residential energy consumption (REC) represents a key step towards the implementation of energy transition policies for more sustainable cities. Developing such policies requires considering the characteristics of the residential building stock (RBS). In the literature, REC modelling is generally applied on a single or set of cities-provinces, through limited approaches, using data from one typical year. In this paper, an energy consumption model for the entire Algerian RBS is developed through a triangular approach combining Geographic Information System, regression analysis and hierarchical clustering, applied to all provinces from 1995 to 2018. This allows mapping the spatial-temporal distribution of REC and RBS, developing a REC model, and dividing all provinces into clusters based on their REC behaviour. Provinces are aggregated into four clusters and four provinces are identified as archetypes. The results highlight that, besides the size of the RBS, REC is highly dependent on the electricity and gas connection rates. However, the influence of GDP and urban density only play a minor role. This can be explained by the evolving demands in thermal comfort associated with access to energy networks. The likely impact of increased gas and electricity connection represents a crucial factor in the design of energy policies.
C1 [Afaifia, Marwa; Djiar, Kahina Amal] Ecole Polytech Architecture & Urbanisme EPAU, Lab Ville Urbanisme & Dev Durable VUDD, Route Beaulieu,El Harrach BP 177, Algiers 16200, Algeria.
   [Afaifia, Marwa; Bich-Ngoc, Nguyen; Teller, Jacques] Univ Liege, Local Environm Management & Anal Lab, Dept UEE, Appl Sci, B-4000 Liege, Belgium.
C3 University of Liege
RP Afaifia, M (corresponding author), Ecole Polytech Architecture & Urbanisme EPAU, Lab Ville Urbanisme & Dev Durable VUDD, Route Beaulieu,El Harrach BP 177, Algiers 16200, Algeria.
EM m.afaifia@epau-alger.edu.dz
CR Al-Ghandoor A, 2009, RENEW SUST ENERG REV, V13, P1262, DOI 10.1016/j.rser.2008.09.008
   Amri F, 2017, RENEW SUST ENERG REV, V76, P62, DOI 10.1016/j.rser.2017.03.029
   [Anonymous], 2021, R LANG ENV STAT COMP, V0, P0
   APRUE, 2015, PUBL EN ZON, V0, P0
   APRUE, 2015, PROGR EC BAT EFF EN, V0, P0
   APRUE, 2017, CONS EN FIN, V0, P0
   Aydinalp-Koksal M, 2008, APPL ENERG, V85, P271, DOI 10.1016/j.apenergy.2006.09.012
   Belaid F, 2013, ENERG POLICY, V55, P286, DOI 10.1016/j.enpol.2012.12.004
   Bianco V, 2013, ENERG SOURCE PART B, V8, P86, DOI 10.1080/15567240903289549
   Biswas MAR, 2016, ENERGY, V117, P84, DOI 10.1016/j.energy.2016.10.066
   Boukarta S, 2018, QUAEST GEOGR, V37, P111, DOI 10.2478/quageo-2018-0034
   Bourdeau M, 2019, SUSTAIN CITIES SOC, V48, P0, DOI 10.1016/j.scs.2019.101533
   Brounen D, 2012, EUR ECON REV, V56, P931, DOI 10.1016/j.euroecorev.2012.02.007
   Caputo P, 2017, SUSTAIN CITIES SOC, V34, P394, DOI 10.1016/j.scs.2017.07.002
   Caputo P, 2013, ENERG POLICY, V55, P261, DOI 10.1016/j.enpol.2012.12.006
   Catalina T, 2013, ENERG BUILDINGS, V57, P302, DOI 10.1016/j.enbuild.2012.11.010
   Chen H, 2016, APPL ENERG, V184, P820, DOI 10.1016/j.apenergy.2015.10.185
   CNERIB, 1997, DTRC32 REGL THERM BA, V0, P0
   de Santoli L, 2019, SUSTAIN CITIES SOC, V46, P0, DOI 10.1016/j.scs.2018.12.041
   Delmastro C, 2016, ENERG POLICY, V99, P42, DOI 10.1016/j.enpol.2016.09.051
   Dujardin S, 2014, ENERG BUILDINGS, V68, P779, DOI 10.1016/j.enbuild.2012.10.059
   Evola G, 2016, ENRGY PROCED, V101, P137, DOI 10.1016/j.egypro.2016.11.018
   Fichera A, 2016, CITIES, V55, P49, DOI 10.1016/j.cities.2016.03.011
   Fonseca JA, 2015, APPL ENERG, V142, P247, DOI 10.1016/j.apenergy.2014.12.068
   Foucquier A, 2013, RENEW SUST ENERG REV, V23, P272, DOI 10.1016/j.rser.2013.03.004
   Fracastoro GV, 2011, ENERG BUILDINGS, V43, P844, DOI 10.1016/j.enbuild.2010.12.004
   Fumo N, 2015, RENEW SUST ENERG REV, V47, P332, DOI 10.1016/j.rser.2015.03.035
   Gassar AAA, 2019, ENERGY, V187, P0, DOI 10.1016/j.energy.2019.115973
   Ghedamsi R, 2016, ENERG BUILDINGS, V121, P309, DOI 10.1016/j.enbuild.2015.12.030
   Gianniou P, 2018, ENERG CONVERS MANAGE, V165, P840, DOI 10.1016/j.enconman.2018.03.015
   Groppi D, 2018, SUSTAIN CITIES SOC, V40, P546, DOI 10.1016/j.scs.2018.05.005
   Howard B, 2012, ENERG BUILDINGS, V45, P141, DOI 10.1016/j.enbuild.2011.10.061
   Hsu D, 2015, ENERGY, V83, P144, DOI 10.1016/j.energy.2015.02.008
   Huo TF, 2018, J CLEAN PROD, V185, P665, DOI 10.1016/j.jclepro.2018.02.283
   Husson F., 2017, EXPLORATORY MULTIVAR, V0, P0, DOI DOI 10.1201/B10345
   IEA, 2020, KEY WORLD ENERGY STA, V0, P81
   Iraganaboina NC, 2021, ENERG BUILDINGS, V240, P0, DOI 10.1016/j.enbuild.2021.110934
   Jones RV, 2015, RENEW SUST ENERG REV, V43, P901, DOI 10.1016/j.rser.2014.11.084
   Kateb K., 2003, ESPACE GEOGR, V4, P311, DOI 10.3917/eg.324.0311
   Kavousian A, 2013, ENERGY, V55, P184, DOI 10.1016/j.energy.2013.03.086
   Kim YJ, 2020, ENERG BUILDINGS, V223, P0, DOI 10.1016/j.enbuild.2020.110226
   Mastrucci A, 2014, ENERG BUILDINGS, V75, P358, DOI 10.1016/j.enbuild.2014.02.032
   Mata E, 2021, ENVIRON RES LETT, V16, P0, DOI 10.1088/1748-9326/abe5d7
   Mattinen MK, 2014, J CLEAN PROD, V81, P70, DOI 10.1016/j.jclepro.2014.05.054
   Minist`ere de lEnergie, 2014, BIL REAL SEC EN MIN, V0, P0
   Ministere de lEnergie, 2020, BIL EN NAT ANN 2019, V0, P0
   Mora D, 2018, ENERG EFFIC, V11, P121, DOI 10.1007/s12053-017-9553-0
   Nouvel R, 2015, ENERG BUILDINGS, V107, P204, DOI 10.1016/j.enbuild.2015.08.021
   ONS, 2018, DEM ALG ER 2008, V0, P32
   ONS, 2020, DEM ALG 2018, V0, P0
   Osterbring M, 2016, ENERG BUILDINGS, V120, P78, DOI 10.1016/j.enbuild.2016.03.060
   QGIS Development Team,, 2018, QGIS 316, V0, P0
   Nishimwe AMR, 2021, RENEW SUST ENERG REV, V135, P0, DOI 10.1016/j.rser.2020.110170
   Reiter S, 2012, J IND ECOL, V16, P829, DOI 10.1111/j.1530-9290.2012.00533.x
   Rhodes JD, 2014, APPL ENERG, V135, P461, DOI 10.1016/j.apenergy.2014.08.111
   Sachs J, 2019, APPL ENERG, V250, P48, DOI 10.1016/j.apenergy.2019.05.011
   Salari M, 2016, ENERG POLICY, V98, P637, DOI 10.1016/j.enpol.2016.09.041
   Sepehr M, 2018, SUSTAIN CITIES SOC, V41, P481, DOI 10.1016/j.scs.2018.05.041
   Streimikiene D, 2014, RENEW SUST ENERG REV, V35, P285, DOI 10.1016/j.rser.2014.04.012
   Swan LG, 2009, RENEW SUST ENERG REV, V13, P1819, DOI 10.1016/j.rser.2008.09.033
   Theodoridou I, 2011, ENERG BUILDINGS, V43, P2422, DOI 10.1016/j.enbuild.2011.05.034
   Torabi Moghadam S, 2018, SUSTAIN CITIES SOC, V37, P70, DOI 10.1016/j.scs.2017.10.002
   Torabi Moghadam S, 2017, J CLEAN PROD, V165, P811, DOI 10.1016/j.jclepro.2017.07.142
   Tso GKF, 2014, ENERGY, V66, P722, DOI 10.1016/j.energy.2014.01.056
   Walter T, 2016, APPL ENERG, V179, P996, DOI 10.1016/j.apenergy.2016.07.087
   Wang YS, 2020, J CLEAN PROD, V251, P0, DOI 10.1016/j.jclepro.2019.119637
   Williams KT, 2016, ENERG BUILDINGS, V128, P1, DOI 10.1016/j.enbuild.2016.06.076
   Zhu D, 2013, APPL ENERG, V106, P17, DOI 10.1016/j.apenergy.2013.01.040
NR 69
TC 5
Z9 5
U1 2
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2210-6707
EI 2210-6715
J9 SUSTAIN CITIES SOC
JI Sust. Cities Soc.
PD NOV 15
PY 2021
VL 74
IS 
BP 
EP 
DI 10.1016/j.scs.2021.103191
EA AUG 2021
PG 16
WC Construction & Building Technology; Green & Sustainable Science & Technology; Energy & Fuels
SC Construction & Building Technology; Science & Technology - Other Topics; Energy & Fuels
GA WP5BO
UT WOS:000713147200009
DA 2023-04-26
ER

PT J
AU Liu, S
   Tang, JL
AF Liu, Shuai
   Tang, Jialan
TI Modified Deep Reinforcement Learning with Efficient Convolution Feature for Small Target Detection in VHR Remote Sensing Imagery
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE deep reinforcement learning; attention networks; object detection; VHR remote sensing image
ID object detection
AB Small object detection in very-high-resolution (VHR) optical remote sensing images is a fundamental but challenaging problem due to the latent complexities. To tackle this problem, the MdrlEcf model is proposed by modifying deep reinforcement learning (DRL) and extracting the efficient convolution feature. Firstly, an efficient attention network is constructed by introducing the local attention into the convolutional neural network. Combining the shallow low-level features with rich detail descriptions and high-level features with more semantic meanings effectively, efficient convolution features can be obtained. By this, the attention network can effectively enhance the ability to extract small target features and suppressing useless features. Secondly, the efficient feature map is sent to the region proposal network constructed by modified DRL. Using the modified reward function, this model can accumulate more rewards to conduct the search process, and potentially generate effective subsequent proposals and classification scores. It also can increase the effectiveness of object locations and classifications for small targets. Quantitative and qualitative experiments are conducted to verify the detection performance of different models. The results show that the proposed MdrlEcf can effectively and accurately locate and identify related small objects.
C1 [Liu, Shuai; Tang, Jialan] Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, S (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Peoples R China.
EM sh_liu@mail.xjtu.edu.cn; jialanT@stu.xjtu.edu.cn
FU National Natural Science Foundation of China [61703328]; China Postdoctoral Science Foundation-funded project [2018M631165]; Shaanxi Province Postdoctoral Science Foundation [2018BSHYDZZ23]; Fundamental Research Funds for the Central Universities [XJJ2018253]
CR Agarwal S., 2018, INT ROADMAP DEVICES, V0, P0
   Al WA, 2020, IEEE T MED IMAGING, V39, P1245, DOI 10.1109/TMI.2019.2946345
   Bosquet B, 2020, ENG APPL ARTIF INTEL, V91, P0, DOI 10.1016/j.engappai.2020.103615
   Caicedo JC, 2015, IEEE I CONF COMP VIS, V0, PP2488, DOI 10.1109/ICCV.2015.286
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003
   Dong RC, 2019, IEEE T GEOSCI REMOTE, V57, P8534, DOI 10.1109/TGRS.2019.2921396
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   Hu DC, 2020, ADV INTELL SYST COMP, V1038, P432, DOI 10.1007/978-3-030-29513-4_31
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Kong XY, 2017, PROC CVPR IEEE, V0, PP7072, DOI 10.1109/CVPR.2017.748
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2020, IEEE T NEUR NET LEAR, V31, P2544, DOI 10.1109/TNNLS.2019.2933451
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Mnih V, 2014, ADV NEUR IN, V27, P0
   Pang JM, 2019, PROC CVPR IEEE, V0, PP821, DOI 10.1109/CVPR.2019.00091
   Pirinen A, 2018, PROC CVPR IEEE, V0, PP6945, DOI 10.1109/CVPR.2018.00726
   Qilong Wang, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP11531, DOI 10.1109/CVPR42600.2020.01155
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Shan CH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P4764
   Sharma V, 2020, COMPUT SCI REV, V38, P0, DOI 10.1016/j.cosrev.2020.100301
   Shuojin Yang, 2020, PATTERN RECOGNITION AND COMPUTER VISION. THIRD CHINESE CONFERENCE, V0, P469, DOI 10.1007/978-3-030-60633-6_39
   Sun C, 2021, APPL INTELL, V51, P3311, DOI 10.1007/s10489-020-01949-0
   Tian Z, 2019, IEEE I CONF COMP VIS, V0, PP9626, DOI 10.1109/ICCV.2019.00972
   Tong K, 2020, IMAGE VISION COMPUT, V97, P0, DOI 10.1016/j.imavis.2020.103910
   Torres J., 2016, P C NEUR INF PROC SY, V0, P0
   Uzkent B, 2020, IEEE WINT CONF APPL, V0, PP1813, DOI 10.1109/WACV45572.2020.9093447
   Wang YY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070765
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Yao QL, 2021, IEEE GEOSCI REMOTE S, V18, P23, DOI 10.1109/LGRS.2020.2967819
   Zhou XY, 2019, PROC CVPR IEEE, V0, PP850, DOI 10.1109/CVPR.2019.00094
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
NR 40
TC 6
Z9 6
U1 4
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD MAR 15
PY 2021
VL 10
IS 3
BP 
EP 
DI 10.3390/ijgi10030170
PG 15
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RD8ET
UT WOS:000633704600001
DA 2023-04-26
ER

PT J
AU Liao, JJ
   Piao, YC
   Su, JH
   Cai, GR
   Huang, XW
   Chen, L
   Huang, ZH
   Wu, YD
AF Liao, Jiajia
   Piao, Yingchao
   Su, Jinhe
   Cai, Guorong
   Huang, Xingwang
   Chen, Long
   Huang, Zhaohong
   Wu, Yundong
TI Unsupervised Cluster Guided Object Detection in Aerial Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Detectors; Feature extraction; Licenses; Proposals; Image resolution; Convolution; Task analysis; Aerial image; convolutional neural networks (CNNs); deep learning; object detection; unmanned aerial vehicles
AB Object detection from high-resolution aerial images has received increasing attention during the last few years. It is a common practice to downsize images before feeding them into a network. In real life, there are lots of scenes where many objects gather together in certain areas, such as crossroads, parking lots, and playgrounds. The downsizing operation significantly limits the detection ability in these scenes. In this article, we proposed an unsupervised cluster guided detection framework (UCGNet) to address these issues by guiding the detector focus on the object-densely distributed area. In particular, a local location module is first applied to predict a binary map presenting how objects distribute in terms of the pixel of the map. Then, an unsupervised cluster method is used to produce dense regions. Each adjusted dense region is fed into the detector for object detection. Finally, a global merge module generates the final predict results. Experiments were conducted on two popular aerial image datasets including VisDrone2019 and UAVDT. In both datasets, our proposed method outperforms the existing baseline methods with achieving 32.8% and 19.1% mAP, respectively.
C1 [Liao, Jiajia; Su, Jinhe; Cai, Guorong; Huang, Xingwang; Chen, Long; Huang, Zhaohong; Wu, Yundong] Jimei Univ, Sch Comp Engn, Xiamen 361021, Peoples R China.
   [Piao, Yingchao] Chinese Acad Sci, Comp Network Informat Ctr, Beijing 100049, Peoples R China.
C3 Jimei University; Chinese Academy of Sciences; Computer Network Information Center, CAS
RP Su, JH; Wu, YD (corresponding author), Jimei Univ, Sch Comp Engn, Xiamen 361021, Peoples R China.
EM jiajialiao@jmu.edu.cn; pyc@cnic.cn; sujh@jmu.edu.cn; guorongcai.jmu@gmail.com; huangxw@jmu.edu.cn; sjhxmu@qq.com; jmuhzh@126.com; yundongwu@jmu.edu.cn
FU National Natural Science Foundation of China [41971424, 61701191]; Natural Science Foundation of Fujian Province, China [2020J01701, 2020J01699]; Fujian Provincial Science and Technology Program Project [JAT190320]
CR Bochkovskiy A, 2020, PREPRINT, V0, P0
   Cai YQ, 2020, MM 20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP709, DOI 10.1145/3394171.3413816
   Chen CR, 2019, IEEE INT CONF COMP V, V0, PP100, DOI 10.1109/ICCVW.2019.00018
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Chennamsetty S. S, 2019, ARXIV08244, V0, P0
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), V0, PP1796, DOI 10.1109/ICIT.2016.7475036
   Ding J, 2019, PROC CVPR IEEE, V0, PP2844, DOI 10.1109/CVPR.2019.00296
   Du DW, 2019, IEEE INT CONF COMP V, V0, PP213, DOI 10.1109/ICCVW.2019.00030
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Ester M, 1996, P 2 INT C KNOWL DISC, V96, P226
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Jadhav A., 2020, 2020 NAT C COMM NCC, V0, P1
   Jiang YY, 2018, INT C PATT RECOG, V0, P3610
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Kong T, 2017, PROC CVPR IEEE, V0, PP5244, DOI 10.1109/CVPR.2017.557
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li CL, 2020, IEEE COMPUT SOC CONF, V0, PP737, DOI 10.1109/CVPRW50498.2020.00103
   Li YH, 2019, IEEE I CONF COMP VIS, V0, PP6053, DOI 10.1109/ICCV.2019.00615
   Li Z., 2017, ARXIV171107264, V0, P0
   Li Zeming, 2018, ARXIV180406215, V0, P0
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Qi CR, 2017, ADV NEUR IN, V30, P0
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Van Etten A., 2018, YOU ONLY LOOK TWICE, V0, P0
   Wang ZW, 2020, PROC CVPR IEEE, V0, PP2046, DOI 10.1109/CVPR42600.2020.00212
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Xu YC, 2021, IEEE T PATTERN ANAL, V43, P1452, DOI 10.1109/TPAMI.2020.2974745
   Yang, 1900, V2020, V0, P0
   Yang F, 2019, IEEE I CONF COMP VIS, V0, PP8310, DOI 10.1109/ICCV.2019.00840
   Yang X, 2019, IEEE I CONF COMP VIS, V0, PP8231, DOI 10.1109/ICCV.2019.00832
   YU F, 2017, PROC CVPR IEEE, V0, PP636, DOI 10.1109/CVPR.2017.75
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, V0, P9259
   Zhaowei Cai, 2018, 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION. PROCEEDINGS, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Zhou X, 2019, PSYCHOL HEALTH, V34, P811, DOI 10.1080/08870446.2019.1574348
   Ziyang Tang, 2020, 2020 19TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP392, DOI 10.1109/ICMLA51294.2020.00069
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
NR 44
TC 4
Z9 4
U1 4
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11204
EP 11216
DI 10.1109/JSTARS.2021.3122152
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WY8YM
UT WOS:000719563200001
DA 2023-04-26
ER

PT J
AU Maepa, F
   Smith, RS
   Tessema, A
AF Maepa, Francisca
   Smith, Richard S.
   Tessema, Abera
TI Support vector machine and artificial neural network modelling of orogenic gold prospectivity mapping in the Swayze greenstone belt, Ontario, Canada
SO ORE GEOLOGY REVIEWS
LA English
DT Article
DE Mineral systems analysis; Mineral prospectivity mapping; Orogenic gold systems; Machine learning; Feature importance; K-Fold cross-validation
ID geographic information-systems; metamorphic devolatilization; abitibi subprovince; superior province; exploration; deposits; fluid; rocks; mineralization; insights
AB Exploration for new mineral deposits has become increasingly difficult as new discoveries are being found under progressively deeper cover. To better understand and predict orogenic gold mineralization in the Archean Swayze greenstone belt, the essential ingredients of a mineral system are considered: 1) the source of gold and transport fluid ligands, 2) fluid pathways, 3) traps, and 4) the processes responsible for gold precipitation. The aim of this study is to use a mineral systems approach to help generate exploration targeting models using a spatial statistical method weights of evidence (WofE) and data-driven machine learning tools, namely radial basis function neural networks (RBFNN) and support vector machine (SVM). The mineral prospectivity maps generated using the RBFNN and SVM machine learning methods were trained using the K-Fold cross-validation approach whereby 10 subsets of the data were used to train and test the model performance. The mean area under receiver operator curve after 10-fold cross-validations were 91% and 94% for the RBFNN models, and the SVM models obtained accuracies of 91% and 87%. Feature importance estimations obtained from both methods indicate that D-2 and D-3 high-strain zones, lithological contacts and D-2 folds (i.e., synclines and anticlines) were found to be important predictor layers for targeting potential prospective zones of gold mineralization. The machine learning algorithms used in this study are novel and pragmatic methods that use the full potential of geoscience datasets in mapping orogenic gold prospectivity.
C1 [Maepa, Francisca; Smith, Richard S.] Laurentian Univ, Sudbury, ON, Canada.
   [Tessema, Abera] Univ Limpopo, Polokwane, South Africa.
C3 Laurentian University; University of Limpopo
RP Maepa, F (corresponding author), Laurentian Univ, Harquail Sch Earth Sci, 935 Ramsey Lake Rd, Sudbury, ON P3E 2C6, Canada.
EM fmaepa@laurentian.ca
FU International Development Research Centre (IDRC), Canada; Queen Elizabeth II Diamond Jubilee Scholarships, Canada; Ivanhoe Mines, South Africa; Goodman School of Mines, Canada
CR Abedi M, 2012, COMPUT GEOSCI-UK, V46, P272, DOI 10.1016/j.cageo.2011.12.014
   Agterberg F.P., 1969, J INT ASS MATH GEOSC, VI, P138
   AGTERBERG FP, 1989, APPL COMP O, V0, P165
   AGTERBERG FP, 1990, COMPUT GEOL, V7, P1
   Andina D., 2008, COMPUTATIONAL INTELL, V0, P212
   [Anonymous], 1994, P 19 ANN SAS USERS G, V0, P0
   Archibald N.J., 1999, EXPLOR GEOPHYS, V30, P38, DOI 10.1071/EG999038
   Ayer J, 2002, PRECAMBRIAN RES, V115, P63, DOI 10.1016/S0301-9268(02)00006-2
   Ayer J., 1995, 297 OP FIL REP, V0, P57
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Bierlein FP, 2006, MINER DEPOSITA, V40, P874, DOI 10.1007/s00126-005-0046-2
   Bonham-Carter G., 1989, STAT APPL EARTH SCI, V89-9, P171
   Bonham-Carter G. F., 1994, GEOGRAPHIC INFORM SY, V0, P416
   BONHAMCARTER GF, 1988, PHOTOGRAMM ENG REM S, V54, P1585
   Breemen O.V., 2006, NAT RESOUR RES, V32, P0, DOI 10.4095/223016
   Broomhead D. S., 1988, COMPLEX SYSTEMS, V2, P321
   Calvert AJ, 1999, TECTONICS, V18, P412, DOI 10.1029/1999TC900006
   Carranza E.J.M., 2004, NAT RESOUR RES, V13, P173, DOI 10.1023/B:NARR.0000046919.87758.F5
   Carranza E.J.M., 2009, GEOCHEMICAL ANOMALY, V0, P368
   Cheraghi S, 2020, GEOPHYS PROSPECT, V68, P62, DOI 10.1111/1365-2478.12854
   Cherkassky V, 1997, IEEE TRANS NEURAL NETW, V8, P1564, DOI 10.1109/TNN.1997.641482
   CONDIE KC, 1986, J GEOL, V94, P845, DOI 10.1086/629091
   Connolly JAD, 2010, ELEMENTS, V6, P165, DOI 10.2113/gselements.6.3.165
   Cox SF, 2016, ECON GEOL, V111, P559, DOI 10.2113/econgeo.111.3.559
   Davies RS, 2020, ORE GEOL REV, V119, P0, DOI 10.1016/j.oregeorev.2020.103369
   Davis J.C., 2002, STAT DATA ANAL GEOLO, V0, P656
   de Sa CR, 2019, LECT NOTES ARTIF INT, V11828, P306, DOI 10.1007/978-3-030-33778-0_24
   Ford A, 2019, ORE GEOL REV, V111, P0, DOI 10.1016/j.oregeorev.2019.102943
   Fumerton S., 1995, 5912 OP FIL REP, V1, P372
   FYFE WS, 1976, J GEOCHEM EXPLOR, V6, P177, DOI 10.1016/0375-6742(76)90013-3
   Gaboury D, 2019, APPL EARTH SCI, V128, P124, DOI 10.1080/25726838.2019.1583310
   Gao Q, 2008, CJCM: 5TH CHINA-JAPAN CONFERENCE ON MECHATRONICS 2008, V0, P53
   Goldfarb RJ, 2015, LITHOS, V233, P2, DOI 10.1016/j.lithos.2015.07.011
   Goldfarb RJ, 2001, ORE GEOL REV, V18, P1, DOI 10.1016/S0169-1368(01)00016-6
   Groves DI, 2020, GEOSCI FRONT, V11, P719, DOI 10.1016/j.gsf.2019.12.007
   Groves DI, 2016, GEOSCI FRONT, V7, P303, DOI 10.1016/j.gsf.2015.07.001
   Groves DI, 2005, ECON GEOL, V100, P203, DOI 10.2113/100.2.203
   Groves DI, 1998, ORE GEOL REV, V13, P7, DOI 10.1016/S0169-1368(97)00012-7
   GRUNSKY EC, 1986, J GEOCHEM EXPLOR, V25, P157, DOI 10.1016/0375-6742(86)90012-9
   Grunsky EC, 2010, GEOCHEM-EXPLOR ENV A, V10, P27, DOI 10.1144/1467-7873/09-210
   Hagemann SG, 2016, ORE GEOL REV, V76, P504, DOI 10.1016/j.oregeorev.2015.12.012
   Hagemann S.G., 2000, REV EC GEOLOGY, V13, P9
   HANNA SS, 1979, J STRUCT GEOL, V1, P155, DOI 10.1016/0191-8141(79)90052-X
   Harris J.R., 2002, THESIS, V0, P0
   Harris J.R., 2001, APPL GIS PROCESSING, V0, P91
   Harris JR, 2000, ORE GEOL REV, V16, P107, DOI 10.1016/S0169-1368(99)00027-X
   Hastie E.C.G., 2017, 6334 ONT GEOL SURV, V0, P0
   Hastie E.C.G., 2015, 6280 ONT GEOL SURV, V0, P0
   Hastie ECG, 2020, ECON GEOL, V115, P241, DOI 10.5382/econgeo.4709
   Heather K., 2001, THESIS, V0, P0
   Heather K.B., 1998, 1 AGE GIANT ORE FORM, V0, P63
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   Ikechukwu M. N., 2017, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V9, P354, DOI 10.4236/jgis.2017.93022
   Jollife I.T., 2002, PRINCIPAL COMPONENTS, V0, P271
   Katz L.R., 2016, THESIS, V0, P347
   Katz LR, 2017, CAN J EARTH SCI, V54, P173, DOI 10.1139/cjes-2016-0007
   Kavzoglu T, 2009, INT J APPL EARTH OBS, V11, P352, DOI 10.1016/j.jag.2009.06.002
   Kecma V., 2005, SUPPORT VECTOR MACHI, V0, P1
   KERRICH R, 1986, PURE APPL GEOPHYS, V124, P225, DOI 10.1007/BF00875727
   Kerrich R., 2000, REV EC GEOL, V13, P501, DOI 10.5382/Rev.13.15
   Kerrich R., 1991, GREENSTONE GOLD CRUS, V0, P13
   KnoxRobinson CM, 1997, AUST J EARTH SCI, V44, P453, DOI 10.1080/08120099708728326
   Kreuzer OP, 2007, ORE GEOL REV, V32, P37, DOI 10.1016/j.oregeorev.2006.12.001
   Kreuzer O.P., 2019, QUEBEC ORE GEOL REV, V111, P1
   Kubat M., 2017, INTRO MACHINE LEARNI, V0, P0, DOI DOI 10.1007/978-3-319-63913-0
   Lambeck A, 2011, ECON GEOL, V106, P321, DOI 10.2113/econgeo.106.3.321
   Large R, 2012, NEW ZEAL J GEOL GEOP, V55, P137, DOI 10.1080/00288306.2012.682282
   Looney CG, 2002, NEUROCOMPUTING, V48, P489, DOI 10.1016/S0925-2312(01)00613-0
   LOVE DA, 1991, ECON GEOL BULL SOC, V86, P644, DOI 10.2113/gsecongeo.86.3.644
   Maepa FM, 2020, ORE GEOL REV, V125, P0, DOI 10.1016/j.oregeorev.2020.103671
   MAGOON L B, 1994, PETROLEUM SYSTEM FRO, V0, P3
   Marmont S.C.A., 1983, 110 ONT GEOL SURV, V0, P0
   McCuaig TC, 2014, SOC ECON GEOL SPEC P, V0, P153
   McCuaig TC, 2010, ORE GEOL REV, V38, P128, DOI 10.1016/j.oregeorev.2010.05.008
   McCulloch W., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Nykanen V., 2008, NAT RES, V17, P29, DOI 10.1007/S11053-008-9062-0
   Nykanen V, 2015, ORE GEOL REV, V71, P853, DOI 10.1016/j.oregeorev.2014.09.007
   Obuchowski NA, 2003, RADIOLOGY, V229, P3, DOI 10.1148/radiol.2291010898
   Oliver M. A., 1990, INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SYSTEMS, V4, P313, DOI 10.1080/02693799008941549
   Ontario Geological Survey, 2003, ONTARIO AIRBORNE MAG, V0, P0
   Parsa M, 2018, J AFR EARTH SCI, V140, P189, DOI 10.1016/j.jafrearsci.2018.01.012
   Parsa M, 2018, ORE GEOL REV, V92, P97, DOI 10.1016/j.oregeorev.2017.11.013
   Parsa M, 2018, NAT RESOUR RES, V27, P15, DOI 10.1007/s11053-017-9351-6
   Parsa M, 2017, NAT RESOUR RES, V26, P443, DOI 10.1007/s11053-017-9346-3
   Parsa M, 2017, J AFR EARTH SCI, V128, P5, DOI 10.1016/j.jafrearsci.2016.11.021
   Parsa M, 2017, INT J APPL EARTH OBS, V58, P157, DOI 10.1016/j.jag.2017.02.006
   Phillips GN, 2010, J METAMORPH GEOL, V28, P689, DOI 10.1111/j.1525-1314.2010.00887.x
   Pirajno W., 2008, HYDROTHERMAL PROCESS, V0, P0
   Pitcairn IK, 2006, ECON GEOL, V101, P1525, DOI 10.2113/gsecongeo.101.8.1525
   Porwal A., 2003, W INDIA NATURAL RESO, V12, P155, DOI 10.1023/A:1025171803637
   Porwal AK, 2010, ORE GEOL REV, V38, P121, DOI 10.1016/j.oregeorev.2010.06.002
   POWELL WG, 1995, CAN J EARTH SCI, V32, P787, DOI 10.1139/e95-067
   Ridley J.R., 2000, REV EC GEOL, V13, P141
   Robb L., 2005, INTRO ORE FORMING PR, V0, P0, DOI DOI 10.2138/am.2005.426
   ROBERT F, 1989, CAN J EARTH SCI, V26, P2661, DOI 10.1139/e89-226
   Robert F, 2001, MINER DEPOSITA, V36, P503, DOI 10.1007/s001260100186
   Robert F, 2005, EC GEOLOGY 100 ANNIV, V100, P1001
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Roshanravan B, 2020, ORE GEOL REV, V125, P0, DOI 10.1016/j.oregeorev.2020.103661
   Sawatzky D., 2010, SPATIAL DATA MODELLE, V0, P0
   Schodde R., 2014, ABSTRACT RIMFIRE PAC, V0, P1
   Schodde R., 2017, 8 FENN EXPL MIN C LE, V0, P1
   Schodde R. C., 2004, PACR 2004 P, V0, P0
   SIBSON RH, 1988, GEOLOGY, V16, P551, DOI 10.1130/0091-7613(1988)016<0551:HARFFP>2.3.CO;2
   Smith RS, 2000, GEOPHYSICS, V65, P1124, DOI 10.1190/1.1444805
   SPITZ G, 1978, CAN J EARTH SCI, V15, P1161, DOI 10.1139/e78-122
   Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2
   Tessema A, 2017, NAT RESOUR RES, V26, P465, DOI 10.1007/s11053-017-9344-5
   Thomas HV, 2011, ECON GEOL, V106, P1, DOI 10.2113/econgeo.106.1.1
   Thurston PC, 2002, PRECAMBRIAN RES, V115, P11, DOI 10.1016/S0301-9268(02)00004-9
   Tomkins AG, 2013, GEOLOGY, V41, P1255, DOI 10.1130/focus122013.1
   Vaughan C., 1988, P USGS SPONS AEM WOR, V0, P0
   Vearncombe J, 1999, ECON GEOL BULL SOC, V94, P475, DOI 10.2113/gsecongeo.94.4.475
   Vearncombe J, 2015, T I MIN METALL B, V124, P2, DOI 10.1179/1743275815Y.0000000003
   Wagner T, 2016, ELEMENTS, V12, P323, DOI 10.2113/gselements.12.5.323
   WYBORN LAI, 1994, AUSTRALAS I MIN MET, V94, P109
   Wyman DA, 2016, ORE GEOL REV, V78, P322, DOI 10.1016/j.oregeorev.2016.04.006
   Xue YX, 2013, GEOLOGY, V41, P791, DOI 10.1130/G34186.1
   Yousefi M, 2019, ORE GEOL REV, V111, P0, DOI 10.1016/j.oregeorev.2019.103005
   Zhong R, 2015, GEOCHIM COSMOCHIM AC, V171, P338, DOI 10.1016/j.gca.2015.09.013
   Zuo RG, 2011, COMPUT GEOSCI-UK, V37, P1967, DOI 10.1016/j.cageo.2010.09.014
NR 121
TC 22
Z9 22
U1 6
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-1368
EI 1872-7360
J9 ORE GEOL REV
JI Ore Geol. Rev.
PD MAR 15
PY 2021
VL 130
IS 
BP 
EP 
DI 10.1016/j.oregeorev.2020.103968
EA JAN 2021
PG 27
WC Geology; Mineralogy; Mining & Mineral Processing
SC Geology; Mineralogy; Mining & Mineral Processing
GA PZ5UA
UT WOS:000612804100002
DA 2023-04-26
ER

PT J
AU Bazame, HC
   Molin, JP
   Althoff, D
   Martello, M
AF Bazame, Helizani Couto
   Molin, Jose Paulo
   Althoff, Daniel
   Martello, Mauricio
TI Detection, classification, and mapping of coffee fruits during harvest with computer vision
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
LA English
DT Article
DE Precision agriculture; Convolutional neural networks; YOLO; Deep learning
ID spatial variability; system; recognition
AB In this study, an algorithm is implemented with a computer vision model to detect and classify coffee fruits and map the fruits maturation stage during harvest. The main contribution of this study is with respect to the assignment of geographic coordinates to each frame, which enables the mapping of detection summaries across coffee rows. The model used to detect and classify coffee fruits was implemented using the Darknet, an open source framework for neural networks written in C. The coffee fruits detection and classification were performed using the object detection system named YOLOv3-tiny. For this study, 90 videos were recorded at the end of the discharge conveyor of a coffee harvester during the 2020 harvest of arabica coffee (Catuai 144) at a commercial area in the region of Patos de Minas, in the state of Minas Gerais, Brazil. The model performance peaked around the similar to 3300th iteration when considering an image input resolution of 800 x 800 pixels. The model presented an mAP of 84%, F1-Score of 82%, precision of 83%, and recall of 82% for the validation set. The average precision for the classes of unripe, ripe, and overripe coffee fruits was 86%, 85%, and 80%, respectively. As the algorithm enabled the detection and classification in videos collected during the harvest, it was possible to map the qualitative attributes regarding the coffee maturation stage along the crop lines. These attribute maps provide managers important spatial information for the application of precision agriculture techniques in crop management. Additionally, this study should incentive future research to customize the deep learning model for certain tasks in agriculture and precision agriculture.
C1 [Bazame, Helizani Couto; Molin, Jose Paulo; Martello, Mauricio] Univ Sao Paulo ESALQ USP, Luiz de Queiroz Coll Agr, Biosyst Engn Dept, Piracicaba, SP, Brazil.
   [Althoff, Daniel] Fed Univ Vicosa UFV, Agr Engn Dept, Vicosa, MG, Brazil.
C3 Universidade de Sao Paulo; Universidade Federal de Vicosa
RP Bazame, HC (corresponding author), Univ Sao Paulo ESALQ USP, Luiz de Queiroz Coll Agr, Biosyst Engn Dept, Piracicaba, SP, Brazil.
EM helizanicouto@usp.br; jpmolin@usp.br; daniel.althoff@ufv.br; mauriciomartello@usp.br
FU Terrena Agronegocios; Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - (CAPES) [001]
CR Avendano J, 2017, EXPERT SYST APPL, V88, P178, DOI 10.1016/j.eswa.2017.06.044
   Baluja J, 2013, PRECIS AGRIC, V14, P40, DOI 10.1007/s11119-012-9282-5
   Belan P.A., 2012, EXACTA, V10, P0, DOI 10.5585/exacta.v10n1.3091
   Bochkovskiy A., 2019, YOLO MARK WINDOWS LI, V0, P0
   Bresilla K, 2019, FRONT PLANT SCI, V10, P0, DOI 10.3389/fpls.2019.00611
   Dalvi L.P., 2013, REV AGRARIAN 410 QUA, V0, P410
   de Oliveira EM, 2016, J FOOD ENG, V171, P22, DOI 10.1016/j.jfoodeng.2015.10.009
   Donizetti A., 2011, QUALIDADE CAFE COLHI, V0, P0
   Ferraz MN, 2019, ENG AGR-JABOTICABAL, V39, P109, DOI 10.1590/1809-4430-eng.agric.v39nep109-117/2019
   Hani N, 2018, IEEE INT C INT ROBOT, V0, PP2559, DOI 10.1109/IROS.2018.8594304
   Kazama EH, 2021, PRECIS AGRIC, V22, P711, DOI 10.1007/s11119-020-09751-1
   Koirala A, 2019, PRECIS AGRIC, V20, P1107, DOI 10.1007/s11119-019-09642-0
   Koirala A, 2020, AGRONOMY-BASEL, V10, P0, DOI 10.3390/agronomy10010143
   Laderach P, 2011, FIELD CROP RES, V120, P321, DOI 10.1016/j.fcr.2010.10.006
   Leme DS, 2019, COMPUT ELECTRON AGR, V156, P312, DOI 10.1016/j.compag.2018.11.029
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu GX, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20072145
   Matiello Santinato, 2015, CULTURA CAFE NO BRAS, V1a. ed, P0
   Mazen FMA, 2019, ARAB J SCI ENG, V44, P6901, DOI 10.1007/s13369-018-03695-5
   Mazzia V, 2020, IEEE ACCESS, V8, P9102, DOI 10.1109/ACCESS.2020.2964608
   Mesquita C.M. de, 2008, MANUAL CAF COLHEITA, V0, P0
   Molin JP, 2010, ACTA SCI-AGRON, V32, P569, DOI 10.4025/actasciagron.v32i4.5282
   Olson D.L., 2008, ADV DATA MINING TECH, V0, P0, DOI DOI 10.1007/978-3-540-76917
   Pimenta CJ, 2018, CIENC AGROTEC, V42, P337, DOI 10.1590/1413-70542018424000118
   Ramos PJ, 2017, COMPUT ELECTRON AGR, V137, P9, DOI 10.1016/j.compag.2017.03.010
   Ramos PJ, 2018, COMPUT IND, V99, P83, DOI 10.1016/j.compind.2018.03.024
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Roy P, 2019, COMPUT ELECTRON AGR, V164, P0, DOI 10.1016/j.compag.2019.104897
   Sa I, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16081222
   Santinato R., 2014, ANALISE QUALIQUANTIT, V0, P0
   Santos FL, 2015, ACTA SCI-TECHNOL, V37, P11, DOI 10.4025/actascitechnol.v37i1.19814
   Sartori S, 2001, PROCEEDINGS OF THE WORLD CONGRESS OF COMPUTERS IN AGRICULTURE AND NATURAL RESOURCES, V0, P196
   Song Y, 2014, BIOSYST ENG, V118, P203, DOI 10.1016/j.biosystemseng.2013.12.008
   Tu SQ, 2020, PRECIS AGRIC, V21, P1072, DOI 10.1007/s11119-020-09709-3
   Velloso NS, 2020, COMPUT ELECTRON AGR, V175, P0, DOI 10.1016/j.compag.2020.105552
   Wang ZL, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19122742
   Wu D, 2013, TRENDS FOOD SCI TECH, V29, P5, DOI 10.1016/j.tifs.2012.08.004
   Yu Y, 2019, COMPUT ELECTRON AGR, V163, P0, DOI 10.1016/j.compag.2019.06.001
NR 40
TC 23
Z9 23
U1 3
U2 44
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0168-1699
EI 1872-7107
J9 COMPUT ELECTRON AGR
JI Comput. Electron. Agric.
PD APR 15
PY 2021
VL 183
IS 
BP 
EP 
DI 10.1016/j.compag.2021.106066
EA MAR 2021
PG 11
WC Agriculture, Multidisciplinary; Computer Science, Interdisciplinary Applications
SC Agriculture; Computer Science
GA RF5KN
UT WOS:000634877300005
DA 2023-04-26
ER

PT J
AU Tang, HK
   Wang, HL
   Zhang, XP
AF Tang, Huakang
   Wang, Honglei
   Zhang, Xiaoping
TI A Segmentation Map Difference-Based Domain Adaptive Change Detection Method
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Image segmentation; Remote sensing; Task analysis; Data mining; Deep learning; Neural networks; Change detection (CD); channel attention; domain adaptive; feature extraction; remote sensing
ID image; algorithms
AB Deep neural network (DNN) has been widely used in remote sensing image change detection (CD) in recent years. Due to the scarcity of training data, a large number of labeled data onto other fields become the source of DNN concept learning in remote sensing image CD. However, the distribution of features of the CD data and other data varies greatly, which prevents DNN from being better applied for one task to another. To solve this problem, a domain adaptive CD method based on segmentation map difference is proposed to this article, which includes the pretraining stage and the CD stage. In the pretraining stage, the domain adaptive UNet (Ada-UNet) is applied as the basic network of remote sensing image segmentation for network training with the purpose of learning the concepts of different features. In the CD stage, strict threshold segmentation results are used to train the channel attention network, which makes it more efficient to utilize the high-dimensional feature map. The probabilistic map generated by the three-channel attention networks is evaluated, and then it is used to accurately classify the changing pixels. In this article, experiments are carried out on datasets with different feature distributions. The results show that this method has strong domain adaptability and can greatly reduce the influence of the difference in feature distributions of the CD results.
C1 [Tang, Huakang; Wang, Honglei] Guizhou Univ, Sch Elect Engn, Guiyang 550025, Peoples R China.
   [Wang, Honglei] Key Lab Internet Collaborat Intelligent Mfg Guizh, Guiyang, Peoples R China.
   [Zhang, Xiaoping] Sci & Technol Dept Guizhou Prov, Guiyang 550000, Peoples R China.
C3 Guizhou University
RP Wang, HL (corresponding author), Guizhou Univ, Sch Elect Engn, Guiyang 550025, Peoples R China.
EM 18311744452@163.com; gzdxhlwang@163.com; 2215093175@qq.com
FU Science and Technology Cooperation Program of Guizhou Province underGrant (QKH) [[2016]5103]
CR Azorin-Lopez J, 2017, NEURAL COMPUT APPL, V28, PS439, DOI 10.1007/s00521-016-2346-0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   BHANU B, 1995, IEEE T SYST MAN CYB, V25, P1543, DOI 10.1109/21.478442
   BINMOHAMAD I, 2013, RES J APPL SCI ENG T, V6, P3299
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen Y, 2018, PROC CVPR IEEE, V0, PP3339, DOI 10.1109/CVPR.2018.00352
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cracknell MJ, 2014, COMPUT GEOSCI-UK, V63, P22, DOI 10.1016/j.cageo.2013.10.008
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Erturk A, 2017, IEEE J-STARS, V10, P321, DOI 10.1109/JSTARS.2016.2606514
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gulcehre Caglar, 2014, MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES. EUROPEAN CONFERENCE, V0, P530, DOI 10.1007/978-3-662-44848-9_34
   Hamel P, 2010, ISMIR, V10, P339, DOI 10.1109/ICALIP.2014.7009771
   Hegazy Ibrahim Rizk, 2015, INTERNATIONAL JOURNAL OF SUSTAINABLE BUILT ENVIRONMENT, V4, P117, DOI 10.1016/j.ijsbe.2015.02.005
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang Zilong, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, VPP, P0, DOI 10.1109/TPAMI.2020.3007032
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Johnson JM, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0192-5
   Li J, 2016, IJCAI, V0, P1697
   Li X, 2019, PROC CVPR IEEE, V0, PP510, DOI 10.1109/CVPR.2019.00060
   Li YH, 2018, PATTERN RECOGN, V80, P109, DOI 10.1016/j.patcog.2018.03.005
   Liu DS, 2008, REMOTE SENS ENVIRON, V112, P2222, DOI 10.1016/j.rse.2007.10.002
   Liu DN, 2021, IEEE T MED IMAGING, V40, P154, DOI 10.1109/TMI.2020.3023466
   Long MS, 2013, IEEE I CONF COMP VIS, V0, PP2200, DOI 10.1109/ICCV.2013.274
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Panboonyuen T, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010083
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Saito K, 2019, PROC CVPR IEEE, V0, PP6949, DOI 10.1109/CVPR.2019.00712
   Song A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111827
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stingo FC, 2013, J AM STAT ASSOC, V108, P876, DOI 10.1080/01621459.2013.804409
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Teney D, 2014, COMPUT VIS IMAGE UND, V125, P265, DOI 10.1016/j.cviu.2014.04.012
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Tong XY, 2018, INT GEOSCI REMOTE SE, V0, P3599
   Volpi M, 2015, 2015 JOINT URBAN REMOTE SENSING EVENT (JURSE), V0, P0
   Wan L, 2019, IEEE T GEOSCI REMOTE, V57, P9941, DOI 10.1109/TGRS.2019.2930322
   Wang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020276
   Wang ZH, 2017, APPL SOFT COMPUT, V61, P1113, DOI 10.1016/j.asoc.2017.02.035
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu X, 2021, ISPRS J PHOTOGRAMM, V174, P87, DOI 10.1016/j.isprsjprs.2021.01.023
   Xia Fen, 2008, P 25 INT C MACH LEAR, V0, PP1192, DOI 10.1145/1390156.1390306
   Xie J., 2016, 2016 IEEE INT C PROG, V0, PP1, DOI 10.1109/ICPHM.2016.7542845
   Xing C, 2016, J SENSORS, V2016, P0, DOI 10.1155/2016/3632943
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang L, 2020, IEEE T NEUR NET LEAR, V31, P3374, DOI 10.1109/TNNLS.2019.2944455
   Zhang XQ, 2020, COMPUT VIS IMAGE UND, V197, P0, DOI 10.1016/j.cviu.2020.103003
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang Z., 2018, ARXIV180709562, V0, P0
   Zhengzhou Li, 2022, IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, V19, P0, DOI 10.1109/LGRS.2020.3017542
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhou ZH, 2016, FRONT COMPUT SCI-CHI, V10, P589, DOI 10.1007/s11704-016-6906-3
NR 65
TC 0
Z9 0
U1 1
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9571
EP 9583
DI 10.1109/JSTARS.2021.3113327
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WC2SC
UT WOS:000704110600006
DA 2023-04-26
ER

PT J
AU Suel, E
   Bhatt, S
   Brauer, M
   Flaxman, S
   Ezzati, M
AF Suel, Esra
   Bhatt, Samir
   Brauer, Michael
   Flaxman, Seth
   Ezzati, Majid
TI Multimodal deep learning from satellite and street-level imagery for measuring income, overcrowding, and environmental deprivation in urban areas
SO REMOTE SENSING OF ENVIRONMENT
LA English
DT Article
DE Convolutional neural networks; Segmentation; Urban measurements; Satellite images; Street-level images
ID view; classification
AB Data collected at large scale and low cost (e.g. satellite and street level imagery) have the potential to substantially improve resolution, spatial coverage, and temporal frequency of measurement of urban inequalities. Multiple types of data from different sources are often available for a given geographic area. Yet, most studies utilize a single type of input data when making measurements due to methodological difficulties in their joint use. We propose two deep learning-based methods for jointly utilizing satellite and street level imagery for measuring urban inequalities. We use London as a case study for three selected outputs, each measured in decile classes: income, overcrowding, and environmental deprivation. We compare the performances of our proposed multimodal models to corresponding unimodal ones using mean absolute error (MAE). First, satellite tiles are appended to street level imagery to enhance predictions at locations where street images are available leading to improvements in accuracy by 20, 10, and 9% in units of decile classes for income, overcrowding, and living environment. The second approach, novel to the best of our knowledge, uses a U-Net architecture to make predictions for all grid cells in a city at high spatial resolution (e.g. for 3 m ? 3 m pixels in London in our experiments). It can utilize city wide availability of satellite images as well as more sparse information from street level images where they are available leading to improvements in accuracy by 6, 10, and 11%. We also show examples of prediction maps from both approaches to visually highlight performance differences.
C1 [Suel, Esra; Ezzati, Majid] Imperial Coll London, MRC Ctr Environm & Hlth, Sch Publ Hlth, London, England.
   [Suel, Esra] Swiss Fed Inst Technol, Swiss Data Sci Ctr, Zurich, Switzerland.
   [Suel, Esra] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
   [Bhatt, Samir] Imperial Coll London, MRC Ctr Global Infect Dis Anal, Sch Publ Hlth, London, England.
   [Bhatt, Samir] Univ Copenhagen, Dept Publ Hlth, Sect Epidemiol, Copenhagen, Denmark.
   [Ezzati, Majid] Imperial Coll London, Abdul Latif Jameel Inst Dis & Emergency Analyt, London, England.
   [Brauer, Michael] Univ British Columbia, Sch Populat & Publ Hlth, Vancouver, BC, Canada.
   [Brauer, Michael] Univ Washington, Inst Hlth Metr & Evaluat, Seattle, WA 98195 USA.
   [Flaxman, Seth] Imperial Coll London, Dept Math, London, England.
   [Ezzati, Majid] Univ Ghana, Reg Inst Populat Studies, Accra, Ghana.
C3 Imperial College London; Swiss Federal Institutes of Technology Domain; ETH Zurich; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Imperial College London; University of Copenhagen; Imperial College London; University of British Columbia; Institute for Health Metrics & Evaluation; University of Washington; University of Washington Seattle; Imperial College London; University of Ghana
RP Suel, E (corresponding author), Imperial Coll London, MRC Ctr Environm & Hlth, Sch Publ Hlth, London, England.
EM esra.suel@imperial.ac.uk
FU Health Data Research UK - UK Medical Research Council [MR/S003983/1]; Wellcome Trust [209376/Z/17/Z]; Imperial College COVID-19 Research Fund - UKRI [MR/V038109/1]; Academy of Medical Sciences [SBF004/1080]; UK Engineering and Physical Sciences Research Council [EP/V002910/1]; MRC [MR/S019669/1, MR/S003983/1, MR/V038109/1] Funding Source: UKRI
CR Albert A, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1357, DOI 10.1145/3097983.3098070
   [Anonymous], 2015, ICLR, V0, P0
   [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   Apte JS, 2017, ENVIRON SCI TECHNOL, V51, P6999, DOI 10.1021/acs.est.7b00891
   Araujo R.M, 2019, P 2019 INT JOINT C N, V0, P1
   Arietta SM, 2014, IEEE T VIS COMPUT GR, V20, P2624, DOI 10.1109/TVCG.2014.2346446
   Bacastow T.M., 2018, ARXIV PREPRINT ARXIV, V0, P0
   Barbierato E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020329
   Bonafilia D, 2019, IEEE C COMP VIS PATT, V0, P0
   Burgdorfer J., 2015, JOINT URBAN REMOTE S, V0, P1
   Cao R, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101553
   Chakma A, 2017, IEEE IMAGE PROC, V0, P3949
   Chew RF, 2018, INT J HEALTH GEOGR, V17, P0, DOI 10.1186/s12942-018-0132-1
   Clark SN, 2020, BMJ OPEN, V10, P0, DOI 10.1136/bmjopen-2019-035798
   da Costa JP, 2005, LECT NOTES ARTIF INT, V3720, P690, DOI 10.1007/11564096_70
   Demir I., 2018, P IEEE COMPUTER SOC, V0, P0
   Engstrom R., 2011, 2011 PROCEEDINGS OF JOINT URBAN REMOTE SENSING EVENT (JURSE 2011), V0, PP145, DOI 10.1109/JURSE.2011.5764740
   Flaxman S., 2018, NIPS 2018 SPAT WORKS, V0, P0
   Gebru T, 2017, P NATL ACAD SCI USA, V114, P13108, DOI 10.1073/pnas.1700035114
   GLA G.L.A., 2017, BETTER HLTH ALL LOND, V0, P0
   GLA G.L.A, 2018, LOND BOR PROF, V0, P0
   Glaeser E. L., 2018, NATL BUREAU EC RES W, V25174, P0, DOI 10.3386/w25174
   Greater London Authority (GLA), 2015, GLA HOUS INC EST SMA, V0, P0
   Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
   King DB, 2015, ACS SYM SER, V1214, P1
   Larkin A, 2019, J EXPO SCI ENV EPID, V29, P447, DOI 10.1038/s41370-018-0017-1
   Law S, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3342240
   Leordeanu M., 2016, ARXIV PREPRINT ARXIV, V0, P0
   Li C., 2018, ACM T INTEL SYST TEC, V0, P0, DOI DOI 10.1145/3298981
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Lobell DB, 2013, FIELD CROP RES, V143, P56, DOI 10.1016/j.fcr.2012.08.008
   Lu YL, 2015, NATURE, V520, P432, DOI 10.1038/520432a
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Martinovic A, 2015, PROC CVPR IEEE, V0, PP4456, DOI 10.1109/CVPR.2015.7299075
   Ministry of Housing Communities & Local Government, 2015, ENGLISH INDICES DEPR, V0, P0
   Mnih V., 2013, CITESEER, V0, P0
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Naik N, 2017, P NATL ACAD SCI USA, V114, P7571, DOI 10.1073/pnas.1619003114
   Naik N, 2014, IEEE COMPUT SOC CONF, V0, PP793, DOI 10.1109/CVPRW.2014.121
   ONS, 2011, UK CENS 2011, V0, P0
   ONS, 2017, ONS POSTC DIR NOV 20, V0, P0
   Oshri B, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP616, DOI 10.1145/3219819.3219924
   Papadomanolaki M, 2016, ISPRS ANN PHOTO REM, V3, P83, DOI 10.5194/isprsannals-III-7-83-2016
   Penatti Otavio A. B., 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP44, DOI 10.1109/CVPRW.2015.7301382
   Planet Team, 2017, PLANET APPL PROGRAM, V0, P0
   Richards DR, 2017, ECOL INDIC, V77, P31, DOI 10.1016/j.ecolind.2017.01.028
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandborn A, 2016, IEEE J-STARS, V9, P1970, DOI 10.1109/JSTARS.2016.2519843
   Seiferling I, 2017, LANDSCAPE URBAN PLAN, V165, P93, DOI 10.1016/j.landurbplan.2017.05.010
   Srivastava S, 2019, REMOTE SENS ENVIRON, V228, P129, DOI 10.1016/j.rse.2019.04.014
   Steele JE, 2017, J R SOC INTERFACE, V14, P0, DOI 10.1098/rsif.2016.0690
   Suel E, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-42036-w
   Uba N.K, 2016, LAND USE LAND COVER, V0, P0
   Verdoliva L., 2015, ARXIV PREPRINT ARXIV, V0, P0
   Weichenthal S., 2019, ARXIV PREPRINT ARXIV, V0, P0
   Weichenthal S, 2019, ENVIRON INT, V122, P3, DOI 10.1016/j.envint.2018.11.042
   Workman S, 2015, IEEE I CONF COMP VIS, V0, PP3961, DOI 10.1109/ICCV.2015.451
   Xie M, 2016, AAAI CONF ARTIF INTE, V0, P3929
   Yin L, 2016, APPL GEOGR, V76, P147, DOI 10.1016/j.apgeog.2016.09.024
   You JX, 2017, AAAI CONF ARTIF INTE, V0, P4559
   Yuan J., 2016, ARXIV PREPRINT ARXIV, V0, P0
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zhai M, 2017, PROC CVPR IEEE, V0, PP4132, DOI 10.1109/CVPR.2017.440
   Zhang C, 2018, MACH VISION APPL, V29, P601, DOI 10.1007/s00138-018-0919-x
   Zhu Y, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), V0, P0, DOI DOI 10.1145/2820783.2820851
NR 67
TC 18
Z9 18
U1 5
U2 25
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0034-4257
EI 1879-0704
J9 REMOTE SENS ENVIRON
JI Remote Sens. Environ.
PD MAY 15
PY 2021
VL 257
IS 
BP 
EP 
DI 10.1016/j.rse.2021.112339
EA FEB 2021
PG 11
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology
GA RB9QH
UT WOS:000632439100002
PM 33941991
DA 2023-04-26
ER

PT J
AU Qi, JH
   Gong, ZQ
   Xue, W
   Liu, XY
   Yao, AH
   Zhong, P
AF Qi, Jiahao
   Gong, Zhiqiang
   Xue, Wei
   Liu, Xingyue
   Yao, Aihuan
   Zhong, Ping
TI An Unmixing-Based Network for Underwater Target Detection From Hyperspectral Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Object detection; Hyperspectral imaging; Detectors; Computational modeling; Interference; Earth; Decoding; Anomaly detection; bathymetric model-based (BMB) autoencoder; hyperspectral unmixing (HU); physical meaningless endmembers
ID collaborative representation; water property; shallow waters; algorithm; model; transform; deep
AB Detecting underwater targets from hyperspectral imagery makes a profound impact on marine exploration. Available methods mainly tackle this problem by modifying the land-based detection algorithms with classical bathymetric models, which usually fail to remove the interference of background and ignore the effect of depth information, leading to a poor detection performance. To achieve a more precise result, in this work we propose a novel network based on hyperspectral unmixing (HU) methodology and bathymetric models to detect the desired underwater targets. The proposed network, called underwater target detection network (UTD-Net), first develops a novel joint anomaly detector with classical HU methods to separate out target-water mixed pixels, which is devoted to eliminate the adverse influence of background. Then, we explore a bathymetric model-based autoencoder to unmix the target-water mixed pixels for acquiring the target-associated abundance values and maps. One dimension convolutional neural network is exploited to construct the encoder part of above autoencoder for the sake of addressing spectral variability problem. Moreover, considering the physical meaningless endmembers issue, a particular spectral constraint is imposed on the objective function as a training guidance. In this way, the autoencoder would be capable of generating specific endmembers and their corresponding abundance maps. Finally, according to the physical essence of abundance maps, we figure out the detection result by fusing the outcomes of autoencoder with weight coefficients determined by abundance values. Qualitative and quantitative illustrations demonstrate the effectiveness and efficiency of UTD-Net in comparison with the state-of-the-art underwater target detection methods.
C1 [Qi, Jiahao; Xue, Wei; Liu, Xingyue; Yao, Aihuan; Zhong, Ping] Natl Univ Def Technol, Natl Key Lab Sci & Technol Automat Target Recogni, Changsha 410073, Peoples R China.
   [Qi, Jiahao; Xue, Wei; Liu, Xingyue; Yao, Aihuan; Zhong, Ping] Anhui Univ Technol, Sch Comp Sci & Technol, Maanshan 243032, Peoples R China.
   [Gong, Zhiqiang] Chinese Acad Mil Sci, Natl Innovat Inst Def Technol, Beijing 100000, Peoples R China.
C3 National University of Defense Technology - China; Anhui University of Technology
RP Zhong, P (corresponding author), Natl Univ Def Technol, Natl Key Lab Sci & Technol Automat Target Recogni, Changsha 410073, Peoples R China.
EM gongzhiqiang13@nudt.edu.cn; cswxue@ahut.edu.cn
FU Natural Science Foundation of China [61971428, 61671456, 61806004, 62001502]; China Postdoctoral Science Foundation [2020T130767]
CR Albert A, 2003, OPT EXPRESS, V11, P2873, DOI 10.1364/OE.11.002873
   Amin R, 2013, IEEE T GEOSCI REMOTE, V51, P732, DOI 10.1109/TGRS.2012.2204267
   [Anonymous], 2007, DATA SERIES, V0, P0
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Boardman J.W., 1995, PROC 5 JPL AIRBORNE, V1, P23
   Brewin RJW, 2011, APPL OPTICS, V50, P4535, DOI 10.1364/AO.50.004535
   Chang CI, 2005, IEEE T GEOSCI REMOTE, V43, P502, DOI 10.1109/TGRS.2004.839543
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Clevers J. G. P. W., 2012, IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, V5, P574, DOI 10.1109/JSTARS.2011.2176468
   Dong Q, 2013, REMOTE SENS ENVIRON, V128, P259, DOI 10.1016/j.rse.2012.10.013
   Garcia RA, 2014, LIMNOL OCEANOGR-METH, V12, P651, DOI 10.4319/lom.2014.12.651
   Gillis DB, 2020, REMOTE SENS LETT, V11, P903, DOI 10.1080/2150704X.2020.1795293
   Gillis DB, 2020, IEEE J-STARS, V13, P1798, DOI 10.1109/JSTARS.2020.2969013
   Harsanyi J. C., 1993, DETECTION CLASSIFICA, V0, P0
   He L, 2020, IEEE J-STARS, V13, P5898, DOI 10.1109/JSTARS.2020.3025040
   Hedley J, 2009, REMOTE SENS ENVIRON, V113, P2527, DOI 10.1016/j.rse.2009.07.008
   Heylen R, 2014, IEEE J-STARS, V7, P1844, DOI 10.1109/JSTARS.2014.2320576
   Jay S, 2012, IEEE J-STARS, V5, P1213, DOI 10.1109/JSTARS.2012.2185488
   Karayiannis NB, 1999, IEEE T NEURAL NETWOR, V10, P1153, DOI 10.1109/72.788654
   Kwan C, 2006, IEEE T GEOSCI REMOTE, V44, P409, DOI 10.1109/TGRS.2005.860985
   Lee ZP, 1999, APPL OPTICS, V38, P3831, DOI 10.1364/AO.38.003831
   Lee ZP, 1998, APPL OPTICS, V37, P6329, DOI 10.1364/AO.37.006329
   Manolakis D., 2001, P SPIE, V4480, P0
   Matteoli S, 2014, IEEE J-STARS, V7, P2317, DOI 10.1109/JSTARS.2014.2315772
   Mei SH, 2020, IEEE J-STARS, V13, P3336, DOI 10.1109/JSTARS.2020.3003456
   MOBLEY CD, 1993, APPL OPTICS, V32, P7484, DOI 10.1364/AO.32.007484
   Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293
   REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107
   Richter R, 2002, INT J REMOTE SENS, V23, P2631, DOI 10.1080/01431160110115834
   Schaum A, 2004, AEROSP CONF PROC, V0, PP1818, DOI 10.1109/AERO.2004.1367963
   Su HJ, 2018, IEEE J-STARS, V11, P5029, DOI 10.1109/JSTARS.2018.2880749
   Su YC, 2019, IEEE T GEOSCI REMOTE, V57, P4309, DOI 10.1109/TGRS.2018.2890633
   Werdell PJ, 2018, PROG OCEANOGR, V160, P186, DOI 10.1016/j.pocean.2018.01.001
   Winter ME, 1999, P SOC PHOTO-OPT INS, V3753, P266, DOI 10.1117/12.366289
   Xie WY, 2020, IEEE J-STARS, V13, P5887, DOI 10.1109/JSTARS.2020.3024903
   Xie WY, 2020, IEEE T GEOSCI REMOTE, V58, P1463, DOI 10.1109/TGRS.2019.2947033
   Xu X, 2020, IEEE J-STARS, V13, P4908, DOI 10.1109/JSTARS.2020.3017023
   Yang B, 2020, IEEE J-STARS, V13, P351, DOI 10.1109/JSTARS.2019.2962609
   Zhan HG, 2003, IEEE T GEOSCI REMOTE, V41, P1123, DOI 10.1109/TGRS.2003.813554
   Zhang Y, 2020, IEEE J-STARS, V13, P2663, DOI 10.1109/JSTARS.2020.2994340
   Zhang YX, 2019, IEEE J-STARS, V12, P2135, DOI 10.1109/JSTARS.2019.2894802
   Zhao CH, 2020, IEEE J-STARS, V13, P5982, DOI 10.1109/JSTARS.2020.3028372
   Zhu DH, 2019, IEEE J-STARS, V12, P1254, DOI 10.1109/JSTARS.2019.2902430
NR 43
TC 8
Z9 8
U1 10
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 5470
EP 5487
DI 10.1109/JSTARS.2021.3080919
PG 18
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SQ8YW
UT WOS:000660636600013
DA 2023-04-26
ER

PT J
AU Ito, Y
   Toyoizumi, T
AF Ito, Yoshiki
   Toyoizumi, Taro
TI Learning poly-synaptic paths with traveling waves
SO PLOS COMPUTATIONAL BIOLOGY
LA English
DT Article
ID visual-evoked potentials; in-vivo; dopamine; oscillations; dynamics; cortex; state; modulation; plasticity; neurons
AB Author summary There are approximately 10(11) neurons with 10(14) connections in the human brain. Information transmission among neurons in this large network is considered crucial for our behavior. To achieve this, multiple synaptic connections along a poly-synaptic network path must be adjusted coherently during learning. Because the previously proposed reward-dependent synaptic plasticity rule requires coactivation of presynaptic and postsynaptic neurons, learning can fail if a subset of neurons along a distant network path is inactive at the beginning of learning. We suggest that traveling waves that are initiated at an information source can mitigate this problem. We performed computer simulations of spiking neural networks with reward-dependent local synaptic plasticity rules and traveling waves. Our results show that this combination facilitates the learning and refinement of synaptic network paths. We argue that these features are a general biological strategy for maintaining and optimizing our brain function. Our research provides new insights into how complex neural networks in the brain form during learning and memory consolidation. Traveling waves are commonly observed across the brain. While previous studies have suggested the role of traveling waves in learning, the mechanism remains unclear. We adopted a computational approach to investigate the effect of traveling waves on synaptic plasticity. Our results indicate that traveling waves facilitate the learning of poly-synaptic network paths when combined with a reward-dependent local synaptic plasticity rule. We also demonstrate that traveling waves expedite finding the shortest paths and learning nonlinear input/output mapping, such as exclusive or (XOR) function.
C1 [Ito, Yoshiki] Univ Tokyo, Grad Sch Informat & Technol, Dept Mechanoinformat, Tokyo, Japan.
   [Toyoizumi, Taro] RIKEN Ctr Brain Sci, Lab Neural Computat & Adaptat, Saitama, Japan.
   [Toyoizumi, Taro] Univ Tokyo, Grad Sch Informat Sci & Technol, Dept Math Informat, Tokyo, Japan.
C3 University of Tokyo; RIKEN; University of Tokyo
RP Ito, Y (corresponding author), Univ Tokyo, Grad Sch Informat & Technol, Dept Mechanoinformat, Tokyo, Japan.; Toyoizumi, T (corresponding author), RIKEN Ctr Brain Sci, Lab Neural Computat & Adaptat, Saitama, Japan.; Toyoizumi, T (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Dept Math Informat, Tokyo, Japan.
EM y.ito@ne.t.u-tokyo.ac.jp; taro.toyoizumi@riken.jp
FU Japan Agency for Medical Research and Development [AMED] [JP21dm020700]; Japan Society for the Promotion of Science [JSPS] KAKENHI [JP18H05432]
CR ALEXANDRE F, 1991, NEURAL NETWORKS, V4, P15, DOI 10.1016/0893-6080(91)90027-3
   [Anonymous], 2011, RIV DIRITTO ELLENICO, V1, P45
   Bassett DS, 2017, NEUROSCIENTIST, V23, P499, DOI 10.1177/1073858416667720
   Beeler JA, 2010, FRONT BEHAV NEUROSCI, V4, P0, DOI 10.3389/fnbeh.2010.00170
   Bi GQ, 1998, J NEUROSCI, V18, P10464, DOI 10.1523/jneurosci.18-24-10464.1998
   Bringuier V, 1999, SCIENCE, V283, P695, DOI 10.1126/science.283.5402.695
   Burkitt GR, 2000, CLIN NEUROPHYSIOL, V111, P246, DOI 10.1016/S1388-2457(99)00194-7
   Calabresi P, 2007, TRENDS NEUROSCI, V30, P211, DOI 10.1016/j.tins.2007.03.001
   Dan Y, 2006, PHYSIOL REV, V86, P1033, DOI 10.1152/physrev.00030.2005
   FEENSTRA MGP, 1995, NEUROSCI LETT, V189, P81, DOI 10.1016/0304-3940(95)11456-7
   Floresco SB, 2003, NAT NEUROSCI, V6, P968, DOI 10.1038/nn1103
   Fremaux N, 2016, FRONT NEURAL CIRCUIT, V9, P0, DOI 10.3389/fncir.2015.00085
   GRINVALD A, 1994, J NEUROSCI, V14, P2545
   Harris KD, 2011, NAT REV NEUROSCI, V12, P509, DOI 10.1038/nrn3084
   Harris KD, 2011, HEARING RES, V271, P37, DOI 10.1016/j.heares.2010.06.006
   Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152
   Klampfl S, 2013, J NEUROSCI, V33, P11515, DOI 10.1523/JNEUROSCI.5044-12.2013
   Klimesch W, 1996, INT J PSYCHOPHYSIOL, V24, P61, DOI 10.1016/S0167-8760(96)00057-8
   Krull EM, 2019, FRONT NEUROSCI-SWITZ, V13, P0, DOI 10.3389/fnins.2019.00316
   Kusmierz L, 2017, CURR OPIN NEUROBIOL, V46, P170, DOI 10.1016/j.conb.2017.08.020
   Lee BR, 2008, NEUROSCI LETT, V434, P282, DOI 10.1016/j.neulet.2008.01.069
   Lefort S, 2009, NEURON, V61, P301, DOI 10.1016/j.neuron.2008.12.020
   Li SM, 2003, NAT NEUROSCI, V6, P526, DOI 10.1038/nn1049
   Lubenov EV, 2009, NATURE, V459, P534, DOI 10.1038/nature08010
   Massimini M, 2004, J NEUROSCI, V24, P6862, DOI 10.1523/JNEUROSCI.1318-04.2004
   Matsumoto K, 2003, SCIENCE, V301, P229, DOI 10.1126/science.1084204
   Miyamoto D, 2017, FRONT NEURAL CIRCUIT, V11, P0, DOI 10.3389/fncir.2017.00092
   Mohajerani MH, 2010, J NEUROSCI, V30, P3745, DOI 10.1523/JNEUROSCI.6437-09.2010
   Monti JM, 2007, SLEEP MED REV, V11, P113, DOI 10.1016/j.smrv.2006.08.003
   Muller L, 2018, NAT REV NEUROSCI, V19, P255, DOI 10.1038/nrn.2018.20
   Nauhaus I, 2012, J NEUROSCI, V32, P3088, DOI 10.1523/JNEUROSCI.5827-11.2012
   Nauhaus I, 2009, NAT NEUROSCI, V12, P70, DOI 10.1038/nn.2232
   Nunez P. L., 2006, ELECT FIELDS BRAIN N, V0, P0
   Orsborn AL, 2017, CURR OPIN NEUROBIOL, V46, P76, DOI 10.1016/j.conb.2017.08.002
   Petersen CCH, 2003, J NEUROSCI, V23, P1298, DOI 10.1523/JNEUROSCI.23-04-01298.2003
   Rasch B, 2007, SCIENCE, V315, P1426, DOI 10.1126/science.1138581
   Rubino D, 2006, NAT NEUROSCI, V9, P1549, DOI 10.1038/nn1802
   Sakata S, 2009, NEURON, V64, P404, DOI 10.1016/j.neuron.2009.09.020
   Sato TK, 2012, NEURON, V75, P218, DOI 10.1016/j.neuron.2012.06.029
   Schultz W, 2007, TRENDS NEUROSCI, V30, P203, DOI 10.1016/j.tins.2007.03.007
   Slovin H, 2002, J NEUROPHYSIOL, V88, P3421, DOI 10.1152/jn.00194.2002
   Srinivasan R, 2006, BRAIN TOPOGR, V18, P167, DOI 10.1007/s10548-006-0267-4
   STERIADE M, 1993, SCIENCE, V262, P679, DOI 10.1126/science.8235588
   Stimberg M, 2019, ELIFE, V8, P0, DOI 10.7554/eLife.47314
   Tahvildari B, 2012, J NEUROSCI, V32, P12165, DOI 10.1523/JNEUROSCI.1181-12.2012
   Tan AYY, 2014, NATURE, V509, P226, DOI 10.1038/nature13159
   Westerberg JA, 2019, J NEUROPHYSIOL, V121, P1938, DOI 10.1152/jn.00113.2019
   Zhang HH, 2018, NEURON, V98, P1269, DOI 10.1016/j.neuron.2018.05.019
   Zhang HH, 2015, J NEUROSCI, V35, P12477, DOI 10.1523/JNEUROSCI.5102-14.2015
NR 49
TC 0
Z9 0
U1 0
U2 4
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1553-734X
EI 1553-7358
J9 PLOS COMPUT BIOL
JI PLoS Comput. Biol.
PD FEB 15
PY 2021
VL 17
IS 2
BP 
EP 
DI 10.1371/journal.pcbi.1008700
PG 18
WC Biochemical Research Methods; Mathematical & Computational Biology
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA QG4CJ
UT WOS:000617535100003
PM 33561118
DA 2023-04-26
ER

PT J
AU Guo, B
   Bian, Y
   Zhang, DM
   Su, Y
   Wang, XX
   Zhang, B
   Wang, Y
   Chen, QJ
   Wu, YR
   Luo, PP
AF Guo, Bin
   Bian, Yi
   Zhang, Dingming
   Su, Yi
   Wang, Xiaoxia
   Zhang, Bo
   Wang, Yan
   Chen, Qiuji
   Wu, Yarui
   Luo, Pingping
TI Estimating Socio-Economic Parameters via Machine Learning Methods Using Luojia1-01 Nighttime Light Remotely Sensed Images at Multiple Scales of China in 2018
SO IEEE ACCESS
LA English
DT Article
DE Spatial resolution; Licenses; Radio frequency; Data models; Biological system modeling; Vegetation; Sociology; NPP; VIIRS; socio-economic parameters; GWR; machine learning; multiple scales; China
ID electric-power consumption; air-temperature; time-series; population; level; areas; gdp; indicators; emissions; dynamics
AB Mapping socio-economic indicators with a raster format is still a great challenge. The nighttime light (NTL) datasets have been widely utilized to estimate the socio-economic parameters. However, the precision of the published datasets was too coarse to meet related issues such as flood losses assessment, urban planning, and epidemiological studies. The present study calibrated gross domestic product (GDP), population (POP), electric consumption (EC), and urban build-up area (B-A) at 100 m resolution for 45 cities of China in 2018 using Luojia1-01 NTL datasets via random forest (RF) as well as geographically weighted regression (GWR) model. The linear regression (LR), back propagation neural network (BPNN), and support vector machine (SVM) methods were selected for comparison with GWR and RF models. Besides, the Suomi National Polar-Orbiting Partnership-Visible Infrared Imaging Radiometer Suite (NPP-VIIRS) was chosen for comparison with Luojia1-01. The ten-folded cross-validation (CV) has been used for evaluating accuracy at county and city scales. Finally, the distribution maps of socio-economic parameters were illustrated and some findings were obtained. First, the validation results revealed that the calibration at the city-scale outperformed the county or district scale. Second, the precision of the Luojia1-01 NTL dataset surpassed the NPP-VIIRS NTL dataset on the same administrative scale except for some specific situations. Third, the precision of the simulation for the gross domestic product (GDP) is the highest than the others, followed by electric consumption (EC), build-up area (B-A), and population (POP). Fourth, the optimum model varied according to the socio-economic parameters. Fifth, the distribution of socio-economic parameters exhibited obvious spatial heterogeneity. This paper can supply scientific support for calibrating socio-economic parameters in other regions.
C1 [Guo, Bin; Bian, Yi; Zhang, Dingming; Su, Yi; Wang, Xiaoxia; Zhang, Bo; Wang, Yan; Chen, Qiuji; Wu, Yarui] Xian Univ Sci & Technol, Coll Geomat, Xian 710054, Peoples R China.
   [Luo, Pingping] Changan Univ, Key Lab Subsurface Hydrol & Ecol Effects Arid Reg, Minist Educ, Xian 710054, Peoples R China.
   [Luo, Pingping] Changan Univ, Sch Water & Environm, Xian 710054, Peoples R China.
C3 Xi'an University of Science & Technology; Chang'an University; Chang'an University
RP Guo, B (corresponding author), Xian Univ Sci & Technol, Coll Geomat, Xian 710054, Peoples R China.; Luo, PP (corresponding author), Changan Univ, Key Lab Subsurface Hydrol & Ecol Effects Arid Reg, Minist Educ, Xian 710054, Peoples R China.; Luo, PP (corresponding author), Changan Univ, Sch Water & Environm, Xian 710054, Peoples R China.
EM guobin12@xust.edu.cn; lpp@chd.edu.cn
FU Fund Project of Shaanxi Key Laboratory of Land Consolidation [2019-JC11]; National Natural Science Foundation of China [41771576]
CR [Anonymous], 2005, COMPUT ENVIRON URBAN, V0, P0, DOI DOI 10.1016/J.COMPENVURBSYS.2003.09.004
   Bu LJ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19173761
   Cao Y, 2018, J INDIAN SOC REMOTE, V46, P1617, DOI 10.1007/s12524-018-0815-x
   Chen SC, 2018, SCI TOTAL ENVIRON, V630, P389, DOI 10.1016/j.scitotenv.2018.02.209
   Chen X, 2011, P NATL ACAD SCI USA, V108, P8589, DOI 10.1073/pnas.1017031108
   Chen XL, 2019, INT J APPL EARTH OBS, V83, P0, DOI 10.1016/j.jag.2019.05.022
   Chen ZQ, 2017, IEEE T GEOSCI REMOTE, V55, P6305, DOI 10.1109/TGRS.2017.2725917
   Chen ZQ, 2015, IEEE J-STARS, V8, P2188, DOI 10.1109/JSTARS.2015.2418201
   Devkota B, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11174718
   Elvidge CD, 2007, INT J REMOTE SENS, V28, P2645, DOI 10.1080/01431160600981525
   Elvidge CD, 1997, INT J REMOTE SENS, V18, P1373, DOI 10.1080/014311697218485
   Elvidge CD, 1997, PHOTOGRAMM ENG REM S, V63, P727
   Elvidge CD, 2007, GEOJOURNAL, V69, P45, DOI 10.1007/s10708-007-9104-x
   Elvidge CD, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12193194
   Falchetta G, 2019, ENERGIES, V12, P0, DOI 10.3390/en12030456
   Falchi F, 2011, J ENVIRON MANAGE, V92, P2714, DOI 10.1016/j.jenvman.2011.06.029
   Feldmeyer D, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9090498
   Fleming ZL, 2018, ELEMENTA-SCI ANTHROP, V6, P0, DOI 10.1525/elementa.273
   Gaston KJ, 2015, CONSERV BIOL, V29, P1132, DOI 10.1111/cobi.12462
   Gaston KJ, 2013, BIOL REV, V88, P912, DOI 10.1111/brv.12036
   Guo B, 2021, POL J ENVIRON STUD, V30, P601, DOI 10.15244/pjoes/123606
   Guo B, 2021, SCI TOTAL ENVIRON, V751, P0, DOI 10.1016/j.scitotenv.2020.141765
   Guo B, 2020, IEEE ACCESS, V8, P171694, DOI 10.1109/ACCESS.2020.3025013
   Guo B, 2020, POL J ENVIRON STUD, V29, P4065, DOI 10.15244/pjoes/118426
   Guo B, 2020, ENVIRON SCI POLLUT R, V27, P24400, DOI 10.1007/s11356-020-08744-x
   Holloway J, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091365
   Hu XF, 2020, LANDSCAPE URBAN PLAN, V195, P0, DOI 10.1016/j.landurbplan.2019.103709
   Ingacheva A, 2018, P 32 EUR C MOD SIM E, V0, P1073
   Jiang W, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18092900
   Ju Y, 2020, CONCURR COMP-PRACT E, V32, P0, DOI 10.1002/cpe.5483
   Kyba CCM, 2017, SCI ADV, V3, P0, DOI 10.1126/sciadv.1701528
   Levin N, 2012, REMOTE SENS ENVIRON, V119, P1, DOI 10.1016/j.rse.2011.12.005
   Li C, 2017, INT J REMOTE SENS, V38, P6007, DOI 10.1080/01431161.2017.1312034
   [李德仁 Li Deren], 2015, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V44, P591
   Li X, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113665
   Li X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060858
   Li X, 2014, INT J REMOTE SENS, V35, P6648, DOI 10.1080/01431161.2014.971469
   Li X, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19173708
   Liang HD, 2020, ADV SPACE RES, V65, P481, DOI 10.1016/j.asr.2019.09.035
   Liu JP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030541
   Liu SS, 2019, REMOTE SENS LETT, V10, P1172, DOI 10.1080/2150704X.2019.1666313
   Liu XP, 2018, J CLEAN PROD, V177, P101, DOI 10.1016/j.jclepro.2017.12.197
   Lo CP, 2002, ANN ASSOC AM GEOGR, V92, P225, DOI 10.1111/1467-8306.00288
   Lu LL, 2019, ENERGY, V189, P0, DOI 10.1016/j.energy.2019.116351
   Luo PP, 2020, J CLEAN PROD, V263, P0, DOI 10.1016/j.jclepro.2020.121154
   Paranunzio R, 2019, ATMOSPHERE-BASEL, V10, P0, DOI 10.3390/atmos10030117
   Qiu RJ, 2020, SCI TOTAL ENVIRON, V737, P0, DOI 10.1016/j.scitotenv.2020.139729
   Rybnikova NA, 2014, INT J REMOTE SENS, V35, P7706, DOI 10.1080/01431161.2014.975380
   Shi KF, 2020, J CLEAN PROD, V255, P0, DOI 10.1016/j.jclepro.2020.120245
   Shi KF, 2016, APPL ENERG, V184, P450, DOI 10.1016/j.apenergy.2016.10.032
   Shi KF, 2014, REMOTE SENS-BASEL, V6, P1705, DOI 10.3390/rs6021705
   Stokes EC, 2019, REMOTE SENS ENVIRON, V234, P0, DOI 10.1016/j.rse.2019.111430
   Sun L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010091
   Tian S. Q., 2014, ADV MATER RES-KR, V989, P5128
   Townsend AC, 2010, INT J REMOTE SENS, V31, P4459, DOI 10.1080/01431160903261005
   Wang CX, 2020, INT J APPL EARTH OBS, V85, P0, DOI 10.1016/j.jag.2019.101989
   Wang W, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19194077
   Wang XT, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020163
   Wei J, 2020, ATMOS CHEM PHYS, V20, P3273, DOI 10.5194/acp-20-3273-2020
   Wu JS, 2013, REMOTE SENS ENVIRON, V134, P111, DOI 10.1016/j.rse.2013.03.001
   Wu XD, 2017, J GEOPHYS RES-ATMOS, V122, P13138, DOI 10.1002/2017JD027262
   Xu YM, 2014, INT J REMOTE SENS, V35, P8108, DOI 10.1080/01431161.2014.978957
   Ye TT, 2019, SCI TOTAL ENVIRON, V658, P936, DOI 10.1016/j.scitotenv.2018.12.276
   Yu BL, 2015, IEEE J-STARS, V8, P1217, DOI 10.1109/JSTARS.2015.2399416
   Zhao NZ, 2017, GISCI REMOTE SENS, V54, P407, DOI 10.1080/15481603.2016.1276705
   Zhao NZ, 2012, INT J REMOTE SENS, V33, P6304, DOI 10.1080/01431161.2012.684076
   Zheng YM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141709
   Zhou HL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171958
   [朱孝林 ZHU Xiaolin], 2008, 自然资源学报 JOURNAL OF NATURAL RESOURCES, V23, P534
NR 70
TC 16
Z9 16
U1 12
U2 43
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2021
VL 9
IS 
BP 34352
EP 34365
DI 10.1109/ACCESS.2021.3059865
PG 14
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA QT0UP
UT WOS:000626308200001
DA 2023-04-26
ER

PT J
AU Guo, MQ
   Bei, WJ
   Huang, Y
   Chen, ZL
   Zhao, XZ
AF Guo, MingQiang
   Bei, Weijia
   Huang, Ying
   Chen, Zhanlong
   Zhao, Xiaozhen
TI Deep learning framework for geological symbol detection on geological maps
SO COMPUTERS & GEOSCIENCES
LA English
DT Article
DE Geological map; Dynamic legend; Deep learning; Object detection; Graph convolution
ID identification; representation; model
AB Dynamic legend generation for geological maps aims to detect and identify geological map symbols within the current viewshed and generate a corresponding real-time legend to help users quickly obtain the name and meaning of symbols. Detection and recognition entail high complexity and uncertainty because of the diversity of symbol types and the randomness of symbol distribution, and thus the generation of dynamic legends for geological maps is challenging. A new framework based on deep learning is proposed in this study, combining the deep convolutional neural network (CNN) and graph convolutional network (GCN) to realize the extraction and recognition of geological map symbols. Within the framework, a CNN-based model called single symbol detection network (SSDN) is developed to detect and identify single geological map symbols, and a novel GCN combined with L2 distance attention (DAGCN) is proposed to deal with the difficulty of extracting compound symbols caused by the randomness of symbol distribution. This work systematically solves the problem of geological symbol detection with the aid of object detection technology based on deep learning, providing foundation for the dynamic legend generation. Experiments show that the framework of the proposed method is effective, and a new benchmark is established for geological symbol detection on geological maps. All of our data and code are publicly available.
C1 [Guo, MingQiang; Bei, Weijia; Chen, Zhanlong; Zhao, Xiaozhen] China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
   [Bei, Weijia] Chinese Acad Sci, Aerosp Informat Res Inst AIR, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Bei, Weijia] Univ Chinese Acad Sci, 19 Yuquan Rd, Beijing 100049, Peoples R China.
   [Huang, Ying] Wuhan Zondy Cyber Technol Ltd Co, Wuhan 430074, Peoples R China.
C3 China University of Geosciences; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Bei, WJ (corresponding author), China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
EM beiweijia21@mails.ucas.ac.cn
FU National Natural Science Foundation of China [41971356, 41701446]; Open Fund of Key Laboratory of Urban Land Resources Monitoring and Simulation, Ministry of Natural Resources of the People's Republic of China [KF-2020-05-011]
CR Bei WJ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19245518
   Caers J, 2011, MODELING UNCERTAINTY IN THE EARTH SCIENCES, V0, PP1, DOI 10.1002/9781119995920
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cucurull P., 2017, GRAPH ATTENTION NETW, V0, P0
   Ding LY, 2012, AUTOMAT CONSTR, V27, P120, DOI 10.1016/j.autcon.2012.05.010
   Du J., 2017, TOPOLOGY ADAPTIVE GR, V0, P0
   Gomez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572
   Gori M, 2005, IEEE IJCNN, V0, P729
   Guo MQ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091400
   Hamilton WL, 2017, NIPS, V0, P0, DOI DOI 10.5555/3294771.3294869
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Jones C. B., 1995, CARTOGR GEOGR INF SC, V22, P317, DOI 10.1559/152304095782540221
   Kipf T. N., 2016, P ICLR, V0, P0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J, 2019, PR MACH LEARN RES, V97, P0
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Ma XG, 2012, COMPUT GEOSCI-UK, V40, P107, DOI 10.1016/j.cageo.2011.07.018
   Rahimzadegan M, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.035018
   Rahimzadegan M, 2015, ARAB J GEOSCI, V8, P7321, DOI 10.1007/s12517-014-1757-4
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Sadeghi B., 2020, THESIS U NEW S WALES, V0, P0
   Scheidt C., 2008, UNCERTAINTY QUANTIFI, V0, P0
   Scheidt C., 2018, QUANTIFYING UNCERTAI, V0, P304
   Scheidt C, 2009, MATH GEOSCI, V41, P397, DOI 10.1007/s11004-008-9186-0
   Siddiquee MMR, 2018, UNET NESTED U NET AR, V0, P0
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Wang K, 2011, IEEE I CONF COMP VIS, V0, PP1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, V0, P3304
   Xu YY, 2017, INT J GEOGR INF SCI, V31, P253, DOI 10.1080/13658816.2016.1192637
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Yu WH, 2020, INT J GEOGR INF SCI, V34, P119, DOI 10.1080/13658816.2019.1650936
   Zhan FN, 2019, PROC CVPR IEEE, V0, PP2054, DOI 10.1109/CVPR.2019.00216
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhanlong Chen, 2011, 2011 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND SERVICE SYSTEM (CSSS), V0, P2583
   Zhou X., 2019, ARXIV190407850, V0, P0
NR 36
TC 5
Z9 5
U1 11
U2 33
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0098-3004
EI 1873-7803
J9 COMPUT GEOSCI-UK
JI Comput. Geosci.
PD DEC 15
PY 2021
VL 157
IS 
BP 
EP 
DI 10.1016/j.cageo.2021.104943
EA SEP 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Geosciences, Multidisciplinary
SC Computer Science; Geology
GA WA4SZ
UT WOS:000702878000003
DA 2023-04-26
ER

PT J
AU Tompkin, C
   Leinss, S
AF Tompkin, Cedric
   Leinss, Silvan
TI Backscatter Characteristics of Snow Avalanches for Mapping With Local Resolution Weighting
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Radar remote sensing; Radar imaging; Radar detection; Synthetic aperture radar; Electromagnetic reflection; Supervised learning; Neural Networks; Image segmentation
ID images
AB Snow avalanches cause a sudden change of snow properties making them detectable with synthetic aperture radar (SAR). However, steep alpine terrain combined with the slant view geometry of SAR sensors complicates detection: the avalanche brightness depends on the incidence angle and the observed area is limited by radar layover and shadow. Likewise, the spatial resolution varies strongly with the local incidence angle relative to the terrain. To increase the avalanche brightness and to improve the imaging coverage and resolution we apply local resolution weighting (LRW) on Sentinel-1 (S1) backscatter images from ascending and descending orbits. LRW merges acquisitions by averaging them, weighted with the local ground-range resolution. To analyze the relative avalanche brightness with respect to the local incidence angle and polarization, and to quantify the benefit of LRW, we created a dataset of 914 manually drawn avalanche outlines based on S1 imagery of an extreme avalanche event on January 4, 2018 in the Swiss Alps. We show that avalanches appear brightest at slopes facing away from the radar at local incidence angles of 55 +/- 20 degrees; such slopes are weighted considerably stronger through LRW. With a processing pipeline for avalanche segmentation using a fixed threshold on the backscatter difference we obtain a higher F1 score (0.75) with LRW compared to an unweighted orbit average (F1 = 0.68) or single orbit acquisitions (F1 = 0.5). For automatic segmentation, we used the manually drawn dataset for training and testing of a deep neural U-Net and achieved a F1 score of 0.81 on LRW backscatter differences.
C1 [Tompkin, Cedric; Leinss, Silvan] Swiss Fed Inst Technol, Inst Environm Engn, CH-8093 Zurich, Switzerland.
   [Tompkin, Cedric] Swiss Fed Inst Technol, Inst Elect Engn & Informat Technol, CH-8092 Zurich, Switzerland.
   [Leinss, Silvan] Univ Savoie Mt Blanc, Lab Informat Syst Traitement Informat & Connaissa, F-74940 Annecy, France.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Tompkin, C (corresponding author), Swiss Fed Inst Technol, Inst Environm Engn, CH-8093 Zurich, Switzerland.
EM ctompkin@student.ethz.ch; leinss@ifu.baug.ethz.ch
FU ETH Zurich
CR [Anonymous], 2016, RAMMS RAPID MASS MOV, V0, P0
   [Anonymous], 2007, WATER AIR SOIL POLL, V0, P0, DOI DOI 10.1007/s11270-007-9372-6
   Bianchi FM, 2021, IEEE J-STARS, V14, P75, DOI 10.1109/JSTARS.2020.3036914
   Bourbigot M., 2016, SENTINEL 1 PRODUCT D, V0, P0
   Buades A, 2005, PROC CVPR IEEE, V0, PP60, DOI 10.1109/cvpr.2005.38
   Buhler Y, 2019, CRYOSPHERE, V13, P3225, DOI 10.5194/tc-13-3225-2019
   Chaplin M., 2007, WATER DIELECTRIC MIC, V0, P0
   Eckerstorfer M, 2017, COLD REG SCI TECHNOL, V144, P39, DOI 10.1016/j.coldregions.2017.08.004
   Eckerstorfer M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232863
   Eckerstorfer M, 2016, COLD REG SCI TECHNOL, V121, P126, DOI 10.1016/j.coldregions.2015.11.001
   Eckerstorfer M, 2015, COLD REG SCI TECHNOL, V120, P205, DOI 10.1016/j.coldregions.2015.08.016
   Ferretti A, 2014, SATELLITE INSAR DATA: RESERVOIR MONITORING FROM SPACE, V0, PP1, DOI 10.3997/9789073834712
   GDAL/OGR contributors, 2020, GDAL OGR GEOSP DAT A, V0, P0
   Hafner E., 2019, ENVIDAT, V0, P0, DOI DOI 10.16904/envidat.77
   Hamar JB, 2016, INT GEOSCI REMOTE SE, V0, PP689, DOI 10.1109/IGARSS.2016.7729173
   Karbou F., 2018, INT SNOW SCI WORKSH, V1, P344
   Leinss S, 2020, NAT HAZARD EARTH SYS, V20, P1783, DOI 10.5194/nhess-20-1783-2020
   Malnes E., 2015, CRYOSPHERE DISCUSS, V9, P1943, DOI 10.5194/TCD-9-1943-2015
   Neubert J., 2020, INFORM MED UNLOCKED, V18, P0
   Nuesch D., 2004, P EUSAR, V0, P25
   OH Y, 1992, IEEE T GEOSCI REMOTE, V30, P370, DOI 10.1109/36.134086
   RANEY RK, 1994, INT GEOSCI REMOTE SE, V0, PP1090, DOI 10.1109/IGARSS.1994.399352
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosen PA, 2000, P IEEE, V88, P333, DOI 10.1109/5.838084
   SLF, 2018, SLF AV B, V0, P0
   Small D, 2012, INT GEOSCI REMOTE SE, V0, PP4521, DOI 10.1109/IGARSS.2012.6350465
   Small D, 2011, IEEE T GEOSCI REMOTE, V49, P3081, DOI 10.1109/TGRS.2011.2120616
   Ulaby F., 2014, MICROWAVE RADAR RADI, V0, P0, DOI DOI 10.3998/0472119356
   Vickers H, 2016, EARTH SPACE SCI, V3, P446, DOI 10.1002/2016EA000168
   Waldeland AU, 2018, INT GEOSCI REMOTE SE, V0, P2386
   Wesselink DS, 2017, POLAR RES-SWEDEN, V36, P0, DOI 10.1080/17518369.2017.1333236
NR 34
TC 4
Z9 4
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4452
EP 4464
DI 10.1109/JSTARS.2021.3074418
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SC1VT
UT WOS:000650468700002
DA 2023-04-26
ER

PT J
AU Rahman, M
   Chen, NS
   Islam, MM
   Dewan, A
   Pourghasemi, HR
   Washakh, RMA
   Nepal, N
   Tian, SF
   Faiz, H
   Alam, M
   Ahmed, N
AF Rahman, Mahfuzur
   Chen, Ningsheng
   Islam, Md Monirul
   Dewan, Ashraf
   Pourghasemi, Hamid Reza
   Washakh, Rana Muhammad Ali
   Nepal, Nirdesh
   Tian, Shufeng
   Faiz, Hamid
   Alam, Mehtab
   Ahmed, Naveed
TI Location-allocation modeling for emergency evacuation planning with GIS and remote sensing: A case study of Northeast Bangladesh
SO GEOSCIENCE FRONTIERS
LA English
DT Article
DE Natural disasters; Emergency evacuation centers; Flooding; Machine learning; Multi-criteria decision making; Location-allocation model
ID multicriteria decision-making; support vector machine; flood hazard; climate-change; susceptibility; area; vulnerability; weights
AB This work developed models to identify optimal spatial distribution of emergency evacuation centers (EECs) such as schools, colleges, hospitals, and fire stations to improve flood emergency planning in the Sylhet region of northeastern Bangladesh. The use of location-allocation models (LAMs) for evacuation in regard to flood victims is essential to minimize disaster risk. In the first step, flood susceptibility maps were developed using machine learning models (MLMs), including: Levenberg-Marquardt back propagation (LM-BP) neural network and decision trees (DT) and multi-criteria decision making (MCDM) method. Performance of the MLMs and MCDM techniques were assessed considering the area under the receiver operating characteristic (AUROC) curve. Mathematical approaches in a geographic information system(GIS) for four well-known LAM problems affecting emergency rescue time are proposed: maximal covering location problem (MCLP), the maximize attendance (MA), p-median problem (PMP), and the location set covering problem(LSCP). The results showed that existing EECs were not optimally distributed, and that some areas were not adequately served by EECs (i.e., not all demand points could be reached within a 60-min travel time). We concluded that the proposed models can be used to improve planning of the distribution of EECs, and that application of the models could contribute to reducing human casualties, property losses, and improve emergency operation. (C) 2021 ChinaUniversity of Geosciences (Beijing) and Peking University. Production and hosting by Elsevier B.V.
C1 [Rahman, Mahfuzur; Chen, Ningsheng; Tian, Shufeng; Faiz, Hamid; Alam, Mehtab] Chinese Acad Sci, Inst Mt Hazards & Environm IMHE, Key Lab Mt Hazards & Earth Surface Proc, Chengdu 610041, Peoples R China.
   [Rahman, Mahfuzur; Chen, Ningsheng; Tian, Shufeng; Faiz, Hamid; Alam, Mehtab; Ahmed, Naveed] Univ Chinese Acad Sci UCAS, Beijing 100049, Peoples R China.
   [Rahman, Mahfuzur; Islam, Md Monirul] Int Univ Business Agr & Technol IUBAT, Dept Civil Engn, Dhaka 1230, Bangladesh.
   [Dewan, Ashraf] Curtin Univ, Sch Earth & Planetary Sci, Kent St, Bentley, WA 6102, Australia.
   [Pourghasemi, Hamid Reza] Shiraz Univ, Coll Agr, Dept Nat Resources & Environm Engn, Shiraz, Iran.
   [Washakh, Rana Muhammad Ali] Neijiang Normal Univ, Sch Architecture, Neijiang 641100, Peoples R China.
   [Washakh, Rana Muhammad Ali] Chinese Acad Sci, Inst Tibetan Plateau Res, Beijing 100101, Peoples R China.
   [Nepal, Nirdesh] Global Inst Interdisciplinary Studies, Kathmandu 3084, Nepal.
C3 Chinese Academy of Sciences; Institute of Mountain Hazards & Environment, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; International University of Business Agriculture & Technology (IUBAT); Curtin University; Shiraz University; Neijiang Normal University; Chinese Academy of Sciences; Institute of Tibetan Plateau Research, CAS
RP Chen, NS (corresponding author), Chinese Acad Sci, Inst Mt Hazards & Environm IMHE, Key Lab Mt Hazards & Earth Surface Proc, Chengdu 610041, Peoples R China.; Chen, NS (corresponding author), Univ Chinese Acad Sci UCAS, Beijing 100049, Peoples R China.
EM chennsh@imde.ac.cn
FU National Natural Science Foundation of China [41861134008, 41671112]; 135 Strategic Programof the Institute of Mountain Hazards and Environment (IMHE), Chinese Academy of Sciences (CAS) [SDS-135-1705]
CR Achour Y, 2020, GEOSCI FRONT, V11, P871, DOI 10.1016/j.gsf.2019.10.001
   Al-Juaidi AEM, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-4095-0
   Alam M, 2002, CONCEPT FLOOD SHELTE, V0, P175
   Algharib S.M, 2011, THESIS KENT STATE U, V0, P0
   Ali SA, 2019, MODEL EARTH SYST ENV, V5, P1083, DOI 10.1007/s40808-019-00593-z
   Alshwesh I.O., 2014, THESIS U LEICESTER, V0, P0
   Anees MT, 2016, J AFR EARTH SCI, V124, P478, DOI 10.1016/j.jafrearsci.2016.10.001
   [Anonymous], 2017, J PART SCI TECHNOL, V0, P0
   [Anonymous], 2009, HYDROL RES LETT, V0, P0, DOI DOI 10.3178/HRL.3.6
   Arabameri A, 2019, SCI TOTAL ENVIRON, V660, P443, DOI 10.1016/j.scitotenv.2019.01.021
   Armah FA, 2010, WATER-SUI, V2, P120, DOI 10.3390/w2020120
   Arnoldus H. M. J., 1980, ASSESSMENT OF EROSION., V0, P127
   Bari S. H., 2015, CIVIL AND ENVIRONMENTAL RESEARCH, V7, P69
   BBS, 2019, GEND STAT BANGL 2018, V0, P0
   Bermudez M, 2019, J FLOOD RISK MANAG, V12, P0, DOI 10.1111/jfr3.12522
   Cabrera JS, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11112203
   CEGIS, 2012, MAST PLAN HAOR AR BA, V0, P0
   Chang MS, 2007, TRANSPORT RES E-LOG, V43, P737, DOI 10.1016/j.tre.2006.10.013
   Chang MJ, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10121734
   Chapi K, 2017, ENVIRON MODELL SOFTW, V95, P229, DOI 10.1016/j.envsoft.2017.06.012
   Chowdhury J.U., 1996, J CIV ENG CE, VCE24, P221
   Church R., 1974, PAP REG SCI ASSOC, V32, P101, DOI 10.1007/BF01942293
   Church RL, 2003, GEOGR ANAL, V35, P277, DOI 10.1111/j.1538-4632.2003.tb01115.x
   Constantin M, 2011, ENVIRON EARTH SCI, V63, P397, DOI 10.1007/s12665-010-0724-y
   Costache R, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.134514
   Cromley E, 2002, GIS PUBLIC HLTH, V2, P303
   Debeljak M, 2011, MODELLING COMPLEX ECOLOGICAL DYNAMICS: AN INTRODUCTION INTO ECOLOGICAL MODELLING FOR STUDENTS, V0, P197, DOI 10.1007/978-3-642-05029-9_14
   Dewan AM, 2007, WATER RESOUR MANAG, V21, P1601, DOI 10.1007/s11269-006-9116-1
   Bui DT, 2019, CATENA, V179, P184, DOI 10.1016/j.catena.2019.04.009
   Dinu S, 2016, IOP CONF SER-MAT SCI, V145, P0, DOI 10.1088/1757-899X/145/8/082021
   Elsafi SH, 2014, ALEX ENG J, V53, P655, DOI 10.1016/j.aej.2014.06.010
   Erena SH, 2018, J HYDROL-REG STUD, V19, P224, DOI 10.1016/j.ejrh.2018.09.005
   Falah F, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, V0, PP323, DOI 10.1016/B978-0-12-815226-3.00014-4
   Frigerio I, 2016, APPL GEOGR, V74, P12, DOI 10.1016/j.apgeog.2016.06.014
   Ganguly KK, 2019, INT J DISAST RISK RE, V34, P283, DOI 10.1016/j.ijdrr.2018.12.002
   Ghenai C, 2020, RENEW ENERG, V146, P580, DOI 10.1016/j.renene.2019.06.157
   Gnyawali KR, 2020, B ENG GEOL ENVIRON, V79, P587, DOI 10.1007/s10064-019-01583-2
   Gu W, 2010, INT J HEALTH GEOGR, V9, P0, DOI 10.1186/1476-072X-9-17
   Haghizadeh A, 2017, J EARTH SYST SCI, V126, P0, DOI 10.1007/s12040-017-0819-x
   Haltas I, 2016, NAT HAZARDS, V81, P2103, DOI 10.1007/s11069-016-2175-6
   Hateffard F, 2019, J MT SCI-ENGL, V16, P1833, DOI 10.1007/s11629-019-5409-8
   Hong HY, 2018, SCI TOTAL ENVIRON, V625, P575, DOI 10.1016/j.scitotenv.2017.12.256
   Hossain MA, 2013, THESIS U DHAKA, V0, P0
   Hunt A, 2011, CLIMATIC CHANGE, V104, P13, DOI 10.1007/s10584-010-9975-6
   Islam K.N, 2011, IMPACTS URBAN FLOODS, V0, P0
   Islam MDM, 2000, HYDROLOG SCI J, V45, P337, DOI 10.1080/02626660009492334
   Islam MM, 2000, HYDROL PROCESS, V14, P605, DOI 10.1002/(SICI)1099-1085(20000228)14:3&lt;605::AID-HYP957&gt;3.0.CO;2-L
   Islam MM, 2002, J HYDROL ENG, V7, P346, DOI 10.1061/(ASCE)1084-0699(2002)7:5(346)
   Janizadeh S, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11195426
   Jato-Espino D, 2019, J FLOOD RISK MANAG, V12, P0, DOI 10.1111/jfr3.12533
   Kar B, 2008, T GIS, V12, P227, DOI 10.1111/j.1467-9671.2008.01097.x
   Kersuliene V, 2010, J BUS ECON MANAG, V11, P243, DOI 10.3846/jbem.2010.12
   Khan SN, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7050185
   Kheir RB, 2010, ENVIRON POLLUT, V158, P520, DOI 10.1016/j.envpol.2009.08.009
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Khosravi K, 2016, NAT HAZARDS, V83, P947, DOI 10.1007/s11069-016-2357-2
   Kia MB, 2012, ENVIRON EARTH SCI, V67, P251, DOI 10.1007/s12665-011-1504-z
   Kim TH, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11030592
   Kourgialas NN, 2011, HYDROLOG SCI J, V56, P212, DOI 10.1080/02626667.2011.555836
   Lamovec P, 2013, J APPL REMOTE SENS, V7, P0, DOI 10.1117/1.JRS.7.073564
   Lee S, 2017, GEOMAT NAT HAZ RISK, V8, P1185, DOI 10.1080/19475705.2017.1308971
   Li XP, 2011, MATH METHOD OPER RES, V74, P281, DOI 10.1007/s00186-011-0363-4
   Masood M, 2012, NAT HAZARDS, V61, P757, DOI 10.1007/s11069-011-0060-x
   Masuya A, 2015, NAT HAZARDS, V78, P1859, DOI 10.1007/s11069-015-1802-y
   Mestre AM, 2015, EUR J OPER RES, V240, P791, DOI 10.1016/j.ejor.2014.07.024
   Mirchooli F, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7979-x
   Mohammady M, 2019, NAT HAZARDS, V99, P951, DOI 10.1007/s11069-019-03785-z
   Mojaddadi H, 2017, GEOMAT NAT HAZ RISK, V8, P1080, DOI 10.1080/19475705.2017.1294113
   Nusser M., 2019, WATER AIR SOIL POLL, V39, P518, DOI 10.1007/s11270-007-9372-6
   Polo G, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0119190
   Pourghasemi HR, 2020, GEOSCI FRONT, V11, P2207, DOI 10.1016/j.gsf.2020.03.005
   Pourghasemi HR, 2020, GEOSCI FRONT, V11, P1203, DOI 10.1016/j.gsf.2019.10.008
   Pourghasemi HR, 2020, J HYDROL, V582, P0, DOI 10.1016/j.jhydrol.2019.124536
   Pourghasemi HR, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-60191-3
   Pourghasemi HR, 2019, SCI TOTAL ENVIRON, V692, P556, DOI 10.1016/j.scitotenv.2019.07.203
   Rahman M, 2019, EARTH SYST ENVIRON, V3, P585, DOI 10.1007/s41748-019-00123-y
   Rahmati O, 2016, GEOCARTO INT, V31, P42, DOI 10.1080/10106049.2015.1041559
   Reduction I. S. F. D, 2004, LIV RISK GLOB REV DI, V0, P0
   Regmi AD, 2014, J MT SCI-ENGL, V11, P1266, DOI 10.1007/s11629-013-2847-6
   Rizeei HM, 2019, INT J DISAST RISK RE, V38, P0, DOI 10.1016/j.ijdrr.2019.101205
   Romero JP, 2012, PROCD SOC BEHV, V54, P646, DOI 10.1016/j.sbspro.2012.09.782
   Samanta RK, 2018, MODEL EARTH SYST ENV, V4, P395, DOI 10.1007/s40808-018-0427-z
   Sarkar D, 2020, APPL WATER SCI, V10, P0, DOI 10.1007/s13201-019-1102-x
   Seejata K, 2018, PROCEDIA ENGINEER, V212, P340, DOI 10.1016/j.proeng.2018.01.044
   SHERALI HD, 1991, TRANSPORT RES B-METH, V25, P439, DOI 10.1016/0191-2615(91)90037-J
   Siahkamari S, 2018, GEOCARTO INT, V33, P927, DOI 10.1080/10106049.2017.1316780
   Tehrany MS, 2019, PEERJ, V7, P0, DOI 10.7717/peerj.7653
   Tehrany MS, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7667-0
   Tehrany MS, 2015, STOCH ENV RES RISK A, V29, P1149, DOI 10.1007/s00477-015-1021-9
   Tingsanchali T, 2005, HYDROL PROCESS, V19, P2055, DOI 10.1002/hyp.5666
   Tong D, 2009, PAP REG SCI, V88, P85, DOI 10.1111/j.1435-5957.2008.00168.x
   Wahab A. M., 2018, IOP CONFERENCE SERIES: EARTH AND ENVIRONMENTAL SCIENCE, V169, P0, DOI 10.1088/1755-1315/169/1/012056
   Wahlstrom M., 2015, HUMAN COST WEATHER R, V0, P0
   Wang YM, 2011, WATER RESOUR MANAG, V25, P3465, DOI 10.1007/s11269-011-9866-2
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   WATERS SJ, 1972, COMPUT J, V15, P258, DOI 10.2307/2284760
   Whitfield PH, 2012, J FLOOD RISK MANAG, V5, P336, DOI 10.1111/j.1753-318X.2012.01150.x
   Xi M., 2013, J APPL MATH, V2013, P1
   Xiong JN, 2019, NAT HAZARD EARTH SYS, V19, P629, DOI 10.5194/nhess-19-629-2019
   Xu W, 2018, INT J GEOGR INF SCI, V32, P236, DOI 10.1080/13658816.2017.1395882
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Zavadskas E.K., 2010, SELECTION RATIONAL D, V0, P0
   Zavadskas EK, 2010, INZ EKON, V21, P32
   Zolfani SH, 2018, SOFT COMPUT, V22, P7399, DOI 10.1007/s00500-018-3092-2
NR 105
TC 30
Z9 30
U1 20
U2 84
PU CHINA UNIV GEOSCIENCES, BEIJING
PI HAIDIAN DISTRICT
PA 29 XUEYUAN RD, HAIDIAN DISTRICT, 100083, PEOPLES R CHINA
SN 1674-9871
EI 
J9 GEOSCI FRONT
JI Geosci. Front.
PD MAY 15
PY 2021
VL 12
IS 3
BP 
EP 
DI 10.1016/j.gsf.2020.09.022
PG 17
WC Geosciences, Multidisciplinary
SC Geology
GA RH8LS
UT WOS:000636463500013
DA 2023-04-26
ER

PT J
AU Abbas, S
   Peng, Q
   Wong, MS
   Li, ZL
   Wang, JC
   Ng, KTK
   Kwok, CYT
   Hui, KKW
AF Abbas, Sawaid
   Peng, Qian
   Wong, Man Sing
   Li, Zhilin
   Wang, Jicheng
   Ng, Kathy Tze Kwun
   Kwok, Coco Yin Tung
   Hui, Karena Ka Wai
TI Characterizing and classifying urban tree species using bi-monthly terrestrial hyperspectral images in Hong Kong
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Urban tree; Hyperspectral library; Tree species; Seasonality; Deep learning; SPECIM-IQ
ID chlorophyll fluorescence; imaging spectroscopy; ecosystem services; forest; classification; vegetation; lidar; reflectance; resolution; red
AB Urban trees exhibit a wide range of ecosystem services that have long been unveiled and increasingly reported. The ability to map tree species and analyze tree health conditions would become vividly essential. Remote sensing techniques, especially hyperspectral imaging, are being evolved for species identification and vegetation monitoring from spectral reponse patterns. In this study, a hyperspectral library for urban tree species in Hong Kong was established comprising 75 urban trees belonging to 19 species. 450 bi-monthly images were acquired by a terrestrial hyperspectral camera (SPECIM-IQ) from November 2018 to October 2019. A Deep Neural Network classification model was developed to identify tree species from the hyperspectral imagery with an overall accuracy ranging from 85% to 96% among different seasons. Representative spectral reflectance curves of healthy and unhealthy conditions for each species were extracted and analyzed. The hyperspectral phenology models were developed to achieve high accuracy and optimization of data acquisition. The bi-monthly canopy signatures and vegetation indices revealed different seasonality patterns of evergreen and deciduous species in Hong Kong. We explored the utility of terrestrial hyperspectral remote sensing and Deep Neural Network for urban tree species identification and characterizing. This provides a unique baseline to understand hyperspectral characteristics and seasonality of urban tree species in Hong Kong that can also contribute to hyperspectral imaging and database development elsewhere in the world.
C1 [Abbas, Sawaid; Peng, Qian; Wong, Man Sing; Li, Zhilin; Kwok, Coco Yin Tung; Hui, Karena Ka Wai] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Peoples R China.
   [Wong, Man Sing] Hong Kong Polytech Univ, Res Inst Sustainable Urban Dev, Hong Kong, Peoples R China.
   [Li, Zhilin] Southwest Jiaotong Univ, Fac Geosci & Environm Engn, Chengdu, Peoples R China.
   [Li, Zhilin] Southwest Jiaotong Univ, State Prov Joint Engn Lab Spatial Informat Techno, Chengdu, Peoples R China.
   [Wang, Jicheng] Sichuan Normal Univ, Minist Educ Land Resources Evaluat & Monitoring S, Key Lab, Chengdu, Peoples R China.
   [Ng, Kathy Tze Kwun] HKSAR Govt, Landscape Div, Highways Dept, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; Hong Kong Polytechnic University; Southwest Jiaotong University; Southwest Jiaotong University; Sichuan Normal University
RP Wong, MS (corresponding author), Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Peoples R China.
EM sabbas@polyu.edu.hk; qian.peng@connect.polyu.hk; Ls.charles@polyu.edu.hk; dean.ge@swjtu.edu.cn; wangjicheng123@sicnu.edu.cn; cla.lsc@hyd.gov.hk; yt-coco.kwok@connect.polyu.hk; karena.kw.hui@polyu.edu.hk
FU Highways Department under the project "Feasibility Study on Setting Up Spectral Library for Common Tree Species in HK"; Research Institute for Sustainable Urban Development, the Hong Kong Polytechnic University [1-BBWD]; PolyU (UGC) funding grant [1-ZVUU]
CR Aasen H, 2015, ISPRS J PHOTOGRAMM, V108, P245, DOI 10.1016/j.isprsjprs.2015.08.002
   Abbas S, 2021, SCI TOTAL ENVIRON, V752, P0, DOI 10.1016/j.scitotenv.2020.141760
   Alonzo M, 2014, REMOTE SENS ENVIRON, V148, P70, DOI 10.1016/j.rse.2014.03.018
   Arasumani M., 2021, TESTING EFFICACY HYP, V0, P0
   Asner GP, 2016, GLOB ECOL CONSERV, V8, P212, DOI 10.1016/j.gecco.2016.09.010
   Asner GP, 2015, REMOTE SENS-BASEL, V7, P3526, DOI 10.3390/rs70403526
   Asner GP, 2015, REMOTE SENS ENVIRON, V158, P15, DOI 10.1016/j.rse.2014.11.011
   Asner GP, 2014, NEW PHYTOL, V204, P127, DOI 10.1111/nph.12895
   Awad MM, 2018, J FORESTRY RES, V29, P1395, DOI 10.1007/s11676-017-0528-y
   Baldridge AM, 2009, REMOTE SENS ENVIRON, V113, P711, DOI 10.1016/j.rse.2008.11.007
   Ballanti L, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060445
   Behmann J, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18020441
   Ben-Dor E, 2002, INT J REMOTE SENS, V23, P1043, DOI 10.1080/01431160010006962
   Bezak P, 2008, ENVIRON SCI-TOKYO, V5, P161, DOI 10.1080/15693430802055524
   Bojinski S, 2003, COMPUT GEOSCI-UK, V29, P27, DOI 10.1016/S0098-3004(02)00107-3
   Bolund P, 1999, ECOL ECON, V29, P293, DOI 10.1016/S0921-8009(99)00013-0
   Buddenbaum H, 2005, INT J REMOTE SENS, V26, P5453, DOI 10.1080/01431160500285076
   Caughlin TT, 2016, ECOL APPL, V26, P2367, DOI 10.1002/eap.1436
   Cho H, 2014, KOREAN J REMOTE SENS, V30, P25, DOI 10.7780/kjrs.2014.30.1.3
   Cho MA, 2006, REMOTE SENS ENVIRON, V101, P181, DOI 10.1016/j.rse.2005.12.011
   Clark ML, 2020, ISPRS J PHOTOGRAMM, V159, P26, DOI 10.1016/j.isprsjprs.2019.11.007
   Cochrane MA, 2000, INT J REMOTE SENS, V21, P2075, DOI 10.1080/01431160050021303
   Cotrozzi L, 2017, TREE PHYSIOL, V37, P1582, DOI 10.1093/treephys/tpx106
   Dadon A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232800
   Dalponte M, 2012, REMOTE SENS ENVIRON, V123, P258, DOI 10.1016/j.rse.2012.03.013
   DeAth G, 2002, ECOLOGY, V83, P1105, DOI 10.2307/3071917
   Degerickx J, 2018, INT J APPL EARTH OBS, V73, P26, DOI 10.1016/j.jag.2018.05.021
   Delegido J, 2014, ECOL INDIC, V40, P34, DOI 10.1016/j.ecolind.2014.01.002
   EcoSIS N., 2014, ECOLOGICAL SPECTRAL, V2021, P0
   Escobedo FJ, 2011, ENVIRON POLLUT, V159, P2078, DOI 10.1016/j.envpol.2011.01.010
   Escobedo FJ, 2009, LANDSCAPE URBAN PLAN, V90, P102, DOI 10.1016/j.landurbplan.2008.10.021
   Fagan ME, 2015, REMOTE SENS-BASEL, V7, P5660, DOI 10.3390/rs70505660
   Ferreira MP, 2019, ISPRS J PHOTOGRAMM, V149, P119, DOI 10.1016/j.isprsjprs.2019.01.019
   Ferreira MP, 2016, REMOTE SENS ENVIRON, V179, P66, DOI 10.1016/j.rse.2016.03.021
   Gamon JA, 1997, OECOLOGIA, V112, P492, DOI 10.1007/s004420050337
   GAMON JA, 1992, REMOTE SENS ENVIRON, V41, P35, DOI 10.1016/0034-4257(92)90059-S
   Ghosh G, 2012, J INDIAN SOC REMOTE, V40, P129, DOI 10.1007/s12524-011-0143-x
   Gomez-Baggethun Erik, 2013, P175, V0, P0
   Gong P, 1997, REMOTE SENS ENVIRON, V62, P189, DOI 10.1016/S0034-4257(97)00094-1
   Goswami S., 2015, DEV WEB BASED VEGETA, V0, P0
   Goswami S, 2011, MONITORING ECOSYSTEM, V0, P0
   Halme E, 2019, INT J APPL EARTH OBS, V83, P0, DOI 10.1016/j.jag.2019.101942
   Hartling S, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19061284
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Irteza SM, 2021, EARTH SYST ENVIRON, V5, P127, DOI 10.1007/s41748-020-00175-5
   Jensen RR, 2012, GEOCARTO INT, V27, P443, DOI 10.1080/10106049.2011.638989
   Katkovsky LV, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111698
   Kothari S, 2018, PHOTOSYNTHETICA, V56, P455, DOI 10.1007/s11099-018-0777-9
   KRAUSE GH, 1991, ANNU REV PLANT PHYS, V42, P313, DOI 10.1146/annurev.pp.42.060191.001525
   Laurin GV, 2016, REMOTE SENS ENVIRON, V176, P163, DOI 10.1016/j.rse.2016.01.017
   Laurin GV, 2014, ISPRS J PHOTOGRAMM, V89, P49, DOI 10.1016/j.isprsjprs.2014.01.001
   Leckie DG, 2005, CAN J REMOTE SENS, V31, P175, DOI 10.5589/m05-004
   Lee J, 2016, IEEE J-STARS, V9, P2554, DOI 10.1109/JSTARS.2016.2569408
   Lin CS, 2018, ISPRS J PHOTOGRAMM, V142, P174, DOI 10.1016/j.isprsjprs.2018.05.022
   Liu LX, 2017, REMOTE SENS ENVIRON, V200, P170, DOI 10.1016/j.rse.2017.08.010
   Maselli F, 2004, REMOTE SENS ENVIRON, V89, P423, DOI 10.1016/j.rse.2003.10.020
   Migliavacca M, 2017, NEW PHYTOL, V214, P1078, DOI 10.1111/nph.14437
   Miyoshi GT, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020244
   Modzelewska A., 1900, P1, V0, P0
   Nijland W, 2014, AGR FOREST METEOROL, V184, P98, DOI 10.1016/j.agrformet.2013.09.007
   Nowak David J., 2008, ARBORICULTURE & URBAN FORESTRY, V34, P347
   Osco LP, 2020, ISPRS J PHOTOGRAMM, V160, P97, DOI 10.1016/j.isprsjprs.2019.12.010
   Paz-Kagan T, 2017, ECOL APPL, V27, P1466, DOI 10.1002/eap.1540
   Pettorelli N, 2005, TRENDS ECOL EVOL, V20, P503, DOI 10.1016/j.tree.2005.05.011
   Rossini M, 2015, GEOPHYS RES LETT, V42, P1632, DOI 10.1002/2014GL062943
   Schaepman M.E., 1998, CALIBRATION FIELD SP, V31, P146
   Schiefer F, 2020, ISPRS J PHOTOGRAMM, V170, P205, DOI 10.1016/j.isprsjprs.2020.10.015
   Shen Q, 2021, ENVIRON RES LETT, V16, P0, DOI 10.1088/1748-9326/abd2f1
   Shi YF, 2021, INT J APPL EARTH OBS, V98, P0, DOI 10.1016/j.jag.2021.102311
   Thenkabail P., 2019, GLOBAL HYPERSPECTRAL, V0, P0
   Thenkabail P.S., 2018, BIOPHYSICAL BIOCH CH, V0, P0
   Townsend PA, 2003, IEEE T GEOSCI REMOTE, V41, P1347, DOI 10.1109/TGRS.2003.813205
   Tratalos J, 2007, LANDSCAPE URBAN PLAN, V83, P308, DOI 10.1016/j.landurbplan.2007.05.003
   Trier OD, 2018, EUR J REMOTE SENS, V51, P336, DOI 10.1080/22797254.2018.1434424
   TUCKER CJ, 1986, INT J REMOTE SENS, V7, P1395, DOI 10.1080/01431168608948944
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Wan H., 1900, V13, V0, P1
   Wu J, 2016, SCIENCE, V351, P972, DOI 10.1126/science.aad5068
   Wu SB, 2021, ISPRS J PHOTOGRAMM, V171, P36, DOI 10.1016/j.isprsjprs.2020.10.017
   Xue JR, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/1353691
   Yan WY, 2020, ISPRS J PHOTOGRAMM, V169, P152, DOI 10.1016/j.isprsjprs.2020.09.001
   Zarco-Tejada PJ, 2001, IEEE T GEOSCI REMOTE, V39, P1491, DOI 10.1109/36.934080
   Zarco-Tejada PJ, 2000, REMOTE SENS ENVIRON, V74, P596, DOI 10.1016/S0034-4257(00)00149-8
   Zhang N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12193188
   Zhang XF, 2013, INT J APPL EARTH OBS, V21, P506, DOI 10.1016/j.jag.2012.07.003
NR 85
TC 13
Z9 13
U1 19
U2 69
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG 15
PY 2021
VL 177
IS 
BP 204
EP 216
DI 10.1016/j.isprsjprs.2021.05.003
EA MAY 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SR3ZD
UT WOS:000660980400014
DA 2023-04-26
ER

PT J
AU Robinson, C
   Malkin, K
   Jojic, N
   Chen, HJ
   Qin, RJ
   Xiao, CL
   Schmitt, M
   Ghamisi, P
   Hansch, R
   Yokoya, N
AF Robinson, Caleb
   Malkin, Kolya
   Jojic, Nebojsa
   Chen, Huijun
   Qin, Rongjun
   Xiao, Changlin
   Schmitt, Michael
   Ghamisi, Pedram
   Haensch, Ronny
   Yokoya, Naoto
TI Global Land-Cover Mapping With Weak Supervision: Outcome of the 2020 IEEE GRSS Data Fusion Contest
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Earth; Data integration; Remote sensing; Satellites; Training; Tensors; Synthetic aperture radar; Convolutional neural networks (CNNs); deep learning; image analysis and data fusion; land-cover mapping; multimodal; random forests (RFs); weak supervision
AB This article presents the scientific outcomes of the 2020 Data Fusion Contest (DFC2020) organized by the Image Analysis and Data Fusion Technical Committee of the IEEE Geoscience and Remote Sensing Society. The 2020 Contest addressed the problem of automatic global land-cover mapping with weak supervision, i.e., estimating high-resolution semantic maps while only low-resolution reference data are available during training. Two separate competitions were organized to assess two different scenarios: 1) high-resolution labels are not available at all; and 2) a small amount of high-resolution labels are available additionally to low-resolution reference data. In this article, we describe the DFC2020 dataset that remains available for further evaluation of corresponding approaches and report the results of the best-performing methods during the contest.
C1 [Robinson, Caleb] Georgia Inst Technol, Sch Computat Sci & Engn, Atlanta, GA 30332 USA.
   [Robinson, Caleb] Microsoft Res, AI Good Res Lab, Redmond, WA 98052 USA.
   [Malkin, Kolya] Yale Univ, Dept Math, New Haven, CT 06520 USA.
   [Jojic, Nebojsa] Microsoft Res, Redmond, WA 98052 USA.
   [Chen, Huijun; Xiao, Changlin] Ohio State Univ, Dept Civil Environm & Geodet Engn, Columbus, OH 43210 USA.
   [Chen, Huijun] Ohio State Univ, Environm Sci Grad Program, Columbus, OH 43210 USA.
   [Qin, Rongjun] Ohio State Univ, Dept Civil Environm & Geodet Engn, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
   [Qin, Rongjun] Ohio State Univ, Translat Data Analyt Inst, Columbus, OH 43210 USA.
   [Schmitt, Michael] Munich Univ Appl Sci, Dept Geoinformat, D-80335 Munich, Germany.
   [Ghamisi, Pedram] Helmholtz Zentrum Dresden Rossendorf, Machine Learning Grp, Helmholtz Inst Freiberg Resource Technol, D-09599 Freiberg, Germany.
   [Haensch, Ronny] German Aerosp Ctr, D-82234 Wessling, Germany.
   [Yokoya, Naoto] Univ Tokyo, Dept Complex Sci & Engn, Chiba 2778561, Japan.
   [Yokoya, Naoto] RIKEN Ctr Adv Intelligence Project, Tokyo 1030027, Japan.
C3 University System of Georgia; Georgia Institute of Technology; Microsoft; Yale University; Microsoft; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; University of Munich; Helmholtz Association; Helmholtz-Zentrum Dresden-Rossendorf (HZDR); Helmholtz Association; German Aerospace Centre (DLR); University of Tokyo; RIKEN
RP Yokoya, N (corresponding author), Univ Tokyo, Dept Complex Sci & Engn, Chiba 2778561, Japan.
EM drobinson67@gatech.edu; kolya_malkin@hotmail.com; jojic@microsoft.com; chen.9317@osu.edu; qin.324@osu.edu; changlinshaw@gmail.com; michael.schtnitt@hm.edu; p.ghamisi@gmail.com; rww.haensch@gmail.com; yokoya@k.u-tokyo.ac.jp
FU Office of Naval Research [N000141712928]
CR Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   Anderson K, 2017, GEO-SPAT INF SCI, V20, P77, DOI 10.1080/10095020.2017.1333230
   Berger C, 2013, IEEE J-STARS, V6, P1324, DOI 10.1109/JSTARS.2013.2245860
   Bgybkndlmah Ballantyne, 2020, LANDCOVERNET GLOBAL, V0, P0, DOI DOI 10.34911/rdnt.d2ce8i
   Campos-Taberner M, 2016, IEEE J-STARS, V9, P5547, DOI 10.1109/JSTARS.2016.2569162
   Cerra al D., 2020, P IEEE INT GEOSC REM, V0, P0
   Cerra D., 2020, P IEEE INT GEOSC REM, V0, P0
   Chen H., 2020, P IEEE INT GEOSC REM, V0, P0
   Debes C, 2014, IEEE J-STARS, V7, P2405, DOI 10.1109/JSTARS.2014.2305441
   Di Gregorio A., 2005, LAND COVER CLASSIFIC, V0, P0
   Dong SW, 2020, REMOTE SENS LETT, V11, P11, DOI 10.1080/2150704X.2019.1677966
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Friedl M., 2019, MCD12Q1 MODISTERRA A, V0, P0, DOI DOI 10.5067/MODIS/MCD12Q1.006
   Ghamisi P, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2018.2890023
   Gong P, 2019, SCI BULL, V64, P370, DOI 10.1016/j.scib.2019.03.002
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Le Saux B, 2019, IEEE GEOSC REM SEN M, V7, P103, DOI 10.1109/MGRS.2019.2893783
   Liao WZ, 2015, IEEE J-STARS, V8, P2984, DOI 10.1109/JSTARS.2015.2420582
   Licciardi G, 2009, IEEE T GEOSCI REMOTE, V47, P3857, DOI 10.1109/TGRS.2009.2029340
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Loveland TR, 1997, ACTA ASTRONAUT, V41, P681, DOI 10.1016/S0094-5765(98)00050-2
   Malkin Nikolay, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12371), V0, PP531, DOI 10.1007/978-3-030-58574-7_32
   Mou L, 2017, IEEE J-STARS, V10, P3435, DOI 10.1109/JSTARS.2017.2696823
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Pacifici F, 2008, IEEE GEOSCI REMOTE S, V5, P331, DOI 10.1109/LGRS.2008.915939
   Pacifici F, 2012, IEEE J-STARS, V5, P3, DOI 10.1109/JSTARS.2012.2186733
   Robinson C., 2020, P IEEE INT GEOSC REM, V0, P0
   Schmitt M., 2020, P ISPRS ANN PHOT REM, VV-3-2020, P795
   Schmitt M., 2019, ISPRS ANN PHOTOGRAMM, V0, P0, DOI DOI 10.5194/isprs-annals-IV-2-W7-153-2019(
   Schmitt M, 2016, IEEE GEOSC REM SEN M, V4, P6, DOI 10.1109/MGRS.2016.2561021
   Sulla-Menashe D, 2019, REMOTE SENS ENVIRON, V222, P183, DOI 10.1016/j.rse.2018.12.013
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   Ulyanov D, 2018, PROC CVPR IEEE, V0, PP9446, DOI 10.1109/CVPR.2018.00984
   Vo AV, 2016, IEEE J-STARS, V9, P5560, DOI 10.1109/JSTARS.2016.2581843
   Xia Y., 2020, P IEEE INT GEOSC REM, V0, P0
   Xu YH, 2019, IEEE J-STARS, V12, P1709, DOI 10.1109/JSTARS.2019.2911113
   Yin S, 2020, P IEEE INT GEOSC REM, V0, P0
   Yokoya N, 2020, IEEE GEOSC REM SEN M, V8, P134, DOI 10.1109/MGRS.2020.3033515
   Yokoya N, 2020, IEEE GEOSC REM SEN M, V8, P154, DOI 10.1109/MGRS.2020.2970124
   Yokoya N, 2018, IEEE J-STARS, V11, P1363, DOI 10.1109/JSTARS.2018.2799698
NR 40
TC 18
Z9 18
U1 1
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3185
EP 3199
DI 10.1109/JSTARS.2021.3063849
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RE9UV
UT WOS:000634496000007
DA 2023-04-26
ER

PT J
AU Napoles, G
   Jastrzebska, A
   Salgueiro, Y
AF Napoles, Gonzalo
   Jastrzebska, Agnieszka
   Salgueiro, Yamisleydi
TI Pattern classification with Evolving Long-term Cognitive Networks
SO INFORMATION SCIENCES
LA English
DT Article
DE Long-term Cognitive Networks; Recurrent neural networks; Backpropagation; Interpretability
ID neural-networks; statistical comparisons; fuzzy; maps; classifiers; extension; time
AB This paper presents an interpretable neural system-termed Evolving Long-term Cognitive Network-for pattern classification. The proposed model was inspired by Fuzzy Cognitive Maps, which are interpretable recurrent neural networks for modeling and simulation. The network architecture is comprised of two neural blocks: a recurrent input layer and an output layer. The input layer is a Long-term Cognitive Network that gets unfolded in the same way as other recurrent neural networks, thus producing a sort of abstract hidden layers. In our model, we can attach meaningful linguistic labels to each neuron since the input neurons correspond to features in a given classification problem and the output neurons correspond to class labels. Moreover, we propose a variant of the backpropagation learning algorithm to compute the required parameters. This algorithm includes two new regularization components that are aimed at obtaining more interpretable knowledge representations. The numerical simulations using 58 datasets show that our model achieves higher prediction rates when compared with traditional white boxes while remaining competitive with the black boxes. Finally, we elaborate on the interpretability of our neural system using a proof of concept. (c) 2020 The Authors. Published by Elsevier Inc.
C1 [Napoles, Gonzalo] Hasselt Univ, Fac Business Econ, Hasselt, Belgium.
   [Napoles, Gonzalo] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
   [Jastrzebska, Agnieszka] Warsaw Univ Technol, Fac Math & Informat Sci, Warsaw, Poland.
   [Salgueiro, Yamisleydi] Univ Talca, Dept Comp Sci, Fac Engn, Campus Curico, Talca, Chile.
C3 Hasselt University; Tilburg University; Warsaw University of Technology; Universidad de Talca
RP Napoles, G (corresponding author), Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
EM g.r.napoles@uvt.nl
FU Special Research Fund (BOF) of Hasselt University, Belgium [BOF20KV01]; National Science Centre [2019/35/D/HS4/01594, DEC-2019/35/D/HS4/01594]
CR Alcala-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   Amirkhani A, 2014, ARAB J SCI ENG, V39, P3723, DOI 10.1007/s13369-014-1012-z
   Bhutani K, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), V0, PP305, DOI 10.1109/ICACEA.2015.7164720
   Christodoulou P., 2017, FUZZ SYST FUZZ IEEE, V0, PP1, DOI 10.1109/FUZZ-IEEE.2017.8015422
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Duda R. O., 2012, PATTERN CLASSIFICATI, V0, P0
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Froelich W, 2017, KNOWL-BASED SYST, V115, P110, DOI 10.1016/j.knosys.2016.10.017
   Garcia S, 2008, J MACH LEARN RES, V9, P2677
   Guo KR, 2019, INT J FUZZY SYST, V21, P263, DOI 10.1007/s40815-018-0567-3
   Han HG, 2017, NEUROCOMPUTING, V242, P51, DOI 10.1016/j.neucom.2017.02.038
   Hanson S. J., 1989, ADV NEURAL INFORM PR, V0, P177
   Hardy NF, 2018, NEURAL COMPUT, V30, P378, DOI 10.1162/neco_a_01041
   Huang W, 2017, IEEE T FUZZY SYST, V25, P1329, DOI 10.1109/TFUZZ.2016.2612267
   Japkowicz N., 2011, EVALUATING LEARNING, V0, P0, DOI DOI 10.1017/CBO9780511921803
   Kannappan A, 2013, IEEE INT CONF FUZZY, V0, P0, DOI DOI 10.1109/FUZZ-IEEE.2013.6622567
   Kim EH, 2018, IEEE T FUZZY SYST, V26, P3054, DOI 10.1109/TFUZZ.2017.2785244
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   Lichman M, 2013, UCI MACHINE LEARNING, V0, P0
   Liu P, 2016, IEEE T SYST MAN CY-S, V46, P512, DOI 10.1109/TSMC.2015.2461191
   Lopez-Rubio E, 2019, NEURAL PROCESS LETT, V50, P121, DOI 10.1007/s11063-018-09974-4
   Loshchilov I., 2019, PROC INT C LEARN REP, V0, P0
   Maji P., 1900, V20, V0, P0
   Marquez BA, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-21624-2
   Nair A, 2020, APPL SOFT COMPUT, V92, P0, DOI 10.1016/j.asoc.2020.106309
   Napoles G., 2019, IEEE T NEURAL NETWOR, V31, P865
   Napoles G, 2020, NEURAL NETWORKS, V124, P258, DOI 10.1016/j.neunet.2020.01.019
   Napoles G, 2021, IEEE T CYBERNETICS, V51, P686, DOI 10.1109/TCYB.2019.2913960
   Napoles G, 2019, NEURAL NETWORKS, V115, P72, DOI 10.1016/j.neunet.2019.03.012
   Napoles G, 2018, STUD FUZZ SOFT COMP, V360, P83, DOI 10.1007/978-3-319-64286-4_5
   Napoles G, 2018, NEURAL NETWORKS, V97, P19, DOI 10.1016/j.neunet.2017.08.007
   Natarajan R, 2016, COMPUT ELECTRON AGR, V127, P147, DOI 10.1016/j.compag.2016.05.016
   Pajares G, 2011, LECT NOTES COMPUT SC, V6915, P103, DOI 10.1007/978-3-642-23687-7_10
   Papageorgiou EI, 2012, APPL SOFT COMPUT, V12, P3798, DOI 10.1016/j.asoc.2012.03.064
   Papakostas GA, 2012, EXPERT SYST APPL, V39, P10620, DOI 10.1016/j.eswa.2012.02.148
   Salmeron JL, 2019, IEEE T CYBERNETICS, V49, P211, DOI 10.1109/TCYB.2017.2771387
   Scarselli F, 1998, NEURAL NETWORKS, V11, P15, DOI 10.1016/S0893-6080(97)00097-X
   Song HJJ, 2011, IEEE T FUZZY SYST, V19, P116, DOI 10.1109/TFUZZ.2010.2087383
   Vargas JAR, 2019, NEUROCOMPUTING, V329, P86, DOI 10.1016/j.neucom.2018.10.008
   Wang JY, 2018, IEEE T NEUR NET LEAR, V29, P1652, DOI 10.1109/TNNLS.2017.2677968
   WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269
NR 43
TC 4
Z9 4
U1 1
U2 11
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD FEB 16
PY 2021
VL 548
IS 
BP 461
EP 478
DI 10.1016/j.ins.2020.08.058
PG 18
WC Computer Science, Information Systems
SC Computer Science
GA PB0SI
UT WOS:000596037700010
DA 2023-04-26
ER

PT J
AU Xiong, P
   Zhai, DL
   Long, C
   Zhou, HY
   Zhang, XM
   Shen, XH
AF Xiong, Pan
   Zhai, Dulin
   Long, Cheng
   Zhou, Huiyu
   Zhang, Xuemin
   Shen, Xuhui
TI Long Short-Term Memory Neural Network for Ionospheric Total Electron Content Forecasting Over China
SO SPACE WEATHER-THE INTERNATIONAL JOURNAL OF RESEARCH AND APPLICATIONS
LA English
DT Article
DE GPS&#8208; TEC modeling; GPS&#8208; TEC prediction; ionosphere; long short&#8208; term memory neural network
ID content maps; tec; prediction; model; solar; algorithm; station; bias; lstm
AB An increasing number of terrestrial- and space-based radio-communication systems are influenced by the ionospheric space weather, making the ionospheric state increasingly important to forecast. In this study, a novel extended encoder-decoder long short-term memory extended (ED-LSTME) neural network, which can predict ionospheric total electron content (TEC) is proposed. Useful inherent features were automatically extracted from the historical TEC by LSTM layers, and the performance of the proposed model was enhanced by considering solar flux and geomagnetic activity data. The proposed ED-LSTME model was validated using 15-min TEC values from GPS measurements over one solar cycle (from January 2006 to July 2018) collected at 15 GPS stations in China. Different assessment experiments were conducted in different geographical locations and seasons as well as under varying geomagnetic activities, to comprehensively evaluate the model's performance. These comparative experiments were conducted using an ED-LSTM, a traditional LSTM, a deep neural network, autoregressive integrated moving average, and the 2016 International Reference Ionosphere models. The results indicated that the ED-LSTME model is superior to the other statistical models, with R-2 and root mean square error values of 0.89 and 12.09 TECU, respectively. In addition, TEC was adequately predicted under different ionospheric conditions, and satisfactory results were obtained even under geomagnetically disturbed conditions. These results suggest that the prediction performance could be significantly improved by utilizing auxiliary data. These observations confirm that the proposed model outperforms several state-of-the-art models in making predictions at different times and under diverse conditions.
C1 [Xiong, Pan; Zhang, Xuemin] China Earthquake Adm, Inst Earthquake Forecasting, Beijing, Peoples R China.
   [Zhai, Dulin] China Earthquake Adm, Key Lab Earthquake Geodesy, Inst Seismol, Wuhan, Peoples R China.
   [Long, Cheng] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Zhou, Huiyu] Univ Leicester, Sch Informat, Leicester, Leics, England.
   [Shen, Xuhui] Minist Emergency Management China, Natl Inst Nat Hazards, Beijing, Peoples R China.
C3 China Earthquake Administration; China Earthquake Administration; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Leicester
RP Shen, XH (corresponding author), Minist Emergency Management China, Natl Inst Nat Hazards, Beijing, Peoples R China.
EM shenxh@seis.ac.cn
FU National Key R&D Program of China [2018YFC1503505]; Special Fund of the Institute of Earthquake Forecasting, China Earthquake Administration [2020IEF0510, 2020IEF0705]
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Acharya R, 2011, ADV SPACE RES, V47, P115, DOI 10.1016/j.asr.2010.08.016
   Afraimovich EL, 2001, J ATMOS SOL-TERR PHY, V63, P1841, DOI 10.1016/S1364-6826(01)00060-8
   Badeke R, 2018, ADV SPACE RES, V61, P2881, DOI 10.1016/j.asr.2018.04.010
   Bartels J., 1949, J GEOPHYS RES, V54, P295, DOI 10.1029/JZ054i003p00295
   Belehaki A, 2009, SPACE SCI REV, V147, P271, DOI 10.1007/s11214-009-9510-0
   Bent R.B., 1975, EFFECT IONOSPHERE SP, V1, P13
   Bilitza D, 2017, SPACE WEATHER, V15, P418, DOI 10.1002/2016SW001593
   Bilitza D, 2001, RADIO SCI, V36, P261, DOI 10.1029/2000RS002432
   Bilitza D, 2018, ADV RADIO SCI, V16, P1, DOI 10.5194/ars-16-1-2018
   Blagoveshchensky DV, 2018, ANN GEOPHYS-GERMANY, V36, P1057, DOI 10.5194/angeo-36-1057-2018
   Castaings T, 2017, P C BIG DAT SPAC BID, V0, P0
   Chen Z, 2019, J GEOPHYS RES-SPACE, V124, P790, DOI 10.1029/2018JA026167
   Choi BK, 2011, ADV SPACE RES, V47, P1590, DOI 10.1016/j.asr.2010.12.021
   Chollet F, 2018, DEEP LEARNING PYTHON, V0, P0
   Chollet F, 2015, KERAS, V0, P0
   Bui DT, 2020, SCI TOTAL ENVIRON, V701, P0, DOI 10.1016/j.scitotenv.2019.134413
   Elmunim NA, 2017, ADV SPACE RES, V60, P276, DOI 10.1016/j.asr.2016.07.025
   Elvidge S, 2014, RADIO SCI, V49, P737, DOI 10.1002/2014RS005435
   Feizi R., 2020, ADV SPACE RES, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Goodman J.M., 1992, HF COMMUNICATION SCI, V0, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Gulcehre C., 2014, P EMNLP C, V0, P0
   Habarulema JB, 2007, J ATMOS SOL-TERR PHY, V69, P1842, DOI 10.1016/j.jastp.2007.09.002
   Habarulema JB, 2011, J GEOPHYS RES-SPACE, V116, P0, DOI 10.1029/2010JA016269
   Hernandez-Pajares M, 2012, SPACE WEATHER, V10, P0, DOI 10.1029/2012SW000826
   Hernandez-Pajares M, 2011, J GEODESY, V85, P887, DOI 10.1007/s00190-011-0508-5
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochegger G, 2000, PHYS CHEM EARTH PT C, V25, P307, DOI 10.1016/S1464-1917(00)00022-2
   Hu YL, 2018, ENERG CONVERS MANAGE, V173, P123, DOI 10.1016/j.enconman.2018.07.070
   Huang Z, 2015, ADV SPACE RES, V55, P1775, DOI 10.1016/j.asr.2015.01.026
   Huang Z, 2014, RADIO SCI, V49, P283, DOI 10.1002/2013RS005247
   Hyndman R.J., 2018, FORECASTING PRINCIPL, V0, P0
   Hyndman RJ, 2008, J STAT SOFTW, V27, P1, DOI 10.18637/jss.v027.i03
   Kaselimi M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091354
   Kersley L., 2004, ANN GEOPHYS-ITALY, V47, P0
   Krankowski A, 2005, J ATMOS SOL-TERR PHY, V67, P1147, DOI 10.1016/j.jastp.2005.03.004
   Kumar S, 2010, J PHYS CONF SER, V208, P0, DOI 10.1088/1742-6596/208/1/012062
   Li J., 2020, ADV SPACE RES, V0, P0
   Li ZS, 2012, J GEODESY, V86, P1059, DOI 10.1007/s00190-012-0565-4
   Ma G, 2003, ANN GEOPHYS-GERMANY, V21, P2083, DOI 10.5194/angeo-21-2083-2003
   Makridakis S, 1997, J FORECASTING, V16, P147, DOI 10.1002/(SICI)1099-131X(199705)16:3<147::AID-FOR652>3.0.CO;2-X
   Mannucci AJ, 1998, RADIO SCI, V33, P565, DOI 10.1029/97RS02707
   Moreno EM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10070988
   Moritz S., 2016, **DATA OBJECT**, V0, P0
   Mukesh R, 2020, ASTROPHYS SPACE SCI, V365, P0, DOI 10.1007/s10509-020-3730-x
   Mukhtarov P, 2014, J ATMOS SOL-TERR PHY, V119, P1, DOI 10.1016/j.jastp.2014.05.009
   Nava B, 2011, RADIO SCI, V46, P0, DOI 10.1029/2010RS004635
   Nava B, 2008, J ATMOS SOL-TERR PHY, V70, P1856, DOI 10.1016/j.jastp.2008.01.015
   Okoh D, 2016, GEOD GEODYN, V7, P19, DOI 10.1016/j.geog.2016.03.003
   Pei SP, 2019, NAT GEOSCI, V12, P387, DOI 10.1038/s41561-019-0347-1
   Perez RO, 2019, ADV SPACE RES, V63, P1607, DOI 10.1016/j.asr.2018.11.011
   Purohit PK, 2015, J PHYS CONF SER, V640, P0, DOI 10.1088/1742-6596/640/1/012072
   Qi L, 2014, ACTA GEODAETICA CART, V43, P118
   Qing XY, 2018, ENERGY, V148, P461, DOI 10.1016/j.energy.2018.01.177
   RAWER K, 1978, REV GEOPHYS, V16, P177, DOI 10.1029/RG016i002p00177
   Razin MRG, 2020, GPS SOLUT, V24, P0, DOI 10.1007/s10291-020-0964-6
   Razin MRG, 2016, J ATMOS SOL-TERR PHY, V149, P21, DOI 10.1016/j.jastp.2016.09.005
   Razin MRG, 2016, ACTA GEOD GEOPHYS, V51, P541, DOI 10.1007/s40328-015-0143-3
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Ruwali A, 2021, IEEE GEOSCI REMOTE S, V18, P1004, DOI 10.1109/LGRS.2020.2992633
   SAMARDJIEV T, 1993, ELECTRON LETT, V29, P1794, DOI 10.1049/el:19931194
   Song R, 2018, ADV SPACE RES, V62, P745, DOI 10.1016/j.asr.2018.03.043
   Srivani I, 2019, IEEE GEOSCI REMOTE S, V16, P1180, DOI 10.1109/LGRS.2019.2895112
   Sutskever I., 2014, P 27 INT C NEUR INF, V2, P0
   Tang RX, 2020, ATMOSPHERE-BASEL, V11, P0, DOI 10.3390/atmos11040316
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Tebabal A, 2019, J ATMOS SOL-TERR PHY, V191, P0, DOI 10.1016/j.jastp.2019.05.016
   Tebabal A, 2018, J ATMOS SOL-TERR PHY, V172, P143, DOI 10.1016/j.jastp.2018.03.004
   Uwamahoro JC, 2015, J GEOPHYS RES-SPACE, V120, P11000, DOI 10.1002/2015JA021961
   Verkhoglyadova OP, 2013, ANN GEOPHYS-GERMANY, V31, P263, DOI 10.5194/angeo-31-263-2013
   Watthanasangmechai K, 2012, EARTH PLANETS SPACE, V64, P473, DOI 10.5047/eps.2011.05.025
   Xiong B, 2016, ADV SPACE RES, V58, P867, DOI 10.1016/j.asr.2016.05.033
   Xiong B, 2014, SPACE WEATHER, V12, P29, DOI 10.1002/2013SW001000
   Yang G, 2020, ATMOSPHERE-BASEL, V11, P0, DOI 10.3390/atmos11040348
   Yuan YB, 2015, GEOD GEODYN, V6, P73, DOI 10.1016/j.geog.2015.01.004
   [翟笃林 Zhai Dulin], 2019, 地震 EARTHQUAKE, V39, P46
   Zhang XH, 2013, CHINESE J GEOPHYS-CH, V56, P441, DOI 10.6038/cjg20130208
   Zhao Z, 2017, IET INTELL TRANSP SY, V11, P68, DOI 10.1049/iet-its.2016.0208
   Zhukov AV, 2021, GPS SOLUT, V25, P0, DOI 10.1007/s10291-020-01055-1
   Zivot E., 2003, MODELING FINANCIAL T, V0, P299
NR 82
TC 28
Z9 30
U1 7
U2 30
PU AMER GEOPHYSICAL UNION
PI WASHINGTON
PA 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA
SN 
EI 1542-7390
J9 SPACE WEATHER
JI Space Weather
PD APR 15
PY 2021
VL 19
IS 4
BP 
EP 
DI 10.1029/2020SW002706
PG 20
WC Astronomy & Astrophysics; Geochemistry & Geophysics; Meteorology & Atmospheric Sciences
SC Astronomy & Astrophysics; Geochemistry & Geophysics; Meteorology & Atmospheric Sciences
GA RT6XS
UT WOS:000644602700010
DA 2023-04-26
ER

PT J
AU Kavhu, B
   Mashimbye, ZE
   Luvuno, L
AF Kavhu, Blessing
   Mashimbye, Zama Eric
   Luvuno, Linda
TI Climate-Based Regionalization and Inclusion of Spectral Indices for Enhancing Transboundary Land-Use/Cover Classification Using Deep Learning and Machine Learning
SO REMOTE SENSING
LA English
DT Article
DE machine learning; ratio-based indices; orthogonal indices; Koppen-Geiger climate regionalization; landscape change; remote sensing; landcover
ID feature-selection techniques; thematic mapper data; cover classification; random forest; neural-networks; use/land cover; soil; landscape; accuracy; imagery
AB Accurate land use and cover data are essential for effective land-use planning, hydrological modeling, and policy development. Since the Okavango Delta is a transboundary Ramsar site, managing natural resources within the Okavango Basin is undoubtedly a complex issue. It is often difficult to accurately map land use and cover using remote sensing in heterogeneous landscapes. This study investigates the combined value of climate-based regionalization and integration of spectral bands with spectral indices to enhance the accuracy of multi-temporal land use/cover classification using deep learning and machine learning approaches. Two experiments were set up, the first entailing the integration of spectral bands with spectral indices and the second involving the combined integration of spectral indices and climate-based regionalization based on Koppen-Geiger climate zones. Landsat 5 TM and Landsat 8 OLI images, machine learning classifiers (random forest and extreme gradient boosting), and deep learning (neural network and deep neural network) classifiers were used in this study. Supervised classification using a total of 5140 samples was conducted for the years 1996, 2004, 2013, and 2020. Average overall accuracy and Kappa coefficients were used to validate the results. The study found that the integration of spectral bands with indices improves the accuracy of land use/cover classification using machine learning and deep learning. Post-feature selection combinations yield higher accuracies in comparison to combinations of bands and indices. A combined integration of spectral indices with bands and climate-based regionalization did not significantly improve the accuracy of land use/cover classification consistently for all the classifiers (p < 0.05). However, post-feature selection combinations and climate-based regionalization significantly improved the accuracy for all classifiers investigated in this study. Findings of this study will improve the reliability of land use/cover monitoring in complex heterogeneous TDBs.
C1 [Kavhu, Blessing; Mashimbye, Zama Eric] Stellenbosch Univ, Dept Geog & Environm Studies, Private Bag X1, ZA-7602 Matieland, South Africa.
   [Kavhu, Blessing; Luvuno, Linda] Stellenbosch Univ, Ctr Sustainabil Transit, ZA-7600 Stellenbosch, South Africa.
   [Kavhu, Blessing] Zimbabwe Pk & Wildlife Management Author, Sci Serv Unit, POB CY 140, Harare, Zimbabwe.
C3 Stellenbosch University; Stellenbosch University
RP Kavhu, B (corresponding author), Stellenbosch Univ, Dept Geog & Environm Studies, Private Bag X1, ZA-7602 Matieland, South Africa.; Kavhu, B (corresponding author), Stellenbosch Univ, Ctr Sustainabil Transit, ZA-7600 Stellenbosch, South Africa.; Kavhu, B (corresponding author), Zimbabwe Pk & Wildlife Management Author, Sci Serv Unit, POB CY 140, Harare, Zimbabwe.
EM 24580538@sun.ac.za; ericm@sun.ac.za; luvunol@sun.ac.za
FU USAID Resilient Waters [72067418C00007]
CR Abdi AM, 2020, GISCI REMOTE SENS, V57, P1, DOI 10.1080/15481603.2019.1650447
   Abdullah AM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070790
   Aburas MM, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7330-6
   [Anonymous], 2014, R LANGUAGE ENV STAT, V0, P0
   [Anonymous], 2003, CATEGORICAL DATA ANA, V0, P0
   Arino O., 2010, P ESA LIV PLAN S BER, V0, P1
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Avogo W, 2008, J BIOSOC SCI, V40, P725, DOI 10.1017/S0021932007002702
   Azgin ST, 2020, WATER RESOUR+, V47, P828, DOI 10.1134/S0097807820050206
   Baig MHA, 2014, REMOTE SENS LETT, V5, P423, DOI 10.1080/2150704X.2014.915434
   Barraque B., 2006, HDOCPA200621 UNDP, V0, P0
   Beck HE, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2018.214
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Beysolow Y., 2017, INTRO DEEP LEARNING, V0, P0, DOI DOI 10.1007/978-1-4842-2734-3
   Bhattarai KK, 2020, ECOSYST SERV, V45, P0, DOI 10.1016/j.ecoser.2020.101184
   Breiman L., 1984, CLASSIFICATION REGRE, V0, P0, DOI DOI 10.1002/widm.8
   Candel A., 2016, DEEP LEARNING H 2 0, V0, P1
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Chen XX, 2004, REMOTE SENS ENVIRON, V91, P14, DOI 10.1016/j.rse.2003.11.003
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Cook D., 2016, PRACTICAL MACHINE LE, V0, P0
   Coskun HG, 2008, WATER AIR SOIL POLL, V194, P275, DOI 10.1007/s11270-008-9716-x
   CRIST EP, 1984, IEEE T GEOSCI REMOTE, V22, P256, DOI 10.1109/TGRS.1984.350619
   Das H, 2022, J KING SAUD UNIV-COM, V34, P3851, DOI 10.1016/j.jksuci.2020.05.002
   de Sousa C, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0227438
   Dessu SB, 2014, CATENA, V115, P104, DOI 10.1016/j.catena.2013.11.017
   Dhanaraj K, 2022, GEOJOURNAL, V87, P1133, DOI 10.1007/s10708-020-10302-4
   Di Gregorio A., 2005, LAND COVER CLASSIFIC, V0, P0
   Draper SE, 2007, J WATER RES PLAN MAN, V133, P446, DOI 10.1061/(ASCE)0733-9496(2007)133:5(446)
   Chaves MED, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12183062
   El Bouchefry K., 2020, KNOWLEDGE DISCOVERY, V0, PP225, DOI 10.1016/B978-0-12-819154-5.00023-0
   Elmannai H., 2020, TELKOMNIKA, V19, P1242, DOI 10.12928/telkomnika.v19i4.18359
   ELVIDGE CD, 1985, REMOTE SENS ENVIRON, V17, P265, DOI 10.1016/0034-4257(85)90099-9
   Evrendilek F, 2011, INT J REMOTE SENS, V32, P3461, DOI 10.1080/01431161003749469
   Farr TG, 2007, REV GEOPHYS, V45, P0, DOI 10.1029/2005RG000183
   Foody GM, 2004, REMOTE SENS ENVIRON, V93, P107, DOI 10.1016/j.rse.2004.06.017
   Fourie C., 2011, ONE CLASS OBJECT BAS, V0, P0
   Ge Y, 2019, REMOTE SENS ENVIRON, V232, P0, DOI 10.1016/j.rse.2019.111285
   Georganos S, 2018, IEEE GEOSCI REMOTE S, V15, P607, DOI 10.1109/LGRS.2018.2803259
   Georganos S, 2017, PROC SPIE, V10431, P0, DOI 10.1117/12.2278482
   Gilbertson JK, 2017, COMPUT ELECTRON AGR, V134, P151, DOI 10.1016/j.compag.2016.12.006
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Guyon I, 2006, STUD FUZZ SOFT COMP, V207, P1
   Haefner A, 2016, EARTHSCAN STUD WATER, V0, P1
   Homer C, 2004, PHOTOGRAMM ENG REM S, V70, P829, DOI 10.14358/PERS.70.7.829
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2
   HUETE A R, 1988, REMOTE SENSING OF ENVIRONMENT, V25, P295
   HUETE AR, 1988, REMOTE SENS ENVIRON, V25, P89, DOI 10.1016/0034-4257(88)90043-0
   Ismail R, 2011, INT J REMOTE SENS, V32, P4249, DOI 10.1080/01431161.2010.486413
   Iyob B., 2010, RESILIENCE ADAPTABIL, V0, P0
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Just RE, 1998, NAT RES MAN, V0, P1
   Kassawmar T, 2018, GEOCARTO INT, V33, P53, DOI 10.1080/10106049.2016.1222637
   Kuhn M., 2015, CARET CLASSIFICATION, V0, P0
   Kuhn M, 2013, APPL PREDICTIVE MODE, V0, P0, DOI DOI 10.1007/978-1-4614-6849-3
   Lagrange A, 2017, IEEE T COMPUT IMAG, V3, P230, DOI 10.1109/TCI.2017.2666551
   Lawrence RL, 1998, REMOTE SENS ENVIRON, V64, P91, DOI 10.1016/S0034-4257(97)00171-5
   Li WJ, 2016, INT J REMOTE SENS, V37, P5632, DOI 10.1080/01431161.2016.1246775
   Ligate EJ, 2018, ECOSYST HEALTH SUST, V4, P188, DOI 10.1080/20964129.2018.1512839
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Low F, 2013, ISPRS J PHOTOGRAMM, V85, P102, DOI 10.1016/j.isprsjprs.2013.08.007
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Manandhar R, 2009, REMOTE SENS-BASEL, V1, P330, DOI 10.3390/rs1030330
   Manis G., 2000, GAP ANAL BULL, V9, P13
   Mendelsohn J., 2004, OKAVANGO RIVER FLOW, V0, P0
   Mianabadi A, 2020, WATER RESOUR MANAG, V34, P3445, DOI 10.1007/s11269-020-02576-7
   Mohajane M, 2018, ENVIRONMENTS, V5, P0, DOI 10.3390/environments5120131
   Mongus D, 2018, INT J APPL EARTH OBS, V66, P56, DOI 10.1016/j.jag.2017.11.004
   Mushore TD, 2017, GEOCARTO INT, V32, P886, DOI 10.1080/10106049.2016.1188168
   Mustapha IB, 2016, MOLECULES, V21, P0, DOI 10.3390/molecules21080983
   Nair V, 2010, ICML, V27, P807
   Narumalani S., 1998, REMOTE SENS REV, V16, P233, DOI 10.1080/02757259809532355
   Noormets Asko, 2009, P59, V0, P0, DOI DOI 10.1007/978-1-4419-0026-5_3
   Omer G, 2015, S AFR J GEOMAT, V4, P414, DOI 10.4314/sajg.v4i4.5
   Piyoosh AK, 2022, GEOCARTO INT, V37, P2137, DOI 10.1080/10106049.2020.1815863
   Poona NK, 2016, APPL SPECTROSC, V70, P322, DOI 10.1177/0003702815620545
   Porto J.G., 2003, TRANSBOUNDARY RIVERS, V0, P0
   Rai PK, 2018, APPL WATER SCI, V8, P0, DOI 10.1007/s13201-018-0660-7
   Reed Bradley C., 2009, P231, V0, P0, DOI DOI 10.1007/978-1-4419-0026-5_10
   Revermann R, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050370
   Richardson AD, 2013, AGR FOREST METEOROL, V169, P156, DOI 10.1016/j.agrformet.2012.09.012
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Rouse J., 1973, NASA SP, V0, P309
   Rousset G, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13122257
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Saini R, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.044511
   Saini R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, V0, P1148
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shahi K, 2017, GEOCARTO INT, V32, P1389, DOI 10.1080/10106049.2016.1213888
   Shi WW, 2018, LECT NOTES COMPUT SC, V11209, P311, DOI 10.1007/978-3-030-01228-1_19
   Steudel Thomas, 2013, BIODIVERSITY ECOL, V5, P247, DOI 10.7809/b-e.00279
   Sturari M, 2017, EUR J REMOTE SENS, V50, P1, DOI 10.1080/22797254.2017.1274572
   Talukdar NR, 2020, MODEL EARTH SYST ENV, V6, P27, DOI 10.1007/s40808-019-00652-5
   Talukdar S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071135
   Tsai CF, 2010, DECIS SUPPORT SYST, V50, P258, DOI 10.1016/j.dss.2010.08.028
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   vanDeventer AP, 1997, PHOTOGRAMM ENG REM S, V63, P87
   Weber T., 2013, BIODIVERSITY ECOL, V5, P15, DOI 10.7809/b-e.00237
   WERBOS PJ, 1994, THEORETICAL ADV NEUR, V0, P449
   Wingate VR, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080681
   Xiong J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101065
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Yang YT, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep23284
   Zeng HW, 2020, CHINESE GEOGR SCI, V30, P397, DOI 10.1007/s11769-020-1119-y
   Zha Y, 2003, INT J REMOTE SENS, V24, P583, DOI 10.1080/01431160304987
   Zhao HM, 2005, INT GEOSCI REMOTE SE, V0, P1666
NR 108
TC 4
Z9 4
U1 4
U2 22
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 15
PY 2021
VL 13
IS 24
BP 
EP 
DI 10.3390/rs13245054
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XZ4BM
UT WOS:000737598700001
DA 2023-04-26
ER

PT J
AU He, D
   Shi, Q
   Liu, XP
   Zhong, YF
   Zhang, XC
AF He, Da
   Shi, Qian
   Liu, Xiaoping
   Zhong, Yanfei
   Zhang, Xinchang
TI Deep Subpixel Mapping Based on Semantic Information Modulated Network for Urban Land Use Mapping
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Semantics; Remote sensing; Image restoration; Spatial resolution; Training; Superresolution; Data models; Deep learning; mixed pixel problem; semantic information modulated (SIM); semantic prior; subpixel mapping (SPM); urban land use mapping
ID convolutional neural-networks; map model; cover; pixel; images; classification
AB Mixed pixel problem is omnipresent in remote sensing images for urban land use interpretation due to the hardware limitations. Subpixel mapping (SPM) is a usual way to solve this problem by improving the observation scale and realizing a finer spatial resolution land cover mapping. Recently, deep learning-based subpixel mapping network (DLSMNet) was proposed, benefited from its strong representation and learning ability, to restore a visually pleasing finer mapping. However, the spatial context features of artifacts are usually aggregated and progressively lost during the forward pass of the network without sufficient representation, which make it difficult to be learned and restored. In this article, a semantic information modulated (SIM) deep subpixel mapping network (SIMNet) is proposed, which uses low-resolution semantic images as prior, to reinforce the representation of spatial context features. In SIMNet, SIM module is proposed to parametrically incorporate the semantic prior into the state-of-the-art (SOTA) feed forward network architecture in an end-to-end training fashion. Furthermore, stacked SIM module with residual blocks (SIM_ResBlock) is adopted to pass the representation of spatial context feature to the deep layers, to get it fully learned during backpropagation. Experiments have been implemented on three public urban scenario data sets, and the SIMNet generates a clearer outline of artificial facilities with sufficient spatial context, and is distinctive for even individual building, which is challenging for other SOTA DLSMNet. The results demonstrate that the proposed SIMNet is a promising way for high-resolution urban land use mapping from easily available lower resolution remote sensing images.Mixed pixel problem is omnipresent in remote sensing images for urban land use interpretation due to the hardware limitations. Subpixel mapping (SPM) is a usual way to solve this problem by improving the observation scale and realizing a finer spatial resolution land cover mapping. Recently, deep learning-based subpixel mapping network (DLSMNet) was proposed, benefited from its strong representation and learning ability, to restore a visually pleasing finer mapping. However, the spatial context features of artifacts are usually aggregated and progressively lost during the forward pass of the network without sufficient representation, which make it difficult to be learned and restored. In this article, a semantic information modulated (SIM) deep subpixel mapping network (SIMNet) is proposed, which uses low-resolution semantic images as prior, to reinforce the representation of spatial context features. In SIMNet, SIM module is proposed to parametrically incorporate the semantic prior into the state-of-the-art (SOTA) feed forward network architecture in an end-to-end training fashion. Furthermore, stacked SIM module with residual blocks (SIM_ResBlock) is adopted to pass the representation of spatial context feature to the deep layers, to get it fully learned during backpropagation. Experiments have been implemented on three public urban scenario data sets, and the SIMNet generates a clearer outline of artificial facilities with sufficient spatial context, and is distinctive for even individual building, which is challenging for other SOTA DLSMNet. The results demonstrate that the proposed SIMNet is a promising way for high-resolution urban land use mapping from easily available lower resolution remote sensing images.
C1 [He, Da; Shi, Qian; Liu, Xiaoping] Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Guangdong, Peoples R China.
   [Zhong, Yanfei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Zhong, Yanfei] Wuhan Univ, Hubei Prov Engn Res Ctr Nat Resources Remote Sens, Wuhan 430079, Peoples R China.
   [Zhang, Xinchang] Guangzhou Univ, Sch Geog & Remote Sensing, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University; Wuhan University; Wuhan University; Guangzhou University
RP Shi, Q (corresponding author), Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Guangdong, Peoples R China.
EM heda@whu.edu.cn; shixi5@mail.sysu.edu.cn; liuxp3@mail.sysu.edu.cn; zhongyanfei@whu.edu.cn; eeszxc@mail.sysu.edu.cn
FU National Key Research and Development Program of China [2019YFB2103102, 2017YFA0604401]; Guangdong Natural Science Foundation [2019A1515011057]; National Natural Science Foundation of China [61976234]; Open Research Fund of the National Key Laboratory of Surveying, Mapping and Remote Sensing Information Engineering, Wuhan University; Guangzhou Applied Basic Research Project; China Postdoctoral Science Foundation [2020M683053]
CR Arun PV, 2018, NEUROCOMPUTING, V311, P51, DOI 10.1016/j.neucom.2018.05.051
   Atkinson P. M., 1997, INNOVATIONS GIS, V4, P166
   Atkinson PM, 2008, IEEE T GEOSCI REMOTE, V46, P573, DOI 10.1109/TGRS.2007.909952
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Chen YH, 2015, IEEE J-STARS, V8, P2040, DOI 10.1109/JSTARS.2015.2417191
   Fisher P, 1997, INT J REMOTE SENS, V18, P679, DOI 10.1080/014311697219015
   Ge Y, 2016, IEEE T GEOSCI REMOTE, V54, P2356, DOI 10.1109/TGRS.2015.2499790
   Ge Y, 2013, INT J APPL EARTH OBS, V22, P115, DOI 10.1016/j.jag.2012.04.013
   He D., 2020, IEEE T GEOSCI ELECT, V0, P0, DOI DOI 10.1109/TGRS.2020.3032475
   He D, 2020, IEEE T GEOSCI REMOTE, V58, P1696, DOI 10.1109/TGRS.2019.2947708
   He D, 2019, IEEE T GEOSCI REMOTE, V57, P2198, DOI 10.1109/TGRS.2018.2872081
   He D, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110894
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Isola P, 2017, PROC CVPR IEEE, V0, PP5967, DOI 10.1109/CVPR.2017.632
   ISPRS, 2016, INT SOC PHOT REM SEN, V0, P0
   Jia YX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151815
   Li XD, 2017, REMOTE SENS ENVIRON, V196, P293, DOI 10.1016/j.rse.2017.05.011
   Ling F, 2019, REMOTE SENS LETT, V10, P598, DOI 10.1080/2150704X.2019.1587196
   Ling F, 2016, IEEE T GEOSCI REMOTE, V54, P7210, DOI 10.1109/TGRS.2016.2598534
   Ling F, 2014, IEEE T GEOSCI REMOTE, V52, P4424, DOI 10.1109/TGRS.2013.2281992
   Ling F, 2013, REMOTE SENS LETT, V4, P629, DOI 10.1080/2150704X.2013.781284
   Ling F, 2012, INT J APPL EARTH OBS, V18, P283, DOI 10.1016/j.jag.2012.02.008
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma XF, 2019, IEEE J-STARS, V12, P4930, DOI 10.1109/JSTARS.2019.2941089
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Makido Y, 2007, PHOTOGRAMM ENG REM S, V73, P1233, DOI 10.14358/PERS.73.11.1233
   Patino JE, 2013, COMPUT ENVIRON URBAN, V37, P1, DOI 10.1016/j.compenvurbsys.2012.06.003
   Ren WQ, 2017, IEEE I CONF COMP VIS, V0, PP1086, DOI 10.1109/ICCV.2017.123
   Shi C, 2014, REMOTE SENS ENVIRON, V149, P70, DOI 10.1016/j.rse.2014.03.034
   Shi WZ, 2016, PROC CVPR IEEE, V0, PP1874, DOI 10.1109/CVPR.2016.207
   Song M, 2019, IEEE T GEOSCI REMOTE, V57, P4490, DOI 10.1109/TGRS.2019.2891354
   Song XP, 2018, NATURE, V560, P639, DOI 10.1038/s41586-018-0411-9
   Su YF, 2019, INT J REMOTE SENS, V40, P8933, DOI 10.1080/01431161.2019.1624865
   Timofte R, 2016, COMPUT VIS IMAGE UND, V142, P1, DOI 10.1016/j.cviu.2015.09.008
   Tong XH, 2013, IEEE T GEOSCI REMOTE, V51, P2799, DOI 10.1109/TGRS.2012.2218612
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang P, 2021, IEEE T GEOSCI REMOTE, V59, P2256, DOI 10.1109/TGRS.2020.3004353
   Wang P, 2019, IEEE J-STARS, V12, P4082, DOI 10.1109/JSTARS.2019.2939670
   Wang P, 2019, IEEE J-STARS, V12, P1835, DOI 10.1109/JSTARS.2019.2910539
   Wang QM, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112054
   Wang QM, 2020, ISPRS J PHOTOGRAMM, V168, P251, DOI 10.1016/j.isprsjprs.2020.08.016
   Wang QM, 2020, REMOTE SENS ENVIRON, V244, P0, DOI 10.1016/j.rse.2020.111817
   Wang QM, 2018, REMOTE SENS ENVIRON, V204, P31, DOI 10.1016/j.rse.2017.10.046
   Wang QM, 2015, REMOTE SENS ENVIRON, V166, P191, DOI 10.1016/j.rse.2015.06.003
   Wang XT, 2018, PROC CVPR IEEE, V0, PP606, DOI 10.1109/CVPR.2018.00070
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Xu X, 2018, IEEE T GEOSCI REMOTE, V56, P6763, DOI 10.1109/TGRS.2018.2842748
   Xu X, 2014, IEEE T GEOSCI REMOTE, V52, P787, DOI 10.1109/TGRS.2013.2244095
   Xu X, 2013, IEEE J-STARS, V6, P580, DOI 10.1109/JSTARS.2012.2227246
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang LP, 2008, NEUROCOMPUTING, V71, P2046, DOI 10.1016/j.neucom.2007.08.033
   Zhang YH, 2019, REMOTE SENS ENVIRON, V224, P74, DOI 10.1016/j.rse.2019.01.038
   Zhang YH, 2017, IEEE T GEOSCI REMOTE, V55, P600, DOI 10.1109/TGRS.2016.2613140
   Zhang YH, 2015, IEEE GEOSCI REMOTE S, V12, P1740, DOI 10.1109/LGRS.2015.2423496
   Zhao J, 2015, IEEE J-STSP, V9, P1049, DOI 10.1109/JSTSP.2015.2416683
   Zhao WZ, 2017, ISPRS J PHOTOGRAMM, V132, P48, DOI 10.1016/j.isprsjprs.2017.08.011
   Zhong YF, 2015, IEEE T GEOSCI REMOTE, V53, P1411, DOI 10.1109/TGRS.2014.2340734
NR 58
TC 48
Z9 48
U1 11
U2 51
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD DEC 15
PY 2021
VL 59
IS 12
BP 10628
EP 10646
DI 10.1109/TGRS.2021.3050824
PG 19
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology
GA XC7DV
UT WOS:000722170500062
DA 2023-04-26
ER

PT J
AU Liu, SY
   Cheng, J
   Liang, LK
   Bai, HW
   Dang, WL
AF Liu, Siyu
   Cheng, Jian
   Liang, Leikun
   Bai, Haiwei
   Dang, Wanli
TI Light-Weight Semantic Segmentation Network for UAV Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Semantics; Image segmentation; Task analysis; Unmanned aerial vehicles; Feature extraction; Convolution; Attention mechanism; light-weight network; remote sensing; semantic segmentation; unmanned aerial vehicle images
AB Semantic segmentation for unmanned aerial vehicle (UAV) remote sensing images has become one of the research focuses in the field of remote sensing at present, which could accurately analyze the ground objects and their relationships. However, conventional semantic segmentation methods based on deep learning require large-scale models that are not suitable for resource-constrained UAV remote sensing tasks. Therefore, it is important to construct a light-weight semantic segmentation method for UAV remote sensing images. With this motivation, we propose a light-weight neural network model with fewer parameters to solve the problem of semantic segmentation of UAV remote sensing images. The network adopts an encoder-decoder architecture. In the encoder, we build a light-weight convolutional neural network model with fewer channels of each layer to reduce the number of model parameters. Then, feature maps of different scales from the encoder are concatenated together after resizing to carry out the multiscale fusion. Moreover, we employ two attention modules to capture the global semantic information from the context and the correlation among channels in UAV remote sensing images. In the decoder part, the model obtains predictions of each pixel through the softmax function. We conducted experiments on the ISPRS Vaihingen dataset, UAVid dataset, and UDD6 dataset to verify the effectiveness of the light-weight network. Our method obtains quality semantic segmentation results evaluated on UAV remote sensing datasets with only 9 M parameters the model owns, which is competitive among popular methods with the same level of parameters.
C1 [Liu, Siyu; Cheng, Jian; Liang, Leikun; Bai, Haiwei; Dang, Wanli] Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China.
   [Dang, Wanli] Second Res Inst Civil Aviat Adm China, Chengdu 610041, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Cheng, J (corresponding author), Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China.
EM syliu@std.uestc.edu.cn; chengjian@uestc.edu.cn; liang_leikun@163.com; hwbaymax@std.uestc.edu.cn; dangwanli@caacsri.com
FU National Natural Science Foundation of China [62071104]; Sichuan Science and Technology Program [2020YFG0085, 2021YFG0328]; Intelligent TerminalKey Laboratory of Sichuan [SCITLAB-0017]
CR [Anonymous], 2017, PREPRINTS, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y, 2018, LECT NOTES COMPUT SC, V11256, P347, DOI 10.1007/978-3-030-03398-9_30
   Chowdhury T, 2020, IEEE INT CONF BIG DA, V0, PP3904, DOI 10.1109/BigData50022.2020.9377916
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Erdelj M., 2016, 2016 INT C COMP NETW, V0, PP1, DOI 10.1109/ICCNC.2016.7440563
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Galarreta JF, 2015, NAT HAZARD EARTH SYS, V15, P1087, DOI 10.5194/nhess-15-1087-2015
   Hashemi-Beni L, 2021, IEEE J-STARS, V14, P2127, DOI 10.1109/JSTARS.2021.3051873
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Howard Andrew G., 2017, PROC IEEE C COMPUT V, V0, P0
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang HY, 2018, IEEE J-STARS, V11, P2253, DOI 10.1109/JSTARS.2018.2830410
   Huang ZL, 2019, IEEE I CONF COMP VIS, V0, PP603, DOI 10.1109/ICCV.2019.00069
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Ke RM, 2019, IEEE T INTELL TRANSP, V20, P54, DOI 10.1109/TITS.2018.2797697
   Kerle N, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9010014
   Khan MA, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030458
   Li Hanchao, 2019, PROC CVPR IEEE, V0, PP9522, DOI 10.1109/CVPR.2019.00975
   Liu MJ, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20082238
   Liu SY, 2020, INT GEOSCI REMOTE SE, V0, PP2595, DOI 10.1109/IGARSS39084.2020.9324723
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lyu Y, 2020, ISPRS J PHOTOGRAMM, V165, P108, DOI 10.1016/j.isprsjprs.2020.05.009
   Marcos D, 2018, ISPRS J PHOTOGRAMM, V145, P96, DOI 10.1016/j.isprsjprs.2018.01.021
   Mou LC, 2019, PROC CVPR IEEE, V0, PP12408, DOI 10.1109/CVPR.2019.01270
   Nex F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030287
   Pan XG, 2018, AAAI CONF ARTIF INTE, V0, P7276
   Paszke A., 2016, ABS160602147 CORR, V0, P0
   Peng C, 2017, PROC CVPR IEEE, V0, PP1743, DOI 10.1109/CVPR.2017.189
   Quang N. T., 2015, P 6 INT S INF COMM T, V0, PP282, DOI 10.1145/2833258.2833272
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O., 2015, INT C MED IM COMP CO, V0, PP234, DOI 10.1007/978-3-319-24574-4_28
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Teng SZ, 2021, INT J COMPUT VISION, V129, P719, DOI 10.1007/s11263-020-01402-2
   Tijtgat N, 2017, IEEE INT CONF COMP V, V0, PP2110, DOI 10.1109/ICCVW.2017.247
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu Changqian, 2020, ARXIV200402147, V2, P8
   Yu F., 2015, 1511 ARXIV, V0, P0
   Zhang X, 2018, PROC CVPR IEEE, V0, PP6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhu JS, 2018, IEEE J-STARS, V11, P4968, DOI 10.1109/JSTARS.2018.2879368
   Zhu XZ, 2019, IEEE I CONF COMP VIS, V0, PP6687, DOI 10.1109/ICCV.2019.00679
NR 46
TC 13
Z9 13
U1 24
U2 87
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 8287
EP 8296
DI 10.1109/JSTARS.2021.3104382
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UK8JJ
UT WOS:000692210900015
DA 2023-04-26
ER

PT J
AU An, FP
   Liu, JE
   Bai, L
AF An, Feng-Ping
   Liu, Jun-e
   Bai, Lei
TI Pedestrian Reidentification Algorithm Based on Deconvolution Network Feature Extraction-Multilayer Attention Mechanism Convolutional Neural Network
SO JOURNAL OF SENSORS
LA English
DT Article
ID person reidentification
AB Pedestrian reidentification is a key technology in large-scale distributed camera systems. It can quickly and efficiently detect and track target people in large-scale distributed surveillance networks. The existing traditional pedestrian reidentification methods have problems such as low recognition accuracy, low calculation efficiency, and weak adaptive ability. Pedestrian reidentification algorithms based on deep learning have been widely used in the field of pedestrian reidentification due to their strong adaptive ability and high recognition accuracy. However, the pedestrian recognition method based on deep learning has the following problems: first, during the learning process of the deep learning model, the initial value of the convolution kernel is usually randomly assigned, which makes the model learning process easily fall into a local optimum. The second is that the model parameter learning method based on the gradient descent method exhibits gradient dispersion. The third is that the information transfer of pedestrian reidentification sequence images is not considered. In view of these issues, this paper first examines the feature map matrix from the original image through a deconvolution neural network, uses it as a convolution kernel, and then performs layer-by-layer convolution and pooling operations. Then, the second derivative information of the error function is directly obtained without calculating the Hessian matrix, and the momentum coefficient is used to improve the convergence of the backpropagation, thereby suppressing the gradient dispersion phenomenon. At the same time, to solve the problem of information transfer of pedestrian reidentification sequence images, this paper proposes a memory network model based on a multilayer attention mechanism, which uses the network to effectively store image visual information and pedestrian behavior information, respectively. It can solve the problem of information transmission. Based on the above ideas, this paper proposes a pedestrian reidentification algorithm based on deconvolution network feature extraction-multilayer attention mechanism convolutional neural network. Experiments are performed on the related data sets using this algorithm and other major popular human reidentification algorithms. The results show that the pedestrian reidentification method proposed in this paper not only has strong adaptive ability but also has significantly improved average recognition accuracy and rank-1 matching rate compared with other mainstream methods.
C1 [An, Feng-Ping] Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223300, JS, Peoples R China.
   [An, Feng-Ping] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, BJ, Peoples R China.
   [Liu, Jun-e] Beijing Wuzi Univ, Sch Informat, Beijing 100061, BJ, Peoples R China.
   [Bai, Lei] North China Inst Sci & Technol, Hebei IoT Monitoring Engn Technol Res Ctr, Langfang 065201, HB, Peoples R China.
C3 Huaiyin Normal University; Beijing Institute of Technology; Beijing Wuzi University; North China Institute Science & Technology
RP An, FP (corresponding author), Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223300, JS, Peoples R China.; An, FP (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, BJ, Peoples R China.; Liu, JE (corresponding author), Beijing Wuzi Univ, Sch Informat, Beijing 100061, BJ, Peoples R China.; Bai, L (corresponding author), North China Inst Sci & Technol, Hebei IoT Monitoring Engn Technol Res Ctr, Langfang 065201, HB, Peoples R China.
EM anfengping@163.com; 2924175349@qq.com; zhouxianwei1961@163.com
FU National Natural Science Foundation of China [61701188]; China Postdoctoral Science Foundation [2019M650512]; Natural Science Foundation of Jiangsu Province [BK20201479]; Scientific, technological innovation service capacity building-high-level discipline construction (city level), Beijing Intelligent Logistics System Collaborative Innovation Center [BILSCIC-2019KF-22]; Hebei IoT Monitoring Engineering Technology Research Center [IOT202004]
CR Ali M. F. T, 2018, PROC EUR C COMPUT VI, V0, P122
   Bai S, 2019, PROC CVPR IEEE, V0, PP740, DOI 10.1109/CVPR.2019.00083
   Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Chen KZ, 2020, NEUROCOMPUTING, V382, P259, DOI 10.1016/j.neucom.2019.11.094
   Cui HC, 2019, IEEE T COMP PACK MAN, V9, P1785, DOI 10.1109/TCPMT.2019.2930741
   Gheissari N., 2006, P C COMPUTER VISION, V2, P1528, DOI 10.1109/CVPR.2006.223
   Han H, 2021, IEEE T INTELL TRANSP, V22, P394, DOI 10.1109/TITS.2019.2958741
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hou RB, 2019, PROC CVPR IEEE, V0, PP7176, DOI 10.1109/CVPR.2019.00735
   Jia JR, 2017, COMPUT VIS IMAGE UND, V160, P87, DOI 10.1016/j.cviu.2017.04.003
   Khagi B, 2019, INT J IMAG SYST TECH, V29, P297, DOI 10.1002/ima.22316
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, V0, P0, DOI DOI 10.5244/C.26.24
   Li DW, 2017, PROC CVPR IEEE, V0, PP7398, DOI 10.1109/CVPR.2017.782
   Li W, 2017, PATTERN RECOGN, V61, P327, DOI 10.1016/j.patcog.2016.08.001
   Li W, 2014, PROC CVPR IEEE, V0, PP152, DOI 10.1109/CVPR.2014.27
   Liang M, 2015, PROC CVPR IEEE, V0, PP3367, DOI 10.1109/CVPR.2015.7298958
   Liao SC, 2015, PROC CVPR IEEE, V0, PP2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Ma F, 2020, IEEE T INF FOREN SEC, V15, P115, DOI 10.1109/TIFS.2019.2917160
   Mitra V, 2017, SPEECH COMMUN, V89, P103, DOI 10.1016/j.specom.2017.03.003
   Monroe ME, 2007, BIOINFORMATICS, V23, P2021, DOI 10.1093/bioinformatics/btm281
   Nanda A, 2019, MULTIMED TOOLS APPL, V78, P3885, DOI 10.1007/s11042-017-4875-7
   Pedagadi S, 2013, PROC CVPR IEEE, V0, PP3318, DOI 10.1109/CVPR.2013.426
   Salehian S, 2019, IEEE I C SIGNAL IMAG, V0, PP192, DOI 10.1109/ICSIPA45851.2019.8977728
   Schumann A, 2017, IEEE COMPUT SOC CONF, V0, PP1435, DOI 10.1109/CVPRW.2017.186
   Sun XX, 2019, PROC CVPR IEEE, V0, PP608, DOI 10.1109/CVPR.2019.00070
   Sun YF, 2019, PROC CVPR IEEE, V0, PP393, DOI 10.1109/CVPR.2019.00048
   Xiao T, 2016, PROC CVPR IEEE, V0, PP1249, DOI 10.1109/CVPR.2016.140
   Xiong W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P5934
   Xu J, 2018, PROC CVPR IEEE, V0, PP2119, DOI 10.1109/CVPR.2018.00226
   Xu SJ, 2017, IEEE I CONF COMP VIS, V0, PP4743, DOI 10.1109/ICCV.2017.507
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zajdel W, 2005, IEEE INT CONF ROBOT, V0, P2081
   Zhang L, 2016, PROC CVPR IEEE, V0, PP1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2013, PROC CVPR IEEE, V0, PP3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhou JH, 2018, PROC CVPR IEEE, V0, PP5373, DOI 10.1109/CVPR.2018.00563
   Zhou JH, 2017, IEEE I CONF COMP VIS, V0, PP2439, DOI 10.1109/ICCV.2017.265
NR 40
TC 1
Z9 1
U1 1
U2 5
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-725X
EI 1687-7268
J9 J SENSORS
JI J. Sens.
PD JAN 28
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/9463092
PG 12
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Engineering; Instruments & Instrumentation
GA QG3NO
UT WOS:000617496300001
DA 2023-04-26
ER

PT J
AU Gonzalez, RQ
   Arsanjani, JJ
AF Gonzalez, Rebeca Quintero
   Arsanjani, Jamal Jokar
TI Prediction of Groundwater Level Variations in a Changing Climate: A Danish Case Study
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE machine learning; groundwater; climate change; random forest; Denmark
ID water-table; model; variables; system
AB Shallow groundwater is a key resource for human activities and ecosystems, and is susceptible to alterations caused by climate change, causing negative socio-economic and environmental impacts, and increasing the need to predict the evolution of the water table. The main objective of this study is to gain insights about future water level changes based on different climate change scenarios using machine learning algorithms, while addressing the following research questions: (a) how will the water table be affected by climate change in the future based on different socio-economic pathways (SSPs)?: (b) do machine learning models perform well enough in predicting changes of the groundwater in Denmark? If so, which ML model outperforms for forecasting these changes? Three ML algorithms were used in R: artificial neural networks (ANN), support vector machine (SVM) and random forest (RF). The ML models were trained with time-series data of groundwater levels taken at wells in the Hovedstaden region, for the period 1990-2018. Several independent variables were used to train the models, including different soil parameters, topographical features and climatic variables for the time period and region selected. Results show that the RF model outperformed the other two, resulting in a higher R-squared and lower mean absolute error (MAE). The future prediction maps for the different scenarios show little variation in the water table. Nevertheless, predictions show that it will rise slightly, mostly in the order of 0-0.25 m, especially during winter. The proposed approach in this study can be used to visualize areas where the water levels are expected to change, as well as to gain insights about how big the changes will be. The approaches and models developed with this paper could be replicated and applied to other study areas, allowing for the possibility to extend this model to a national level, improving the prevention and adaptation plans in Denmark and providing a more global overview of future water level predictions to more efficiently handle future climate change scenarios.
C1 [Gonzalez, Rebeca Quintero; Arsanjani, Jamal Jokar] Aalborg Univ, Dept Planning Geog & Surveying, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
C3 Aalborg University
RP Arsanjani, JJ (corresponding author), Aalborg Univ, Dept Planning Geog & Surveying, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
EM rquint19@student.aau.dk; jja@plan.aau.dk
CR Adhikari K, 2013, SOIL SCI SOC AM J, V77, P860, DOI 10.2136/sssaj2012.0275
   [Anonymous], 1900, P2021, V0, P0
   [Anonymous], 2008, US GEOLOGICAL SURVEY, V0, P0
   Bates B., 2008, CLIMATE CHANGE WATER, V0, PP210, DOI 10.1029/90EO00112
   Blanco CMG, 2018, GEODERMA, V316, P100, DOI 10.1016/j.geoderma.2017.12.002
   Bogataj M., 2018, MULTIDISCIPLINARY DI, V2, P697, DOI 10.3390/PROCEEDINGS2110697
   Bowes BD, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11051098
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brownlee J., 2020, RANDOM FOREST TIME S, V0, P0
   Brutsaert W., 2005, HYDROLOGY INTRO, V0, P605
   Catani F, 2013, NAT HAZARD EARTH SYS, V13, P2815, DOI 10.5194/nhess-13-2815-2013
   Chen C, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-60698-9
   Copernicus EU-DEM v1.0, 2021, COPERNICUS PROGRAMME, V0, P0
   Danish Agriculture Food Council, 2019, DENM A FOOD FARM COU, V0, P0
   Danish Ministry of the Environment, 2021, DAN ACT PLAN PROM EC, V0, P0
   Danish Nature Agency, 2012, MAPP CLIM CHAN BARR, V0, P0
   Dormann CF, 2013, ECOGRAPHY, V36, P27, DOI 10.1111/j.1600-0587.2012.07348.x
   Fahimi F, 2017, THEOR APPL CLIMATOL, V128, P875, DOI 10.1007/s00704-016-1735-8
   Fick SE, 2017, INT J CLIMATOL, V37, P4302, DOI 10.1002/joc.5086
   Frankenfield J., 2020, ARTIFICIAL NEURAL NE, V0, P0
   Fung A, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12071934
   GEUS, 2017, GROUNDWATER MONITORI, V0, P0
   GEUS, 2021, NAT GEOL UND DANM GR, V0, P0
   GEUS, 2021, DOK PCJUP TAB KOD NA, V0, P0
   Gleeson T, 2016, NAT GEOSCI, V9, P161, DOI 10.1038/NGEO2590
   Guergachi A, 2008, APPL MATH COMPUT, V204, P553, DOI 10.1016/j.amc.2008.05.136
   Harris I, 2014, INT J CLIMATOL, V34, P623, DOI 10.1002/joc.3711
   Hedley CB, 2013, GEODERMA, V199, P22, DOI 10.1016/j.geoderma.2012.07.018
   Hengl T., 2018, RANDOM FOREST SPATIA, V0, P0
   Henriksen H.J., 2012, KLIMAEFFEKTER P HYDR, V0, P0
   Henriksen HJ, 2003, J HYDROL, V280, P52, DOI 10.1016/S0022-1694(03)00186-0
   Hijmans R.J., 2020, PACKAGERASTER, V0, P0
   Hussein EA, 2020, ALGORITHMS, V13, P0, DOI 10.3390/a13110300
   IBM Cloud Education, 2020, MACH LEARN, V0, P0
   Jankowfsky S, 2014, J HYDROL, V517, P1056, DOI 10.1016/j.jhydrol.2014.06.034
   Jebens M, 2016, E3S WEB CONF, V7, P0, DOI 10.1051/e3sconf/20160723005
   Jorgensen LF, 2009, HYDROGEOL J, V17, P827, DOI 10.1007/s10040-008-0398-7
   Kahlown MA, 2005, AGR WATER MANAGE, V76, P24, DOI 10.1016/j.agwat.2005.01.005
   Kidmose J, 2013, HYDROL EARTH SYST SC, V17, P1619, DOI 10.5194/hess-17-1619-2013
   Koch J, 2019, HYDROL EARTH SYST SC, V23, P4603, DOI 10.5194/hess-23-4603-2019
   Kuhn M., 2019, THE CARET PACKAGE, V0, P0
   Lakshamanan V., 2015, MACHINE LEARNING DAT, V0, P0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Levin G, 2007, AGR ECOSYST ENVIRON, V120, P330, DOI 10.1016/j.agee.2006.10.018
   Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9
   Meyer H., 2018, R PROJECT, V0, P0
   Meyer H, 2018, ENVIRON MODELL SOFTW, V101, P1, DOI 10.1016/j.envsoft.2017.12.001
   Miljo Metropolen, 2011, COPENHAGEN CLIMATE A, V0, P0
   Mohanty S, 2013, J HYDROL, V495, P38, DOI 10.1016/j.jhydrol.2013.04.041
   Moller AB, 2019, GEODERMA, V352, P314, DOI 10.1016/j.geoderma.2017.10.015
   Organisation for Economic Co-operation and Development [OECD], 2013, WAT CLIM CHANG AD PO, V0, P0
   Rolnick D., 2019, ARXIV190605433, V0, P0
   Rossbach P., 2018, NEURAL NETWORKS VS R, V0, P0
   Sayad S., 2021, INTRO DATA SCI, V0, P0
   Seneviratne SI, 2012, MANAGING THE RISKS OF EXTREME EVENTS AND DISASTERS TO ADVANCE CLIMATE CHANGE ADAPTATION, V0, P109
   Singh A, 2014, SCI TOTAL ENVIRON, V499, P414, DOI 10.1016/j.scitotenv.2014.05.048
   Singh R., 2014, DEEP LEARNING MEETS, V0, P0
   Solomatine DP, 2008, J HYDROINFORM, V10, P3, DOI 10.2166/hydro.2008.015
   Solomatine DP, 2009, WATER RESOUR RES, V45, P0, DOI 10.1029/2008WR006839
   Statistics Denmark, 2017, GEOGR ENV EN STAT YB, V0, P0
   Statistics Denmark, 2021, STATBANK DENM GEOGR, V0, P0
   STHDA, 1900, P2021, V0, P0
   Stocker T.F., 2013, WORKING GROUP I CONTRIBUTION TO THE FIFTH ASSESSMENT REPORT OF THE INTERGOVERNMENTAL PANEL ON CLIMATE CHANGE, V0, P0, DOI DOI 10.1017/CBO9781107415324
   Woldeamlak ST, 2007, HYDROGEOL J, V15, P891, DOI 10.1007/s10040-006-0145-x
   World Bank, 2021, CLIM DAT HIST, V0, P0
   Wuebbles D.J., 2017, CLIMATE SCI SPECIAL, V1, P0, DOI 10.7930/J0J964J6
   Zhou V, 2019, MACHINE LEARNING BEG, V0, P0
   Zipper SC, 2015, WATER RESOUR RES, V51, P6338, DOI 10.1002/2015WR017522
NR 74
TC 4
Z9 4
U1 3
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD NOV 15
PY 2021
VL 10
IS 11
BP 
EP 
DI 10.3390/ijgi10110792
PG 26
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA XK6KK
UT WOS:000727571800001
DA 2023-04-26
ER

PT J
AU Guan, XD
   Huang, C
   Yang, J
   Li, AN
AF Guan, Xudong
   Huang, Chong
   Yang, Juan
   Li, Ainong
TI Remote Sensing Image Classification with a Graph-Based Pre-Trained Neighborhood Spatial Relationship
SO SENSORS
LA English
DT Article
DE remote sensing; image classification; SVM (Support Vector Machine); knowledge graph; object-based image analysis; fuzzy classification; graph theory
ID object-based analysis; land-cover; expert-system; scene classification; neural-network; knowledge; information; gis; segmentation; ontology
AB Previous knowledge of the possible spatial relationships between land cover types is one factor that makes remote sensing image classification "smarter". In recent years, knowledge graphs, which are based on a graph data structure, have been studied in the community of remote sensing for their ability to build extensible relationships between geographic entities. This paper implements a classification scheme considering the neighborhood relationship of land cover by extracting information from a graph. First, a graph representing the spatial relationships of land cover types was built based on an existing land cover map. Empirical probability distributions of the spatial relationships were then extracted using this graph. Second, an image was classified based on an object-based fuzzy classifier. Finally, the membership of objects and the attributes of their neighborhood objects were joined to decide the final classes. Two experiments were implemented. Overall accuracy of the two experiments increased by 5.2% and 0.6%, showing that this method has the ability to correct misclassified patches using the spatial relationship between geo-entities. However, two issues must be considered when applying spatial relationships to image classification. The first is the "siphonic effect" produced by neighborhood patches. Second, the use of global spatial relationships derived from a pre-trained graph loses local spatial relationship in-formation to some degree.
C1 [Guan, Xudong; Li, Ainong] Chinese Acad Sci, Res Ctr Digital Mt & Remote Sensing Applicat, Inst Mt Hazards & Environm, Chengdu 610041, Peoples R China.
   [Huang, Chong] Chinese Acad Sci, State Key Lab Resources & Environm Informat Syst, Inst Geog Sci & Nat Resources Res, Beijing 100101, Peoples R China.
   [Yang, Juan] Shaanxi Energy Inst, Xianyang 712000, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Mountain Hazards & Environment, CAS; Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS
RP Li, AN (corresponding author), Chinese Acad Sci, Res Ctr Digital Mt & Remote Sensing Applicat, Inst Mt Hazards & Environm, Chengdu 610041, Peoples R China.
EM guanxd@imde.ac.cn; huangch@lreis.ac.cn; sxnyyj2014@163.com; ainongli@imde.ac.cn
FU National Science Foundation of China [41901309, 41701433, 42090015]; Youth Talent Team Program of the Institute of Mountain Hazards and Environment, CAS [SDSQB2020000032, Y8R2230230]; Sichuan Science and Technology Program [2020JDJQ0003]; Second Tibetan Plateau Scientific Expedition and Research Program [2019QZKK0308]; CAS "Light of West China" Program
CR Batuwita R, 2010, IEEE T FUZZY SYST, V18, P558, DOI 10.1109/TFUZZ.2010.2042721
   Belgiu M, 2014, REMOTE SENS LETT, V5, P530, DOI 10.1080/2150704X.2014.930563
   Belgiu M, 2014, REMOTE SENS-BASEL, V6, P1347, DOI 10.3390/rs6021347
   Benz U, 2001, INT GEOSCI REMOTE SE, V0, PP1427, DOI 10.1109/IGARSS.2001.976867
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Bouziani M, 2010, IEEE T GEOSCI REMOTE, V48, P3198, DOI 10.1109/TGRS.2010.2044508
   CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179, DOI 10.1109/T-C.1974.223827
   Chen Z, 2012, INT J REMOTE SENS, V33, P3048, DOI 10.1080/01431161.2011.625055
   Cheng G, 2020, IEEE J-STARS, V13, P3735, DOI 10.1109/JSTARS.2020.3005403
   Cheung AKL, 2015, INT J GEOGR INF SCI, V29, P580, DOI 10.1080/13658816.2014.989856
   Cui W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091044
   Dale MRT, 2010, ANNU REV ECOL EVOL S, V41, P21, DOI 10.1146/annurev-ecolsys-102209-144718
   Dianat R, 2010, IEEE GEOSCI REMOTE S, V7, P215, DOI 10.1109/LGRS.2009.2031686
   Dobson MC, 1996, IEEE T GEOSCI REMOTE, V34, P83, DOI 10.1109/36.481896
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Forestier G, 2013, COMPUT GEOSCI-UK, V54, P88, DOI 10.1016/j.cageo.2012.11.023
   Forestier G, 2012, COMPUT ENVIRON URBAN, V36, P470, DOI 10.1016/j.compenvurbsys.2012.01.003
   Ghimire B, 2010, REMOTE SENS LETT, V1, P45, DOI 10.1080/01431160903252327
   GOODENOUGH DG, 1987, IEEE T GEOSCI REMOTE, V25, P349, DOI 10.1109/TGRS.1987.289805
   Gu YT, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9102110
   Guarino N, 1998, FR ART INT, V46, P3
   Guo QH, 2007, GISCI REMOTE SENS, V44, P24, DOI 10.2747/1548-1603.44.1.24
   Hardin PJ, 1997, PHOTOGRAMM ENG REM S, V63, P735
   Hong DH, 2003, FUZZY SET SYST, V138, P271, DOI 10.1016/S0165-0114(02)00514-6
   Jabari S, 2013, ALGORITHMS, V6, P762, DOI 10.3390/a6040762
   KARTIKEYAN B, 1995, IEEE T GEOSCI REMOTE, V33, P58, DOI 10.1109/36.368222
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Li YS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12234003
   Li YF, 2020, MATH BIOSCI ENG, V17, P4443, DOI 10.3934/mbe.2020245
   Luo B, 2014, IEEE T GEOSCI REMOTE, V52, P1451, DOI 10.1109/TGRS.2013.2251468
   Ma L, 2016, PATTERN RECOGN LETT, V83, P133, DOI 10.1016/j.patrec.2016.01.022
   Masjedi A, 2016, IEEE T GEOSCI REMOTE, V54, P932, DOI 10.1109/TGRS.2015.2469691
   Metternicht G, 2001, ECOL MODEL, V144, P163, DOI 10.1016/S0304-3800(01)00371-4
   Murai H, 1997, INT J REMOTE SENS, V18, P811, DOI 10.1080/014311697218773
   Ouyang S, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010119
   Pacifici F, 2009, REMOTE SENS ENVIRON, V113, P1276, DOI 10.1016/j.rse.2009.02.014
   Pu SL, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030526
   Pu S, 2009, ISPRS J PHOTOGRAMM, V64, P575, DOI 10.1016/j.isprsjprs.2009.04.001
   Qiao C, 2015, INT J DIGIT EARTH, V8, P710, DOI 10.1080/17538947.2014.925517
   Rejichi S, 2015, IEEE J-STARS, V8, P2138, DOI 10.1109/JSTARS.2015.2433257
   Rezaee M, 2018, IEEE J-STARS, V11, P3030, DOI 10.1109/JSTARS.2018.2846178
   SARMA LCS, 1994, SADHANA-ACAD P ENG S, V19, P93
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Sebari I, 2013, ISPRS J PHOTOGRAMM, V79, P171, DOI 10.1016/j.isprsjprs.2013.02.006
   Tobler W, 2004, ANN ASSOC AM GEOGR, V94, P304, DOI 10.1111/j.1467-8306.2004.09402009.x
   Visser F, 2018, HYDROBIOLOGIA, V812, P157, DOI 10.1007/s10750-016-2928-y
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Witharana C, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13040558
   Xu C, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10020061
   Xu YH, 2021, IEEE T GEOSCI REMOTE, V59, P1604, DOI 10.1109/TGRS.2020.2999962
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhao LJ, 2019, MULTIMED TOOLS APPL, V78, P9667, DOI 10.1007/s11042-018-6548-6
   Zhao M, 2018, IEEE T IMAGE PROCESS, V27, P2731, DOI 10.1109/TIP.2018.2810516
NR 54
TC 2
Z9 2
U1 12
U2 30
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD AUG 15
PY 2021
VL 21
IS 16
BP 
EP 
DI 10.3390/s21165602
PG 28
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA UH2YM
UT WOS:000689803200001
PM 34451044
DA 2023-04-26
ER

PT J
AU Habibi, V
   Ahmadi, H
   Jafari, M
   Moeini, A
AF Habibi, Vahid
   Ahmadi, Hasan
   Jafari, Mohammad
   Moeini, Abolfazl
TI Mapping soil salinity using a combined spectral and topographical indices with artificial neural network
SO PLOS ONE
LA English
DT Article
ID prediction; regression; models; salt
AB Monitoring the status of natural and ecological resources is necessary for conservation and protection. Soil is one of the most important environmental resources in agricultural lands and natural resources. In this research study, we used Landsat 8 and Artificial Neural Network (ANN) to monitor soil salinity in Qom plain. The geographical location of 72 surface soil samples from 7 land types was determined by the Latin hypercube method, and the samples were taken to determine the electrical conductivity (EC). Thirty percent of the data was considered as a validation set and 70% as a test set. In addition to the Landsat 8 bands, we used spectral indices of salinity, vegetation, topography, and drainage (DEM, TWI, and TCI) because of their impacts on soil formation and development. We used ANN with different algorithms to model soil salinity. We found that the GFF algorithm is the best for soil salinity modeling. Also, the TWI topography index and SI5 salinity index and NDVI vegetation index had the most effect on the outputs of the selected model. It was also found that flood plains and lowlands had the highest levels of salinity accumulation.
C1 [Habibi, Vahid; Moeini, Abolfazl] Islamic Azad Univ, Sci & Res Branch, Dept Nat Resources & Environm, Tehran, Iran.
   [Ahmadi, Hasan; Jafari, Mohammad] Univ Tehran, Fac Nat Resource, Karaj, Iran.
C3 Islamic Azad University; University of Tehran
RP Jafari, M (corresponding author), Univ Tehran, Fac Nat Resource, Karaj, Iran.
EM jafary@ut.ac.ir
CR Abbas A, 2013, PHYS CHEM EARTH, V55-57, P43, DOI 10.1016/j.pce.2010.12.004
   Akramkhanov A, 2012, ENVIRON MONIT ASSESS, V184, P2475, DOI 10.1007/s10661-011-2132-5
   Alhammadi MS, 2008, INT J REMOTE SENS, V29, P1745, DOI 10.1080/01431160701395195
   Bagheri Bodaghabadi M, 2015, PEDOSPHERE, V25, P580, DOI 10.1016/S1002-0160(15)30038-2
   Baig MHA, 2014, REMOTE SENS LETT, V5, P423, DOI 10.1080/2150704X.2014.915434
   Bannari A, 2008, COMMUN SOIL SCI PLAN, V39, P2795, DOI 10.1080/00103620802432717
   Bennett SJ, 2013, CROP PASTURE SCI, V64, P285, DOI 10.1071/CP12417
   Conrad O, 2015, GEOSCI MODEL DEV, V8, P1991, DOI 10.5194/gmd-8-1991-2015
   Ebrahimi M, 2017, COMPUT ELECTRON AGR, V140, P409, DOI 10.1016/j.compag.2017.06.019
   Ennaji W., 2018, GEOL ECOL LANDSC, V2, P22, DOI 10.1080/24749508.2018.1438744
   Ennouri K, 2017, 3 BIOTECH, V7, P0, DOI 10.1007/s13205-017-0799-1
   Ghorbani MA, 2019, SOIL TILL RES, V186, P152, DOI 10.1016/j.still.2018.09.012
   Hoseini Y., 2017, IRAN AGRICULTURAL RESEARCH, V36, P91
   Jiang H, 2019, INT J REMOTE SENS, V40, P284, DOI 10.1080/01431161.2018.1513180
   Jin PB, 2015, ECOL INDIC, V54, P116, DOI 10.1016/j.ecolind.2015.02.028
   Jones HG, 2007, J EXP BOT, V58, P119, DOI 10.1093/jxb/erl118
   Khan NM, 2005, AGR WATER MANAGE, V77, P96, DOI 10.1016/j.agwat.2004.09.038
   Khan NM, 2001, MAPPING SALT AFFECTE, V0, P5
   McCulloch W., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Minasny B, 2010, GEODERMA, V155, P132, DOI 10.1016/j.geoderma.2009.04.024
   Mohamed ES, 2018, EGYPT J REMOTE SENS, V21, P1, DOI 10.1016/j.ejrs.2017.02.001
   MOORE ID, 1991, HYDROL PROCESS, V5, P3, DOI 10.1002/hyp.3360050103
   Nguyen AK, 2018, ESTIMATION SALINITY, V0, P0
   Noureddine K., 1900, V4531, V0, P401
   Patel RM, 2002, J AM WATER RESOUR AS, V38, P91, DOI 10.1111/j.1752-1688.2002.tb01537.x
   Plain A., 2017, DIGITAL MAPPING TOPS, V5, P1771
   QI J, 1994, REMOTE SENS ENVIRON, V48, P119, DOI 10.1016/0034-4257(94)90134-1
   Roustaei F., 2018, COMP ARTIFICIAL NEUR, V7, P11
   Saei M., 2014, FOREST CANOPY DENSIT, V0, P0
   Scudiero E, 2016, FRONT ENV SCI-SWITZ, V4, P0, DOI 10.3389/fenvs.2016.00065
   Shahabi M, 2017, ARCH AGRON SOIL SCI, V63, P151, DOI 10.1080/03650340.2016.1193162
   Silva S H G., 2016, THESIS U FEDERAL LAV, V0, P0
   Taghizadeh-Mehrjardi R, 2015, GEODERMA, V253, P67, DOI 10.1016/j.geoderma.2015.04.008
   Taghizadeh-Mehrjardi R, 2014, GEODERMA, V213, P15, DOI 10.1016/j.geoderma.2013.07.020
   Webster R, 2007, GEOSTATISTICS ENV SC, V0, P271
   Yang F, 2011, J ENVIRON PROT ECOL, V12, P1160
   Zou P, 2010, AGR WATER MANAGE, V97, P2009, DOI 10.1016/j.agwat.2010.02.011
NR 37
TC 10
Z9 10
U1 1
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
EI 
J9 PLOS ONE
JI PLoS One
PD MAY 13
PY 2021
VL 16
IS 5
BP 
EP 
DI 10.1371/journal.pone.0228494
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA SW6MO
UT WOS:000664628200001
PM 33983942
DA 2023-04-26
ER

PT J
AU Lian, YC
   Feng, T
   Zhou, JL
   Jia, MX
   Li, AJ
   Wu, ZY
   Jiao, LC
   Brown, M
   Hager, G
   Yokoya, N
   Hansch, R
   Le Saux, B
AF Lian, Yanchao
   Feng, Tuo
   Zhou, Jinliu
   Jia, Meixia
   Li, Aijin
   Wu, Zhaoyang
   Jiao, Licheng
   Brown, Myron
   Hager, Gregory
   Yokoya, Naoto
   Hansch, Ronny
   Le Saux, Bertrand
TI Large-Scale Semantic 3-D Reconstruction: Outcome of the 2019 IEEE GRSS Data Fusion Contest-Part B
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Three-dimensional displays; Semantics; Laser radar; Training; Earth; Data integration; Satellites; Classification; convolutional neural networks; data fusion contest (DFC); deep learning; image analysis and data fusion; light detection and ranging (LiDAR); point cloud; semantic labeling; semantic mapping
ID high-resolution lidar; land-use; classification; algorithms
AB We present the scientific outcomes of the 2019 Data Fusion Contest organized by the Image Analysis and Data Fusion Technical Committee of the IEEE Geoscience and Remote Sensing Society. The contest included challenges with large-scale datasets for semantic 3-D reconstruction from satellite images and also semantic 3-D point cloud classification from airborne LiDAR. 3-D reconstruction results are discussed separately in Part-A. In this Part-B, we report the results of the two best-performing approaches for 3-D point cloud classification. Both are deep learning methods that improve upon the PointSIFT model with mechanisms to combine multiscale features and task-specific postprocessing to refine model outputs.
C1 [Lian, Yanchao; Feng, Tuo; Zhou, Jinliu; Jia, Meixia; Li, Aijin; Wu, Zhaoyang; Jiao, Licheng] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ,Sch Artificial Intelligence, Int Res Ctr Intelligent Percept & Computat,Joint, Xian 710071, Peoples R China.
   [Brown, Myron] Johns Hopkins Univ, Appl Phys Lab, Laurel, MD 11100 USA.
   [Hager, Gregory] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Yokoya, Naoto] Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778561, Japan.
   [Yokoya, Naoto] RIKEN Ctr Adv Intelligence Project, Tokyo 1030027, Japan.
   [Hansch, Ronny] German Aerosp Ctr DLR, D-82234 Wessling, Germany.
   [Le Saux, Bertrand] ESA ESRIN, Lab, I-00044 Frascati, RM, Italy.
C3 Xidian University; Johns Hopkins University; Johns Hopkins University Applied Physics Laboratory; Johns Hopkins University; University of Tokyo; RIKEN; Helmholtz Association; German Aerospace Centre (DLR); European Space Agency
RP Hansch, R (corresponding author), German Aerosp Ctr DLR, D-82234 Wessling, Germany.
EM yclian@stu.xidian.edu.cn; fengt@stu.xidian.edu.cn; zhoujinliu@stu.xidian.edu.cn; mxjia@stu.xidian.edu.cn; aijinli@stu.xidian.edu.cn; wuzhaoyang@stu.xidian.edu.cn; lchjiao@mail.xidian.edu.cn; myron.brown@jhuapl.edu; hager@cs.jhu.edu; naoto.yokoya@riken.jp; rww.haensch@gmail.com; bls@ieee.org
FU StateKey Program of National Natural Science of China [61836009]; National Natural Science Foundation of China [U1701267]; Major Research Plan of the National Natural Science Foundation of China [91438201]; IARPA [2017-17032700004]
CR Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   [Anonymous], 2016, 4 INT C LEARN REPR I, V0, P0
   Axelsson PE, 1999, ISPRS J PHOTOGRAMM, V54, P138, DOI 10.1016/S0924-2716(99)00008-8
   Berger C, 2013, IEEE J-STARS, V6, P1324, DOI 10.1109/JSTARS.2013.2245860
   Bosch M, 2019, IEEE WINT CONF APPL, V0, PP1524, DOI 10.1109/WACV.2019.00167
   Brown M., 2019, **DATA OBJECT**, V0, P0, DOI DOI 10.21227/c6tm-vw12
   Campos-Taberner M, 2016, IEEE J-STARS, V9, P5547, DOI 10.1109/JSTARS.2016.2569162
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Debes C, 2014, IEEE J-STARS, V7, P2405, DOI 10.1109/JSTARS.2014.2305441
   Foster K., 2020, **DATA OBJECT**, V0, P0, DOI DOI 10.21227/9frn-7208
   Hackel T., 2017, PROC ISPRS ANN, V0, P0, DOI DOI 10.5194/isprsannals-IV-1-W1-91-2017
   Jia MX, 2019, INT GEOSCI REMOTE SE, V0, PP5065, DOI 10.1109/IGARSS.2019.8900102
   Jiang Mingyang, 2018, ABS180700652 CORR, V0, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kunwar S, 2021, IEEE J-STARS, V14, P922, DOI 10.1109/JSTARS.2020.3032221
   Li H, 2018, P BRIT MACH VIS C, V0, P0
   Li YY, 2018, ADV NEUR IN, V31, P0
   Lian YC, 2019, INT GEOSCI REMOTE SE, V0, P5061
   Liao WZ, 2015, IEEE J-STARS, V8, P2984, DOI 10.1109/JSTARS.2015.2420582
   Licciardi G, 2009, IEEE T GEOSCI REMOTE, V47, P3857, DOI 10.1109/TGRS.2009.2029340
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Mou L, 2017, IEEE J-STARS, V10, P3435, DOI 10.1109/JSTARS.2017.2696823
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Pacifici F, 2008, IEEE GEOSCI REMOTE S, V5, P331, DOI 10.1109/LGRS.2008.915939
   Pacifici F, 2012, IEEE J-STARS, V5, P3, DOI 10.1109/JSTARS.2012.2186733
   Poli D, 2012, PHOTOGRAMM REC, V26, P58, DOI 10.1111/j.1477-9730.2011.00665.x
   Qi CR, 2017, ADV NEUR IN, V30, P0
   Roynard X, 2018, INT J ROBOT RES, V37, P545, DOI 10.1177/0278364918767506
   Vallet B, 2015, COMPUT GRAPH-UK, V49, P126, DOI 10.1016/j.cag.2015.03.004
   Vo AV, 2016, IEEE J-STARS, V9, P5560, DOI 10.1109/JSTARS.2016.2581843
   Vosselman G., 2010, AIRBORNE TERRESTRIAL, V0, P0
   Wehr A, 1999, ISPRS J PHOTOGRAMM, V54, P68, DOI 10.1016/S0924-2716(99)00011-8
   Wu B, 2018, NEUROCOMPUTING, V321, P346, DOI 10.1016/j.neucom.2018.09.008
   Wu WX, 2019, PROC CVPR IEEE, V0, PP9613, DOI 10.1109/CVPR.2019.00985
   Xie YX, 2020, IEEE GEOSC REM SEN M, V8, P38, DOI 10.1109/MGRS.2019.2937630
   Xu YH, 2019, IEEE J-STARS, V12, P1709, DOI 10.1109/JSTARS.2019.2911113
   Yan WY, 2015, REMOTE SENS ENVIRON, V158, P295, DOI 10.1016/j.rse.2014.11.001
   Yokoya N, 2018, IEEE J-STARS, V11, P1363, DOI 10.1109/JSTARS.2018.2799698
   Zhang H., 2018, ARXIV180508318, V0, P0
   Zwicker M., 2018, POINT2SEQUENCE LEARN, V0, P0
NR 40
TC 9
Z9 9
U1 1
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1158
EP 1170
DI 10.1109/JSTARS.2020.3035274
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900037
DA 2023-04-26
ER

PT J
AU Jiang, X
   Zhang, XC
   Xin, QC
   Xi, X
   Zhang, PC
AF Jiang, Xin
   Zhang, Xinchang
   Xin, Qinchuan
   Xi, Xu
   Zhang, Pengcheng
TI Arbitrary-Shaped Building Boundary-Aware Detection With Pixel Aggregation Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Buildings; Image segmentation; Semantics; Remote sensing; Optimization; Image edge detection; Boundary quality; building extraction; high resolution; structural similarity (SSIM)
ID convolutional neural-network; semantic segmentation; lidar data; extraction; images; scale; classification; texture
AB Large-scale building extraction is an essential work in the field of a remote sensing image analysis. The high-resolution image extraction methods based on deep learning have achieved state-of-the-art performance. However, most of the previous work has focused on region accuracy rather than boundary quality. Aiming at the low-accuracy problems and incomplete boundary of the building extraction method, we propose a predictive optimization architecture, BAPANet. Notably, the architecture consists of an encoder-decoder network, and residual refinement modules responsible for prediction, and refinement. The objective function optimizes the network in the form of three levels (pixel, feature map, and patch) by fusing three loss functions: binary cross-entropy, intersection over-union, and structural similarity. The five public datasets' experimental results show that the extraction method in this article has high region accuracy, and the boundary of buildings is clear and complete.
C1 [Jiang, Xin; Xin, Qinchuan] Sun Yat Sen Univ, Guangzhou 510275, Peoples R China.
   [Zhang, Xinchang] Guangzhou Univ, Guangzhou 510275, Peoples R China.
   [Xi, Xu] Suzhou Univ Sci & Technol, Suzhou 215000, Peoples R China.
   [Zhang, Pengcheng] Guangzhou Urban Planning & Design Survey Res Inst, Guangzhou 510275, Peoples R China.
C3 Sun Yat Sen University; Guangzhou University; Suzhou University of Science & Technology
RP Zhang, XC (corresponding author), Guangzhou Univ, Guangzhou 510275, Peoples R China.
EM jiangx3@mail.sustech.edu.cn; eeszxc@mail.sysu.edu.cn; xinqinchuan@mail.sysu.edu.cn; xixu2016sysu@outlook.com; 1260142133@qq.com
FU National Key R&D Program of China [2018YFB2100702, 2017YFA0604300, 2017YFA0604400]; National Natural Science Foundation of China [41875122, 41431178, 41801351, 41671453]; Natural Science Foundation of Guangdong Province [2016A030311016]; Research Institute of Henan Spatio-Temporal Big Data Industrial Technology [2017DJA001, BTZH2018001]; Hunan Botong Information Company, Ltd. [BTZH2018001]; Western Talent [2018XBYJRC004]; Guangdong Top Young Talents of Science and Technology [2017TQ04Z359]
CR Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Awrangjeb M, 2011, INT ARCH PHOTOGRAMM, V38-3, P143
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Berman M, 2018, PROC CVPR IEEE, V0, PP4413, DOI 10.1109/CVPR.2018.00464
   Chai DF, 2020, ISPRS J PHOTOGRAMM, V161, P309, DOI 10.1016/j.isprsjprs.2020.01.023
   Chen Q, 2019, ISPRS J PHOTOGRAMM, V147, P42, DOI 10.1016/j.isprsjprs.2018.11.011
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.32
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P684
   Galvanin EAD, 2012, IEEE T GEOSCI REMOTE, V50, P981, DOI 10.1109/TGRS.2011.2163823
   [Дунаева Александра Валерьевна Dunaeva A.V.], 2017, ВЕСТНИК ЮЖНО-УРАЛЬСКОГО ГОСУДАРСТВЕННОГО УНИВЕРСИТЕТА. СЕРИЯ: ВЫЧИСЛИТЕЛЬНАЯ МАТЕМАТИКА И ИНФОРМАТИКА BULLETIN OF THE SOUTH URAL STATE UNIVERSITY. SERIES: COMPUTATIONAL MATHEMATICS AND SOFTWARE ENGINEERING VESTNIK YUZHNO-URALSKOGO GOSUDARSTVENNOGO UNIVERSITETA. SERIYA: VYCHISLITELNAYA MATEMATIKA I INFORMATIKA, V6, P84, DOI 10.14529/cmse170306
   Ferraioli G, 2010, IEEE T GEOSCI REMOTE, V48, P1224, DOI 10.1109/TGRS.2009.2029338
   Hamer MJM, 2019, DISASTER MED PUBLIC, V13, P400, DOI 10.1017/dmp.2018.44
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Huang X, 2017, IEEE J-STARS, V10, P654, DOI 10.1109/JSTARS.2016.2587324
   Huang ZM, 2016, INT GEOSCI REMOTE SE, V0, PP1835, DOI 10.1109/IGARSS.2016.7729471
   Islam M.A., 2017, BIODIESEL PRODUCTION, V0, P0, DOI DOI 10.5244/C.31.61
   Karimi D, 2020, IEEE T MED IMAGING, V39, P499, DOI 10.1109/TMI.2019.2930068
   Laliberte AS, 2009, IEEE T GEOSCI REMOTE, V47, P761, DOI 10.1109/TGRS.2008.2009355
   Li E, 2017, IEEE J-STARS, V10, P906, DOI 10.1109/JSTARS.2016.2603184
   Li XX, 2017, PROC CVPR IEEE, V0, PP6459, DOI 10.1109/CVPR.2017.684
   Lin C, 1998, COMPUT VIS IMAGE UND, V72, P101, DOI 10.1006/cviu.1998.0724
   LIOW YT, 1990, COMPUT VISION GRAPH, V49, P242, DOI 10.1016/0734-189X(90)90139-M
   Liu PH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070830
   Liu Y, 1900, V2019, V0, P0
   Liu YC, 2018, ISPRS J PHOTOGRAMM, V145, P78, DOI 10.1016/j.isprsjprs.2017.12.007
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Maltezos E, 2019, IEEE GEOSCI REMOTE S, V16, P155, DOI 10.1109/LGRS.2018.2867736
   Marcos D, 2018, ISPRS J PHOTOGRAMM, V145, P96, DOI 10.1016/j.isprsjprs.2018.01.021
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Mnih V., 2013, MACHINE LEARNING AER, V0, P0
   Peng C, 2017, PROC CVPR IEEE, V0, PP1743, DOI 10.1109/CVPR.2017.189
   Perazzi F, 2012, PROC CVPR IEEE, V0, PP733, DOI 10.1109/CVPR.2012.6247743
   Rottensteiner F., 2012, ISPRS ANN PHOTOGRAMM, V0, P293
   Simonyan K, 2015, ARXIV, V0, P0
   Sirmacek B, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, V0, P6
   Sohn G, 2007, ISPRS J PHOTOGRAMM, V62, P43, DOI 10.1016/j.isprsjprs.2007.01.001
   Sun Y, 2018, ISPRS J PHOTOGRAMM, V143, P3, DOI 10.1016/j.isprsjprs.2018.06.005
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tally RT, 2018, FRONT COLLECT, V0, PP599, DOI 10.1007/978-3-319-72478-2_32
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang TT, 2017, IEEE I CONF COMP VIS, V0, PP4039, DOI 10.1109/ICCV.2017.433
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091461
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010144
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yang MK, 2018, PROC CVPR IEEE, V0, PP3684, DOI 10.1109/CVPR.2018.00388
   Yuan JY, 2018, IEEE T PATTERN ANAL, V40, P2793, DOI 10.1109/TPAMI.2017.2750680
   Zhang XY, 2016, REMOTE SENS ENVIRON, V178, P172, DOI 10.1016/j.rse.2016.03.015
   Zhang Y, 1999, ISPRS J PHOTOGRAMM, V54, P50, DOI 10.1016/S0924-2716(98)00027-6
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
   Zhong C, 2015, INT GEOSCI REMOTE SE, V0, PP3345, DOI 10.1109/IGARSS.2015.7326535
NR 56
TC 6
Z9 6
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2699
EP 2710
DI 10.1109/JSTARS.2020.3017934
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XW3GG
UT WOS:000735511500001
DA 2023-04-26
ER

PT J
AU Chen, YY
   Ming, DP
   Ling, X
   Lv, XW
   Zhou, CH
AF Chen, Yangyang
   Ming, Dongping
   Ling, Xiao
   Lv, Xianwei
   Zhou, Chenghu
TI Landslide Susceptibility Mapping Using Feature Fusion-Based CPCNN-ML in Lantau Island, Hong Kong
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Terrain factors; Numerical models; Feature extraction; Training; Statistical analysis; Geology; Reliability; Convolutional neural networks (CNNs); landslide susceptibility mapping (LSM); Lantau Island; remote sensing
ID convolutional neural-networks; classification; prediction; model; area; integration; hazard
AB Landslide susceptibility mapping (LSM) is an effective way to predict spatial probability of landslide occurrence. Existing convolutional neural network (CNN)-based methods apply self-built CNN with simple structure, which failed to reach CNN's full potential on high-level feature extraction, meanwhile ignored the use of numerical predisposing factors. For the purpose of exploring feature fusion based CNN models with greater reliability in LSM, this study proposes an ensemble model based on channel-expanded pre-trained CNN and traditional machine learning model (CPCNN-ML). In CPCNN-ML, pre-trained CNN with mature structure is modified to excavate high-level features of multichannel predisposing factor layers. LSM result is generated by traditional machine learning (ML) model based on hybrid feature of high-level features and numerical predisposing factors. Lantau Island, Hong Kong is selected as study area; temporal landslide inventory is used for model training and evaluation. Experimental results show that CPCNN-ML has ability to predict landslide occurrence with high reliability, especially the CPCNN-ML based on random forest. Contrast experiments with self-built CNN and traditional ML models further embody the superiority of CPCNN-ML. It is worth noting that coastal regions are newly identified landslide-prone regions compared with previous research. This finding is of great reference value for Hong Kong authorities to formulate appropriate disaster prevention and mitigation policies.
C1 [Chen, Yangyang; Ming, Dongping; Ling, Xiao] China Univ Geosci Beijing, Sch Informat Engn, Beijing 100083, Peoples R China.
   [Lv, Xianwei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Zhou, Chenghu] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.
C3 China University of Geosciences; Wuhan University; Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS
RP Ming, DP (corresponding author), China Univ Geosci Beijing, Sch Informat Engn, Beijing 100083, Peoples R China.
EM jimmyxiyangyang@hotmail.com; mingdp@cugb.edu.cn; lingx0527@163.com; xianweilv@whu.edu.cn; zhouch@lreis.ac.cn
FU China Geological Survey [DD20191006]; National Natural Science Foundation of China [41671369]; National Key Research and Development Program [2017YFB0503600-05]; Fundamental Research Funds for the Central Universities
CR Achour Y, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2980-6
   Amatya P, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192284
   Anagnostopoulos GG, 2015, WATER RESOUR RES, V51, P7501, DOI 10.1002/2015WR016909
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030475
   Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Pham BT, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11164386
   Blaschke T., 2019, EGU GEN ASSEMBLY 201, V0, P0
   Boureau Y.-L., 2010, P 27 INT C INT C MAC, V0, P111
   Brandmeier M, 2019, P INT ARCH PHOT REM, V0, P55
   Chae BG, 2017, GEOSCI J, V21, P1033, DOI 10.1007/s12303-017-0034-4
   Chen W, 2019, GEOCARTO INT, V34, P1177, DOI 10.1080/10106049.2019.1588393
   Chen W, 2018, CATENA, V164, P135, DOI 10.1016/j.catena.2018.01.012
   Chen YY, 2019, EARTH SCI INFORM, V12, P341, DOI 10.1007/s12145-019-00383-2
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Dhillon Anamika, 2020, PROGRESS IN ARTIFICIAL INTELLIGENCE, V9, P85, DOI 10.1007/s13748-019-00203-0
   Fang ZC, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13020238
   Fang ZC, 2020, COMPUT GEOSCI-UK, V139, P0, DOI 10.1016/j.cageo.2020.104470
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Froude MJ, 2018, NAT HAZARD EARTH SYS, V18, P2161, DOI 10.5194/nhess-18-2161-2018
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11172046
   Ghorbanzadeh O, 2019, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON GEOGRAPHICAL INFORMATION SYSTEMS THEORY, V0, P33, DOI 10.5220/0007675300330040
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gupta R., 2012, J S ASIA DISASTER ST, V2, P81
   Guzzetti F, 2005, GEOMORPHOLOGY, V72, P272, DOI 10.1016/j.geomorph.2005.06.002
   Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007
   Haque U, 2016, LANDSLIDES, V13, P1545, DOI 10.1007/s10346-016-0689-3
   Huang FM, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9060377
   Huang FM, 2020, LANDSLIDES, V17, P2919, DOI 10.1007/s10346-020-01473-9
   Huang FM, 2020, CATENA, V191, P0, DOI 10.1016/j.catena.2020.104580
   Huang FM, 2020, LANDSLIDES, V17, P217, DOI 10.1007/s10346-019-01274-9
   Huang FM, 2018, GEOMAT NAT HAZ RISK, V9, P919, DOI 10.1080/19475705.2018.1482963
   Huang Y, 2018, CATENA, V165, P520, DOI 10.1016/j.catena.2018.03.003
   Imamverdiyev Y, 2019, J PETROL SCI ENG, V174, P216, DOI 10.1016/j.petrol.2018.11.023
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lu TT, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091496
   Luo XG, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0215134
   Lv XW, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121946
   Lv ZY, 2020, IEEE J-STARS, V13, P4575, DOI 10.1109/JSTARS.2020.2980895
   Marcum RA, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042614
   Melchiorre C, 2006, IEEE IJCNN, V0, P4375
   Nair V., 2010, P 27 INT C MACH LEAR, V0, P807
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Nichol J, 2005, LAND DEGRAD DEV, V16, P243, DOI 10.1002/ldr.648
   Pirasteh S., 2017, GEOENVIRONMENTAL DIS, V4, P17, DOI 10.1186/s40677-017-0083-z
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI 10.1162/NECO_a_00990
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Roy J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232866
   Scaioni M, 2014, REMOTE SENS-BASEL, V6, P9600, DOI 10.3390/rs60x000x
   Shao ZF, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12061050
   Shi WZ, 2021, IEEE T GEOSCI REMOTE, V59, P4654, DOI 10.1109/TGRS.2020.3015826
   Shirzadi A, 2017, CATENA, V157, P213, DOI 10.1016/j.catena.2017.05.016
   Stanley T, 2017, NAT HAZARDS, V87, P145, DOI 10.1007/s11069-017-2757-y
   Tofani V, 2013, NAT HAZARD EARTH SYS, V13, P299, DOI 10.5194/nhess-13-299-2013
   Ullo SL, 2019, INT GEOSCI REMOTE SE, V0, PP9646, DOI 10.1109/IGARSS.2019.8898632
   van Westen CJ, 2008, ENG GEOL, V102, P112, DOI 10.1016/j.enggeo.2008.03.010
   Venture M.-F. J, 2007, FINAL REPORT COMPILA, V0, P0
   Pham VD, 2020, IEEE ACCESS, V8, P32727, DOI 10.1109/ACCESS.2020.2973415
   Wang Y, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104217
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Wang Y, 2019, MATH PROBL ENG, V2019, P0, DOI 10.1155/2019/8389368
   Ye CM, 2019, IEEE J-STARS, V12, P5047, DOI 10.1109/JSTARS.2019.2951725
   Zhang HR, 2019, IEEE J-STARS, V12, P4239, DOI 10.1109/JSTARS.2019.2938554
   Zhang YH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232801
   Zhou KQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11172065
   Zhou W, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111458
   Zhu Q, 2020, IEEE J-STARS, V13, P3917, DOI 10.1109/JSTARS.2020.3006192
NR 69
TC 18
Z9 18
U1 8
U2 37
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3625
EP 3639
DI 10.1109/JSTARS.2021.3066378
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RO0RM
UT WOS:000640757900003
DA 2023-04-26
ER

PT J
AU Maxwell, AE
   Warner, TA
   Guillen, LA
AF Maxwell, Aaron E.
   Warner, Timothy A.
   Guillen, Luis Andres
TI Accuracy Assessment in Convolutional Neural Network-Based Deep Learning Remote Sensing Studies-Part 1: Literature Review
SO REMOTE SENSING
LA English
DT Review
DE accuracy assessment; thematic mapping; feature extraction; object detection; semantic segmentation; instance segmentation; deep learning
ID map accuracy; semantic segmentation; scene classification; sampling designs; estimating area; imagery; cover; allocation; framework
AB Convolutional neural network (CNN)-based deep learning (DL) is a powerful, recently developed image classification approach. With origins in the computer vision and image processing communities, the accuracy assessment methods developed for CNN-based DL use a wide range of metrics that may be unfamiliar to the remote sensing (RS) community. To explore the differences between traditional RS and DL RS methods, we surveyed a random selection of 100 papers from the RS DL literature. The results show that RS DL studies have largely abandoned traditional RS accuracy assessment terminology, though some of the accuracy measures typically used in DL papers, most notably precision and recall, have direct equivalents in traditional RS terminology. Some of the DL accuracy terms have multiple names, or are equivalent to another measure. In our sample, DL studies only rarely reported a complete confusion matrix, and when they did so, it was even more rare that the confusion matrix estimated population properties. On the other hand, some DL studies are increasingly paying attention to the role of class prevalence in designing accuracy assessment approaches. DL studies that evaluate the decision boundary threshold over a range of values tend to use the precision-recall (P-R) curve, the associated area under the curve (AUC) measures of average precision (AP) and mean average precision (mAP), rather than the traditional receiver operating characteristic (ROC) curve and its AUC. DL studies are also notable for testing the generalization of their models on entirely new datasets, including data from new areas, new acquisition times, or even new sensors.
C1 [Maxwell, Aaron E.; Warner, Timothy A.; Guillen, Luis Andres] West Virginia Univ, Dept Geol & Geog, Morgantown, WV 26505 USA.
C3 West Virginia University
RP Maxwell, AE (corresponding author), West Virginia Univ, Dept Geol & Geog, Morgantown, WV 26505 USA.
EM Aaron.Maxwell@mail.wvu.edu; Tim.Warner@mail.wvu.edu; lg0018@mix.wvu.edu
FU National Science Foundation (NSF) [2046059]; Directorate For Geosciences [2046059] Funding Source: National Science Foundation; Division Of Earth Sciences [2046059] Funding Source: National Science Foundation
CR Abdalla A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11243001
   Abraham N, 2019, I S BIOMED IMAGING, V0, PP683, DOI 10.1109/ISBI.2019.8759329
   Aksoy S, 2005, IEEE T GEOSCI REMOTE, V43, P581, DOI 10.1109/TGRS.2004.839547
   [Anonymous], 2017, P IEEE INT C COMP VI, V0, P0
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bai YB, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13112220
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Basu S, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), V0, P0, DOI DOI 10.1145/2820783.2820816
   Bertels J, 2020, LECT NOTES COMPUT SC, V11992, P89, DOI 10.1007/978-3-030-46640-4_9
   Bertels J, 2019, LECT NOTES COMPUT SC, V11765, P92, DOI 10.1007/978-3-030-32245-8_11
   Bhuiyan MA, 2020, J IMAGING, V6, P0, DOI 10.3390/jimaging6090097
   Boyd Kendrick, 2013, MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES. EUROPEAN CONFERENCE, V0, P451, DOI 10.1007/978-3-642-40994-3_29
   Brandtberg T, 2003, IEEE T GEOSCI REMOTE, V41, P102, DOI 10.1109/TGRS.2002.808059
   Bundzel M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223685
   Cai YZ, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13071367
   Carbonneau PE, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112107
   Chen J, 2020, IEEE GEOSCI REMOTE S, V17, P681, DOI 10.1109/LGRS.2019.2930462
   Chen L-C., 2018, P EUROPEAN C COMPUTE, V0, P801
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2020, IEEE J-STARS, V13, P3735, DOI 10.1109/JSTARS.2020.3005403
   Clinton N, 2010, PHOTOGRAMM ENG REM S, V76, P289, DOI 10.14358/PERS.76.3.289
   Congalton R, 1900, VVOLUME 12, V0, P383
   Congalton R.G., 2019, ASSESSING ACCURACY R, V0, P0
   CONGALTON RG, 1983, PHOTOGRAMM ENG REM S, V49, P1671
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Cortes C., 2005, ADV NEURAL INFORM PR, V17, P305
   Du L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040644
   Dziedzic T., 2020, ARXIV200502264, V0, P0
   Fan Jerome, 2006, CJEM, V8, P19
   Foody G., 2009, SAGE HDB REMOTESENSI, V0, P0
   Foody GM, 2008, INT J REMOTE SENS, V29, P3137, DOI 10.1080/01431160701442120
   Foody GM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111630
   Foody GM, 2009, INT J REMOTE SENS, V30, P5273, DOI 10.1080/01431160903130937
   Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   He C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091501
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12183053
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101667
   Howard J, 2020, INFORMATION, V11, P0, DOI 10.3390/info11020108
   Huang Z., 2018, PYTORCH SEMANTIC SEG, V0, P0
   Jiao LB, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122001
   Jin SC, 2020, IEEE T GEOSCI REMOTE, V58, P2644, DOI 10.1109/TGRS.2019.2953092
   Keilwagen J, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0092209
   Kerner HR, 2019, IEEE J-STARS, V12, P3900, DOI 10.1109/JSTARS.2019.2936771
   Li WM, 2020, IEEE J-STARS, V13, P1986, DOI 10.1109/JSTARS.2020.2988477
   Li WW, 2020, INT J GEOGR INF SCI, V34, P637, DOI 10.1080/13658816.2018.1542697
   Li XB, 2020, IEEE GEOSCI REMOTE S, V17, P297, DOI 10.1109/LGRS.2019.2918955
   Li YS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12234003
   Li YQ, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18041172
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Lobo JM, 2008, GLOBAL ECOL BIOGEOGR, V17, P145, DOI 10.1111/j.1466-8238.2007.00358.x
   Luo S, 2020, ISPRS J PHOTOGRAMM, V167, P443, DOI 10.1016/j.isprsjprs.2020.07.016
   Ma J, 2021, MED IMAGE ANAL, V71, P0, DOI 10.1016/j.media.2021.102035
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   Maxwell AE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12244145
   Maxwell AE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030547
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   MCNEIL BJ, 1984, MED DECIS MAKING, V4, P137, DOI 10.1177/0272989X8400400203
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P7557, DOI 10.1109/TGRS.2020.2979552
   Oh S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182981
   Panagiotou E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122002
   Papp A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12132111
   Park JH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12233941
   Pierdicca R, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12061005
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Prakash N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030346
   Qamar F, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162540
   Qian JH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172669
   Qiu CP, 2020, ISPRS J PHOTOGRAMM, V163, P152, DOI 10.1016/j.isprsjprs.2020.01.028
   Radoux J, 2011, INT J GEOGR INF SCI, V25, P895, DOI 10.1080/13658816.2010.498378
   Radoux J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9070646
   Radoux J, 2014, REMOTE SENS ENVIRON, V142, P9, DOI 10.1016/j.rse.2013.10.030
   Rangnekar A, 2020, IEEE T GEOSCI REMOTE, V58, P8116, DOI 10.1109/TGRS.2020.2987199
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Robinson C., 2019, PROC CVPR IEEE, V0, PP12726, DOI 10.1109/CVPR.2019.01301
   Saito T, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0118432
   Salomonson VV, 2004, REMOTE SENS ENVIRON, V89, P351, DOI 10.1016/j.rse.2003.10.016
   Shi YL, 2020, ISPRS J PHOTOGRAMM, V159, P184, DOI 10.1016/j.isprsjprs.2019.11.004
   Singh A, 2020, IEEE T GEOSCI REMOTE, V58, P7570, DOI 10.1109/TGRS.2020.2981082
   Soloy A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213659
   Stehman S.V., 2009, SAGE HDB REMOTE SENS, V0, P297
   Stehman SV, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.018
   Stehman SV, 2014, INT J REMOTE SENS, V35, P4923, DOI 10.1080/01431161.2014.930207
   Stehman SV, 2013, REMOTE SENS ENVIRON, V132, P202, DOI 10.1016/j.rse.2013.01.016
   Stehman SV, 2011, REMOTE SENS ENVIRON, V115, P3044, DOI 10.1016/j.rse.2011.06.007
   Stehman SV, 2012, REMOTE SENS LETT, V3, P111, DOI 10.1080/01431161.2010.541950
   Stehman SV, 2009, INT J REMOTE SENS, V30, P5243, DOI 10.1080/01431160903131000
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Stehman SV, 1999, INT J REMOTE SENS, V20, P2423, DOI 10.1080/014311699212100
   Stehman SV, 2004, PHOTOGRAMM ENG REM S, V70, P743, DOI 10.14358/PERS.70.6.743
   Stehman SV, 1996, PHOTOGRAMM ENG REM S, V62, P401
   STEHMAN SV, 1995, INT J REMOTE SENS, V16, P589, DOI 10.1080/01431169508954425
   Stehman SV, 1998, REMOTE SENS ENVIRON, V64, P331, DOI 10.1016/S0034-4257(98)00010-8
   Stehman SV, 2000, REMOTE SENS ENVIRON, V72, P35, DOI 10.1016/S0034-4257(99)00090-5
   Stehman SV, 1997, REMOTE SENS ENVIRON, V60, P258, DOI 10.1016/S0034-4257(96)00176-9
   Stehman SV, 2001, PHOTOGRAMM ENG REM S, V67, P727
   STEHMAN SV, 1992, PHOTOGRAMM ENG REM S, V58, P1343
   Su H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060989
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Sun F, 2021, ALGORITHMS, V14, P0, DOI 10.3390/a14060159
   Sun X, 2020, IEEE J-STARS, V13, P5398, DOI 10.1109/JSTARS.2020.3021098
   Sun Y, 2019, FORESTS, V10, P0, DOI 10.3390/f10111047
   Tharwat A., 2021, APPL COMPUTING INFOR, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Sivakumar ANV, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12132136
   Waldner F, 2020, REMOTE SENS ENVIRON, V245, P0, DOI 10.1016/j.rse.2020.111741
   Wandishin MS, 2009, WEATHER FORECAST, V24, P530, DOI 10.1175/2008WAF2222119.1
   Wang MC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121933
   Wang P, 2018, LECT NOTES COMPUT SC, V11045, P119, DOI 10.1007/978-3-030-00889-5_14
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Wang WJ, 2019, IEEE ACCESS, V7, P47918, DOI 10.1109/ACCESS.2019.2907564
   Wang Z., 2019, P 5 INT C COMM INF P, V0, P124
   Warner TA, 2006, SCI CHINA SER E, V49, P128, DOI 10.1007/s11431-006-8114-0
   Witharana C, 2020, ISPRS J PHOTOGRAMM, V170, P174, DOI 10.1016/j.isprsjprs.2020.10.010
   Xu SW, 2020, IEEE J-STARS, V13, P6124, DOI 10.1109/JSTARS.2020.3028158
   Yang MD, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040633
   Yang RL, 2017, J VIS COMMUN IMAGE R, V48, P396, DOI 10.1016/j.jvcir.2017.02.002
   Ye S, 2018, ISPRS J PHOTOGRAMM, V141, P137, DOI 10.1016/j.isprsjprs.2018.04.002
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Yun P, 2019, IEEE ROBOT AUTOM LET, V4, P1263, DOI 10.1109/LRA.2019.2894858
   Yurtkulu S.C., 2019, 2019 27 SIGN PROC CO, V0, P1
   Zang N, 2021, IEEE J-STARS, V14, P5372, DOI 10.1109/JSTARS.2021.3078631
   Zhang CM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020213
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang LB, 2020, IEEE GEOSCI REMOTE S, V17, P117, DOI 10.1109/LGRS.2019.2914490
   Zhang TW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182997
   Zhang WX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071085
   Zhang WX, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091487
   Zhang X, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030417
   Zhang XZ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030548
   Zhang YJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071196
   Zhang Z, 2018, ARXIV180507836, V0, P0
   Zhao RJ, 2020, IEEE DATA MINING, V0, PP851, DOI 10.1109/ICDM50108.2020.00094
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 144
TC 28
Z9 28
U1 7
U2 52
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL 15
PY 2021
VL 13
IS 13
BP 
EP 
DI 10.3390/rs13132450
PG 27
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TF9SY
UT WOS:000671055800001
DA 2023-04-26
ER

PT J
AU Gigon, A
   Mosinska, A
   Montesel, A
   Derradji, Y
   Apostolopoulos, S
   Ciller, C
   De Zanet, S
   Mantel, I
AF Gigon, Anthony
   Mosinska, Agata
   Montesel, Andrea
   Derradji, Yasmine
   Apostolopoulos, Stefanos
   Ciller, Carlos
   De Zanet, Sandro
   Mantel, Irmela
TI Personalized Atrophy Risk Mapping in Age-Related Macular Degeneration
SO TRANSLATIONAL VISION SCIENCE & TECHNOLOGY
LA English
DT Article
DE atrophy; optical; coherence tomography; artificial; intelligence
ID geographic atrophy; progression; prediction; enhancement; secondary
AB Purpose: To develop and validate an automatic retinal pigment epithelial and outer retinal atrophy (RORA) progression prediction model for nonexudative age-related macular degeneration (AMD) cases in optical coherence tomography (OCT) scans. Methods: Longitudinal OCT data from 129 eyes/119 patients with RORA was collected and separated into training and testing groups. RORA was automatically segmented in all scans and additionally manually annotated in the test scans. OCT-based features such as layers thicknesses, mean reflectivity, and a drusen height map served as an input to the deep neural network. Based on the baseline OCT scan or the previous visit OCT, en face RORA predictions were calculated for future patient visits. The performance was quantified over time with the means of Dice scores and square root area errors. Results: The average Dice score for segmentations at baseline was 0.85. When predicting progression from baseline OCTs, the Dice scores ranged from 0.73 to 0.80 for total RORA area and from 0.46 to 0.72 for RORA growth region. The square root area error ranged from 0.13 mm to 0.33 mm. By providing continuous time output, the model enabled creation of a patient-specific atrophy risk map. Conclusions: We developed a machine learning method for RORA progression prediction, which provides continuous-time output. It was used to compute atrophy risk maps, which indicate time-to-RORA-conversion, a novel and clinically relevant way of representing disease progression. Translational Relevance: Application of recent advances in artificial intelligence to predict patient-specific progression of atrophic AMD.
C1 [Gigon, Anthony; Montesel, Andrea; Derradji, Yasmine; Mantel, Irmela] Univ Lausanne, Jules Gonin Eye Hosp, Fdn Asile Aveugles, Dept Ophthalmol, Lausanne, Switzerland.
   [Mosinska, Agata; Apostolopoulos, Stefanos; Ciller, Carlos; De Zanet, Sandro] RetinAI Med AG, Bern, Switzerland.
C3 University of Lausanne
RP Mantel, I (corresponding author), Jules Gonin Eye Hosp, 15 Ave France,CP 5143, CH-1004 Lausanne, Switzerland.
EM irmela.mantel@fa2.ch
CR Apostolopoulos S, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-64724-8
   BIRD AEC, 1995, SURV OPHTHALMOL, V39, P367, DOI 10.1016/S0039-6257(05)80092-X
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS), V0, P0
   Cousins SW, 2019, INVEST OPHTH VIS SCI, V60, P0
   Dabov K, 2006, PROC SPIE, V6064, P0, DOI 10.1117/12.643267
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Derradji Y, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-01227-0
   Flaxman SR, 2017, LANCET GLOB HEALTH, V5, PE1221, DOI 10.1016/S2214-109X(17)30393-5
   Fleckenstein M, 2018, OPHTHALMOLOGY, V125, P369, DOI 10.1016/j.ophtha.2017.08.038
   Guymer RH, 2020, OPHTHALMOLOGY, V127, P394, DOI 10.1016/j.ophtha.2019.09.035
   Halupka KJ, 2018, BIOMED OPT EXPRESS, V9, P6205, DOI 10.1364/BOE.9.006205
   Holz FG, 2001, INVEST OPHTH VIS SCI, V42, P1051
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Jaffe GJ, 2021, OPHTHALMOL RETINA, V5, P855, DOI 10.1016/j.oret.2020.12.009
   Kuppermann BD, 2021, RETINA-J RET VIT DIS, V41, P144, DOI 10.1097/IAE.0000000000002789
   Liefers B, 2020, OPHTHALMOLOGY, V127, P1086, DOI 10.1016/j.ophtha.2020.02.009
   Mantel I, 2021, TRANSL VIS SCI TECHN, V10, P0, DOI 10.1167/tvst.10.4.17
   Moult EM, 2021, TRANSL VIS SCI TECHN, V10, P0, DOI 10.1167/tvst.10.7.26
   Niu SJ, 2016, OPHTHALMOLOGY, V123, P1737, DOI 10.1016/j.ophtha.2016.04.042
   Pfau M, 2020, JAMA OPHTHALMOL, V138, P1026, DOI 10.1001/jamaophthalmol.2020.2914
   Rogowska J, 2002, PHYS MED BIOL, V47, P641, DOI 10.1088/0031-9155/47/4/307
   Sadda SR, 2018, OPHTHALMOLOGY, V125, P537, DOI 10.1016/j.ophtha.2017.09.028
   Sayegh RG, 2017, AM J OPHTHALMOL, V179, P118, DOI 10.1016/j.ajo.2017.03.031
   Schmidt-Erfurth U, 2020, AM J OPHTHALMOL, V216, P257, DOI 10.1016/j.ajo.2020.03.042
   Schmidt-Erfurth U, 2018, INVEST OPHTH VIS SCI, V59, P3199, DOI 10.1167/iovs.18-24106
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Waldstein SM, 2020, JAMA OPHTHALMOL, V138, P740, DOI 10.1001/jamaophthalmol.2020.1376
   Wang JY, 2021, OPHTHALMIC RES, V64, P205, DOI 10.1159/000510507
   Wu ZC, 2014, OPHTHALMOLOGY, V121, P2415, DOI 10.1016/j.ophtha.2014.06.034
   Yehoshua Z, 2011, OPHTHALMOLOGY, V118, P679, DOI 10.1016/j.ophtha.2010.08.018
   Zhang YH, 2021, MED IMAGE ANAL, V68, P0, DOI 10.1016/j.media.2020.101893
   Zhang YH, 2019, I S BIOMED IMAGING, V0, PP565, DOI 10.1109/ISBI.2019.8759253
NR 33
TC 4
Z9 4
U1 0
U2 4
PU ASSOC RESEARCH VISION OPHTHALMOLOGY INC
PI ROCKVILLE
PA 12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA
SN 2164-2591
EI 
J9 TRANSL VIS SCI TECHN
JI Transl. Vis. Sci. Technol.
PD NOV 15
PY 2021
VL 10
IS 13
BP 
EP 
DI 10.1167/tvst.10.13.18
PG 13
WC Ophthalmology
SC Ophthalmology
GA XU5WJ
UT WOS:000734334400015
PM 34767623
DA 2023-04-26
ER

PT J
AU D'Amico, G
   Francini, S
   Giannetti, F
   Vangi, E
   Travaglini, D
   Chianucci, F
   Mattioli, W
   Grotti, M
   Puletti, N
   Corona, P
   Chirici, G
AF D'Amico, G.
   Francini, S.
   Giannetti, F.
   Vangi, E.
   Travaglini, D.
   Chianucci, F.
   Mattioli, W.
   Grotti, M.
   Puletti, N.
   Corona, P.
   Chirici, G.
TI A deep learning approach for automatic mapping of poplar plantations using Sentinel-2 imagery
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Big data; multitemporal classification; fully connected neural networks; forest tree crops; tree species mapping; deep learning
ID remote-sensing applications; classification; metaanalysis; landsat; area
AB Poplars are one of the most widespread fast-growing tree species used for forest plantations. Owing to their distinct features (fast growth and short rotation) and the dependency on the timber price market, poplar plantations are characterized by large inter-annual fluctuations in their extent and distribution. Therefore, monitoring poplar plantations requires a frequent update of information - not feasible by National Forest Inventories due to their periodicity - achievable by remote sensing systems applications. In particular, the new Sentinel-2 mission, with a revisiting period of 5 days, represents a potentially efficient tool for meeting this need. In this paper, we present a deep learning approach for mapping poplar plantations using Sentinel-2 time series. A reference dataset of poplar plantations was available for a large study area of more than 46,000 km(2) in Northern Italy and served as training and testing data. Two classification methods were compared: (1) a fully connected neural network (also called multilayer perceptron), and (2) a traditional logistic regression. The performance of the two approaches was estimated through bootstrapping procedure with a confidence interval of 99%. Results indicated for deep learning an omission error rate of 2.77%+/- 2.76%, showing improvements compared to logistic regression, omission error rate = 8.91%+/- 4.79%.
C1 [D'Amico, G.; Francini, S.; Giannetti, F.; Vangi, E.; Travaglini, D.; Chirici, G.] Univ Studi Firenze, Dept Agr Food Environm & Forestry, Florence, Italy.
   [Francini, S.] Univ Studi Tuscia, Dipt lInnovazione Sistemi Biologici Agro, Viterbo, Italy.
   [Francini, S.; Vangi, E.] Univ Studi Molise, Dipt Bioscienze Territorio, Pesche, Italy.
   [Chianucci, F.; Grotti, M.; Puletti, N.; Corona, P.] CREA, Res Ctr Forestry & Wood, Arezzo, Italy.
   [Mattioli, W.] CREA, Res Ctr Forestry & Wood, Rome, Italy.
   [Grotti, M.] ERSAF Reg Agcy Serv Agr & Forestry, Milan, Italy.
C3 University of Florence; Tuscia University; University of Molise; Consiglio per la Ricerca in Agricoltura e L'analisi Dell'economia Agraria (CREA); Consiglio per la Ricerca in Agricoltura e L'analisi Dell'economia Agraria (CREA)
RP Francini, S (corresponding author), Univ Studi Firenze, Dept Agr Food Environm & Forestry, Florence, Italy.
EM saverio.francini@unifi.it
FU Regione Lombardia [E86C18002690002]
CR Abadi M, 2017, MAPL17: PROCEEDINGS OF THE 1ST ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, V0, PP1, DOI 10.1145/3088525.3088527
   Agresti A., 2007, WILEY SERIES PROBABI, V0, P0
   Ahmad T, 2016, AGROFOREST SYST, V90, P289, DOI 10.1007/s10457-015-9854-2
   Alhassan V, 2020, NEURAL COMPUT APPL, V32, P8529, DOI 10.1007/s00521-019-04349-9
   Azar R, 2016, EUR J REMOTE SENS, V49, P361, DOI 10.5721/EuJRS20164920
   Ball J., 2005, UNASYLVA (ENGLISH ED.), V56, P3
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Boukir S., 2012, ISPRS ANN PHOTOGRAMM, V1, P111, DOI 10.5194/isprsannals-I-7-111-2012
   Bradleyel E., 1993, ADV PEDIAT, V0, P0, DOI DOI 10.1016/j.yapd.2013.04.017
   BRUZZONE L, 2017, P 2017 9 INT WORKSH, V0, PP1, DOI 10.1109/MULTI-TEMP.2017.8035230
   Chianucci Francesco, 2021, ANNALS OF SILVICULTURAL RESEARCH, V46, P8, DOI 10.12899/asr-2074
   Chianucci F, 2020, FOREST SCI, V66, P737, DOI 10.1093/forsci/fxaa021
   Chiarabaglio Pier Mario, 2018, ANNALS OF SILVICULTURAL RESEARCH, V42, P39, DOI 10.12899/asr-1494
   Chirici G, 2016, REMOTE SENS ENVIRON, V176, P282, DOI 10.1016/j.rse.2016.02.001
   Chollet F., 2017, DEEP LEARNING R MANN, V0, P0
   Coaloa D., 2019, SHERWOOD, V243, P33
   Corona P., 2018, LINEE INDIRIZZO PIOP, V0, P68
   Corona P, 2020, EUR J FOREST RES, V139, P981, DOI 10.1007/s10342-020-01300-9
   Corona Piermaria, 2018, ANNALS OF SILVICULTURAL RESEARCH, V42, P1, DOI 10.12899/ASR-1617
   DAmico G, 2021, IFOREST, V14, P144, DOI 10.3832/ifor3648-014
   DOdorico P, 2013, IEEE T GEOSCI REMOTE, V51, P1336, DOI 10.1109/TGRS.2012.2235447
   Devarriya D, 2020, EXPERT SYST APPL, V140, P0, DOI 10.1016/j.eswa.2019.112866
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Enwright NM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080976
   Forstmaier A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142176
   Francini S, 2021, INT J REMOTE SENS, V42, P4697, DOI 10.1080/01431161.2021.1899334
   Francini S, 2020, EUR J REMOTE SENS, V53, P233, DOI 10.1080/22797254.2020.1806734
   Garcia J., 2018, EMBRAPA DOCUMENTATIO, V156, P0
   Gomez C, 2016, ISPRS J PHOTOGRAMM, V116, P55, DOI 10.1016/j.isprsjprs.2016.03.008
   Hagolle O, 2015, REMOTE SENS-BASEL, V7, P2668, DOI 10.3390/rs70302668
   Hamrouni Y., 2020, INT ARCH PHOTOGRAMME, V43, P1457, DOI 10.5194/isprs-archives-XLIII-B3-2020-1457-2020
   Hawrylo P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203331
   Heaton J., 2017, GENET PROGRAM EVOL M, V19, P305, DOI 10.1007/S10710-017-9314-Z
   Hu YF, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10122053
   Inglada J, 2015, REMOTE SENS-BASEL, V7, P12356, DOI 10.3390/rs70912356
   JAAFOR O, 2020, LECT NOTES NETWORKS, V0, P0
   Laurin GV, 2021, FORESTRY, V94, P407, DOI 10.1093/forestry/cpaa043
   Li XC, 2015, REMOTE SENS ENVIRON, V166, P78, DOI 10.1016/j.rse.2015.06.007
   Liu XN, 2021, APPL ARTIF INTELL, V35, P13, DOI 10.1080/08839514.2020.1831226
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Marcelli A, 2020, SILVA FENN, V54, P0, DOI 10.14214/sf.10247
   Maria Di Biase Rosa, 2018, ANNALS OF SILVICULTURAL RESEARCH, V42, P46, DOI 10.12899/asr-1738
   Mathieu R, 2007, SENSORS-BASEL, V7, P2860, DOI 10.3390/s7112860
   Mattioli W., 2019, SHERWOOD, V239, P7
   Mazzia V, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10010238
   McRoberts RE, 2013, IEEE J-STARS, V6, P27, DOI 10.1109/JSTARS.2012.2227299
   Muller-Wilm U., 2013, P ESA LIV PLAN S ED, V0, P9
   Mura M, 2018, INT J APPL EARTH OBS, V66, P126, DOI 10.1016/j.jag.2017.11.013
   Najafabadi M.M., 2015, J BIG DATA-GER, V2, P21, DOI 10.1186/S40537-014-0007-7
   Nwankpa C., 2018, ARXIV181103378, V0, P0
   Puletti N, 2019, FORESTS, V10, P0, DOI 10.3390/f10030239
   Rizvi RH, 2020, AGROFOREST SYST, V94, P2185, DOI 10.1007/s10457-020-00540-3
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tonbul H, 2020, J GEOD SCI, V10, P14, DOI 10.1515/jogs-2020-0003
   Tong XY, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111322
   Vrieling A, 2018, REMOTE SENS ENVIRON, V215, P517, DOI 10.1016/j.rse.2018.03.014
   Vuolo F, 2018, INT J APPL EARTH OBS, V72, P122, DOI 10.1016/j.jag.2018.06.007
   White JC, 2014, CAN J REMOTE SENS, V40, P192, DOI 10.1080/07038992.2014.945827
   White JC, 2016, CAN J REMOTE SENS, V42, P619, DOI 10.1080/07038992.2016.1207484
   Yu XR, 2017, GISCI REMOTE SENS, V54, P741, DOI 10.1080/15481603.2017.1323377
   Zheng JP, 2019, INT GEOSCI REMOTE SE, V0, PP1422, DOI 10.1109/IGARSS.2019.8898360
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 64
TC 8
Z9 8
U1 5
U2 18
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD NOV 17
PY 2021
VL 58
IS 8
BP 1352
EP 1368
DI 10.1080/15481603.2021.1988427
EA OCT 2021
PG 17
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA XN8NW
UT WOS:000708841900001
DA 2023-04-26
ER

PT J
AU Wu, TJ
   Luo, JC
   Gao, LJ
   Sun, YW
   Dong, W
   Zhou, YN
   Liu, W
   Hu, XD
   Xi, JB
   Wang, CP
   Yang, Y
AF Wu, Tianjun
   Luo, Jiancheng
   Gao, Lijing
   Sun, Yingwei
   Dong, Wen
   Zhou, Ya'nan
   Liu, Wei
   Hu, Xiaodong
   Xi, Jiangbo
   Wang, Changpeng
   Yang, Yun
TI Geo-Object-Based Vegetation Mapping via Machine Learning Methods with an Intelligent Sample Collection Scheme: A Case Study of Taibai Mountain, China
SO REMOTE SENSING
LA English
DT Article
DE vegetation mapping; geo-objects; remote sensing; multi-source geospatial data; sample collection and purification
ID artificial neural-networks; land-cover; time-series; multispectral imagery; forest types; slope aspect; mean-shift; classification; maps; multiresolution
AB Precise vegetation maps of mountainous areas are of great significance to grasp the situation of an ecological environment and forest resources. In this paper, while multi-source geospatial data can generally be quickly obtained at present, to realize effective vegetation mapping in mountainous areas when samples are difficult to collect due to their perilous terrain and inaccessible deep forest, we propose a novel and intelligent method of sample collection for machine-learning (ML)-based vegetation mapping. First, we employ geo-objects (i.e., polygons) from topographic partitioning and constrained segmentation as basic mapping units and formalize the problem as a supervised classification process using ML algorithms. Second, a previously available vegetation map with rough-scale label information is overlaid on the geo-object-level polygons, and candidate geo-object-based samples can be identified when all the grids' labels of vegetation types within the geo-objects are the same. Third, various kinds of geo-object-level features are extracted according to high-spatial-resolution remote sensing (HSR-RS) images and multi-source geospatial data. Some unreliable geo-object-based samples are rejected in the candidate set by comparing their features and the rules based on local expert knowledge. Finally, based on these automatically collected samples, we train the model using a random forest (RF)-based algorithm and classify all the geo-objects with labels of vegetation types. A case experiment of Taibai Mountain in China shows that the methodology has the ability to achieve good vegetation mapping results with the rapid and convenient sample collection scheme. The map with a finer geographic distribution pattern of vegetation could clearly promote the vegetation resources investigation and monitoring of the study area; thus, the methodological framework is worth popularizing in the mapping areas such as mountainous regions where the field survey sampling is difficult to implement.
C1 [Wu, Tianjun; Wang, Changpeng] Changan Univ, Sch Sci, Xian 710064, Peoples R China.
   [Luo, Jiancheng; Gao, Lijing; Dong, Wen; Liu, Wei; Hu, Xiaodong] Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.
   [Luo, Jiancheng; Gao, Lijing; Dong, Wen; Liu, Wei; Hu, Xiaodong] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
   [Sun, Yingwei] Chinese Acad Agr Sci, Inst Agr Resources & Reg Planning, Beijing 100081, Peoples R China.
   [Zhou, Ya'nan] Hohai Univ, Sch Hydrol & Water Resources, Nanjing 210098, Peoples R China.
   [Xi, Jiangbo; Yang, Yun] Changan Univ, Sch Geol Engn & Geomat, Xian 710064, Peoples R China.
C3 Chang'an University; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Agricultural Sciences; Institute of Agricultural Resources & Regional Planning, CAAS; Hohai University; Chang'an University
RP Luo, JC (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.; Luo, JC (corresponding author), Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
EM tjwu@chd.edu.cn; luojc@radi.ac.cn; gaolj@radi.ac.cn; sunyingwei@caas.cn; dongwen01@radi.ac.cn; zhouyn@hhu.edu.cn; liuwei18@mails.ucas.ac.cn; huxd@radi.ac.cn; xijiangbo@chd.edu.cn; cpwang@chd.edu.cn; yangyunbox@chd.edu.cn
FU National Key Research and Development Program [2017YFB0503600]; National Natural Science Foundation of China [41631179, 42071316, 61806022, 12001057]; Fundamental Research Funds for the Central Universities, CHD [300102120201, 300102269205, 300102320202, 300102269103]; Ningxia Academy of Agricultural and Forestry Sciences Foreign Science and Technology Cooperation Project [07030002]; State Key Laboratory of Geo-Information Engineering [SKLGIE2018-M-3-4]; Open Projects of Key Laboratory of Spatial Data Mining & Information Sharing of Ministry of Education, Fuzhou University [2018LSDMIS03]; Key Research and Development Program of Shaanxi [2018JQ1038]
CR Adede C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11091099
   [Anonymous], 2009, ASSESSING ACCURACY R, V0, P0, DOI DOI 10.1201/9781420055139
   Badano EI, 2005, J ARID ENVIRON, V62, P93, DOI 10.1016/j.jaridenv.2004.10.012
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burrough PA, 2001, LANDSCAPE ECOL, V16, P523, DOI 10.1023/A:1013167712622
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Domac A, 2006, INT J REMOTE SENS, V27, P1329, DOI 10.1080/01431160500444806
   Dong W, 2019, GEODERMA, V340, P234, DOI 10.1016/j.geoderma.2019.01.018
   Foody GM, 2007, INT J REMOTE SENS, V28, P1733, DOI 10.1080/01431160600962566
   Foody GM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111630
   Fu BL, 2017, ECOL INDIC, V73, P105, DOI 10.1016/j.ecolind.2016.09.029
   Gao LJ, 2019, INT J REMOTE SENS, V40, P7127, DOI 10.1080/01431161.2019.1601281
   Gaston KJ, 2000, NATURE, V405, P220, DOI 10.1038/35012228
   Ghosh A, 2014, INT J APPL EARTH OBS, V26, P49, DOI 10.1016/j.jag.2013.05.017
   Gilbertson JK, 2017, COMPUT ELECTRON AGR, V134, P151, DOI 10.1016/j.compag.2016.12.006
   Goncalves e Goncalves W., 2016, AMBIENTE & AGUA, V11, P612, DOI 10.4136/ambi-agua.1871
   Gong P, 2019, SCI BULL, V64, P370, DOI 10.1016/j.scib.2019.03.002
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Hay G.J., 2008, OBJECT BASED IMAGE A, V0, PP75, DOI 10.1007/978-3-540-77058
   Helmer EH, 2012, FOREST ECOL MANAG, V279, P147, DOI 10.1016/j.foreco.2012.05.016
   Hengl T, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0169748
   Hoersch B., 2002, COMPUTERS, V0, P0
   Huang X, 2008, IEEE T GEOSCI REMOTE, V46, P4173, DOI 10.1109/TGRS.2008.2002577
   Immitzer M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222599
   Janz K, 1993, UNASYLVA, V44, P1
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Jia K, 2014, INT J APPL EARTH OBS, V33, P32, DOI 10.1016/j.jag.2014.04.015
   Karpatne A, 2016, IEEE GEOSC REM SEN M, V4, P8, DOI 10.1109/MGRS.2016.2528038
   Ke YH, 2011, INT J REMOTE SENS, V32, P4725, DOI 10.1080/01431161.2010.494184
   Ke YH, 2010, REMOTE SENS ENVIRON, V114, P1141, DOI 10.1016/j.rse.2010.01.002
   Kempeneers P, 2011, IEEE T GEOSCI REMOTE, V49, P4977, DOI 10.1109/TGRS.2011.2158548
   Klein I, 2012, APPL GEOGR, V35, P219, DOI 10.1016/j.apgeog.2012.06.016
   Kohl M.., 2004, ENC SCI, V0, PP403, DOI 10.1016/B0-12-145160-7/00154-X
   Leckie DG, 2005, REMOTE SENS ENVIRON, V94, P311, DOI 10.1016/j.rse.2004.10.011
   Linderman M, 2004, INT J REMOTE SENS, V25, P1685, DOI 10.1080/01431160310001598971
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   MARCEAU DJ, 1990, IEEE T GEOSCI REMOTE, V28, P513, DOI 10.1109/TGRS.1990.572937
   Mills H, 2006, INT J REMOTE SENS, V27, P2177, DOI 10.1080/01431160500396501
   Pan Y, 2003, INT J REMOTE SENS, V24, P1009, DOI 10.1080/01431160110115816
   Pepin NC, 2017, GLOBAL PLANET CHANGE, V157, P244, DOI 10.1016/j.gloplacha.2017.08.006
   Pouliot D, 2014, REMOTE SENS ENVIRON, V140, P731, DOI 10.1016/j.rse.2013.10.004
   Rajan S, 2008, IEEE T GEOSCI REMOTE, V46, P1231, DOI 10.1109/TGRS.2007.910220
   Ren GP, 2009, FOREST ECOL MANAG, V258, P26, DOI 10.1016/j.foreco.2009.03.043
   Rogan J, 2002, REMOTE SENS ENVIRON, V80, P143, DOI 10.1016/S0034-4257(01)00296-6
   Roy PS, 2015, INT J APPL EARTH OBS, V39, P142, DOI 10.1016/j.jag.2015.03.003
   Saha A, 2005, GEOCARTO INT, V20, P33, DOI 10.1080/10106040508542343
   Shrestha D.P., 2001, INT J APPL EARTH OBS, V3, P78
   SKIDMORE AK, 1989, PHOTOGRAMM ENG REM S, V55, P1449
   Stage AR, 2007, FOREST SCI, V53, P486
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Tigges J, 2013, REMOTE SENS ENVIRON, V136, P66, DOI 10.1016/j.rse.2013.05.001
   Treitz P, 2000, PHOTOGRAMM ENG REM S, V66, P305
   Tuia D, 2009, IEEE T GEOSCI REMOTE, V47, P2218, DOI 10.1109/TGRS.2008.2010404
   Tuominen S, 2005, REMOTE SENS ENVIRON, V94, P256, DOI 10.1016/j.rse.2004.10.001
   Voisin A, 2014, IEEE T GEOSCI REMOTE, V52, P3346, DOI 10.1109/TGRS.2013.2272581
   Wang L, 2004, PHOTOGRAMM ENG REM S, V70, P351, DOI 10.14358/PERS.70.3.351
   Wu TJ, 2019, IEEE J-STARS, V12, P1091, DOI 10.1109/JSTARS.2019.2902375
   Wu TJ, 2019, EARTH SCI INFORM, V12, P57, DOI 10.1007/s12145-018-0360-8
   Wu TJ, 2018, J INDIAN SOC REMOTE, V46, P1805, DOI 10.1007/s12524-018-0841-8
   Wu TJ, 2015, J INDIAN SOC REMOTE, V43, P653, DOI 10.1007/s12524-014-0446-9
   Wulder MA, 2004, PROG PLANN, V61, P365, DOI 10.1016/S0305-9006(03)00069-2
   Yang YP, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121298
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zhang KW, 2012, REMOTE SENS-BASEL, V4, P1741, DOI 10.3390/rs4061741
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhu X, 2008, COMPUTER SCI T, V0, P2
NR 70
TC 4
Z9 5
U1 4
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN 15
PY 2021
VL 13
IS 2
BP 
EP 
DI 10.3390/rs13020249
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PY3OJ
UT WOS:000611956400001
DA 2023-04-26
ER

PT J
AU Chen, B
   Tu, Y
   Song, YM
   Theobald, D
   Zhang, T
   Ren, ZH
   Li, XC
   Yang, J
   Wang, J
   Wang, X
   Gong, P
   Bai, YQ
   Xu, B
AF Chen, Bin
   Tu, Ying
   Song, Yimeng
   Theobald, David M.
   Zhang, Tao
   Ren, Zhehao
   Li, Xuecao
   Yang, Jun
   Wang, Jie
   Wang, Xi
   Gong, Peng
   Bai, Yuqi
   Xu, Bing
TI Mapping essential urban land use categories with open big data: Results for five metropolitan areas in the United States of America
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Land use classification; Block-level mapping; Geospatial big data; Ensemble learning; NAIP; Sentinel-1/2
ID nighttime light; classification; information; cover; openstreetmap; points
AB Urban land-use maps outlining the distribution, pattern, and composition of various land use types are critically important for urban planning, environmental management, disaster control, health protection, and biodiversity conservation. Recent advances in remote sensing and social sensing data and methods have shown great potentials in mapping urban land use categories, but they are still constrained by mixed land uses, limited predictors, non-localized models, and often relatively low accuracies. To inform these issues, we proposed a robust and cost-effective framework for mapping urban land use categories using openly available multi-source geo-spatial "big data". With street blocks generated from OpenStreetMap (OSM) data as the minimum classification unit, we integrated an expansive set of multi-scale spatially explicit information on land surface, vertical height, socio-economic attributes, social media, demography, and topography. We further proposed to apply the automatic ensemble learning that leverages a bunch of machine learning algorithms in deriving optimal urban land use classification maps. Results of block-level urban land use classification in five metropolitan areas of the United States found the overall accuracies of major-class (Level-I) and minor-class (Level-II) classification could be high as 91% and 86%, respectively. A multi-model comparison revealed that for urban land use classification with high-dimensional features, the multi-layer stacking ensemble models achieved better performance than base models such as random forest, extremely randomized trees, LightGBM, CatBoost, and neural networks. We found without very-high-resolution National Agriculture Imagery Program imagery, the classification results derived from Sentinel-1, Sentinel-2, and other open big data based features could achieve plausible overall accuracies of Level-I and Level-II classification at 88% and 81%, respectively. We also found that model transferability depended highly on the heterogeneity in characteristics of different regions. The methods and findings in this study systematically elucidate the role of data sources, classification methods, and feature transferability in block-level land use classifications, which have important implications for mapping multi-scale essential urban land use categories.
C1 [Chen, Bin] Univ Hong Kong, Div Landscape Architecture, Fac Architecture, Hong Kong, Peoples R China.
   [Tu, Ying; Zhang, Tao; Ren, Zhehao; Yang, Jun; Bai, Yuqi; Xu, Bing] Tsinghua Univ, Dept Earth Syst Sci, Key Lab Earth Syst Modeling, Minist Educ, Beijing 100084, Peoples R China.
   [Song, Yimeng] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Peoples R China.
   [Song, Yimeng] Hong Kong Polytech Univ, Smart Cities Res Inst, Hong Kong, Peoples R China.
   [Theobald, David M.] Conservat Planning Technol, Ft Collins, CO 80521 USA.
   [Theobald, David M.] Colorado State Univ, Dept Fish Wildlife & Conservat Biol, Ft Collins, CO 80523 USA.
   [Li, Xuecao] China Agr Univ, Coll Land Sci & Technol, Beijing 100083, Peoples R China.
   [Yang, Jun; Bai, Yuqi; Xu, Bing] Tsinghua Univ, Tsinghua Urban Inst, Beijing 100084, Peoples R China.
   [Yang, Jun; Bai, Yuqi; Xu, Bing] Tsinghua Univ, Ctr Hlth Cities, Inst China Sustainable Urbanizat, Beijing 100084, Peoples R China.
   [Wang, Jie] Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.
   [Wang, Xi] Tsinghua Univ, Cross Strait Inst, AI Earth Lab, Beijing 100084, Peoples R China.
   [Gong, Peng] Univ Hong Kong, Dept Geog & Earth Sci, Hong Kong, Peoples R China.
C3 University of Hong Kong; Tsinghua University; Hong Kong Polytechnic University; Hong Kong Polytechnic University; Colorado State University; China Agricultural University; Tsinghua University; Tsinghua University; Chinese Academy of Sciences; Tsinghua University; University of Hong Kong
RP Chen, B (corresponding author), Univ Hong Kong, Div Landscape Architecture, Fac Architecture, Hong Kong, Peoples R China.; Bai, YQ; Xu, B (corresponding author), Tsinghua Univ, Dept Earth Syst Sci, Key Lab Earth Syst Modeling, Minist Educ, Beijing 100084, Peoples R China.
EM binley.chen@hku.hk; yuqibai@tsinghua.edu.cn; bingxu@tsinghua.edu.cn
FU Major Program of the National Natural Science Foundation of China [20201321441, 20201320003]; University of Hong Kong HKU-100 Scholars Fund
CR Agarwala M, 2014, CONSERV SOC, V12, P437, DOI 10.4103/0972-4923.155592
   Barrington-Leigh C, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0180698
   Brown de Colstoun E. C., 2017, DOCUMENTATION GLOBAL, V0, P0, DOI DOI 10.7927/H4JD4TVQ
   Chen B, 2017, SCI TOTAL ENVIRON, V609, P956, DOI 10.1016/j.scitotenv.2017.07.238
   Chen B, 2017, ISPRS J PHOTOGRAMM, V124, P27, DOI 10.1016/j.isprsjprs.2016.12.008
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Clinton N, 2018, EARTHS FUTURE, V6, P40, DOI 10.1002/2017EF000536
   Dobson JE, 2000, PHOTOGRAMM ENG REM S, V66, P849
   Dorogush A.V., 2018, ARXIV, V0, P0
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Du SH, 2021, REMOTE SENS ENVIRON, V261, P0, DOI 10.1016/j.rse.2021.112480
   Elvidge CD, 2017, INT J REMOTE SENS, V38, P5860, DOI 10.1080/01431161.2017.1342050
   Erickson N., 2020, ICML WORKSH AUT MACH, V0, P0
   Erol H, 2005, INT J REMOTE SENS, V26, P1229, DOI 10.1080/01431160512331326800
   Evans, 2010, VITA WEBINAR SERIES, V0, P0
   Frantz D, 2021, REMOTE SENS ENVIRON, V252, P0, DOI 10.1016/j.rse.2020.112128
   Frias-Martinez V, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, V0, P0
   Gao J, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-15788-7
   GONG P, 1990, PHOTOGRAMM ENG REM S, V56, P67
   GONG P, 1992, PHOTOGRAMM ENG REM S, V58, P423
   Gong P, 2020, SCI BULL, V65, P182, DOI 10.1016/j.scib.2019.12.007
   Gong P, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111510
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Grimm NB, 2008, SCIENCE, V319, P756, DOI 10.1126/science.1150195
   Guo W, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010131
   Haklay M, 2010, ENVIRON PLANN B, V37, P682, DOI 10.1068/b35097
   Hu TY, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020151
   Huang X, 2021, ISPRS J PHOTOGRAMM, V175, P403, DOI 10.1016/j.isprsjprs.2021.03.019
   Huang X, 2018, IEEE T GEOSCI REMOTE, V56, P4258, DOI 10.1109/TGRS.2018.2805829
   Kennedy CM, 2019, GLOBAL CHANGE BIOL, V25, P811, DOI 10.1111/gcb.14549
   Koppel K, 2017, INT J REMOTE SENS, V38, P6298, DOI 10.1080/01431161.2017.1353160
   Lansley G, 2016, COMPUT ENVIRON URBAN, V58, P85, DOI 10.1016/j.compenvurbsys.2016.04.002
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XT, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030477
   Li XC, 2020, ENVIRON RES LETT, V15, P0, DOI 10.1088/1748-9326/ab9be3
   Li XC, 2020, REMOTE SENS ENVIRON, V240, P0, DOI 10.1016/j.rse.2020.111705
   Liu SJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060690
   Liu XP, 2017, INT J GEOGR INF SCI, V31, P1675, DOI 10.1080/13658816.2017.1324976
   Liu XJ, 2016, ENVIRON PLANN B, V43, P341, DOI 10.1177/0265813515604767
   Liu X, 2020, NAT NANOTECHNOL, V15, P307, DOI 10.1038/s41565-020-0641-5
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Lu DS, 2006, REMOTE SENS ENVIRON, V102, P146, DOI 10.1016/j.rse.2006.02.010
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, V0, PP1, DOI 10.1007/978-1-4419-9326-7
   Machado MR, 2019, INT CONF COMP SCI ED, V0, PP1111, DOI 10.1109/ICCSE.2019.8845529
   Meijer JR, 2018, ENVIRON RES LETT, V13, P0, DOI 10.1088/1748-9326/aabd42
   Mills S, 2013, PROC SPIE, V8866, P0, DOI 10.1117/12.2023107
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Pesaresi M, 2013, IEEE J-STARS, V6, P2102, DOI 10.1109/JSTARS.2013.2271445
   Petropoulos GP, 2012, COMPUT GEOSCI-UK, V41, P99, DOI 10.1016/j.cageo.2011.08.019
   Sarzynski A, 2014, URBAN GEOGR, V35, P25, DOI 10.1080/02723638.2013.823730
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schneider A, 2009, ENVIRON RES LETT, V4, P0, DOI 10.1088/1748-9326/4/4/044003
   Seto KC, 2009, CURR OPIN ENV SUST, V1, P89, DOI 10.1016/j.cosust.2009.07.012
   Shi KF, 2014, REMOTE SENS LETT, V5, P358, DOI 10.1080/2150704X.2014.905728
   Stevens FR, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0107042
   Su M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091497
   Tan B., 2017, PALISADES, V0, P0
   Tatem AJ, 2017, SCI DATA, V4, P0, DOI 10.1038/sdata.2017.4
   Theobald DM, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0094628
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   Tu Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071058
   UNDESA, 2014, WORLD URB PROSP 2011, V0, P0
   Watts N, 2015, LANCET, V386, P1861, DOI 10.1016/S0140-6736(15)60854-6
   Watts RD, 2007, SCIENCE, V316, P736, DOI 10.1126/science.1138141
   Weiss Karl, 2016, JOURNAL OF BIG DATA, V3, P0, DOI 10.1186/s40537-016-0043-6
   Wheater H, 2009, LAND USE POLICY, V26, PS251, DOI 10.1016/j.landusepol.2009.08.019
   Xu B, 2020, SCI REMOTE SENS, V0, P0
   Yao Y, 2017, INT J GEOGR INF SCI, V31, P825, DOI 10.1080/13658816.2016.1244608
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang XY, 2017, ISPRS J PHOTOGRAMM, V132, P170, DOI 10.1016/j.isprsjprs.2017.09.007
   Zhong YF, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111838
   Zhou YY, 2018, REMOTE SENS ENVIRON, V219, P206, DOI 10.1016/j.rse.2018.10.015
NR 73
TC 23
Z9 24
U1 15
U2 67
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG 15
PY 2021
VL 178
IS 
BP 203
EP 218
DI 10.1016/j.isprsjprs.2021.06.010
EA JUN 2021
PG 16
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TE4AS
UT WOS:000669954900015
DA 2023-04-26
ER

PT J
AU Bengana, N
   Heikkila, J
AF Bengana, Nadir
   Heikkila, Janne
TI Improving Land Cover Segmentation Across Satellites Using Domain Adaptation
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Domain adaptation (DA); image segmentation; land cover segmentation
ID image classification
AB Land use and land cover mapping is essential to various fields of study, such as forestry, agriculture, and urban management. Generally, earth observation satellites facilitate and accelerate the mapping process. Subsequently, deep learning methods have been proven to be excellent in automating the mapping via semantic image segmentation. However, because deep neural networks require large amounts of labeled data, it is not easy to exploit the full potential of satellite imagery. Additionally, land cover tends to differ in appearance from one region to another; therefore, having labeled data from one location does not necessarily help map others. Furthermore, satellite images come in various multispectral bands, which range from RGB to over 12 bands. In this study, our aim is to use domain adaptation (DA) to solve the aforementioned problems. We applied a well-performing DA approach on the DeepGlobe land cover dataset as well as datasets that we built using RGB images from Sentinel-2, WorldView-2, and Pleiades-1B satellites with CORINE Land Cover as ground truth (GT) labels. The experiments revealed significant improvements over the results obtained without using DA. In some cases, an improvement of over 20% mean intersection over union was obtained. Sometimes, our model manages to correct errors in the GT labels.
C1 [Bengana, Nadir; Heikkila, Janne] Univ Oulu, Fac Informat Technol & Elect Engn, Oulu 90014, Finland.
C3 University of Oulu
RP Bengana, N (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, Oulu 90014, Finland.
EM mohamed.bengana@oulu.fi; janne.heikkila@oulu.fi
FU Business Finland [1259/31/2018]
CR AHMAD W, 1992, INT J REMOTE SENS, V13, P673, DOI 10.1080/01431169208904145
   Arief HA, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060973
   Benjdira B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111369
   Bruzzone L, 2009, IEEE T GEOSCI REMOTE, V47, P3180, DOI 10.1109/TGRS.2009.2019636
   Chang WL, 2019, PROC CVPR IEEE, V0, PP1900, DOI 10.1109/CVPR.2019.00200
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen YH, 2017, IEEE I CONF COMP VIS, V0, PP2011, DOI 10.1109/ICCV.2017.220
   Cook D. J., 2018, ARXIV181202849, V0, P0
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Demir I, 2018, IEEE COMPUT SOC CONF, V0, PP172, DOI 10.1109/CVPRW.2018.00031
   Deng X., 1900, V177, V0, P0
   Emery W., 1999, VISIBLE INFRARED REM, V12, P0
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Hoffman J, 2018, PR MACH LEARN RES, V80, P0
   Hoffmann Johannes, 2016, 2016 CONFERENCE ON PRECISION ELECTROMAGNETIC MEASUREMENTS (CPEM), V0, PP1, DOI 10.1109/CPEM.2016.7540615
   Hong WX, 2018, PROC CVPR IEEE, V0, PP1335, DOI 10.1109/CVPR.2018.00145
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Inamdar S, 2008, IEEE T GEOSCI REMOTE, V46, P1243, DOI 10.1109/TGRS.2007.912445
   Izquierdo-Verdiguier E, 2013, IEEE GEOSCI REMOTE S, V10, P981, DOI 10.1109/LGRS.2012.2227297
   Ji SP, 2021, IEEE T GEOSCI REMOTE, V59, P3816, DOI 10.1109/TGRS.2020.3020804
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Kuo TS, 2018, IEEE COMPUT SOC CONF, V0, PP247, DOI 10.1109/CVPRW.2018.00046
   Li YS, 2019, PROC CVPR IEEE, V0, PP6929, DOI 10.1109/CVPR.2019.00710
   Luo YW, 2019, PROC CVPR IEEE, V0, PP2502, DOI 10.1109/CVPR.2019.00261
   Mohajerani S, 2019, INT GEOSCI REMOTE SE, V0, PP1029, DOI 10.1109/IGARSS.2019.8898776
   Penatti Otavio A. B., 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP44, DOI 10.1109/CVPRW.2015.7301382
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G, 2016, PROC CVPR IEEE, V0, PP3234, DOI 10.1109/CVPR.2016.352
   ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326
   Tasar O., 2019, COLORMAPGAN DOMAIN A, V0, P0
   Tehrany MS, 2014, GEOCARTO INT, V29, P351, DOI 10.1080/10106049.2013.768300
   Tian C, 2018, IEEE COMPUT SOC CONF, V0, PP262, DOI 10.1109/CVPRW.2018.00049
   Tsai YH, 2018, PROC CVPR IEEE, V0, PP7472, DOI 10.1109/CVPR.2018.00780
   Vu TH, 2019, PROC CVPR IEEE, V0, PP2512, DOI 10.1109/CVPR.2019.00262
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   Tzeng E, 2017, PROC CVPR IEEE, V0, PP2962, DOI 10.1109/CVPR.2017.316
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Zhang Y, 2017, IEEE I CONF COMP VIS, V0, PP2039, DOI 10.1109/ICCV.2017.223
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_
NR 51
TC 12
Z9 12
U1 2
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1399
EP 1410
DI 10.1109/JSTARS.2020.3042887
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900045
DA 2023-04-26
ER

PT J
AU Adriano, B
   Yokoya, N
   Xia, JS
   Miura, H
   Liu, W
   Matsuoka, M
   Koshimura, S
AF Adriano, Bruno
   Yokoya, Naoto
   Xia, Junshi
   Miura, Hiroyuki
   Liu, Wen
   Matsuoka, Masashi
   Koshimura, Shunichi
TI Learning from multimodal and multitemporal earth observation data for building damage mapping
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Multimodal remote sensing; Disaster damage mapping; Deep convolutional neural network
ID field survey; 2015 gorkha; sar images; reconnaissance; segmentation; network; puebla; nepal
AB Earth observation (EO) technologies, such as optical imaging and synthetic aperture radar (SAR), provide excellent means to continuously monitor ever-growing urban environments. Notably, in the case of large-scale disasters (e.g., tsunamis and earthquakes), in which a response is highly time-critical, images from both data modalities can complement each other to accurately convey the full damage condition in the disaster aftermath. However, due to several factors, such as weather and satellite coverage, which data modality will be the first available for rapid disaster response efforts is often uncertain. Hence, novel methodologies that can utilize all accessible EO datasets are essential for disaster management. In this study, we developed a global multimodal and multitemporal dataset for building damage mapping. We included building damage characteristics from three disaster types, namely, earthquakes, tsunamis, and typhoons, and considered three building damage categories. The global dataset contains high-resolution (HR) optical imagery and high-to-moderate-resolution SAR data acquired before and after each disaster. Using this comprehensive dataset, we analyzed five data modality scenarios for damage mapping: single-mode (optical and SAR datasets), cross-modal (pre-disaster optical and post-disaster SAR datasets), and mode fusion scenarios. We defined a damage mapping framework for semantic segmentation of damaged buildings based on a deep convolutional neural network (CNN) algorithm. We also compared our approach to another state-of-the-art model for damage mapping. The results indicated that our dataset, together with a deep learning network, enabled acceptable predictions for all the data modality scenarios. We also found that the results from cross-modal mapping were comparable to the results obtained from a fusion sensor and optical mode analysis.
C1 [Adriano, Bruno; Yokoya, Naoto; Xia, Junshi] RIKEN Ctr Adv Intelligence Project, Geoinformat Unit, Tokyo, Japan.
   [Yokoya, Naoto] Univ Tokyo, Complex Sci & Engn, Grad Sch Frontier Sci, Tokyo, Japan.
   [Miura, Hiroyuki] Hiroshima Univ, Sch Adv Sci & Engn, Higashihiroshima, Japan.
   [Liu, Wen] Chiba Univ, Grad Sch Engn, Chiba, Japan.
   [Matsuoka, Masashi] Tokyo Inst Technol, Dept Architecture & Bldg Engn, Tokyo, Japan.
   [Koshimura, Shunichi] Tohoku Univ, Int Res Inst Disaster Sci, Sendai, Miyagi, Japan.
C3 RIKEN; University of Tokyo; Hiroshima University; Chiba University; Tokyo Institute of Technology; Tohoku University
RP Adriano, B (corresponding author), RIKEN Ctr Adv Intelligence Project, Geoinformat Unit, Tokyo, Japan.
EM bruno.adriano@riken.jp
FU Japan Society for the Promotion of Science [KAKENHI 19K20309, 19H02408, 18K18067, 17H06108]; JSPS Bilateral Joint Research Projects [JPJSBP 120203211]; Center for Environmental Remote Sensing (CEReS), Chiba University; Grants-in-Aid for Scientific Research [18K18067] Funding Source: KAKEN
CR 2007EERI, 2007, TECHNICAL REPORT, V0, P0
   Adriano B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070886
   Alberto Y, 2018, SOILS FOUND, V58, P1073, DOI 10.1016/j.sandf.2018.06.007
   Altan O, 2001, ISPRS J PHOTOGRAMM, V55, P359, DOI 10.1016/S0924-2716(01)00025-9
   Ataei H, 2018, FORENSIC ENGINEERING 2018: FORGING FORENSIC FRONTIERS, V0, P957
   Bai YB, 2018, IEEE GEOSCI REMOTE S, V15, P43, DOI 10.1109/LGRS.2017.2772349
   Bai YB, 2017, EARTHQ SPECTRA, V33, PS185, DOI 10.1193/121516EQS232M
   Booth E, 2011, EARTHQ SPECTRA, V27, PS157, DOI 10.1193/1.3632109
   Brett PTB, 2013, IEEE T GEOSCI REMOTE, V51, P4877, DOI 10.1109/TGRS.2013.2271564
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Celebi M, 2018, B SEISMOL SOC AM, V108, P3289, DOI 10.1785/0120180100
   Dong LG, 2013, ISPRS J PHOTOGRAMM, V84, P85, DOI 10.1016/j.isprsjprs.2013.06.011
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ferro A, 2013, IEEE T GEOSCI REMOTE, V51, P935, DOI 10.1109/TGRS.2012.2205156
   Freire S, 2014, ISPRS J PHOTOGRAMM, V90, P1, DOI 10.1016/j.isprsjprs.2013.12.009
   Ge PL, 2020, REMOTE SENS ENVIRON, V240, P0, DOI 10.1016/j.rse.2020.111693
   Geiss C, 2015, ISPRS J PHOTOGRAMM, V104, P175, DOI 10.1016/j.isprsjprs.2014.07.016
   Ghosh S, 2011, EARTHQ SPECTRA, V27, PS179, DOI 10.1193/1.3636416
   Goda K., 2015, FRONTT BUILT ENV, V1, P8, DOI 10.3389/FBUIL.2015.00008
   Gokon H, 2015, IEEE GEOSCI REMOTE S, V12, P1277, DOI 10.1109/LGRS.2015.2392792
   Gokon H, 2012, COAST ENG J, V54, P0, DOI 10.1142/S0578563412500064
   Grunthal G., 1998, 101 CTR E1R GEOD SEI, V0, P0
   Gupta R., 2019, ALGAE KARNATAKA CHEC, V0, P10
   Karimzadeh S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081255
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Koshimura S, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10050177
   Koshimura S, 2009, COAST ENG J, V51, P243, DOI 10.1142/S0578563409002004
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LI QD, 2020, IEEE T GEOSCI REMOTE, V0, P0, DOI DOI 10.1080/1034912X.2020.1719986
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Ma HJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010044
   Mas E, 2015, NAT HAZARD EARTH SYS, V15, P805, DOI 10.5194/nhess-15-805-2015
   Masi A, 2017, NAT HAZARDS, V86, P193, DOI 10.1007/s11069-017-2776-8
   Matsuoka M, 2013, J DISASTER RES, V8, P346, DOI 10.20965/jdr.2013.p0346
   Miura H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121924
   Miura H, 2016, EARTHQ SPECTRA, V32, P591, DOI 10.1193/033014EQS042M
   Monfort D, 2019, REMOTE SENS APPL, V14, P46, DOI 10.1016/j.rsase.2019.02.003
   Mori N, 2012, COAST ENG J, V54, P0, DOI 10.1142/S0578563412500015
   Mori N, 2011, GEOPHYS RES LETT, V38, P0, DOI 10.1029/2011GL049210
   Naito S, 2020, EARTHQ SPECTRA, V36, P1166, DOI 10.1177/8755293019901309
   Okada S, 2000, P 12 WORLD C EARTHQ, V0, P0
   Okamura M, 2015, SOILS FOUND, V55, P1015, DOI 10.1016/j.sandf.2015.09.005
   Oktay O, 2018, ARXIV180403999, V0, P0
   Park JM, 1999, IEE P-VIS IMAGE SIGN, V146, P191, DOI 10.1049/ip-vis:19990550
   Paulik R, 2019, PURE APPL GEOPHYS, V176, P3305, DOI 10.1007/s00024-019-02254-9
   Plank S, 2014, REMOTE SENS-BASEL, V6, P4870, DOI 10.3390/rs6064870
   Roeber V, 2015, NAT COMMUN, V6, P0, DOI 10.1038/ncomms8854
   Roeslin S, 2018, FRONT BUILT ENVIRON, V4, P0, DOI 10.3389/fbuil.2018.00072
   Rogan J, 2008, REMOTE SENS ENVIRON, V112, P2272, DOI 10.1016/j.rse.2007.10.004
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rossi C, 2015, IEEE T GEOSCI REMOTE, V53, P6457, DOI 10.1109/TGRS.2015.2440913
   Shahzad M, 2019, IEEE T GEOSCI REMOTE, V57, P1100, DOI 10.1109/TGRS.2018.2864716
   Sharma K, 2016, ENG STRUCT, V121, P61, DOI 10.1016/j.engstruct.2016.04.043
   Shermeyer J, 2020, IEEE COMPUT SOC CONF, V0, PP768, DOI 10.1109/CVPRW50498.2020.00106
   Shi YL, 2020, ISPRS J PHOTOGRAMM, V159, P184, DOI 10.1016/j.isprsjprs.2019.11.004
   Smith LN, 2017, IEEE WINT CONF APPL, V0, PP464, DOI 10.1109/WACV.2017.58
   Tajima Y, 2014, COAST ENG J, V56, P0, DOI 10.1142/S0578563414500065
   Taucer F, 2009, B EARTHQ ENG, V7, P1, DOI 10.1007/s10518-008-9092-3
   Tong XH, 2012, ISPRS J PHOTOGRAMM, V68, P13, DOI 10.1016/j.isprsjprs.2011.12.004
   Twumasi N.Y.D., 2019, INT J TREND SCI RES, V3, P918, DOI 10.31142/IJTSRD23976
   Vetr M.G., 2018, J SEISMOLOGY EARTHQU, V10, P0
   Wallemacq P., 2018, EC LOSSES POVERTY DI, V0, P0
   Wei Y, 2020, IEEE T GEOSCI REMOTE, V58, P8919, DOI 10.1109/TGRS.2020.2991733
   Widiyanto W, 2019, NAT HAZARD EARTH SYS, V19, P2781, DOI 10.5194/nhess-19-2781-2019
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   Xie YJ, 2019, J SENSORS, V2019, P0, DOI 10.1155/2019/1246548
   Yamada M, 2017, EARTHQ SPECTRA, V33, P1555, DOI 10.1193/090816EQS144M
   Yamaguchi Y, 2012, P IEEE, V100, P2851, DOI 10.1109/JPROC.2012.2195469
   Yamanaka H, 2016, EARTH PLANETS SPACE, V68, P0, DOI 10.1186/s40623-016-0574-2
   Yamazaki F, 2007, J EARTHQ TSUNAMI, V1, P193, DOI 10.1142/S1793431107000122
   Yamazaki F, 2005, EARTHQ SPECTRA, V21, PS328, DOI 10.1193/1.2101807
   Yusuf Yalkun, 2001, J INDIAN SOC REMOTE, V29, P17, DOI 10.1007/BF02989909
NR 73
TC 30
Z9 30
U1 11
U2 43
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY 15
PY 2021
VL 175
IS 
BP 132
EP 143
DI 10.1016/j.isprsjprs.2021.02.016
EA MAR 2021
PG 12
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT8HA
UT WOS:000644695700010
DA 2023-04-26
ER

PT J
AU Zhang, Q
   Zhang, PL
   Hu, XD
AF Zhang, Qi
   Zhang, Penglin
   Hu, Xudong
TI Unsupervised GRNN flood mapping approach combined with uncertainty analysis using bi-temporal Sentinel-2 MSI imageries
SO INTERNATIONAL JOURNAL OF DIGITAL EARTH
LA English
DT Article
DE Unsupervised flood mapping; optical remote sensing image; spatial-spectral feature extraction; uncertainty analysis; GRNN; Sentinel-2
ID water index ndwi; classification; features
AB Floods occur frequently worldwide. The timely, accurate mapping of the flooded areas is an important task. Therefore, an unsupervised approach is proposed for automated flooded area mapping from bi-temporal Sentinel-2 multispectral images in this paper. First, spatial-spectral features of the images before and after the flood are extracted to construct the change magnitude image (CMI). Then, the certain flood pixels and non-flood pixels are obtained by performing uncertainty analysis on the CMI, which are considered reliable classification samples. Next, Generalized Regression Neural Network (GRNN) is used as the core classifier to generate the initial flood map. Finally, an easy-to-implement two-stage post-processing is proposed to reduce the mapping error of the initial flood map, and generate the final flood map. Different from other methods based on machine learning, GRNN is used as the classifier, but the proposed approach is automated and unsupervised because it uses samples automatically generated in uncertainty analysis for model training. Results of comparative experiments in the three sub-regions of the Poyang Lake Basin demonstrate the effectiveness and superiority of the proposed approach. Moreover, its superiority in dealing with uncertain pixels is further proven by comparing the classification accuracy of different methods on uncertain pixels.
C1 [Zhang, Qi; Zhang, Penglin; Hu, Xudong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Zhang, Qi; Zhang, Penglin] Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simula, Shenzhen, Peoples R China.
C3 Wuhan University; Ministry of Natural Resources of the People's Republic of China
RP Zhang, PL (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM zpl@whu.edu.cn
FU National Key Research and Development Program of China [2018YFF0215006]; Open Fund of Key Laboratory of Urban Land Resources Monitoring and Simulation, Ministry of Natural Resources [KF-2019-04-046]
CR Ahamed A, 2017, INT J APPL EARTH OBS, V61, P104, DOI 10.1016/j.jag.2017.05.006
   Azareh A, 2021, GEOCARTO INT, V36, P2345, DOI 10.1080/10106049.2019.1695958
   Berezowski T, 2020, IEEE J-STARS, V13, P2626, DOI 10.1109/JSTARS.2020.2995888
   Boschetti M, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0088741
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Choubin B, 2019, SCI TOTAL ENVIRON, V651, P2087, DOI 10.1016/j.scitotenv.2018.10.064
   Cian F, 2018, REMOTE SENS ENVIRON, V209, P712, DOI 10.1016/j.rse.2018.03.006
   Dodangeh E, 2020, SCI TOTAL ENVIRON, V705, P0, DOI 10.1016/j.scitotenv.2019.135983
   Dunn J. C., 1973, JOURNAL OF CYBERNETICS, V3, P32, DOI 10.1080/01969727308546046
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   Goffi A, 2020, INT J APPL EARTH OBS, V84, P0, DOI 10.1016/j.jag.2019.101951
   Hao M, 2020, IEEE GEOSCI REMOTE S, V17, P1401, DOI 10.1109/LGRS.2019.2948660
   Hosseini FS, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.135161
   HUETE A R, 1988, REMOTE SENSING OF ENVIRONMENT, V25, P295
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Li LY, 2019, IEEE GEOSCI REMOTE S, V16, P1269, DOI 10.1109/LGRS.2019.2894350
   Li N, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3077247
   Li YQ, 2018, IMMS 2019: 2019 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND MANAGEMENT SCIENCES, V0, PP123, DOI 10.1145/3357292.3357320
   Lv ZY, 2014, IEEE J-STARS, V7, P4644, DOI 10.1109/JSTARS.2014.2328618
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Mosavi A, 2022, GEOCARTO INT, V37, P2541, DOI 10.1080/10106049.2020.1829101
   Peng B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212492
   Sarker C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192331
   Scotti V, 2020, J FLOOD RISK MANAG, V13, P0, DOI 10.1111/jfr3.12647
   Shen L, 2010, P 18 INT C GEOINF BE, V0, PP1, DOI 10.1109/GEOINFORMATICS.2010.5567762
   Singh KV, 2015, GEOCARTO INT, V30, P650, DOI 10.1080/10106049.2014.965757
   Solovey T, 2020, GEOL Q, V64, P492, DOI 10.7306/gq.1509
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Tong XH, 2018, ISPRS J PHOTOGRAMM, V136, P144, DOI 10.1016/j.isprsjprs.2017.11.006
   Uddin K, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131581
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Zhai K, 2015, GEO-SPAT INF SCI, V18, P32, DOI 10.1080/10095020.2015.1017911
   Zhang GY, 2018, INT J REMOTE SENS, V39, P5978, DOI 10.1080/01431161.2018.1506593
   Zhang H, 2018, IEEE J-STARS, V11, P2896, DOI 10.1109/JSTARS.2018.2846603
NR 34
TC 5
Z9 5
U1 6
U2 14
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1753-8947
EI 1753-8955
J9 INT J DIGIT EARTH
JI Int. J. Digit. Earth
PD NOV 2
PY 2021
VL 14
IS 11
BP 1561
EP 1581
DI 10.1080/17538947.2021.1953160
EA JUL 2021
PG 21
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA WR1EX
UT WOS:000674164100001
DA 2023-04-26
ER

PT J
AU Mason, DC
   Dance, SL
   Cloke, HL
AF Mason, David C.
   Dance, Sarah L.
   Cloke, Hannah L.
TI Floodwater detection in urban areas using Sentinel-1 and WorldDEM data
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE flood incident management; hydrology; synthetic aperture radar
ID convolutional neural-network; induced backscatter changes; digital elevation model; aperture radar images; assimilation; inundation; intensity; coherence; accuracy; extent
AB Remote sensing using synthetic aperture radar (SAR) is an important tool for emergency flood incident management. At present, operational services are mainly aimed at flood mapping in rural areas, as mapping in urban areas is hampered by the complicated backscattering mechanisms occurring there. A method for detecting flooding at high resolution in urban areas that may contain dense housing is presented. This largely uses remotely sensed data sets that are readily available on a global basis, including open-access Sentinel-1 SAR data, the WorldDEM digital surface model (DSM), and open-accessWorld Settlement Footprint data to identify urban areas. The method is a change detection technique that locally estimates flood levels in urban areas. It searches for increased SAR backscatter in the post-flood image due to double scattering between water (rather than unflooded ground) and adjacent buildings, and reduced SAR backscatter in areas away from high slopes. Areas of urban flooding are detected by comparing an interpolated flood level surface to the DSM. The method was tested on two flood events that occurred in the UK during the storms of Winter 2019-2020. High urban flood detection accuracies were achieved for the event in moderate density housing. The accuracy was reduced for the event in dense housing, when street widths became comparable to the DSM resolution, though it would still be useful for incident management. The method has potential for operational use for detecting urban flooding in near real-time on a global basis. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.
C1 [Mason, David C.; Cloke, Hannah L.] Univ Reading, Dept Geog & Environm Sci, Reading, Berks, England.
   [Dance, Sarah L.; Cloke, Hannah L.] Univ Reading, Dept Meteorol, Reading, Berks, England.
   [Dance, Sarah L.] Univ Reading, Dept Math & Stat, Reading, Berks, England.
   [Cloke, Hannah L.] Uppsala Univ, Dept Earth Sci, Uppsala, Sweden.
   [Cloke, Hannah L.] Ctr Nat Hazards & Disaster Sci, Uppsala, Sweden.
C3 University of Reading; University of Reading; University of Reading; Uppsala University; Centre of Natural Hazards & Disaster Science (CNDS)
RP Mason, DC (corresponding author), Univ Reading, Dept Geog & Environm Sci, Reading, Berks, England.
EM d.c.mason@reading.ac.uk
FU UK Engineering and Physical Sciences Research Council [EP/P002331/1]
CR [Anonymous], 2020, RIVER LEVELS UK, V0, P0
   [Anonymous], 2019, BBC NEWS, V0, P0
   Baier G, 2018, IEEE T GEOSCI REMOTE, V56, P6469, DOI 10.1109/TGRS.2018.2839027
   Benoudjit A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070779
   Biggs DSC, 1997, APPL OPTICS, V36, P1766, DOI 10.1364/AO.36.001766
   Chini M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020107
   Chini M, 2017, IEEE T GEOSCI REMOTE, V55, P6975, DOI 10.1109/TGRS.2017.2737664
   Cooper ES, 2018, ENVIRON MODELL SOFTW, V104, P199, DOI 10.1016/j.envsoft.2018.03.013
   Cooper ES, 2019, HYDROL EARTH SYST SC, V23, P2541, DOI 10.5194/hess-23-2541-2019
   DAddabbo A, 2018, COMPUT GEOSCI-UK, V112, P64, DOI 10.1016/j.cageo.2017.12.005
   DAddabbo A, 2016, IEEE T GEOSCI REMOTE, V54, P3612, DOI 10.1109/TGRS.2016.2520487
   Davis L.S., 1975, COMPUTER GRAPHICS IM, V4, P248, DOI 10.1016/0146-664X(75)90012-X
   Dong Y, 1997, INT J REMOTE SENS, V18, P1351, DOI 10.1080/014311697218467
   Environment Agency, 2020, LEARN MOR FLOOD RISK, V0, P0
   Franceschetti G, 2002, IEEE T GEOSCI REMOTE, V40, P1787, DOI 10.1109/TGRS.2002.802459
   Garcia-Pintado J, 2015, J HYDROL, V523, P706, DOI 10.1016/j.jhydrol.2015.01.084
   Garcia-Pintado J, 2013, J HYDROL, V495, P252, DOI 10.1016/j.jhydrol.2013.03.050
   Giustarini L, 2015, INT J APPL EARTH OBS, V34, P70, DOI 10.1016/j.jag.2014.06.017
   Giustarini L, 2016, IEEE T GEOSCI REMOTE, V54, P6958, DOI 10.1109/TGRS.2016.2592951
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Gopal S., 2009, P EARSEL S REM SENS, V0, P188
   Grimaldi S, 2016, SURV GEOPHYS, V37, P977, DOI 10.1007/s10712-016-9378-y
   Guida R, 2010, IEEE T GEOSCI REMOTE, V48, P2967, DOI 10.1109/TGRS.2010.2041460
   Hostache R, 2018, WATER RESOUR RES, V54, P5516, DOI 10.1029/2017WR022205
   Iervolino P, 2015, IEEE T GEOSCI REMOTE, V53, P2295, DOI 10.1109/TGRS.2014.2358501
   Lachaise M., 2016, P EUR C SYNTH AP RAD, V0, P1
   Li Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192231
   Li Y, 2019, ISPRS J PHOTOGRAMM, V152, P178, DOI 10.1016/j.isprsjprs.2019.04.014
   Lin YN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151778
   Marconcini M, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-00580-5
   Martinis S, 2009, NAT HAZARD EARTH SYS, V9, P303, DOI 10.5194/nhess-9-303-2009
   Martinis S, 2015, ISPRS J PHOTOGRAMM, V104, P203, DOI 10.1016/j.isprsjprs.2014.07.014
   Martinis S, 2011, IEEE T GEOSCI REMOTE, V49, P251, DOI 10.1109/TGRS.2010.2052816
   Mason DC, 2014, INT J APPL EARTH OBS, V28, P150, DOI 10.1016/j.jag.2013.12.002
   Mason DC, 2012, REMOTE SENS ENVIRON, V124, P705, DOI 10.1016/j.rse.2012.06.017
   Mason DC, 2012, IEEE T GEOSCI REMOTE, V50, P3041, DOI 10.1109/TGRS.2011.2178030
   Mason DC, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.045011
   Mason DC, 2016, REMOTE SENS ENVIRON, V173, P15, DOI 10.1016/j.rse.2015.11.018
   Mason DC, 2010, IEEE T GEOSCI REMOTE, V48, P882, DOI 10.1109/TGRS.2009.2029236
   Matgen P, 2011, PHYS CHEM EARTH, V36, P241, DOI 10.1016/j.pce.2010.12.009
   Munich R E, 2015, LOSS EVENTS WORLDWID, V0, P0
   Nemni E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162532
   Ohki M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172709
   Pierdicca N, 2013, ACTA ASTRONAUT, V84, P122, DOI 10.1016/j.actaastro.2012.10.034
   Pitt M, 2008, PITT REV LEARNING LE, V0, P0
   Pulvirenti L, 2011, NAT HAZARD EARTH SYS, V11, P529, DOI 10.5194/nhess-11-529-2011
   Pulvirenti L, 2011, REMOTE SENS ENVIRON, V115, P990, DOI 10.1016/j.rse.2010.12.002
   Pulvirenti L, 2016, IEEE T GEOSCI REMOTE, V54, P1532, DOI 10.1109/TGRS.2015.2482001
   Ritchie H., 2014, NATURAL DISASTERS, V0, P0
   Schlaffer S, 2017, INT J APPL EARTH OBS, V56, P77, DOI 10.1016/j.jag.2016.12.003
   Schumann G, 2009, IEEE T GEOSCI REMOTE, V47, P2801, DOI 10.1109/TGRS.2009.2017937
   Schumann GJP, 2018, FRONT EARTH SC-SWITZ, V6, P0, DOI 10.3389/feart.2018.00225
   Soergel U, 2003, 2ND GRSS/ISPRS JOINT WORKSHOP ON REMOTE SENSING AND DATA FUSION OVER URBAN AREAS, V0, PP120, DOI 10.1109/DFUA.2003.1219970
   Tanguy M, 2017, REMOTE SENS ENVIRON, V198, P442, DOI 10.1016/j.rse.2017.06.042
   Twele A, 2016, INT J REMOTE SENS, V37, P2990, DOI 10.1080/01431161.2016.1192304
   WalesOnline, 2020, PONT TOWN CTR FLOOD, V0, P0
   Wessel B, 2018, ISPRS J PHOTOGRAMM, V139, P171, DOI 10.1016/j.isprsjprs.2018.02.017
   Westerhoff RS, 2013, HYDROL EARTH SYST SC, V17, P651, DOI 10.5194/hess-17-651-2013
   Winsemius HC, 2016, NAT CLIM CHANGE, V6, P381, DOI 10.1038/nclimate2893
NR 59
TC 14
Z9 14
U1 8
U2 62
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 
EI 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD FEB 23
PY 2021
VL 15
IS 3
BP 
EP 
DI 10.1117/1.JRS.15.032003
PG 22
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology
GA RQ2GD
UT WOS:000642237500001
DA 2023-04-26
ER

PT J
AU Chen, M
   Briffa, JA
   Valentino, G
   Farrugia, RA
AF Chen, Mang
   Briffa, Johann A.
   Valentino, Gianluca
   Farrugia, Reuben A.
TI Stereo Matching Of Remote Sensing Images Using Deep Stereo Matching
SO IMAGE AND SIGNAL PROCESSING FOR REMOTE SENSING XXVII
LA English
DT Proceedings Paper
DE deep learning; digital elevation model; earth observation; stereo vision
AB Very high resolution satellite images can be used to generate stereoscopic digital elevation models (DEMs), efficiently and at scale, as exemplified by the upcoming CO3D mission, which aims to produce worldwide DEMs by the end of 2025. In this paper we present a deep learning stereo-vision algorithm, integrated in the Stereo Pipeline for Pushbroom Images (S2P) framework. The proposed stereo matching method applies a Siamese convolutional neural network (CNN) to construct a cost volume. A median filter is applied to every slice in the cost volume to enforce spatial smoothness, and another CNN estimates a confidence map which is used to derive the final disparity map. Simulation results on the IARPA dataset show that the proposed method improves completeness by 4.5%, compared to the state of the art. A qualitative assessment also shows that the proposed method generates DEMs with less noise.
C1 [Chen, Mang; Briffa, Johann A.; Valentino, Gianluca; Farrugia, Reuben A.] Univ Malta, Dept Commun & Comp Engn, Msida, Malta.
C3 University of Malta
RP Farrugia, RA (corresponding author), Univ Malta, Dept Commun & Comp Engn, Msida, Malta.
EM reuben.farrugia@tum.edu.mt
FU Malta Council for Science Technology; Foundation for Science and Technology, through the MCST-CNES Space Bilateral Fund
CR Bagnardi M, 2016, GEOPHYS RES LETT, V43, P6267, DOI 10.1002/2016GL069457
   Bosch M, 2016, IEEE APP IMG PAT, V0, P0
   Facciolo G, 2017, IEEE COMPUT SOC CONF, V0, PP1542, DOI 10.1109/CVPRW.2017.198
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Kim S, 2019, PROC CVPR IEEE, V0, PP205, DOI 10.1109/CVPR.2019.00029
   Knobelreiter P, 2018, INT GEOSCI REMOTE SE, V0, P4379
   Krauss T, 2015, INT ARCH PHOTOGRAMM, V40-3, P115, DOI 10.5194/isprsarchives-XL-3-W2-115-2015
   Laga Hamid, 2020, IEEE T PATTERN ANAL, V0, P0
   Lebe`gue L., 2020, INT ARCH PHOTOGRAMME, V43, P299
   Panagiotakis E, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7030118
   Qin R., 2017, ASPRS IGTF ANN C, V0, P0
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Tsanis IK, 2014, J HYDROINFORM, V16, P1, DOI 10.2166/hydro.2013.197
   Youssefi D., 2020, IEEE INT GEOSC REM S, V0, P0
   Zbontar J, 2016, J MACH LEARN RES, V17, P0
NR 16
TC 1
Z9 1
U1 4
U2 10
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
J9 PROC SPIE
PD JUN 15
PY 2021
VL 11862
IS 
BP 
EP 
DI 10.1117/12.2597702
PG 6
WC Computer Science, Artificial Intelligence; Remote Sensing; Optics; Imaging Science & Photographic Technology
SC Computer Science; Remote Sensing; Optics; Imaging Science & Photographic Technology
GA BS7DU
UT WOS:000759218100007
DA 2023-04-26
ER

PT J
AU Chen, Y
   Weng, QH
   Tang, LL
   Liu, QH
   Zhang, X
   Bilal, M
AF Chen, Yang
   Weng, Qihao
   Tang, Luliang
   Liu, Qinhuo
   Zhang, Xia
   Bilal, Muhammad
TI Automatic mapping of urban green spaces using a geospatial neural network
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Urban green spaces; remote-sensing imagery; crowdsourcing; geospatial big data; deep learning; SDG 11; 7; urban areas
ID land-cover classification; openstreetmap data; convolutional networks; time-series; heat-island; imagery; impacts; extraction; multiscale; dynamics
AB Detailed and precise urban green spaces (UGS) maps provide essential data for the sustainable urban development and related studies (e.g. heatwave events, heat related health risk, urban flooding, urban biodiversity and ecosystem services). However, remote sensing of mapping UGS is challenging due to the existence of mixed pixels and the cost and difficulty of collecting quality training data. This study presents a neural network-based automatic mapping method of UGS that integrates the use of Sentinel-2A satellite images and crowdsourced geospatial big data. The proposed neural network consists of three parts: (i) a multi-scale feature extraction module; (ii) a multi-modal information fuse module; and (iii) and a boundary enhancement module. The results showed that the proposed method achieved a high overall classification accuracy of 94.6%, which presents a clear UGS structure of a large scale. This study provides a fresh insight into how remote-sensing and crowdsourced geospatial big data can be integrated to improve urban mapping of green spaces through neural network.
C1 [Chen, Yang; Tang, Luliang] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Peoples R China.
   [Weng, Qihao] Indiana State Univ, Ctr Urban & Environm Change, Dept Earth & Environm Syst, Terre Haute, IN 47809 USA.
   [Liu, Qinhuo] Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing, Peoples R China.
   [Zhang, Xia] Wuhan Univ, Sch Urban Design, Wuhan, Peoples R China.
   [Bilal, Muhammad] Nanjing Univ Informat Sci & Technol, Nanjing, Peoples R China.
C3 Wuhan University; Indiana State University; Chinese Academy of Sciences; Wuhan University; Nanjing University of Information Science & Technology
RP Tang, LL (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Peoples R China.; Weng, QH (corresponding author), Indiana State Univ, Ctr Urban & Environm Change, Dept Earth & Environm Syst, Terre Haute, IN 47809 USA.
EM qweng@indstate.edu; tll@whu.edu.cn
FU National Natural Science Foundation of China [41971405, 41671442]; National Key Research and Development Plan of China [2017YFB0503604, 2016YFE0200400]
CR Abbott BW, 2019, NAT GEOSCI, V12, P533, DOI 10.1038/s41561-019-0374-y
   Amir M., 2017, P IEEE INT C COMM IC, V0, P1
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Arsanjani JJ, 2013, INT ARCH PHOTOGRAMM, V40-4-W1, P51
   Astell-Burt T, 2020, ENVIRON INT, V145, P0, DOI 10.1016/j.envint.2020.106102
   Bengio Yoshua, 2012, NEURAL NETWORKS: TRICKS OF THE TRADE. SECOND EDITION: LNCS 7700, V0, PP437, DOI 10.1007/978-3-642-35289-8_26
   Carpio M, 2020, ENERG BUILDINGS, V226, P0, DOI 10.1016/j.enbuild.2020.110379
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y., 2021, IEEE T GEOSCI REMOTE, V59, P1
   Chen Y, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10050585
   Chen Y, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7050181
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Dai ZX, 2018, SCI TOTAL ENVIRON, V626, P1136, DOI 10.1016/j.scitotenv.2018.01.165
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Di SC, 2019, INT J REMOTE SENS, V40, P1909, DOI 10.1080/01431161.2018.1479798
   Du SJ, 2020, GISCI REMOTE SENS, V57, P411, DOI 10.1080/15481603.2020.1724707
   Eigen D, 2015, IEEE I CONF COMP VIS, V0, PP2650, DOI 10.1109/ICCV.2015.304
   Elwood S, 2012, ANN ASSOC AM GEOGR, V102, P571, DOI 10.1080/00045608.2011.595657
   Fonte CC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203428
   FOODY GM, 1995, INT J REMOTE SENS, V16, P301, DOI 10.1080/01431169508954396
   Fu X., 2018, 2018 12 INT S ANT PR, V0, P1
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Hartling S, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19061284
   Havinga I, 2020, ECOSYST SERV, V43, P0, DOI 10.1016/j.ecoser.2020.101091
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Ji YZ, 2018, NEUROCOMPUTING, V322, P130, DOI 10.1016/j.neucom.2018.09.061
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Kranjcic N, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060655
   Kuang WH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121929
   Lee JS, 1999, IEEE T GEOSCI REMOTE, V37, P2249, DOI 10.1109/36.789621
   Lee S, 2006, IEEE T GEOSCI REMOTE, V44, P1642, DOI 10.1109/TGRS.2006.869984
   Li DL, 2020, URBAN FOR URBAN GREE, V54, P0, DOI 10.1016/j.ufug.2020.126764
   Liang P, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010016
   Liu DD, 2020, ISPRS J PHOTOGRAMM, V159, P337, DOI 10.1016/j.isprsjprs.2019.11.021
   Liu YL, 2016, PATTERN RECOGN, V55, P58, DOI 10.1016/j.patcog.2016.01.030
   Luo NX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010088
   Ma L, 2014, J APPL REMOTE SENS, V8, P0, DOI 10.1117/1.JRS.8.083673
   Mishra P, 2019, TENCON IEEE REGION, V0, PP2087, DOI 10.1109/TENCON.2019.8929465
   Peng C, 2017, PROC CVPR IEEE, V0, PP1743, DOI 10.1109/CVPR.2017.189
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Qin XB, 2019, PROC CVPR IEEE, V0, PP7471, DOI 10.1109/CVPR.2019.00766
   Quintano C, 2018, INT J APPL EARTH OBS, V64, P221, DOI 10.1016/j.jag.2017.09.014
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Selway CA, 2020, ENVIRON INT, V145, P0, DOI 10.1016/j.envint.2020.106084
   Studer Linda, 2020, 2020 7TH SWISS CONFERENCE ON DATA SCIENCE (SDS), V0, PP57, DOI 10.1109/SDS49233.2020.00021
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Tavares PA, 2019, ENVIRONMENTS, V6, P0, DOI 10.3390/environments6050051
   Teodoro A, 2019, ENVIRONMENTS, V6, P0, DOI 10.3390/environments6030036
   Teodoro AC, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.016011
   Tong ZQ, 2019, NEUROCOMPUTING, V333, P76, DOI 10.1016/j.neucom.2018.12.036
   Van Herzele A, 2003, LANDSCAPE URBAN PLAN, V63, P109, DOI 10.1016/S0169-2046(02)00192-5
   Voltersen M, 2014, REMOTE SENS ENVIRON, V154, P192, DOI 10.1016/j.rse.2014.08.024
   Wan TL, 2017, IEEE GEOSCI REMOTE S, V14, P2305, DOI 10.1109/LGRS.2017.2762466
   WANG F, 1990, IEEE T GEOSCI REMOTE, V28, P194, DOI 10.1109/36.46698
   Wang Q, 2020, ATMOS RES, V236, P0, DOI 10.1016/j.atmosres.2019.104805
   Wang QM, 2018, REMOTE SENS ENVIRON, V204, P31, DOI 10.1016/j.rse.2017.10.046
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Wenya Liu, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON IMAGE, Vision and Computing (ICIVC), P311, DOI 10.1109/ICIVC47709.2019.8981007
   Xiao ZS, 2020, ATMOS ENVIRON, V230, P0, DOI 10.1016/j.atmosenv.2020.117508
   Xu F, 2021, ISPRS J PHOTOGRAMM, V171, P133, DOI 10.1016/j.isprsjprs.2020.11.009
   Xu ZY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223845
   Yao Y, 2017, INT J GEOGR INF SCI, V31, P825, DOI 10.1080/13658816.2016.1244608
   Yue C, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-16953-8
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang J, 2011, INT GEOSCI REMOTE SE, V0, PP150, DOI 10.1109/IGARSS.2011.6048920
   Zhang T., 2019, ARXIV PREPRINT ARXIV, V0, P0
   Zhang XL, 2015, ISPRS J PHOTOGRAMM, V102, P73, DOI 10.1016/j.isprsjprs.2015.01.009
   Zhao WZ, 2019, ISPRS J PHOTOGRAMM, V151, P237, DOI 10.1016/j.isprsjprs.2019.03.019
   Zheng YC, 2019, PATTERN RECOGN, V93, P558, DOI 10.1016/j.patcog.2019.05.014
   Zou XH, 2017, IEEE GEOSCI REMOTE S, V14, P2360, DOI 10.1109/LGRS.2017.2764938
NR 74
TC 14
Z9 14
U1 29
U2 117
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD MAY 19
PY 2021
VL 58
IS 4
BP 624
EP 642
DI 10.1080/15481603.2021.1933367
EA JUN 2021
PG 19
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA SX2QJ
UT WOS:000657539000001
DA 2023-04-26
ER

PT J
AU Coelho, FF
   Giasson, E
   Campos, AR
   Tiecher, T
   Costa, JJF
   Coblinski, JA
AF Coelho, Fabricio Fernandes
   Giasson, Elvio
   Campos, Alcinei Ribeiro
   Tiecher, Tales
   Ferreira Costa, Jose Janderson
   Coblinski, Joao Augusto
TI Digital soil class mapping in Brazil: a systematic review
SO SCIENTIA AGRICOLA
LA English
DT Review
DE pedology; mapping unit density; artificial neural networks; soil-forming factors; overall accuracy
ID grande-do-sul; multiple logistic-regression; artificial neural-networks; landscape relationships; elevation models; decision trees; extrapolation; area; map; prediction
AB In Brazil several digital soil class mapping studies were carried out from 2006 onwards to maximize the use of existing maps and information and to provide estimates for wider areas. However, there is no consensus on which methods have produced superior results in the predictive value of soil maps. This study conducts a systematic review of digital soil class mapping in Brazil and aims to analyze the factors which can improve the accuracy of digital soil class maps. Data from 334 digital soil class mapping studies were grouped and analyzed by Student's t-test, Wilcoxon-Mann-Whitney test and Kruskal-Wallis test. When conventional maps were used for validation, the studies showed average values of 63 % and when field samples were used, 56 % for Overall Accuracy. Studies compatible with the Planimetric Cartographic Accuracy Standard for Digital Cartographic Products (PEC-PCD) averaged between 4 % and 15 % higher accuracy than those of the incompatible group. There seems to be no evidence that increasing the number of variables and samples results in more accurate soil map prediction, but studies using variables related to four soil-forming factors enhanced accuracy. From a density of 0.08 MU km(-2) and upwards, it became more difficult for studies to obtain greater accuracy. Artificial neural network classifiers and Decision Tree models seem to be producing more accurate digital soil class maps.
C1 [Coelho, Fabricio Fernandes; Giasson, Elvio; Campos, Alcinei Ribeiro; Tiecher, Tales; Ferreira Costa, Jose Janderson; Coblinski, Joao Augusto] Univ Fed Rio Grande do Sul, Dept Solos, Av Bento Goncalves 7712, BR-91540000 Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Coelho, FF (corresponding author), Univ Fed Rio Grande do Sul, Dept Solos, Av Bento Goncalves 7712, BR-91540000 Porto Alegre, RS, Brazil.
EM fabricio.coelho@ufrgs.br
FU Coordination for the Improvement of Higher Level Personnel (CAPES) [001]
CR Arrouays D, 2017, GEODERMA REG, V9, P1, DOI 10.1016/j.geodrs.2017.03.002
   Bagatini T, 2016, PESQUI AGROPECU BRAS, V51, P1317, DOI 10.1590/S0100-204X2016000900031
   Bagatini T, 2015, REV BRAS CIENC SOLO, V39, P960, DOI 10.1590/01000683rbcs20140289
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Brungard CW, 2015, GEODERMA, V239, P68, DOI 10.1016/j.geoderma.2014.09.019
   Calderano B, 2014, REV BRAS CIENC SOLO, V38, P1681, DOI 10.1590/S0100-06832014000600003
   Campos AR, 2019, REV BRAS CIENC AGRAR, V14, P0, DOI 10.5039/agraria.v14i2a5653
   Campos AR, 2018, REV BRAS CIENC SOLO, V42, P0, DOI 10.1590/18069657rbcs20170414
   Cancian LC, 2018, AN ACAD BRAS CIENC, V90, P3911, DOI 10.1590/0001-3765201820180423
   Chagas CD, 2017, GEODERMA REG, V9, P47, DOI 10.1016/j.geodrs.2017.03.004
   Chagas CD, 2013, REV BRAS CIENC SOLO, V37, P339, DOI 10.1590/S0100-06832013000200005
   Chagas CD, 2011, REV BRAS CIENC SOLO, V35, P693
   Chagas CD, 2010, PESQUI AGROPECU BRAS, V45, P497, DOI 10.1590/S0100-204X2010000500009
   Silva BPC, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-50376-w
   Coelho FF, 2010, CIENC RURAL, V40, P2099, DOI 10.1590/S0103-84782010005000156
   Costa EM, 2018, CIENC AGROTEC, V42, P608, DOI 10.1590/1413-70542018426027418
   Crivelenti RC, 2009, PESQUI AGROPECU BRAS, V44, P1707, DOI 10.1590/S0100-204X2009001200021
   da Silva CC, 2013, REV BRAS CIENC SOLO, V37, P846, DOI 10.1590/S0100-06832013000400003
   Dias LMD, 2016, PESQUI AGROPECU BRAS, V51, P1396, DOI 10.1590/S0100-204X2016000900038
   de Arruda GP, 2016, SCI AGR, V73, P266, DOI 10.1590/0103-9016-2015-0131
   de Arruda GP, 2013, REV BRAS CIENC SOLO, V37, P327, DOI 10.1590/S0100-06832013000200004
   de Carvalho W, 2011, SCI AGR, V68, P691, DOI 10.1590/S0103-90162011000600014
   Dearden P., 2011, MENDELEY REFERENCE M, V0, P0
   Dematte JAM, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100826
   Diretoria de Servico Geografico. Quartel General do Exercito, 2011, TECHN SPEC GEOSP VEC, V0, P0
   Figueiredo SR, 2008, REV BRAS CIENC SOLO, V32, P2779, DOI 10.1590/S0100-06832008000700023
   Giasson E, 2006, SCI AGR, V63, P262, DOI 10.1590/S0103-90162006000300008
   Giasson E, 2015, CIENC RURAL, V45, P1592, DOI 10.1590/0103-8478cr20140694
   Giasson E, 2013, CIENC RURAL, V43, P1967, DOI 10.1590/S0103-84782013001100008
   Giasson E, 2011, SCI AGR, V68, P167, DOI 10.1590/S0103-90162011000200006
   Silva SHG, 2016, GEODERMA, V267, P65, DOI 10.1016/j.geoderma.2015.12.025
   Grinand C, 2008, GEODERMA, V143, P180, DOI 10.1016/j.geoderma.2007.11.004
   Hofig P, 2014, PESQUI AGROPECU BRAS, V49, P958, DOI 10.1590/S0100-204X2014001200006
   Khaledian Y, 2020, APPL MATH MODEL, V81, P401, DOI 10.1016/j.apm.2019.12.016
   Ma YX, 2019, EUR J SOIL SCI, V70, P216, DOI 10.1111/ejss.12790
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   Meier M, 2018, REV BRAS CIENC SOLO, V42, P0, DOI 10.1590/18069657rbcs20170421
   Minasny B, 2016, GEODERMA, V264, P301, DOI 10.1016/j.geoderma.2015.07.017
   Moura-Bueno JM, 2019, PESQUI AGROPECU BRAS, V54, P0, DOI 10.1590/S1678-3921.pab2019.v54.00420
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Pelegrino MHP, 2016, CIENC AGROTEC, V40, P534, DOI 10.1590/1413-70542016405011416
   Silvero NEQ, 2019, SCI TOTAL ENVIRON, V693, P0, DOI 10.1016/j.scitotenv.2019.07.269
   Sarmento EC, 2012, PESQUI AGROPECU BRAS, V47, P1395, DOI 10.1590/S0100-204X2012000900025
   ten Caten A, 2013, REV BRAS CIENC SOLO, V37, P359, DOI 10.1590/S0100-06832013000200007
   ten Caten A, 2012, CIENC RURAL, V42, P1989, DOI 10.1590/S0103-84782012001100013
   Ten Caten A, 2012, REV BRAS CIENC SOLO, V36, P1083, DOI 10.1590/S0100-06832012000400003
   ten Caten A, 2011, CIENC RURAL, V41, P1170, DOI 10.1590/S0103-84782011000700011
   ten Caten A, 2011, PESQUI AGROPECU BRAS, V46, P554
   ten Caten A, 2011, CIENC RURAL, V41, P812, DOI 10.1590/S0103-84782011000500012
   ten Caten A, 2011, REV BRAS CIENC SOLO, V35, P53, DOI 10.1590/S0100-06832011000100005
   Teske R, 2015, REV BRAS CIENC SOLO, V39, P950, DOI 10.1590/01000683rbcs20140285
   Teske R, 2015, REV BRAS CIENC SOLO, V39, P14, DOI 10.1590/01000683rbcs20150344
   Teske R, 2014, REV BRAS CIENC SOLO, V38, P1367, DOI 10.1590/S0100-06832014000500002
   Vasques GM, 2015, EUR J SOIL SCI, V66, P767, DOI 10.1111/ejss.12255
   Wolski MS, 2017, PESQUI AGROPECU BRAS, V52, P633, DOI 10.1590/S0100-204X2017000800009
   Zhang GL, 2017, J INTEGR AGR, V16, P2871, DOI 10.1016/S2095-3119(17)61762-3
   Zuur AF, 2010, METHODS ECOL EVOL, V1, P3, DOI 10.1111/j.2041-210X.2009.00001.x
NR 57
TC 8
Z9 8
U1 6
U2 64
PU UNIV SAO PAOLO
PI CERQUERA CESAR
PA AV  DR ENEAS DE CARVALHO AGUIAR, 419, CERQUERA CESAR, SP 05403-000, BRAZIL
SN 1678-992X
EI 
J9 SCI AGR
JI Sci. Agric.
PD JUN 15
PY 2021
VL 78
IS 5
BP 
EP 
DI 10.1590/1678-992X-2019-0227
PG 11
WC Agriculture, Multidisciplinary
SC Agriculture
GA NE6VL
UT WOS:000562739200001
DA 2023-04-26
ER

PT J
AU Wen, CC
   Li, X
   Yao, XJ
   Peng, L
   Chi, TH
AF Wen, Congcong
   Li, Xiang
   Yao, Xiaojing
   Peng, Ling
   Chi, Tianhe
TI Airborne LiDAR point cloud classification with global-local graph attention convolution neural network
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Airborne LiDAR; Point cloud classification; Point cloud deep learning; Graph attention convolution; ISPRS 3D labeling
ID line
AB Airborne light detection and ranging (LiDAR) plays an increasingly significant role in urban planning, topographic mapping, environmental monitoring, power line detection and other fields thanks to its capability to quickly acquire large-scale and high-precision ground information. To achieve point cloud classification, previous studies proposed point cloud deep learning models that can directly process raw point clouds based on PointNet-like architectures. And some recent works proposed graph convolution neural network based on the inherent topology of point clouds. However, the above point cloud deep learning models only pay attention to exploring local geometric structures, yet ignore global contextual relationships among all points. In this paper, we present a global-local graph attention convolution neural network (GACNN) that can be directly applied to the classification of unstructured 3D point clouds obtained by airborne LiDAR. Specifically, we first introduce a graph attention convolution module that incorporates global contextual information and local structural features. The global attention module examines spatial relationships among all points, while the local attention module can dynamically learn convolution weights with regard to the spatial position of the local neighboring points and reweight the convolution weights by inspecting the density of each local region. Based on the proposed graph attention convolution module, we further design an end-to-end encoder-decoder network, named GACNN, to capture multiscale features of the point clouds and therefore enable more accurate airborne point cloud classification. Experiments on the ISPRS 3D labeling dataset show that the proposed model achieves a new state-of-the-art performance in terms of average F1 score (71.5%) and a satisfying overall accuracy (83.2%). Additionally, experiments further conducted on the 2019 Data Fusion Contest Dataset by comparing with other prevalent point cloud deep learning models demonstrate the favorable generalization capability of the proposed model.
C1 [Wen, Congcong; Yao, Xiaojing; Peng, Ling; Chi, Tianhe] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
   [Wen, Congcong] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wen, Congcong; Li, Xiang] NYU, Tandon Sch Engn, New York, NY USA.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; New York University; New York University Tandon School of Engineering
RP Peng, L (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
EM plqiqi@126.com
FU Beijing Municipal Science and Technology Project [Z191100001419002]; program of China Scholarship Council [201904910848]
CR [Anonymous], 2000, INT ARCH PHOTOGRAMME, V0, P0
   [Anonymous], 2009, ISPRS ARCH PHOTOGRAM, V0, P0
   Arief H.A., 2019, ARXIV PREPRINT ARXIV, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Blomley R., 2016, 3D SEMANTIC LABELING, V0, P0
   Bradbury RB, 2005, IBIS, V147, P443, DOI 10.1111/j.1474-919x.2005.00438.x
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen Charles, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Chen Q, 2007, PHOTOGRAMM ENG REM S, V73, P109
   Collobert R., 2008, P 25 INT C MACHINE L, V0, P0
   Cramer M, 2010, PHOTOGRAMM FERNERKUN, V0, PP73, DOI 10.1127/1432-8364/2010/0041
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horvat D, 2016, ISPRS J PHOTOGRAMM, V116, P1, DOI 10.1016/j.isprsjprs.2016.02.011
   Huang CQ, 2014, REMOTE SENS ENVIRON, V141, P231, DOI 10.1016/j.rse.2013.10.020
   Jiang M, 2018, ARXIV PREPRINT ARXIV, V0, P0
   KRABILL WB, 1984, PHOTOGRAMM ENG REM S, V50, P685
   Li YY, 2018, ADV NEUR IN, V31, P0
   Liu XY, 2008, PROG PHYS GEOG, V32, P31, DOI 10.1177/0309133308089496
   Lodha SK, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, V0, P435
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Munoz D, 2009, PROC CVPR IEEE, V0, PP975, DOI 10.1109/CVPRW.2009.5206590
   Niemeyer J, 2016, INT ARCH PHOTOGRAMM, V41, P655, DOI 10.5194/isprsarchives-XLI-B3-655-2016
   Niemeyer J, 2012, ISPRS ANN PHOTOGRAMM, V1, P263, DOI 10.5194/ISPRSANNALS-I-3-263-2012
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Niemeyer J, 2011, LECT NOTES COMPUT SC, V6952, P233, DOI 10.1007/978-3-642-24393-6_20
   Qi C.R., 2017, ADV NEUR IN, V0, P5099
   Shapovalov R., 2010, INT ARCH PHOTOGRAMME, VXXXVIII, P0
   Te GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP746, DOI 10.1145/3240508.3240621
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang L, 2019, PROC CVPR IEEE, V0, PP10288, DOI 10.1109/CVPR.2019.01054
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Wang Z, 2018, IEEE T GEOSCI REMOTE, V56, P4594, DOI 10.1109/TGRS.2018.2829625
   Wen CC, 2020, ISPRS J PHOTOGRAMM, V162, P50, DOI 10.1016/j.isprsjprs.2020.02.004
   Wen CC, 2019, SCI TOTAL ENVIRON, V654, P1091, DOI 10.1016/j.scitotenv.2018.11.086
   Yang Z., 2017, REMOTE SENS-BASEL, V9, P0
   Yang Z., 2018, SENSORS-BASEL, V18, P0
   Yousefhussien M, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Yousefhussien M, 2018, ISPRS J PHOTOGRAMM, V143, P191, DOI 10.1016/j.isprsjprs.2018.03.018
   Yu BL, 2010, LANDSCAPE URBAN PLAN, V98, P210, DOI 10.1016/j.landurbplan.2010.08.004
   Zhang JX, 2013, REMOTE SENS-BASEL, V5, P3749, DOI 10.3390/rs5083749
   Zhao RB, 2018, INT J GEOGR INF SCI, V32, P960, DOI 10.1080/13658816.2018.1431840
   Zhu LL, 2014, REMOTE SENS-BASEL, V6, P11267, DOI 10.3390/rs61111267
NR 45
TC 36
Z9 38
U1 12
U2 86
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAR 15
PY 2021
VL 173
IS 
BP 181
EP 194
DI 10.1016/j.isprsjprs.2021.01.007
EA JAN 2021
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO3ZZ
UT WOS:000640986100012
DA 2023-04-26
ER

PT J
AU Wang, PP
   Yuan, MY
   He, Y
   Sun, J
AF Wang, Peipei
   Yuan, Mingyuan
   He, Yan
   Sun, Jiuai
TI 3D augmented fundus images for identifying glaucoma via transferred convolutional neural networks
SO INTERNATIONAL OPHTHALMOLOGY
LA English
DT Article
DE Glaucoma; 3D; Convolutional neural network; Transfer learning
AB Purpose Glaucoma is a chronic and irreversible retinopathy threatening the vision of millions of patients around the world. Its early diagnosis and treatment can help to prolong the period of sight deterioration from no visual impairment to blindness, whereas the screening and diagnosis of glaucoma in clinical remains challenging because some key assessment criteria like cup-to-disc ratio is limited by subjective analysis and intra- and inter-observer variability. This paper exploits the potential of new augmented image data of the optic nerve head (ONH) combining with the latest deep learning networks to achieve better diagnosis of glaucoma. Methods This paper explores the potential value of additional three-dimensional topographic map of the optic nerve head proceeded by the latest deep learning approaches, i.e. convolutional neural networks to improve the diagnosis efficiency. Specifically, 3D topography map of the ONH and RGB fundus image has been used to train the transferred AlexNet and VGG-16 networks. The diagnostic performance is compared to those achieved by using the 2D fundus images only. Results The 3D topographic map of ONH reconstructed from the shape from shading method provides better visualization of the structure of optic cup and disc. These new enhanced dataset was employed to train the proposed deep learning networks and finally achieve diagnostic accuracy of 94.3% which is superior to the networks trained via 2D conventional images. Conclusion Employing the deep learning neural networks with augmented 3D images can increase the accuracy of automatic separating glaucoma and non-glaucoma fundus images. It may be used as an objective tool in developing computer assisted diagnosis systems for assessment of glaucoma.
C1 [Wang, Peipei; Yuan, Mingyuan] Shanghai Univ Med & Hlth Sci, Dept Radiol, Affliated Zhoupu Hosp, Shanghai 201318, Peoples R China.
   [Wang, Peipei; Sun, Jiuai] Shanghai Univ Med & Hlth Sci, Coll Med Imaging, Shanghai 201318, Peoples R China.
   [He, Yan] Cent South Univ, Xiangya Hosp 2, Dept Ophthalmol, Changsha 410011, Hunan, Peoples R China.
   [He, Yan] Hunan Clin Res Ctr Ophthalm Dis, Changsha 410011, Hunan, Peoples R China.
   [He, Yan] Cent South Univ, Clin Immunol Ctr, Changsha 410011, Hunan, Peoples R China.
C3 Shanghai University of Medicine & Health Sciences; Shanghai University of Medicine & Health Sciences; Central South University; Central South University
RP Sun, J (corresponding author), Shanghai Univ Med & Hlth Sci, Coll Med Imaging, Shanghai 201318, Peoples R China.; He, Y (corresponding author), Cent South Univ, Xiangya Hosp 2, Dept Ophthalmol, Changsha 410011, Hunan, Peoples R China.
EM sunja@sumhs.edu.cn
FU Shanghai University of Medicine and Health Sciences (Innovative and Collaborative Project Funding of Shanghai University of Medicine and Health Sciences) [SPCI-17-18-001]
CR Abbas Q, 2017, INT J ADV COMPUT SC, V8, P41
   Benzebouchi N.E., 2018, INT J ADV ELECT COMP, V5, P31
   Brooks, 1985, COMPUT VIS GR IMAGE, V32, P142, DOI 10.1016/0734-189x(85)90010-6
   Budai A, 2013, INT J BIOMED IMAGING, V2013, P0, DOI 10.1155/2013/154860
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Chan EW, 2013, TRANSL VIS SCI TECHN, V2, P0, DOI 10.1167/tvst.2.5.2
   Chen X, 2015, IEEE ENG MED BIO, V0, PP6834, DOI 10.1109/EMBC.2015.7319963
   Choi JY, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0187336
   Claro M, 2019, J VIS COMMUN IMAGE R, V64, P0, DOI 10.1016/j.jvcir.2019.102597
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   DAMMS T, 1993, INVEST OPHTH VIS SCI, V34, P2246
   Dave P, 2015, BRIT J OPHTHALMOL, V99, P1713, DOI 10.1136/bjophthalmol-2014-306331
   DONG Y, 2017, IEEE CONF IMAGING SY, V0, P0
   Ferreira MVD, 2018, EXPERT SYST APPL, V110, P250, DOI 10.1016/j.eswa.2018.06.010
   Fumero F, 2011, COMP MED SY, V0, P0
   Gao XT, 2015, LECT NOTES COMPUT SC, V9004, P632, DOI 10.1007/978-3-319-16808-1_42
   Harizman N, 2006, ARCH OPHTHALMOL-CHIC, V124, P1579, DOI 10.1001/archopht.124.11.1579
   Orlando JI, 2017, PROC SPIE, V10160, P0, DOI 10.1117/12.2255740
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Morgan JE, 2012, OPHTHALMOLOGY, V119, P723, DOI 10.1016/j.ophtha.2011.10.004
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Resnikoff S, 2004, B WORLD HEALTH ORGAN, V82, P844
   Roslin M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P2210, DOI 10.1109/ICCSP.2016.7754086
   Sivaswamy J., 2015, JSM BIOMEDICAL IMAGI, V2, P1004
   Varma R, 2011, AM J OPHTHALMOL, V152, P515, DOI 10.1016/j.ajo.2011.06.004
   Wang PP, 2018, PROC SPIE, V10615, P0, DOI 10.1117/12.2302502
   Zoph Barret, 2016, P 2016 C EMP METH NA, V0, P1568
NR 29
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0165-5701
EI 1573-2630
J9 INT OPHTHALMOL
JI Int. Ophthalmol.
PD JUN 15
PY 2021
VL 41
IS 6
BP 2065
EP 2072
DI 10.1007/s10792-021-01762-9
EA MAR 2021
PG 8
WC Ophthalmology
SC Ophthalmology
GA SM1GK
UT WOS:000624430300002
PM 33655390
DA 2023-04-26
ER

PT J
AU Wagatsuma, N
   Hidaka, A
   Tamura, H
AF Wagatsuma, Nobuhiko
   Hidaka, Akinori
   Tamura, Hiroshi
TI Correspondence between monkey visual cortices and layers of a saliency map model based on a deep convolutional neural network for representations of natural images
SO ENEURO
LA English
DT Article
ID classical receptive-field; inferior temporal cortex; v1 mechanisms; contextual influences; contour integration; border ownership; areas v1; attention; organization; suppression
AB Attentional selection is a function that allocates the brain's computational resources to the most important part of a visual scene at a specific moment. Saliency map models have been proposed as computational models to predict attentional selection within a spatial location. Recent saliency map models based on deep convolutional neural networks (DCNNs) exhibit the highest performance for predicting the location of attentional selection and human gaze, which reflect overt attention. Trained DCNNs potentially provide insight into the perceptual mechanisms of biological visual systems. However, the relationship between artificial and neural representations used for determining attentional selection and gaze location remains unknown. To understand the mechanism underlying saliency map models based on DCNNs and the neural system of attentional selection, we investigated the correspondence between layers of a DCNN saliency map model and monkey visual areas for natural image representations. We compared the characteristics of the responses in each layer of the model with those of the neural representation in the primary visual (V1), intermediate visual (V4), and inferior temporal cortices. Regardless of the DCNN layer level, the characteristics of the responses were consistent with that of the neural representation in V1. We found marked peaks of correspondence between V1 and the early level and higher-intermediate-level layers of the model. These results provide insight into the mechanism of the trained DCNN saliency map model and suggest that the neural representations in V1 play an important role in computing the saliency that mediates attentional selection, which supports the V1 saliency hypothesis.
C1 [Wagatsuma, Nobuhiko] Toho Univ, Fac Sci, Miyama 2-2-1, Funabashi, Chiba 2748510, Japan.
   [Hidaka, Akinori] Tokyo Denki Univ, Sch Sci & Engn, Tokyo, Japan.
   [Tamura, Hiroshi] Osaka Univ, Grad Sch Frontiers Biosci, Suita, Osaka, Japan.
   [Tamura, Hiroshi] Ctr Informat & Neural Networks CiNet, Osaka, Japan.
C3 Toho University; Tokyo Denki University; Osaka University; National Institute of Information & Communications Technology (NICT) - Japan
RP Wagatsuma, N (corresponding author), Toho Univ, Fac Sci, Miyama 2-2-1, Funabashi, Chiba 2748510, Japan.
EM nwagatsuma@is.sci.toho-u.ac.jp
CR Adesnik H, 2012, NATURE, V490, P226, DOI 10.1038/nature11526
   ALLMAN J, 1985, ANNU REV NEUROSCI, V8, P407, DOI 10.1146/annurev.ne.08.030185.002203
   Borji A., 2015, P IEEE C COMP VIS PA, V0, P0
   Bruce NDB, 2009, J VISION, V9, P0, DOI 10.1167/9.3.5
   Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005
   Carrasco M, 2011, VISION RES, V51, P1484, DOI 10.1016/j.visres.2011.04.012
   Chen G, 2017, NEURON, V96, P1403, DOI 10.1016/j.neuron.2017.11.033
   Craft E, 2007, J NEUROPHYSIOL, V97, P4310, DOI 10.1152/jn.00203.2007
   Deco G, 2004, EUR J NEUROSCI, V20, P1089, DOI 10.1111/j.1460-9568.2004.03528.x
   Geirhos R., 2019, INT C LEARNING REPRE, V0, P0
   Goda N, 2014, J NEUROSCI, V34, P2660, DOI 10.1523/JNEUROSCI.2593-13.2014
   Green DM., 1966, SIGNAL DETECTION THE, V0, P0
   Haxby JV, 2011, NEURON, V72, P404, DOI 10.1016/j.neuron.2011.08.026
   Hiramatsu C, 2011, NEUROIMAGE, V57, P482, DOI 10.1016/j.neuroimage.2011.04.056
   Hu B, 2017, J COMPUT NEUROSCI, V43, P227, DOI 10.1007/s10827-017-0659-3
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jiang M, 2015, PROC CVPR IEEE, V0, PP1072, DOI 10.1109/CVPR.2015.7298710
   Jingling L, 2008, PERCEPTION, V37, P197, DOI 10.1068/p5829
   Jones HE, 2002, J NEUROPHYSIOL, V88, P2796, DOI 10.1152/jn.00403.2001
   Jones HE, 2001, J NEUROPHYSIOL, V86, P2011, DOI 10.1152/jn.2001.86.4.2011
   Judd T, 2009, IEEE I CONF COMP VIS, V0, PP2106, DOI 10.1109/ICCV.2009.5459462
   Kaneko H, 1999, IEEE T BIO-MED ENG, V46, P280, DOI 10.1109/10.748981
   Kaneko H, 2007, IEEE T BIO-MED ENG, V54, P262, DOI 10.1109/TBME.2006.886934
   Kiani R, 2007, J NEUROPHYSIOL, V97, P4296, DOI 10.1152/jn.00024.2007
   Kiimmerer M., 2014, ARXIV14111045, V0, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   KNIERIM JJ, 1992, J NEUROPHYSIOL, V67, P961, DOI 10.1152/jn.1992.67.4.961
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Koene AR, 2007, J VISION, V7, P0, DOI 10.1167/7.7.6
   Kriegeskorte N, 2008, NEURON, V60, P1126, DOI 10.1016/j.neuron.2008.10.043
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kummerer M, 2017, IEEE I CONF COMP VIS, V0, PP4799, DOI 10.1109/ICCV.2017.513
   Le Q. V., 2012, P INT C MACH LEARN I, V0, P8595
   Lee DK, 1999, NAT NEUROSCI, V2, P375, DOI 10.1038/7286
   LI CY, 1994, VISION RES, V34, P2337, DOI 10.1016/0042-6989(94)90280-1
   Zhaoping L, 2019, CURR OPIN NEUROBIOL, V58, P1, DOI 10.1016/j.conb.2019.06.001
   Li ZP, 1999, P NATL ACAD SCI USA, V96, P10530, DOI 10.1073/pnas.96.18.10530
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   Li ZP, 2000, ADV NEUR IN, V12, P136
   Li ZP, 1999, NETWORK-COMP NEURAL, V10, P187, DOI 10.1088/0954-898X/10/2/305
   Li ZP, 1998, NEURAL COMPUT, V10, P903, DOI 10.1162/089976698300017557
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Mahendran A, 2015, PROC CVPR IEEE, V0, PP5188, DOI 10.1109/CVPR.2015.7299155
   Martin AB, 2015, J NEUROSCI, V35, P6860, DOI 10.1523/JNEUROSCI.3590-14.2015
   Mihalas S, 2011, P NATL ACAD SCI USA, V108, P7583, DOI 10.1073/pnas.1014655108
   Nair V, 2010, ICML, V27, P807
   Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Ozeki H, 2009, NEURON, V62, P578, DOI 10.1016/j.neuron.2009.03.028
   Pan J., 2017, CVPR SCEN UND WORKSH, V0, P0
   Pan JT, 2016, PROC CVPR IEEE, V0, PP598, DOI 10.1109/CVPR.2016.71
   Pasupathy A, 2001, J NEUROPHYSIOL, V86, P2505, DOI 10.1152/jn.2001.86.5.2505
   Poort J, 2016, CEREB CORTEX, V26, P3964, DOI 10.1093/cercor/bhw235
   Poort J, 2012, NEURON, V75, P143, DOI 10.1016/j.neuron.2012.04.032
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Pospisil DA, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.38242
   Qiu FTT, 2007, NAT NEUROSCI, V10, P1492, DOI 10.1038/nn1989
   Rolls E. T., 2002, COMPUTATIONAL NEUROS, V0, P0
   Russell AF, 2014, VISION RES, V94, P1, DOI 10.1016/j.visres.2013.10.005
   Sakai K, 2006, J COGNITIVE NEUROSCI, V18, P562, DOI 10.1162/jocn.2006.18.4.562
   Sakai K, 2012, NEURAL NETWORKS, V33, P257, DOI 10.1016/j.neunet.2012.05.006
   Simonyan K, 2015, ARXIV, V0, P0
   Tamura H, 2001, CEREB CORTEX, V11, P384, DOI 10.1093/cercor/11.5.384
   Tamura H, 2016, NEURONS INFERIOR TEM, V0, P0
   Tamura H, 2014, J NEUROPHYSIOL, V111, P2589, DOI 10.1152/jn.00336.2013
   Tokui T, 2015, P WORKSH MACH LEARN, V0, P0
   Uejima T, 2020, FRONT COMPUT NEUROSC, V14, P0, DOI 10.3389/fncom.2020.541581
   Wagatsuma N, 2019, NEURAL NETWORKS, V110, P33, DOI 10.1016/j.neunet.2018.10.015
   Wagatsuma N, 2016, J NEUROPHYSIOL, V116, P1418, DOI 10.1152/jn.01142.2015
   WURTZ RH, 1969, J NEUROPHYSIOL, V32, P727, DOI 10.1152/jn.1969.32.5.727
   Yamins DLK, 2016, NAT NEUROSCI, V19, P356, DOI 10.1038/nn.4244
   Yan Y, 2018, P NATL ACAD SCI USA, V115, P10499, DOI 10.1073/pnas.1803854115
   Yang TX, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0203024
   Zeiler M.D., 2013, P EUR C COMP VIS, V0, P0, DOI DOI 10.1007/978-3-319-10590-1_53
   Zhang XL, 2012, NEURON, V73, P183, DOI 10.1016/j.neuron.2011.10.035
   Zhaoping L, 2003, J PHYSIOL-PARIS, V97, P503, DOI 10.1016/j.jphysparis.2004.01.008
   Zhaoping L, 2014, UNDERSTANDING VISION, V0, P189
   Zhaoping L, 2015, PLOS COMPUT BIOL, V11, P0, DOI 10.1371/journal.pcbi.1004375
   Zhou H, 2000, J NEUROSCI, V20, P6594, DOI 10.1523/JNEUROSCI.20-17-06594.2000
NR 81
TC 4
Z9 4
U1 1
U2 12
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 
EI 2373-2822
J9 ENEURO
JI eNeuro
PD JAN-FEB 15
PY 2021
VL 8
IS 1
BP 
EP 
DI 10.1523/ENEURO.0200-20.2020
PG 68
WC Neurosciences
SC Neurosciences & Neurology
GA UK2DH
UT WOS:000691785000002
PM 33234544
DA 2023-04-26
ER

PT J
AU Zhang, S
   Li, C
   Peng, JY
   Peng, DL
   Xu, Q
   Zhang, Q
   Bate, B
AF Zhang, Shuai
   Li, Can
   Peng, Jingyu
   Peng, Dalei
   Xu, Qiang
   Zhang, Qun
   Bate, Bate
TI GIS-based soil planar slide susceptibility mapping using logistic regression and neural networks: a typical red mudstone area in southwest China
SO GEOMATICS NATURAL HAZARDS & RISK
LA English
DT Article
DE Soil landslides; slope stability; spatial susceptibility; logistic regression model; artificial neural network
AB Global warming increases the frequency and intensity of extreme rainfall, putting many areas at risk of landslides. Landslide susceptibility assessment is essential to understand the threats and to predict, prevent, and mitigate landslides. In this study, a soil landslide inventory was constructed based on satellite images, topological maps, and extensive field studies. Subsequently, eight different GIS layers, which were geomorphology, elevation, slope angle, slope aspect, slope structure, slope curvature, antecedent rainfall, and cumulative rainfall on 16 September, were produced as control factors of soil planar slides for the susceptibility mapping. Landslide susceptibility mapping was performed using two different methods, logistic regression model and backpropagation (BP) neural network. Landslide susceptibility in the study area is divided into four levels, which are high, moderate, low, and no susceptibility in both the logistic regression model and the BP neural network model. In both the two models, most of the observed soil planar slides were located in areas with high or moderate susceptibility. For the logistic regression model, total 605 soil planar slides locate in the area with high susceptibility, of which the area is 800.56 km(2), accounting for 40.31% of the total area. Finally, the validation of two models was evaluated. The AUC value of the logistic regression model was 0.878 and the parameters of BP neural network has the correlation coefficient of 0.880, which shows the two models are both reliable and reasonable for predicting the spatial susceptibility of soil planar slides. According to field checks, the BP neural network model is verified to have more accurate spatial prediction performance than the logistic regression model.
C1 [Zhang, Shuai; Li, Can; Peng, Jingyu; Bate, Bate] Zhejiang Univ, MOE Key Lab Soft Soils & Geoenvironm Engn, Hangzhou, Peoples R China.
   [Peng, Dalei; Xu, Qiang] Chengdu Univ Technol, State Key Lab Geohazard Prevent & Geoenvironm Pro, Chengdu, Peoples R China.
   [Zhang, Qun] Geoenvironm Monitoring Stn Sichuan Prov, Chengdu, Peoples R China.
   [Peng, Dalei] Technol & Higher Educ Inst Hong Kong, Fac Sci & Technol, Hong Kong, Peoples R China.
C3 Zhejiang University; Chengdu University of Technology
RP Bate, B (corresponding author), Zhejiang Univ, MOE Key Lab Soft Soils & Geoenvironm Engn, Hangzhou, Peoples R China.
EM batebate@zju.edu.cn
FU Youth Program of National Natural Science Foundation of China [41907243]; Key Program of National Natural Science Foundation of China [41630640]; Science Fund for Creative Research Groups of the National Natural Science Foundation of China [41521002]
CR Akgun A, 2012, LANDSLIDES, V9, P93, DOI 10.1007/s10346-011-0283-7
   ANIYA M, 1985, ANN ASSOC AM GEOGR, V75, P102, DOI 10.1111/j.1467-8306.1985.tb00061.x
   Atkinson PM, 1998, COMPUT GEOSCI-UK, V24, P373, DOI 10.1016/S0098-3004(97)00117-9
   Ayalew L, 2005, GEOMORPHOLOGY, V65, P15, DOI 10.1016/j.geomorph.2004.06.010
   Ayalew L, 2004, LANDSLIDES, V1, P73, DOI 10.1007/s10346-003-0006-9
   Bai SB, 2010, GEOMORPHOLOGY, V115, P23, DOI 10.1016/j.geomorph.2009.09.025
   Balteanu D, 2020, GEOMORPHOLOGY, V371, P0, DOI 10.1016/j.geomorph.2020.107432
   Basak Debasish, 2007, NEURAL INFORM PROCES, V11, P203, DOI 10.1007/978-1-4302-5990-9_4
   Pham BT, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-017-6689-3
   Blahut J, 2010, GEOMORPHOLOGY, V119, P36, DOI 10.1016/j.geomorph.2010.02.017
   Brabb EE, 1984, P 4 INT S LANDSLIDES, V1, P307
   Can T, 2005, GEOMORPHOLOGY, V72, P250, DOI 10.1016/j.geomorph.2005.05.011
   Cantarino I, 2019, LANDSLIDES, V16, P265, DOI 10.1007/s10346-018-1063-4
   Chen W, 2018, SCI TOTAL ENVIRON, V626, P1121, DOI 10.1016/j.scitotenv.2018.01.124
   Chu C-M., 2009, WORLD ACAD, V59, P479
   Chung CJF, 2003, NAT HAZARDS, V30, P451, DOI 10.1023/B:NHAZ.0000007172.62651.2b
   Cruden D.M., 1996, LANDSLIDES INVESTIGA, V0, P36
   Dahal RK, 2008, ENVIRON GEOL, V54, P311, DOI 10.1007/s00254-007-0818-3
   Bui DT, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5919-4
   Bui DT, 2012, MATH PROBL ENG, V2012, P0, DOI 10.1155/2012/974638
   Dou J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060638
   Dou J, 2015, TERR ATMOS OCEAN SCI, V26, P227, DOI 10.3319/TAO.2014.12.02.07(EOSI)
   Felicisimo A, 2013, LANDSLIDES, V10, P175, DOI 10.1007/s10346-012-0320-1
   Gigovic L, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8020079
   Guo QH, 2005, ECOL MODEL, V182, P75, DOI 10.1016/j.ecolmodel.2004.07.012
   Guzzetti F, 1999, GEOMORPHOLOGY, V31, P181, DOI 10.1016/S0169-555X(99)00078-1
   Hungr O, 2014, LANDSLIDES, V11, P167, DOI 10.1007/s10346-013-0436-y
   Jadda M, 2011, NAT HAZARDS, V57, P395, DOI 10.1007/s11069-010-9620-8
   Kamp U, 2008, GEOMORPHOLOGY, V101, P631, DOI 10.1016/j.geomorph.2008.03.003
   Kawabata D, 2009, GEOMORPHOLOGY, V113, P97, DOI 10.1016/j.geomorph.2009.06.006
   Le LT, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9132630
   Le LT, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9132714
   Lee S, 2001, INT GEOSCI REMOTE SE, V0, PP2364, DOI 10.1109/IGARSS.2001.978003
   Lee S, 2001, ENVIRON GEOL, V40, P1095, DOI 10.1007/s002540100310
   Lee S, 2006, ENVIRON GEOL, V50, P847, DOI 10.1007/s00254-006-0256-7
   Lee S, 2006, MATH GEOL, V38, P199, DOI 10.1007/s11004-005-9012-x
   [李秀珍 Li Xiuzhen], 2014, 工程地质学报 JOURNAL OF ENGINEERING GEOLOGY, V22, P272
   Lv YL, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10020635
   Menard S. W., 1995, APPL LOGISTIC REGRES, V0, P0
   Moller MF., 1993, DPB, V22, P0, DOI 10.7146/dpb.v22i464.6937
   Nawi NM, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 1, P152
   Nefeslioglu HA, 2010, MATH PROBL ENG, V2010, P0, DOI 10.1155/2010/901095
   Oh HJ, 2009, ENVIRON GEOL, V57, P641, DOI 10.1007/s00254-008-1342-9
   Ohlmacher GC, 2003, ENG GEOL, V69, P331, DOI 10.1016/S0013-7952(03)00069-3
   Poiraud A, 2014, GEOMORPHOLOGY, V216, P208, DOI 10.1016/j.geomorph.2014.04.001
   Pourghasemi HR, 2014, ARAB J GEOSCI, V7, P1857, DOI 10.1007/s12517-012-0825-x
   Pradhan B, 2013, COMPUT GEOSCI-UK, V51, P350, DOI 10.1016/j.cageo.2012.08.023
   Saito H, 2009, GEOMORPHOLOGY, V109, P108, DOI 10.1016/j.geomorph.2009.02.026
   Schuster R.J., 1978, 176 TRB NAT RES COUN, V0, P11
   Shariati M, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9245534
   Singh P, 2021, ENVIRON DEV SUSTAIN, V23, P5233, DOI 10.1007/s10668-020-00811-0
   Su C, 2015, NAT HAZARDS, V76, P1759, DOI 10.1007/s11069-014-1562-0
   Suzen ML, 2004, ENG GEOL, V71, P303, DOI 10.1016/S0013-7952(03)00143-1
   SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615
   Vakhshoori V, 2018, GEOMAT NAT HAZ RISK, V9, P249, DOI 10.1080/19475705.2018.1424043
   den Eeckhaut M, 2006, GEOMORPHOLOGY, V76, P392, DOI 10.1016/j.geomorph.2005.12.003
   vanWesten CJ, 1997, GEOL RUNDSCH, V86, P404, DOI 10.1007/s005310050149
   Wang D., 2013, J MT SCI-ENGL, V31, P101
   Wang F, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6060172
   Wang QQ, 2015, J EARTH SYST SCI, V124, P1399, DOI 10.1007/s12040-015-0624-3
   Wooten MR., 2006, GEOLOGICAL SOC AM AB, V38, P28
   Wu YL, 2020, CATENA, V187, P0, DOI 10.1016/j.catena.2019.104396
   Xu C, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5576-7
   Xu Q, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4773-0
   Yalcin A, 2008, CATENA, V72, P1, DOI 10.1016/j.catena.2007.01.003
   Yao X., 2006, IAEG2006, V793, P1
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Yilmaz I, 2007, ENG GEOL, V90, P89, DOI 10.1016/j.enggeo.2006.12.004
   Yilmaz I, 2009, COMPUT GEOSCI-UK, V35, P1125, DOI 10.1016/j.cageo.2008.08.007
   Zeng-Wang X.U., 2001, J GEOGR SCI, V11, P374, DOI 10.1007/BF02892323
   Zhang M, 2015, LANDSLIDES, V12, P973, DOI 10.1007/s10346-015-0611-4
   [张群 Zhang Qun], 2014, 水文地质工程地质 HYDROGEOLOGY & ENGINEERING GEOLOGY, V41, P90
   Zhang S, 2017, GEOMORPHOLOGY, V276, P86, DOI 10.1016/j.geomorph.2016.10.009
   Zhang S, 2012, NAT HAZARD EARTH SYS, V12, P1381, DOI 10.5194/nhess-12-1381-2012
   Zhang S., 2016, SCI REPORT, V0, P0
   Zhang S, 2017, ENG GEOL, V217, P1, DOI 10.1016/j.enggeo.2016.11.025
   Zhang S, 2016, ENG GEOL, V204, P1, DOI 10.1016/j.enggeo.2016.01.013
NR 77
TC 4
Z9 5
U1 7
U2 38
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1947-5705
EI 1947-5713
J9 GEOMAT NAT HAZ RISK
JI Geomat. Nat. Hazards Risk
PD JAN 1
PY 2021
VL 12
IS 1
BP 852
EP 879
DI 10.1080/19475705.2021.1896584
PG 28
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources
SC Geology; Meteorology & Atmospheric Sciences; Water Resources
GA RB1IN
UT WOS:000631870100001
DA 2023-04-26
ER

PT J
AU Marchesi, G
   Eichhorn, C
   Plecher, DA
   Itoh, Y
   Klinker, G
AF Marchesi, Giulia
   Eichhorn, Christian
   Plecher, David A.
   Itoh, Yuta
   Klinker, Gudrun
TI EnvSLAM: Combining SLAM Systems and Neural Networks to Improve the Environment Fusion in AR Applications
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE SLAM; semantic segmentation; Semantic SLAM; GPS; Augmented Reality; machine learning; AR games; robotics; autonomous driving
ID tracking
AB Augmented Reality (AR) has increasingly benefited from the use of Simultaneous Localization and Mapping (SLAM) systems. This technology has enabled developers to create AR markerless applications, but lack semantic understanding of their environment. The inclusion of this information would empower AR applications to better react to the surroundings more realistically. To gain semantic knowledge, in recent years, focus has shifted toward fusing SLAM systems with neural networks, giving birth to the field of Semantic SLAM. Building on existing research, this paper aimed to create a SLAM system that generates a 3D map using ORB-SLAM2 and enriches it with semantic knowledge originated from the Fast-SCNN network. The key novelty of our approach is a new method for improving the predictions of neural networks, employed to balance the loss of accuracy introduced by efficient real-time models. Exploiting sensor information provided by a smartphone, GPS coordinates are utilized to query the OpenStreetMap database. The returned information is used to understand which classes are currently absent in the environment, so that they can be removed from the network's prediction with the goal of improving its accuracy. We achieved 87.40% Pixel Accuracy with Fast-SCNN on our custom version of COCO-Stuff and showed an improvement by involving GPS data for our self-made smartphone dataset resulting in 90.24% Pixel Accuracy. Having in mind the use on smartphones, the implementation aimed to find a trade-off between accuracy and efficiency, making the system achieve an unprecedented speed. To this end, the system was carefully designed and a strong focus on lightweight neural networks is also fundamental. This enabled the creation of an above real-time Semantic SLAM system that we called EnvSLAM (Environment SLAM). Our extensive evaluation reveals the efficiency of the system features and the operability in above real-time (48.1 frames per second with an input image resolution of 640 x 360 pixels). Moreover, the GPS integration indicates an effective improvement of the network's prediction accuracy.
C1 [Marchesi, Giulia; Eichhorn, Christian; Plecher, David A.; Klinker, Gudrun] Tech Univ Munich, Fac Comp Sci, D-85748 Garching, Germany.
   [Itoh, Yuta] Tokyo Inst Technol, Yokohama, Kanagawa 2260026, Japan.
C3 Technical University of Munich; Tokyo Institute of Technology
RP Eichhorn, C (corresponding author), Tech Univ Munich, Fac Comp Sci, D-85748 Garching, Germany.
EM giulia.marchesi@tum.de; christian.eichhorn@tum.de; plecher@in.tum.de; yuta.itoh@c.titech.ac.jp; klinker@in.tum.de
CR Ardeshir S, 2015, PROC CVPR IEEE, V0, PP2792, DOI 10.1109/CVPR.2015.7298896
   Ardeshir S, 2014, LECT NOTES COMPUT SC, V8694, P602, DOI 10.1007/978-3-319-10599-4_39
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bao SY, 2012, PROC CVPR IEEE, V0, PP2703, DOI 10.1109/CVPR.2012.6247992
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Caesar H, 2018, PROC CVPR IEEE, V0, PP1209, DOI 10.1109/CVPR.2018.00132
   Cavallari T., 2017, SEMANTIC SLAM NEW PA, V0, P0
   Chao P, 2019, IEEE I CONF COMP VIS, V0, PP3551, DOI 10.1109/ICCV.2019.00365
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Costante G, 2016, IEEE ROBOT AUTOM LET, V1, P18, DOI 10.1109/LRA.2015.2505717
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   DeTone D., 2017, ARXIV170707410, V0, P0
   Eichhorn C, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), V0, PP24, DOI 10.1109/ISMAR-Adjunct51615.2020.00022
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335
   Frese U, 2010, KUNSTL INTELL, V24, P191, DOI 10.1007/s13218-010-0040-4
   Hachiuma Ryo, 2019, BMVC, V0, P0
   Han SY, 2016, IEEE ICC, V0, P0, DOI DOI 10.1109/ICC.2016.7511104
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Hosseinyalamdary S, 2015, ISPRS INT J GEO-INF, V4, P1301, DOI 10.3390/ijgi4031301
   Howard A, 2019, IEEE I CONF COMP VIS, V0, PP1314, DOI 10.1109/ICCV.2019.00140
   Hubara I, 2016, ADV NEUR IN, V29, P0
   Kiss-Illes D, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19224973
   Klein George, 2007, P1, V0, P0
   Li B, 2018, INT CONF DAT MIN WOR, V0, PP1233, DOI 10.1109/ICDMW.2018.00176
   Li H., 2017, PROC INT C LEARN REP, V0, P1
   Li RH, 2018, COGN COMPUT, V10, P875, DOI 10.1007/s12559-018-9591-8
   LI X, 2016, ARXIV161104144, V0, P0
   Li X, 2019, PROC CVPR IEEE, V0, PP9137, DOI 10.1109/CVPR.2019.00936
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   McCormac John, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), V0, PP4628, DOI 10.1109/ICRA.2017.7989538
   McCormac J, 2018, INT CONF 3D VISION, V0, PP32, DOI 10.1109/3DV.2018.00015
   Meingast M., 2009, P OMN VIS CAM NETW N, V0, P0
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nakajima Y, 2018, IEEE INT C INT ROBOT, V0, PP385, DOI 10.1109/IROS.2018.8593993
   Newcombe RA, 2011, IEEE I CONF COMP VIS, V0, PP2320, DOI 10.1109/ICCV.2011.6126513
   Oufqir Zainab, 2020, EMBEDDED SYSTEMS AND ARTIFICIAL INTELLIGENCE. PROCEEDINGS OF ESAI 2019. ADVANCES IN INTELLIGENT SYSTEMS AND COMPUTING (AISC 1076), V0, PP599, DOI 10.1007/978-981-15-0947-6_57
   Plecher DA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), V0, PP1618, DOI 10.1109/VR.2019.8797846
   Poudel R., 2018, ARXIV180504554, V0, P0
   Poudel R. P. K., 2019, ARXIV190204502, V0, P0
   Poulose A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19235084
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reitmayr G., 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON UBIQUITOUS VIRTUAL REALITY (ISUVR 2010), V0, PP5, DOI 10.1109/ISUVR.2010.12
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosinol A., 2020, ARXIV200206289, V0, P0
   Runz M, 2018, INT SYM MIX AUGMENT, V0, PP10, DOI 10.1109/ISMAR.2018.00024
   Saffar M.H., 2018, ARXIV180606172, V0, P0
   Salas-Moreno RF, 2013, PROC CVPR IEEE, V0, PP1352, DOI 10.1109/CVPR.2013.178
   Shrivastava A, 2016, PROC CVPR IEEE, V0, PP761, DOI 10.1109/CVPR.2016.89
   Siam M, 2018, IEEE IMAGE PROC, V0, PP1603, DOI 10.1109/ICIP.2018.8451495
   Siltanen S., 2012, THESIS AALTO U ESPOO, V0, P0
   Tateno K, 2017, PROC CVPR IEEE, V0, PP6565, DOI 10.1109/CVPR.2017.695
   Tateno K, 2015, IEEE INT C INT ROBOT, V0, PP4465, DOI 10.1109/IROS.2015.7354011
   Ulku I., 2020, ARXIV191210230, V0, P0
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Wang Y, 2019, IEEE IMAGE PROC, V0, PP1860, DOI 10.1109/ICIP.2019.8803154
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), V0, P0, DOI DOI 10.1109/CISS.2018.8362280
   Xu JG, 2020, IEEE INFOCOM SER, V0, PP1828, DOI 10.1109/INFOCOM41043.2020.9155438
   Younes G., 2018, ARXIV160700470V1, V0, P0
   Younes G, 2017, ROBOT AUTON SYST, V98, P67, DOI 10.1016/j.robot.2017.09.010
   Yu C, 2018, IEEE INT C INT ROBOT, V0, PP1168, DOI 10.1109/IROS.2018.8593691
   Yun DS, 2014, I C INF COMM TECH CO, V0, PP609, DOI 10.1109/ICTC.2014.6983225
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhao Z., 2019, P 2019 2 CHIN S COGN, V0, PP149, DOI 10.1109/CCHI.2019.8901910
   Zhong FW, 2018, IEEE WINT CONF APPL, V0, PP1001, DOI 10.1109/WACV.2018.00115
NR 71
TC 3
Z9 3
U1 3
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD NOV 15
PY 2021
VL 10
IS 11
BP 
EP 
DI 10.3390/ijgi10110772
PG 21
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA XG5RB
UT WOS:000724808900001
DA 2023-04-26
ER

PT J
AU Bjanes, A
   de la Fuente, R
   Mena, P
AF Bjanes, Alexandra
   de la Fuente, Rodrigo
   Mena, Pablo
TI A deep learning ensemble model for wildfire susceptibility mapping
SO ECOLOGICAL INFORMATICS
LA English
DT Article
DE Wildfire susceptibility; Convolutional neural network; Geographical information systems; Forestry; Satellite imagery
ID neural-network; fire; danger
AB Devastating wildfires have increased in frequency and intensity over the last few years, worsened by climate change and prolonged droughts. Wildfire susceptibility mapping with machine learning has been proven useful for fire-prevention plans, turning into an indispensable tool in wildfire prevention. However, applications of deep learning models in wildfire susceptibility prediction to date are scarce. This study proposes a new Ensemble model based on two deep learning networks previously presented in literature that achieved remarkable results for forest fire susceptibility and other environmental risks. We compare our model with each of its sub-models, two more deep learning networks, and other machine learning benchmark, namely, XGBoost and SVM. Furthermore, we analyze the effects that different sample patch sizes have on the predictive performance of the algorithms. As case study we selected the fire occurrences in two regions in Chile, from 2013 to 2019. Satellite imagery data for fifteen fire influencing factors in the study area were retrieved to build a dataset to extract the samples to train the models. These factors include elevation, aspect, surface roughness, slope, minimum and maximum temperature, wind speed, precipitation, actual evapotranspiration, climatic water deficit, NDVI, land cover type, distance to rivers, distance to roads and distance to urban areas. During training, the best sample patch size was found to be 25 x 25 pixels. As a result, the highest area under the curve (AUC) was 0.953 achieved by the Ensemble model, followed by CNN-1 with AUC = 0.902. The Ensemble model also achieved the best accuracy, sensitivity, specificity, negative predictive value and F1 score. Finally, the predicted susceptibility maps suggest that static variables can be considered as predisposing factors, while dynamic variables affect the intensity of the predicted probabilities, with an important role of the anthropogenic variables. These resulting maps may be useful to prioritize wildfire surveillance and monitoring in extensive high risk areas.
C1 [Bjanes, Alexandra; de la Fuente, Rodrigo] Univ Concepcion, Victor Lamas 1290, Concepcion 4030000, Chile.
   [Mena, Pablo] Invest Forest Bioforest SA, Camino Coronel,Km 15, Concepcion 4030000, Chile.
C3 Universidad de Concepcion
RP de la Fuente, R (corresponding author), Univ Concepcion, Victor Lamas 1290, Concepcion 4030000, Chile.
EM abjanes@udec.cl; rodelafuente@udec.cl; pablo.mena@arauco.com
CR Abatzoglou JT, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2017.191
   Adab H, 2017, NAT HAZARDS, V87, P1807, DOI 10.1007/s11069-017-2850-2
   [Anonymous], 2018, WILDFIRE CONTRIBUTIO, V0, P0
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Artes TS, 2019, SCI DATA, V6, P0, DOI 10.1038/s41597-019-0312-2
   Bajocco S, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0119811
   Barbosa A, 2020, COMPUT ELECTRON AGR, V170, P0, DOI 10.1016/j.compag.2019.105197
   Barros AMG, 2017, ECOL SOC, V22, P0, DOI 10.5751/ES-08917-220124
   Benson RP, 2009, DEV ENVIRONM SCI, V8, P37, DOI 10.1016/S1474-8177(08)00002-8
   Carranza-Garcia M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030274
   CONAF, 2020, INCENDIOS FORESTALES, V0, P0
   CONAF, 2019, EST HIST, V0, P0
   Dacre HF, 2018, B AM METEOROL SOC, V99, P2259, DOI 10.1175/BAMS-D-17-0111.1
   Davis R, 2017, FOREST ECOL MANAG, V390, P173, DOI 10.1016/j.foreco.2017.01.027
   De Rigo D., 2017, JRC TECHNICAL REPORT, V0, P0
   Didan K., 2015, MOD13A1 MODIS TERRA, V0, P0, DOI DOI 10.5067/MODIS/MOD13A1.006
   Eskandari S, 2021, ENVIRON SCI POLLUT R, V28, P47395, DOI 10.1007/s11356-021-13881-y
   Friedl M., 2019, MCD12Q1 MODISTERRA A, V0, P0, DOI DOI 10.5067/MODIS/MCD12Q1.006
   Friedman J., 2016, ELEMENTS STAT LEARNI, V1, P0
   Ghorbanzadeh O, 2019, FIRE-BASEL, V2, P0, DOI 10.3390/fire2030050
   Ghorbanzadeh O, 2019, FIRE-BASEL, V2, P0, DOI 10.3390/fire2030043
   Gigovic L, 2019, FORESTS, V10, P0, DOI 10.3390/f10050408
   Goldarag YJ, 2016, J INDIAN SOC REMOTE, V44, P885, DOI 10.1007/s12524-016-0557-6
   Gomes M.d.M., 2021, ARXIVARXIV10111669V3, V15, P0, DOI 10.5772/intechopen.82948
   Gonzalez M., 2020, INCENDIOS CHILE CAUS, V0, P0
   Gonzalez ME, 2018, ECOSPHERE, V9, P0, DOI 10.1002/ecs2.2300
   Gonzalez-Caban A., 2013, EC DIMENSION WILDLAN, V0, P229
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gray CA, 2017, FOREST ECOL MANAG, V392, P125, DOI 10.1016/j.foreco.2017.03.004
   Guo FT, 2016, FORESTS, V7, P0, DOI 10.3390/f7110250
   He Q, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13081572
   Le HV, 2021, ECOL INFORM, V63, P0, DOI 10.1016/j.ecoinf.2021.101300
   Jain P, 2020, ENVIRON REV, V28, P478, DOI 10.1139/er-2020-0019
   Justino F, 2021, ENVIRON RES LETT, V16, P0, DOI 10.1088/1748-9326/abf0d0
   Kim SJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010086
   Koch GR, 2015, SIAMESE NEURAL NETWO, V0, P0
   Lelieveld J, 2015, NATURE, V525, P367, DOI 10.1038/nature15371
   Leuenberger M, 2018, ENVIRON MODELL SOFTW, V101, P194, DOI 10.1016/j.envsoft.2017.12.019
   Li S, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-88131-9
   Mann M., 2014, AGU FALL M ABSTR, V0, P0
   Martin Y, 2019, GEOMAT NAT HAZ RISK, V10, P385, DOI 10.1080/19475705.2018.1526219
   Mercurio E., 2017, CRONOLOGIA CATASTROF, V0, P0
   Mohajane M, 2021, ECOL INDIC, V129, P0, DOI 10.1016/j.ecolind.2021.107869
   Mpakairi KS, 2019, S AFR GEOGR J, V101, P110, DOI 10.1080/03736245.2018.1541023
   NASA/METI/AIST/Japan Spacesystems a. U. S. J. A. S. T., 2019, ASTER GLOBAL DIGITAL, V0, P0
   National Parks Service, 2018, WILDF CAUS EV, V0, P0
   Nguyen NT, 2018, ECOL INFORM, V46, P74, DOI 10.1016/j.ecoinf.2018.05.009
   Ozbayoglu AM, 2020, APPL SOFT COMPUT, V93, P0, DOI 10.1016/j.asoc.2020.106384
   Pourghasemi HR, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-60191-3
   QGIS.org, 2020, ORG QGIS GEOGR INF S, V0, P0
   Sachdeva S, 2018, NAT HAZARDS, V92, P1399, DOI 10.1007/s11069-018-3256-5
   Sanchez MB, 2021, GEOSCIENCES, V11, P0, DOI 10.3390/geosciences11050224
   Satir O, 2016, GEOMAT NAT HAZ RISK, V7, P1645, DOI 10.1080/19475705.2015.1084541
   Saxe A, 2021, NAT REV NEUROSCI, V22, P55, DOI 10.1038/s41583-020-00395-8
   Shorten C, 2021, J BIG DATA-GER, V8, P0, DOI 10.1186/s40537-020-00392-9
   Sun Y, 2017, J ELECTR COMPUT ENG, V2017, P0, DOI 10.1155/2017/9240407
   Tonini M, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10030105
   Urrutia-Jalabert R, 2018, ECOSPHERE, V9, P0, DOI 10.1002/ecs2.2171
   Vacchiano G, 2018, NAT HAZARD EARTH SYS, V18, P935, DOI 10.5194/nhess-18-935-2018
   Valdez MC, 2017, GEOMAT NAT HAZ RISK, V8, P876, DOI 10.1080/19475705.2016.1278404
   van der Werf GR, 2017, EARTH SYST SCI DATA, V9, P697, DOI 10.5194/essd-9-697-2017
   Vilar L, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0161344
   Villagra P, 2021, ENVIRONMENT, V63, P4, DOI 10.1080/00139157.2021.1898891
   Wang DP, 2021, NAT SUSTAIN, V4, P252, DOI 10.1038/s41893-020-00646-7
   Wang W., 2020, DEEP LEARNING HEALTH, V0, PP33, DOI 10.1007/978-3-030-32606-7_3
   Xu RB, 2020, NEW ENGL J MED, V383, P2173, DOI 10.1056/NEJMsr2028985
   Yousefi S, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-69233-2
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zema DA, 2020, COMPUT ELECTRON AGR, V170, P0, DOI 10.1016/j.compag.2020.105280
   Zhang GL, 2021, ECOL INDIC, V127, P0, DOI 10.1016/j.ecolind.2021.107735
   Zhang GL, 2019, INT J DISAST RISK SC, V10, P386, DOI 10.1007/s13753-019-00233-1
NR 72
TC 14
Z9 14
U1 5
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-9541
EI 1878-0512
J9 ECOL INFORM
JI Ecol. Inform.
PD NOV 15
PY 2021
VL 65
IS 
BP 
EP 
DI 10.1016/j.ecoinf.2021.101397
EA AUG 2021
PG 15
WC Ecology
SC Environmental Sciences & Ecology
GA WB7RN
UT WOS:000703766700001
DA 2023-04-26
ER

PT J
AU Liang, Z
   Wang, CM
   Duan, ZJ
   Liu, HL
   Liu, XY
   Khan, KUJ
AF Liang, Zhu
   Wang, Changming
   Duan, Zhijie
   Liu, Hailiang
   Liu, Xiaoyang
   Ullah Jan Khan, Kaleem
TI A Hybrid Model Consisting of Supervised and Unsupervised Learning for Landslide Susceptibility Mapping
SO REMOTE SENSING
LA English
DT Article
DE landslide susceptibility; unsupervised machine learning; supervised machine learning; hybrid model; geographic information system
ID principal component analysis; debris flow susceptibility; logistic-regression; spatial prediction; neural-networks; decision tree; random forest; machine; china; area
AB Landslides cause huge damage to social economy and human beings every year. Landslide susceptibility mapping (LSM) occupies an important position in land use and risk management. This study is to investigate a hybrid model which makes full use of the advantage of supervised learning model (SLM) and unsupervised learning model (ULM). Firstly, ten continuous variables were used to develop a ULM which consisted of factor analysis (FA) and k-means cluster for a preliminary landslide susceptibility map. Secondly, 351 landslides with "1" label were collected and the same number of non-landslide samples with "0" label were selected from the very low susceptibility area in the preliminary map, constituting a new priori condition for a SLM, and thirteen factors were used for the modeling of gradient boosting decision tree (GBDT) which represented for SLM. Finally, the performance of different models was verified using related indexes. The results showed that the performance of the pretreated GBDT model was improved with sensitivity, specificity, accuracy and the area under the curve (AUC) values of 88.60%, 92.59%, 90.60% and 0.976, respectively. It can be concluded that a pretreated model with strong robustness can be constructed by increasing the purity of samples.
C1 [Liang, Zhu; Wang, Changming; Liu, Hailiang; Liu, Xiaoyang; Ullah Jan Khan, Kaleem] Jilin Univ, Coll Construct Engn, Changchun 130012, Peoples R China.
   [Duan, Zhijie] Tsinghua Univ, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.
C3 Jilin University; Tsinghua University
RP Wang, CM (corresponding author), Jilin Univ, Coll Construct Engn, Changchun 130012, Peoples R China.
EM liangzhu19@mails.jlu.edu.cn; wangcm@jlu.edu.cn; duanzj17@mails.tsinghua.edu.cn; hailiang19@mails.jlu.edu.cn; liuxiaoy19@mails.jlu.edu.cn; Khan2417@mails.jlu.edu.cn
FU Graduate Innovation Fund of Jilin University [101832020CX232]; National Natural Science Foundation of China [41972267, 41977221, 41572257]
CR Ali S, 2019, NAT HAZARD EARTH SYS, V19, P999, DOI 10.5194/nhess-19-999-2019
   Pham BT, 2019, B ENG GEOL ENVIRON, V78, P1911, DOI 10.1007/s10064-017-1202-5
   Pham BT, 2017, CATENA, V149, P52, DOI 10.1016/j.catena.2016.09.007
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Can A, 2019, B ENG GEOL ENVIRON, V78, P89, DOI 10.1007/s10064-017-1034-3
   Catani F, 2013, NAT HAZARD EARTH SYS, V13, P2815, DOI 10.5194/nhess-13-2815-2013
   Chang ZL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030502
   Chen W, 2018, SCI TOTAL ENVIRON, V626, P1121, DOI 10.1016/j.scitotenv.2018.01.124
   Choubin B, 2019, SCI TOTAL ENVIRON, V651, P2087, DOI 10.1016/j.scitotenv.2018.10.064
   Chung CJF, 2003, NAT HAZARDS, V30, P451, DOI 10.1023/B:NHAZ.0000007172.62651.2b
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Bui DT, 2012, GEOMORPHOLOGY, V171, P12, DOI 10.1016/j.geomorph.2012.04.023
   Ding C., 2004, SKK, V0, P0
   Dou J, 2019, NAT HAZARDS, V97, P579, DOI 10.1007/s11069-019-03659-4
   Dou J, 2019, SCI TOTAL ENVIRON, V662, P332, DOI 10.1016/j.scitotenv.2019.01.221
   Erener A, 2017, COMPUT GEOSCI-UK, V104, P62, DOI 10.1016/j.cageo.2017.03.022
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Guzzetti F, 2006, NAT HAZARD EARTH SYS, V6, P115, DOI 10.5194/nhess-6-115-2006
   Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007
   Haque U, 2019, SCI TOTAL ENVIRON, V682, P673, DOI 10.1016/j.scitotenv.2019.03.415
   Hong HY, 2016, GEOMORPHOLOGY, V259, P105, DOI 10.1016/j.geomorph.2016.02.012
   Hong HY, 2015, CATENA, V133, P266, DOI 10.1016/j.catena.2015.05.019
   Huang FM, 2020, CATENA, V191, P0, DOI 10.1016/j.catena.2020.104580
   Jaafari A, 2015, LAND USE POLICY, V47, P198, DOI 10.1016/j.landusepol.2015.04.010
   James G, 2013, SPRINGER TEXTS STAT, V103, P303, DOI 10.1007/978-1-4614-7138-7_8
   Jiang SH, 2020, ENG GEOL, V271, P0, DOI 10.1016/j.enggeo.2020.105597
   Karimi V, 2020, WATER RESOUR MANAG, V34, P2389, DOI 10.1007/s11269-020-02555-y
   Kornejady A, 2017, CATENA, V152, P144, DOI 10.1016/j.catena.2017.01.010
   Levada ALM, 2020, PATTERN RECOGN LETT, V135, P425, DOI 10.1016/j.patrec.2020.05.011
   Liang Z, 2021, STOCH ENV RES RISK A, V35, P1243, DOI 10.1007/s00477-020-01893-y
   Liang Z, 2020, STOCH ENV RES RISK A, V34, P1887, DOI 10.1007/s00477-020-01851-8
   Liang Z, 2020, NAT HAZARD EARTH SYS, V20, P1287, DOI 10.5194/nhess-20-1287-2020
   Liu C, 2013, NAT HAZARDS, V69, P1477, DOI 10.1007/s11069-013-0759-y
   Merghadi A, 2020, EARTH-SCI REV, V207, P0, DOI 10.1016/j.earscirev.2020.103225
   Merghadi A, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7070268
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Nasiri V, 2019, J FORESTRY RES, V30, P943, DOI 10.1007/s11676-018-0659-9
   Nedbal V, 2018, SCI TOTAL ENVIRON, V633, P658, DOI 10.1016/j.scitotenv.2018.03.220
   Omta WA, 2020, SLAS DISCOV, V25, P655, DOI 10.1177/2472555220919345
   Peng L, 2014, GEOMORPHOLOGY, V204, P287, DOI 10.1016/j.geomorph.2013.08.013
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Rossi M, 2019, EARTH-SCI REV, V196, P0, DOI 10.1016/j.earscirev.2019.04.021
   Sabokbar HF, 2014, GEOMORPHOLOGY, V226, P15, DOI 10.1016/j.geomorph.2014.07.026
   Sharma S, 2019, B ENG GEOL ENVIRON, V78, P2431, DOI 10.1007/s10064-018-1259-9
   Shi MY, 2016, B ENG GEOL ENVIRON, V75, P909, DOI 10.1007/s10064-015-0784-z
   Soeters R., 1996, SLOPE INSTABILITY RE, V0, P0
   Tang YM, 2020, J CLEAN PROD, V277, P0, DOI 10.1016/j.jclepro.2020.124159
   Trigila A, 2015, GEOMORPHOLOGY, V249, P119, DOI 10.1016/j.geomorph.2015.06.001
   Vahidnia MH, 2010, COMPUT GEOSCI-UK, V36, P1101, DOI 10.1016/j.cageo.2010.04.004
   Vasu NN, 2016, GEOMORPHOLOGY, V263, P50, DOI 10.1016/j.geomorph.2016.03.023
   Wang Q, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-016-2752-8
   Wang YM, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104425
   Wilson JP, 2000, TERRAIN ANAL PRINCIP, V0, P0
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Yi YN, 2019, NAT HAZARD EARTH SYS, V19, P1973, DOI 10.5194/nhess-19-1973-2019
   Zhu AX, 2018, CATENA, V171, P222, DOI 10.1016/j.catena.2018.07.012
NR 56
TC 14
Z9 14
U1 9
U2 52
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD APR 15
PY 2021
VL 13
IS 8
BP 
EP 
DI 10.3390/rs13081464
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT7YX
UT WOS:000644674500001
DA 2023-04-26
ER

PT J
AU Ibrahim, MR
   Haworth, J
   Cheng, T
AF Ibrahim, Mohamed R.
   Haworth, James
   Cheng, Tao
TI URBAN-i: From urban scenes to mapping slums, transport modes, and pedestrians in cities using deep learning and computer vision
SO ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE
LA English
DT Article
DE Computer vision; deep learning; convolutional neural networks; object-based detection; mapping slums; urban modelling; cities
ID networks; improve; size
AB In recent years, deep learning and computer vision have been applied to solve complex problems across many domains. In urban studies, these technologies have been instrumental in the development of smart cities and autonomous vehicles. However, a knowledge gap is present when it comes to informal urban regions in less developed countries. How can deep learning and artificial intelligence untangle the complexities of informality to advance urban modelling? In this paper, we introduce a framework for multipurpose realistic-dynamic urban modelling using deep convolutional neural networks. The purpose of the framework is twofold: (1) to sense and detect informality and slums in urban scenes from aerial and street-level images and (2) to detect pedestrian and transport modes. The model has been trained on images of urban scenes in cities across the globe. The framework shows strong validation performance in the identification of planned and unplanned regions, despite broad variations in the classified images. The algorithms of the URBAN-i model are coded in Python and the trained models can be applied to images of any urban setting, including informal settlements and slum regions.
C1 [Ibrahim, Mohamed R.; Haworth, James] Univ Coll London UCL, SpaceTimeLab, Dept Civil Environm & Geomat Engineer, London, England.
   [Cheng, Tao] Univ Coll London UCL, Geoinformat, London, England.
C3 University of London; University College London; University of London; University College London
RP Ibrahim, MR (corresponding author), Univ Coll London UCL, Dept Civil Environm & Geomat Engn, Room 1-02,Chadwick Bldg,Gower St, London WC1E 6BT, England.
EM mohamed.ibrahim.17@ucl.ac.uk
FU EPSRC [EP/J004197/1] Funding Source: UKRI
CR [Anonymous], 2015, LEARNING REPRESENTAT, V0, P0
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   [Anonymous], 2014, PROC IEEE C COMPUT V, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Batty M, 2005, ENVIRON PLANN A, V37, P1373, DOI 10.1068/a3784
   Batty M, 1996, ENVIRON PLANN A, V28, P1745, DOI 10.1068/a281745
   Batty M, 1997, J AM PLANN ASSOC, V63, P266, DOI 10.1080/01944369708975918
   Batty M, 1997, ENVIRON PLANN B, V24, P159
   Batty M., 1984, PSEUDO DYNAMIC URBAN, V0, P0
   Batty M., 2001, CYBERGEO, V0, P0, DOI DOI 10.4000/cybergeo.1035
   Batty M., 1994, FRACTAL CITIES GEOME, V0, P0
   Batty M, 2008, SCIENCE, V319, P769, DOI 10.1126/science.1151419
   Bettencourt L, 2010, NATURE, V467, P912, DOI 10.1038/467912a
   Bettencourt LMA, 2013, SCIENCE, V340, P1438, DOI 10.1126/science.1235823
   Brown E, 2017, PYTORCH IMPLEMENTATI, V0, P0
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Crandall D., 2009, P 18 INT C WORLD WID, V0, PP761, DOI 10.1145/1526709.1526812
   Dahl GE, 2013, INT CONF ACOUST SPEE, V0, PP8609, DOI 10.1109/ICASSP.2013.6639346
   de Almeida C. M., 2003, COMPUTERS, V0, P0
   Demir I, 2018, IEEE COMPUT SOC CONF, V0, PP172, DOI 10.1109/CVPRW.2018.00031
   Dubey A, 2016, LECT NOTES COMPUT SC, V9905, P196, DOI 10.1007/978-3-319-46448-0_12
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Frankhauser P., 1998, POPUL ENGL SEL, V0, P205
   Friesen J, 2018, HABITAT INT, V73, P79, DOI 10.1016/j.habitatint.2018.02.002
   Gallagher Andrew, 2009, 2009 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPR WORKSHOPS), V0, PP55, DOI 10.1109/CVPR.2009.5204168
   Gamba P., 2007, INT ARCH PHOTOGRAMME, V36, P0
   Glorot X., 2011, P 14 INT C ART INT S, V0, P315
   Garcia CG, 2017, FUTURE GENER COMP SY, V76, P301, DOI 10.1016/j.future.2016.12.033
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hays J., 2015, LARGE SCALE IMAGE GE, V0, PP41, DOI 10.1007/978-3-319-09861-6_3
   He K., 2015, PROC CVPR IEEE, V5, P6
   Heppenstall AJJ., 2012, AGENT BASED MODELS G, V164, P1, DOI 10.1007/978-90-481-8927-4
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Isalgue A, 2007, PHYSICA A, V382, P643, DOI 10.1016/j.physa.2007.04.019
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kuffer M, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7110428
   Kuffer M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060455
   LAW S, 2018, ARXIV180707155CSECON, V0, P0
   Li X, 2017, IEEE I CONF COMP VIS, V0, PP784, DOI 10.1109/ICCV.2017.91
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lynch K., 2008, IMAGE CITY, V33rd ed., P0
   Mahabir R, 2018, URBAN SCI, V2, P0, DOI 10.3390/urbansci2010008
   Mboga N, 2017, INT GEOSCI REMOTE SE, V0, P5169
   Murcio R, 2015, PHYS REV E, V92, P0, DOI 10.1103/PhysRevE.92.062130
   Naik N, 2017, P NATL ACAD SCI USA, V114, P7571, DOI 10.1073/pnas.1619003114
   Naik N, 2016, AM ECON REV, V106, P128, DOI 10.1257/aer.p20161030
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Peng C, 2017, PROC CVPR IEEE, V0, PP1743, DOI 10.1109/CVPR.2017.189
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), V0, PP1, DOI 10.1109/ICPHM.2017.7998297
   Quack T., 2008, P INT C CONT BAS IM, V0, PP47, DOI 10.1145/1386352.1386363
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salesses P, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0068400
   Sandler E., 2011, GET LAT LON EXIF PIL, V0, P0
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tarigan J, 2017, PROCEDIA COMPUT SCI, V116, P365, DOI 10.1016/j.procs.2017.10.068
   UN-Habitat, 2010, CHALL SLUMS GLOB REP, V0, P0
   Wang L, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18030769
   Yu F., 2015, 1511 ARXIV, V0, P0
   Zhou BL, 2014, LECT NOTES COMPUT SC, V8691, P519, DOI 10.1007/978-3-319-10578-9_34
NR 69
TC 13
Z9 13
U1 7
U2 27
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 2399-8083
EI 2399-8091
J9 ENVIRON PLAN B-URBAN
JI Env. Plan. B-Urban Anal. City Sci.
PD JAN 15
PY 2021
VL 48
IS 1
BP 76
EP 93
DI 10.1177/2399808319846517
PG 18
WC Environmental Studies; Geography; Regional & Urban Planning; Urban Studies
SC Environmental Sciences & Ecology; Geography; Public Administration; Urban Studies
GA PY6EO
UT WOS:000612136400006
DA 2023-04-26
ER

PT J
AU Neagoe, IC
   Coca, M
   Vaduva, C
   Datcu, M
AF Neagoe, Iulia Coca
   Coca, Mihai
   Vaduva, Corina
   Datcu, Mihai
TI Cross-Bands Information Transfer to Offset Ambiguities and Atmospheric Phenomena for Multispectral Data Visualization
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Data visualization; Visualization; Remote sensing; Image color analysis; Neural networks; Earth; Contamination; Autoencoder; data visualization; multispectral Earth Observation (EO) images; remote sensing
ID images; classification; illumination; enhancement; autoencoder; removal
AB Visualization of multispectral images through band selection methods determines an information loss that in utmost cases proves to be critical for the adequate understanding of the represented scene. The R-G-B representation obtained by mapping the visual bands to the R, G, and B channels is highly used due to its great resemblance with the natural color one and aspects perceivable by the human eye. However, despite the similarity in terms of color code, ambiguities between classes such as water and vegetation or atmospheric phenomena like fog, clouds, and smoke that have been penetrated by other bands, remain visible and hinder the process of visualization of the Earth surface. This article presents a set of five different methods to offset the effects caused by ambiguities, fog, light clouds, and smoke by transferring relevant information between bands in order to visually reconstitute those parts of the image affected by atmospheric phenomena. The general concept shared by these methods implies a stacked autoencoder that successfully encompasses the information from all spectral bands into a latent representation used for visualization. Each proposed method is defined by different combination of input and error function formula. Spectral and polar coordinates features represent the possible options for the input, while formulas based on mean squared error or angular spectral distances determine the potential choices in terms of error function definition. The property of angular spectral distance and polar coordinates transformation to obtain illuminant invariant features determined their use in three out of five methods. We evaluate the methods through spectral signature graphical comparison and visual comparison related to the R-G-B representation. We conduct experiments on multiple Sentinel 2 full images.
C1 [Neagoe, Iulia Coca; Coca, Mihai; Vaduva, Corina; Datcu, Mihai] Univ Politehn Bucuresti, Res Ctr Spatial Informat, Bucharest 061071, Romania.
   [Datcu, Mihai] German Aerosp Ctr, Remote Sensing Technol Inst, D-82234 Oberpfaffenhofen, Germany.
C3 Polytechnic University of Bucharest; Helmholtz Association; German Aerospace Centre (DLR)
RP Neagoe, IC (corresponding author), Univ Politehn Bucuresti, Res Ctr Spatial Informat, Bucharest 061071, Romania.
EM neagoe.iulia@yahoo.ro; coca.mihai5@gmail.com; na.vaduva@gmail.com; mihai.datcu@dlr.de
FU Romanian Ministry of Education and Research, CNCS - UEFISCDI, within PNCDI III [PN-III-P4ID-PCE-2020-2120]
CR Bratasanu D, 2012, IEEE J-STARS, V5, P207, DOI 10.1109/JSTARS.2011.2169772
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chaudhry H, 2018, MULTIMED TOOLS APPL, V77, P15485, DOI 10.1007/s11042-017-5126-7
   Ching-Hung Su, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRICAL AND CONTROL ENGINEERING, V0, PP5746, DOI 10.1109/ICECENG.2011.6058026
   Dey N., 2019, BIG DATA REMOTE SENS, V0, P0
   Gahegan M, 1999, INT J GEOGR INF SCI, V13, P289, DOI 10.1080/136588199241210
   GAHEGAN MN, 1996, P 3 INT C GIS ENV MO, V0, P0
   Georgescu FA, 2017, IEEE GEOSCI REMOTE S, V14, P987, DOI 10.1109/LGRS.2017.2656822
   Antunes MAH, 2018, INT GEOSCI REMOTE SE, V0, P9145
   Jacobson NP, 2005, IEEE T GEOSCI REMOTE, V43, P2684, DOI 10.1109/TGRS.2005.857623
   Kapoor R, 2019, MULTIMED TOOLS APPL, V78, P23281, DOI 10.1007/s11042-019-7574-8
   Koda S, 2020, IEEE GEOSCI REMOTE S, V17, P469, DOI 10.1109/LGRS.2019.2921225
   Kong TL, 2017, MULTIMED TOOLS APPL, V76, P14305, DOI 10.1007/s11042-016-3787-2
   Luotamo M, 2021, IEEE T GEOSCI REMOTE, V59, P4972, DOI 10.1109/TGRS.2020.3015272
   MacEachren A.M., 1990, CARTOGRAPHICA, V27, P64, DOI 10.3138/M226-1337-2387-3007
   Sotoca JM, 2007, IEEE T SYST MAN CY C, V37, P258, DOI 10.1109/TSMCC.2006.876055
   Marzano FS, 2021, IEEE T GEOSCI REMOTE, V59, P915, DOI 10.1109/TGRS.2020.2980941
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Neagoe I., 2021, P IEEE INT GEOSC REM, V0, P2102
   Neagoe I, 2018, INT GEOSCI REMOTE SE, V0, P2079
   Okamura T, 2003, OPT ENG, V42, P1665, DOI 10.1117/1.1569497
   Pan HZ, 2019, IEEE J-STARS, V12, P482, DOI 10.1109/JSTARS.2018.2855564
   Polder G, 2001, P SOC PHOTO-OPT INS, V4553, P132, DOI 10.1117/12.441578
   Qiu CP, 2020, IEEE GEOSCI REMOTE S, V17, P1787, DOI 10.1109/LGRS.2019.2953497
   Qiu CP, 2020, IEEE J-STARS, V13, P2793, DOI 10.1109/JSTARS.2020.2995711
   Rheingans P, 2002, IEEE COMPUT GRAPH, V22, P6, DOI 10.1109/38.974511
   Singh P, 2018, INT GEOSCI REMOTE SE, V0, P1772
   Sohn YS, 1999, PHOTOGRAMM ENG REM S, V65, P947
   Sovdat B, 2019, REMOTE SENS ENVIRON, V225, P392, DOI 10.1016/j.rse.2019.01.036
   Su HJ, 2014, IEEE J-STARS, V7, P2647, DOI 10.1109/JSTARS.2013.2272654
   Vincenzi S, 2021, INT C PATT RECOG, V0, PP3034, DOI 10.1109/ICPR48806.2021.9413112
   Wang CL, 2011, ENTROPY-SWITZ, V13, P254, DOI 10.3390/e13010254
   Wang J, 2012, PROCEDIA COMPUT SCI, V13, P120, DOI 10.1016/j.procs.2012.09.120
   Xi YBA, 2021, IEEE J-STARS, V14, P7589, DOI 10.1109/JSTARS.2021.3098817
   Yi Wan, 2015, 2015 VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP), V0, PP1, DOI 10.1109/VCIP.2015.7457892
   Zhang ML, 2017, SMART INNOV SYST TEC, V64, P19, DOI 10.1007/978-3-319-50212-0_3
   Zhou YM, 2021, IEEE J-STARS, V14, P4194, DOI 10.1109/JSTARS.2021.3071577
NR 37
TC 0
Z9 0
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11297
EP 11310
DI 10.1109/JSTARS.2021.3123120
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WY8YM
UT WOS:000719563200008
DA 2023-04-26
ER

PT J
AU Tao, JT
   Yuan, F
   Zhang, NN
   Chang, JY
AF Tao, Jintao
   Yuan, Feng
   Zhang, Nannan
   Chang, Jinyu
TI Three-Dimensional Prospectivity Modeling of Honghai Volcanogenic Massive Sulfide Cu-Zn Deposit, Eastern Tianshan, Northwestern China Using Weights of Evidence and Fuzzy Logic
SO MATHEMATICAL GEOSCIENCES
LA English
DT Article
DE 3D geological modeling; Weights of evidence; Fuzzy logic; Prospectivity modeling; Receiver operating characteristic (ROC); Honghai volcanogenic massive sulfide (VMS) Cu-Zn deposit
ID mapping mineral prospectivity; vms mineralization; metallogenic belt; kalatag district; spatial evidence; neural-networks; orogenic gold; random forest; mining area; systems
AB Three-dimensional (3D) prospectivity modeling based on the weights of evidence and fuzzy logic methods was carried out for the Honghai volcanogenic massive sulfide Cu-Zn deposit in eastern Tianshan, northwestern China. A 3D geological model was constructed using geological maps, geological plans, cross sections, and boreholes. The geological model and metallogenic model of the Honghai deposit were used to generate 3D predictor maps. The weights of evidence method and fuzzy logic were then used to integrate the various predictor maps to create prospectivity maps. Capture efficiency curves were subsequently used to delineate high-prospectivity areas in the prospectivity maps. The weights of evidence method and fuzzy logic delineated 96.13% and 90.60%, respectively, of the known mineralization in the high-prospectivity areas, which occupied about 5.89% and 6.33% of the study area. Receiver operating characteristic (ROC) curves were used to evaluate the performance of the two methods, with both showing area under the curve values > 0.5, which indicates the effectiveness of both methods for 3D prospectivity modeling of the Honghai deposit. However, the weights of evidence method generally performed better than fuzzy logic for identification of the concealed and deep-seated Honghai deposit. Conversely, fuzzy logic exhibited better generalization capability. Based on the findings of this study, the high-prospectivity areas located in the south of the known orebody of the Honghai deposit should be considered as high-priority targets for future mineral exploration. This study aims to enable more effective delineation of concealed and deep-seated exploration targets in the Honghai deposit.
C1 [Tao, Jintao; Zhang, Nannan; Chang, Jinyu] Chinese Acad Sci, Xinjiang Inst Ecol & Geog, State Key Lab Desert & Oasis Ecol, Urumqi 830011, Peoples R China.
   [Tao, Jintao; Yuan, Feng; Zhang, Nannan; Chang, Jinyu] Xinjiang Key Lab Mineral Resources & Digital Geol, Urumqi 830011, Peoples R China.
   [Tao, Jintao; Zhang, Nannan; Chang, Jinyu] Chinese Acad Sci, Xinjiang Res Ctr Mineral Resources, Urumqi 830011, Peoples R China.
   [Tao, Jintao; Zhang, Nannan; Chang, Jinyu] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Yuan, Feng] Hefei Univ Technol, Sch Resources & Environm Engn, Hefei 230009, Peoples R China.
C3 Chinese Academy of Sciences; Xinjiang Institute of Ecology & Geography, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Hefei University of Technology
RP Zhang, NN (corresponding author), Chinese Acad Sci, Xinjiang Inst Ecol & Geog, State Key Lab Desert & Oasis Ecol, Urumqi 830011, Peoples R China.; Zhang, NN (corresponding author), Xinjiang Key Lab Mineral Resources & Digital Geol, Urumqi 830011, Peoples R China.; Zhang, NN (corresponding author), Chinese Acad Sci, Xinjiang Res Ctr Mineral Resources, Urumqi 830011, Peoples R China.; Zhang, NN (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM znn_0802@163.com
FU Opening Subject of Key Laboratories in the Xinjiang Uygur Autonomous Region [2018D04025]; National Key Research and Development Program of China [2018YFC0604006-4]; Strategic Priority Research Program of the Chinese Academy of Sciences [XDA19030204]; Light of West China program of the China Academy of Science
CR Abedi M, 2012, COMPUT GEOSCI-UK, V46, P272, DOI 10.1016/j.cageo.2011.12.014
   Agterberg F. P., 2011, NATURAL RESOURCES RE, V20, P95, DOI 10.1007/s11053-011-9138-0.
   Agterberg F.P., 1992, NONRENEWABLE RESOURC, V1, P39, DOI 10.1007/BF01782111
   AGTERBERG FP, 1990, COMPUT GEOL, V7, P1
   Apel M, 2006, COMPUT GEOSCI-UK, V32, P222, DOI 10.1016/j.cageo.2005.06.016
   Bergmann R, 2000, AM STAT, V54, P72, DOI 10.2307/2685616
   Bonham-Carter GF., 1994, GEOGRAPHIC INFORM SY, V13, P398
   BONHAMCARTER GF, 1988, PHOTOGRAMM ENG REM S, V54, P1585
   Brown WM, 2000, AUST J EARTH SCI, V47, P757, DOI 10.1046/j.1440-0952.2000.00807.x
   Carranza E.J.M., 2004, NAT RESOUR RES, V13, P173, DOI 10.1023/B:NARR.0000046919.87758.F5
   Carranza E.J.M., 1999, NAT RESOUR RES, V8, P165, DOI 10.1023/A:1021846820568
   Carranza EJM, 2016, NAT RESOUR RES, V25, P35, DOI 10.1007/s11053-015-9268-x
   Carranza EJM, 2015, ORE GEOL REV, V71, P777, DOI 10.1016/j.oregeorev.2014.08.010
   Carranza EJM, 2015, COMPUT GEOSCI-UK, V74, P60, DOI 10.1016/j.cageo.2014.10.004
   Carranza EJM, 2010, ORE GEOL REV, V38, P219, DOI 10.1016/j.oregeorev.2010.02.003
   Chen YJ, 2012, INT J EARTH SCI, V101, P889, DOI 10.1007/s00531-011-0689-4
   Chen YJ, 2000, GEOLOGICAL J CHINA U, V6, P17, DOI 10.16108/J.ISSN1006-7493.2000.01.002
   Chen YL, 2019, NAT RESOUR RES, V28, P31, DOI 10.1007/s11053-018-9375-6
   Chen YL, 2017, ORE GEOL REV, V80, P200, DOI 10.1016/j.oregeorev.2016.06.033
   Chen YL, 2016, ORE GEOL REV, V74, P26, DOI 10.1016/j.oregeorev.2015.11.011
   Chen YL, 2015, ORE GEOL REV, V71, P749, DOI 10.1016/j.oregeorev.2014.08.012
   DErcole C, 2000, AUST J EARTH SCI, V47, P913, DOI 10.1046/j.1440-0952.2000.00821.x
   Deng XH, 2019, J GEOCHEM EXPLOR, V196, P8, DOI 10.1016/j.gexplo.2018.09.010
   Deng XH, 2018, GEOL J, V53, P2178, DOI 10.1002/gj.3046
   Deng XH, 2018, ORE GEOL REV, V100, P250, DOI 10.1016/j.oregeorev.2016.08.006
   Deng XH, 2016, ORE GEOL REV, V77, P72, DOI 10.1016/j.oregeorev.2016.01.014
   Fabbri A.G., 2008, NAT RESOUR RES, V0, PP315, DOI 10.1007/s11053-008-9072-y
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ford A, 2016, NAT RESOUR RES, V25, P19, DOI 10.1007/s11053-015-9263-2
   Gao Y, 2016, ORE GEOL REV, V75, P16, DOI 10.1016/j.oregeorev.2015.12.005
   Hale M, 2009, HBK EXPL ENV GEOCHEM, V11, P189
   Harris D., 1999, NAT RESOUR RES, V8, P93, DOI 10.1023/A:1021886501912
   Hu XY, 2018, ORE GEOL REV, V92, P240, DOI 10.1016/j.oregeorev.2017.11.019
   Huang JH, 2018, ORE GEOL REV, V100, P263, DOI 10.1016/j.oregeorev.2017.02.037
   Joly A, 2010, EGU GEN ASS C, V0, P341
   Joly A, 2012, ORE GEOL REV, V48, P349, DOI 10.1016/j.oregeorev.2012.05.004
   Kaufmann O, 2008, COMPUT GEOSCI-UK, V34, P278, DOI 10.1016/j.cageo.2007.09.005
   Kim YH, 2019, ORE GEOL REV, V107, P239, DOI 10.1016/j.oregeorev.2019.02.026
   Li W Q., 2006, GEOLOGY CHINA, V33, P559
   Li XH, 2019, ORE GEOL REV, V105, P1, DOI 10.1016/j.oregeorev.2018.12.003
   Li XH, 2015, ORE GEOL REV, V71, P633, DOI 10.1016/j.oregeorev.2015.06.001
   Lisitsin VA, 2013, ORE GEOL REV, V52, P100, DOI 10.1016/j.oregeorev.2012.04.001
   Lu QT, 2013, GEOPHYSICS, V78, PB25, DOI 10.1190/GEO2012-0126.1
   Malehmir A, 2009, GEOPHYSICS, V74, PB9, DOI 10.1190/1.3008053
   Mao Q.G., 2014, GEOLOGICAL METALLOGE, V0, P1
   Mao Q.G., 2016, MINERAL EXPLORATION, V7, P17
   [毛启贵 Mao Qigui], 2015, 矿床地质 MINERAL DEPOSITS, V34, P730
   Mao QG, 2010, ACTA PETROL SIN, V26, P3017
   McKay G, 2016, NAT RESOUR RES, V25, P125, DOI 10.1007/s11053-015-9274-z
   Moradi M, 2015, EARTH SCI INFORM, V8, P197, DOI 10.1007/s12145-014-0151-9
   Mutele L, 2017, NAT RESOUR RES, V26, P535, DOI 10.1007/s11053-017-9325-8
   Najafi A, 2014, INT J APPL EARTH OBS, V33, P142, DOI 10.1016/j.jag.2014.05.003
   Nielsen SHH, 2015, ORE GEOL REV, V71, P578, DOI 10.1016/j.oregeorev.2015.02.001
   Nykanen V, 2015, ORE GEOL REV, V71, P853, DOI 10.1016/j.oregeorev.2014.09.007
   Payne CE, 2015, ORE GEOL REV, V71, P558, DOI 10.1016/j.oregeorev.2014.11.013
   Porwal A, 2006, COMPUT GEOSCI-UK, V32, P1, DOI 10.1016/j.cageo.2005.03.018
   Porwal A, 2010, ORE GEOL REV, V38, P184, DOI 10.1016/j.oregeorev.2010.04.002
   Porwal A., 2001, EXPLOR MIN GEOL J, V10, P273, DOI 10.2113/0100273
   Porwal A., 2003, NAT RESOUR RES, V12, P1, DOI 10.1023/A:1022693220894
   Porwal A, 2015, ORE GEOL REV, V71, P839, DOI 10.1016/j.oregeorev.2014.10.016
   Qin KZ, 2011, AM J SCI, V311, P237, DOI 10.2475/03.2011.03
   [秦克章 Qin Kezhang], 2002, 新疆地质 XINJIANG GEOLOGY, V20, P302
   Reddy R. K. T., 1991, CANADIAN JOURNAL OF REMOTE SENSING, V17, P191
   Rodriguez-Galiano V, 2015, ORE GEOL REV, V71, P804, DOI 10.1016/j.oregeorev.2015.01.001
   Sandham W, 2003, GEOPHYS APPL ARTIFIC, V0, P348
   SENGOR AMC, 1993, NATURE, V364, P299, DOI 10.1038/364299a0
   Singer DA, 1996, MATH GEOL, V28, P1017, DOI 10.1007/BF02068587
   SINGER DA, 1999, NATURAL RESOURCES RE, V8, P287, DOI 10.1023/A:1021606417010
   Sprague K, 2006, COMPUT GEOSCI-UK, V32, P396, DOI 10.1016/j.cageo.2005.07.008
   [孙岳 Sun Yue], 2013, 地质与勘探 GEOLOGY AND PROSPECTING, V49, P179
   Tessema A, 2017, NAT RESOUR RES, V26, P465, DOI 10.1007/s11053-017-9344-5
   Wang GW, 2017, J AFR EARTH SCI, V128, P97, DOI 10.1016/j.jafrearsci.2016.06.020
   Wang GW, 2015, ORE GEOL REV, V71, P592, DOI 10.1016/j.oregeorev.2015.03.002
   Wang GW, 2012, J APPL GEOPHYS, V80, P1, DOI 10.1016/j.jappgeo.2012.01.006
   Wang GW, 2011, COMPUT GEOSCI-UK, V37, P1976, DOI 10.1016/j.cageo.2011.05.007
   Wang J B., 2006, GEOLOGY CHINA, V33, P461
   Windley BF, 2007, J GEOL SOC LONDON, V164, P31, DOI 10.1144/0016-76492006-022
   Xiao KY, 2015, ORE GEOL REV, V71, P611, DOI 10.1016/j.oregeorev.2015.03.001
   Xiao WJ, 2013, GONDWANA RES, V23, P1316, DOI 10.1016/j.gr.2012.01.012
   Xu XY, 2009, GEOLOGICAL BACKGROUN, V0, P0
   Yang F, 2017, ORE GEOL REV, V89, P228, DOI 10.1016/j.oregeorev.2017.06.013
   Yousefi M, 2017, J AFR EARTH SCI, V128, P47, DOI 10.1016/j.jafrearsci.2016.04.019
   Yousefi M, 2015, COMPUT GEOSCI-UK, V74, P97, DOI 10.1016/j.cageo.2014.10.014
   Yousefi M, 2014, GEOCHEM-EXPLOR ENV A, V14, P45, DOI 10.1144/geochem2012-144
   Yuan F, 2014, J GEOCHEM EXPLOR, V145, P82, DOI 10.1016/j.gexplo.2014.05.012
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang NN, 2017, J AFR EARTH SCI, V128, P84, DOI 10.1016/j.jafrearsci.2016.12.011
   Zheng JH, 2015, ORE GEOL REV, V67, P244, DOI 10.1016/j.oregeorev.2014.12.006
NR 88
TC 8
Z9 8
U1 4
U2 20
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1874-8961
EI 1874-8953
J9 MATH GEOSCI
JI Math Geosci.
PD JAN 15
PY 2021
VL 53
IS 1
BP 131
EP 162
DI 10.1007/s11004-019-09844-2
EA DEC 2019
PG 32
WC Geosciences, Multidisciplinary; Mathematics, Interdisciplinary Applications
SC Geology; Mathematics
GA PV6KQ
UT WOS:000574544000001
DA 2023-04-26
ER

PT J
AU Osco, LP
   de Arruda, MD
   Goncalves, DN
   Dias, A
   Batistoti, J
   de Souza, M
   Gomes, FDG
   Ramos, APM
   Jorge, LAD
   Liesenberg, V
   Li, J
   Ma, LF
   Marcato, J
   Goncalves, WN
AF Osco, Lucas Prado
   de Arruda, Mauro dos Santos
   Goncalves, Diogo Nunes
   Dias, Alexandre
   Batistoti, Juliana
   de Souza, Mauricio
   Georges Gomes, Felipe David
   Marques Ramos, Ana Paula
   de Castro Jorge, Lucio Andre
   Liesenberg, Veraldo
   Li, Jonathan
   Ma, Lingfei
   Marcato, Jose
   Goncalves, Wesley Nunes
TI A CNN approach to simultaneously count plants and detect plantation-rows from UAV imagery
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Deep learning; UAV imagery; Object detection; Remote sensing; Precision agriculture
ID tree-crown detection; citrus-trees; delineation
AB Accurately mapping croplands is an important prerequisite for precision farming since it assists in field management, yield-prediction, and environmental management. Crops are sensitive to planting patterns and some have a limited capacity to compensate for gaps within a row. Optical imaging with sensors mounted on Unmanned Aerial Vehicles (UAV) is a cost-effective option for capturing images covering croplands nowadays. However, visual inspection of such images can be a challenging and biased task, specifically for detecting plants and rows on a one-step basis. Thus, developing an architecture capable of simultaneously extracting plant individually and plantation-rows from UAV-images is yet an important demand to support the management of agricultural systems. In this paper, we propose a novel deep learning method based on a Convolutional Neural Network (CNN) that simultaneously detects and geolocates plantation-rows while counting its plants considering highly-dense plantation configurations. The experimental setup was evaluated in (a) a cornfield (Zea mays L.) with different growth stages (i.e. recently planted and mature plants) and in a (b) Citrus orchard (Citrus Sinensis Pera). Both datasets characterize different plant density scenarios, in different locations, with different types of crops, and from different sensors and dates. This scheme was used to prove the robustness of the proposed approach, allowing a broader discussion of the method. A two-branch architecture was implemented in our CNN method, where the information obtained within the plantation-row is updated into the plant detection branch and retro-feed to the row branch; which are then refined by a Multi-Stage Refinement method. In the corn plantation datasets (with both growth phases - young and mature), our approach returned a mean absolute error (MAE) of 6.224 plants per image patch, a mean relative error (MRE) of 0.1038, precision and recall values of 0.856, and 0.905, respectively, and an F-measure equal to 0.876. These results were superior to the results from other deep networks (HRNet, Faster R-CNN, and RetinaNet) evaluated with the same task and dataset. For the plantation-row detection, our approach returned precision, recall, and F-measure scores of 0.913, 0.941, and 0.925, respectively. To test the robustness of our model with a different type of agriculture, we performed the same task in the citrus orchard dataset. It returned an MAE equal to 1.409 citrus-trees per patch, MRE of 0.0615, precision of 0.922, recall of 0.911, and F-measure of 0.965. For the citrus plantation-row detection, our approach resulted in precision, recall, and F-measure scores equal to 0.965, 0.970, and 0.964, respectively. The proposed method achieved state-of-the-art performance for counting and geolocating plants and plant-rows in UAV images from different types of crops. The method proposed here may be applied to future decision-making models and could contribute to the sustainable management of agricultural systems.
C1 [Osco, Lucas Prado] Univ Western Sao Paulo, Fac Engn & Architecture & Urbanism, R Jose Bongiovanni 700,Cidade Univ, BR-19050920 Presidente Prudente, SP, Brazil.
   [de Arruda, Mauro dos Santos; Goncalves, Diogo Nunes] Univ Fed Mato Grosso do Sul, Fac Comp Sci, Av Costa & Silva S-N, BR-79070900 Campo Grande, MS, Brazil.
   [Dias, Alexandre; Batistoti, Juliana] Univ Fed Mato Grosso do Sul, Fac Vet Med & Anim Sci, Ave Senador Filinto Muller 2443, BR-79074960 Campo Grande, MS, Brazil.
   [de Souza, Mauricio; Marcato, Jose; Goncalves, Wesley Nunes] Univ Fed Mato Grosso do Sul, Fac Engn Architecture & Urbanism & Geog, Av Costa & Silva, BR-79070900 Campo Grande, MS, Brazil.
   [Georges Gomes, Felipe David; Marques Ramos, Ana Paula] Univ Western Sao Paulo UNOESTE, Postgrad Program Environm & Reg Dev, Rodovia Raposo Tavares,Km 572 Limoeiro, BR-19067175 Pres Prudente, SP, Brazil.
   [de Castro Jorge, Lucio Andre] Brazilian Agr Res Agcy EMBRAPA, Natl Res Ctr Dev Agr Instrumentat, R XV Novembro 1452, BR-13560970 Sao Carlos, SP, Brazil.
   [Liesenberg, Veraldo] Univ Santa Catarina State UDESC, Forest Engn Dept, Av Luiz de Camoes 2090, BR-88520000 Lages, SC, Brazil.
   [Li, Jonathan; Ma, Lingfei] Univ Waterloo, Dept Geog & Environm Management, Waterloo, ON N2L 3G1, Canada.
C3 Universidade do Oeste Paulista; Universidade Federal de Mato Grosso do Sul; Universidade Federal de Mato Grosso do Sul; Universidade Federal de Mato Grosso do Sul; Universidade do Oeste Paulista; University of Waterloo
RP Ramos, APM (corresponding author), Univ Western Sao Paulo UNOESTE, Postgrad Program Environm & Reg Dev, Rodovia Raposo Tavares,Km 572 Limoeiro, BR-19067175 Pres Prudente, SP, Brazil.
EM lucasosco@unoeste.br; mauro.arruda@ufms.br; alexandre.dias@ufms.br; juliana.batistoti@ufms.br; mauricio.souza@ufms.br; anaramos@unoeste.br; veraldo.liesenberg@udesc.br; junli@uwaterloo.ca; l53ma@uwaterloo.ca; jose.marcato@ufms.br; wesley.goncalves@ufms.br
FU EMBRAPA [23700.19/0192-9-1]; National Council for Scientific and Technological Development (CNPq) [303559/2019-5, 433783/2018-4, 310517/2020-6, 313887/2018-7, 304173/2016-9]; Fundect [59/300.066/2015, 59/300.095/2015]; FAPESC [2017TR1762]; CAPES-Print [88881.311850/2018-01]
CR Adhikari SP, 2019, FRONT PLANT SCI, V10, P0, DOI 10.3389/fpls.2019.01404
   Aich S., 2018, ARXIV PREPRINT ARXIV, V0, P0
   Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Ampatzidis Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040410
   An JY, 2019, SYMMETRY-BASEL, V11, P0, DOI 10.3390/sym11020256
   [Anonymous], 2015, INTRO DIGITAL IMAGE, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bah MD, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111690
   Bah MD, 2020, IEEE ACCESS, V8, P5189, DOI 10.1109/ACCESS.2019.2960873
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Csillik O, 2018, DRONES-BASEL, V2, P0, DOI 10.3390/drones2040039
   Delloye C, 2018, REMOTE SENS ENVIRON, V216, P245, DOI 10.1016/j.rse.2018.06.037
   Deng L, 2018, ISPRS J PHOTOGRAMM, V146, P124, DOI 10.1016/j.isprsjprs.2018.09.008
   Djerriri K, 2018, INT GEOSCI REMOTE SE, V0, P2627
   dos Santos AA, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19163595
   Fan Z, 2018, IEEE J-STARS, V11, P876, DOI 10.1109/JSTARS.2018.2793849
   Freudenberg M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030312
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Gnadinger F, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060544
   Goldman E, 2019, PROC CVPR IEEE, V0, PP5222, DOI 10.1109/CVPR.2019.00537
   Hartling S, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19061284
   Hassanein M., 2019, INT ARCH PHOTOGRAMME, V42, P349
   Huang X, 2014, REMOTE SENS-BASEL, V6, P8424, DOI 10.3390/rs6098424
   Hunt ER, 2018, INT J REMOTE SENS, V39, P5345, DOI 10.1080/01431161.2017.1410300
   Hunt ML, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111410
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jakubowski MK, 2013, REMOTE SENS-BASEL, V5, P4163, DOI 10.3390/rs5094163
   Jiang H, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9070721
   Jin ZN, 2019, REMOTE SENS ENVIRON, V228, P115, DOI 10.1016/j.rse.2019.04.016
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Khamparia A, 2019, EXPERT SYST, V36, P0, DOI 10.1111/exsy.12400
   Kitano B. T., 2019, IEEE GEOSCI REMOTE S, V0, PP1, DOI 10.1109/lgrs.2019.2930549.
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Larsen M, 2011, INT J REMOTE SENS, V32, P5827, DOI 10.1080/01431161.2010.507790
   Leiva JN, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.036003
   Li D, 2016, IEEE GEOSCI REMOTE S, V13, P1330, DOI 10.1109/LGRS.2016.2584109
   Li WJ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010022
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Minh DHT, 2018, IEEE GEOSCI REMOTE S, V15, P464, DOI 10.1109/LGRS.2018.2794581
   Miyoshi GT, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081294
   Mochida K, 2019, GIGASCIENCE, V8, P0, DOI 10.1093/gigascience/giy153
   Mohanty SK, 2019, BIOETHANOL PRODUCTION FROM FOOD CROPS: SUSTAINABLE SOURCES, V0, P45, DOI 10.1016/B978-0-12-813766-6.00003-5
   Ndikumana E, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081217
   Nevalainen O, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030185
   Oliveira HC, 2018, IEEE GEOSCI REMOTE S, V15, P991, DOI 10.1109/LGRS.2018.2819944
   Osco LP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060906
   Osco LP, 2020, ISPRS J PHOTOGRAMM, V160, P97, DOI 10.1016/j.isprsjprs.2019.12.010
   Osco LP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242925
   Ozcan AH, 2017, REMOTE SENS LETT, V8, P761, DOI 10.1080/2150704X.2017.1322733
   Ozdarici-Ok A, 2015, INT J REMOTE SENS, V36, P4275, DOI 10.1080/01431161.2015.1079663
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Primicerio J, 2017, EUR J REMOTE SENS, V50, P179, DOI 10.1080/22797254.2017.1308234
   Quan LZ, 2019, BIOSYST ENG, V184, P1, DOI 10.1016/j.biosystemseng.2019.05.002
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribera J, 2017, IEEE GLOB CONF SIG, V0, P1344
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Safonova A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060643
   Salami E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030316
   Simonyan K, 2015, ARXIV, V0, P0
   Sun J, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19204363
   Sylvain JD, 2019, ISPRS J PHOTOGRAMM, V156, P14, DOI 10.1016/j.isprsjprs.2019.07.010
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tao SL, 2015, ISPRS J PHOTOGRAMM, V110, P66, DOI 10.1016/j.isprsjprs.2015.10.007
   Varela S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020343
   Verma NK, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050388
   Wang HQ, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111234
   Wang S, 2019, REMOTE SENS ENVIRON, V222, P303, DOI 10.1016/j.rse.2018.12.026
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111309
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111402
   Wu JT, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060691
   Zhang HK, 2017, REMOTE SENS LETT, V8, P438, DOI 10.1080/2150704X.2017.1280200
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhou CQ, 2018, IEEE T GEOSCI REMOTE, V56, P4618, DOI 10.1109/TGRS.2018.2830823
NR 77
TC 24
Z9 27
U1 24
U2 86
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2021
VL 174
IS 
BP 1
EP 17
DI 10.1016/j.isprsjprs.2021.01.024
EA FEB 2021
PG 17
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO4AQ
UT WOS:000640987800001
DA 2023-04-26
ER

PT J
AU Ajayakumar, J
   Curtis, AJ
   Rouzier, V
   Pape, JW
   Bempah, S
   Alam, MT
   Alam, MM
   Rashid, MH
   Ali, A
   Morris, JG
AF Ajayakumar, Jayakrishnan
   Curtis, Andrew J.
   Rouzier, Vanessa
   Pape, Jean William
   Bempah, Sandra
   Alam, Meer Taifur
   Alam, Md. Mahbubul
   Rashid, Mohammed H.
   Ali, Afsar
   Morris, John Glenn
TI Exploring convolutional neural networks and spatial video for on-the-ground mapping in informal settlements
SO INTERNATIONAL JOURNAL OF HEALTH GEOGRAPHICS
LA English
DT Article
ID dar-es-salaam; malaria prevalence; temporal dynamics; slums; dengue; environments; community; risks; fever; model
AB Background The health burden in developing world informal settlements often coincides with a lack of spatial data that could be used to guide intervention strategies. Spatial video (SV) has proven to be a useful tool to collect environmental and social data at a granular scale, though the effort required to turn these spatially encoded video frames into maps limits sustainability and scalability. In this paper we explore the use of convolution neural networks (CNN) to solve this problem by automatically identifying disease related environmental risks in a series of SV collected from Haiti. Our objective is to determine the potential of machine learning in health risk mapping for these environments by assessing the challenges faced in adequately training the required classification models. Results We show that SV can be a suitable source for automatically identifying and extracting health risk features using machine learning. While well-defined objects such as drains, buckets, tires and animals can be efficiently classified, more amorphous masses such as trash or standing water are difficult to classify. Our results further show that variations in the number of image frames selected, the image resolution, and combinations of these can be used to improve the overall model performance. Conclusion Machine learning in combination with spatial video can be used to automatically identify environmental risks associated with common health problems in informal settlements, though there are likely to be variations in the type of data needed for training based on location. Success based on the risk type being identified are also likely to vary geographically. However, we are confident in identifying a series of best practices for data collection, model training and performance in these settings. We also discuss the next step of testing these findings in other environments, and how adding in the simultaneously collected geographic data could be used to create an automatic health risk mapping tool.
C1 [Ajayakumar, Jayakrishnan; Curtis, Andrew J.] Case Western Reserve Univ, Sch Med, Dept Populat & Quantitat Hlth Sci, Cleveland, OH 44106 USA.
   [Rouzier, Vanessa; Pape, Jean William] Les Ctr Haitian Grp Study Kaposis Sarcoma & Oppor, Port Au Prince, Haiti.
   [Bempah, Sandra] Kent State Univ, Dept Geog, Kent, OH 44242 USA.
   [Alam, Meer Taifur; Alam, Md. Mahbubul; Rashid, Mohammed H.; Ali, Afsar; Morris, John Glenn] Univ Florida, Coll Med, Emerging Pathogens Inst, Gainesville, FL USA.
   [Alam, Meer Taifur; Alam, Md. Mahbubul; Rashid, Mohammed H.; Ali, Afsar; Morris, John Glenn] Univ Florida, Coll Med, Dept Med, Gainesville, FL USA.
   [Alam, Meer Taifur; Alam, Md. Mahbubul; Ali, Afsar] Univ Florida, Coll Publ Hlth & Hlth Profess, Emerging Pathogens Inst, Gainesville, FL 32601 USA.
   [Alam, Meer Taifur; Alam, Md. Mahbubul; Ali, Afsar] Univ Florida, Coll Publ Hlth & Hlth Profess, Dept Environm & Global Hlth, Gainesville, FL 32601 USA.
C3 Case Western Reserve University; University System of Ohio; Kent State University; Kent State University Kent; Kent State University Salem; State University System of Florida; University of Florida; State University System of Florida; University of Florida; State University System of Florida; University of Florida; State University System of Florida; University of Florida
RP Ajayakumar, J (corresponding author), Case Western Reserve Univ, Sch Med, Dept Populat & Quantitat Hlth Sci, Cleveland, OH 44106 USA.
EM jxa421@case.edu
FU National Institute of Allergy & Infectious Diseases [RO1 Al126357]
CR Ajami A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111282
   Amarasinghe A, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS17), V0, P0, DOI DOI 10.1145/3131672.3136986
   [Anonymous], 2014, PROC IEEE C COMPUT V, V0, P0
   Bahdanau D, 2016, ARXIV, V0, P0
   Bempah S, 2020, HEALTH PLACE, V64, P0, DOI 10.1016/j.healthplace.2020.102382
   Boller D, 2019, URBAN WATER J, V16, P480, DOI 10.1080/1573062X.2019.1687743
   Chow CK, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0110042
   Corburn J., 2012, MATHARE ZONAL PLAN N, V0, P0
   Corburn J, 2015, J ENVIRON PUBLIC HEA, V2015, P0, DOI 10.1155/2015/209505
   Curtis A, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16050807
   Curtis A, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16010033
   Curtis A, 2017, APPL GEOGR, V87, P197, DOI 10.1016/j.apgeog.2017.08.008
   Curtis A, 2016, INT J ENV RES PUB HE, V13, P0, DOI 10.3390/ijerph13020187
   Curtis A, 2013, INT J HEALTH GEOGR, V12, P0, DOI 10.1186/1476-072X-12-21
   Delmelle E, 2016, ACTA TROP, V164, P169, DOI 10.1016/j.actatropica.2016.08.028
   Dewan AM, 2013, PLOS NEGLECT TROP D, V7, P0, DOI 10.1371/journal.pntd.0001998
   Dickin SK, 2014, APPL GEOGR, V46, P71, DOI 10.1016/j.apgeog.2013.11.003
   Emina J, 2011, J URBAN HEALTH, V88, P200, DOI 10.1007/s11524-011-9594-1
   Engstrom R, 2019, JOINT URB REMOTE SEN, V0, P0
   Falco E, 2019, HABITAT INT, V94, P0, DOI 10.1016/j.habitatint.2019.102038
   Fulton M, 2019, IEEE INT CONF ROBOT, V0, PP5752, DOI 10.1109/ICRA.2019.8793975
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Goldberg Y., 2017, SYNTHESIS LECT HUMAN, V0, P0, DOI DOI 10.2200/S00762ED1V01Y201703HLT037
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Ibrahim MR, 2019, COMPUT ENVIRON URBAN, V76, P31, DOI 10.1016/j.compenvurbsys.2019.03.005
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Karanja I, 2010, ENVIRON URBAN, V22, P217, DOI 10.1177/0956247809362642
   Krasin Ivan, 2017, OPENIMAGES PUBLIC DA, V0, P0
   Law S, 2020, INT J GEOGR INF SCI, V34, P681, DOI 10.1080/13658816.2018.1555832
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P0, DOI 10.5555/303568.303704
   Liu RY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232844
   Long J., 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Messina JP, 2011, MALARIA J, V10, P0, DOI 10.1186/1475-2875-10-161
   Mooney SJ, 2016, AM J PUBLIC HEALTH, V106, P462, DOI 10.2105/AJPH.2015.302978
   Mwakalinga VM, 2016, MALARIA J, V15, P0, DOI 10.1186/s12936-016-1186-9
   Panek J, 2015, ELECTR J INF SYS DEV, V68, P0
   Price H, 2019, SCI TOTAL ENVIRON, V671, P818, DOI 10.1016/j.scitotenv.2019.03.355
   Rad MS, 2017, LECT NOTES COMPUT SC, V10528, P195, DOI 10.1007/978-3-319-68345-4_18
   REDMON J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Ren S., 2016, ARXIV, V0, P0, DOI DOI 10.1109/TPAMI.2016.2577031
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Smiley SL, 2017, TROP MED INFECT DIS, V2, P0, DOI 10.3390/tropicalmed2020008
   Stark T., 2019, P 2019 JOINT URBAN R, V2019, P1, DOI 10.1109/JURSE.2019.8808965
   Thomson DR, 2020, SOC SCI-BASEL, V9, P0, DOI 10.3390/socsci9050080
   Townes LR, 2013, MALARIA J, V12, P0, DOI 10.1186/1475-2875-12-407
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Verma D, 2019, HABITAT INT, V88, P0, DOI 10.1016/j.habitatint.2019.04.008
   Wang J, 2016, PROC CVPR IEEE, V0, PP2285, DOI 10.1109/CVPR.2016.251
   Wurm M, 2019, ISPRS J PHOTOGRAMM, V150, P59, DOI 10.1016/j.isprsjprs.2019.02.006
NR 50
TC 6
Z9 6
U1 2
U2 33
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1476-072X
EI 
J9 INT J HEALTH GEOGR
JI Int. J. Health Geogr.
PD JAN 25
PY 2021
VL 20
IS 1
BP 
EP 
DI 10.1186/s12942-021-00259-z
PG 17
WC Public, Environmental & Occupational Health
SC Public, Environmental & Occupational Health
GA PX7ME
UT WOS:000611537200001
PM 33494756
DA 2023-04-26
ER

PT J
AU Yang, AN
   Wang, CM
   Pang, GW
   Long, YQ
   Wang, L
   Cruse, RM
   Yang, QK
AF Yang, Annan
   Wang, Chunmei
   Pang, Guowei
   Long, Yongqing
   Wang, Lei
   Cruse, Richard M.
   Yang, Qinke
TI Gully Erosion Susceptibility Mapping in Highly Complex Terrain Using Machine Learning Models
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE gully erosion; machine learning; the weight of evidence; gully erosion susceptibility mapping; Loess Plateau
ID logistic-regression; statistical-models; neural-networks; loess plateau; prediction; resolution; ensemble; region; geomorphology; catchments
AB Gully erosion is the most severe type of water erosion and is a major land degradation process. Gully erosion susceptibility mapping (GESM)'s efficiency and interpretability remains a challenge, especially in complex terrain areas. In this study, a WoE-MLC model was used to solve the above problem, which combines machine learning classification algorithms and the statistical weight of evidence (WoE) model in the Loess Plateau. The three machine learning (ML) algorithms utilized in this research were random forest (RF), gradient boosted decision trees (GBDT), and extreme gradient boosting (XGBoost). The results showed that: (1) GESM were well predicted by combining both machine learning regression models and WoE-MLC models, with the area under the curve (AUC) values both greater than 0.92, and the latter was more computationally efficient and interpretable; (2) The XGBoost algorithm was more efficient in GESM than the other two algorithms, with the strongest generalization ability and best performance in avoiding overfitting (averaged AUC = 0.947), followed by the RF algorithm (averaged AUC = 0.944), and GBDT algorithm (averaged AUC = 0.938); and (3) slope gradient, land use, and altitude were the main factors for GESM. This study may provide a possible method for gully erosion susceptibility mapping at large scale.</p>
C1 [Yang, Annan; Wang, Chunmei; Pang, Guowei; Long, Yongqing; Wang, Lei; Yang, Qinke] Northwest Univ, Coll Urban & Environm Sci, Shaanxi Key Lab Earth Surface Syst & Environm Car, Xian 710127, Peoples R China.
   [Yang, Annan; Wang, Chunmei; Pang, Guowei; Long, Yongqing; Wang, Lei; Yang, Qinke] Northwest Univ, Key Lab Natl Forestry Adm Ecol Hydrol & Disaster, Xian 710127, Peoples R China.
   [Cruse, Richard M.] Iowa State Univ, Dept Agron, Ames, IA 50011 USA.
C3 Northwest University Xi'an; Northwest University Xi'an; Iowa State University
RP Long, YQ (corresponding author), Northwest Univ, Coll Urban & Environm Sci, Shaanxi Key Lab Earth Surface Syst & Environm Car, Xian 710127, Peoples R China.; Long, YQ (corresponding author), Northwest Univ, Key Lab Natl Forestry Adm Ecol Hydrol & Disaster, Xian 710127, Peoples R China.
EM yangannan@stumail.nwu.edu.cn; cmwang@nwu.edu.cn; gwpang@nwu.edu.cn; sjzxlyq@nwu.edu.cn; montez@nwu.edu.cn; rmc@iastate.edu; qkyang@nwu.edu.cn
FU National Natural Science Foundation of China [41977062, 41601290, 41930102]; SKL Foundation; Strategic Priority Research Program of the Chinese Academy of Sciences [XDA20040202]; Program for Key Science and Technology Innovation Team in Shaanxi Province [2014KCT-27]
CR Abedi R, 2022, GEOCARTO INT, V37, P5479, DOI 10.1080/10106049.2021.1920636
   Alin A, 2010, WIRES COMPUT STAT, V2, P370, DOI 10.1002/wics.84
   Amiri M, 2019, GEODERMA, V340, P55, DOI 10.1016/j.geoderma.2018.12.042
   Arabameri A, 2021, GEOMAT NAT HAZ RISK, V12, P469, DOI 10.1080/19475705.2021.1880977
   Arabameri A, 2020, GEOMORPHOLOGY, V359, P0, DOI 10.1016/j.geomorph.2020.107136
   Arabameri A, 2020, GEOSCI FRONT, V11, P1609, DOI 10.1016/j.gsf.2019.11.009
   Arabameri A, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11061129
   Arabameri A, 2019, SCI TOTAL ENVIRON, V688, P903, DOI 10.1016/j.scitotenv.2019.06.205
   Arabameri A, 2018, LAND DEGRAD DEV, V29, P4035, DOI 10.1002/ldr.3151
   Arabameri A, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7808-5
   Arabameri A, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8081369
   Avand M, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11102076
   Azareh A, 2019, SCI TOTAL ENVIRON, V655, P684, DOI 10.1016/j.scitotenv.2018.11.235
   Azedou A, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su13020682
   Band SS, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20195609
   Barzegar R, 2021, J HYDROL, V598, P0, DOI 10.1016/j.jhydrol.2021.126370
   Bigdeli B, 2021, APPL SOFT COMPUT, V110, P0, DOI 10.1016/j.asoc.2021.107563
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Can R, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11114993
   Castillo C, 2016, EARTH-SCI REV, V160, P300, DOI 10.1016/j.earscirev.2016.07.009
   Chaplot V, 2005, CATENA, V63, P167, DOI 10.1016/j.catena.2005.06.003
   Chaplot V, 2013, GEOMORPHOLOGY, V186, P1, DOI 10.1016/j.geomorph.2012.10.031
   Chen T., 1900, P785, V0, P0
   Chowdhuri I, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213620
   Conforti M, 2011, NAT HAZARDS, V56, P881, DOI 10.1007/s11069-010-9598-2
   Conoscenti C, 2008, NAT HAZARDS, V46, P287, DOI 10.1007/s11069-007-9188-0
   Conoscenti C, 2014, GEOMORPHOLOGY, V204, P399, DOI 10.1016/j.geomorph.2013.08.021
   Cui Y, 2017, BIOMED RES INT, V2017, P0, DOI 10.1155/2017/7323508
   Dai W, 2019, CATENA, V177, P114, DOI 10.1016/j.catena.2019.02.010
   Dev VA, 2019, COMPUT CHEM ENG, V128, P392, DOI 10.1016/j.compchemeng.2019.06.001
   Dewitte O, 2015, GEOMORPHOLOGY, V228, P101, DOI 10.1016/j.geomorph.2014.08.010
   Bui DT, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19112444
   Ding H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050793
   Dotterweich M, 2012, CATENA, V95, P50, DOI 10.1016/j.catena.2012.03.001
   Garosi Y, 2018, GEODERMA, V330, P65, DOI 10.1016/j.geoderma.2018.05.027
   Gayen A, 2019, SCI TOTAL ENVIRON, V668, P124, DOI 10.1016/j.scitotenv.2019.02.436
   He Q, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13081572
   Jin FM, 2021, SCI TOTAL ENVIRON, V773, P0, DOI 10.1016/j.scitotenv.2021.145514
   Kirkby MJ, 2009, EARTH SURF PROC LAND, V34, P1841, DOI 10.1002/esp.1866
   Kuhnert PM, 2010, ENVIRONMETRICS, V21, P493, DOI 10.1002/env.999
   Lei XX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152478
   Li SJ, 2020, GEOMORPHOLOGY, V354, P0, DOI 10.1016/j.geomorph.2020.107045
   Majhi A, 2021, GEOMORPHOLOGY, V375, P0, DOI 10.1016/j.geomorph.2020.107547
   Meliho M, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7844-1
   Nampak H, 2018, LAND DEGRAD DEV, V29, P3440, DOI 10.1002/ldr.3112
   Petovello M.G., 2017, SPRINGER HDB GLOBAL, V0, P535
   Poesen J, 2003, CATENA, V50, P91, DOI 10.1016/S0341-8162(02)00143-1
   Polykretis C, 2015, B ENG GEOL ENVIRON, V74, P27, DOI 10.1007/s10064-014-0607-7
   Pourghasemi HR, 2020, GEOSCI FRONT, V11, P2207, DOI 10.1016/j.gsf.2020.03.005
   Pourghasemi HR, 2016, GEOMAT NAT HAZ RISK, V7, P861, DOI 10.1080/19475705.2014.984247
   Rahmati O, 2017, GEOMORPHOLOGY, V298, P118, DOI 10.1016/j.geomorph.2017.09.006
   Rahmati O, 2016, NAT HAZARDS, V82, P1231, DOI 10.1007/s11069-016-2239-7
   Saha S, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20051313
   Sahin EK, 2020, SN APPL SCI, V2, P0, DOI 10.1007/s42452-020-3060-1
   Shit PK, 2020, ADV SCI TECHNOL INN, V0, PP133, DOI 10.1007/978-3-030-23243-6_8
   Song YX, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8010004
   Tehrany MS, 2013, J HYDROL, V504, P69, DOI 10.1016/j.jhydrol.2013.09.034
   Torri D, 2014, EARTH-SCI REV, V130, P73, DOI 10.1016/j.earscirev.2013.12.006
   Vanmaercke M, 2021, EARTH-SCI REV, V218, P0, DOI 10.1016/j.earscirev.2021.103637
   Wang CM, 2021, CATENA, V200, P0, DOI 10.1016/j.catena.2021.105158
   Wu YQ, 2005, CATENA, V63, P154, DOI 10.1016/j.catena.2005.06.002
   Xie ZT, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-017-6640-7
   Xiong LY, 2021, J GEOGR SCI, V31, P456, DOI 10.1007/s11442-021-1853-9
   Yang X, 2017, T GIS, V21, P1204, DOI 10.1111/tgis.12273
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Zhu TX, 2012, GEOMORPHOLOGY, V153, P144, DOI 10.1016/j.geomorph.2012.02.019
NR 67
TC 12
Z9 12
U1 8
U2 27
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD OCT 15
PY 2021
VL 10
IS 10
BP 
EP 
DI 10.3390/ijgi10100680
PG 19
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA WO9XS
UT WOS:000712798300001
DA 2023-04-26
ER

PT J
AU Bort, W
   Baskin, II
   Gimadiev, T
   Mukanov, A
   Nugmanov, R
   Sidorov, P
   Marcou, G
   Horvath, D
   Klimchuk, O
   Madzhidov, T
   Varnek, A
AF Bort, William
   Baskin, Igor I.
   Gimadiev, Timur
   Mukanov, Artem
   Nugmanov, Ramil
   Sidorov, Pavel
   Marcou, Gilles
   Horvath, Dragos
   Klimchuk, Olga
   Madzhidov, Timur
   Varnek, Alexandre
TI Discovery of novel chemical reactions by deep generative recurrent neural network
SO SCIENTIFIC REPORTS
LA English
DT Article
ID topographic mapping approach; data mining techniques; organic-reactions; data visualization; condensed graphs; classification; design; prediction; space; formalism
AB The "creativity" of Artificial Intelligence (AI) in terms of generating de novo molecular structures opened a novel paradigm in compound design, weaknesses (stability & feasibility issues of such structures) notwithstanding. Here we show that "creative" AI may be as successfully taught to enumerate novel chemical reactions that are stoichiometrically coherent. Furthermore, when coupled to reaction space cartography, de novo reaction design may be focused on the desired reaction class. A sequence-to-sequence autoencoder with bidirectional Long Short-Term Memory layers was trained on on-purpose developed "SMILES/CGR" strings, encoding reactions of the USPTO database. The autoencoder latent space was visualized on a generative topographic map. Novel latent space points were sampled around a map area populated by Suzuki reactions and decoded to corresponding reactions. These can be critically analyzed by the expert, cleaned of irrelevant functional groups and eventually experimentally attempted, herewith enlarging the synthetic purpose of popular synthetic pathways.
C1 [Bort, William; Baskin, Igor I.; Marcou, Gilles; Horvath, Dragos; Klimchuk, Olga; Varnek, Alexandre] Univ Strasbourg, Lab Chemoinformat, CNRS, UMR 7140, 1 Rue Blaise Pascal, F-67000 Strasbourg, France.
   [Baskin, Igor I.; Mukanov, Artem; Nugmanov, Ramil; Madzhidov, Timur] Kazan Fed Univ, Butlerov Inst Chem, Lab Chemoinformat & Mol Modeling, Kremlyovskaya Str 18, Kazan 420008, Russia.
   [Gimadiev, Timur; Sidorov, Pavel; Varnek, Alexandre] Hokkaido Univ, Inst Chem React Design & Discovery WPI ICReDD, Kita Ku, Kita 21 Nishi 10, Sapporo, Hokkaido 0010021, Japan.
   [Baskin, Igor I.] Technion Israel Inst Technol, Dept Mat Sci & Engn, IL-3200003 Haifa, Israel.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute of Chemistry (INC); UDICE-French Research Universities; Universites de Strasbourg Etablissements Associes; Universite de Strasbourg; Kazan Federal University; Hokkaido University; Technion Israel Institute of Technology
RP Varnek, A (corresponding author), Univ Strasbourg, Lab Chemoinformat, CNRS, UMR 7140, 1 Rue Blaise Pascal, F-67000 Strasbourg, France.; Varnek, A (corresponding author), Hokkaido Univ, Inst Chem React Design & Discovery WPI ICReDD, Kita Ku, Kita 21 Nishi 10, Sapporo, Hokkaido 0010021, Japan.
EM varnek@unistra.fr
FU Russian Scence Foundation [19-73-10137]; Russian Science Foundation [19-73-10137] Funding Source: Russian Science Foundation
CR [Anonymous], 1997, NEURAL COMPUT, V0, P0
   ARENS JF, 1979, RECL TRAV CHIM PAY B, V98, P471
   ARENS JF, 1979, RECL TRAV CHIM PAY B, V98, P395
   ARENS JF, 1979, RECL TRAV CHIM PAY B, V98, P155
   BALABAN AT, 1967, REV ROUM CHIM, V12, P875
   Baskin II, 2017, RUSS CHEM REV+, V86, P1127, DOI 10.1070/RCR4746
   Baskin II, 2017, J COMPUT AID MOL DES, V31, P701, DOI 10.1007/s10822-017-0033-6
   BAUER J, 1985, CHIMIA, V39, P43
   Bauer J., 1989, TETRAHED COMP METHOD, V2, P269
   Bell R., 1936, P ROY SOC LOND A MAT, V154, P414, DOI 10.1098/RSPA.1936.0060
   BENSON SW, 1965, J CHEM EDUC, V42, P502, DOI 10.1021/ed042p502
   Blaschke T, 2018, MOL INFORM, V37, P0, DOI 10.1002/minf.201700123
   Brown N, 2019, J CHEM INF MODEL, V59, P1096, DOI 10.1021/acs.jcim.8b00839
   Chakraborty J, 2019, CHEM ENG J, V358, P580, DOI 10.1016/j.cej.2018.09.037
   ChemAxon, 2019, CHEM STRUCTURE REPRE, V0, P0
   Chen WL, 2013, WIRES COMPUT MOL SCI, V3, P560, DOI 10.1002/wcms.1140
   Chi Y., 2017, FAMING ZHUANLI SHENQ, V0, P0
   Coley CW, 2017, ACS CENTRAL SCI, V3, P434, DOI 10.1021/acscentsci.7b00064
   Cottrell T. L, 1958, STRENGTHS CHEM BONDS, V0, P0
   Darwent B. de B., 1970, BOND DISSOCIATION EN, V0, P0
   Duan YZ, 2005, SYNLETT, V0, PP355, DOI 10.1055/s-2004-837211
   Dugundji J., 1973, TOP CURR CHEM, V0, PP19, DOI 10.1007/BFB0051317
   Elton DC, 2019, MOL SYST DES ENG, V4, P828, DOI 10.1039/c9me00039a
   Evans MG, 1936, T FARADAY SOC, V32, P1333, DOI 10.1039/tf9363201333
   Fooshee D, 2018, MOL SYST DES ENG, V3, P442, DOI 10.1039/c7me00107j
   Gaspar HA, 2015, MOL INFORM, V34, P348, DOI 10.1002/minf.201400153
   Gaspar HA, 2016, ACS SYM SER, V1222, P211
   Gaspar HA, 2015, J CHEM INF MODEL, V55, P2403, DOI 10.1021/acs.jcim.5b00398
   Gaspar HA, 2015, J CHEM INF MODEL, V55, P84, DOI 10.1021/ci500575y
   Gaspar HA, 2013, J CHEM INF MODEL, V53, P3318, DOI 10.1021/ci400423c
   Gimadiev TR, 2019, J MOL STRUCT, V1198, P0, DOI 10.1016/j.molstruc.2019.126897
   Gimadiev TR, 2018, J COMPUT AID MOL DES, V32, P401, DOI 10.1007/s10822-018-0101-6
   Gimadiev T. R, 2015, 2 KAZAN SUMMER SCH C, V34, P0
   Gimadiev T, 2019, MOL INFORM, V38, P0, DOI 10.1002/minf.201800104
   Gimadiev TR, 2016, BIONANOSCIENCE, V6, P464, DOI 10.1007/s12668-016-0246-5
   Glavatskikh M, 2018, MOL INFORM, V37, P0, DOI 10.1002/minf.201800056
   Glavatskikh M, 2019, MOL INFORM, V38, P0, DOI 10.1002/minf.201800077
   Gupta A, 2018, MOL INFORM, V37, P0, DOI 10.1002/minf.201700111
   HENDRICKSON JB, 1974, ANGEW CHEM INT EDIT, V13, P47, DOI 10.1002/anie.197400471
   HERGES R, 1992, SCIENCE, V255, P711, DOI 10.1126/science.255.5045.711
   HERGES R, 1990, J CHEM INF COMP SCI, V30, P377, DOI 10.1021/ci00068a006
   Herges R, 1988, TETRAHED COMP METHOD, V1, P15, DOI 10.1016/0898-5529(88)90005-X
   Hoonakker F, 2011, INT J ARTIF INTELL T, V20, P253, DOI 10.1142/S0218213011000140
   Hoonakker F, 2010, LECT NOTES ARTIF INT, V6097, P318, DOI 10.1007/978-3-642-13025-0_34
   Horvath D, 2017, CHALL ADV COMPUT CHE, V24, P167, DOI 10.1007/978-3-319-56850-8_6
   Horvath D, 2016, J CHEM INF MODEL, V56, P1631, DOI 10.1021/acs.jcim.6b00359
   Inaloo ID, 2020, ACS OMEGA, V5, P7406, DOI 10.1021/acsomega.9b04450
   James C. A, 2016, OPENSMILES SPECIFICA, V0, P0
   Jorgensen PB, 2018, MOL INFORM, V37, P0, DOI 10.1002/minf.201700133
   Karpov P, 2019, LECT NOTES COMPUT SC, V11731, P817, DOI 10.1007/978-3-030-30493-5_78
   Kayala MA, 2012, J CHEM INF MODEL, V52, P2526, DOI 10.1021/ci3003039
   Kireeva N, 2012, MOL INFORM, V31, P301, DOI 10.1002/minf.201100163
   Klimenko K, 2016, J CHEM INF MODEL, V56, P1438, DOI 10.1021/acs.jcim.6b00192
   Kori M., 2012, PCT INT APPL, V16, P0
   Laikov DN, 1997, CHEM PHYS LETT, V281, P151, DOI 10.1016/S0009-2614(97)01206-2
   Latino DARS, 2011, METHODS MOL BIOL, V672, P325, DOI 10.1007/978-1-60761-839-3_13
   Lin A.I, 2020, ATOM TO ATOM MAPPING, V0, P0, DOI DOI 10.26434/chemrxiv.13012679.v1
   Liu BW, 2017, ACS CENTRAL SCI, V3, P1103, DOI 10.1021/acscentsci.7b00303
   Lowe D. M., 2012, THESIS U CAMBRIDGE, V0, P0
   Luo ZJ, 2018, ORG LETT, V20, P2543, DOI 10.1021/acs.orglett.8b00692
   Madzhidov TI, 2015, J STRUCT CHEM+, V56, P1227, DOI 10.1134/S002247661507001X
   Madzhidov TI, 2014, RUSS J ORG CHEM+, V50, P459, DOI 10.1134/S1070428014040010
   Madzhidov T. I, 2018, 22 EUR S QUANT STRUC, V186, P0
   Maniyar DM, 2006, J CHEM INF MODEL, V46, P1806, DOI 10.1021/ci050471a
   Marcou G, 2015, J CHEM INF MODEL, V55, P239, DOI 10.1021/ci500698a
   Molchanova MS, 2003, J PHYS ORG CHEM, V16, P463, DOI 10.1002/poc.609
   Nam J., 2016, LINKING NEURAL MACHI, V0, P0
   Nugmanov RI, 2019, J CHEM INF MODEL, V59, P2516, DOI 10.1021/acs.jcim.9b00102
   Owen JR, 2011, J CHEM INF MODEL, V51, P1552, DOI 10.1021/ci1004042
   Park J, 2013, PATENT NO. PCT/KR2013/003289 2013003289, V0, P0
   Perdew JP, 1996, PHYS REV LETT, V77, P3865, DOI 10.1103/PhysRevLett.77.3865
   Sanchez-Lengeling B, 2018, SCIENCE, V361, P360, DOI 10.1126/science.aat2663
   Sattarov B, 2019, J CHEM INF MODEL, V59, P1182, DOI 10.1021/acs.jcim.8b00751
   SCHAFER A, 1994, J CHEM PHYS, V100, P5829, DOI 10.1063/1.467146
   Schwaller P, 2019, PREDICTING RETROSYNT, V0, P0, DOI DOI 10.26434/chemrxiv.9992489.v1
   Schwaller P, 2018, CHEM SCI, V9, P6091, DOI 10.1039/c8sc02339e
   Segler MHS, 2018, NATURE, V555, P604, DOI 10.1038/nature25978
   Segler MHS, 2017, CHEM-EUR J, V23, P6118, DOI 10.1002/chem.201604556
   Sidorov P, 2015, J COMPUT AID MOL DES, V29, P1087, DOI 10.1007/s10822-015-9882-z
   Sutskever I., 2014, ADV NEURAL INF PROCE, V2, P3104, DOI 10.48550/ARXIV.1409.3215
   Thiebes C, 1998, SYNLETT, V0, P141
   Varnek A, 2005, J COMPUT AID MOL DES, V19, P693, DOI 10.1007/s10822-005-9008-0
   Weires NA, 2016, NAT CHEM, V8, P75, DOI 10.1038/NCHEM.2388
   Xu YJ, 2019, FUTURE MED CHEM, V11, P567, DOI 10.4155/fmc-2018-0358
   Xu Z, 2017, P 8 ACM INT C BIOINF, V0, P285
   Xue DY, 2019, WIRES COMPUT MOL SCI, V9, P0, DOI 10.1002/wcms.1395
   Zefirov N. S., 1977, MATCH-COMMUN MATH CO, V3, P263
   ZEFIROV NS, 1980, CHEM SCRIPTA, V15, P4
   ZEFIROV NS, 1994, J CHEM INF COMP SCI, V34, P994, DOI 10.1021/ci00020a038
   Zefirov NS, 2002, MATCH-COMMUN MATH CO, V0, P253
   Zong Y, 2012, SYNLETT, V0, PP2393, DOI 10.1055/s-0032-1317097
NR 91
TC 22
Z9 22
U1 3
U2 13
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
EI 
J9 SCI REP-UK
JI Sci Rep
PD FEB 4
PY 2021
VL 11
IS 1
BP 
EP 
DI 10.1038/s41598-021-81889-y
PG 15
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA QH1PT
UT WOS:000618049600136
PM 33542271
DA 2023-04-26
ER

PT J
AU Yoon, S
   Suh, W
   Lee, YJ
AF Yoon, Sungsik
   Suh, Wonho
   Lee, Young-Joo
TI Optimal decision making in post-hazard bridge recovery strategies for transportation networks after seismic events
SO GEOMATICS NATURAL HAZARDS & RISK
LA English
DT Article
DE Benefit-cost analysis; optimal restoration strategy; seismic resilience; transportation network; total system travel time; artificial neural network
ID postearthquake functionality; infrastructure systems; resilience assessment; spatial correlation; risk-assessment; ground-motion; restoration; vulnerability; earthquake; prediction
AB In this study, optimal post-hazard bridge recovery strategies were proposed for transportation networks under seismic conditions. To predict the performance of the transportation network, a robust performance measure, total system travel time (TSTT), was employed, and an artificial neural network (ANN)-based surrogate model was developed to enable an accelerated Monte Carlo analysis. In addition, a sensitivity analysis based on the benefit-cost ratio was proposed to support optimal decision making immediately after an earthquake. To demonstrate the proposed methodology, an actual transportation network in South Korea was adopted, and a network map was reconstructed based on geographic information system (GIS) data. A surrogate model for network performance evaluation was constructed using training data generated based on historical earthquake epicenters. In addition, the damage ratio and required recovery days according to the damage states of bridges were employed to perform network recovery analysis. For the numerical analysis, a limited budget was set for each scenario, and the recovery and damage curve were compared with existing priority strategy. The numerical results showed that the priority strategy of bridge restoration determined through the benefit-cost analysis generated a faster recovery curve and significantly reduced the damage, as compared to existing strategy. Therefore, it is concluded that the proposed methodology enables optimal decision making and also helps risk management that can minimize the economic damage.
C1 [Yoon, Sungsik] Univ Illinois, Dept Civil & Environm Engn, Urbana, IL USA.
   [Suh, Wonho] Hanyang Univ, Dept Transportat & Logist Engn, Ansan, South Korea.
   [Lee, Young-Joo] Ulsan Natl Inst Sci & Technol Ulsan, Dept Urban & Environm Engn, Ulsan, South Korea.
C3 University of Illinois System; University of Illinois Urbana-Champaign; Hanyang University; Ulsan National Institute of Science & Technology (UNIST)
RP Lee, YJ (corresponding author), Ulsan Natl Inst Sci & Technol Ulsan, Dept Urban & Environm Engn, Ulsan, South Korea.
EM ylee@unist.ac.kr
FU Construction technology research program - Ministry of Land, Infrastructure and Transport of Korean government [21SCIP-B146959-04]; UNIST (Ulsan National Institute of Science and Technology) [1.210045.01]
CR Achillopoulou DV, 2020, SCI TOTAL ENVIRON, V746, P0, DOI 10.1016/j.scitotenv.2020.141001
   Alipour A, 2016, J STRUCT ENG, V142, P0, DOI 10.1061/(ASCE)ST.1943-541X.0001399
   [Anonymous], 1945, NATURE, V156, P371
   Applied Technology Council, 1985, ATC13, V0, P0
   Argyroudis SA, 2021, INT J DISASTER RESIL, V12, P209, DOI 10.1108/IJDRBE-02-2020-0014
   Ayyub BM, 2014, RISK ANAL, V34, P340, DOI 10.1111/risa.12093
   Baker J.W., 2013, INTRO PROBABILISTIC, V2.0.1, P79
   Bocchini P, 2012, BRIDGE MAINTENANCE, V0, P0
   Bocchini P, 2012, EARTHQ SPECTRA, V28, P427, DOI 10.1193/1.4000019
   Boore DM, 2003, B SEISMOL SOC AM, V93, P2737, DOI 10.1785/0120020197
   Chang L, 2010, THESIS GRADUATE COLL, V0, P0
   Choi CH, 2007, TRANSPORT RES REC, V0, PP92, DOI 10.3141/1996-12
   Cimellaro GP, 2010, STRUCT INFRASTRUCT E, V6, P127, DOI 10.1080/15732470802663847
   Daniels G, 2000, TRANSPORT RES REC, V0, P70
   Deco A, 2013, EARTHQ ENG STRUCT D, V42, P1469, DOI 10.1002/eqe.2282
   Emolo A, 2015, B SEISMOL SOC AM, V105, P2625, DOI 10.1785/0120140296
   Farzam A, 2018, GEOMAT NAT HAZ RISK, V9, P589, DOI 10.1080/19475705.2018.1466731
   Federal Emergency Management Agency FEMA, 2003, MULT LOSS EST METH E, V0, P0
   Florian D., 2014, EMME 4 OVERVIEW NEW, V0, P0
   Goda K, 2008, B SEISMOL SOC AM, V98, P354, DOI 10.1785/0120070078
   Islam MA, 2021, GEOMAT NAT HAZ RISK, V12, P279, DOI 10.1080/19475705.2020.1870169
   JOYNER WB, 1993, B SEISMOL SOC AM, V83, P469
   Kim Y-S., 2008, SEISMIC LOSS ASSESSM, V0, P1940
   Lee YJ, 2011, STRUCT INFRASTRUCT E, V7, P509, DOI 10.1080/15732479.2010.493338
   Liu YH, 2019, GEOMAT NAT HAZ RISK, V10, P958, DOI 10.1080/19475705.2018.1524400
   Loperte S, 2019, GEOMAT NAT HAZ RISK, V10, P873, DOI 10.1080/19475705.2018.1550113
   Mackie KR, 2006, EARTHQ ENG STRUCT D, V35, P77, DOI 10.1002/eqe.534
   Masoomi H, 2020, J STRUCT ENG, V146, P0, DOI 10.1061/(ASCE)ST.1943-541X.0002555
   Mebarki A, 2016, GEOMAT NAT HAZ RISK, V7, P5, DOI 10.1080/19475705.2016.1181458
   Misra S, 2020, EARTHQ SPECTRA, V36, P983, DOI 10.1177/8755293019891722
   Mitoulis SA, 2021, ENG STRUCT, V238, P0, DOI 10.1016/j.engstruct.2021.112180
   Murachi Y., 2003, SMART STRUCTURES MAT, V0, P0
   Nuti C., 2009, SAFETY RELIABILITY R, V0, P0
   Nuti C, 2007, EARTHQ ENG STRUCT D, V36, P245, DOI 10.1002/eqe.622
   Ouyang M, 2015, RELIAB ENG SYST SAFE, V141, P74, DOI 10.1016/j.ress.2015.03.011
   Padgett JE, 2007, EARTHQ SPECTRA, V23, P115, DOI 10.1193/1.2431209
   Parvez IA, 2013, GEOMAT NAT HAZ RISK, V4, P299, DOI 10.1080/19475705.2012.731659
   Poljansek K, 2012, EARTHQ ENG STRUCT D, V41, P61, DOI 10.1002/eqe.1118
   Porter KA., 2004, SURVEY BRIDGE PRACTI, V0, P0
   Rokneddin K, 2013, STRUCT INFRASTRUCT E, V9, P1050, DOI 10.1080/15732479.2011.654230
   Sanchez-Silva M, 2005, TRANSPORT RES B-METH, V39, P47, DOI 10.1016/j.trb.2004.03.002
   Shafieezadeh A, 2014, RELIAB ENG SYST SAFE, V132, P207, DOI 10.1016/j.ress.2014.07.021
   Sharma S, 2011, ENVIRON PLANN B, V38, P520, DOI 10.1068/b37018
   Sharma TA., 2020, COMPUTER AIDED CIVIL, V0, P0
   Shinozuka M, 2003, EARTHQ ENG ENG VIB, V2, P169, DOI 10.1007/s11803-003-0001-0
   Statistics Korea, 2016, RES 2015 POP HOUS CE, V0, P0
   Tak HY, 2019, MATH PROBL ENG, V2019, P0, DOI 10.1155/2019/6503616
   Wagener T, 2016, SOIL DYN EARTHQ ENG, V85, P166, DOI 10.1016/j.soildyn.2016.03.016
   Yoon S, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10186476
   Yoon S, 2020, STRUCT ENG MECH, V73, P339, DOI 10.12989/sem.2020.73.3.339
   Yoon S, 2019, INT J PRES VES PIP, V175, P0, DOI 10.1016/j.ijpvp.2019.103932
   Yoon S, 2018, INT J DISAST RISK RE, V31, P983, DOI 10.1016/j.ijdrr.2018.09.002
   Zhang WL, 2017, STRUCT INFRASTRUCT E, V13, P1404, DOI 10.1080/15732479.2016.1271813
NR 53
TC 0
Z9 0
U1 4
U2 21
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1947-5705
EI 1947-5713
J9 GEOMAT NAT HAZ RISK
JI Geomat. Nat. Hazards Risk
PD JAN 1
PY 2021
VL 12
IS 1
BP 2629
EP 2653
DI 10.1080/19475705.2021.1961881
PG 25
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources
SC Geology; Meteorology & Atmospheric Sciences; Water Resources
GA UM4WX
UT WOS:000693333300001
DA 2023-04-26
ER

PT J
AU Wong, PY
   Lee, HY
   Chen, YC
   Zeng, YT
   Chern, YR
   Chen, NT
   Lung, SCC
   Su, HJ
   Wu, CD
AF Wong, Pei-Yi
   Lee, Hsiao-Yun
   Chen, Yu-Cheng
   Zeng, Yu-Ting
   Chern, Yinq-Rong
   Chen, Nai-Tzu
   Lung, Shih-Chun Candice
   Su, Huey-Jen
   Wu, Chih-Da
TI Using a land use regression model with machine learning to estimate ground level PM2.5
SO ENVIRONMENTAL POLLUTION
LA English
DT Article
DE PM2.5; Land-use regression; Variable selection; Machine learning; Extreme gradient boosting
ID air-pollution; no2 exposure; china; pm10; particles; impact; areas; mass
AB Ambient fine particulate matter (PM2.5) has been ranked as the sixth leading risk factor globally for death and disability. Modelling methods based on having access to a limited number of monitor stations are required for capturing PM2.5 spatial and temporal continuous variations with a sufficient resolution. This study utilized a land use regression (LUR) model with machine learning to assess the spatial-temporal variability of PM2.5. Daily average PM2.5 data was collected from 73 fixed air quality monitoring stations that belonged to the Taiwan EPA on the main island of Taiwan. Nearly 280,000 observations from 2006 to 2016 were used for the analysis. Several datasets were collected to determine spatial predictor variables, including the EPA environmental resources dataset, a meteorological dataset, a land-use inventory, a landmark dataset, a digital road network map, a digital terrain model, MODIS Normalized Difference Vegetation Index (NDVI) database, and a power plant distribution dataset. First, conventional LUR and Hybrid Kriging-LUR were utilized to identify the important predictor variables. Then, deep neural network, random forest, and XGBoost algorithms were used to fit the prediction model based on the variables selected by the LUR models. Data splitting, 10-fold cross validation, external data verification, and seasonal-based and county-based validation methods were used to verify the robustness of the developed models. The results demonstrated that the proposed conventional LUR and Hybrid Kriging-LUR models captured 58% and 89% of PM2.5 variations, respectively. When XGBoost algorithm was incorporated, the explanatory power of the models increased to 73% and 94%, respectively. The Hybrid Kriging-LUR with XGBoost algorithm outperformed the other integrated methods. This study demonstrates the value of combining Hybrid Kriging-LUR model and an XGBoost algorithm for estimating the spatial-temporal variability of PM2.5 exposures. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Wong, Pei-Yi; Su, Huey-Jen] Natl Cheng Kung Univ, Dept Environm & Occupat Hlth, Tainan, Taiwan.
   [Lee, Hsiao-Yun] Natl Taipei Univ Nursing & Hlth Sci, Dept Leisure Ind & Hlth Promot, Taipei, Taiwan.
   [Chen, Yu-Cheng; Wu, Chih-Da] Natl Hlth Res Inst, Natl Inst Environm Hlth Sci, Miaoli, Taiwan.
   [Zeng, Yu-Ting; Chern, Yinq-Rong; Wu, Chih-Da] Natl Cheng Kung Univ, Dept Geomat, 1 Univ Rd, Tainan 701, Taiwan.
   [Chen, Nai-Tzu] Natl Cheng Kung Univ, Res Ctr Environm Trace Tox Subst, Tainan, Taiwan.
   [Lung, Shih-Chun Candice] Acad Sinica, Res Ctr Environm Changes, Taipei, Taiwan.
   [Lung, Shih-Chun Candice] Natl Taiwan Univ, Dept Atmospher Sci, Taipei, Taiwan.
   [Lung, Shih-Chun Candice] Natl Taiwan Univ, Inst Environm Hlth, Taipei, Taiwan.
C3 National Cheng Kung University; National Taipei University of Nursing & Health Science (NTUNHS); National Health Research Institutes - Taiwan; National Cheng Kung University; National Cheng Kung University; Academia Sinica - Taiwan; National Taiwan University; National Taiwan University
RP Wu, CD (corresponding author), Natl Cheng Kung Univ, Dept Geomat, 1 Univ Rd, Tainan 701, Taiwan.
EM chidawu@mail.ncku.edu.tw
FU Ministry of Science and Technology, R.O.C. [MOST 108-2621-M-006-017 -]; Academia Sinica, Taiwan [ASeSSe110-02]
CR Araki S, 2018, SCI TOTAL ENVIRON, V634, P1269, DOI 10.1016/j.scitotenv.2018.03.324
   Bai W, 2020, ENVIRON RES, V185, P0, DOI 10.1016/j.envres.2020.109471
   Beelen R, 2013, ATMOS ENVIRON, V72, P10, DOI 10.1016/j.atmosenv.2013.02.037
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chang S.Y., 2007, LONG RANGE TRANSPORT, V0, P0
   Chen GB, 2018, SCI TOTAL ENVIRON, V636, P52, DOI 10.1016/j.scitotenv.2018.04.251
   Chen J, 2019, ENVIRON INT, V130, P0, DOI 10.1016/j.envint.2019.104934
   Chen KS, 2004, J AIR WASTE MANAGE, V54, P36, DOI 10.1080/10473289.2004.10470880
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Chen TH, 2020, ENVIRON POLLUT, V259, P0, DOI 10.1016/j.envpol.2019.113875
   Chow JC, 2006, J AIR WASTE MANAGE, V56, P1368, DOI 10.1080/10473289.2006.10464545
   Collobert R., 2008, P 25 INT C MACHINE L, V0, P0
   Di Q, 2019, ENVIRON INT, V130, P0, DOI 10.1016/j.envint.2019.104909
   Didan K., 2015, MODIS VEGETATION IND, V0, P1
   Eeftens M, 2012, ENVIRON SCI TECHNOL, V46, P11195, DOI 10.1021/es301948k
   Forouzanfar MH, 2016, LANCET, V388, P1659, DOI 10.1016/S0140-6736(16)31679-8
   Friedman B, 2018, ATMOS ENVIRON, V187, P335, DOI 10.1016/j.atmosenv.2018.06.003
   Hellack B, 2017, ATMOS ENVIRON, V171, P181, DOI 10.1016/j.atmosenv.2017.10.017
   Hu XF, 2017, ENVIRON SCI TECHNOL, V51, P6936, DOI 10.1021/acs.est.7b01210
   Huang L, 2017, ENVIRON RES, V158, P542, DOI 10.1016/j.envres.2017.07.010
   Joharestani MZ, 2019, ATMOSPHERE-BASEL, V10, P0, DOI 10.3390/atmos10070373
   Kammer J, 2018, SCI TOTAL ENVIRON, V621, P1084, DOI 10.1016/j.scitotenv.2017.10.118
   Kim KH, 2015, ENVIRON INT, V74, P136, DOI 10.1016/j.envint.2014.10.005
   Kioumourtzoglou MA, 2016, ENVIRON HEALTH PERSP, V124, P23, DOI 10.1289/ehp.1408973
   Knibbs LD, 2018, ENVIRON SCI TECHNOL, V52, P12445, DOI 10.1021/acs.est.8b02328
   Lee CS, 2018, ENVIRON SCI POLLUT R, V25, P22136, DOI 10.1007/s11356-018-2273-y
   Lee SC, 2004, ATMOS ENVIRON, V38, P941, DOI 10.1016/j.atmosenv.2003.11.002
   Li LF, 2013, ATMOS ENVIRON, V71, P54, DOI 10.1016/j.atmosenv.2013.01.038
   Lin CY, 2005, ATMOS ENVIRON, V39, P6066, DOI 10.1016/j.atmosenv.2005.06.046
   Mohamed AR, 2011, INT CONF ACOUST SPEE, V0, P5060
   Motc, 2020, VEH STAT, V0, P0
   Nowak David J., 2006, URBAN FORESTRY & URBAN GREENING, V5, P93, DOI 10.1016/j.ufug.2006.04.002
   Saebo A, 2012, SCI TOTAL ENVIRON, V427, P347, DOI 10.1016/j.scitotenv.2012.03.084
   Sayer AM, 2013, J GEOPHYS RES-ATMOS, V118, P7864, DOI 10.1002/jgrd.50600
   Shtein A, 2020, ENVIRON SCI TECHNOL, V54, P120, DOI 10.1021/acs.est.9b04279
   Simpraga M, 2019, EUR J FOREST RES, V138, P763, DOI 10.1007/s10342-019-01213-2
   Srimuruganandam B, 2012, SCI TOTAL ENVIRON, V433, P8, DOI 10.1016/j.scitotenv.2012.05.082
   Stafoggia M, 2019, ENVIRON INT, V124, P170, DOI 10.1016/j.envint.2019.01.016
   TWEPA, 2020, INTR CENTR MON SENS, V0, P0
   Weichenthal S, 2016, ENVIRON RES, V146, P65, DOI 10.1016/j.envres.2015.12.016
   Wu CD, 2018, SCI TOTAL ENVIRON, V645, P1456, DOI 10.1016/j.scitotenv.2018.07.073
   Wu CD, 2017, ENVIRON POLLUT, V224, P148, DOI 10.1016/j.envpol.2017.01.074
   Xu H, 2019, SCI TOTAL ENVIRON, V655, P423, DOI 10.1016/j.scitotenv.2018.11.125
   Yang DY, 2018, STOCH ENV RES RISK A, V32, P2445, DOI 10.1007/s00477-017-1497-6
   Yin S, 2011, ENVIRON POLLUT, V159, P2155, DOI 10.1016/j.envpol.2011.03.009
   Young MT, 2016, ENVIRON SCI TECHNOL, V50, P3686, DOI 10.1021/acs.est.5b05099
   Yu KP, 2015, BUILD ENVIRON, V93, P258, DOI 10.1016/j.buildenv.2015.06.024
   Zhan Y, 2017, ATMOS ENVIRON, V155, P129, DOI 10.1016/j.atmosenv.2017.02.023
   Zhang CY, 2015, IEEE T SUSTAIN ENERG, V6, P1416, DOI 10.1109/TSTE.2015.2434387
   Zhang ZY, 2018, ATMOS ENVIRON, V192, P48, DOI 10.1016/j.atmosenv.2018.08.046
   Zou B, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010001
NR 52
TC 35
Z9 36
U1 14
U2 109
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0269-7491
EI 1873-6424
J9 ENVIRON POLLUT
JI Environ. Pollut.
PD MAY 15
PY 2021
VL 277
IS 
BP 
EP 
DI 10.1016/j.envpol.2021.116846
EA MAR 2021
PG 10
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA RJ6VA
UT WOS:000637737100053
PM 33735646
DA 2023-04-26
ER

PT J
AU Zuo, YF
   Fang, YM
   An, P
   Shang, XW
   Yang, JN
AF Zuo, Yifan
   Fang, Yuming
   An, Ping
   Shang, Xiwu
   Yang, Junnan
TI Frequency-Dependent Depth Map Enhancement via Iterative Depth-Guided Affine Transformation and Intensity-Guided Refinement
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Color; Image edge detection; Image resolution; Optimization; Robustness; Encoding; Dictionaries; Intensity-guided depth map enhancement; depth-guided intensity image filtering; deep convolutional neual network; residual learning; dense connection
ID superresolution; recovery
AB Recently, deep convolutional neural network sho-ws significant improvement for intensity-guided depth map enhancement. The most networks focus on either increasing depth or easing features propagation via residual learning and dense connection. However, it has not been explicitly considered yet to mitigate the artifacts caused by the differences of the distributions between the depth map and the corresponding color image, e.g., edge misalignment. In this paper, a novel depth-guided affine transformation is used to filter out the unrelated intensity features, which is further used to refine the depth features. Since the quality of initial depth features is low, the depth-guided intensity features filtering and the intensity-guided depth features refinement are iteratively performed, which progressively promotes effects of such tasks. To make full use of the iterations, all the refined depth features are dense connected followed by a 1 x 1 convolution layer. In addition, to improve the performance in the case of large upsampling factors (e.g., 16x), the depth features are enhanced from coarse to fine. In each frequency-dependent refinement of the depth features, the above iterative subnetwork as well as the residual learning are introduced. The proposed method is tested for the noise-free and noisy cases which compares against 16 state-of-the-art methods. Our experimental results show the improved performances based on the qualitative and quantitative evaluations.
C1 [Zuo, Yifan; Fang, Yuming] Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang 330013, Jiangxi, Peoples R China.
   [An, Ping] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Shang, Xiwu] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
   [Yang, Junnan] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia.
C3 Jiangxi University of Finance & Economics; Shanghai University; Shanghai University of Engineering Science; University of Technology Sydney
RP Fang, YM (corresponding author), Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang 330013, Jiangxi, Peoples R China.
EM kenny0410@126.com; leo.fangyuming@foxmail.com; anping@shu.edu.cn; dxsxw@126.com; junnan.yang@student.uts.edu.au
FU "2030 Megaproject" New Generation Artificial Intelligence [2018AAA0100601]; National Natural Science Foundation of China [61901197, 61822109]; Natural Science Foundation of Jiangxi Province [20192BAB217005, 20181BBH80002]; Foundation of Jiangxi Provincial Department of Education [GJJ190288]; Jiangxi province postdoctoral research projects [9KY52]; Double Thousand Plan of Jiangxi Province
CR Bose NK, 2006, IEEE T IMAGE PROCESS, V15, P2239, DOI 10.1109/TIP.2006.877406
   Chen BL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P1473
   Choi O, 2014, IEEE T IMAGE PROCESS, V23, P3321, DOI 10.1109/TIP.2014.2329766
   Deng Xin, 2019, IEEE T CIRCUITS SYST, V0, P0
   Diebel J., 2005, P ADV NEUR INF PROC, V18, P291
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2017, IEEE T MULTIMEDIA, V19, P293, DOI 10.1109/TMM.2016.2613824
   Ferstl D, 2015, IEEE I CONF COMP VIS, V0, PP513, DOI 10.1109/ICCV.2015.66
   Ferstl D, 2013, IEEE I CONF COMP VIS, V0, PP993, DOI 10.1109/ICCV.2013.127
   Garcia F, 2012, IEEE J-STSP, V6, P425, DOI 10.1109/JSTSP.2012.2207090
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hua KL, 2016, IEEE MULTIMEDIA, V23, P72, DOI 10.1109/MMUL.2015.52
   Huang LQ, 2019, IEEE SIGNAL PROC LET, V26, P1723, DOI 10.1109/LSP.2019.2944646
   Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Kiechle M, 2013, IEEE I CONF COMP VIS, V0, PP1545, DOI 10.1109/ICCV.2013.195
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Kopf J, 2007, ACM T GRAPHIC, V26, P0, DOI 10.1145/1239451.1239547
   Kwon H, 2015, PROC CVPR IEEE, V0, PP159, DOI 10.1109/CVPR.2015.7298611
   Li Y, 2016, LECT NOTES COMPUT SC, V9907, P717, DOI 10.1007/978-3-319-46487-9_44
   Liu MY, 2013, PROC CVPR IEEE, V0, PP169, DOI 10.1109/CVPR.2013.29
   Liu W, 2017, IEEE T IMAGE PROCESS, V26, P0, DOI 10.1109/TIP.2016.2612826
   Liu XM, 2019, IEEE T IMAGE PROCESS, V28, P1636, DOI 10.1109/TIP.2018.2875506
   Lo KH, 2018, IEEE T CYBERNETICS, V48, P371, DOI 10.1109/TCYB.2016.2637661
   Mayer N, 2016, PROC CVPR IEEE, V0, PP4040, DOI 10.1109/CVPR.2016.438
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Park J, 2014, IEEE T IMAGE PROCESS, V23, P5559, DOI 10.1109/TIP.2014.2361034
   Riegler G., 2016, P BRIT MACH VIS C, V0, P0
   Riegler G, 2016, LECT NOTES COMPUT SC, V9907, P268, DOI 10.1007/978-3-319-46487-9_17
   Song WF, 2020, IEEE T MULTIMEDIA, V22, P1220, DOI 10.1109/TMM.2019.2941776
   Song XB, 2019, IEEE T CIRC SYST VID, V29, P2323, DOI 10.1109/TCSVT.2018.2866399
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Wang ZF, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON FLUID POWER AND MECHATRONICS - FPM 2015, V0, PP370, DOI 10.1109/FPM.2015.7337142
   Wen Y, 2019, IEEE T IMAGE PROCESS, V28, P994, DOI 10.1109/TIP.2018.2874285
   Wu HY, 2007, IEEE I CONF COMP VIS, V0, PP628, DOI 10.1109/cvpr.2007.383211
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Yang JY, 2019, IEEE T BROADCAST, V65, P123, DOI 10.1109/TBC.2018.2818405
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yanjie Li, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), V0, PP152, DOI 10.1109/ICME.2012.30
   Yin B., 2019, IEEE T MULTIMEDIA, V0, P0
   Zbontar J, 2015, PROC CVPR IEEE, V0, PP1592, DOI 10.1109/CVPR.2015.7298767
   Zhang YB, 2020, IEEE T CIRC SYST VID, V30, P320, DOI 10.1109/TCSVT.2018.2890574
   Zuo Y, 2017, IEEE INT CON MULTI, V0, PP211, DOI 10.1109/ICME.2017.8019366
   Zuo Y., 2016, P IEEE INT C MULT EX, V0, P1
   Zuo YF, 2020, IEEE T CIRC SYST VID, V30, P297, DOI 10.1109/TCSVT.2018.2890271
   Zuo YF, 2019, INFORM SCIENCES, V495, P52, DOI 10.1016/j.ins.2019.05.003
   Zuo YF, 2018, IEEE T IMAGE PROCESS, V27, P4145, DOI 10.1109/TIP.2018.2828335
   Zuo YF, 2018, IEEE T CIRC SYST VID, V28, P439, DOI 10.1109/TCSVT.2016.2609438
NR 53
TC 6
Z9 7
U1 1
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUN 15
PY 2021
VL 23
IS 
BP 772
EP 783
DI 10.1109/TMM.2020.2987706
PG 12
WC Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications
SC Computer Science; Telecommunications
GA QI9PL
UT WOS:000619321200003
DA 2023-04-26
ER

PT J
AU Yang, R
   Pan, ZR
   Jia, XX
   Zhang, L
   Deng, YK
AF Yang, Rong
   Pan, Zhenru
   Jia, Xiaoxue
   Zhang, Lei
   Deng, Yunkai
TI A Novel CNN-Based Detector for Ship Detection Based on Rotatable Bounding Box in SAR Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Neural network; rotatable bounding box (RBox); synthetic aperture radar; target detection
ID convolutional neural-networks; synthetic-aperture radar; automatic ship; targets
AB Thanks to the excellent feature representation capabilities of neural networks, deep learning-based methods perform far better than traditional methods on target detection tasks such as ship detection. Although various network models have been proposed for SAR ship detection such as DRBox-v1, DRBox-v2, and MSR2N, there are still some problems such as mismatch of feature scale, contradictions between different learning tasks, and unbalanced distribution of positive samples, which have not been mentioned in these studies. In this article, an improved one-stage object detection framework based on RetinaNet and rotatable bounding box (RBox), which is referred as R-RetinaNet, is proposed to solve the above problems. The main improvements of R-RetinaNet as well as the contributions of this article are threefold. First, a scale calibration method is proposed to align the scale distribution of the output backbone feature map with the scale distribution of the targets. Second, a feature fusion network based on task-wise attention feature pyramid network is designed to decouple the feature optimization process of different tasks, which alleviates the conflict between different learning goals. Finally, an adaptive intersection over union (IoU) threshold training method is proposed for RBox-based model to correct the unbalanced distribution of positive samples caused by the fixed IoU threshold on RBox. Experimental results show that our method obtains 13.26%, 9.49%, 8.92%, and 4.55% gains in average precision under an IoU threshold of 0.5 on the public SAR ship detection dataset compared with four state-of-the-art RBox-based methods, respectively.
C1 [Yang, Rong; Pan, Zhenru; Jia, Xiaoxue; Zhang, Lei; Deng, Yunkai] Chinese Acad Sci, Aerosp Informat Res Inst, Dept Space Microwave Remote Sensing Syst, Beijing 100190, Peoples R China.
   [Yang, Rong; Pan, Zhenru] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 101408, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Jia, XX (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Dept Space Microwave Remote Sensing Syst, Beijing 100190, Peoples R China.
EM yangrong16@mails.ucas.ac.cn; panzhenru16@mails.ucas.ac.cn; xiaoxue_snowing@163.com; 314forever@163.com; ykdeng@mail.ie.ac.cn
FU National Natural Science Foundation of China [61901446]
CR An QZ, 2019, IEEE T GEOSCI REMOTE, V57, P8333, DOI 10.1109/TGRS.2019.2920534
   An QZ, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18020334
   [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   Ao W, 2018, IEEE J-STARS, V11, P536, DOI 10.1109/JSTARS.2017.2787573
   Brusch S, 2011, IEEE T GEOSCI REMOTE, V49, P1092, DOI 10.1109/TGRS.2010.2071879
   Chen C, 2019, IEEE ACCESS, V7, P104848, DOI 10.1109/ACCESS.2019.2930939
   Chen J, 2009, IEEE GEOSCI REMOTE S, V6, P723, DOI 10.1109/LGRS.2009.2024224
   Crisp D. J, 2004, TECH REP DSTO RR 027, V0, P0
   Cui ZY, 2019, IEEE T GEOSCI REMOTE, V57, P8983, DOI 10.1109/TGRS.2019.2923988
   Deng ZP, 2019, IEEE T GEOSCI REMOTE, V57, P4021, DOI 10.1109/TGRS.2018.2889353
   Eldhuset K, 1996, IEEE T GEOSCI REMOTE, V34, P1010, DOI 10.1109/36.508418
   Fan WW, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232862
   Ferrara G, 2011, IEEE J OCEANIC ENG, V36, P195, DOI 10.1109/JOE.2011.2109491
   Gao G, 2017, IEEE T GEOSCI REMOTE, V55, P1812, DOI 10.1109/TGRS.2016.2634862
   Gao G, 2016, IEEE T GEOSCI REMOTE, V54, P4302, DOI 10.1109/TGRS.2016.2539200
   Gheradi, 2010, P 3 INT WORKSH ESRIN, V679, P32
   Guanglu Song, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP11560, DOI 10.1109/CVPR42600.2020.01158
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Jiang Y., 2017, ARXIV 1706 09579, V0, P0
   Jiao J, 2018, IEEE ACCESS, V6, P20881, DOI 10.1109/ACCESS.2018.2825376
   Kang M., 2017, 2017 INT WORKSHOP RE, V0, PP1, DOI 10.1109/RSIP.2017.7958815
   Leng XG, 2017, INT GEOSCI REMOTE SE, V0, P1876
   Leng XG, 2018, IEEE J-STARS, V11, P2376, DOI 10.1109/JSTARS.2018.2820078
   Li J, 2017, 2018 IEEE INT C ACOU, V0, PP1, DOI 10.1109/BIGSARDATA.2017.8124934
   Li JA, 1996, IEEE T AERO ELEC SYS, V32, P613, DOI 10.1109/7.489506
   Li T, 2018, IEEE J-STARS, V11, P184, DOI 10.1109/JSTARS.2017.2764506
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin Z, 2019, IEEE GEOSCI REMOTE S, V16, P751, DOI 10.1109/LGRS.2018.2882551
   Marino A, 2015, REMOTE SENS-BASEL, V7, P5416, DOI 10.3390/rs70505416
   Marino A, 2010, INT GEOSCI REMOTE SE, V0, PP3704, DOI 10.1109/IGARSS.2010.5651362
   Nunziata F, 2012, IEEE J OCEANIC ENG, V37, P384, DOI 10.1109/JOE.2012.2198931
   Pan ZR, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20082340
   Pelich R, 2015, IEEE J-STARS, V8, P3892, DOI 10.1109/JSTARS.2014.2319195
   Pichel W.G., 2004, SYNTHETIC APERTURE R, V0, P277
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Renga A, 2019, IEEE T GEOSCI REMOTE, V57, P1463, DOI 10.1109/TGRS.2018.2866934
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Song SL, 2016, IEEE GEOSCI REMOTE S, V13, P319, DOI 10.1109/LGRS.2015.2510378
   Su H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060989
   [孙显 Sun Xian], 2019, 雷达学报 JOURNAL OF RADARS, V8, P852
   Touzi R, 2002, IEEE T GEOSCI REMOTE, V40, P2507, DOI 10.1109/TGRS.2002.805070
   Wackerman CC, 2001, CAN J REMOTE SENS, V27, P568, DOI 10.1080/07038992.2001.10854896
   Wang JZ, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18092851
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Wang YY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050531
   Wang YY, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18092929
   Wang YY, 2018, REMOTE SENS LETT, V9, P780, DOI 10.1080/2150704X.2018.1475770
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Wei SJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010167
   Yeremy M, 2001, CAN J REMOTE SENS, V27, P328, DOI 10.1080/07038992.2001.10854875
   Zhang S, 2018, PROC CVPR IEEE, V0, PP4203, DOI 10.1109/CVPR.2018.00442
   Zhang TW, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212483
   Zhang XH, 2019, IEEE ACCESS, V7, P141662, DOI 10.1109/ACCESS.2019.2943241
   Zhao JP, 2018, IEEE ACCESS, V6, P50693, DOI 10.1109/ACCESS.2018.2869289
   Zou Z., 2019, ARXIV 1905 05055, V0, P0
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P5832, DOI 10.1109/TGRS.2016.2572736
NR 59
TC 37
Z9 39
U1 13
U2 51
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1938
EP 1958
DI 10.1109/JSTARS.2021.3049851
PG 21
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QA6MJ
UT WOS:000613557400008
DA 2023-04-26
ER

PT J
AU Darabi, H
   Haghighi, AT
   Rahmati, O
   Shahrood, AJ
   Rouzbeh, S
   Pradhan, B
   Bui, DT
AF Darabi, Hamid
   Haghighi, Ali Torabi
   Rahmati, Omid
   Shahrood, Abolfazl Jalali
   Rouzbeh, Sajad
   Pradhan, Biswajeet
   Bui, Dieu Tien
TI A hybridized model based on neural network and swarm intelligence-grey wolf algorithm for spatial prediction of urban flood-inundation
SO JOURNAL OF HYDROLOGY
LA English
DT Article
DE Flood inundation; Flood inventory; GIS; NN-SGW model; Confusion matrix
ID random-forest; optimization algorithm; climate-change; tree models; susceptibility; scale; machine; vulnerability; impacts; city
AB In regions with lack of hydrological and hydraulic data, a spatial flood modeling and mapping is an opportunity for the urban authorities to predict the spatial distribution and the intensity of the flooding. It helps decision-makers to develop effective flood prevention and management plans. In this study, flood inventory data were prepared based on the historical and field surveys data by Sari municipality and regional water company of Mazandaran, Iran. The collected flood data accompanied with different variables (digital elevation model and slope have been considered as topographic variables, land use/land cover, precipitation, curve number, distance to river, distance to channel and depth to groundwater as environmental variables) were applied to novel hybridized model based on neural network and swarm intelligence-grey wolf algorithm (NN-SGW) to map flood-inundation. Several confusion matrix criteria were used for accuracy evaluation by cutoff-dependent and independent metrics (e.g., efficiency (E), positive predictive value (PPV), negative predictive value (NPV), area under the receiver operating characteristic curve (AUC)). The accuracy of the flood inundation map produced by the NN-SGW model was compared with that of maps produced by four state-of-the-art benchmark models: random forest (RF), logistic model tree (LMT), classification and regression trees (CART), and J48 decision tree (J48DT). The NN-SGW model outperformed all benchmark models in both training (E = 90.5%, PPV = 93.7%, NPV = 87.3%, AUC = 96.3%) and validation (E = 79.4%, PPV = 85.3%, NPV = 73.5%, AUC = 88.2%). As the NN-SGW model produced the most accurate flood-inundation map, it can be employed for robust flood contingency planning. Based on the obtained results from NN-SGW model, distance from channel, distance from river, and depth to groundwater were identified as the most important variables for spatial prediction of urban flood inundation. This work can serve as a basis for future studies seeking to predict flood susceptibility in urban areas using hybridized machine learning (ML) models and can also be applied in other urban areas where flood inundation presents a pressing challenge, and there are some problems regarding required model and availability of input data.
C1 [Darabi, Hamid; Haghighi, Ali Torabi; Shahrood, Abolfazl Jalali] Univ Oulu, Water Energy & Environm Engn Res Unit, POB 4300, FIN-90014 Oulu, Finland.
   [Rahmati, Omid] AREEO, Kurdistan Agr & Nat Resources Res & Educ Ctr, Soil Conservat & Watershed Management Res Dept, Sanandaj, Iran.
   [Rouzbeh, Sajad] Sari Agr Sci & Nat Resources Univ, Dept Watershed Management, POB 737, Sari, Iran.
   [Pradhan, Biswajeet] Univ Technol Sydney, Fac Engn & Informat Technol, Ctr Adv Modeling & Geospatial Informat Syst CAMGI, Sydney, NSW 2007, Australia.
   [Bui, Dieu Tien] Univ South Eastern Norway, Dept Business & IT, GIS Grp, Gullbringvegen 36, N-3800 Bo Telemark, Norway.
   [Pradhan, Biswajeet] Sejong Univ, Dept Energy & Mineral Resources Engn, 209 Neungdong Ro, Seoul 05006, South Korea.
   [Pradhan, Biswajeet] Univ Kebangsaan Malaysia, Inst Climate Change, Earth Observat Ctr, Ukm 43600, Bangi Selangor, Malaysia.
C3 University of Oulu; Sari Agricultural Sciences & Natural Resources University (SANRU); University of Technology Sydney; Sejong University; Universiti Kebangsaan Malaysia
RP Darabi, H (corresponding author), Univ Oulu, Water Energy & Environm Engn Res Unit, POB 4300, FIN-90014 Oulu, Finland.; Pradhan, B (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, Ctr Adv Modeling & Geospatial Informat Syst CAMGI, Sydney, NSW 2007, Australia.; Bui, DT (corresponding author), Univ South Eastern Norway, Dept Business & IT, GIS Grp, Gullbringvegen 36, N-3800 Bo Telemark, Norway.
EM Hamid.darabi@oulu.fi; Biswajeet.Pradhan@uts.edu.au; dieu.t.bui@usn.no
FU Maa-ja vesitekniikan tuki r.y. (MVTT)
CR Abdi K., 2019, PHYS GEOGRAPHY RES Q, V51, P431, DOI 10.22059/jphgr.2019.272801.1007324
   Abily M, 2016, ENVIRON MODELL SOFTW, V77, P183, DOI 10.1016/j.envsoft.2015.12.002
   Ahmad AS, 2014, RENEW SUST ENERG REV, V33, P102, DOI 10.1016/j.rser.2014.01.069
   Ahmadisharaf E, 2016, J ENVIRON PLANN MAN, V59, P1397, DOI 10.1080/09640568.2015.1077104
   Andaryani S, 2021, J ENVIRON MANAGE, V291, P0, DOI 10.1016/j.jenvman.2021.112731
   [Anonymous], 2005, URBAN WATER J, V0, P0, DOI DOI 10.1080/15730620500386529
   Arabameri A, 2020, GEOSCI FRONT, V11, P1609, DOI 10.1016/j.gsf.2019.11.009
   Arani BO, 2013, SWARM EVOL COMPUT, V11, P1, DOI 10.1016/j.swevo.2012.12.004
   Ashley ST, 2008, J APPL METEOROL CLIM, V47, P805, DOI 10.1175/2007JAMC1611.1
   Pham BT, 2017, GEOTECH GEOL ENG, V35, P2597, DOI 10.1007/s10706-017-0264-2
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 2017, CLASSIFICATION REGRE, V1st, P0
   Chang H, 2010, ANN ASSOC AM GEOGR, V100, P938, DOI 10.1080/00045608.2010.497110
   Chen J, 2009, J HYDROL, V373, P184, DOI 10.1016/j.jhydrol.2009.04.021
   Chen S., 2020, ENERGY, V2, P0, DOI 10.1016/J.EGYAI.2020.100028
   Chen W, 2017, CATENA, V151, P147, DOI 10.1016/j.catena.2016.11.032
   Costabile P, 2020, J HYDROL, V580, P0, DOI 10.1016/j.jhydrol.2019.124231
   Cui H, 2019, PATTERN RECOGN LETT, V125, P828, DOI 10.1016/j.patrec.2019.02.009
   Daniel E, 2017, KNOWL-BASED SYST, V131, P58, DOI 10.1016/j.knosys.2017.05.017
   Darabi H, 2019, J HYDROL, V569, P142, DOI 10.1016/j.jhydrol.2018.12.002
   Deb K., 2012, OPTIMIZATION ENG DES, V2nd, P0
   Demolli H, 2019, ENERG CONVERS MANAGE, V198, P0, DOI 10.1016/j.enconman.2019.111823
   Di Baldassarre G, 2009, NAT HAZARDS, V50, P479, DOI 10.1007/s11069-009-9355-6
   Bui DT, 2019, CATENA, V179, P184, DOI 10.1016/j.catena.2019.04.009
   Dong BL, 2021, ADV WATER RESOUR, V147, P0, DOI 10.1016/j.advwatres.2020.103824
   Du SQ, 2015, NAT HAZARDS, V76, P1457, DOI 10.1007/s11069-014-1463-2
   Eini M, 2020, INT J DISAST RISK RE, V50, P0, DOI 10.1016/j.ijdrr.2020.101687
   Erdal HI, 2013, J HYDROL, V477, P119, DOI 10.1016/j.jhydrol.2012.11.015
   Falah F, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, V0, PP323, DOI 10.1016/B978-0-12-815226-3.00014-4
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Feng QL, 2015, WATER-SUI, V7, P1437, DOI 10.3390/w7041437
   Fernandez DS, 2010, ENG GEOL, V111, P90, DOI 10.1016/j.enggeo.2009.12.006
   Fewtrell TJ, 2008, HYDROL PROCESS, V22, P5107, DOI 10.1002/hyp.7148
   Fletcher MP, 2018, IJC HEART VASC, V20, P46, DOI 10.1016/j.ijcha.2018.03.005
   Frattini P, 2010, ENG GEOL, V111, P62, DOI 10.1016/j.enggeo.2009.12.004
   Glenis V, 2018, ENVIRON MODELL SOFTW, V109, P272, DOI 10.1016/j.envsoft.2018.07.018
   Guha D, 2016, ENG SCI TECHNOL, V19, P1693, DOI 10.1016/j.jestch.2016.07.004
   Gupta S, 2020, APPL SOFT COMPUT, V93, P0, DOI 10.1016/j.asoc.2020.106367
   Hallegatte S, 2011, CLIMATIC CHANGE, V104, P1, DOI 10.1007/s10584-010-9981-8
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hosseini FS, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.135161
   Howard K, 2018, J GREAT LAKES RES, V44, P1, DOI 10.1016/j.jglr.2017.11.012
   Hu P, 2020, KNOWL-BASED SYST, V195, P0, DOI 10.1016/j.knosys.2020.105746
   Javidrad F, 2017, APPL SOFT COMPUT, V60, P634, DOI 10.1016/j.asoc.2017.07.023
   Jayabarathi T, 2016, ENERGY, V111, P630, DOI 10.1016/j.energy.2016.05.105
   Jayaprakasam S, 2015, APPL SOFT COMPUT, V30, P229, DOI 10.1016/j.asoc.2015.01.024
   Jia WW, 2019, NEURAL NETWORKS, V119, P46, DOI 10.1016/j.neunet.2019.07.019
   Jonkman SN, 2008, J FLOOD RISK MANAG, V1, P43, DOI 10.1111/j.1753-318X.2008.00006.x
   Kim B, 2015, J HYDROL, V523, P680, DOI 10.1016/j.jhydrol.2015.01.059
   Komaki GM, 2015, J COMPUT SCI-NETH, V8, P109, DOI 10.1016/j.jocs.2015.03.011
   Landwehr N, 2003, LECT NOTES ARTIF INT, V2837, P241
   Lee S, 2018, EXPERT SYST APPL, V97, P137, DOI 10.1016/j.eswa.2017.12.014
   Lee S, 2017, GEOMAT NAT HAZ RISK, V8, P1185, DOI 10.1080/19475705.2017.1308971
   Liu D., 2020, J HYDROL, V597, P0, DOI 10.1016/j.jhydrol
   Liu JP, 2017, INTELL AUTOM SOFT CO, V23, P235, DOI 10.1080/10798587.2016.1196926
   Long W, 2016, ADV INTEL SYS RES, V136, P643
   Madsen AL, 2017, KNOWL-BASED SYST, V117, P46, DOI 10.1016/j.knosys.2016.07.031
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Majumder P, 2020, WATER RESOUR MANAG, V34, P763, DOI 10.1007/s11269-019-02472-9
   Marchi L, 2010, J HYDROL, V394, P118, DOI 10.1016/j.jhydrol.2010.07.017
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mosa MA, 2019, KNOWL-BASED SYST, V163, P518, DOI 10.1016/j.knosys.2018.09.008
   Neumann B, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0118571
   Niu PF, 2019, KNOWL-BASED SYST, V171, P37, DOI 10.1016/j.knosys.2019.01.018
   Ouma YO, 2014, WATER-SUI, V6, P1515, DOI 10.3390/w6061515
   Panahi M, 2020, SCI TOTAL ENVIRON, V741, P0, DOI 10.1016/j.scitotenv.2020.139937
   Peyravi Mahmoudreza, 2019, BULL EMERG TRAUMA, V7, P199, DOI 10.29252/beat-070219
   Piotrowski AP, 2013, J HYDROL, V476, P97, DOI 10.1016/j.jhydrol.2012.10.019
   Pirnia A, 2019, J WATER CLIM CHANGE, V10, P725, DOI 10.2166/wcc.2018.162
   Pontius RG, 2001, AGR ECOSYST ENVIRON, V85, P239, DOI 10.1016/S0167-8809(01)00187-6
   Pourghasemi HR, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-60191-3
   Qasim T, 2019, PATTERN RECOGN LETT, V128, P220, DOI 10.1016/j.patrec.2019.09.003
   Rahmati O, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-69703-7
   Rahmati O, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11112370
   Schmitt TG, 2004, J HYDROL, V299, P300, DOI 10.1016/S0022-1694(04)00374-9
   Schubert JE, 2012, ADV WATER RESOUR, V41, P49, DOI 10.1016/j.advwatres.2012.02.012
   Senel FA, 2019, ENG COMPUT-GERMANY, V35, P1359, DOI 10.1007/s00366-018-0668-5
   Sessarego M, 2020, RENEW ENERG, V146, P1524, DOI 10.1016/j.renene.2019.07.046
   Sharifinia Z, 2019, GEOGRAPHY ENV HAZARD, V8, P1
   Shirwaikar RD, 2019, ARTIF INTELL MED, V98, P59, DOI 10.1016/j.artmed.2019.07.008
   Tan K, 2020, J HAZARD MATER, V382, P0, DOI 10.1016/j.jhazmat.2019.120987
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Tikhamarine Y, 2020, J HYDROL, V582, P0, DOI 10.1016/j.jhydrol.2019.124435
   Torres MA, 2014, INT J RIVER BASIN MA, V12, P377, DOI 10.1080/15715124.2013.847844
   Wen H, 2019, ENERGY, V187, P0, DOI 10.1016/j.energy.2019.116106
   Xing JK, 2019, BIORESOURCE TECHNOL, V288, P0, DOI 10.1016/j.biortech.2019.121541
   Yagiura M., 2001, SYSTEMS AND COMPUTERS IN JAPAN, V32, P33, DOI 10.1002/1520-684X(200103)32:3<33::AID-SCJ4>3.0.CO;2-P
   Yang XS, 2014, EVOL INTELL, V7, P17, DOI 10.1007/s12065-013-0102-2
   Yu S, 2018, J HYDROL, V559, P156, DOI 10.1016/j.jhydrol.2018.02.033
   Zedadra O, 2018, J PARALLEL DISTR COM, V122, P173, DOI 10.1016/j.jpdc.2018.08.007
   Zhang YY, 2020, KNOWL-BASED SYST, V187, P0, DOI 10.1016/j.knosys.2019.07.007
   Zhao B, 2019, ENERGY, V185, P1032, DOI 10.1016/j.energy.2019.07.111
   Zhao G, 2018, SCI TOTAL ENVIRON, V615, P1133, DOI 10.1016/j.scitotenv.2017.10.037
   Zhao YN, 2016, GEOD GEODYN, V7, P348, DOI 10.1016/j.geog.2016.07.005
   Zhao YH, 2008, ADV SPACE RES, V41, P1955, DOI 10.1016/j.asr.2007.07.020
NR 96
TC 16
Z9 16
U1 10
U2 69
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0022-1694
EI 1879-2707
J9 J HYDROL
JI J. Hydrol.
PD DEC 15
PY 2021
VL 603
IS 
BP 
EP 
DI 10.1016/j.jhydrol.2021.126854
EA SEP 2021
PG 11
WC Engineering, Civil; Geosciences, Multidisciplinary; Water Resources
SC Engineering; Geology; Water Resources
GA WF4YZ
UT WOS:000706313000040
DA 2023-04-26
ER

PT J
AU Khennou, F
   Ghaoui, J
   Akhloufi, MA
AF Khennou, Fadoua
   Ghaoui, Jade
   Akhloufi, Moulay A.
TI Forest Fire Spread Prediction using Deep Learning
SO GEOSPATIAL INFORMATICS XI
LA English
DT Proceedings Paper
DE forest fires; deep learning; wildfire perimeters; satellite images; Digital Elevation Model; neural network; U-Net
AB Nowadays, we are facing a tremendous increase in the number of forest fires around the world. While in 2010, the world had 3.92Gha of forest cover, covering 30% of its land area, in 2019, there was a loss of forest cover of 24.2Mha according to the Global Forest Watch institute. These fires can take different forms depending on the characteristics of the vegetation and the climatic conditions in which they develop. To better manage this and reduce human, economic and environmental consequences, it is crucial to consider artificial intelligence as a mean to predict the new probable burned area. In this paper, we present FU-NetCast, a deep learning model based on U-Net, past wildfires events and weather data. Our approach uses an intelligent model to study forest fire spread over a period of 24 hours. The model achieved an accuracy of 92.73% and an AUC of 80% using 120 wildfire perimeters, satellite images, Digital Elevation Model maps and weather data.
C1 [Khennou, Fadoua; Ghaoui, Jade; Akhloufi, Moulay A.] Univ Moncton, Dept Comp Sci, Percept Robot & Intelligent Machines Res Grp PRIM, Moncton, NB, Canada.
C3 University of Moncton
RP Akhloufi, MA (corresponding author), Univ Moncton, Dept Comp Sci, Percept Robot & Intelligent Machines Res Grp PRIM, Moncton, NB, Canada.
EM moulay.akhloufi@umoncton.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC) [RGPIN-2018-06233]
CR Amol Dhumal Rashmi, 2020, ITM WEB OF CONFERENCES, V32, P0, DOI 10.1051/itmconf/20203203046
   Artes T, 2015, PROCEDIA COMPUT SCI, V51, P1623, DOI 10.1016/j.procs.2015.05.294
   Beaudoin A, 2014, CAN J FOREST RES, V44, P521, DOI 10.1139/cjfr-2013-0401
   Boer MM, 2020, NAT CLIM CHANGE, V10, P171, DOI 10.1038/s41558-020-0716-1
   Dhall A, 2020, APPL GEOGR, V121, P0, DOI 10.1016/j.apgeog.2020.102266
   Bui DT, 2018, ECOL INFORM, V48, P104, DOI 10.1016/j.ecoinf.2018.08.008
   Dubey Arun Kumar, 2019, APPLICATIONS OF COMPUTING, V0, P873, DOI 10.1007/978-981-13-6772-4_76
   Elia M, 2020, ENVIRON IMPACT ASSES, V85, P0, DOI 10.1016/j.eiar.2020.106474
   Karouni Ali, 2014, JOURNAL OF THEORETICAL AND APPLIED INFORMATION TECHNOLOGY, V63, P282
   Liu ZC, 2020, OPTIK, V223, P0, DOI 10.1016/j.ijleo.2020.165491
   Narayanaraj G, 2011, INT J WILDLAND FIRE, V20, P792, DOI 10.1071/WF10032
   Radke D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4575
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanjuan G, 2014, PROCEDIA COMPUT SCI, V29, P1535, DOI 10.1016/j.procs.2014.05.139
   Subramanian S. G., 2017, C REINF LEARN DEC MA, V0, P0
NR 18
TC 1
Z9 1
U1 5
U2 17
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
J9 PROC SPIE
PD JUN 15
PY 2021
VL 11733
IS 
BP 
EP 
DI 10.1117/12.2585997
PG 12
WC Computer Science, Information Systems; Remote Sensing; Optics; Imaging Science & Photographic Technology
SC Computer Science; Remote Sensing; Optics; Imaging Science & Photographic Technology
GA BS2VD
UT WOS:000706984300010
DA 2023-04-26
ER

PT J
AU Yuan, KH
   Zhuang, X
   Schaefer, G
   Feng, JX
   Guan, L
   Fang, H
AF Yuan, Kunhao
   Zhuang, Xu
   Schaefer, Gerald
   Feng, Jianxin
   Guan, Lin
   Fang, Hui
TI Deep-Learning-Based Multispectral Satellite Image Segmentation for Water Body Detection
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Image segmentation; Remote sensing; Indexes; Satellites; Vegetation mapping; Urban areas; Deep convolutional neural networks (DCNNs); feature fusion; multispectral remote sensing; semantic segmentation; water body detection
ID fully convolutional networks; semantic segmentation; neural-network; index ndwi; classification; extraction
AB Automated water body detection from satellite imagery is a fundamental stage for urban hydrological studies. In recent years, various deep convolutional neural network (DCNN)-based methods have been proposed to segment remote sensing data collected by conventional RGB or multispectral imagery for such studies. However, how to effectively explore the wider spectrum bands of multispectral sensors to achieve significantly better performance compared to the use of only RGB bands has been left underexplored. In this article, we propose a novel DCNN model-multichannel water body detection network (MC-WBDN)-that incorporates three innovative components, i.e., a multichannel fusion module, an Enhanced Atrous Spatial Pyramid Pooling module, and Space-to-Depth/Depth-to-Space operations, to outperform state-of-the-art DCNN-based water body detection methods. Experimental results convincingly show that our MC-WBDN model achieves remarkable water body detection performance, is more robust to light and weather variations, and can better distinguish tiny water bodies compared to other DCNN models.
C1 [Yuan, Kunhao; Zhuang, Xu] Chengdu Union Big Data Technol Co, Chengdu 610095, Peoples R China.
   [Yuan, Kunhao; Schaefer, Gerald; Guan, Lin; Fang, Hui] Loughborough Univ, Dept Comp Sci, Loughborough LE11 3TU, Leics, England.
   [Zhuang, Xu] Southwest Jiaotong Univ, Chengdu 611756, Peoples R China.
   [Feng, Jianxin] Dalian Univ, Informat Engn Coll, Dalian 116024, Peoples R China.
C3 Loughborough University; Southwest Jiaotong University; Dalian University
RP Feng, JX (corresponding author), Dalian Univ, Informat Engn Coll, Dalian 116024, Peoples R China.
EM k.yuan@lboro.ac.uk; zhuangxusc@gmail.com; gerald.schaefer@ieee.org; fengjianxin863@163.com; l.guan@lboro.ac.uk; h.fang@lboro.ac.uk
FU Government of Chengdu City
CR Ben Hamida A, 2017, INT GEOSCI REMOTE SE, V0, P2569
   Berman M, 2018, PROC CVPR IEEE, V0, PP4413, DOI 10.1109/CVPR.2018.00464
   Cai J., 2017, MEDICAL IMAGE COMPU, V0, P0
   Chan L, 2021, INT J COMPUT VISION, V129, P361, DOI 10.1007/s11263-020-01373-4
   Chen GZ, 2018, IEEE J-STARS, V11, P1633, DOI 10.1109/JSTARS.2018.2810320
   Chen L.-C., 2017, ABS170605587 CORR, V0, P0
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Dinh Laurent, 2017, 5 INT C LEARN REPR I, V0, P0
   Feng WQ, 2019, IEEE GEOSCI REMOTE S, V16, P618, DOI 10.1109/LGRS.2018.2879492
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   GAO BC, 1995, P SOC PHOTO-OPT INS, V2480, P225, DOI 10.1117/12.210877
   Geng J, 2015, IEEE GEOSCI REMOTE S, V12, P2351, DOI 10.1109/LGRS.2015.2478256
   Guo J, 2013, INFORM SCIENCES, V221, P84, DOI 10.1016/j.ins.2012.09.024
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, V0, PP680, DOI 10.1109/CVPRW.2016.90
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Keutzer K., 2014, DENSENET IMPLEMENTIN, V0, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lan M, 2020, INFORM SCIENCES, V535, P156, DOI 10.1016/j.ins.2020.05.062
   Li LW, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101162
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Makantasis K, 2019, INT CONF ACOUST SPEE, V0, PP2927, DOI 10.1109/ICASSP.2019.8682616
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Miao ZM, 2018, IEEE GEOSCI REMOTE S, V15, P602, DOI 10.1109/LGRS.2018.2794545
   Mukherjee J, 2019, IEEE J-STARS, V12, P2550, DOI 10.1109/JSTARS.2019.2895385
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Noi PT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010018
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Ravishankar H., 2017, INT C MED IM COMP CO, V0, P0, DOI DOI 10.1007/978-3-319-66182-7_24
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shao ZF, 2019, REMOTE SENS ENVIRON, V232, P0, DOI 10.1016/j.rse.2019.111338
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   Tao A., 2020, ARXIV, V0, P0
   Wang GJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050795
   Wang MW, 2017, INFORM SCIENCES, V402, P50, DOI 10.1016/j.ins.2017.03.027
   Wang XW, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10050608
   Wurm M, 2019, ISPRS J PHOTOGRAMM, V150, P59, DOI 10.1016/j.isprsjprs.2019.02.006
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Yang T.-J., 1900, V2019, V0, P0
   Yu B, 2018, IEEE J-STARS, V11, P3252, DOI 10.1109/JSTARS.2018.2860989
   Yu F., 2016, INT C LEARN REPR ICL, V0, P1
   Zhang JS, 2021, IEEE T GEOSCI REMOTE, V59, P316, DOI 10.1109/TGRS.2020.2999405
   Zhang X, 2018, PROC CVPR IEEE, V0, PP6848, DOI 10.1109/CVPR.2018.00716
   Zhang YJ, 2019, IEEE GEOSCI REMOTE S, V16, P927, DOI 10.1109/LGRS.2018.2886422
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhou LC, 2018, IEEE COMPUT SOC CONF, V0, PP192, DOI 10.1109/CVPRW.2018.00034
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zhu WT, 2019, MED PHYS, V46, P576, DOI 10.1002/mp.13300
   Zoph B., 2018, 6 INT C LEARN REPR I, V0, P1
NR 54
TC 21
Z9 21
U1 18
U2 54
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7422
EP 7434
DI 10.1109/JSTARS.2021.3098678
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TU6PM
UT WOS:000681156300011
DA 2023-04-26
ER

PT J
AU MohanRajan, SN
   Loganathan, A
AF MohanRajan, Sam Navin
   Loganathan, Agilandeeswari
TI Modelling Spatial Drivers for LU/LC Change Prediction Using Hybrid Machine Learning Methods in Javadi Hills, Tamil Nadu, India
SO JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING
LA English
DT Article
DE Remote sensing; Geographic information system; Random forest classification; Artificial neural network; Logistic regression; Cellular automata; LU; LC prediction
ID land-use; logistic-regression; cellular-automata; random forest; markov-chain; time-series; classification; gis; integration; landscape
AB The land-use/land-cover (LU/LC) information can be extracted through continuous monitoring and observation of the global environment in the field of RS and GIS (remote sensing and geographic information system). With many inventions on satellite technologies, RS plays a crucial role throughout the world, and the researchers had shown their interest in finding the past, present, and future LU/LC information using the RS satellite data. In this research work, the non-forest- and forest-covered changes of Javadi Hills located in India were simulated and predicted using the hybrid machine learning models. The Markov chain-artificial neural network with cellular automata (MC-ANN-CA) and Markov chain-logistic regression with cellular automata (MC-LR-CA) were used and compared using the actual LU/LC maps of 2009, 2012, and 2015 along with the spatial variables (slope, aspect, hill shade, and distance road map). The results of the comparative analysis between the predicted and actual map of 2015 had shown a higher percentage of correctness in the MC-ANN-CA model for the spatial variables like slope, aspect, and distance road map. The LU/LC for 2021 and 2027 was predicted using the MC-ANN-CA model. By 2021, the forest-covered area will decrease by nearly - 0.38%, and the non-forest-covered area will increase by 0.79%. By 2027, forest-covered areas will decrease by - 0.52%, and non-forest-covered areas will increase by 1.06%, respectively, indicating the impacts of human and urbanization on LU/LC in Javadi Hills.
C1 [MohanRajan, Sam Navin] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Loganathan, Agilandeeswari] Vellore Inst Technol, Sch Informat Technol & Engn, Dept Digital Commun, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of Technology (VIT); VIT Vellore
RP Loganathan, A (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Dept Digital Commun, Vellore, Tamil Nadu, India.
EM agila.l@vit.ac.in
CR Aburas MM, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7330-6
   Adam E, 2014, INT J REMOTE SENS, V35, P693, DOI 10.1080/01431161.2013.870676
   Anand V, 2020, REMOTE SENS LETT, V11, P225, DOI 10.1080/2150704X.2019.1704304
   Ansari A, 2019, INT SOIL WATER CONSE, V7, P64, DOI 10.1016/j.iswcr.2018.10.001
   Arsanjani JJ, 2013, INT J APPL EARTH OBS, V21, P265, DOI 10.1016/j.jag.2011.12.014
   Behera NK, 2020, TROP ECOL, V61, P51, DOI 10.1007/s42965-020-00073-x
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bey A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100807
   Bose A, 2020, MODEL EARTH SYST ENV, V6, P2235, DOI 10.1007/s40808-020-00842-6
   Bounouh O., 2017, PROC INT C ADV TECHN, V0, PP1, DOI 10.1109/ATSIP.2017.8075511
   Chen L, 2019, J INDIAN SOC REMOTE, V47, P1847, DOI 10.1007/s12524-019-01031-4
   Chen LP, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0200493
   Das P, 2019, J INDIAN SOC REMOTE, V47, P1443, DOI 10.1007/s12524-019-00986-8
   Dinda S, 2019, MODEL EARTH SYST ENV, V5, P331, DOI 10.1007/s40808-018-0536-8
   Eisavi V, 2015, ENVIRON MONIT ASSESS, V187, P0, DOI 10.1007/s10661-015-4489-3
   El-Tantawi AM, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7478-0
   Elagouz MH, 2020, EGYPT J REMOTE SENS, V23, P57, DOI 10.1016/j.ejrs.2018.10.004
   Fonji SF, 2014, SPRINGERPLUS, V3, P0, DOI 10.1186/2193-1801-3-61
   Gupta R, 2020, ECOL INDIC, V112, P0, DOI 10.1016/j.ecolind.2020.106171
   Haque MI, 2017, EGYPT J REMOTE SENS, V20, P251, DOI 10.1016/j.ejrs.2016.12.003
   Heidarlou HB, 2019, LAND USE POLICY, V81, P76, DOI 10.1016/j.landusepol.2018.10.036
   Huang YC, 2020, ENVIRON EARTH SCI, V79, P0, DOI 10.1007/s12665-019-8785-z
   Islam K, 2018, ECOL INDIC, V88, P439, DOI 10.1016/j.ecolind.2018.01.047
   Jin Y, 2018, INT CONF COMPUT NETW, V0, PP1, DOI 10.1080/01431161.2018.1490976
   Kale MP, 2016, ENVIRON MONIT ASSESS, V188, P0, DOI 10.1007/s10661-016-5369-1
   Kamwi JM, 2018, LAND-BASEL, V7, P0, DOI 10.3390/land7040131
   Kantakumar LN, 2015, EGYPT J REMOTE SENS, V18, P289, DOI 10.1016/j.ejrs.2015.09.003
   Kavzoglu T, 2017, HANDBOOK OF NEURAL COMPUTATION, V0, PP607, DOI 10.1016/B978-0-12-811318-9.00033-8
   Khawaldah H. A., 2016, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V8, P412, DOI 10.4236/jgis.2016.83035
   Kumar R, 2014, ECOL INDIC, V45, P444, DOI 10.1016/j.ecolind.2014.05.003
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mandal S., 2019, STAT APPROACHES LAND, V0, PP107, DOI 10.1007/978-3-319-93897-4_4
   Mandal S., 2019, STAT APPROACHES LAND, V0, P123
   Mansour S, 2020, LAND USE POLICY, V91, P0, DOI 10.1016/j.landusepol.2019.104414
   Mishra VN, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2138-3
   Misra A, 2015, ARAB J GEOSCI, V8, P267, DOI 10.1007/s12517-013-1220-y
   Mohajane M, 2018, ENVIRONMENTS, V5, P0, DOI 10.3390/environments5120131
   MohanRajan SN, 2020, ENVIRON SCI POLLUT R, V27, P29900, DOI 10.1007/s11356-020-09091-7
   Mondal S, 2018, GEORISK, V12, P29, DOI 10.1080/17499518.2017.1347949
   Munthali MG, 2020, REMOTE SENS APPL, V17, P0, DOI 10.1016/j.rsase.2019.100276
   Navin M.S., 2019, INT J ENG ADV TECHNO, V0, P0
   Navin MS, 2020, MULTIMED TOOLS APPL, V79, P29751, DOI 10.1007/s11042-020-09531-z
   Nurwanda A, 2020, SUSTAIN CITIES SOC, V52, P0, DOI 10.1016/j.scs.2019.101772
   Odindi J, 2014, J APPL REMOTE SENS, V8, P0, DOI 10.1117/1.JRS.8.083527
   Pandey P, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), V0, P56
   Silva LPE, 2020, GLOB ECOL CONSERV, V21, P0, DOI 10.1016/j.gecco.2019.e00811
   Pimple U, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9020258
   Poor EE, 2019, J ENVIRON MANAGE, V231, P397, DOI 10.1016/j.jenvman.2018.10.065
   Qiang Y, 2015, ENVIRON MONIT ASSESS, V187, P0, DOI 10.1007/s10661-015-4298-8
   Reddy CS, 2017, J EARTH SYST SCI, V126, P0, DOI 10.1007/s12040-016-0786-7
   Rwanga S. S., 2017, INTERNATIONAL JOURNAL OF GEOSCIENCES, V8, P611, DOI 10.4236/ijg.2017.84033
   Saputra MH, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11113024
   Satya BA, 2020, APPL GEOMAT, V12, P281, DOI 10.1007/s12518-020-00298-4
   Sawant SS, 2020, EGYPT J REMOTE SENS, V23, P243, DOI 10.1016/j.ejrs.2018.11.001
   Sawant SS, 2020, J SPECT IMAG, V0, P0, DOI DOI 10.1255/jsi.2020.a5
   Siddiqui A, 2018, EGYPT J REMOTE SENS, V21, P229, DOI 10.1016/j.ejrs.2017.11.006
   Singh SK, 2018, GEOCARTO INT, V33, P1202, DOI 10.1080/10106049.2017.1343390
   Singh SK, 2015, ENVIRON PROCESS, V2, P61, DOI 10.1007/s40710-015-0062-x
   Somvanshi SS, 2020, ENVIRON DEV SUSTAIN, V22, P1073, DOI 10.1007/s10668-018-0234-8
   Taufik A, 2019, LECT NOTE NETW SYST, V67, P275, DOI 10.1007/978-981-13-6031-2_46
   Tavangar S, 2021, GEOCARTO INT, V36, P1100, DOI 10.1080/10106049.2019.1633419
   Tavares PA, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19051140
   Thyagharajan KK, 2019, ARCH COMPUT METHOD E, V26, P275, DOI 10.1007/s11831-017-9239-y
   Tilahun A, 2015, AM J ENV PROT, V4, P193, DOI 10.4236/IJG.2017.84033
   Yatoo SA, 2022, GEOJOURNAL, V87, P765, DOI 10.1007/s10708-020-10274-5
   Yirsaw E, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9071204
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
NR 68
TC 8
Z9 8
U1 0
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0255-660X
EI 0974-3006
J9 J INDIAN SOC REMOTE
JI J. Indian Soc. Remote Sens.
PD APR 15
PY 2021
VL 49
IS 4
BP 913
EP 934
DI 10.1007/s12524-020-01258-6
EA NOV 2020
PG 22
WC Environmental Sciences; Remote Sensing
SC Environmental Sciences & Ecology; Remote Sensing
GA RO1IB
UT WOS:000591961400002
DA 2023-04-26
ER

PT J
AU Wiwatcharakoses, C
   Berrar, D
AF Wiwatcharakoses, Chayut
   Berrar, Daniel
TI A self-organizing incremental neural network for continual supervised learning
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Catastrophic forgetting; Concept drift; Continual learning; Incremental learning; Supervised learning
AB Continual learning algorithms can adapt to changes of data distributions, new classes, and even completely new tasks without catastrophically forgetting previously acquired knowledge. Here, we present a novel self-organizing incremental neural network, GSOINN+, for continual supervised learning. GSOINN+ learns a topological mapping of the input data to an undirected network and uses a weighted nearest-neighbor rule with fractional distance for classification. GSOINN+ learns incrementally-new classification tasks do not need to be specified a priori, and no rehearsal of previously learned tasks with stored training sets is required. In a series of sequential learning experiments, we show that GSOINN+ can mitigate catastrophic forgetting, even when completely new tasks are to be learned.
C1 [Wiwatcharakoses, Chayut; Berrar, Daniel] Tokyo Inst Technol, Data Sci Lab, Meguro Ku, 2-12-1-S3-70 Ookayama, Tokyo 1528550, Japan.
C3 Tokyo Institute of Technology
RP Berrar, D (corresponding author), Tokyo Inst Technol, Data Sci Lab, Meguro Ku, 2-12-1-S3-70 Ookayama, Tokyo 1528550, Japan.
EM wiwatcharakoses.c.aa@m.titech.ac.jp; daniel.berrar@ict.e.titech.ac.jp
FU Japanese Ministry of Education, Culture, Sports, Science and Technology
CR Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420
   Aljundi Rahaf, 2019, INT C LEARN REPR, V0, P0
   Benavoli A, 2017, J MACH LEARN RES, V18, P0
   BRUSKE J, 1995, NEURAL COMPUT, V7, P845, DOI 10.1162/neco.1995.7.4.845
   Cohen G, 2017, ABS170205373 CORR, V0, P0
   Flesch T, 2018, P NATL ACAD SCI USA, V115, PE10313, DOI 10.1073/pnas.1800755115
   Francois D, 2007, IEEE T KNOWL DATA EN, V19, P873, DOI 10.1109/TKDE.2007.1037
   FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4
   Fritzke B., 1994, INT C NEUR INF PROC, V0, P625
   Furao S, 2007, NEURAL NETWORKS, V20, P893, DOI 10.1016/j.neunet.2007.07.008
   Furao S, 2008, NEURAL NETWORKS, V21, P1537, DOI 10.1016/j.neunet.2008.07.001
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kruschke JK., 2015, DOING BAYESIAN DATA, V0, PP265, DOI 10.1016/B978-0-12-405888-0.00010-6
   Kruschke JK, 2018, PSYCHON B REV, V25, P178, DOI 10.3758/s13423-016-1221-4
   Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37
   Liu B, 2017, FRONT COMPUT SCI-CHI, V11, P359, DOI 10.1007/s11704-016-6903-6
   Lomonaco V., 2017, CORL, V78, P17
   Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3
   Mccloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI 10.1016/S0079-7421(08)60536-8
   Nakamura Y, 2017, IEEE T NEUR NET LEAR, V28, P8, DOI 10.1109/TNNLS.2015.2489225
   Parisi GI, 2018, FRONT NEUROROBOTICS, V12, P0, DOI 10.3389/fnbot.2018.00078
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Parisi GI, 2017, NEURAL NETWORKS, V96, P137, DOI 10.1016/j.neunet.2017.09.001
   Parisi GI, 2015, FRONT NEUROROBOTICS, V9, P1, DOI 10.3389/fnbot.2015.00003
   Rebuffi SA, 2017, PROC CVPR IEEE, V0, PP5533, DOI 10.1109/CVPR.2017.587
   Rios A, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3332
   Rusu Andrei A., 2016, PROGRESSIVE, V0, P0
   Ruvolo P., 2013, P INT C MACHINE LEAR, V28, P507
   Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006
   Wiwatcharakoses C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P6476
   Wiwatcharakoses C, 2020, EXPERT SYST APPL, V143, P0, DOI 10.1016/j.eswa.2019.113069
   Xiao H., 2017, ARXIV170807747, V0, P0
NR 33
TC 8
Z9 8
U1 3
U2 20
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2021
VL 185
IS 
BP 
EP 
DI 10.1016/j.eswa.2021.115662
EA AUG 2021
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science
SC Computer Science; Engineering; Operations Research & Management Science
GA WH0PD
UT WOS:000707390300001
DA 2023-04-26
ER

PT J
AU Huang, W
   Huang, Y
   Wu, ZB
   Yin, JR
   Chen, QQ
AF Huang, Wei
   Huang, Yao
   Wu, Zebin
   Yin, Junru
   Chen, Qiqiang
TI A Multi-Kernel Mode Using a Local Binary Pattern and Random Patch Convolution for Hyperspectral Image Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Kernel; Convolution; Licenses; Correlation; Support vector machines; Principal component analysis; Deep learning; hyperspectral image (HSI) classification; local binary pattern (LBP); multikernel mode; random patches
ID dimensionality reduction; kernel; information; superpixel; algorithm; military; networks; graph
AB With the development of deep learning technology, more and more scholars have applied it to hyperspectral image (HSI) classification to improve classification accuracy. However, these deep-learning methods not only take a lot of time in the pre-training phase, but also have relatively limited classification performance when there are fewer labeled samples. In order to improve classification performance while reducing costs, this article proposes a multikernel method based on a local binary pattern and random patches (LBPRP-MK), which integrates a local binary pattern (LBP) and deep learning into a multiple-kernel framework. First, we use LBP and hierarchical convolutional neural networks to extract local textural features and multilayer convolutional features, respectively. The convolution kernel for the convolution operation is obtained from the original image using a random strategy without training. Then, we input local textural features, multilayer convolutional features, and spectral features obtained from the original image into the radial basis function to obtain three kernel functions. Finally, the three kernel functions are merged into a multikernel function according to their optimal weights under the composite kernel strategy. This multikernel function is used as the input for the support vector machine to obtain the classification result map. Experiments show that compared with other HSI classification methods, the proposed method achieves better classification performance on three HSI datasets.
C1 [Huang, Wei; Huang, Yao; Yin, Junru; Chen, Qiqiang] Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou 450000, Peoples R China.
   [Wu, Zebin] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
C3 Zhengzhou University of Light Industry; Nanjing University of Science & Technology
RP Huang, W (corresponding author), Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou 450000, Peoples R China.
EM hnhw235@163.com; huangyao@zzuli.edu.cn; wuzb@njust.edu.at; yinjr@zzuli.edu.cn; chenqq@zzuli.edu.cn
FU National Natural Science Foundation of China [61971233, 61872185]; Henan Province Science and Technology Breakthrough Project [212102210102, 212102210105]
CR Aleshin IM, 2020, SEISM INSTRUM, V56, P509, DOI 10.3103/S0747923920050035
   An JL, 2018, IEEE T GEOSCI REMOTE, V56, P4731, DOI 10.1109/TGRS.2018.2835514
   Bengio Y, 2006, P ADV NEUR INF PROC, V0, PP153, DOI 10.7551/MITPRESS/7503.003.0024
   Blackwell WJ, 2011, IEEE T GEOSCI REMOTE, V49, P128, DOI 10.1109/TGRS.2010.2052260
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Cao XY, 2020, IEEE T GEOSCI REMOTE, V58, P4604, DOI 10.1109/TGRS.2020.2964627
   Carmeli C, 2006, ANAL APPL, V4, P377, DOI 10.1142/S0219530506000838
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Duan YL, 2021, IEEE T GEOSCI REMOTE, V59, P613, DOI 10.1109/TGRS.2020.2995709
   Fang LY, 2015, IEEE T GEOSCI REMOTE, V53, P6663, DOI 10.1109/TGRS.2015.2445767
   Gao F, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081271
   Gao HM, 2021, IEEE T GEOSCI REMOTE, V59, P3396, DOI 10.1109/TGRS.2020.3008286
   Gao HM, 2021, IEEE J-STARS, V14, P2563, DOI 10.1109/JSTARS.2021.3056124
   Gao LR, 2021, IEEE T GEOSCI REMOTE, V59, P2269, DOI 10.1109/TGRS.2020.3000684
   Haertel V, 1999, IEEE T GEOSCI REMOTE, V37, P2374, DOI 10.1109/36.789636
   Han MX, 2020, PATTERN RECOGN LETT, V130, P38, DOI 10.1016/j.patrec.2018.10.003
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P1424, DOI 10.1109/TGRS.2020.3003341
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   He L, 2018, IEEE T GEOSCI REMOTE, V56, P1579, DOI 10.1109/TGRS.2017.2765364
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Huang X, 2014, REMOTE SENS-BASEL, V6, P8424, DOI 10.3390/rs6098424
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Jia S, 2017, IEEE T GEOSCI REMOTE, V55, P2399, DOI 10.1109/TGRS.2016.2642951
   Jia XP, 1999, IEEE T GEOSCI REMOTE, V37, P538, DOI 10.1109/36.739109
   Kendler S, 2019, IEEE SENS J, V19, P2657, DOI 10.1109/JSEN.2018.2886269
   Li L, 2018, NEUROCOMPUTING, V275, P1725, DOI 10.1016/j.neucom.2017.09.004
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Lorenzo PR, 2020, IEEE ACCESS, V8, P42384, DOI 10.1109/ACCESS.2020.2977454
   Luft L, 2014, ECOL INDIC, V46, P264, DOI 10.1016/j.ecolind.2014.06.025
   Luo FL, 2020, IEEE T GEOSCI REMOTE, V58, P5336, DOI 10.1109/TGRS.2020.2963848
   Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239
   Saboori A, 2021, IEEE GEOSCI REMOTE S, V18, P356, DOI 10.1109/LGRS.2020.2969970
   Satapathy J, 2020, REMOTE SENS APPL, V19, P0, DOI 10.1016/j.rsase.2020.100339
   Shen LL, 2011, IEEE T GEOSCI REMOTE, V49, P5039, DOI 10.1109/TGRS.2011.2157166
   Shimoni M, 2019, IEEE GEOSC REM SEN M, V7, P101, DOI 10.1109/MGRS.2019.2902525
   Sun L, 2019, IEEE J-STARS, V12, P1905, DOI 10.1109/JSTARS.2019.2915588
   Sun L, 2015, IEEE T GEOSCI REMOTE, V53, P1490, DOI 10.1109/TGRS.2014.2344442
   Sun YJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161954
   Tan KL, 2020, INT J COAL SCI TECHN, V7, P311, DOI 10.1007/s40789-020-00323-2
   Tu B, 2020, IEEE T GEOSCI REMOTE, V58, P4116, DOI 10.1109/TGRS.2019.2961141
   Wang Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010120
   Wang Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030441
   Xu YH, 2018, ISPRS J PHOTOGRAMM, V142, P344, DOI 10.1016/j.isprsjprs.2018.05.014
   Yang JX, 2017, IEEE T GEOSCI REMOTE, V55, P4729, DOI 10.1109/TGRS.2017.2698503
   Yang WD, 2020, IEEE J-STARS, V13, P5833, DOI 10.1109/JSTARS.2020.3026316
   Zeng D, 2019, IEEE ACCESS, V7, P104514, DOI 10.1109/ACCESS.2019.2932117
   Zheng K, 2021, IEEE T GEOSCI REMOTE, V59, P2487, DOI 10.1109/TGRS.2020.3006534
NR 51
TC 11
Z9 11
U1 4
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4607
EP 4620
DI 10.1109/JSTARS.2021.3076198
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SE4PF
UT WOS:000652054400004
DA 2023-04-26
ER

PT J
AU Chen, SQ
   Zhan, RH
   Wang, W
   Zhang, J
AF Chen, Shiqi
   Zhan, Ronghui
   Wang, Wei
   Zhang, Jun
TI Learning Slimming SAR Ship Object Detector Through Network Pruning and Knowledge Distillation
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Attention mechanism; feature imitation; knowledge distillation (KD); lightweight synthetic aperture radar (SAR) ship detector; network pruning
AB The deployment of deep convolutional neural networks (CNNs) in synthetic aperture radar (SAR) ship real-time detection is largely hindered by huge computational cost. In this article, we propose a novel learning scheme for training a lightweight ship detector called Tiny YOLO-Lite, which simultaneously 1) reduces the model storage size; 2) decreases the floating point operations (FLOPs) calculation; and 3) guarantees the high accuracy with faster speed. This is achieved by self-designed backbone structure and network pruning, which enforces channel-level sparsity in the backbone network and yields a compact model. In addition, knowledge distillation is also applied to make up for the performance decline caused by network pruning. Hereinto, we propose to let small student model mimic cumbersome teacher's output to achieve improved generalization. Rather than applying vanilla full feature imitation, we redefine the distilled knowledge as the inter-relationship between different levels of feature maps and then transfer it from the large network to a smaller one. On account that the detectors should focus more on the salient regions containing ships while background interference is overwhelming, a novel attention mechanism is designed and then attached to the distilled feature for enhanced representation. Finally, extensive experiments are conducted on SSDD, HRSID, and two large-scene SAR images to verify the effectiveness of the thinner SAR ship object detector in comparison of with other CNN-based algorithms. The detection results demonstrate that the proposed detector can achieve lighter architecture with 2.8-M model size, more efficient inference (>$200 fps) with low computation cost, and more accurate prediction with knowledge transfer strategy.
C1 [Chen, Shiqi; Zhan, Ronghui; Wang, Wei; Zhang, Jun] Natl Univ Def Technol, Coll Elect Sci, Natl Key Lab Sci & Technol Automat Target Recogni, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China
RP Zhan, RH (corresponding author), Natl Univ Def Technol, Coll Elect Sci, Natl Key Lab Sci & Technol Automat Target Recogni, Changsha 410073, Peoples R China.
EM 337035302@qq.com; zhanrh@nudt.edu.cn; wangwei_nudt@hotmail.com; zhangjun@nudt.edu.cn
FU National Natural Science Foundation of China [61901500]; Natural Science Foundation of Hunan Province [2020JJ5674]
CR Chang YL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070786
   Chen C, 2019, IEEE ACCESS, V7, P104848, DOI 10.1109/ACCESS.2019.2930939
   Chen GB, 2017, ADV NEUR IN, V30, P0
   Chen TH, 2015, DES AUT CON, V0, P0, DOI DOI 10.1145/2744769.2744837
   Cui ZY, 2021, IEEE T GEOSCI REMOTE, V59, P379, DOI 10.1109/TGRS.2020.2997200
   Cui ZY, 2019, IEEE T GEOSCI REMOTE, V57, P8983, DOI 10.1109/TGRS.2019.2923988
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Gao F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222694
   Han S., 2016, PROC INT C LEARN REP, V0, P0
   Han S., 2015, ADV NEUR IN, V0, P0
   He YH, 2017, IEEE I CONF COMP VIS, V0, PP1398, DOI 10.1109/ICCV.2017.155
   Hinton G. E., 2015, ARXIV, V0, P0
   Hou Q., 1900, V2020, V0, P4003
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   HUANG G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang ZH, 2018, LECT NOTES COMPUT SC, V11220, P317, DOI 10.1007/978-3-030-01270-0_19
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Kaiming He, 2020, IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Li H., 2016, PRUNING FILTERS EFFI, Vabs/1608.08710, P0
   Li J, 2017, 2018 IEEE INT C ACOU, V0, PP1, DOI 10.1109/BIGSARDATA.2017.8124934
   LI QQ, 2017, PROC CVPR IEEE, V0, PP7341, DOI 10.1109/CVPR.2017.776
   Li ZS, 2019, CHIN AUTOM CONGR, V0, PP2701, DOI 10.1109/CAC48633.2019.8996995
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Lin X., 2017, ADV NEURAL INFORM PR, V0, P344
   Liu Z, 2017, IEEE I CONF COMP VIS, V0, PP2755, DOI 10.1109/ICCV.2017.298
   Molchanov P., 2016, ARXIV161106440 CORR, V0, P0
   Redmon J., 2016, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Romero A., 2014, ARXIV14126550, V0, P0
   Samadi F, 2019, IET IMAGE PROCESS, V13, P2255, DOI 10.1049/iet-ipr.2018.6248
   Sharifzadeh Foroogh, 2019, JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING, V47, P551, DOI 10.1007/s12524-018-0891-y
   Shih KH, 2019, INT CONF ACOUST SPEE, V0, PP1398, DOI 10.1109/ICASSP.2019.8683842
   [孙显 Sun Xian], 2019, 雷达学报 JOURNAL OF RADARS, V8, P852
   Tirandaz Z, 2020, MEASUREMENT, V153, P0, DOI 10.1016/j.measurement.2019.107432
   Van Etten A., 2018, YOU ONLY LOOK TWICE, V0, P0
   Wang Z., 1900, V2020, V0, P1
   Wang ZY, 2016, LECT NOTES COMPUT SC, V9912, P533, DOI 10.1007/978-3-319-46484-8_32
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Wei S., 2020, IEEE ACCESS, V8, P0
   Wei SJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010167
   Ye J., 2018, INT C LEARN REPR, V0, P1
   Yim J, 2017, PROC CVPR IEEE, V0, PP7130, DOI 10.1109/CVPR.2017.754
   Zagoruyko S., 2016, PROC BRIT MACH VIS C, V0, P0
   Zalpour M, 2020, INT J REMOTE SENS, V41, P2239, DOI 10.1080/01431161.2019.1685720
   Zhang PY, 2019, IEEE INT CONF COMP V, V0, PP37, DOI 10.1109/ICCVW.2019.00011
   Zhang T., 1900, V167, V0, P123
   Zhang TW, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212483
   Zhaowei Cai, 2018, 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION. PROCEEDINGS, V0, PP6154, DOI 10.1109/CVPR.2018.00644
NR 51
TC 36
Z9 37
U1 23
U2 76
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1267
EP 1282
DI 10.1109/JSTARS.2020.3041783
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900041
DA 2023-04-26
ER

PT J
AU Mughal, MH
   Khokhar, MJ
   Shahzad, M
AF Mughal, Muhammad Hamza
   Khokhar, Muhammad Jawad
   Shahzad, Muhammad
TI Assisting UAV Localization Via Deep Contextual Image Matching
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Location awareness; Global Positioning System; Deep learning; Image matching; Data mining; Neural networks; Deep learning; neighborhood consensus networks; remote sensing; SIFT; template matching; UAV; vision-based localization
AB In this article, we aim to explore the potential of using onboard cameras and pre-stored geo-referenced imagery for Unmanned Aerial Vehicle (UAV) localization. Such a vision-based localization enhancing system is of vital importance, particularly in situations where the integrity of the global positioning system (GPS) is in question (i.e., in the occurrence of GPS outages, jamming, etc.). To this end, we propose a complete trainable pipeline to localize an aerial image in a pre-stored orthomosaic map in the context of UAV localization. The proposed deep architecture extracts the features from the aerial imagery and localizes it in a pre-ordained, larger, and geotagged image. The idea is to train a deep learning model to find neighborhood consensus patterns that encapsulate the local patterns in the neighborhood of the established dense feature correspondences by introducing semi-local constraints. We qualitatively and quantitatively evaluate the performance of our approach on real UAV imagery. The training and testing data is acquired via multiple flights over different regions. The source code along with the entire dataset, including the annotations of the collected images has been made public.(1) Up-to our knowledge, such a dataset is novel and first of its kind which consists of 2052 high-resolution aerial images acquired at different times over three different areas in Pakistan spanning a total area of around 2 km(2).
C1 [Mughal, Muhammad Hamza; Shahzad, Muhammad] Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci SEECS, Islamabad, Pakistan.
   [Khokhar, Muhammad Jawad] Teradata Global Delivery Ctr GDC, Islamabad, Pakistan.
   [Shahzad, Muhammad] Natl Ctr Artificial Intelligence, Deep Learning Lab, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Shahzad, M (corresponding author), Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci SEECS, Islamabad, Pakistan.; Shahzad, M (corresponding author), Natl Ctr Artificial Intelligence, Deep Learning Lab, Islamabad, Pakistan.
EM mmughal.bee15seecs@seecs.edu.pk; mjawadak@hotmail.com; muhammad.shehzad@seecs.edu.pk
FU NUST, Islamabad, Pakistan
CR Altwaijry H, 2016, PROC CVPR IEEE, V0, PP3539, DOI 10.1109/CVPR.2016.385
   Balntas V., 2016, ARXIV160105030, V0, P0
   Balntas V., 2016, BMVC, V1, P3, DOI 10.5244/C.30.119
   Bay H., 2008, COMPUTER VISION IMAG, V0, P0, DOI DOI 10.1007/11744023_32
   Bekkers EJ, 2018, IEEE T PATTERN ANAL, V40, P452, DOI 10.1109/TPAMI.2017.2652452
   Bian JW, 2017, PROC CVPR IEEE, V0, PP2828, DOI 10.1109/CVPR.2017.302
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   Canhoto Andrea, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA 2009), V0, PP496, DOI 10.1109/ICSIPA.2009.5478706
   Chaolei Wang, 2012, PROCEEDINGS OF THE 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), V0, PP896, DOI 10.1109/ROBIO.2012.6491082
   Chen ST, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121244
   Cheng JX, 2019, PROC CVPR IEEE, V0, PP11545, DOI 10.1109/CVPR.2019.01182
   Chollet F, 2016, PROC CVPR IEEE, V0, P0, DOI DOI 10.48550/arXiv.1610.02357
   Costea D., 2018, ARXIV180401322, V0, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Fischer P., 2015, ARXIV14055769, V0, P0
   FISCHLER MA, 1981, VISAPP 2009 P 4 INT, V24, P381
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Howard A. G., 2017, MOBILENETS EFFICIENT, V0, P0
   HUANG G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   KOCH T, 2016, LECT NOTES COMPUT SC, V3, P83
   Lai JX, 2020, PATTERN RECOGN, V98, P0, DOI 10.1016/j.patcog.2019.107029
   Leutenegger S, 2011, IEEE I CONF COMP VIS, V0, PP2548, DOI 10.1109/ICCV.2011.6126542
   Li J., 2016, P INT MICROAIR VEHIC, V2016, P237
   Li J.-X., 2011, P 3 INT C DIG IM PRO, V8009, P437
   Lin Y., 2007, CVPR, V1, P0, DOI 10.1109/CVPR.2007.383428
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mark Everingham, 2010, IJCV, V88, P303, DOI 10.1007/S11263-009-0275-4
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   NAIR D, 2000, P SOC PHOTO-OPT INS, V0, P472
   Nassar A, 2018, IEEE COMPUT SOC CONF, V0, PP1594, DOI 10.1109/CVPRW.2018.00201
   Natarajan, 2018, P AS C COMP VIS, V0, P546
   Noh H, 2017, IEEE I CONF COMP VIS, V0, PP3476, DOI 10.1109/ICCV.2017.374
   Rocco I., 2018, ADV NEURAL INF PROCE, V31, P151
   Rublee E, 2011, IEEE I CONF COMP VIS, V0, PP2564, DOI 10.1109/ICCV.2011.6126544
   SCHAFFALITZKY F, 2002, INT C IM VID RETR, V0, P0
   Schonberger JL, 2017, PROC CVPR IEEE, V0, PP6959, DOI 10.1109/CVPR.2017.736
   Seung H., 2017, ARXIV170508593, V0, P0
   Shan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), V0, PP114, DOI 10.1109/ROBIO.2015.7418753
   Simonyan K, 2015, ARXIV, V0, P0
   Solbrig P., 2008, P INT C INF FUS, V0, P1
   Taira H, 2018, PROC CVPR IEEE, V0, PP7199, DOI 10.1109/CVPR.2018.00752
   Tian YC, 2017, PROC CVPR IEEE, V0, PP1998, DOI 10.1109/CVPR.2017.216
   Wan X, 2016, ISPRS J PHOTOGRAMM, V119, P198, DOI 10.1016/j.isprsjprs.2016.05.016
   YANG H, 2019, IEEE I CONF COMP VIS, V91, P345
   Yoo J, 2014, PATTERN RECOGN, V47, P3006, DOI 10.1016/j.patcog.2014.02.016
   Yuan W., 2014, SENSORS TRANSDUCERS, V169, P61
   ZHUO X, 2017, IEEE COMPUT SOC CONF, V9, P376, DOI 10.3390/RS9040376
NR 48
TC 10
Z9 10
U1 2
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2445
EP 2457
DI 10.1109/JSTARS.2021.3054832
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QL9MB
UT WOS:000621403900007
DA 2023-04-26
ER

PT J
AU Yang, BC
   Xiao, ZF
AF Yang, Bochen
   Xiao, Zhifeng
TI A Multi-Channel and Multi-Spatial Attention Convolutional Neural Network for Prostate Cancer ISUP Grading
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE prostate cancer; ISUP grading; channel attention; spatial attention; convolutional neural network; reduction ratio; kernel size
ID international society; gleason
AB Prostate cancer (PCa) is one of the most prevalent cancers worldwide. As the demand for prostate biopsies increases, a worldwide shortage and an uneven geographical distribution of proficient pathologists place a strain on the efficacy of pathological diagnosis. Deep learning (DL) is able to automatically extract features from whole-slide images of prostate biopsies annotated by skilled pathologists and to classify the severity of PCa. A whole-slide image of biopsies has many irrelevant features that weaken the performance of DL models. To enable DL models to focus more on cancerous tissues, we propose a Multi-Channel and Multi-Spatial (MCMS) Attention module that can be easily plugged into any backbone CNN to enhance feature extraction. Specifically, MCMS learns a channel attention vector to assign weights to channels in the feature map by pooling from multiple attention branches with different reduction ratios; similarly, it also learns a spatial attention matrix to focus on more relevant areas of the image, by pooling from multiple convolutional layers with different kernel sizes. The model is verified on the most extensive multi-center PCa dataset that consists of 11,000 H&E-stained histopathology whole-slide images. Experimental results demonstrate that an MCMS-assisted CNN can effectively boost prediction performance in accuracy (ACC) and quadratic weighted kappa (QWK), compared with prior studies. The proposed model and results can serve as a credible benchmark for future research in automated PCa grading.
C1 [Yang, Bochen] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.
   [Xiao, Zhifeng] Behrend Coll, Sch Engn, Penn State Erie, Erie, PA 16563 USA.
C3 Beijing University of Posts & Telecommunications; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University
RP Xiao, ZF (corresponding author), Behrend Coll, Sch Engn, Penn State Erie, Erie, PA 16563 USA.
EM bochenyang@outlook.com; zux2@psu.edu
CR [Anonymous], 2016, PROC CVPR IEEE, V0, P0, DOI DOI 10.1109/CVPR.2016.90
   Arvaniti E, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-30535-1
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Campanella G., 2018, 180506983 ARXIV, V0, P0
   Copeland AR, 2007, ARCH PATHOL LAB MED, V131, P1767
   Egevad L, 2019, VIRCHOWS ARCH, V474, P577, DOI 10.1007/s00428-019-02540-w
   Epstein JI, 2016, AM J SURG PATHOL, V40, P244, DOI 10.1097/PAS.0000000000000530
   Farjam R, 2007, CYTOM PART B-CLIN CY, V72B, P227, DOI 10.1002/cyto.b.20162
   Gorelick L, 2013, IEEE T MED IMAGING, V32, P1804, DOI 10.1109/TMI.2013.2265334
   Hou L, 2016, PROC CVPR IEEE, V0, PP2424, DOI 10.1109/CVPR.2016.266
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Hussain L, 2018, CANCER BIOMARK, V21, P393, DOI 10.3233/CBM-170643
   Ilse M, 2018, PR MACH LEARN RES, V80, P0
   Li J., 2019, 190513208 ARXIV, V0, P0
   Munir K, 2019, CANCERS, V11, P0, DOI 10.3390/cancers11091235
   Nagpal K, 2019, NPJ DIGIT MED, V2, P0, DOI 10.1038/s41746-019-0112-2
   Nguyen Kien, 2011, J PATHOL INFORM, V2, PS3, DOI 10.4103/2153-3539.92030
   Nirthika Rajendran, 2020, 2020 IEEE 15TH INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS (ICIIS), V0, PP144, DOI 10.1109/ICIIS51140.2020.9342711
   Pinckaers H., 2020, 200603394 ARXIV, V0, P0
   Regnier-Coudert O, 2012, ARTIF INTELL MED, V55, P25, DOI 10.1016/j.artmed.2011.11.003
   Samaratunga H, 2016, SCAND J UROL, V50, P325, DOI 10.1080/21681805.2016.1201858
   Strom P, 2020, LANCET ONCOL, V21, P222, DOI 10.1016/S1470-2045(19)30738-7
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie H., 2020, 201114301 ARXIV, V0, P0
   Xu HM, 2020, IEEE ACM T COMPUT BI, V17, P1871, DOI 10.1109/TCBB.2019.2941195
   Zhang GK, 2019, IEEE ACCESS, V7, P131448, DOI 10.1109/ACCESS.2019.2939389
   Zhou B, 2016, PROC CVPR IEEE, V0, PP2921, DOI 10.1109/CVPR.2016.319
NR 27
TC 5
Z9 5
U1 0
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD MAY 15
PY 2021
VL 11
IS 10
BP 
EP 
DI 10.3390/app11104321
PG 11
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA ST7JE
UT WOS:000662615200001
DA 2023-04-26
ER

PT J
AU Korovin, IS
   Klimenko, AB
   Kalyaev, IA
   Safronenkova, IB
AF Korovin, I. S.
   Klimenko, A. B.
   Kalyaev, I. A.
   Safronenkova, I. B.
TI An experience of the cognitive map-based classifier usage in astronaut's emotional state monitoring
SO ACTA ASTRONAUTICA
LA English
DT Article
DE Cognitive map; Classification; Emotional states monitoring
ID space exploration; recognition
AB This paper is devoted to the relevant problem of the astronaut's emotional states identification. The latest research in this domain have revealed the tendency of the emotional state definition via facial expression recognition. Besides, some other technologies are applied: heartrate monitors, brain activity analyzers, speech tone recognition, etc. Nevertheless, the problem of the emotional state monitoring relates to the classification one, so, a wide range of solutions has been proposed, including artificial neural networks, K-nearest neighbors, fuzzy logic and others. The main contribution of this paper is the development of the cognitive-map based classifier. The results of testing demonstrate the robustness and the adequacy of the cognitive map proposed.
C1 [Korovin, I. S.; Klimenko, A. B.; Kalyaev, I. A.] Southern Fed Univ, Sci Res Inst Multiprocessor Comp Syst, 2 Chekhov St, Taganrog 347922, Russia.
   [Safronenkova, I. B.] Russian Acad Sci, Southern Sci Ctr, Fed Res Ctr, 41 Chekhov St, Rostov Na Donu 344006, Russia.
C3 Southern Federal University; Russian Academy of Sciences; Southern Scientific Center, Russian Academy of Sciences
RP Korovin, IS (corresponding author), Southern Fed Univ, Sci Res Inst Multiprocessor Comp Syst, 2 Chekhov St, Taganrog 347922, Russia.
EM korovin_yakov@mail.ru
FU RFBR [20-04-60485]
CR Agrawal E., 2020, COMMUNICATIONS COMPU, V1240, P0, DOI 10.1007/978-981-15-6315-7_16
   Akcay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Alfano CA, 2018, ACTA ASTRONAUT, V142, P289, DOI 10.1016/j.actaastro.2017.11.009
   [Anonymous], 2020, YOUR BRAIN MARS SCIE, V0, P0
   [Anonymous], 2019, EMOTION RECOGNITION, V0, P0
   [Anonymous], 2008, TINY SCANNER MAY MON, V0, P0
   [Anonymous], 2017, OPTICAL COMPUTER REC, V0, P0
   [Anonymous], 1976, STRUCTURE DECISION C, V0, P0
   Bejani M, 2014, NEURAL COMPUT APPL, V24, P399, DOI 10.1007/s00521-012-1228-3
   BOUGON M, 1977, ADMIN SCI QUART, V22, P606, DOI 10.2307/2392403
   BROWN SM, 1992, J MANAGE STUD, V29, P287, DOI 10.1111/j.1467-6486.1992.tb00666.x
   Chakraborty A, 2009, STUD COMPUT INTELL, V234, P133
   Decadi A., 2018, ADDRESSING KEY PSYCH, V0, P0
   Dinculescu A., 2015, E HLTH BIOENG C EHB, V0, PP1, DOI 10.1109/EHB.2015.7391378
   Dinges D.F., 2014, NASA HUM RES PROGR I, V0, P0
   Dinges DF, 2007, ACTA ASTRONAUT, V60, P341, DOI 10.1016/j.actaastro.2006.09.003
   Friedman E, 2017, AEROSP MED HUM PERF, V88, P1024, DOI 10.3357/AMHP.4901.2017
   Garcia-Ceja E, 2018, PERVASIVE MOB COMPUT, V51, P1, DOI 10.1016/j.pmcj.2018.09.003
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Headspace, 2019, SPAC TRAV AFF ASTR M, V0, P0
   Hernandez-Matamoros A, 2016, KNOWL-BASED SYST, V110, P1, DOI 10.1016/j.knosys.2016.07.011
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   KOUR A, 2015, INT J COMPUT APPL, V115, P10, DOI 10.5120/20170-2329
   Lee H.C., 2013, ADV INTELLIGENT SYST, V21, P259, DOI 10.1007/978-3-642-35473-1_26
   Lee TS, 2018, ACTA ASTRONAUT, V143, P169, DOI 10.1016/j.actaastro.2017.11.032
   Li M, 2018, TECHNOL HEALTH CARE, V26, PS509, DOI 10.3233/THC-174836
   Li Y., 2012, 39 COSPAR SCI ASSEMB, V39, P1074
   Liu S, 2012, IMAGE VISION COMPUT, V30, P535, DOI 10.1016/j.imavis.2012.05.004
   Manzey D, 1998, ERGONOMICS, V41, P537, DOI 10.1080/001401398186991
   Mather M, 2018, CURR OPIN BEHAV SCI, V19, P98, DOI 10.1016/j.cobeha.2017.12.017
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Patel RS, 2018, BEHAV SCI-BASEL, V8, P0, DOI 10.3390/bs8110098
   Rappaport MB, 2020, ACTA ASTRONAUT, V175, P438, DOI 10.1016/j.actaastro.2020.06.011
   Zhang S, 2018, LECT NOTES COMPUT SC, V11335, P105, DOI 10.1007/978-3-030-05054-2_8
NR 34
TC 2
Z9 2
U1 2
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0094-5765
EI 1879-2030
J9 ACTA ASTRONAUT
JI Acta Astronaut.
PD APR 15
PY 2021
VL 181
IS 
BP 537
EP 543
DI 10.1016/j.actaastro.2021.01.022
EA FEB 2021
PG 7
WC Engineering, Aerospace
SC Engineering
GA SZ5EV
UT WOS:000666589400045
DA 2023-04-26
ER

PT J
AU Cai, HJ
   Chen, T
   Niu, RQ
   Plaza, A
AF Cai, Haojie
   Chen, Tao
   Niu, Ruiqing
   Plaza, Antonio
TI Landslide Detection Using Densely Connected Convolutional Networks and Environmental Conditions
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Terrain factors; Remote sensing; Feature extraction; Deep learning; Computers; Machine learning algorithms; Visualization; Dense convolutional networks; image classification; landslide detection
ID neural-networks; logistic-regression; spatial prediction; models; performance; county
AB A complete and accurate landslide map is necessary for landslide susceptibility and risk assessment. Currently, deep learning faces the dilemma of insufficient application, scarce samples, and poor efficiency in landslide recognition. This article utilizes the advantages of dense convolutional networks (DenseNets) and their modified technique to solve the three proposed problems. For this purpose, we created a new landslide sample library. On the original remote sensing image, 12 geological, topographic, hydrological and land cover factors that can directly or indirectly reflect the landslide are superimposed. Then, landslide detection was carried out in the three Gorges reservoir area in China to test the performance of the improved method. The quantitative evaluation of the landslide detection map shows that the combination of environmental factors and DenseNet can improve the accuracy of the detection model. Compared with the optical image, kappa and F1 increased by 9.7% and 9.1% respectively. Compared with other traditional neural networks and machine learning algorithms, DenseNet has the highest kappa and F1 values. Based on the base Densenet, through data augmentation and fine-tuning optimization technology, the kappa and F1 values reach the highest values of 0.9474 and 0.9505, respectively. The proposed method has promising applicability in large area landslide identification scenarios.
C1 [Cai, Haojie; Chen, Tao; Niu, Ruiqing] China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
   [Chen, Tao] Beijing Key Lab Urban Spatial Informat Engn, Beijing 100038, Peoples R China.
   [Plaza, Antonio] Univ Extremadura, Escuela Politecn, Dept Technol Comp & Commun, Hyperspectral Comp Lab, Caceres 10071, Spain.
C3 China University of Geosciences; Universidad de Extremadura
RP Chen, T (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
EM cason@cug.edu.cn; taochen@cug.edu.cn; niuruiqing@cug.edu.cn; aplaza@unex.es
FU National Natural Science Foundation of China [62071439, 61601418, 61871259]; Opening Foundation of Qilian Mountain National Park Research Center (Qinghai) [GKQ2019-01, 20210209]; Opening Foundation of Geomatics Technology and Application Key Laboratory of Qinghai Province [QHDX-2019-01]
CR Adia B., 2016, REMOTE SENS-BASEL, V8, P1
   [Anonymous], 2015, ADV NEURAL INFORM PR, V0, P0
   Arbanas S. M., 2014, S MACEDONIAN ASS GEO, V0, P57
   Bai SB, 2010, GEOMORPHOLOGY, V115, P23, DOI 10.1016/j.geomorph.2009.09.025
   Pham BT, 2016, NAT HAZARDS, V83, P97, DOI 10.1007/s11069-016-2304-2
   Brenning A, 2005, NAT HAZARD EARTH SYS, V5, P853, DOI 10.5194/nhess-5-853-2005
   Chen T, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5317-y
   Chen W, 2018, B ENG GEOL ENVIRON, V77, P611, DOI 10.1007/s10064-017-1004-9
   Chen ZY, 2016, Q J ENG GEOL HYDROGE, V49, P279, DOI 10.1144/qjegh2016-100
   Constantin M, 2011, ENVIRON EARTH SCI, V63, P397, DOI 10.1007/s12665-010-0724-y
   Costanzo D, 2012, NAT HAZARD EARTH SYS, V12, P327, DOI 10.5194/nhess-12-327-2012
   Das SL, 2017, BIOMED RES-INDIA, V28, P4294
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260
   Fiorucci F, 2011, GEOMORPHOLOGY, V129, P59, DOI 10.1016/j.geomorph.2011.01.013
   Gao H, 2016, SUSTAINABILITY-BASEL, V8, P0, DOI 10.3390/su8070619
   Ghorbanzadeh O, 2021, IEEE J-STARS, V14, P452, DOI 10.1109/JSTARS.2020.3043836
   Ghorbanzadeh O, 2019, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON GEOGRAPHICAL INFORMATION SYSTEMS THEORY, V0, P33, DOI 10.5220/0007675300330040
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Goetz JN, 2015, COMPUT GEOSCI-UK, V81, P1, DOI 10.1016/j.cageo.2015.04.007
   Gorsevski PV, 2016, LANDSLIDES, V13, P467, DOI 10.1007/s10346-015-0587-0
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   He KM, 2015, PROC CVPR IEEE, V0, PP5353, DOI 10.1109/CVPR.2015.7299173
   He KQ, 2008, ENVIRON GEOL, V55, P55, DOI 10.1007/s00254-007-0964-7
   He YX, 2023, TRANSPORTMETRICA A, V19, P0, DOI 10.1080/23249935.2022.2033348
   Huang BL, 2017, COAST ENG, V123, P52, DOI 10.1016/j.coastaleng.2017.03.003
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Kargel JS, 2016, SCIENCE, V351, P0, DOI 10.1126/science.aac8353
   Kavzoglu T, 2019, ADV NAT TECH HAZ RES, V50, P283, DOI 10.1007/978-3-319-77377-3_13
   Kavzoglu T, 2015, ENG GEOL, V192, P101, DOI 10.1016/j.enggeo.2015.04.004
   Keyport RN, 2018, INT J APPL EARTH OBS, V64, P1, DOI 10.1016/j.jag.2017.08.015
   Kolodny M. A., 2014, P SPIE INT SOC OPT E, V0, P0
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lei XY, 2019, IEEE ACCESS, V7, P124087, DOI 10.1109/ACCESS.2019.2927169
   Li DR, 2012, SCI CHINA EARTH SCI, V55, P1043, DOI 10.1007/s11430-012-4445-9
   Liu P, 2013, INT J APPL EARTH OBS, V21, P253, DOI 10.1016/j.jag.2011.10.010
   Lu H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050752
   Marjanovic M, 2011, ACTA GEOTECH SLOV, V8, P45
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Martha TR, 2012, ISPRS J PHOTOGRAMM, V67, P105, DOI 10.1016/j.isprsjprs.2011.11.004
   Meena SR, 2021, LANDSLIDES, V18, P1937, DOI 10.1007/s10346-020-01602-4
   Mei SH, 2017, IEEE T GEOSCI REMOTE, V55, P4520, DOI 10.1109/TGRS.2017.2693346
   Mezaal MR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071029
   Nair V., 2010, P 27 INT C MACH LEAR, V0, P807
   Pagot E, 2008, IEEE J-STARS, V1, P120, DOI 10.1109/JSTARS.2008.2001154
   Pradhan B, 2010, ENVIRON MODELL SOFTW, V25, P747, DOI 10.1016/j.envsoft.2009.10.016
   Prakash N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030346
   Qiao G, 2013, REMOTE SENS-BASEL, V5, P4319, DOI 10.3390/rs5094319
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sai W, 2015, P SPIE INT SOC OPT E, V9669, P307
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   Sarkar S, 2004, PHOTOGRAMM ENG REM S, V70, P617, DOI 10.14358/PERS.70.5.617
   Scaioni M, 2014, REMOTE SENS-BASEL, V6, P9600, DOI 10.3390/rs60x000x
   Shi W., 2021, IEEE T GEOSCI ELECT, V59, P4654
   Tian Y, 2021, MEASUREMENT, V168, P0, DOI 10.1016/j.measurement.2020.108493
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Wu S, 2019, IEEE T NEUR NET LEAR, V30, P2043, DOI 10.1109/TNNLS.2018.2876179
   Xing AG, 2014, ENG GEOL, V181, P1, DOI 10.1016/j.enggeo.2014.07.022
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Yi YN, 2020, IEEE J-STARS, V13, P6166, DOI 10.1109/JSTARS.2020.3028855
   Yi YN, 2020, CATENA, V195, P0, DOI 10.1016/j.catena.2020.104851
   Yu B, 2020, COMPUT GEOSCI-UK, V135, P0, DOI 10.1016/j.cageo.2019.104388
   Zhu M., 2019, INT J GEOSCIENCES, V10, P1
NR 65
TC 20
Z9 20
U1 13
U2 69
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 5235
EP 5247
DI 10.1109/JSTARS.2021.3079196
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SN5PE
UT WOS:000658340600008
DA 2023-04-26
ER

PT J
AU Kharazi, BA
   Behzadan, AH
AF Kharazi, Bahareh Alizadeh
   Behzadan, Amir H.
TI Flood depth mapping in street photos with image processing and deep neural networks
SO COMPUTERS ENVIRONMENT AND URBAN SYSTEMS
LA English
DT Article
DE Water depth; Flood; Disaster management; Image processing; Deep learning; Edge detection
ID elevation model accuracy; multisensor approach; simulation; risk; dem
AB Many parts of the world experience severe episodes of flooding every year. In addition to the high cost of mitigation and damage to property, floods make roads impassable and hamper community evacuation, movement of goods and services, and rescue missions. Knowing the depth of floodwater is critical to the success of response and recovery operations that follow. However, flood mapping especially in urban areas using traditional methods such as remote sensing and digital elevation models (DEMs) yields large errors due to reshaped surface topography and microtopographic variations combined with vegetation bias. This paper presents a deep neural network approach to detect submerged stop signs in photos taken from flooded roads and intersections, coupled with Canny edge detection and probabilistic Hough transform to calculate pole length and estimate floodwater depth. Additionally, a tilt correction technique is implemented to address the problem of sideways tilt in visual analysis of submerged stop signs. An in-house dataset, named BluPix 2020.1 consisting of paired web-mined photos of submerged stop signs across 10 FEMA regions (for U.S. locations) and Canada is used to evaluate the models. Overall, pole length is estimated with an RMSE of 17.43 and 8.61 in. in pre- and post-flood photos, respectively, leading to a mean absolute error of 12.63 in. in floodwater depth estimation. Findings of this research are sought to equip jurisdictions, local governments, and citizens in flood-prone regions with a simple, reliable, and scalable solution that can provide (near-) real time estimation of floodwater depth in their surroundings.
C1 [Kharazi, Bahareh Alizadeh] Texas A&M Univ, Dept Landscape Architecture & Urban Planning, 3137 TAMU, College Stn, TX 77843 USA.
   [Behzadan, Amir H.] Texas A&M Univ, Dept Construct Sci, 3137 TAMU, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station; Texas A&M University System; Texas A&M University College Station
RP Behzadan, AH (corresponding author), Texas A&M Univ, Dept Construct Sci, 3137 TAMU, College Stn, TX 77843 USA.
EM bahareh.alizadeh@tamu.edu; abehzadan@tamu.edu
FU National Oceanic and Atmospheric Administration (NOAA), U.S. Department of Commerce [NA18OAR4170088]
CR AECOM, 2013, IMPACT CLIMATE CHANG, V0, P0
   Alfieri L, 2017, EARTHS FUTURE, V5, P171, DOI 10.1002/2016EF000485
   Alley R. B., 2018, SEA LEVEL RISE, V16, P30, DOI 10.5065/D6445K82/
   American Climate, 2019, DEATHS MAJ EV, V0, P0
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Barz B., 2019, ENHANCING FLOOD IMPA, V0, P0, DOI DOI 10.5445/KSP/1000087327/06
   Baugh CA, 2013, WATER RESOUR RES, V49, P5276, DOI 10.1002/wrcr.20412
   Boeing G, 2020, ENVIRON PLAN B-URBAN, V47, P590, DOI 10.1177/2399808318784595
   Chaudhary P., 2019, REMOTE SENSING SPATI, V2, P5, DOI 10.5194/isprs-annals-IV-2-W5-5-2019
   Chetpattananondh K, 2014, SENSOR ACTUAT A-PHYS, V209, P175, DOI 10.1016/j.sna.2014.01.040
   Church JA, 2011, SURV GEOPHYS, V32, P585, DOI 10.1007/s10712-011-9119-1
   Cleetus R, 2013, UNION CONCERNED SCIE, V0, P0
   Cohen S, 2019, NAT HAZARD EARTH SYS, V19, P2053, DOI 10.5194/nhess-19-2053-2019
   Collins K. A., 2007, WORLD ENV WAT RES C, V0, PP1, DOI 10.1061/40927%28243%29435
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cutnell J, 1998, PHYSICS-BASEL, V2, P631
   Delgado D. F. M, 2018, PROMOTION INSTABILIT, V0, P0
   Dong SJ, 2020, COMPUT-AIDED CIV INF, V35, P668, DOI 10.1111/mice.12527
   Dunham M., 2003, DATA MINING INTRO AD, V0, P0
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan C, 2020, COMPUT ENVIRON URBAN, V83, P0, DOI 10.1016/j.compenvurbsys.2020.101514
   Farras A. W, 2020, MATLAB CENTRAL FILE, V0, P0
   Federal Emergency Management Agency, 2016, PRED REC PLANN GUID, V0, P0
   Federal Emergency Management Agency, 2010, AR YOU READ GUID, V0, P0
   Federal Highway Administration, 2004, MAN UN TRAFF CONTR D, V0, P0
   Federal Highway Administration, 2009, FHWASA10005 US DEP T, V0, P0
   First Street Foundation, 2019, FEM FLOOD MAPS LIM, V0, P0
   FloodZone, 2018, WHY YOU SHOULD PURCH, V0, P0
   Ford A, 2019, COMPUT ENVIRON URBAN, V75, P229, DOI 10.1016/j.compenvurbsys.2019.02.005
   Galloway G.E., 2018, GROWING THREAT URBAN, V0, P0
   Gebrehiwot A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071486
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Guillermo Marielet, 2020, 2020 IEEE REGION 10 CONFERENCE (TENCON), V0, PP708, DOI 10.1109/TENCON50793.2020.9293906
   Gulli A., 2017, DEEP LEARNING KERA, V0, P0
   Hauer ME, 2016, NAT CLIM CHANGE, V6, P691, DOI 10.1038/NCLIMATE2961
   Hawker L, 2018, FRONT EARTH SC-SWITZ, V6, P0, DOI 10.3389/feart.2018.00233
   Hsiao P. Y, 2006, 2006 IEEE INT S CIRC, V0, P0, DOI DOI 10.1109/ISCAS.2006.1693303.57
   Huang ZJ, 2019, PROC CVPR IEEE, V0, PP6402, DOI 10.1109/CVPR.2019.00657
   Hudson P, 2019, GLOBAL ENVIRON CHANG, V58, P0, DOI 10.1016/j.gloenvcha.2019.101966
   Incetas MO, 2019, GAZI U J SCI, V32, P458
   Kenward T, 2000, REMOTE SENS ENVIRON, V74, P432, DOI 10.1016/S0034-4257(00)00136-X
   Kwan MP, 2010, COMPUT ENVIRON URBAN, V34, P179, DOI 10.1016/j.compenvurbsys.2010.02.001
   Li XX, 2020, IOP C SER EARTH ENV, V440, P0, DOI 10.1088/1755-1315/440/3/032126
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lorencik D, 2013, IEEE 11TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2013), V0, PP85, DOI 10.1109/SAMI.2013.6480950
   McDougall K., 2012, ISPRS ANN PHOTOGRAMM, V0, PP251, DOI 10.5194/ISPRSANNALS-I-4-251-2012
   Meesuk V, 2017, COMPUT ENVIRON URBAN, V64, P239, DOI 10.1016/j.compenvurbsys.2017.03.004
   Mizutori M, 2018, EC LOSS POV DIS 1998, V0, P0
   National Oceanic and Atmospheric Administration, 2020, NAT OC ATM ADM NAT W, V0, P0
   Nayak S, 2008, REMOTE SENSING GIS T, V0, P0, DOI DOI 10.1007/978-3-540-79259-8.pdf
   OLoughlin FE, 2016, REMOTE SENS ENVIRON, V182, P49, DOI 10.1016/j.rse.2016.04.018
   Odli Z S M, 2016, ARPN J ENG APPL SCI, V11, P5352
   Ogawa Kohei, 2010, PROCEEDINGS 2010 FIRST INTERNATIONAL CONFERENCE ON NETWORKING AND COMPUTING (ICNC 2010), V0, PP279, DOI 10.1109/IC-NC.2010.13
   OpenCV Dev Team, 2019, CANN EDG DET, V0, P0
   Pan J, 2018, IEEE ACCESS, V6, P73561, DOI 10.1109/ACCESS.2018.2883702
   Park S, 2021, J COMPUT CIVIL ENG, V35, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000956
   Pedersini F, 1997, IEEE T PATTERN ANAL, V19, P1278, DOI 10.1109/34.632986
   Pi YL, 2020, ADV ENG INFORM, V43, P0, DOI 10.1016/j.aei.2019.101009
   Powers D. M., 2011, J MACH LEARN TECHNOL, V0, P0
   Public Safety Canada, 2010, EMERGENCY MANAGEMENT, V0, P0
   Puttinaovarat S, 2020, IEEE ACCESS, V8, P5885, DOI 10.1109/ACCESS.2019.2963819
   Ren S., 2015, PROC INT C NEURAL IN, V0, PP91, DOI 10.1109/ICCV.2015.169.
   Rong WB, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), V0, PP577, DOI 10.1109/ICMA.2014.6885761
   Salmonsson A., 2015, MIKE 21 FM URBAN FLO, V0, P0
   Sazara C, 2019, IEEE INT C INTELL TR, V0, PP804, DOI 10.1109/ITSC.2019.8917368
   Schumann GJP, 2014, NATURE, V507, P169, DOI 10.1038/507169e
   Shinar D, 2003, ERGONOMICS, V46, P1549, DOI 10.1080/0014013032000121615
   Simonyan K, 2015, ICLR2015 C INT C LEA, V0, P0
   Singh KK, 2018, IEEE CONF CLOUD COMP, V0, PP49, DOI 10.1109/CCEM.2018.00016
   Smith AB., 2020, 2010 2019 LANDMARK D, V0, P0
   SOBEL I, 1978, COMPUT VISION GRAPH, V8, P127, DOI 10.1016/S0146-664X(78)80020-3
   Tanyeri U, 2019, 2019 3 INT S MULT ST, V0, P1
   ten Veen PMH, 2009, J TRAUMA STRESS, V22, P505, DOI 10.1002/jts.20462
   Texas General Land Office, 2019, STAT TEX CDBG MIT CD, V0, P0
   Toyra J, 2002, HYDROL PROCESS, V16, P1569, DOI 10.1002/hyp.1021
   U.S. Department of Homeland Security, 2017, OIG17110 US DEP HOM, V0, P0
   United States Geological Survey, 2019, INTR NEXT GEN USGS W, V0, P0
   Vincent O.R., 2009, INF SCI IT ED C, V2009, P97
   Walker JP, 1999, WATER RESOUR RES, V35, P2259, DOI 10.1029/1999WR900034
   Wang R, 2013, CANNY EDGE DETECTION, V0, P0
   Yang HC, 2014, NAT HAZARDS, V74, P737, DOI 10.1007/s11069-014-1208-2
   Zhu Z., 2009, P 2009 ASCE INT WORK, V0, PP135, DOI 10.1061/41052 (346)14
NR 86
TC 26
Z9 26
U1 6
U2 15
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0198-9715
EI 1873-7587
J9 COMPUT ENVIRON URBAN
JI Comput. Environ. Urban Syst.
PD JUL 15
PY 2021
VL 88
IS 
BP 
EP 
DI 10.1016/j.compenvurbsys.2021.101628
EA APR 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research & Management Science; Regional & Urban Planning
SC Computer Science; Engineering; Environmental Sciences & Ecology; Geography; Operations Research & Management Science; Public Administration
GA SR8EO
UT WOS:000661278600004
DA 2023-04-26
ER

PT J
AU Yusof, N
   Shafri, HZM
   Shaharum, NSN
AF Yusof, Nurasmalaily
   Shafri, Helmi Zulhaidi Mohd
   Shaharum, Nur Shafira Nisa
TI The use of Landsat-8 and Sentinel-2 imageries in detecting and mapping rubber trees
SO JOURNAL OF RUBBER RESEARCH
LA English
DT Article
DE Rubber trees; Sentinel-2A; Landsat-8 OLI; Supervised classification; Remote sensing
ID classification; index; oli; plantations; multiscale; accuracy; mcnemar
AB Information on rubber tree (Hevea brasiliensis) areas and stages of rubber tree growth is needed in making decisions to maximise land use and for efficient farm management. The use of conventional methods in collecting this information requires a long time, high costs, and constraints to access certain areas. Therefore, this study was conducted to evaluate Landsat-8 OLI and Sentinel-2 images in detecting and mapping the rubber tree area. This study presents a pixel-based supervised classification approach to obtain an accurate map of land cover and rubber tree growth stage distribution using resampled 10 m spatial resolution of Sentinel-2 and pansharpened 15 m Landsat-8 OLI. Seven land cover classes (bare soil, water, mature rubber, immature rubber, oil palm, forest, and built-up area) were classified using support vector machine (SVM), artificial neural network (ANN) and spectral angle mapper (SAM). The results showed that the highest classification accuracy was obtained using SVM, 87.22% for Sentinel-2 and 85.74% for Landsat-8. Next, the classification accuracies of ANN were almost similar with 86.17% and 82.39% for Sentinel-2 and Landsat-8, respectively. SAM has produced less than 60% of acceptable accuracy for both datasets. The performance of the aforementioned classifiers was statistically tested using a McNemar test. The test showed that the p-value between SVM and ANN was not significant and thus, ANN and SVM produced similar accuracies and outperformed SAM for both cases. In this study, the best output produced via SVM from Sentinel-2 was selected to produce the thematic map due to the spatial accuracy advantage of Sentinel-2 compared to Landsat-8. The calculated areas of immature and mature rubber from the thematic map were 7.79 km(2) and 10.93 km(2), respectively, which then used to estimate the number of tappers needed for the management of rubber. It is concluded that the Sentinel-2 Multispectral Instrument (MSI) data can be recommended to be used in rubber cultivation area assessment.
C1 [Yusof, Nurasmalaily] Malaysian Rubber Board MRB, Prod Dev Div, Sungai Buloh 47000, Selangor, Malaysia.
   [Yusof, Nurasmalaily; Shafri, Helmi Zulhaidi Mohd; Shaharum, Nur Shafira Nisa] Univ Putra Malaysia UPM, Fac Engn, Dept Civil Engn, Serdang 43400, Selangor, Malaysia.
   [Yusof, Nurasmalaily; Shafri, Helmi Zulhaidi Mohd; Shaharum, Nur Shafira Nisa] Univ Putra Malaysia UPM, Fac Engn, Geospatial Informat Sci Res Ctr GISRC, Serdang 43400, Selangor, Malaysia.
C3 Universiti Putra Malaysia; Universiti Putra Malaysia
RP Shafri, HZM (corresponding author), Univ Putra Malaysia UPM, Fac Engn, Dept Civil Engn, Serdang 43400, Selangor, Malaysia.; Shafri, HZM (corresponding author), Univ Putra Malaysia UPM, Fac Engn, Geospatial Informat Sci Res Ctr GISRC, Serdang 43400, Selangor, Malaysia.
EM helmi@upm.edu.my
FU Universiti Putra Malaysia (UPM); Malaysian Rubber Board
CR Abd Razak JAB, 2018, GEOCARTO INT, V33, P627, DOI 10.1080/10106049.2017.1289559
   [Anonymous], 2013, NUMBER NODES LAYERS, V0, P0
   Aziz A, 2014, THESIS, V0, P0
   Cho MA, 2010, IEEE T GEOSCI REMOTE, V48, P4133, DOI 10.1109/TGRS.2010.2058579
   Clevers JGPW, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050405
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Delloye C, 2018, REMOTE SENS ENVIRON, V216, P245, DOI 10.1016/j.rse.2018.06.037
   Dibs H, 2014, 35 AS C REM SENS 201, V0, P0
   Dibs H, 2017, EGYPT J REMOTE SENS, V20, P21, DOI 10.1016/j.ejrs.2017.01.004
   DWYER AJ, 1991, RADIOLOGY, V178, P328, DOI 10.1148/radiology.178.2.1987587
   ESRI, 2011, ARCGIS DESKT REL 10, V0, P0
   Fagerland MW, 2013, BMC MED RES METHODOL, V13, P0, DOI 10.1186/1471-2288-13-91
   Fan H, 2015, REMOTE SENS-BASEL, V7, P6041, DOI 10.3390/rs70506041
   Foody GM, 2009, INT J REMOTE SENS, V30, P5273, DOI 10.1080/01431160903130937
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Gallego FJ, 2014, INT J APPL EARTH OBS, V29, P22, DOI 10.1016/j.jag.2013.12.013
   Gao F, 2017, REMOTE SENS ENVIRON, V188, P9, DOI 10.1016/j.rse.2016.11.004
   Han PP, 2018, INT J REMOTE SENS, V39, P2189, DOI 10.1080/01431161.2017.1420933
   Harris Geospatial Solutions, 2016, US ENVI, V0, P0
   Harris Geospatial Solutions, 2017, SPECTR ANGL MAPP, V0, P0, DOI DOI 10.1002/(SICI)1096-9926(199606)54:2<less than>84::AID-TERA4<greater than>3.0.CO;2-4
   Hazir MHM, 2020, EGYPT J REMOTE SENS, V23, P35, DOI 10.1016/j.ejrs.2018.05.001
   Kamal M, 2015, REMOTE SENS-BASEL, V7, P4753, DOI 10.3390/rs70404753
   Keshtkar H, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2899-y
   Kuo BC, 2014, IEEE J-STARS, V7, P317, DOI 10.1109/JSTARS.2013.2262926
   Li QT, 2015, REMOTE SENS-BASEL, V7, P16091, DOI 10.3390/rs71215820
   Malaysian Rubber Board, 2009, RUBB PLANT PROC TECH, V0, P301
   Malaysian Rubber Board, 2018, NAT RUBB STAT JAN DE, V0, P0
   Malaysian Rubber Board, 2014, PAND LAD 2014, V0, P0
   Malaysian Rubber Board, 2020, SMR 20 PRIC CHART 20, V0, P0
   Marin DB, 2019, PRECIS AGRIC, V20, P959, DOI 10.1007/s11119-018-09623-9
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Mooibroek H, 2000, APPL MICROBIOL BIOT, V53, P355, DOI 10.1007/s002530051627
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Nguyen H.T.T., 2018, INT ARCHIV PHOTOGRAM, V42, P363, DOI 10.5194/isprs-archives-XLII-3-W4-363-2018
   Park B, 2007, BIOSYST ENG, V96, P323, DOI 10.1016/j.biosystemseng.2006.11.012
   PCI Geomatics, 2018, GEOM ONL HELP, V0, P0
   Phinn SR, 2012, INT J REMOTE SENS, V33, P3768, DOI 10.1080/01431161.2011.633122
   Richter R., 2007, ATMOSPHERIC TOPOGRAP, V0, P0
   Saufe N. A., 2017, IOSR J AGR VET SCI, V10, P29, DOI 10.9790/2380-1002022932
   Shafri H. Z. M., 2017, MACHINE LEARNING HYP, V0, PP3, DOI 10.1142/9789813206823_0001
   Shaharum NSN., 2018, REMOTE SENS APPL SOC, V10, P24, DOI 10.1016/j.rsase.2018.01.002
   Shang K, 2011, PROC SPIE, V8002, P0, DOI 10.1117/12.902908
   SNAP, 2016, SNAP OP SOURC SOFTW, V0, P0
   Trajman A, 2008, SCAND J CLIN LAB INV, V68, P77, DOI 10.1080/00365510701666031
   Trimble Navigation, 1996, TRIMBL PATHF OFF SOF, V0, P432
   Veysi S, 2017, AGR WATER MANAGE, V189, P70, DOI 10.1016/j.agwat.2017.04.016
   Waldner F, 2016, INT J REMOTE SENS, V37, P3196, DOI 10.1080/01431161.2016.1194545
   Xiao CW, 2019, REMOTE SENS LETT, V10, P214, DOI 10.1080/2150704X.2018.1541106
   Yonezawa C, 2007, INT J REMOTE SENS, V28, P3729, DOI 10.1080/01431160701373713
NR 49
TC 2
Z9 3
U1 0
U2 14
PU SPRINGER SINGAPORE PTE LTD
PI SINGAPORE
PA #04-01 CENCON I, 1 TANNERY RD, SINGAPORE 347719, SINGAPORE
SN 1511-1768
EI 2524-3993
J9 J RUBBER RES
JI J. Rubber Res.
PD MAR 15
PY 2021
VL 24
IS 1
BP 121
EP 135
DI 10.1007/s42464-020-00078-0
EA JAN 2021
PG 15
WC Polymer Science
SC Polymer Science
GA QV2RH
UT WOS:000612880100001
DA 2023-04-26
ER

PT J
AU Zhang, F
   Liu, FL
   Xu, R
   Luo, XY
   Ding, SC
   Tian, HC
AF Zhang, Fan
   Liu, Fenlin
   Xu, Rui
   Luo, Xiangyang
   Ding, Shichang
   Tian, Hechan
TI Street-Level IP Geolocation Algorithm Based on Landmarks Clustering
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE IP geolocation; neural network; landmarks clustering; delay similarity; relative hop
ID network
AB Existing IP geolocation algorithms based on delay similarity often rely on the principle that geographically adjacent IPs have similar delays. However, this principle is often invalid in real Internet environment, which leads to unreliable geolocation results. To improve the accuracy and reliability of locating IP in real Internet, a street-level IP geolocation algorithm based on landmarks clustering is proposed. Firstly, we use the probes to measure the known landmarks to obtain their delay vectors, and cluster landmarks using them. Secondly, the landmarks are clustered again by their latitude and longitude, and the intersection of these two clustering results is taken to form training sets. Thirdly, we train multiple neural networks to get the mapping relationship between delay and location in each training set. Finally, we determine one of the neural networks for the target by the delay similarity and relative hop counts, and then geolocate the target by this network. As it brings together the delay and geographical coordinates clustering, the proposed algorithm largely improves the inconsistency between them and enhances the mapping relationship between them. We evaluate the algorithm by a series of experiments in Hong Kong, Shanghai, Zhengzhou and New York. The experimental results show that the proposed algorithm achieves street-level IP geolocation, and comparing with existing typical street level geolocation algorithms, the proposed algorithm improves the geolocation reliability significantly.
C1 [Zhang, Fan; Liu, Fenlin; Luo, Xiangyang; Tian, Hechan] PLA Strateg Support Force Informat Engn Univ, Zhengzhou 450001, Peoples R China.
   [Zhang, Fan; Liu, Fenlin; Luo, Xiangyang; Tian, Hechan] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
   [Xu, Rui] Cyberspace Secur Key Lab Sichuan Prov, Chengdu 610000, Peoples R China.
   [Xu, Rui] China Elect Technol Cyber Secur Co Ltd, Chengdu 610000, Peoples R China.
   [Ding, Shichang] Univ Goettingen, D-37075 Gottingen, Germany.
C3 PLA Information Engineering University; PLA Information Engineering University; University of Gottingen
RP Liu, FL (corresponding author), PLA Strateg Support Force Informat Engn Univ, Zhengzhou 450001, Peoples R China.; Liu, FL (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
EM liufenlin@vip.sina.com
FU National Key R&D Program of China [2016YFB0801303, 2016QY01W0105]; National Natural Science Foundation of China [U1636219, 61772549, U1736214, U1804263]; Science and Technology Innovation Talent Project of Henan Province [184200510018]
CR ARIF MJ, 2010, P 33 AUSTR C COMP SC, V102, P89
   Augustin B., 2006, P 6 ACM SIGCOMM C IN, V0, PP153, DOI 10.1145/1177080.1177100
   Chen JN, 2018, J INTERNET TECHNOL, V19, P2096, DOI 10.3966/160792642018121907013
   Dan O, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM16), V0, PP347, DOI 10.1145/2835776.2835820
   Eriksson B, 2008, ACM SIGCOMM COMP COM, V38, P291, DOI 10.1145/1402946.1402992
   Eriksson B, 2010, LECT NOTES COMPUT SC, V6032, P171, DOI 10.1007/978-3-642-12334-4_18
   Govindan R., 2000, PROCEEDINGS IEEE INFOCOM 2000. CONFERENCE ON COMPUTER COMMUNICATIONS. NINETEENTH ANNUAL JOINT CONFERENCE OF THE IEEE COMPUTER AND COMMUNICATIONS SOCIETIES (CAT. NO.00CH37064), V0, PP1371, DOI 10.1109/INFCOM.2000.832534
   Gueye B, 2006, IEEE ACM T NETWORK, V14, P1219, DOI 10.1109/TNET.2006.886332
   IP2location, 2020, ID GEOGR LOC IP ADDR, V0, P0
   Li RX, 2019, CMC-COMPUT MATER CON, V59, P591, DOI 10.32604/cmc.2019.05208
   LIPPMANN RP, 1989, IEEE COMMUN MAG, V27, P47, DOI 10.1109/35.41401
   Liu SQ, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2016), V0, PP109, DOI 10.1109/INFOCOMAN.2016.7784225
   Liu Y, 2019, CMC-COMPUT MATER CON, V58, P79, DOI 10.32604/cmc.2019.03626
   Maxmind, 2020, DET ONL FRAUD LOC ON, V0, P0
   Muir JA, 2009, ACM COMPUT SURV, V42, P0, DOI 10.1145/1592451.1592455
   Padmanabhan VN, 2001, ACM SIGCOMM COMP COM, V31, P173, DOI 10.1145/964723.383073
   Poese I, 2011, ACM SIGCOMM COMP COM, V41, P53, DOI 10.1145/1971162.1971171
   Shavitt Y, 2011, IEEE J SEL AREA COMM, V29, P2044, DOI 10.1109/JSAC.2011.111214
   Wang Yong, 2011, P 8 USENIX C NETW SY, V0, P365
   Wang YH, 2019, CMC-COMPUT MATER CON, V59, P983, DOI 10.32604/cmc.2019.05547
   Whois, 2020, WHOIS LOOK, V0, P0
   Wong B., 2007, P 4 USENIX C NETW SY, V0, P313
   Yuan FX, 2019, IEEE ACCESS, V7, P28340, DOI 10.1109/ACCESS.2019.2902337
   Zhang K, 2016, 2016 SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), V0, PP117, DOI 10.1109/ICICIP.2016.7885887
   Zhao F., 2018, CONCURR COMP-PRACT E, V31, P0
   Zhu G, 2016, INT CONF ADV COMMUN, V0, PP306, DOI 10.1109/ICACT.2016.7423370
   Zu SD, 2018, IEEE ACCESS, V6, P64867, DOI 10.1109/ACCESS.2018.2878309
NR 27
TC 1
Z9 1
U1 3
U2 7
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PD JUN 15
PY 2021
VL 66
IS 3
BP 3345
EP 3361
DI 10.32604/cmc.2021.014526
PG 17
WC Computer Science, Information Systems; Materials Science, Multidisciplinary
SC Computer Science; Materials Science
GA PN6NF
UT WOS:000604593000001
DA 2023-04-26
ER

PT J
AU Arapostathis, SG
AF Arapostathis, Stathis G.
TI The Ianos Cyclone (September 2020, Greece) from Perspective of Utilizing Social Networks for DM
SO INFORMATION TECHNOLOGY IN DISASTER RISK REDUCTION, ITDRR 2020
LA English
DT Proceedings Paper
DE Machine learning; Disaster management; Social media; Volunteered Geographic Information; Ianos cyclone
AB Main purpose of current research is to present evolutions in previous presented approaches of the author for manipulating social media content for disaster management of natural events. Those innovations suggest the adoption of machine learning for classifying both photos and text posted in social networks along with hybrid geo-referencing. As case study the author chose the Ianos cyclone, occurred between Italy and Greece, during September 2020. The geographic focus of the research was in Greece where the cyclone caused 4 human losses and damages in the urban environment. A dataset consisted of 4655 photos, with their corresponding captions, timestamps and location information was crawled from Instagram. The main hashtag used was #Ianos. Two data samples, one for each type, were classified manually for calibrating the classification models. The classes regarding photos were initially: (i) related and (ii) not related to Ianos, while the general classification schema for photos and text was: (i) Ianos event identification, (ii) consequences, scaled according to the impact of each report, (iii) precaution, (iv) disaster management: announcements, measures, volunteered actions. Author's approach regarding classification suggests the use of convolutional neural networks and support vector machine algorithms for image and text classification respectively. The classified dataset, was geo-referenced by using commercial geocoding API and list-based geoparsing. The results of the research in current status are at an initial level, a subset of data though of automatically or manually processed information is presented in four related maps.
C1 [Arapostathis, Stathis G.] Harokopio Univ, Athens 17671, Greece.
C3 Harokopio University Athens
RP Arapostathis, SG (corresponding author), Harokopio Univ, Athens 17671, Greece.
CR Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Annis A, 2019, GEO-SPAT INF SCI, V22, P223, DOI 10.1080/10095020.2019.1626135
   Arapostathis S.G., 2019, IAICT, V550, P142, DOI 10.1007/978-3-030-32169-7_11
   Arapostathis S.G., 2020, FLOOD IMPACT MITIGAT, V0, P0
   Arapostathis S.G., 2018, P GEOM INT C 2K SYR, V0, P0
   Asghar M.Z., 2014, SCI INT LAHORE, V26, P385
   Crooks A, 2013, T GIS, V17, P124, DOI 10.1111/j.1467-9671.2012.01359.x
   de Bruijn JA, 2018, J GEOVIS SPAT ANAL, V2, P0, DOI 10.1007/s41651-017-0010-6
   De Longueville Bertrand, 2009, P 2009 INT WORKSH LO, V0, PP73, DOI 10.1145/1629890.1629907
   Depoux A, 2020, J TRAVEL MED, V27, P0, DOI 10.1093/jtm/taaa031
   Feng Y, 2020, ARXIV, V0, P0
   Feng Y, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7020039
   Gao H, 2011, IEEE INTELL SYST, V26, P10, DOI 10.1109/MIS.2011.52
   Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y
   Gorayeb A, 2020, J LAT AM GEOGR, V19, P260, DOI 10.1353/lag.2020.0048
   Grunder-Fahrer S, 2018, LECT NOTES ARTIF INT, V10713, P199, DOI 10.1007/978-3-319-73706-5_17
   Hernandez-Suarez A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071746
   Kankanamge N, 2020, INT J DISAST RISK RE, V42, P0, DOI 10.1016/j.ijdrr.2019.101360
   Li ZL, 2018, CARTOGR GEOGR INF SC, V45, P97, DOI 10.1080/15230406.2016.1271356
   Stojanovski D., 2016, EUROPEAN HDB CROWDSO, V0, P223
   Suliman A, 2013, PROC INT CONF COMP, V0, P327
   Yang C., 2017, 6 INT C AGRO GEOINFO, V0, P1
NR 23
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1868-4238
EI 1868-422X
J9 IFIP ADV INF COMM TE
PD JUN 15
PY 2021
VL 622
IS 
BP 160
EP 169
DI 10.1007/978-3-030-81469-4_13
PG 10
WC Computer Science, Information Systems; Green & Sustainable Science & Technology; Engineering, Industrial
SC Computer Science; Science & Technology - Other Topics; Engineering
GA BT7WD
UT WOS:000851272600013
DA 2023-04-26
ER

PT J
AU Wang, YJ
   Li, XF
   Song, JM
   Li, XG
   Zhong, GR
   Zhang, B
AF Wang, Yanjun
   Li, Xiaofeng
   Song, Jinming
   Li, Xuegang
   Zhong, Guorong
   Zhang, Bin
TI Carbon Sinks and Variations of pCO(2) in the Southern Ocean From 1998 to 2018 Based on a Deep Learning Approach
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Carbon sink; feedforward neural network (FFNN); machine learning; pCO(2); Southern Ocean
ID seasonal cycle; co2 fluxes; anthropogenic carbon; variability; storage
AB The Southern Ocean comprises 25% of the global ocean surface area, accounts for nearly half of the total carbon sink of the global oceans, and is a place that significantly reduces the impacts of anthropogenic CO2 emissions. Due to the sparsity of observational data, the changes in Southern Ocean carbon sinks over time remain uncertain. In this study, we integrated correlation analysis and a feedforward neural network to improve the accuracy of carbon flux estimations in the Southern Ocean. Based on observation data from 1998-2018, we reconstructed the Southern Ocean's pCO(2) grid data during this period. The root-mean-square error obtained by fitting the observation data was 8.86 mu atm, indicating that the results were better than those of the two primary statistically based models in the Surface Ocean pCO(2) mapping intercomparison. The results also showed that the Southern Ocean's capacity to act as a carbon sink has gradually increased since 2000; it reduced during 2010-2013 but increased significantly after that. The Southern Ocean's seasonality is characterized by minimum carbon uptake in winter due to increased upwelling; this is followed by a rapid increase toward maximum uptake in summer, which is mainly biologically driven. There is an apparent double-ring structure in the Southern Ocean, as noted in other studies. This study confirms that the inner ring (50-70 degrees S) is a carbon source area gradually transforming into a carbon sink, while the outer ring (35-50 degrees S) continues to serve as a carbon sink.
C1 [Wang, Yanjun; Li, Xiaofeng; Zhang, Bin] Chinese Acad Sci, Dept Marine Sci Data Ctr, Inst Oceanol, Qingdao 266071, Peoples R China.
   [Wang, Yanjun; Li, Xiaofeng; Song, Jinming; Li, Xuegang; Zhong, Guorong; Zhang, Bin] Chinese Acad Sci, Ctr Ocean Megasci, Qingdao 266071, Peoples R China.
   [Song, Jinming; Li, Xuegang; Zhong, Guorong] Chinese Acad Sci, Inst Oceanol, Key Lab Marine Ecol & Environm Sci, Qingdao 266071, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Oceanology, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Oceanology, CAS
RP Li, XF (corresponding author), Chinese Acad Sci, Dept Marine Sci Data Ctr, Inst Oceanol, Qingdao 266071, Peoples R China.; Li, XF (corresponding author), Chinese Acad Sci, Ctr Ocean Megasci, Qingdao 266071, Peoples R China.
EM yjwang@qdio.ac.cn; xiaofeng.li@ieee.org; jmsong@qdio.ac.cn; xiaofeng.li@ieee.org; zhongguorong18@mails.ucas.ac.cn; zhangbin@qdio.ac.cn
FU National Key R&D Program of China [2017YFA0603201]; 13th FiveYear Informatization Plan of the Chinese Academy of Sciences, Construction of Scientific Data Center System [XXH-13514]; Big Earth Data Science Engineering Project [XDA19060104]
CR Anderson RF, 2009, SCIENCE, V323, P1443, DOI 10.1126/science.1167441
   Caldeira K, 2000, SCIENCE, V287, P620, DOI 10.1126/science.287.5453.620
   Cheng LJ, 2020, J CLIMATE, V33, P10357, DOI 10.1175/JCLI-D-20-0366.1
   Cosca CE, 2003, J GEOPHYS RES-OCEANS, V108, P0, DOI 10.1029/2000JC000677
   Denvil-Sommer A, 2019, GEOSCI MODEL DEV, V12, P2091, DOI 10.5194/gmd-12-2091-2019
   Friedlingstein P, 2019, EARTH SYST SCI DATA, V11, P1783, DOI 10.5194/essd-11-1783-2019
   Frolicher TL, 2015, J CLIMATE, V28, P862, DOI 10.1175/JCLI-D-14-00117.1
   Fung IY, 2005, P NATL ACAD SCI USA, V102, P11201, DOI 10.1073/pnas.0504949102
   Gregor L, 2019, GEOSCI MODEL DEV, V12, P5113, DOI 10.5194/gmd-12-5113-2019
   Gregor L, 2018, BIOGEOSCIENCES, V15, P2361, DOI 10.5194/bg-15-2361-2018
   Gregor L, 2017, BIOGEOSCIENCES, V14, P5551, DOI 10.5194/bg-14-5551-2017
   Gruber N, 2019, ANNU REV MAR SCI, V11, P159, DOI 10.1146/annurev-marine-121916-063407
   Jones SD, 2015, J ADV MODEL EARTH SY, V7, P1554, DOI 10.1002/2014MS000416
   Keppler L, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-43826-y
   Khatiwala S, 2013, BIOGEOSCIENCES, V10, P2169, DOI 10.5194/bg-10-2169-2013
   Kortzinger A., 2007, METHODS SEAWATER ANA, V0, P149
   Lacis AA, 2010, SCIENCE, V330, P356, DOI 10.1126/science.1190653
   Landschutzer P, 2013, BIOGEOSCIENCES, V10, P7793, DOI 10.5194/bg-10-7793-2013
   Landschutzer P, 2016, GLOBAL BIOGEOCHEM CY, V30, P1396, DOI 10.1002/2015GB005359
   Landschutzer P, 2018, NAT CLIM CHANGE, V8, P146, DOI 10.1038/s41558-017-0057-x
   Landschutzer P, 2015, SCIENCE, V349, P1221, DOI 10.1126/science.aab2620
   Majkut JD, 2014, PHILOS T R SOC A, V372, P0, DOI 10.1098/rsta.2013.0046
   Metzl N, 2006, DEEP-SEA RES PT I, V53, P1548, DOI 10.1016/j.dsr.2006.07.006
   Mongwe NP, 2018, BIOGEOSCIENCES, V15, P2851, DOI 10.5194/bg-15-2851-2018
   Morrison AK, 2015, PHYS TODAY, V68, P27, DOI 10.1063/PT.3.2654
   Park GH, 2010, TELLUS B, V62, P352, DOI 10.1111/j.1600-0889.2010.00498.x
   Peylin P, 2005, GLOBAL BIOGEOCHEM CY, V19, P0, DOI 10.1029/2003GB002214
   Pinho L, 2016, BIOGEOSCIENCES, V13, P865, DOI 10.5194/bg-13-865-2016
   Ritter R, 2017, GEOPHYS RES LETT, V44, P12339, DOI 10.1002/2017GL074837
   Rodenbeck C, 2005, ESTIMATING CO2 SOURC, V2010, P0
   Rodenbeck C, 2015, BIOGEOSCIENCES, V12, P7251, DOI 10.5194/bg-12-7251-2015
   Ruder S., 2016, OVERVIEW GRADIENT DE, V2016, P0
   Shadwick EH, 2015, GLOBAL BIOGEOCHEM CY, V29, P223, DOI 10.1002/2014GB004906
   Silvano A, 2020, NAT GEOSCI, V13, P4, DOI 10.1038/s41561-019-0516-2
   Takahashi T, 2012, OCEANOGRAPHY, V25, P26, DOI 10.5670/oceanog.2012.71
   Takahashi T, 2009, DEEP-SEA RES PT II, V56, P554, DOI 10.1016/j.dsr2.2008.12.009
   Takao S, 2020, DEEP-SEA RES PT I, V160, P0, DOI 10.1016/j.dsr.2020.103263
   Thomalla SJ, 2011, BIOGEOSCIENCES, V8, P2849, DOI 10.5194/bg-8-2849-2011
   WANNINKHOF R, 1992, J GEOPHYS RES-OCEANS, V97, P7373, DOI 10.1029/92JC00188
   Wanninkhof R, 2013, BIOGEOSCIENCES, V10, P1983, DOI 10.5194/bg-10-1983-2013
   Watson AJ, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-18203-3
NR 42
TC 9
Z9 9
U1 14
U2 58
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3495
EP 3503
DI 10.1109/JSTARS.2021.3066552
PG 9
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RK6JR
UT WOS:000638400600005
DA 2023-04-26
ER

PT J
AU Li, XH
   Hou, JL
   Huang, CL
AF Li, Xianghua
   Hou, Jinliang
   Huang, Chunlin
TI High-Resolution Gridded Livestock Projection for Western China Based on Machine Learning
SO REMOTE SENSING
LA English
DT Article
DE machine learning; livestock; spatialization; western China
ID patterns; ducks
AB Accurate high-resolution gridded livestock distribution data are of great significance for the rational utilization of grassland resources, environmental impact assessment, and the sustainable development of animal husbandry. Traditional livestock distribution data are collected at the administrative unit level, which does not provide a sufficiently detailed geographical description of livestock distribution. In this study, we proposed a scheme by integrating high-resolution gridded geographic data and livestock statistics through machine learning regression models to spatially disaggregate the livestock statistics data into 1 km x 1 km spatial resolution. Three machine learning models, including support vector machine (SVM), random forest (RF), and deep neural network (DNN), were constructed to represent the complex nonlinear relationship between various environmental factors (e.g., land use practice, topography, climate, and socioeconomic factors) and livestock density. By applying the proposed method, we generated a set of 1 km x 1 km spatial distribution maps of cattle and sheep for western China from 2000 to 2015 at five-year intervals. Our projected cattle and sheep distribution maps reveal the spatial heterogeneity structures and change trend of livestock distribution at the grid level from 2000 to 2015. Compared with the traditional census livestock density, the gridded livestock distribution based on DNN has the highest accuracy, with the determinant coefficient (R-2) of 0.75, root mean square error (RMSE) of 9.82 heads/km(2) for cattle, and the R-2 of 0.73, RMSE of 31.38 heads/km(2) for sheep. The accuracy of the RF is slightly lower than the DNN but higher than the SVM. The projection accuracy of the three machine learning models is superior to those of the published Gridded Livestock of the World (GLW) datasets. Consequently, deep learning has the potential to be an effective tool for high-resolution gridded livestock projection by combining geographic and census data.
C1 [Li, Xianghua; Hou, Jinliang; Huang, Chunlin] Northwest Inst Ecoenvironm & Resources, Chinese Acad Sci, Key Lab Remote Sensing Gansu Prov, Lanzhou 730000, Peoples R China.
   [Li, Xianghua; Hou, Jinliang; Huang, Chunlin] Northwest Inst Ecoenvironm & Resources, Chinese Acad Sci, Heihe Remote Sensing Expt Res Stn, Zhangye 734000, Peoples R China.
   [Li, Xianghua] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Hou, JL (corresponding author), Northwest Inst Ecoenvironm & Resources, Chinese Acad Sci, Key Lab Remote Sensing Gansu Prov, Lanzhou 730000, Peoples R China.; Hou, JL (corresponding author), Northwest Inst Ecoenvironm & Resources, Chinese Acad Sci, Heihe Remote Sensing Expt Res Stn, Zhangye 734000, Peoples R China.
EM lixianghua@lzb.ac.cn; jlhours@lzb.ac.cn; huangcl@lzb.ac.cn
CR [Anonymous], 2008, TRAVEL TIME MAJOR CI, V0, P0, DOI DOI 10.6084/M9.FIGSHARE.7638134
   [Anonymous], 2007, GRIDDED LIVESTOCK WO, V0, P0
   Bailey DW, 2015, ANIM PROD SCI, V55, P298, DOI 10.1071/AN14462
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cecchi G, 2010, AGR ECOSYST ENVIRON, V135, P98, DOI 10.1016/j.agee.2009.08.011
   [董南 Dong Nan], 2016, 地球信息科学学报 JOURNAL OF GEO-INFORMATION SCIENCE, V18, P1295
   El Moustaid F, 2021, PARASITE VECTOR, V14, P0, DOI 10.1186/s13071-021-04826-y
   Fang K. N., 2011, J STAT INFORM, V26, P32, DOI 10.3969/J.ISSN.1007-3116.2011.03.006
   Ganskopp D., 2007, U CALIF DIV AGR NAT, V8217, P20
   Gilbert M, 2018, SCI DATA, V5, P0, DOI 10.1038/sdata.2018.227
   GOODCHILD MF, 1993, ENVIRON PLANN A, V25, P383, DOI 10.1068/a250383
   Hollings T, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0183626
   Kruska RL, 2003, AGR SYST, V77, P39, DOI 10.1016/S0308-521X(02)00085-9
   Kuwata K, 2015, INT GEOSCI REMOTE SE, V0, PP858, DOI 10.1109/IGARSS.2015.7325900
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leng GY, 2021, SCI TOTAL ENVIRON, V760, P0, DOI 10.1016/j.scitotenv.2020.144035
   Liu JY, 2014, J GEOGR SCI, V24, P195, DOI 10.1007/s11442-014-1082-6
   Liu JY, 2005, REMOTE SENS ENVIRON, V98, P442, DOI 10.1016/j.rse.2005.08.012
   Liu XY, 2020, J METEOROL RES-PRC, V34, P646, DOI 10.1007/s13351-020-9133-7
   Lloyd CT, 2017, SCI DATA, V4, P0, DOI 10.1038/sdata.2017.1
   Merkel GD, 2018, ENERGIES, V11, P0, DOI 10.3390/en11082008
   Monteny GJ, 2006, AGR ECOSYST ENVIRON, V112, P163, DOI 10.1016/j.agee.2005.08.015
   Neumann K, 2009, LANDSCAPE ECOL, V24, P1207, DOI 10.1007/s10980-009-9357-5
   Nicolas G, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0150424
   Olesen JE, 2006, AGR ECOSYST ENVIRON, V112, P207, DOI 10.1016/j.agee.2005.08.022
   Pasolli L, 2011, IEEE GEOSCI REMOTE S, V8, P1080, DOI 10.1109/LGRS.2011.2156759
   Peng S., 2020, BIG EARTH DATA PLATF, V0, P0
   Piipponen J., 2021, EARTH SPACE SCI OPEN, V0, P0, DOI DOI 10.1002/essoar.10505875.1
   Prosser DJ, 2011, AGR ECOSYST ENVIRON, V141, P381, DOI 10.1016/j.agee.2011.04.002
   Qiao Y. X., 2017, SCI CHINA TECHNOL SC, V49, P53, DOI 10.3772/J.ISSN.1674-1544.2017.06.008
   Raynor EJ, 2021, RANGELAND ECOL MANAG, V75, P91, DOI 10.1016/j.rama.2020.12.002
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Robinson TP, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0096084
   Scorneti Erwan, 2017, ESAIM: PROCEEDINGS AND SURVEYS, V60, P144, DOI 10.1051/proc/201760144
   Steinfeld H., 2006, LIVESTOCKS LONG SHADOW: ENVIRONMENTAL ISSUES AND OPTIONS, V0, P0
   Thomas S, 2017, GEOMAT NAT HAZ RISK, V8, P177, DOI 10.1080/19475705.2016.1176604
   Van Boeckel TP, 2011, AGR ECOSYST ENVIRON, V141, P373, DOI 10.1016/j.agee.2011.04.013
   Van Velthuizen H., 2007, MAPPING BIOPHYSICAL, V0, P0
   Vapnik V., 2013, NATURE STAT LEARNING, V0, P0
   Wang M. L., 2018, ISSUES AGR EC, V8, P60, DOI 10.13246/j.cnki.iae.2018.08.007
   Wang YC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213645
   Weiss DJ, 2018, NATURE, V553, P333, DOI 10.1038/nature25181
   Zhang L, 2021, ECOSYST HEALTH SUST, V7, P0, DOI 10.1080/20964129.2021.1918024
   Zhao S, 2020, J CLEAN PROD, V256, P0, DOI 10.1016/j.jclepro.2020.120644
   Zhou L, 2018, APPL GEOGR, V90, P282, DOI 10.1016/j.apgeog.2017.10.006
NR 47
TC 3
Z9 3
U1 11
U2 32
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 15
PY 2021
VL 13
IS 24
BP 
EP 
DI 10.3390/rs13245038
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XY8RY
UT WOS:000737233900001
DA 2023-04-26
ER

PT J
AU Rahman, MS
   Pientong, C
   Zafar, S
   Ekalaksananan, T
   Paul, RE
   Haque, U
   Rocklov, J
   Overgaard, HJ
AF Rahman, M. S.
   Pientong, Chamsai
   Zafar, Sumaira
   Ekalaksananan, Tipaya
   Paul, Richard E.
   Haque, Ubydul
   Rocklov, Joacim
   Overgaard, Hans J.
TI Mapping the spatial distribution of the dengue vector Aedes aegypti and predicting its abundance in northeastern Thailand using machine-learning approach
SO ONE HEALTH
LA English
DT Article
DE Supervised learning; Aedes aegypti; Prediction; Dengue; Early warning
ID malaria transmission; precipitation; dynamics; density
AB Background: Mapping the spatial distribution of the dengue vector Aedes (Ae.) aegypti and accurately predicting its abundance are crucial for designing effective vector control strategies and early warning tools for dengue epidemic prevention. Socio-ecological and landscape factors influence Ae. aegypti abundance. Therefore, we aimed to map the spatial distribution of female adult Ae. aegypti and predict its abundance in northeastern Thailand based on socioeconomic, climate change, and dengue knowledge, attitude and practices (KAP) and/or landscape factors using machine learning (ML)-based system. Method: A total of 1066 females adult Ae. aegypti were collected from four villages in northeastern Thailand during January-December 2019. Information on household socioeconomics, KAP regarding climate change and dengue, and satellite-based landscape data were also acquired. Geographic information systems (GIS) were used to map the household-based spatial distribution of female adult Ae. aegypti abundance (high/low). Five popular supervised learning models, logistic regression (LR), support vector machine (SVM), k-nearest neighbor (kNN), artificial neural network (ANN), and random forest (RF), were used to predict females adult Ae. aegypti abundance (high/low). The predictive accuracy of each modeling technique was calculated and evaluated. Important variables for predicting female adult Ae. aegypti abundance were also identified using the best-fitted model. Results: Urban areas had higher abundance of female adult Ae. aegypti compared to rural areas. Overall, study respondents in both urban and rural areas had inadequate KAP regarding climate change and dengue. The average landscape factors per household in urban areas were rice crop (47.4%), natural tree cover (17.8%), built-up area (13.2%), permanent wetlands (21.2%), and rubber plantation (0%), and the corresponding figures for rural areas were 12.1, 2.0, 38.7, 40.1 and 0.1% respectively. Among all assessed models, RF showed the best prediction performance (socioeconomics: area under curve, AUC = 0.93, classification accuracy, CA = 0.86, F1 score = 0.85; KAP: AUC = 0.95, CA = 0.92, F1 = 0.90; landscape: AUC = 0.96, CA = 0.89, F1 = 0.87) for female adult Ae. aegypti abundance. The combined influences of all factors further improved the predictive accuracy in RF model (socioeconomics + KAP + landscape: AUC = 0.99, CA = 0.96 and F1 = 0.95). Dengue prevention practices were shown to be the most important predictor in the RF model for female adult Ae. aegypti abundance in northeastern Thailand. Conclusion: The RF model is more suitable for the prediction of Ae. aegypti abundance in northeastern Thailand. Our study exemplifies that the application of GIS and machine learning systems has significant potential for understanding the spatial distribution of dengue vectors and predicting its abundance. The study findings might help optimize vector control strategies, future mosquito suppression, prediction and control strategies of epidemic arboviral diseases (dengue, chikungunya, and Zika). Such strategies can be incorporated into One Health approaches applying transdisciplinary approaches considering human-vector and agro-environmental interrelationships.
C1 [Rahman, M. S.; Pientong, Chamsai; Ekalaksananan, Tipaya; Overgaard, Hans J.] Khon Kaen Univ, Fac Med, Dept Microbiol, Khon Kaen, Thailand.
   [Rahman, M. S.] Begum Rokeya Univ, Dept Stat, Rangpur 5404, Rangpur, Bangladesh.
   [Pientong, Chamsai; Ekalaksananan, Tipaya] Khon Kaen Univ, HPV & EBV & Carcinogenesis Res Grp, Khon Kaen, Thailand.
   [Zafar, Sumaira] Asian Inst Technol, Environm Engn & Management Program, Pathum Thani, Thailand.
   [Paul, Richard E.] Inst Pasteur, CNRS UMR 2000, Unite Genet Fonct Malad Infect, F-75015 Paris, France.
   [Haque, Ubydul] Univ North Texas, Hlth Sci Ctr, Dept Biostat & Epidemiol, Ft Worth, TX 76177 USA.
   [Rocklov, Joacim] Umea Univ, Dept Publ Hlth & Clin Med, S-90187 Umea, Sweden.
   [Overgaard, Hans J.] Norwegian Univ Life Sci, Fac Sci & Technol, POB 5003, As, Norway.
C3 Khon Kaen University; Khon Kaen University; Asian Institute of Technology; UDICE-French Research Universities; Universite Paris Cite; Le Reseau International des Instituts Pasteur (RIIP); Institut Pasteur Paris; University of North Texas System; University of North Texas Denton; Umea University; Norwegian University of Life Sciences
RP Rahman, MS (corresponding author), Khon Kaen Univ, Fac Med, Dept Microbiol, Khon Kaen, Thailand.; Overgaard, HJ (corresponding author), Norwegian Univ Life Sci, Fac Sci & Technol, POB 5003, As, Norway.
EM siddikur@brur.ac.bd; hans.overgaard@nmbu.no
FU Research Council of Norway [281077]; Khon Kaen University Faculty of Medicine [IN63312]
CR Achee NL, 2019, PLOS NEGLECT TROP D, V13, P0, DOI 10.1371/journal.pntd.0006822
   [Anonymous], 1999, MACHINE LEARNING MET, V0, P0
   Arunyawat S, 2016, SUSTAINABILITY-BASEL, V8, P0, DOI 10.3390/su8080768
   Benelli G, 2018, ENVIRON SCI POLLUT R, V25, P10184, DOI 10.1007/s11356-017-9752-4
   Bhatt S, 2013, NATURE, V496, P504, DOI 10.1038/nature12060
   Boonchutima S, 2017, J INFECT PUBLIC HEAL, V10, P836, DOI 10.1016/j.jiph.2017.01.016
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burger R.E.A., 2018, INTRO MACHINE LEARNI, V0, P0
   Chandrakantha L, 2019, STATS-BASEL, V2, P272, DOI 10.3390/stats2020021
   Chen S, 2019, LANDSCAPE ECOL, V34, P1295, DOI 10.1007/s10980-019-00839-2
   Chen Yeong-Ren, 1994, KAOHSIUNG JOURNAL OF MEDICAL SCIENCES, V10, P0
   Cianci D, 2015, INT J HEALTH GEOGR, V14, P0, DOI 10.1186/s12942-015-0001-0
   Demsar J, 2004, LECT NOTES ARTIF INT, V3202, P537
   Dhar-Chowdhury P, 2016, AM J TROP MED HYG, V94, P1223, DOI 10.4269/ajtmh.15-0639
   Diaz-Quijano FA, 2018, BMC PUBLIC HEALTH, V18, P0, DOI 10.1186/s12889-018-5055-z
   Diuk-Wasser MA, 2005, AM J TROP MED HYG, V72, P725, DOI 10.4269/ajtmh.2005.72.725
   Focks D, 2004, TDRIDEDEN031 WHO, V0, P0
   Ganguli P, 2014, HYDROL PROCESS, V28, P4989, DOI 10.1002/hyp.9966
   Hairi Farizah, 2003, ASIA PAC J PUBLIC HEALTH, V15, P37, DOI 10.1177/101053950301500107
   Harapan H, 2018, BMC INFECT DIS, V18, P0, DOI 10.1186/s12879-018-3006-z
   Humphries G., 2018, MACHINE LEARNING ECO, V0, P0
   Jain R, 2019, BMC INFECT DIS, V19, P0, DOI 10.1186/s12879-019-3874-x
   Jopp F., 2010, MODELLING COMPLEX EC, V0, P0
   Kasem S, 2011, LAND USE POLICY, V28, P618, DOI 10.1016/j.landusepol.2010.12.001
   Koenraadt CJM, 2006, AM J TROP MED HYG, V74, P692, DOI 10.4269/ajtmh.2006.74.692
   Koyadun Surachart, 2012, INTERDISCIP PERSPECT INFECT DIS, V2012, P907494, DOI 10.1155/2012/907494
   Lorenz C, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-78755-8
   Maneerat S, 2016, ECOL MODEL, V333, P66, DOI 10.1016/j.ecolmodel.2016.04.012
   Maniruzzaman M, 2020, HEALTH INF SCI SYST, V8, P0, DOI 10.1007/s13755-019-0095-z
   Morand S, 2015, SOCIOECOLOGICAL DIME, V0, P0
   Murray Natasha Evelyn Anne, 2013, CLIN EPIDEMIOL, V5, P299, DOI 10.2147/CLEP.S34440
   Nicolopoulou-Stamati P, 2016, FRONT PUBLIC HEALTH, V4, P0, DOI 10.3389/fpubh.2016.00148
   Overgaard H. J., 2015, SOCIO-ECOLOGICAL DIMENSIONS OF INFECTIOUS DISEASES IN SOUTHEAST ASIA, V0, P123
   Overgaard HJ, 2003, LANDSCAPE ECOL, V18, P605, DOI 10.1023/A:1026074910038
   Phiri D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090967
   Rahman MS, 2021, INT J ENV RES PUB HE, V18, P0, DOI 10.3390/ijerph18115971
   Rahman MS, 2021, ENVIRON RES, V193, P0, DOI 10.1016/j.envres.2020.110509
   Rahman MS, 2021, T ROY SOC TROP MED H, V115, P85, DOI 10.1093/trstmh/traa093
   Rodrigues MD, 2015, PARASITE VECTOR, V8, P0, DOI 10.1186/s13071-015-0703-y
   Romero-Vivas CME, 2005, J AM MOSQUITO CONTR, V21, P15, DOI 10.2987/8756-971X(2005)21[15:IORBAA]2.0.CO;2
   RStudio Team, 2021, RSTUDIO INT DEV ENV, V0, P0
   Rueda L. M., 2004, PICTORIAL KEYS IDENT, V0, P0
   Sachindra DA, 2018, ATMOS RES, V212, P240, DOI 10.1016/j.atmosres.2018.05.022
   Salim NAM, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-020-79193-2
   Santos J, 2017, ACTA TROP, V168, P80, DOI 10.1016/j.actatropica.2017.01.015
   Saputra M., 2018, KNE LIFE SCI, V4, P201, DOI 10.18502/kls.v4i1.1382
   Scott TW, 2010, CURR TOP MICROBIOL, V338, P115, DOI 10.1007/978-3-642-02215-9_9
   Selvarajoo S, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-66212-5
   Smits GF, 2002, IEEE IJCNN, V0, PP2785, DOI 10.1109/IJCNN.2002.1007589
   Sulistyawati S, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16061013
   Tripathi S, 2006, J HYDROL, V330, P621, DOI 10.1016/j.jhydrol.2006.04.030
   Vannavong N, 2017, PARASITE VECTOR, V10, P0, DOI 10.1186/s13071-017-2107-7
   Young B, 2017, LANDSCAPE ECOL, V32, P397, DOI 10.1007/s10980-016-0450-2
NR 53
TC 4
Z9 4
U1 10
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 
EI 2352-7714
J9 ONE HEALTH-AMSTERDAM
JI One Health
PD DEC 15
PY 2021
VL 13
IS 
BP 
EP 
DI 10.1016/j.onehlt.2021.100358
EA DEC 2021
PG 10
WC Public, Environmental & Occupational Health; Infectious Diseases
SC Public, Environmental & Occupational Health; Infectious Diseases
GA XQ9CV
UT WOS:000731839400003
PM 34934797
DA 2023-04-26
ER

PT J
AU Gondwe, JF
   Lin, S
   Munthali, RM
AF Gondwe, Jane Ferah
   Lin, Sun
   Munthali, Rodger Millar
TI Analysis of Land Use and Land Cover Changes in Urban Areas Using Remote Sensing: Case of Blantyre City
SO DISCRETE DYNAMICS IN NATURE AND SOCIETY
LA English
DT Article
ID artificial neural-network; classification; dynamics
AB Blantyre City has experienced a wide range of changes in land use and land cover (LULC). This study used Remote Sensing (RS) to detect and quantify LULC changes that occurred in the city throughout a twenty-year study period, using Landsat 7 Enhanced Thematic Mapper (ETM+) images from 1999 and 2010 and Landsat 8 Operational Land Imager (OLI) images from 2019. A supervised classification method using an Artificial Neural Network (ANN) was used to classify and map LULC types. The kappa coefficient and the overall accuracy were used to ascertain the classification accuracy. Using the classified images, a postclassification comparison approach was used to detect LULC changes between 1999 and 2019. The study revealed that built-up land and agricultural land increased in their respective areas by 28.54 km(2) (194.81%) and 35.80 km(2) (27.16%) with corresponding annual change rates of 1.43 km center dot year(-1) and 1.79 km center dot year(-1). The area of bare land, forest land, herbaceous land, and waterbody, respectively, decreased by 0.05%, 90.52%, 71.67%, and 6.90%. The LULC changes in the study area were attributed to urbanization, population growth, social-economic growth, and climate change. The findings of this study provide information on the changes in LULC and driving factors, which Blantyre City authorities can utilize to develop sustainable development plans.
C1 [Gondwe, Jane Ferah; Lin, Sun] Shandong Univ Sci & Technol, Coll Geomat, Qingdao 266510, Peoples R China.
   [Munthali, Rodger Millar] Yangtze Univ, Sch Urban Construct, Jingzhou 434000, Peoples R China.
C3 Shandong University of Science & Technology; Yangtze University
RP Gondwe, JF (corresponding author), Shandong Univ Sci & Technol, Coll Geomat, Qingdao 266510, Peoples R China.
EM jgondwe1919@gmail.com
CR Afify HA, 2011, ALEX ENG J, V50, P187, DOI 10.1016/j.aej.2011.06.001
   Alawamy JS, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12114490
   Anderson J.R., 1976, LAND USE LAND COVER, V964, P0
   [Anonymous], 2018, BRITANNICA BLANTYRE, V0, P0
   Attua EM, 2011, EARTH INTERACT, V15, P0, DOI 10.1175/2010EI304.1
   Ayala-Silva Tomas, 2009, AMERICAN JOURNAL OF APPLIED SCIENCES, V6, P656, DOI 10.3844/ajas.2009.656.660
   Bekturov A, 2015, LAND USE LAND COVER, V0, P0
   Berrick N.O.S., 2021, WHAT IS REMOTE SENSI, V0, P0
   Bouhennache R, 2014, 2014 GLOBAL SUMMIT ON COMPUTER & INFORMATION TECHNOLOGY (GSCIT), V0, P0
   Brhane KW, 2021, J THEOR BIOL, V509, P0, DOI 10.1016/j.jtbi.2020.110515
   Briassoulis H., 2011, LAND USE LAND COVER, V1, P0
   Chaikaew P., 2019, LAND USE CHANGE MONI, V0, P0
   Chang Y, 2018, IOP C SER EARTH ENV, V113, P0, DOI 10.1088/1755-1315/113/1/012087
   Chen F., 2012, DATA ACQUIS APPL, V0, P0
   Chen LP, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0200493
   Chen PY, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17061295
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Deer P, 1995, DIGITAL CHANGE DETEC, V0, P0
   Degife AW, 2018, HELIYON, V4, P0, DOI 10.1016/j.heliyon.2018.e00919
   Enderle D. I., 2005, J ARK ACAD SCI, V59, P65
   FAO, 2012, ATL MAL LAND COV LAN, V0, P0
   FOODY GM, 1995, PHOTOGRAMM ENG REM S, V61, P391
   Frankenfield J., 2020, ARTIFICIAL NEURAL NE, V0, P0
   Genet A., 2020, INT J ENV PROT POLIC, V8, P77, DOI 10.11648/j.ijepp.20200804.12
   Gupta R, 2014, ENVIRON URBAN ASIA, V5, P83, DOI 10.1177/0975425314521539
   Halefom A.T., 2018, APPL RES J GEOGRAPHI, V1, P1
   Hasmadi I Mohd, 2009, J SOC SPACE, V5, P1
   HEPNER GF, 1990, PHOTOGRAMM ENG REM S, V56, P469
   Hussain S., 2018, LAND USE LAND COVER, V0, P0
   Jagger P, 2016, ENVIRON RES LETT, V11, P0, DOI 10.1088/1748-9326/11/12/125004
   Jensen Jensen J.R. J.R., 2015, INTRO DIGITAL IMAGE, V0, P0
   Kuhlman T., 2010, SUSTAINABILITY, V2, P3436, DOI 10.3390/SU2113436
   Lambin EF, 2001, GLOBAL ENVIRON CHANG, V11, P261, DOI 10.1016/S0959-3780(01)00007-3
   Lambin EF, 2003, ANNU REV ENV RESOUR, V28, P205, DOI 10.1146/annurev.energy.28.050302.105459
   Li XM, 2016, DISCRETE DYN NAT SOC, V2016, P0, DOI 10.1155/2016/8061069
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Malawi Government, 2019, 2018 MAL HOUS POP CE, V0, P0
   Malawi Government, 2017, NAT CHARC STRAT, V0, P0
   Mallupattu PK, 2013, SCI WORLD J, V0, P0, DOI DOI 10.1155/2013/268623
   Manda M.A.Z., 2013, MALAWI SITUATION URB, V0, P0
   Manoj K.A, 2010, LAND COVER CLASSIFIC, V0, P0
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Mas JF, 1999, INT J REMOTE SENS, V20, P139, DOI 10.1080/014311699213659
   Matsa M, 2020, J ENVIRON MANAGE, V276, P0, DOI 10.1016/j.jenvman.2020.111312
   Meteo Climat, 2020, MTO CLIM STATS STAT, V0, P0
   Mohajane M, 2018, ENVIRONMENTS, V5, P0, DOI 10.3390/environments5120131
   Mohammady M, 2015, INT J ENVIRON SCI TE, V12, P1515, DOI 10.1007/s13762-014-0728-3
   Munthali MG, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11030832
   Olokeogun OS, 2014, INT ARCH PHOTOGRAMM, V40-8, P613, DOI 10.5194/isprsarchives-XL-8-613-2014
   Pullanikkatil D, 2016, PHYS CHEM EARTH, V93, P96, DOI 10.1016/j.pce.2016.03.002
   Raabe E.A., 1997, IMAGE PROCESSING MET, V0, P0
   Radhadevi P.V., 2003, INT J GEO INFORM, V4, P90
   Rawat JS, 2015, EGYPT J REMOTE SENS, V18, P77, DOI 10.1016/j.ejrs.2015.02.002
   Shiferaw H, 2019, SCI TOTAL ENVIRON, V675, P354, DOI 10.1016/j.scitotenv.2019.04.220
   Salah HS, 2020, INT J REMOTE SENS, V41, P1788, DOI 10.1080/01431161.2019.1674463
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Suzanchi K, 2006, P SOC PHOTO-OPT INS, V6405, PC4051, DOI 10.1117/12.698196
   Talukdar S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071135
   Tong XY, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111322
   Traore M., 2021, ENV CHALLENGES, V4, P0, DOI 10.1016/j.envc.2021.100114
   UN Habitat, 2011, MAL BLANT URB PROF, V0, P0
   Usman M, 2015, J GEOGR SCI, V25, P1479, DOI 10.1007/s11442-015-1247-y
   Vargo J, 2013, J ENVIRON MANAGE, V114, P243, DOI 10.1016/j.jenvman.2012.10.007
   Wang RC, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6050150
   Wang SW, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12093925
   World Bank, 2016, MAL URB REV LEV URB, V0, P0
   Xue Q, 2021, APPL MATH COMPUT, V399, P0, DOI 10.1016/j.amc.2021.126038
   Yan W, 2021, ECOL INDIC, V130, P0, DOI 10.1016/j.ecolind.2021.108074
   Yin GH, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010012
   Young NE, 2021, ECOLOGY, V0, P0, DOI DOI 10.1002/ecy.1730
NR 70
TC 0
Z9 0
U1 2
U2 2
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1026-0226
EI 1607-887X
J9 DISCRETE DYN NAT SOC
JI Discrete Dyn. Nat. Soc.
PD DEC 23
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/8011565
PG 17
WC Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences
SC Mathematics; Science & Technology - Other Topics
GA 1I7SB
UT WOS:000797426300003
DA 2023-04-26
ER

PT J
AU Chou, TY
   Hoang, TV
   Fang, YM
   Nguyen, QH
   Lai, TA
   Pham, VM
   Vu, VM
   Bui, QT
AF Chou, Tien-Yin
   Thanh-Van Hoang
   Fang, Yao-Min
   Quoc-Huy Nguyen
   Tuan Anh Lai
   Van-Manh Pham
   Van-Manh Vu
   Quang-Thanh Bui
TI Swarm-based optimizer for convolutional neural network: An application for flood susceptibility mapping
SO TRANSACTIONS IN GIS
LA English
DT Article
ID feature-selection; ensemble; algorithm; model; shallow; forest; areas
AB This article investigates the use of the galactic swarm optimization algorithm in searching for parameters of a convolutional neural network for flood susceptibility mapping. Ha Giang province, the mountainous area of Vietnam, was chosen as a case study because of the frequent occurrence of floods. From this study area, 11 predictor variables and historical flood locations were selected to build up the training datasets, in which each sample is prepared in the 3D form of (height x width x channels or variables) = (5 x 5 x 11), (7 x 7 x 11), and (9 x 9 x 11), respectively for three experiments. The model performance was assessed by root mean square error, area under the receiver operating characteristic (AUC), and overall accuracy (OA). The results showed that the examined model significantly improved the classification accuracies: OA = 83.093, AUC = 0.917; OA = 83.726, AUC = 0.923; and OA = 82.791, AUC = 0.908 for the three training datasets in comparison to benchmarked classifiers, and this model can be considered as an alternative solution for flood susceptibility mapping.
C1 [Chou, Tien-Yin; Thanh-Van Hoang; Fang, Yao-Min; Quoc-Huy Nguyen] Feng Chia Univ, Geog Informat Syst Res Ctr, Taichung, Taiwan.
   [Quoc-Huy Nguyen] Feng Chia Univ, Coll Construct & Dev, Water Resources & Infrastruct Engn, Civil & Hydraul Engn, Taichung, Taiwan.
   [Tuan Anh Lai] Thuy Loi Univ, Fac Water Resources Engn, Hanoi, Vietnam.
   [Van-Manh Pham; Quang-Thanh Bui] VNU Univ Sci, Fac Geog, Ctr Appl Res Remote Sensing & GIS CARGIS, 334 Nguyen Trai, Hanoi, Vietnam.
   [Van-Manh Vu] VNU Univ Sci, Fac Environm Sci, Hanoi, Vietnam.
C3 Feng Chia University; Feng Chia University; Thuyloi University; Vietnam National University Hanoi; Vietnam National University Hanoi
RP Bui, QT (corresponding author), VNU Univ Sci, Fac Geog, Ctr Appl Res Remote Sensing & GIS CARGIS, 334 Nguyen Trai, Hanoi, Vietnam.
EM qthanh.bui@gmail.com
CR Arabameri A, 2020, GEOCARTO INT, V35, P1680, DOI 10.1080/10106049.2019.1585484
   Arabameri A, 2019, J MT SCI-ENGL, V16, P595, DOI 10.1007/s11629-018-5168-y
   Ayumi V, 2016, INT C ADV COMP SCI I, V0, PP506, DOI 10.1109/ICACSIS.2016.7872787
   Aziz K, 2016, STUD COMPUT INTELL, V628, P307, DOI 10.1007/978-3-319-28495-8_13
   Brunner MI, 2019, HYDROL EARTH SYST SC, V23, P107, DOI 10.5194/hess-23-107-2019
   Chiroma H, 2020, ADV INTELL SYST COMP, V943, P59, DOI 10.1007/978-3-030-17795-9_5
   Bui DT, 2019, SCI TOTAL ENVIRON, V668, P1038, DOI 10.1016/j.scitotenv.2019.02.422
   Bui DT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18082464
   Bui DT, 2016, J HYDROL, V540, P317, DOI 10.1016/j.jhydrol.2016.06.027
   Guo BS, 2019, ELECTRONICS-SWITZ, V8, P0, DOI 10.3390/electronics8050579
   Hu XY, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8090730
   Kazakis N, 2015, SCI TOTAL ENVIRON, V538, P555, DOI 10.1016/j.scitotenv.2015.08.055
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Kumar Leo, 2017, ENG APPL ARTIF INTEL, V65, P294, DOI 10.1016/J.ENGAPPAI.2017.08.005
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Marcos D, 2018, ISPRS J PHOTOGRAMM, V145, P96, DOI 10.1016/j.isprsjprs.2018.01.021
   Mezaal MR, 2018, CATENA, V167, P147, DOI 10.1016/j.catena.2018.04.038
   Moayedi H, 2019, ENG COMPUT-GERMANY, V35, P967, DOI 10.1007/s00366-018-0644-0
   Mojaddadi H, 2017, GEOMAT NAT HAZ RISK, V8, P1080, DOI 10.1080/19475705.2017.1294113
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Muthiah-Nakarajan V, 2016, APPL SOFT COMPUT, V38, P771, DOI 10.1016/j.asoc.2015.10.034
   Ngo PTT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113704
   Pulvirenti L, 2011, NAT HAZARD EARTH SYS, V11, P529, DOI 10.5194/nhess-11-529-2011
   Bui QT, 2020, J HYDROL, V581, P0, DOI 10.1016/j.jhydrol.2019.124379
   Bui QT, 2019, INT J DIGIT EARTH, V12, P1118, DOI 10.1080/17538947.2018.1542039
   Bui QT, 2019, INT J REMOTE SENS, V40, P5078, DOI 10.1080/01431161.2019.1578000
   Bui QT, 2019, GEOMAT NAT HAZ RISK, V10, P136, DOI 10.1080/19475705.2018.1509902
   Rere LMR, 2016, COMPUT INTEL NEUROSC, V2016, P0, DOI 10.1155/2016/1537325
   Sayers W, 2014, PROCEDIA ENGINEER, V70, P1505, DOI 10.1016/j.proeng.2014.02.165
   Shahin MA, 2015, INT J GEOTECH ENG, V9, P49, DOI 10.1179/1939787914Y.0000000058
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Tehrany MS, 2014, J HYDROL, V512, P332, DOI 10.1016/j.jhydrol.2014.03.008
   Tian Z., 2016, OPTIMIZATION ALGORIT, V0, P0, DOI DOI 10.5772/63785
   Pham TD, 2018, INT J REMOTE SENS, V39, P7761, DOI 10.1080/01431161.2018.1471544
   Twele A, 2016, INT J REMOTE SENS, V37, P2990, DOI 10.1080/01431161.2016.1192304
   Wang HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050446
   Wang Y, 2020, J HYDROL, V582, P0, DOI 10.1016/j.jhydrol.2019.124482
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Wang YM, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104425
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050489
NR 40
TC 11
Z9 11
U1 3
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1361-1682
EI 1467-9671
J9 T GIS
JI Trans. GIS
PD APR 15
PY 2021
VL 25
IS 2
BP 1009
EP 1026
DI 10.1111/tgis.12715
EA NOV 2020
PG 18
WC Geography
SC Geography
GA RU8ID
UT WOS:000594737600001
DA 2023-04-26
ER

PT J
AU Zhao, DY
   Si, BL
   Li, XL
AF Zhao, Dongye
   Si, Bailu
   Li, Xiaoli
TI Learning allocentric representations of space for navigation
SO NEUROCOMPUTING
LA English
DT Article
DE Deep learning; Localization; Large-scale environment; Place cells; Sensorimotor integration; HippDNN
ID hippocampal place cells; path-integration; grid cells; large environments; spatial map; model; transformation; information; direction; lesions
AB The hippocampus of the mammalian brain supports spatial navigation by building cognitive maps of the environments in which the animal explores. Currently, there is little neurocomputational work investigating the encoding and decoding mechanisms of hippocampal neural representations in large-scale environments. We propose a biologically-inspired hierarchical neural network architecture to learn the transformation of egocentric sensorimotor inputs into allocentric spatial representation for navigation. The hierarchical network is composed of two parallel subnetworks mimicking the lateral entorhinal cortex (LEC) and medial entorhinal cortex (MEC), and one convergent subnetwork mimicking the hippocampus. LEC relays time-related visual information and MEC supplies space-related information in the form of multi-resolution grid codes as resulted from integrating movement information. The convergent subnetwork integrates all information from the parallel subnetworks and predicts the position of the agent in the environment. Synaptic weights of the vision-to-place and grid-to-place connections are learned based on the stochastic gradient descent algorithm. Simulations in a large virtual maze demonstrate that hippocampal place units in the model form multiple and irregularly-spaced place fields, similar to those observed in neurobiological experiments. The model is able to accurately decode the positions of the agent from the learned spatial representations. Moreover, the model is capable of adaptation to degraded visual inputs, and therefore is robust against perturbations. When the motion inputs are deprived, the model meets with localization difficulty, suffering from less accuracy in position predictions. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Zhao, Dongye] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang 110016, Peoples R China.
   [Zhao, Dongye] Chinese Acad Sci, Inst Robot, Shenyang 110169, Peoples R China.
   [Zhao, Dongye] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Si, Bailu] Beijing Normal Univ, Sch Syst Sci, Beijing 100875, Peoples R China.
   [Li, Xiaoli] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Beijing Normal University; Beijing Normal University
RP Si, BL (corresponding author), Beijing Normal Univ, Sch Syst Sci, Beijing 100875, Peoples R China.
EM zhaodongye@sia.cn; bailusi@bnu.edu.cn; xiaoli@bnu.edu.cn
FU National Key Research and Development Program of China [2016YFC0801808]; Shenzhen-Hong Kong Institute of Brain Science -Shenzhen Fundamental Research Institutions [NYKFKT20190018]
CR Arleo A, 2000, BIOL CYBERN, V83, P287, DOI 10.1007/s004220000171
   Banino A, 2018, NATURE, V557, P429, DOI 10.1038/s41586-018-0102-6
   Brun VH, 2002, SCIENCE, V296, P2243, DOI 10.1126/science.1071089
   Bush D, 2014, TRENDS NEUROSCI, V37, P136, DOI 10.1016/j.tins.2013.12.003
   Chicco D., 2014, P 5 ACM C BIOINF COM, V0, PP533, DOI 10.1145/2649387
   Conklin J, 2005, J COMPUT NEUROSCI, V18, P183, DOI 10.1007/s10827-005-6558-z
   de Almeida L, 2009, J NEUROSCI, V29, P7504, DOI 10.1523/JNEUROSCI.6048-08.2009
   de Calignon A, 2012, NEURON, V73, P685, DOI 10.1016/j.neuron.2011.11.033
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   Fenton AA, 2008, J NEUROSCI, V28, P11250, DOI 10.1523/JNEUROSCI.2862-08.2008
   Franco L, 2007, BIOL CYBERN, V96, P547, DOI 10.1007/s00422-007-0149-1
   Franzius M, 2007, J COMPUT NEUROSCI, V22, P297, DOI 10.1007/s10827-006-0013-7
   Frey M., 2019, DEEPINSIGHT GENERAL, V0, P0
   Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901
   Giocomo LM, 2007, SCIENCE, V315, P1719, DOI 10.1126/science.1139207
   Grossberg S, 2012, PLOS COMPUT BIOL, V8, P0, DOI 10.1371/journal.pcbi.1002648
   Guazzelli A, 2001, HIPPOCAMPUS, V11, P216, DOI 10.1002/hipo.1039
   Gustafson NJ, 2011, PLOS COMPUT BIOL, V7, P0, DOI 10.1371/journal.pcbi.1002235
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Jeffery KJ, 2007, HIPPOCAMPUS, V17, P775, DOI 10.1002/hipo.20322
   Karlsson MP, 2008, J NEUROSCI, V28, P14271, DOI 10.1523/JNEUROSCI.4261-08.2008
   KNIERIM JJ, 1995, J NEUROSCI, V15, P1648, DOI 10.1523/JNEUROSCI.15-03-01648.1995
   Lipton P. A., 2008, NEURAL PLASTICITY, V2008, P1, DOI 10.1155/2008/258467
   Liu S, 2015, IEEE IJCNN, V0, P0
   MARKUS EJ, 1994, HIPPOCAMPUS, V4, P410, DOI 10.1002/hipo.450040404
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932
   Mizumori SJY, 1999, HIPPOCAMPUS, V9, P444, DOI 10.1002/(SICI)1098-1063(1999)9:4<444::AID-HIPO10>3.3.CO;2-Q
   Muir GM, 2001, J NEUROSCI, V21, P4016, DOI 10.1523/JNEUROSCI.21-11-04016.2001
   Norman G, 2005, BEHAV NEUROSCI, V119, P557, DOI 10.1037/0735-7044.119.2.557
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   Park E, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0022349
   QUIRK GJ, 1990, J NEUROSCI, V10, P2008
   Rich PD, 2014, SCIENCE, V345, P814, DOI 10.1126/science.1255635
   Rolls E.T., 1998, NEURAL NETWORKS BRAI, V572, P0
   Rolls ET, 2006, NETWORK-COMP NEURAL, V17, P447, DOI 10.1080/09548980601064846
   Rolls ET, 2011, PROG NEUROBIOL, V95, P448, DOI 10.1016/j.pneurobio.2011.08.002
   Samsonovich A, 1997, J NEUROSCI, V17, P5900
   Sargolini F, 2006, SCIENCE, V312, P758, DOI 10.1126/science.1125572
   Sathyanarayana A, 2016, JMIR MHEALTH UHEALTH, V4, P0, DOI 10.2196/mhealth.6562
   Save E, 1998, J NEUROSCI, V18, P1818
   Savelli F, 2010, J NEUROPHYSIOL, V103, P3167, DOI 10.1152/jn.00932.2009
   Schmidt-Hieber C, 2013, NAT NEUROSCI, V16, P325, DOI 10.1038/nn.3340
   Si BL, 2014, PLOS COMPUT BIOL, V10, P0, DOI 10.1371/journal.pcbi.1003558
   Si B, 2009, COGN NEURODYNAMICS, V3, P177, DOI 10.1007/s11571-009-9079-z
   Solstad T, 2006, HIPPOCAMPUS, V16, P1026, DOI 10.1002/hipo.20244
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suzuki WA, 1997, J NEUROPHYSIOL, V78, P1062, DOI 10.1152/jn.1997.78.2.1062
   Tampuu A, 2019, PLOS COMPUT BIOL, V15, P0, DOI 10.1371/journal.pcbi.1006822
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Tsao A, 2018, NATURE, V561, P57, DOI 10.1038/s41586-018-0459-6
   Urdapilleta E, 2017, HIPPOCAMPUS, V27, P1204, DOI 10.1002/hipo.22765
   Wang C, 2018, SCIENCE, V362, P945, DOI 10.1126/science.aau4940
   Wang S, 2017, INT CONF ACOUST SPEE, V0, PP436, DOI 10.1109/ICASSP.2017.7952193
   Yan CK, 2016, COGN NEURODYNAMICS, V10, P353, DOI 10.1007/s11571-016-9384-2
   Yoganarasimha D, 2011, HIPPOCAMPUS, V21, P1363, DOI 10.1002/hipo.20839
   Zeng NY, 2019, IEEE T NANOTECHNOL, V18, P819, DOI 10.1109/TNANO.2019.2932271
   Zeng NY, 2016, COGN COMPUT, V8, P684, DOI 10.1007/s12559-016-9404-x
   Zhao DW, 2021, IEEE T SYST MAN CY-S, V51, P7823, DOI 10.1109/TSMC.2020.2987163
   ZHU XO, 1995, EUR J NEUROSCI, V7, P753, DOI 10.1111/j.1460-9568.1995.tb00679.x
NR 63
TC 1
Z9 1
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD SEP 17
PY 2021
VL 453
IS 
BP 579
EP 589
DI 10.1016/j.neucom.2020.10.013
EA JUN 2021
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SU8ZB
UT WOS:000663418700014
DA 2023-04-26
ER

PT J
AU Gemitzi, A
AF Gemitzi, Alexandra
TI Predicting land cover changes using a CA Markov model under different shared socioeconomic pathways in Greece
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Land change model; remote sensing; land cover; land use; land cover change
AB Land change modeling (LCM) is a complex GIS procedure aiming at predicting land cover changes in the future, contributing thus to the design of interventions that help maintain ecosystem services and mitigate climate change impacts. In the present work, the land change model for Greece, a typical Mediterranean country, has been developed, based on historical information from remotely sensed land cover data. Land cover types based on the International Geosphere-Biosphere Program (IGBP) classification were obtained from the Moderate Resolution Imaging Spectroradiometer (MODIS) land cover product, i.e. MCD12Q1, provided annually from 2001 to 2018 at a spatial resolution of 500 m. Initially, the dominant land cover changes and their driving variables for the decade of 2001 to 2011 were determined and the transition potential of land was mapped using a multi-layer perceptron (MLP) neural network. Four dominant land-cover transformations were found in Greece from 2001 to 2011, i.e. land transformation from Savannas to Woody Savannas, from Savannas to Grasslands, from Grasslands to Savannas, and from Croplands to Grasslands. Driving variables were found to be the Evidence Likelihood of Land Cover, i.e. the relative frequency with which different land cover categories occurred within the areas that transitioned, the Altitude as realized in the Digital Elevation Model of Greece from ASTER GDEM, the Distance from previously changed land and two climate variables i.e. Mean Annual Precipitation and Mean Annual Minimum Temperature. After the model was calibrated, its predictive ability was tested for land cover prediction for 2018 and was found to be 96.7%. Future land cover projections up to 2030 were developed incorporating CMIP6 climate data under two Shared Socioeconomic Pathways (SSPs), i.e SSP126 corresponding to a sustainable future and SSP585, which describes the future world based on fossil-fueled development. The results indicate that major historical land transformations in Greece, do not correspond to land degradation or desertification, as it has been reported in previous works. On the contrary, the land cover transitions indicate that the Woody Savannas gain areas constantly, whereas Grasslands and Croplands lose areas, and forested areas of all types demonstrate moderate gains. Concerning future land cover, the present work indicates that the direction of historical changes will also prevail in the next decade, with the most severe scenario, i.e. SSP585 slowing down the rate of changes and the most sustainable one, i.e. SSP126, accelerating the rate of expansion of woody vegetation land cover type.
C1 [Gemitzi, Alexandra] Democritus Univ Thrace, Dept Environm Engn, Xanthi, Greece.
C3 Democritus University of Thrace
RP Gemitzi, A (corresponding author), Democritus Univ Thrace, Dept Environm Engn, Xanthi, Greece.
EM agkemitz@env.duth.gr
FU Technical Chamber of Greece - Democritus University of Thrace [82430]
CR Aitkenhead MJ, 2009, J ENVIRON MANAGE, V90, P236, DOI 10.1016/j.jenvman.2007.09.010
   [Anonymous], 2018, ASTER GLOB DIG EL MO, V0, P0, DOI DOI 10.5067/ASTER/ASTGTM
   [Anonymous], 2019, ASTER GLOBAL DIGITAL, V0, P0, DOI DOI 10.5067/ASTER/ASTGTM.003
   [Anonymous], 2020, GREEK EC HELLENIC RE, V0, P0
   Assaf C, 2021, LAND USE POLICY, V100, P0, DOI 10.1016/j.landusepol.2020.104895
   Banti MA, 2019, J LAND USE SCI, V14, P21, DOI 10.1080/1747423X.2019.1614687
   CECCHINI M, 2018, GEOJOURNAL, V0, P0
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dematte JAM, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-61408-1
   Eastman J.R, 2016, TERRSET GEOSPATIAL M, V0, P0
   Eastman J.R., 2005, TRANSITION POTENTIAL, V0, P357
   ELEFTHERIOU D, 2018, SCI TOTAL ENVIRON, V6617, P0
   European Union, 2018, DIR UE 2018 844 PARL, V0, P0
   Fallah Shamsi S.R., 2010, J APPL SCI ENVIRON M, V14, P0, DOI 10.4314/jasem.v14i2.57868
   FENG L, 2020, GEOSCI MODEL DEV, V13, P0
   Feng YJ, 2018, GISCI REMOTE SENS, V55, P678, DOI 10.1080/15481603.2018.1426262
   Fernandes MM, 2020, LAND USE POLICY, V99, P0, DOI 10.1016/j.landusepol.2020.104795
   Gemitzi A, 2019, ENVIRON EARTH SCI, V78, P0, DOI 10.1007/s12665-019-8180-9
   Giorgi F, 2006, GEOPHYS RES LETT, V33, P0, DOI 10.1029/2006GL025734
   Giorgi F, 2008, GLOBAL PLANET CHANGE, V63, P90, DOI 10.1016/j.gloplacha.2007.09.005
   Harris I, 2014, INT J CLIMATOL, V34, P623, DOI 10.1002/joc.3711
   HEREHER ME, 2017, NAT HAZARDS, V0, P0
   Hyandye C., 2015, AM J REMOTE SENSING, V3, P0, DOI 10.11648/j.ajrs.20150301.12
   Hyandye C, 2017, INT J REMOTE SENS, V38, P64, DOI 10.1080/01431161.2016.1259675
   Karamesouti M, 2018, CATENA, V167, P266, DOI 10.1016/j.catena.2018.04.042
   Labrianidis L., 2014, PROJECT FUNDED NATL, V0, P0
   LIANG D, 2015, ISPRS INT J GEO-INF, V4, P0
   Mchenry M.P., 2015, LAND USE LAND USE CH, V0, P0, DOI DOI 10.4337/9781849805834.00023
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Moody A., 1999, MODIS LAND COVR PROD, V0, P0
   Nagy A, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0209080
   Pnevmatikos JD, 2006, METEOROL APPL, V13, P331, DOI 10.1017/S1350482706002350
   Pravalie R, 2017, CATENA, V158, P309, DOI 10.1016/j.catena.2017.07.006
   Ralha CG, 2013, ENVIRON MODELL SOFTW, V42, P30, DOI 10.1016/j.envsoft.2012.12.003
   Sangermano F, 2010, T GIS, V14, P569, DOI 10.1111/j.1467-9671.2010.01226.x
   Sharma R.C., 2017, ADV REMOTE SENSING, V06, P0, DOI 10.4236/ars.2017.61004
   SHOOSHTARI J, 2020, J INDIAN SOC REMOTE, V48, P0
   SINGH SK, 2018, GEOCARTO INT, V33, P0
   Song XP, 2018, NATURE, V560, P639, DOI 10.1038/s41586-018-0411-9
   Subedi P., 2013, APPL ECOLOGY ENV SCI, V1, P0, DOI 10.12691/aees-1-6-5
   Sulla-Menashe D., 2019, DISTRIBUTED NASA EOS, V0, P0, DOI DOI 10.5067/MODIS/MCD12Q1.006
   Sulla-Menashe D, 2019, REMOTE SENS ENVIRON, V222, P183, DOI 10.1016/j.rse.2018.12.013
   Tsampra M., 2018, NEW OXFORD HDB EC GE, V0, P0, DOI DOI 10.1093/oxfordhb/9780198755609.013.39
   Vijith H, 2020, REMOTE SENS APPL, V18, P0, DOI 10.1016/j.rsase.2020.100311
   Wijitkosum S, 2016, SUSTAIN ENVIRON RES, V26, P84, DOI 10.1016/j.serj.2015.11.004
   Wirt Bradford, 2020, AFRICAN SAHEL TRANSI, V0, P0
   Yang H, 2020, J EARTH SYST SCI, V129, P0, DOI 10.1007/s12040-020-1347-7
   Yang X, 2012, ECOL MODEL, V233, P11, DOI 10.1016/j.ecolmodel.2012.03.011
   Yin J, 2011, ENVIRON MONIT ASSESS, V177, P609, DOI 10.1007/s10661-010-1660-8
   ZHANG HK, 2017, REMOTE SENS ENVIRON, V197, P0
NR 50
TC 10
Z9 10
U1 5
U2 61
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD APR 3
PY 2021
VL 58
IS 3
BP 425
EP 441
DI 10.1080/15481603.2021.1885235
EA FEB 2021
PG 17
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA RV5HK
UT WOS:000618318200001
DA 2023-04-26
ER

PT J
AU Sohrabi, A
   Kadkhodaie, A
   Kadkhodaie-Ilkhchi, R
AF Sohrabi, Akbar
   Kadkhodaie, Ali
   Kadkhodaie-Ilkhchi, Rahim
TI Artificial intelligence approach to palaeogeography and evolutionary trend analysis of Laurentian brachiopod fauna in the Rhynchotrema-Hiscobeccus lineage
SO PALAEOGEOGRAPHY PALAEOCLIMATOLOGY PALAEOECOLOGY
LA English
DT Article
DE Rhynchonellid brachiopods; Katian; Quantitative analysis; Neural network; North America
ID series upper ordovician; neural-network; sequence stratigraphy; carbon; field; ohio
AB Previous studies, based on the qualitative morphological description on the Late Ordovician brachiopod fauna hypothesized that the earliest species of Hiscobeccus, which is one of the diagnostic taxa in North American epicontinental brachiopod fauna, evolved from Rhynchotrema, a well-known rhynchonellide brachiopod, which lived in pericratonic regions of Laurentia. A quantitative approach conducting multivariate analysis, which was based on biometric characters of rhynchonellide brachiopod specimens from the Late Ordovician (upper Sandbian-upper Katian) in North America, supported this hypothesis that the younger and larger species of Hiscobeccus evolved from older and smaller species of Rhynchotrema during the Late Ordovician. The current study proposes the first report of employing an artificial intelligence model based on neural networks to map a set of quantitative morphological measurements of the Rhynchotrema-Hiscobeccus lineage of North America to their locality and evolutionary trend. For this purpose, a total of 171 morphometric measurements of the Late Ordovician brachiopods from 11 localities of North America were divided into 114 training and validation samples and 57 testing sets. The input morphometric parameters of the studied brachiopods include shell length (L), shell width (W), shell thickness (T), sulcus depth (T1), sulcus maximum width (W1), sulcus floor width (W2), apical angle (AA), lamella-covered shell length (L1), lamella number (Ln). Artificial neural network tries to find a mathematical formulation between the mentioned morphometric parameters and their corresponding localities from North America. The results showed that the accuracy of the neural network approach in estimating the locality of the testing brachiopod samples is 81%. In the light of satisfactory results of neural networks, having a set of the morphometric data from the unseen Late Ordovician brachiopods, their localities can be estimated.
C1 [Sohrabi, Akbar; Kadkhodaie, Ali; Kadkhodaie-Ilkhchi, Rahim] Univ Tabriz, Fac Nat Sci, Dept Earth Sci, Tabriz 5166616471, Iran.
C3 University of Tabriz
RP Sohrabi, A; Kadkhodaie, A (corresponding author), Univ Tabriz, Fac Nat Sci, Dept Earth Sci, Tabriz 5166616471, Iran.
EM ak.sohrabi@yahoo.com; kadkhodaie_ali@tabrizu.ac.ir
CR Abdizadeh H, 2017, GEOPERSIA, V7, P255, DOI 10.22059/geope.2017.229418.648307
   Alizadeh B, 2012, COMPUT GEOSCI-UK, V45, P261, DOI 10.1016/j.cageo.2011.11.024
   Amsden T. W., 1983, OKLAHOMA GEOLOGICAL, V132, P36
   Amsden T.W., 1983, OKLAHOMA GEOLOGICAL, V0, P1
   Anemone R, 2011, EVOL ANTHROPOL, V20, P169, DOI 10.1002/evan.20324
   [Anonymous], 1996, GEOL SOC AM SPEC PAP, V0, P0
   BARNES CR, 1981, ORDOVICIAN SYSTEM CA, V8, P21
   Beaufort L, 2004, MAR MICROPALEONTOL, V51, P57, DOI 10.1016/j.marmicro.2003.09.003
   Bergstrom S.M., 1971, MEMOIRS GEOLOGICAL SOCIETY OF AMERICA, V127, P83
   Bhattacharya A., 1999, P 5 ANN ACM IEEE INT, V0, P1
   Bolton T.E., 2000, GEOLOGY PALEONTOLOGY, V557, P39
   Brett CE, 2004, PALAEOGEOGR PALAEOCL, V210, P295, DOI 10.1016/j.palaeo.2004.02.038
   Brett K., 1997, GUIDEBOOK FIELD TRIP, V0, P0
   Cocks LRM, 2011, EARTH-SCI REV, V106, P1, DOI 10.1016/j.earscirev.2011.01.007
   Cressman E. R., 1973, US GEOLOGICAL SURVEY, V0, P61
   Elias R.J., 1991, GEOLOGICAL SURVEY OF CANADA PAPER, V90, P205
   ELIAS RJ, 1983, J PALEONTOL, V57, P924
   Farzi R, 2017, J NAT GAS SCI ENG, V39, P54, DOI 10.1016/j.jngse.2017.01.029
   HALL J., 1860, ANN REPORT REGENTS U, V13, P55
   Holland S. M., 2008, STRATIGRAPHIC RENAIS, V2, P174
   HOLLAND SM, 1993, GEOL SOC AM BULL, V105, P306, DOI 10.1130/0016-7606(1993)105<0306:SSOACC>2.3.CO;2
   Holland SM, 2007, PALAIOS, V22, P392, DOI 10.2110/palo.2006.p06-066r
   Jin J., 1996, GEOLOGICAL SURVEY OF CANADA BULLETIN, V491, P20
   Jin J., 1997, GEOLOGICAL SURVEY CA, V115, P115
   Jin J., 2001, LATE ORDOVICIAN ARTI, V0, P0
   Jin Jisuo, 1992, PALAEONTOGRAPHICA ABTEILUNG A PALAEOZOOLOGIE-STRATIGRAPHIE, V224, P133
   Jin JS, 2001, CAN J EARTH SCI, V38, P143, DOI 10.1139/e00-049
   Johnson LM, 2018, COMPUT GEOSCI-UK, V120, P73, DOI 10.1016/j.cageo.2018.08.004
   Kadkhodaie-Ilkhchi A, 2010, IEEE GEOSCI REMOTE S, V7, P680, DOI 10.1109/LGRS.2010.2046312
   Kadkhodaie-Ilkhchi A, 2009, J PETROL SCI ENG, V65, P23, DOI 10.1016/j.petrol.2008.12.012
   Ludvigson GA, 2004, PALAEOGEOGR PALAEOCL, V210, P187, DOI 10.1016/j.palaeo.2004.02.043
   MACOMBER R W, 1970, JOURNAL OF PALEONTOLOGY, V44, P416
   Malmgren BA, 1997, PALAEOGEOGR PALAEOCL, V136, P359, DOI 10.1016/S0031-0182(97)00031-X
   Melchin M.J., 1994, GEOLOGICAL ASS CANAD, V0, P0
   MITCHELL C E, 1991, GEOLOGICAL SURVEY OF CANADA PAPER, V0, P59
   Mossler J. H., 1992, MINNESOTA GEOLOGIC C, VC-7, P0
   Norford B.S., 1996, GEOLOGICAL SURVEY OF CANADA BULLETIN, V491, P5
   Nouri-Taleghani M, 2015, J PETROL GEOL, V38, P177, DOI 10.1111/jpg.12605
   Ojakangas RW., 1982, MINNESOTAS GEOLOGY, V0, P0, DOI DOI 10.5749/j.cttttrsq
   Okulitch Vladimir J., 1943, TRANS ROYAL SOC CANADA SECT 4, V37, P59
   Sanford BV., 2000, GEOLOGICAL SURVEY CA, V557, P13
   Schumacher Gregory A., 1997, P131, V0, P0
   Sohrabi A, 2013, LETHAIA, V46, P188, DOI 10.1111/j.1502-3931.2012.00333.x
   Tasch P., 1969, T KANSAS ACAD SCI, V72, P195
   TOBIN RC, 1986, AM J SCI, V286, P673, DOI 10.2475/ajs.286.9.673
   Vogel K, 2009, PALAEOGEOGR PALAEOCL, V281, P1, DOI 10.1016/j.palaeo.2009.06.032
   Wang Y., 1949, GEOLOGICAL SOC AM ME, V42, P55
   Webby BD, 2004, CRIT MOM PERSP EARTH, V0, P124
   Weir G.W., 1981, 1151E US GEOL SURV, V0, P121
   Williams D. A., 1986, FIELD TRIP GUIDEBOOK, V8, P0
   Wilson A. E., 1946, GEOLOGICAL SURVEY CA, V8, P149
   Young G. A., 2008, CANADIAN PALEONTOLOG, V13, P97
   Young Graham A., 1999, ACTA UNIVERSITATIS CAROLINAE GEOLOGICA, V43, P429
NR 53
TC 0
Z9 0
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0031-0182
EI 1872-616X
J9 PALAEOGEOGR PALAEOCL
JI Paleogeogr. Paleoclimatol. Paleoecol.
PD JAN 15
PY 2021
VL 562
IS 
BP 
EP 
DI 10.1016/j.palaeo.2020.110114
PG 12
WC Geography, Physical; Geosciences, Multidisciplinary; Paleontology
SC Physical Geography; Geology; Paleontology
GA PN6JZ
UT WOS:000604584600048
DA 2023-04-26
ER

PT J
AU Munoz, JVE
   Tuia, D
   Falcao, AX
AF Vargas Munoz, John E.
   Tuia, Devis
   Falcao, Alexandre X.
TI Deploying machine learning to assist digital humanitarians: making image annotation in OpenStreetMap more efficient
SO INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
LA English
DT Article
DE Interactive annotation; very high resolution mapping; convolutional neural networks; OpenStreetMap; volunteered geographical information; vector maps update
AB Locating populations in rural areas of developing countries has attracted the attention of humanitarian mapping projects since it is important to plan actions that affect vulnerable areas. Recent efforts have tackled this problem as the detection of buildings in aerial images. However, the quality and the amount of rural building annotated data in open mapping services like OpenStreetMap (OSM) is not sufficient for training accurate models for such detection. Although these methods have the potential of aiding in the update of rural building information, they are not accurate enough to automatically update the rural building maps. In this paper, we explore a human-computer interaction approach and propose an interactive method to support and optimize the work of volunteers in OSM. The user is asked to verify/correct the annotation of selected tiles during several iterations and therefore improving the model with the new annotated data. The experimental results, with simulated and real user annotation corrections, show that the proposed method greatly reduces the amount of data that the volunteers of OSM need to verify/correct. The proposed methodology could benefit humanitarian mapping projects, not only by making more efficient the process of annotation but also by improving the engagement of volunteers.
C1 [Vargas Munoz, John E.; Falcao, Alexandre X.] Univ Estadual Campinas, Lab Image Data Sci, Inst Comp, Campinas, Brazil.
   [Tuia, Devis] Wageningen Univ & Res, Lab Geoinformat Sci & Remote Sensing, Wageningen, Netherlands.
C3 Universidade Estadual de Campinas; Wageningen University & Research
RP Munoz, JVE (corresponding author), Univ Estadual Campinas, Lab Image Data Sci, Inst Comp, Campinas, Brazil.
EM john.vargas@ic.unicamp.br
FU Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [2016/14760-5, 2014/12236-1]; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq) [303808/2018-7]; Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior -Brasil (CAPES) [001]; Swiss National Science Foundation [PP00P2-150593]
CR ALI A, 2017, ISPRS J PHOTOGRAMM, V127, P0
   Ali A.L., 2014, P 22 ACM SIGSPATIAL, V0, PP143, DOI https://doi.org/10.1145/2666310.2666392
   Alsaade, 2012, RES J INFORM TECHNOL, V4, P204, DOI 10.3923/RJIT.2012.204.211
   Audebert N., 2017, C COMP VIS PATT REC, V0, P0
   Chen J., 2018, IEEE T GEOSCI REMOTE, V57, P1
   Chen J, 2017, IEEE INT SYMP INFO, V0, PP719, DOI 10.1109/ISIT.2017.8006622
   Cheng D, 2019, PROC CVPR IEEE, V0, PP7423, DOI 10.1109/CVPR.2019.00761
   Demir I, 2018, IEEE COMPUT SOC CONF, V0, PP172, DOI 10.1109/CVPRW.2018.00031
   Fleischmann P., 2017, INTELLIGENT AUTONOMO, V14, P0
   Gomes R., 2011, P ADV NEUR INF PROC, V0, P0
   Hamaguchi R, 2018, IEEE COMPUT SOC CONF, V0, PP223, DOI 10.1109/CVPRW.2018.00041
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Jilani M., 2014, P 22 ACM SIGSPATIAL, V0, PP449, DOI 10.1145/2666310.2666476
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Luxen C. Vetter, 2011, P 19 ACM SIGSPATIAL, V0, PP513, DOI 10.1145/2093973.2094062
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Marcos D., 2018, COMPUTER VISION PATT, V0, P0
   Matasci G, 2012, IEEE J-STARS, V5, P1335, DOI 10.1109/JSTARS.2012.2202881
   Mnih V., 2012, P 29 INT C MACH LEAR, V0, P567
   Neis P, 2014, FUTURE INTERNET, V6, P76, DOI 10.3390/fi6010076
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saito S, 2016, J IMAGING SCI TECHN, V60, P0, DOI 10.2352/J.ImagingSci.Technol.2016.60.1.010402
   Srivastava S, 2018, MEN AND FEMINISM IN INDIA, V0, P35
   Srivastava S, 2019, REMOTE SENS ENVIRON, V228, P129, DOI 10.1016/j.rse.2019.04.014
   Tasar O, 2018, INT GEOSCI REMOTE SE, V0, P6404
   Vargas-Munoz JE, 2019, ISPRS J PHOTOGRAMM, V147, P283, DOI 10.1016/j.isprsjprs.2018.11.010
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang PC, 2017, IEEE INT CONF COMP V, V0, PP1005, DOI 10.1109/ICCVW.2017.123
   Wang Z., 2017, ISPRS ANN PHOTOGRAMM, V0, PP411, DOI 10.5194/isprs-annals-IV-2-W4-411-2017
NR 31
TC 8
Z9 8
U1 3
U2 16
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1365-8816
EI 1362-3087
J9 INT J GEOGR INF SCI
JI Int. J. Geogr. Inf. Sci.
PD SEP 2
PY 2021
VL 35
IS 9
BP 1725
EP 1745
DI 10.1080/13658816.2020.1814303
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science
SC Computer Science; Geography; Physical Geography; Information Science & Library Science
GA TY2YC
UT WOS:000563370900001
DA 2023-04-26
ER

PT J
AU Vergini, ES
   Groumpos, PP
AF Vergini, Eleni S.
   Groumpos, Peter P.
TI Advanced State Fuzzy Cognitive Maps applied on nearly Zero Energy Building model
SO IFAC PAPERSONLINE
LA English
DT Proceedings Paper
DE Advanced state fuzzy cognitive maps; Zero energy building; Learning algorithms; State-space theory
ID hebbian learning algorithm
AB Fuzzy Cognitive Maps method combines the advantages of Fuzzy Logic, such as their human reasoning and linguistic features, with the advantages of Neural Networks, such as their low mathematical calculation requirements, in order to model complex dynamic systems on a wide variety of applications. The system variables and their interconnections are described using a graph and a weight matrix. Application of experts' knowledge leads towards more realistic system models. In addition, the implementation of state-space theory in combination with learning algorithms, lead to a new generation of Fuzzy Cognitive Maps, the Advanced State Fuzzy Cognitive Maps. All the above are implemented on a nearly Zero Energy Building model, using real weather data and presenting its annual energy response. Copyright (C) 2021 The Authors.
C1 [Vergini, Eleni S.; Groumpos, Peter P.] Dept Elect & Comp Engn, Rion 19200, Greece.
RP Vergini, ES (corresponding author), Dept Elect & Comp Engn, Rion 19200, Greece.
EM vergini@ece.upatras.gr; groumpos@ece.upatras.gr
CR Afram A, 2014, BUILD ENVIRON, V72, P343, DOI 10.1016/j.buildenv.2013.11.016
   Clau J, 2017, IBPSA BUILDING SIMUL, V0, P0
   De Coninck R, 2016, APPL ENERG, V162, P653, DOI 10.1016/j.apenergy.2015.10.114
   DellAnna F, 2020, SMART SUSTAIN BUILT, V9, P413, DOI 10.1108/SASBE-09-2019-0121
   Groumpos PP, 2010, STUD FUZZ SOFT COMP, V247, P1
   Kannappan A, 2011, EXPERT SYST APPL, V38, P1282, DOI 10.1016/j.eswa.2010.06.069
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Mpelogianni Vassiliki, 2015, INTERNATIONAL JOURNAL OF MONITORING AND SURVEILLANCE TECHNOLOGIES RESEARCH, V3, P1, DOI 10.4018/IJMSTR.2015100101
   OConnell N, 2014, RENEW SUST ENERG REV, V39, P686, DOI 10.1016/j.rser.2014.07.098
   Papageorgiou EI, 2004, INT J APPROX REASON, V37, P219, DOI 10.1016/j.ijar.2004.01.001
   Papageorgiou EI, 2012, IEEE T SYST MAN CY C, V42, P150, DOI 10.1109/TSMCC.2011.2138694
   Papageorgiou EI, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P2094, DOI 10.1109/FUZZY.2009.5277254
   Perez-Lombard L, 2008, ENERG BUILDINGS, V40, P394, DOI 10.1016/j.enbuild.2007.03.007
   Pless S., 2010, NATL RENEWABLE ENERG, V0, P0
   Salom J, 2014, APPL ENERG, V136, P119, DOI 10.1016/j.apenergy.2014.09.018
   Vergini ES, 2016, IFAC PAPERSONLINE, V49, P300, DOI 10.1016/j.ifacol.2016.11.083
NR 16
TC 3
Z9 3
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-8963
EI 
J9 IFAC PAPERSONLINE
JI IFAC PAPERSONLINE
PD JUN 15
PY 2021
VL 54
IS 13
BP 533
EP 538
DI 10.1016/j.ifacol.2021.10.504
EA NOV 2021
PG 6
WC Automation & Control Systems
SC Automation & Control Systems
GA WX1LI
UT WOS:000718365000097
DA 2023-04-26
ER

PT J
AU Fyleris, T
   Krisciunas, A
   Gruzauskas, V
   Calneryte, D
AF Fyleris, Tautvydas
   Krisciunas, Andrius
   Gruzauskas, Valentas
   Calneryte, Dalia
TI Deep Learning Application for Urban Change Detection from Aerial Images
SO PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON GEOGRAPHICAL INFORMATION SYSTEMS THEORY, APPLICATIONS AND MANAGEMENT (GISTAM)
LA English
DT Proceedings Paper
DE Urban Change; Aerial Images; Deep Learning
ID semantic segmentation; satellite images; extraction; tracking
AB Urban growth estimation is an essential part of urban planning in order to ensure sustainable regional development. For such purpose, analysis of remote sensing data can be used. The difficulty in analysing a time series of remote sensing data lies in ensuring that the accuracy stays stable in different periods. In this publication, aerial images were analysed for three periods, which lasted for 9 years. The main issues arose due to the different quality of images, which lead to bias between periods. Consequently, this results in difficulties in interpreting whether the urban growth actually happened, or it was identified due to the incorrect segmentation of images. To overcome this issue, datasets were generated to train the convolutional neural network (CNN) and transfer learning technique has been applied. Finally, the results obtained with the created CNN of different periods enable to implement different approaches to detect, analyse and interpret urban changes for the policymakers and investors on different levels as a map, grid, or contour map.
C1 [Fyleris, Tautvydas] Kaunas Univ Technol, Fac Informat, Dept Software Engn, Kaunas, Lithuania.
   [Krisciunas, Andrius; Calneryte, Dalia] Kaunas Univ Technol, Fac Informat, Dept Appl Informat, Kaunas, Lithuania.
   [Gruzauskas, Valentas] Kaunas Univ Technol, Sch Econ & Business, Sustainable Management Res Grp, Kaunas, Lithuania.
C3 Kaunas University of Technology; Kaunas University of Technology; Kaunas University of Technology
RP Fyleris, T (corresponding author), Kaunas Univ Technol, Fac Informat, Dept Software Engn, Kaunas, Lithuania.
FU Research, Development and Innovation Fund of Kaunas University of Technology [PP91L/19]
CR Al-Ruzouq R, 2017, ANN GIS, V23, P183, DOI 10.1080/19475683.2017.1325935
   Albert A, 2017, KDD17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP1357, DOI 10.1145/3097983.3098070
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Corbane C., 2020, ARXIV, V0, P0
   de Jong K. L., 2019, 2019 INT JOINT C NEU, V0, P1
   Donaldson D, 2016, J ECON PERSPECT, V30, P171, DOI 10.1257/jep.30.4.171
   Dornaika F, 2016, EXPERT SYST APPL, V58, P130, DOI 10.1016/j.eswa.2016.03.024
   Goyette N., 2012, 2012 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPR WORKSHOPS), V0, P0, DOI DOI 10.1109/CVPRW.2012.6238919
   Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
   Kanagamalliga S, 2018, OPTIK, V157, P787, DOI 10.1016/j.ijleo.2017.11.181
   Krupinski M, 2019, PROC SPIE, V11176, P0, DOI 10.1117/12.2535547
   Langkvist M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8040329
   Liu YS, 2020, IEEE T GEOSCI REMOTE, V58, P6699, DOI 10.1109/TGRS.2020.2979011
   Marmanis D, 2016, ISPRS ANN PHOTO REM, V3, P473, DOI 10.5194/isprsannals-III-3-473-2016
   Nahhas F. H., 2018, DEEP LEARNING APPROA, V2018, P0
   Shermeyer J, 2019, IEEE COMPUT SOC CONF, V0, PP1432, DOI 10.1109/CVPRW.2019.00184
   Suraj P. K., 2018, MONITORING DEV INDIC, V0, P1
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, V0, PP1873, DOI 10.1109/IGARSS.2015.7326158
   Verbesselt J, 2012, REMOTE SENS ENVIRON, V123, P98, DOI 10.1016/j.rse.2012.02.022
   Verbesselt J, 2010, REMOTE SENS ENVIRON, V114, P106, DOI 10.1016/j.rse.2009.08.014
   Wang B, 2019, J VIS COMMUN IMAGE R, V58, P102, DOI 10.1016/j.jvcir.2018.11.014
   Wang J, 2015, INT J REMOTE SENS, V36, P3144, DOI 10.1080/01431161.2015.1054049
   Witwit W, 2017, J ELECTRON IMAGING, V26, P0, DOI 10.1117/1.JEI.26.2.023014
   Wu GM, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030407
   Wurm M, 2019, ISPRS J PHOTOGRAMM, V150, P59, DOI 10.1016/j.isprsjprs.2019.02.006
   Xie M, 2016, AAAI CONF ARTIF INTE, V0, P3929
   Ye ZR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242970
NR 27
TC 3
Z9 3
U1 1
U2 3
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 15
EP 24
DI 10.5220/0010415700150024
PG 10
WC Computer Science, Information Systems; Geography, Physical
SC Computer Science; Physical Geography
GA BT3MY
UT WOS:000821066300001
DA 2023-04-26
ER

PT J
AU Ma, JW
   Czerniawski, T
   Leite, F
AF Ma, Jong Won
   Czerniawski, Thomas
   Leite, Fernanda
TI An application of metadata-based image retrieval system for facility management
SO ADVANCED ENGINEERING INFORMATICS
LA English
DT Article
DE Facility management; Image retrieval system; Indoor localization; Bluetooth; Building Information Model; Geographical Information System
ID color
AB For facility management, photography is an efficient and accurate method of recording the physical state of infrastructure. However, without an effective organizational scheme, the difficulty of retrieving relevant photos from historical databases can become overly burdensome for highly complex or long-lived assets. To make strategic decisions, it is crucial to retrieve the right information from a plurality of sources in a timely manner. The main objective of this paper is to present a method for organizing and retrieving photos from massive facility management photo databases using photo-metadata: photographed location, camera perspective, and image semantic content information. Indoor localization experiments were performed using Bluetooth technology to infer the location information. Perspective is inferred from the device's on-board inertial measurement unit (IMU). Image semantic content is inferred using a Convolutional Neural Network (CNN)-based deep learning algorithm. Fusing these three features, seven query options were provided for the user when retrieving images. Leveraging Building Information Modeling (BIM) as a process and Geographic Information Systems (GIS) as a framework, this paper also envisions a federated information management by connecting 2D and 3D facility assets with our real-world map which can be smoothly bridged with our image retrieval system. The realization of the integrated application with BIM and GIS is significantly beneficial for the facility management domain by advancing the understanding of projects in a broader view with a federated data platform. In this research, the framework is illustrated with 21 institutional buildings within the University of Texas at Austin's main campus, and the authors conclude that the proposed metadata-based image retrieval system can ultimately enhance the better-informed decision-making process through rapid information retrieval.
C1 [Ma, Jong Won] Univ Texas Austin, Dept Civil Architectural & Environm Engn, Construct Engn & Project Management Program, 301 E Dean Keeton St,Stop C1752, Austin, TX 78712 USA.
   [Czerniawski, Thomas] Arizona State Univ, Del E Webb Sch Construct, Sch Sustainable Engn & Built Environm, Ira A Fulton Sch Engn, 660 S Coll Ave, Tempe, AZ 85281 USA.
   [Leite, Fernanda] Univ Texas Austin, Dept Civil Architectural & Environm Engn, Construct Engn & Project Management Program, Civil Engn, 301 E Dean Keeton St,Stop C1752, Austin, TX 78712 USA.
C3 University of Texas System; University of Texas Austin; Arizona State University; Arizona State University-Tempe; University of Texas System; University of Texas Austin
RP Ma, JW (corresponding author), Univ Texas Austin, Dept Civil Architectural & Environm Engn, Construct Engn & Project Management Program, 301 E Dean Keeton St,Stop C1752, Austin, TX 78712 USA.
EM jwma1231@utexas.edu; thomas.czerniawski@asu.edu; fernanda.leite@utexas.edu
FU National Science Foundation Civil Infrastructure Systems Grant [1562438]; Directorate For Engineering; Div Of Civil, Mechanical, & Manufact Inn [1562438] Funding Source: National Science Foundation
CR Abdelhalim AM, 2017, 2017 12TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), V0, PP436, DOI 10.1109/ICCES.2017.8275347
   Alzubi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Brilakis I, 2005, J COMPUT CIVIL ENG, V19, P341, DOI 10.1061/(ASCE)0887-3801(2005)19:4(341)
   Brilakis I, 2005, AUTOMAT CONSTR, V14, P537, DOI 10.1016/j.autcon.2004.11.003
   Brilakis I, 2006, J CONSTR ENG M, V132, P777, DOI 10.1061/(ASCE)0733-9364(2006)132:7(777)
   Ceron JD, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20174742
   Chang A, 2017, INT CONF 3D VISION, V0, PP667, DOI 10.1109/3DV.2017.00081
   Chawathe SS, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, V0, PP980, DOI 10.1109/ITSC.2008.4732690
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cho SB, 2002, IEEE T SYST MAN CY A, V32, P452, DOI 10.1109/TSMCA.2002.802812
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Cotts D. G, 1999, FACILITY MANAGEMENT, V0, P0
   Crane A.S., 2012, GOOGLE PATENTS, V0, P0
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Czerniawski T., 2018, **DATA OBJECT**, V0, P0, DOI DOI 10.5281/zenodo.1292314
   Czerniawski T, 2020, ADV ENG INFORM, V45, P0, DOI 10.1016/j.aei.2020.101131
   Dai A, 2017, PROC CVPR IEEE, V0, PP2432, DOI 10.1109/CVPR.2017.261
   Pedro RWD, 2013, ACM COMPUT SURV, V46, P0, DOI 10.1145/2543581.2543593
   Dutta A, 2019, PROC CVPR IEEE, V0, PP5084, DOI 10.1109/CVPR.2019.00523
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Faragher R, 2015, IEEE J SEL AREA COMM, V33, P2418, DOI 10.1109/JSAC.2015.2430281
   Finch E, 2012, FACILITIES CHANGE MA, V0, P0, DOI DOI 10.1002/9781119967316.ch1
   Flasinski M, 2014, PATTERN ANAL APPL, V17, P465, DOI 10.1007/s10044-013-0322-1
   Fuh CS, 2000, IEEE T IMAGE PROCESS, V9, P156, DOI 10.1109/83.817608
   GELFAND L, 2011, SUSTAINABLE RENOVATI, V0, P0
   Giuliano R, 2020, ELECTRONICS-SWITZ, V9, P0, DOI 10.3390/electronics9061055
   Graham A., 2002, JCDL 2002. PROCEEDINGS OF THE SECOND ACM/IEEE-CS JOINT CONFERENCE ON DIGITAL LIBRARIES, V0, PP326, DOI 10.1145/544220.544301
   Greene MR, 2009, PSYCHOL SCI, V20, P464, DOI 10.1111/j.1467-9280.2009.02316.x
   Guo HY, 2016, IEEE T IMAGE PROCESS, V25, P5526, DOI 10.1109/TIP.2016.2609814
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong Shao, 2008, 2008 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, V0, PP753, DOI 10.1109/ICYCS.2008.89
   Hoxha G, 2020, IEEE J-STARS, V13, P4462, DOI 10.1109/JSTARS.2020.3013818
   Ionescu B, 2016, MULTIMED TOOLS APPL, V75, P1301, DOI 10.1007/s11042-014-2369-4
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Kalantidis Yannis, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE: WORKSHOPS. PROCEEDINGS: LNCS 9913, V0, PP685, DOI 10.1007/978-3-319-46604-0_48
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Kumar N, 2009, IEEE I CONF COMP VIS, V0, PP365, DOI 10.1109/ICCV.2009.5459250
   Kuzovkin D, 2019, ACM T APPL PERCEPT, V16, P0, DOI 10.1145/3333612
   Kuzovkin D, 2018, ICMR 18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP397, DOI 10.1145/3206025.3206077
   Latif A, 2019, MATH PROBL ENG, V2019, P0, DOI 10.1155/2019/9658350
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu F, 2019, IEEE ACCESS, V7, P119209, DOI 10.1109/ACCESS.2019.2935222
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Long FH, 2003, SIG COM TEC, V0, P1
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Napoletano P, 2018, INT J REMOTE SENS, V39, P1343, DOI 10.1080/01431161.2017.1399472
   Nazir A., 2018, P 2018 INT C COMPUTI, V0, PP1, DOI 10.1109/ICOMET.2018.8346343
   NonAlinsavath K., 2020, INT J INTELL ENG SYS, V13, P171
   ping Tian D., 2013, INT J MULTIMED UBIQU, V8, P385
   Pusnik M, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20082336
   Qizhe Xie, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10684, DOI 10.1109/CVPR42600.2020.01070
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Rhodes B, 2003, IEEE T COMPUT, V52, P1011, DOI 10.1109/TC.2003.1223636
   Rodden K, 2003, P SIGCHI C HUM FACT, V0, PP409, DOI 10.1145/642611.642682
   Santosh KC, 2018, DOCUMENT IMAGE ANAL, V0, P0
   Smith D.K., 2009, BUILDING INFORM MODE, V0, P0, DOI DOI 10.1002/9780470432846
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   Talamo C., 2015, KNOWLEDGE MANAGEMENT, V0, P0, DOI DOI 10.1007/978-3-319-23959-0
   Teicholz E, 2012, TECHNOLOGY FACILITY, V0, P0, DOI DOI 10.1002/9781119572626
   Teicholz P, 2013, BIM FACILITY MANAGER, V0, P0, DOI DOI 10.1002/9781119572633
   Tolias G, 2015, ARXIV PREPRINT ARXIV, V0, P0
   Torres-Solis J., 2010, REV INDOOR LOCALIZAT, V0, P0, DOI DOI 10.5772/8678
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Wang G, 2009, IEEE I CONF COMP VIS, V0, PP428, DOI 10.1109/ICCV.2009.5459167
   Wang WCV, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20133661
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wiggins J.M., 2014, FACILITIES MANAGERS, V0, P0, DOI DOI 10.1002/9781118785386
   Wu FQ, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1103
   Xiang J, 2019, IEEE ACCESS, V7, P35405, DOI 10.1109/ACCESS.2019.2898906
   Xu C., 2011, P 19 ACM INT C MULT, V0, P63
   Yang Z, 2013, ACM COMPUT SURV, V46, P0, DOI 10.1145/2543581.2543592
   Zhang Hang, 2022, 2022 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP2735, DOI 10.1109/CVPRW56347.2022.00309
NR 75
TC 6
Z9 6
U1 6
U2 22
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1474-0346
EI 1873-5320
J9 ADV ENG INFORM
JI Adv. Eng. Inform.
PD OCT 15
PY 2021
VL 50
IS 
BP 
EP 
DI 10.1016/j.aei.2021.101417
EA SEP 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Multidisciplinary
SC Computer Science; Engineering
GA UZ1EI
UT WOS:000701954700002
DA 2023-04-26
ER

PT J
AU Wang, JY
   Peng, Z
   Wang, XD
   Li, C
   Wu, JJ
AF Wang, Jingyuan
   Peng, Zhen
   Wang, Xiaoda
   Li, Chao
   Wu, Junjie
TI Deep Fuzzy Cognitive Maps for Interpretable Multivariate Time Series Prediction
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Time series analysis; Predictive models; Fuzzy cognitive maps; Biological neural networks; Heuristic algorithms; Transforms; Deep neural networks; fuzzy cognitive maps (FCM); interpretable prediction; time series prediction
ID extension; network; design
AB The fuzzy cognitive map (FCM) is a powerful model for system state prediction and interpretable knowledge representation. Recent years have witnessed the tremendous efforts devoted to enhancing the basic FCM, such as introducing temporal factors, uncertainty or fuzzy rules to improve interpretation, and introducing fuzzy neural networks or wavelets to improve time series prediction. But how to achieve high-precision yet interpretable prediction in cross-domain real-life applications remains a great challenge. In this article, we propose a novel FCM extension called deep FCM (DFCM) for multivariate time series forecasting, in order to take both the advantage of FCM in interpretation and the advantage of deep neural networks in prediction. Specifically, to improve the predictive power, DFCM leverages a fully connected neural network to model connections (relationships) among concepts in a system, and a recurrent neural network to model unknown exogenous factors that have influences on system dynamics. Moreover, to foster model interpretability encumbered by the embedded deep structures, a partial derivative-based approach is proposed to measure the connection strengths between concepts in DFCM. An alternate function gradient descent algorithm is then proposed for parameter inference. The effectiveness of DFCM is validated over four publicly available datasets with the presence of seven baselines. DFCM indeed provides an important clue to building interpretable predictors for real-life applications.
C1 [Wang, Jingyuan] Beihang Univ, Sch Comp Sci & Engn, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100191, Peoples R China.
   [Wang, Jingyuan] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Peng, Zhen] Beijing Inst Petrochem Technol, Sch Econ & Management, Beijing 102617, Peoples R China.
   [Wang, Xiaoda; Li, Chao] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Wang, Xiaoda; Li, Chao] Beihang Univ, MOE Engn Res Ctr ACAT, Beijing 100191, Peoples R China.
   [Wu, Junjie] Beihang Univ, Sch Econ & Management, Beijing 100191, Peoples R China.
   [Wu, Junjie] Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University; Beijing Institute of Petrochemical Technology; Beihang University; Beihang University; Beihang University; Beihang University
RP Peng, Z (corresponding author), Beijing Inst Petrochem Technol, Sch Econ & Management, Beijing 102617, Peoples R China.
EM jywang@buaa.edu.cn; zhenpeng@bipt.edu.cn; percy001@outlook.com; licc@buaa.edu.cn; wujj@buaa.edu.cn
FU National Key R&D Program of China [2019YFB2102100]; National Natural Science Foundation of China [61572059, 71531001, 71725002, U1636210]; Fundamental Research Funds for the Central Universities [YWF-20-BJ-J-839]; National Science Foundation of China [71601022]; Youth Top Talent Cultivation Plan Project of Beijing [CITTCD201804036]
CR Acampora G, 2011, SERV ORIENTED COMPUT, V5, P17, DOI 10.1007/s11761-011-0078-7
   Aguilar J., 2003, INT J COMPUTATIONAL, V1, P91
   Andreou AS, 2003, DEFENCE PEACE ECON, V14, P293, DOI 10.1080/10242690302931
   [Anonymous], 1997, NEURAL COMPUT, V0, P0
   Cai YD, 2010, IEEE COMPUT GRAPH, V30, P58, DOI 10.1109/MCG.2009.80
   Carvalho JP, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P280, DOI 10.1109/FUZZ.2001.1007303
   Froelich W, 2014, FUZZY COGNITIVE MAPS, V0, P121
   Georgopoulos VC, 2003, ARTIF INTELL MED, V29, P261, DOI 10.1016/S0933-3657(02)00076-3
   HAGIWARA M, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, V0, PP795, DOI 10.1109/FUZZY.1992.258761
   Hobbs BF, 2002, ECOL APPL, V12, P1548, DOI 10.1890/1051-0761(2002)012[1548:FCMAAT]2.0.CO;2
   Homenda W, 2014, IEEE INT FUZZY SYST, V0, PP2055, DOI 10.1109/FUZZ-IEEE.2014.6891719
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Iakovidis DK, 2011, IEEE T INF TECHNOL B, V15, P100, DOI 10.1109/TITB.2010.2093603
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Koulouriotis DE, 2001, IEEE C EVOL COMPUTAT, V0, PP364, DOI 10.1109/CEC.2001.934413
   KRUGLANSKI AW, 1975, PSYCHOL REV, V82, P387, DOI 10.1037/0033-295X.82.6.387
   Lai Xiangwei, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING (ISISE 2009), V0, PP472, DOI 10.1109/ISISE.2009.78
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Maia ALS, 2008, NEUROCOMPUTING, V71, P3344, DOI 10.1016/j.neucom.2008.02.022
   Miao Y, 2001, IEEE T FUZZY SYST, V9, P760, DOI 10.1109/91.963762
   Miao Y, 2010, IEEE T FUZZY SYST, V18, P114, DOI 10.1109/TFUZZ.2009.2037218
   Osoba O., 2019, ARXIV190611247, V0, P0
   Papageorgiou E, 2003, LECT NOTES ARTIF INT, V2903, P256
   Papageorgiou EI, 2004, INT J APPROX REASON, V37, P219, DOI 10.1016/j.ijar.2004.01.001
   Papageorgiou EI, 2017, NEUROCOMPUTING, V232, P113, DOI 10.1016/j.neucom.2016.10.072
   Papageorgiou EI, 2013, IEEE T FUZZY SYST, V21, P66, DOI 10.1109/TFUZZ.2012.2201727
   Papageorgiou EI, 2012, NEUROCOMPUTING, V92, P28, DOI 10.1016/j.neucom.2011.08.034
   PARK KS, 1995, INT J HUM-COMPUT ST, V42, P157, DOI 10.1006/ijhc.1995.1007
   Parsopoulos KE, 2003, IEEE C EVOL COMPUTAT, V0, P1440
   PEDRYCZ W, 1994, FUZZY SET SYST, V64, P21, DOI 10.1016/0165-0114(94)90003-5
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Perusich K, 1996, TECHNICAL EXPERTISE AND PUBLIC DECISIONS - 1996 INTERNATIONAL SYMPOSIUM ON TECHNOLOGY AND SOCIETY, V0, P369, DOI 10.1109/ISTAS.1996.541174
   Quan JN, 2014, ATMOS ENVIRON, V88, P83, DOI 10.1016/j.atmosenv.2014.01.058
   Ruan D., 2011, ADV INTELLIGENT SOFT, V0, PP1, DOI 10.1109/NAFIPS.2011.5751916
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Salmeron JL, 2010, EXPERT SYST APPL, V37, P7581, DOI 10.1016/j.eswa.2010.04.085
   Shumway RH, 2017, TIME SERIES ANAL ITS, V0, P0, DOI DOI 10.1007/978-3-319-52452-8
   Song HJ, 2010, NEURAL NETWORKS, V23, P1264, DOI 10.1016/j.neunet.2010.08.003
   Song HJ, 2010, IEEE T FUZZY SYST, V18, P233, DOI 10.1109/TFUZZ.2009.2038371
   Song HJJ, 2011, IEEE T FUZZY SYST, V19, P116, DOI 10.1109/TFUZZ.2010.2087383
   Stach W, 2005, FUZZY SET SYST, V153, P371, DOI 10.1016/j.fss.2005.01.009
   Stach W, 2008, IEEE T FUZZY SYST, V16, P61, DOI 10.1109/TFUZZ.2007.902020
   Tsui A, 2003, J QUANT ECON, V1, P103, DOI 10.1007/BF03404652
   Tu J, 2007, ATMOS RES, V85, P310, DOI 10.1016/j.atmosres.2007.02.003
   Vanhoenshoven F, 2018, SMART INNOV SYST TEC, V72, P255, DOI 10.1007/978-3-319-59421-7_24
   Wei Z, 2008, EXPERT SYST APPL, V35, P1583, DOI 10.1016/j.eswa.2007.08.071
   Yang SC, 2018, IEEE T FUZZY SYST, V26, P3391, DOI 10.1109/TFUZZ.2018.2831640
   Zhang CY, 2011, COMM COM INF SC, V144, P224
NR 48
TC 16
Z9 17
U1 11
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD SEP 15
PY 2021
VL 29
IS 9
BP 2647
EP 2660
DI 10.1109/TFUZZ.2020.3005293
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA UL3KJ
UT WOS:000692553900020
DA 2023-04-26
ER

PT J
AU Xi, YBA
   Ren, CY
   Tian, QJ
   Ren, YX
   Dong, XY
   Zhang, ZC
AF Xi, Yanbiao
   Ren, Chunying
   Tian, Qingjiu
   Ren, Yongxing
   Dong, Xinyu
   Zhang, Zhichao
TI Exploitation of Time Series Sentinel-2 Data and Different Machine Learning Algorithms for Detailed Tree Species Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Vegetation; Forestry; Support vector machines; Machine learning algorithms; Time series analysis; Remote sensing; Feature extraction; Deep learning; sentinel-2 image; sequential pattern; tree species classification
ID hyperspectral images; lidar; landsat; sensitivity; ndvi
AB The classification of tree species through remote sensing data is of great significance to monitoring forest disturbances, biodiversity assessment, and carbon estimation. The dense time series and a wide swath of Sentinel-2 data provided the opportunity to map tree species accurately and in a timely manner over a large area. Many current studies have applied machine learning (ML) algorithms combined with Sentinel-2 images to classify tree species, but it is still unclear, which algorithm is more effective in the automotive extraction of tree species. In this study, five ML algorithms were compared to identify the composition of tree species with multitemporal Sentinel-2 images in the JianShe forest farm, Northeast China. Three major types of deep neural networks [Conv1D, AlexNet, and long short-term memory (LSTM)] were tested to classify Sentinel-2 time series, which represent three disparate but effective strategies to apply sequential data. The other two models are support vector machine (SVM) and random forest (RF), which are renowned for extensive adoption and high performance for various remote sensing applications. The results show that the overall accuracy of neural network models is better than that of SVM and RF. The Conv1D model had the highest classification accuracy (84.19%), followed by the LSTM model (81.52%), and the AlexNet model (76.02%). For non-neural network models, RF's classification accuracy (79.04%) is higher than that of SVM (72.79%), but lower than that of Conv1D and LSTM. Therefore, the deep neural networks combined with multitemporal Sentinel-2 images can efficiently improve the accuracy of tree species classification.
C1 [Xi, Yanbiao; Tian, Qingjiu; Dong, Xinyu; Zhang, Zhichao] Nanjing Univ, Int Inst Earth Syst Sci, Nanjing 210023, Peoples R China.
   [Ren, Chunying] Chinese Acad Sci, Northeast Inst Geog & Agroecol, Key Lab Wetland Ecol & Environm, Changchun 130102, Peoples R China.
   [Ren, Yongxing] Jilin Univ, Coll Earth Sci, Changchun 130100, Peoples R China.
C3 Nanjing University; Chinese Academy of Sciences; Northeast Institute of Geography & Agroecology, CAS; Jilin University
RP Ren, CY (corresponding author), Chinese Acad Sci, Northeast Inst Geog & Agroecol, Key Lab Wetland Ecol & Environm, Changchun 130102, Peoples R China.
EM xiyb@smail.nju.edu.cn; renchy@iga.ac.cn; tianqj@nju.edu.cn; ryx20@mails.jlu.edu.cn; dg1827003@smail.nju.edu.cn; zhangzc@smail.nju.edu.cn
FU National Key Research and Development project of China [2016yfc0500300, 2017yfd0600903]; National Natural Science Foundation of China [42001349, 41771370]
CR Amani M, 2017, CAN J REMOTE SENS, V43, P360, DOI 10.1080/07038992.2017.1346468
   Arslan N, 2019, J ATMOS SOL-TERR PHY, V194, P0, DOI 10.1016/j.jastp.2019.105100
   Benediktsson J. A, 2017, P SPIE P SPIE, V0427, P0
   Blomley R, 2017, ISPRS J PHOTOGRAMM, V133, P142, DOI 10.1016/j.isprsjprs.2017.08.013
   Chen L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040414
   Chen L, 2018, FORESTS, V9, P0, DOI 10.3390/f9100582
   Cho MA, 2012, REMOTE SENS ENVIRON, V125, P214, DOI 10.1016/j.rse.2012.07.010
   Clark ML, 2020, ISPRS J PHOTOGRAMM, V159, P26, DOI 10.1016/j.isprsjprs.2019.11.007
   Dalponte M, 2012, REMOTE SENS ENVIRON, V123, P258, DOI 10.1016/j.rse.2012.03.013
   Eckle K, 2019, NEURAL NETWORKS, V110, P232, DOI 10.1016/j.neunet.2018.11.005
   Fassnacht FE, 2016, REMOTE SENS ENVIRON, V186, P64, DOI 10.1016/j.rse.2016.08.013
   Ferreira MP, 2020, FOREST ECOL MANAG, V475, P0, DOI 10.1016/j.foreco.2020.118397
   Gandhi GM, 2015, PROCEDIA COMPUT SCI, V57, P1199, DOI 10.1016/j.procs.2015.07.415
   Grabska E, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112103
   Grabska E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101197
   Guidici D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060629
   Hamraz H, 2019, ISPRS J PHOTOGRAMM, V158, P219, DOI 10.1016/j.isprsjprs.2019.10.011
   Han XB, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9080848
   Heinzel J, 2011, INT J APPL EARTH OBS, V13, P152, DOI 10.1016/j.jag.2010.09.010
   Hoscilo A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080929
   Hovi A, 2016, REMOTE SENS ENVIRON, V173, P224, DOI 10.1016/j.rse.2015.08.019
   Immitzer M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222599
   Immitzer M, 2012, REMOTE SENS-BASEL, V4, P2661, DOI 10.3390/rs4092661
   Ke YH, 2010, REMOTE SENS ENVIRON, V114, P1141, DOI 10.1016/j.rse.2010.01.002
   Kim SR, 2011, SENSORS-BASEL, V11, P1943, DOI 10.3390/s110201943
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laurin GV, 2016, REMOTE SENS ENVIRON, V176, P163, DOI 10.1016/j.rse.2016.01.017
   Li LW, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111265
   Lim J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122049
   Lim J, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8030150
   Lin WJ, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9071462
   Liu BX, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8040160
   Torres DL, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20020563
   Matsushita B, 2007, SENSORS-BASEL, V7, P2636, DOI 10.3390/s7112636
   McInerney D, 2019, INT J APPL EARTH OBS, V78, P130, DOI 10.1016/j.jag.2018.12.005
   Meng Y, 2020, FORESTS, V11, P0, DOI 10.3390/f11020130
   Mngadi M, 2021, GEOCARTO INT, V36, P1, DOI 10.1080/10106049.2019.1585483
   Nezami S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071070
   Ottosen TB, 2020, INT J APPL EARTH OBS, V84, P0, DOI 10.1016/j.jag.2019.101947
   Persson M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111794
   Reiche J, 2018, REMOTE SENS ENVIRON, V204, P147, DOI 10.1016/j.rse.2017.10.034
   Ren CY, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18124452
   Santosh T, 2020, COMPUT BIOL MED, V124, P0, DOI 10.1016/j.compbiomed.2020.103859
   Sherstinsky A, 2020, PHYSICA D, V404, P0, DOI 10.1016/j.physd.2019.132306
   Shi YF, 2018, INT J APPL EARTH OBS, V73, P207, DOI 10.1016/j.jag.2018.06.018
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Soleimannejad L, 2019, J SUSTAIN FOREST, V38, P615, DOI 10.1080/10549811.2019.1598443
   Tang Wan, 2015, SHANGHAI ARCH PSYCHIATRY, V27, P62, DOI 10.11919/j.issn.1002-0829.215010
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   WENSEL LC, 1980, J FOREST, V78, P83
   Wessel M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091419
   Wu YS, 2020, FORESTS, V11, P0, DOI 10.3390/f11010032
   Xi YB, 2019, FORESTS, V10, P0, DOI 10.3390/f10090818
   Xiao CJ, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111358
   Yildirim O, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16040599
   Yin Q, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141699
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zhang B, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111938
   Zhang CY, 2019, ISPRS J PHOTOGRAMM, V148, P221, DOI 10.1016/j.isprsjprs.2019.01.006
   Zhao CH, 2018, INFRARED PHYS TECHN, V95, P61, DOI 10.1016/j.infrared.2018.10.012
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
NR 61
TC 14
Z9 14
U1 18
U2 66
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7589
EP 7603
DI 10.1109/JSTARS.2021.3098817
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TZ8CP
UT WOS:000684698600004
DA 2023-04-26
ER

PT J
AU Wang, ZW
   Wu, J
   Liu, XD
   Garg, H
AF Wang, Zengwen
   Wu, Jian
   Liu, Xiaodi
   Garg, Harish
TI New Framework for FCMs Using Dual Hesitant Fuzzy Sets with an Analysis of Risk Factors in Emergency Event
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS
LA English
DT Article
DE Dual hesitant fuzzy sets; Fuzzy cognitive maps; Dual hesitant fuzzy cognitive maps; Similarity measure; Emergency decision-making
ID attribute decision-making; nuclear-power-plant; cognitive map; similarity measures; management model; breast-cancer; distance; information; networks; feedback
AB As a kind of soft computing tool with strong knowledge representation and causal reasoning ability, fuzzy cognitive maps (FCMs) is a product of fuzzy logic and neural network. A limitation of the current FCMs method is its inability to model the uncertainty that is introduced into a complex system due to the hesitancy of people. Dual hesitant fuzzy sets (DHFSs), which considers the membership and nonmembership degrees by a set of possible values respectively, is an effective tool to model the hesitancy and epistemic uncertainty. Thus, a novel extension of FCMs model called dual hesitant fuzzy cognitive maps (DHFCMs) is proposed in this paper. Firstly, motivated by the idea of Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) method, a new similarity measure based on dual hesitant fuzzy distance measure is put forward, and its properties are also discussed. Then, detailed procedure and algorithm for DHFCMs are specified. Moreover, the application steps of the proposed met hod are provided. Finally, a case study on the huge explosion at 'Tianjin Port in China in 2015 is given to illustrate the rationality and effectiveness of the proposed method. (C) 2021 The Authors. Published by Atlantis Press B.V.
C1 [Wang, Zengwen; Wu, Jian] Wuhan Univ, Researching Ctr Social Secur, Wuhan 430072, Hubei, Peoples R China.
   [Liu, Xiaodi] Anhui Univ Technol, Sch Math & Phys, Maanshan 243002, Peoples R China.
   [Liu, Xiaodi] Anhui Univ Technol, Key Lab Multidisciplinary Management & Control Co, Maanshan 243002, Peoples R China.
   [Garg, Harish] Thapar Inst Engn & Technol Deemed Univ, Sch Math, Patiala 147004, Punjab, India.
C3 Wuhan University; Anhui University of Technology; Anhui University of Technology; Thapar Institute of Engineering & Technology
RP Liu, XD (corresponding author), Anhui Univ Technol, Sch Math & Phys, Maanshan 243002, Peoples R China.; Liu, XD (corresponding author), Anhui Univ Technol, Key Lab Multidisciplinary Management & Control Co, Maanshan 243002, Peoples R China.
EM lxy1160@163.com
FU National Natural Science Foundation of China [71601002, 72074001]; Foundation for Young Talents in College of Anhui Province [gxyqZD2018033]; major project of Humanities and Social Sciences of Ministry of Education of China [16JJD840008]; Open Fund of Key Laboratory of Anhui Higher Education Institutes [CS2020-02]; Fundamental Research Funds for the Central Universities [2020AI017]
CR [Anonymous], 2006, THESIS, V0, P0
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Baykasoglu A, 2015, INFORM SCIENCES, V301, P75, DOI 10.1016/j.ins.2014.12.048
   Choi J, 2017, PUBLIC RELAT REV, V43, P1016, DOI 10.1016/j.pubrev.2017.09.004
   Coban V, 2017, INT J COMPUT INT SYS, V10, P1149
   Deng Julong, 1989, JOURNAL OF GREY SYSTEMS, V1, P1
   Faubet P, 2008, GENETICS, V178, P1491, DOI 10.1534/genetics.107.082560
   Feng Yan, 2013, APPLIED MECHANICS AND MATERIALS, V389, P136, DOI 10.4028/www.scientific.net/AMM.389.136
   FU LM, 1991, SIMULATION, V56, P251, DOI 10.1177/003754979105600409
   Garg H, 2018, ARAB J SCI ENG, V43, P3213, DOI 10.1007/s13369-017-2986-0
   Garg H, 2018, SOFT COMPUT, V22, P4959, DOI 10.1007/s00500-018-3202-1
   Garg H, 2017, INT J UNCERTAIN QUAN, V7, P229, DOI 10.1615/Int.J.UncertaintyQuantification.2017019801
   Gitinavard H., 2017, INT J APPL MANAG SCI, V9, P253, DOI 10.1504/IJAMS.2017.088225
   Hwang C.L., 1981, LECT NOTES EC MATH S, V0, P0
   Iakovidis DK, 2011, IEEE T INF TECHNOL B, V15, P100, DOI 10.1109/TITB.2010.2093603
   Kang I, 2004, EXPERT SYST APPL, V26, P545, DOI 10.1016/j.eswa.2003.10.012
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Lee S, 2000, INFORM MANAGE, V37, P37, DOI 10.1016/S0378-7206(99)00033-6
   Levy JK, 2007, MATH COMPUT MODEL, V46, P906, DOI 10.1016/j.mcm.2007.03.001
   Li Y, 2014, APPL SOFT COMPUT, V22, P504, DOI 10.1016/j.asoc.2014.03.042
   Liao HC, 2014, INT J INF TECH DECIS, V13, P47, DOI 10.1142/S0219622014500035
   Liu XD, 2019, ADAPT BEHAV, V27, P331, DOI 10.1177/1059712319858623
   Liu XD, 2019, INT J COMPUT INT SYS, V12, P842, DOI 10.2991/ijcis.d.190722.001
   Liu XD, 2018, TECHNOL ECON DEV ECO, V24, P1979, DOI 10.3846/tede.2018.5837
   Liu XD, 2018, COMPLEXITY, V0, P0, DOI DOI 10.1155/2018/5145348
   Liu XD, 2017, J BUS ECON MANAG, V18, P726, DOI 10.3846/16111699.2017.1341848
   Liu Y, 2014, COMPUT OPER RES, V42, P75, DOI 10.1016/j.cor.2012.08.008
   Liu Y, 2014, COMPUT OPER RES, V42, P49, DOI 10.1016/j.cor.2012.08.015
   Miao Y, 2001, IEEE T FUZZY SYST, V9, P760, DOI 10.1109/91.963762
   Ohnishi T, 2012, RADIAT RES, V177, P1, DOI 10.1667/RR2830.1
   Osei-Bryson KM, 2004, COMPUT OPER RES, V31, P1165, DOI 10.1016/S0305-0548(03)00070-4
   Papageorgiou EI, 2006, INT J HUM-COMPUT ST, V64, P727, DOI 10.1016/j.ijhcs.2006.02.009
   Papageorgiou EI, 2015, COMPUT METH PROG BIO, V122, P123, DOI 10.1016/j.cmpb.2015.07.003
   Papageorgiou EI, 2013, IEEE T FUZZY SYST, V21, P342, DOI 10.1109/TFUZZ.2012.2214224
   Singh P, 2017, COMPUT APPL MATH, V36, P111, DOI 10.1007/s40314-015-0219-2
   Song HJ, 2010, NEURAL NETWORKS, V23, P1264, DOI 10.1016/j.neunet.2010.08.003
   Stach W, 2008, IEEE T FUZZY SYST, V16, P61, DOI 10.1109/TFUZZ.2007.902020
   Su Z, 2015, J INTELL FUZZY SYST, V29, P731, DOI 10.3233/IFS-141474
   Subramanian J, 2015, COMPUT METH PROG BIO, V118, P280, DOI 10.1016/j.cmpb.2015.01.001
   Torra V, 2010, INT J INTELL SYST, V25, P529, DOI 10.1002/int.20418
   Tzeng GH, 2010, SOFT COMPUT, V14, P1141, DOI 10.1007/s00500-009-0507-0
   Voropai N. I., 2011, IFAC P, V44, P1658
   Voropai N. I., 2013, IFAC P, V46, P245
   Wada K, 2012, OCCUP ENVIRON MED, V69, P599, DOI 10.1136/oemed-2011-100587
   Wang L., 2013, J APPL MATH, V2013, P12
   Wang L, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), V0, PP88, DOI 10.1109/PIC.2014.6972302
   Wu J, 2019, IEEE ACCESS, V7, P7054, DOI 10.1109/ACCESS.2018.2890110
   Yang SH, 2015, J INTELL FUZZY SYST, V28, P1533, DOI 10.3233/IFS-141436
   Ye J, 2014, APPL MATH MODEL, V38, P659, DOI 10.1016/j.apm.2013.07.010
   Ye X.R., 2006, THEORY PRACTICE CRIS, V0, P0
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang BW, 2020, EUR J OPER RES, V287, P546, DOI 10.1016/j.ejor.2020.04.014
   Zhang GQ, 2009, STOCH ENV RES RISK A, V23, P517, DOI 10.1007/s00477-008-0237-3
   Zhang HJ, 2020, INFORM FUSION, V60, P65, DOI 10.1016/j.inffus.2020.03.001
   Zhang HJ, 2020, IISE TRANS, V52, P1275, DOI 10.1080/24725854.2020.1731774
   Zhang Z, 2020, KNOWL-BASED SYST, V204, P0, DOI 10.1016/j.knosys.2020.106240
   Zhang Z, 2021, J OPER RES SOC, V72, P1914, DOI 10.1080/01605682.2020.1748529
   Zhang Z, 2020, IEEE T FUZZY SYST, V28, P2875, DOI 10.1109/TFUZZ.2019.2949758
   Zhou Q, 2011, SAFETY SCI, V49, P243, DOI 10.1016/j.ssci.2010.08.005
   Zhou S, 2006, IEEE T FUZZY SYST, V14, P412, DOI 10.1109/TFUZZ.2006.876335
   Zhu B, 2012, J APPL MATH, V0, P0, DOI DOI 10.1155/2012/879629
NR 61
TC 8
Z9 8
U1 13
U2 30
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1875-6891
EI 1875-6883
J9 INT J COMPUT INT SYS
JI Int. J. Comput. Intell. Syst.
PD JUN 15
PY 2021
VL 14
IS 1
BP 67
EP 78
DI 10.2991/ijcis.d.201015.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA PU2UI
UT WOS:000609160600002
DA 2023-04-26
ER

PT J
AU Huang, JQ
   Weng, LG
   Chen, BY
   Xia, M
AF Huang, Junqing
   Weng, Liguo
   Chen, Bingyu
   Xia, Min
TI DFFAN: Dual Function Feature Aggregation Network for Semantic Segmentation of Land Cover
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE land cover; semantic segmentation; convolution neural network
ID water areas segmentation; remote-sensing images; classification
AB Analyzing land cover using remote sensing images has broad prospects, the precise segmentation of land cover is the key to the application of this technology. Nowadays, the Convolution Neural Network (CNN) is widely used in many image semantic segmentation tasks. However, existing CNN models often exhibit poor generalization ability and low segmentation accuracy when dealing with land cover segmentation tasks. To solve this problem, this paper proposes Dual Function Feature Aggregation Network (DFFAN). This method combines image context information, gathers image spatial information, and extracts and fuses features. DFFAN uses residual neural networks as backbone to obtain different dimensional feature information of remote sensing images through multiple downsamplings. This work designs Affinity Matrix Module (AMM) to obtain the context of each feature map and proposes Boundary Feature Fusion Module (BFF) to fuse the context information and spatial information of an image to determine the location distribution of each image's category. Compared with existing methods, the proposed method is significantly improved in accuracy. Its mean intersection over union (MIoU) on the LandCover dataset reaches 84.81%.
C1 [Huang, Junqing; Weng, Liguo; Chen, Bingyu; Xia, Min] Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Big Data Anal Technol, Nanjing 210044, Peoples R China.
   [Huang, Junqing; Weng, Liguo; Chen, Bingyu; Xia, Min] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology
RP Weng, LG (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Big Data Anal Technol, Nanjing 210044, Peoples R China.; Weng, LG (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
EM hjq@nuist.edu.cn; 002311@nuist.edu.cn; 20191222015@nuist.edu.cn; xiamin@nuist.edu.cn
FU National Natural Science Foundation of PR China [42075130,41875027]
CR Ahlawat S, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20123344
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Boguszewski A, 2021, IEEE COMPUT SOC CONF, V0, PP1102, DOI 10.1109/CVPRW53098.2021.00121
   Changqian Yu, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP12413, DOI 10.1109/CVPR42600.2020.01243
   Chen BY, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13040731
   Diganta M., 2020, ARXIV190808681, V10, P0
   Fang WD, 2019, CMC-COMPUT MATER CON, V61, P583, DOI 10.32604/cmc.2019.05237
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   Gu BJ, 2020, CMC-COMPUT MATER CON, V63, P243, DOI 10.32604/cmc.2020.06898
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Janarthanan A, 2019, CMC-COMPUT MATER CON, V60, P895, DOI 10.32604/cmc.2019.06805
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lee S, 2020, CMC-COMPUT MATER CON, V65, P1, DOI 10.32604/cmc.2020.011104
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1264
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Qian JH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172669
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Samaniego L, 2008, IEEE T GEOSCI REMOTE, V46, P2112, DOI 10.1109/TGRS.2008.916629
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Sezer OB, 2020, INTELL AUTOM SOFT CO, V26, P323, DOI 10.31209/2018.100000065
   Simonyan K, 2015, ARXIV, V0, P0
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Weng LG, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040256
   Wulder MA, 2012, REMOTE SENS ENVIRON, V122, P2, DOI 10.1016/j.rse.2012.01.010
   Xia M, 2021, INT J REMOTE SENS, V42, P2594, DOI 10.1080/01431161.2020.1856964
   Xia M, 2021, INT J REMOTE SENS, V42, P2022, DOI 10.1080/01431161.2020.1849852
   Xia M, 2020, EXPERT SYST APPL, V160, P0, DOI 10.1016/j.eswa.2020.113669
   Xia M, 2020, INT J REMOTE SENS, V41, P7779, DOI 10.1080/01431161.2020.1763511
   Xia M, 2020, IEEE T INF FOREN SEC, V15, P2417, DOI 10.1109/TIFS.2020.2969552
   Xu M, 2005, REMOTE SENS ENVIRON, V97, P322, DOI 10.1016/j.rse.2005.05.008
   Yang WB, 2020, CMC-COMPUT MATER CON, V63, P283, DOI 10.32604/cmc.2020.07511
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
NR 38
TC 8
Z9 8
U1 0
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD MAR 15
PY 2021
VL 10
IS 3
BP 
EP 
DI 10.3390/ijgi10030125
PG 17
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RD8GN
UT WOS:000633709200001
DA 2023-04-26
ER

PT J
AU Javan, FD
   Samadzadegan, F
   Mehravar, S
   Toosi, A
   Khatami, R
   Stein, A
AF Javan, Farzaneh Dadrass
   Samadzadegan, Farhad
   Mehravar, Soroosh
   Toosi, Ahmad
   Khatami, Reza
   Stein, Alfred
TI A review of image fusion techniques for pan-sharpening of high-resolution satellite imagery
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Review
DE Image fusion; Pan-sharpening; Spectral and spatial quality
ID wavelet transform; pansharpening methods; intensity modulation; landsat tm; quality; multiresolution; algorithms; regression; tradeoff; details
AB Pan-sharpening methods are commonly used to synthesize multispectral and panchromatic images. Selecting an appropriate algorithm that maintains the spectral and spatial information content of input images is a challenging task. This review paper investigates a wide range of algorithms, including 41 methods. For this purpose, the methods were categorized as Component Substitution (CS-based), Multi-Resolution Analysis (MRA), Variational Optimization-based (VO), and Hybrid and were tested on a collection of 21 case studies. These include images from WorldView-2, 3 & 4, GeoEye-1, QuickBird, IKONOS, KompSat-2, KompSat-3A, TripleSat, Pleiades-1, Pleiades with the aerial platform, and Deimos-2. Neural network-based methods were excluded due to their substantial computational requirements for operational mapping purposes. The methods were evaluated based on four Spectral and three Spatial quality metrics. An Analysis Of Variance (ANOVA) was used to statistically compare the pan-sharpening categories. Results indicate that MRA-based methods performed better in terms of spectral quality, whereas most Hybrid-based methods had the highest spatial quality and CS-based methods had the lowest results both spectrally and spatially. The revisited version of the Additive Wavelet Luminance Proportional Pan-sharpening method had the highest spectral quality, whereas Generalized IHS with Best Trade-off Parameter with Additive Weights showed the highest spatial quality. CS-based methods generally had the fastest run-time, whereas the majority of methods belonging to MRA and VO categories had relatively long run times.
C1 [Javan, Farzaneh Dadrass; Samadzadegan, Farhad; Mehravar, Soroosh; Toosi, Ahmad] Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, POB 11155-4563, Tehran 1439957131, Iran.
   [Javan, Farzaneh Dadrass; Stein, Alfred] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, NL-7522 NB Enschede, Netherlands.
   [Khatami, Reza] Univ Florida, Dept Geog, Gainesville, FL 32611 USA.
C3 University of Tehran; University of Twente; State University System of Florida; University of Florida
RP Javan, FD (corresponding author), Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, POB 11155-4563, Tehran 1439957131, Iran.
EM fdadrasjavan@ut.ac.ir; samadz@ut.ac.ir; sorooshmehravar@ut.ac.ir; ahmadtoosi71@ut.ac.ir; seyedghkhatami@ufl.edu; a.stein@utwente.nl
CR Aiazzi B, 2006, PHOTOGRAMM ENG REM S, V72, P591, DOI 10.14358/PERS.72.5.591
   Aiazzi B, 2003, 2ND GRSS/ISPRS JOINT WORKSHOP ON REMOTE SENSING AND DATA FUSION OVER URBAN AREAS, V0, PP90, DOI 10.1109/DFUA.2003.1219964
   Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alidoost F, 2015, INT J IMAGE DATA FUS, V6, P216, DOI 10.1080/19479832.2015.1055834
   Alparone I., 2015, REMOTE SENSING IMAGE, V0, P0
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   Alparone L, 2017, IEEE T GEOSCI REMOTE, V55, P4682, DOI 10.1109/TGRS.2017.2697943
   Aly HA, 2014, IEEE T IMAGE PROCESS, V23, P2596, DOI 10.1109/TIP.2014.2316641
   Amolins K, 2007, ISPRS J PHOTOGRAMM, V62, P249, DOI 10.1016/j.isprsjprs.2007.05.009
   Amro I, 2011, EURASIP J ADV SIG PR, V0, P0, DOI DOI 10.1186/1687-6180-2011-79
   [Anonymous], 2018, CONCURR COMPUT PRACT, V0, P0, DOI DOI 10.1007/978-981-13-0104-9_80
   [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0
   Azarang A, 2019, IEEE ACCESS, V7, P35673, DOI 10.1109/ACCESS.2019.2905511
   Baisantry M., 2011, 2011 INT C IM INF PR, V0, P1
   Ballester C, 2006, INT J COMPUT VISION, V69, P43, DOI 10.1007/s11263-006-6852-x
   Belgiu M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070818
   Blasch E, 2008, 11 INT C DIG OBJ ID, V0, PP1, DOI 10.1109/ICIF.2008.4632263
   Cai J., 2020, IEEE T GEOSCI REMOTE, V0, P0
   Cao X, 2008, GEOCARTO INT, V23, P155
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Chen S., 2008, IGARSS 2008 2008 IEE, V0, P0
   Chen Y., 2005, 2005 7TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), V0, P0
   Chen YH, 2005, INT GEOSCI REMOTE SE, V0, P3924
   Cheng J, 2015, ISPRS J PHOTOGRAMM, V104, P158, DOI 10.1016/j.isprsjprs.2015.02.015
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Choi M, 2006, IEEE T GEOSCI REMOTE, V44, P1672, DOI 10.1109/TGRS.2006.869923
   DadrasJavan F, 2014, ADV SPACE RES, V54, P2286, DOI 10.1016/j.asr.2014.08.024
   DadrasJavan F., 2018, EUR J APPL SCI, V6, P1
   Dou W, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010154
   Duran J, 2017, ISPRS J PHOTOGRAMM, V125, P78, DOI 10.1016/j.isprsjprs.2016.12.013
   Ehlers M, 2010, INT J IMAGE DATA FUS, V1, P25, DOI 10.1080/19479830903561985
   El Tawel G.S, 2020, TRANSFORM SENS IMAGI, V21, P3
   Fasbender D, 2008, IEEE T GEOSCI REMOTE, V46, P1847, DOI 10.1109/TGRS.2008.917131
   Fu XY, 2019, PROC CVPR IEEE, V0, PP10257, DOI 10.1109/CVPR.2019.01051
   Garzelli A., 2004, PAN SHARPENING MULTI, V0, P0
   Garzelli A, 2008, IEEE T GEOSCI REMOTE, V46, P228, DOI 10.1109/TGRS.2007.907604
   Ghahremani M, 2016, IEEE GEOSCI REMOTE S, V13, P1606, DOI 10.1109/LGRS.2016.2597271
   Ghahremani M, 2016, IEEE T GEOSCI REMOTE, V54, P2194, DOI 10.1109/TGRS.2015.2497309
   Gharbia R, 2014, ADV INTELL SYST, V303, P311, DOI 10.1007/978-3-319-08156-4_31
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Gonzalez-Audicana M, 2005, INT J REMOTE SENS, V26, P595, DOI 10.1080/01431160512331314056
   Gonzalez-Audicana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Gore SA, 2017, GEOCARTO INT, V32, P1268, DOI 10.1080/10106049.2016.1206627
   Hasanlou M, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2015-0
   He L, 2019, IEEE J-STARS, V12, P1188, DOI 10.1109/JSTARS.2019.2898574
   He XY, 2014, IEEE T IMAGE PROCESS, V23, P4160, DOI 10.1109/TIP.2014.2333661
   Helmy AK, 2015, EGYPT INFORM J, V16, P121, DOI 10.1016/j.eij.2015.02.003
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Javan FD, 2013, REMOTE SENS-BASEL, V5, P6539, DOI 10.3390/rs5126539
   Jelenek J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100794
   Jiang D, 2011, IMAGE FUSION ITS APP, V0, PP1, DOI 10.5772/10548
   Jiang MH, 2020, ISPRS J PHOTOGRAMM, V163, P257, DOI 10.1016/j.isprsjprs.2020.03.006
   Jing LH, 2012, INT J REMOTE SENS, V33, P2434, DOI 10.1080/01431161.2011.611183
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P5088, DOI 10.1109/TGRS.2013.2286827
   Kaplan N.H., 2016, INT J COMPUT APPL, V140, P0
   Khan MM, 2008, IEEE GEOSCI REMOTE S, V5, P98, DOI 10.1109/LGRS.2007.909934
   Khan MM, 2009, IEEE T GEOSCI REMOTE, V47, P3880, DOI 10.1109/TGRS.2009.2029094
   Kim Y, 2011, IEEE GEOSCI REMOTE S, V8, P263, DOI 10.1109/LGRS.2010.2067192
   Klonus S, 2009, FUSION: 2009 12TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4, P1409
   Lari S.N., 2016, INT J SIGNAL PROCESS, V9, P291, DOI 10.14257/ijsip.2016.9.3.26
   Lee J, 2010, IEEE T GEOSCI REMOTE, V48, P155, DOI 10.1109/TGRS.2009.2028613
   Leung L.W., 2001, 22 AS C REM SENS, V5, P9
   Li H, 2017, IEEE J-STARS, V10, P5039, DOI 10.1109/JSTARS.2017.2730221
   Li H, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17010089
   Li XJ, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20102764
   Licciardi G, 2016, MULTIDIM SYST SIGN P, V27, P807, DOI 10.1007/s11045-015-0359-y
   Liu JG, 2000, INT J REMOTE SENS, V21, P3461, DOI 10.1080/014311600750037499
   Liu PF, 2018, IEEE T GEOSCI REMOTE, V56, P1788, DOI 10.1109/TGRS.2017.2768386
   Liu XY, 2020, INFORM FUSION, V55, P1, DOI 10.1016/j.inffus.2019.07.010
   Liu XY, 2018, IEEE IMAGE PROC, V0, PP873, DOI 10.1109/ICIP.2018.8451049
   Liu Y, 2013, IEEE CONF IMAGING SY, V0, PP288, DOI 10.1109/IST.2013.6729708
   Loncan L, 2015, IEEE GEOSC REM SEN M, V3, P27, DOI 10.1109/MGRS.2015.2440094
   Mandhare R. A., 2013, INT J ADV RES ELECT, V2, P2690
   Masi G, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070594
   Meng XC, 2019, INFORM FUSION, V46, P102, DOI 10.1016/j.inffus.2018.05.006
   Nikolakopoulos KG, 2008, PHOTOGRAMM ENG REM S, V74, P647, DOI 10.14358/PERS.74.5.647
   Nunez J, 1999, IEEE T GEOSCI REMOTE, V37, P1204, DOI 10.1109/36.763274
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   Padwick C., 2010, P ASPRS 2010 ANN C S, V0, P0
   Palsson F., 2013, THESIS, V0, P0
   Palsson F, 2014, IEEE GEOSCI REMOTE S, V11, P318, DOI 10.1109/LGRS.2013.2257669
   Pan ZX, 2013, IEEE T GEOSCI REMOTE, V51, P4864, DOI 10.1109/TGRS.2012.2230270
   Pandit V.R., 2015, INT COMPUT APPL, V120, P0
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS
   Pohith G., 2020, IEEE ACCESS, V8, P162099
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Pushparaj J, 2017, APPL GEOMAT, V9, P1, DOI 10.1007/s12518-016-0179-2
   Qu Y., 2020, IEEE T GEOSCI REMOTE, V0, P0
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Restaino R, 2017, IEEE T GEOSCI REMOTE, V55, P753, DOI 10.1109/TGRS.2016.2614367
   Restaino R, 2016, IEEE T IMAGE PROCESS, V25, P2882, DOI 10.1109/TIP.2016.2556944
   Riyahi R., 2009, INT SOC PHOTOGRAMM R, V38, P1
   Rockinger O, 1998, P SOC PHOTO-OPT INS, V3374, P378, DOI 10.1117/12.327135
   Rodriguez-Esparragon D, 2017, NEUROCOMPUTING, V255, P40, DOI 10.1016/j.neucom.2016.06.091
   Sagan V, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030330
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Shandoosti H.R., 2011, MULTISPECTRAL PANCHR, V0, P0
   Shandoosti H.R., 2017, ARXIV170101996, V0, P0
   Shen HF, 2019, IEEE T GEOSCI REMOTE, V57, P6169, DOI 10.1109/TGRS.2019.2904659
   Student P, 2014, STUDY IMAGE FUSION T, V0, P0
   Te-Ming Tu, 2001, INFORMATION FUSION, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Thomas C., 2006, 2006 9 INT C INF FUS, V0, P1
   Toosi A, 2020, ARAB J GEOSCI, V13, P0, DOI 10.1007/s12517-020-05523-3
   Tu TM, 2007, IEEE GEOSCI REMOTE S, V4, P302, DOI 10.1109/LGRS.2007.894143
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Vicinanza MR, 2015, IEEE GEOSCI REMOTE S, V12, P180, DOI 10.1109/LGRS.2014.2331291
   Vijayaraj V, 2006, OPT ENG, V45, P0, DOI 10.1117/1.2195987
   Vitale S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030348
   Vivone G, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192315
   Vivone G, 2019, IEEE T GEOSCI REMOTE, V57, P6421, DOI 10.1109/TGRS.2019.2906073
   Vivone G, 2018, IEEE T IMAGE PROCESS, V27, P3418, DOI 10.1109/TIP.2018.2819501
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P1997, DOI 10.1109/TGRS.2014.2351754
   Wald L, 2002, INT J REMOTE SENS, V23, P593, DOI 10.1080/01431160110088772
   Wald L., 2000, PROC 3 C FUSION EART, V0, P99
   Wang TT, 2019, IEEE T IMAGE PROCESS, V28, P227, DOI 10.1109/TIP.2018.2866954
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei J, 2020, IEEE J-STARS, V13, P5455, DOI 10.1109/JSTARS.2020.3021074
   Wei YC, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017), V0, P0
   Witharana C, 2013, APPL GEOGR, V37, P63, DOI 10.1016/j.apgeog.2012.10.008
   Xing YH, 2018, ISPRS J PHOTOGRAMM, V145, P165, DOI 10.1016/j.isprsjprs.2018.01.016
   Xu J., 2008, REMOTE SENS SPAT INF, V37, P1169
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yakhdani Mohammad Fallah, 2010, QUALITY ASSESSMENT I, V0, P0
   Yang C, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113624
   Yang J.Fu, 2017, P IEEE INT C COMP VI, V0, P5449
   Yang Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040391
   Yin HT, 2017, IEEE T GEOSCI REMOTE, V55, P3545, DOI 10.1109/TGRS.2017.2675961
   Yin HT, 2015, SIGNAL PROCESS, V113, P218, DOI 10.1016/j.sigpro.2014.12.017
   Yuhendra, 2012, INT J APPL EARTH OBS, V18, P165, DOI 10.1016/j.jag.2012.01.013
   Yun Zhang, 2005, INFORMATION FUSION, V6, P225, DOI 10.1016/j.inffus.2004.06.009
   Zeng DL, 2016, REMOTE SENS LETT, V7, P1170, DOI 10.1080/2150704X.2016.1222098
   Zhang LB, 2020, INT J REMOTE SENS, V41, P3095, DOI 10.1080/01431161.2019.1698784
   Zhang XM, 2004, OPT APPL, V34, P453
   Zhang Y, 2008, IAPRSIS B7, V37, P1101
   Zhang YJ, 2019, IEEE T GEOSCI REMOTE, V57, P5549, DOI 10.1109/TGRS.2019.2900419
   Zheng Y., 2017, INT ARCH PHOTOGRAMM, V42, P0
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
   Zhu XX, 2016, IEEE T GEOSCI REMOTE, V54, P2664, DOI 10.1109/TGRS.2015.2504261
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 143
TC 48
Z9 51
U1 19
U2 79
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN 15
PY 2021
VL 171
IS 
BP 101
EP 117
DI 10.1016/j.isprsjprs.2020.11.001
PG 17
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PN3UD
UT WOS:000604406500007
DA 2023-04-26
ER

PT J
AU Zheng, ZX
   Zhang, XL
   Xiao, PF
   Li, ZS
AF Zheng, Zixian
   Zhang, Xueliang
   Xiao, Pengfeng
   Li, Zhenshi
TI Integrating Gate and Attention Modules for High-Resolution Image Semantic Segmentation
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Semantics; Image segmentation; Feature extraction; Decoding; Remote sensing; Spatial resolution; Logic gates; Attention module (AM); gate module (GM); high-resolution (HR) remote sensing imagery; semantic segmentation
ID fully convolutional networks; aerial; multiscale; fusion
AB Semantic segmentation of high-resolution (HR) remote sensing images achieved great progress by utilizing deep convolutional neural networks (DCNNs) in recent years. However, the decrease of resolution in the feature map of DCNNs brings about the loss of spatial information and thus leads to the blurring of object boundary and misclassification of small objects. In addition, the class imbalance and the high diversity of geographic objects in HR images exacerbate the performance. To deal with the above problems, we proposed an end-to-end DCNN network named GAMNet to balance the contradiction between global semantic information and local details. An integration of attention and gate module (GAM) is specially designed to simultaneously realize multiscale feature extraction and boundary recovery. The integration module can be inserted in an encoder-decoder network with skip connection. Meanwhile, a composite loss function is designed to achieve deep supervision of GAM by adding an auxiliary loss, which can help improve the effectiveness of the integration module. The performance of GAMNet is quantitatively evaluated on the ISPRS 2-D semantic labeling datasets and achieves state-of-the-art performance in comparison with other representative methods.
C1 [Zheng, Zixian; Zhang, Xueliang; Xiao, Pengfeng; Li, Zhenshi] Nanjing Univ, Sch Geog & Ocean Sci, Key Lab Land Satellite Remote Sensing Applicat, Minist Nat Resources,Jiangsu Prov Key Lab Geog In, Nanjing 210023, Peoples R China.
C3 Ministry of Natural Resources of the People's Republic of China; Nanjing University
RP Zhang, XL (corresponding author), Nanjing Univ, Sch Geog & Ocean Sci, Key Lab Land Satellite Remote Sensing Applicat, Minist Nat Resources,Jiangsu Prov Key Lab Geog In, Nanjing 210023, Peoples R China.
EM zhengzx95@gmail.com; zxl@nju.edu.cn; xiaopf@nju.edu.cn; lzhenshi@outlook.com
FU National Science and Technology Major Project of China [21-Y20A06-9001-17/18]; National Natural Science Foundation of China [42071297, 41871235, 41871326]; Fundamental Research Funds for the Central Universities [020914380080]; Highlevel Innovation and Entrepreneurship Talents Introduction Program of Jiangsu Province of China
CR [Anonymous], 2017, C COMP VIS PATT REC, V0, P0
   [Anonymous], 2015, ARXIV, V0, P0
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Audebert N, 2016, INT GEOSCI REMOTE SE, V0, PP5091, DOI 10.1109/IGARSS.2016.7730327
   Cao ZY, 2019, IEEE GEOSCI REMOTE S, V16, P1766, DOI 10.1109/LGRS.2019.2907009
   Chai DF, 2020, ISPRS J PHOTOGRAMM, V161, P309, DOI 10.1016/j.isprsjprs.2020.01.023
   Chai D, 2019, REMOTE SENS ENVIRON, V225, P307, DOI 10.1016/j.rse.2019.03.007
   Chen GZ, 2018, IEEE J-STARS, V11, P1633, DOI 10.1109/JSTARS.2018.2810320
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2016, PROC CVPR IEEE, V0, PP3640, DOI 10.1109/CVPR.2016.396
   Chen YT, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040625
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Cramer M, 2010, PHOTOGRAMM FERNERKUN, V0, PP73, DOI 10.1127/1432-8364/2010/0041
   Deng J., 2009, P CVPR, V0, P248
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Ding HH, 2019, IEEE I CONF COMP VIS, V0, PP6818, DOI 10.1109/ICCV.2019.00692
   Fu JL, 2017, PROC CVPR IEEE, V0, PP4476, DOI 10.1109/CVPR.2017.476
   Fu YY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030280
   Geng QC, 2016, I C VIRTUAL REALITY, V0, PP158, DOI 10.1109/ICVRV.2016.34
   Gerke M., 2014, USE STAIR VISION LIB, V0, P0, DOI DOI 10.13140/2.1.5015.9683
   He K., 2015, P IEEE C COMP VIS PA, V0, P0
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang ZL, 2019, IEEE I CONF COMP VIS, V0, PP603, DOI 10.1109/ICCV.2019.00069
   Islam M. A., 2018, GATED FEEDBACK REFIN, V0, P0
   Kang WC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232813
   Li XT, 2020, AAAI CONF ARTIF INTE, V34, P11418
   Lin HN, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050480
   Liu QH, 2020, IEEE T GEOSCI REMOTE, V58, P6309, DOI 10.1109/TGRS.2020.2976658
   Liu YC, 2018, ISPRS J PHOTOGRAMM, V145, P78, DOI 10.1016/j.isprsjprs.2017.12.007
   Liu Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060522
   Liu Z., 2019, P 8 INT C COMP PATT, V0, P117
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P7092, DOI 10.1109/TGRS.2017.2740362
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Milan A., 2016, REFINENET MULTIPATH, V0, P0
   Nogueira K, 2019, IEEE T GEOSCI REMOTE, V57, P7503, DOI 10.1109/TGRS.2019.2913861
   Paisitkriangkrai S, 2016, IEEE J-STARS, V9, P2868, DOI 10.1109/JSTARS.2016.2582921
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Rottensteiner F., 2012, ISPRS ANN PHOTOGRAMM, V0, P293
   Shi YL, 2020, ISPRS J PHOTOGRAMM, V159, P184, DOI 10.1016/j.isprsjprs.2019.11.004
   Trinh TH, 2018, PR MACH LEARN RES, V80, P0
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050446
   Wang L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070884
   Wang MC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121933
   Weng LG, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040256
   Wieland M, 2019, REMOTE SENS ENVIRON, V230, P0, DOI 10.1016/j.rse.2019.05.022
   Xi BB, 2021, IEEE T GEOSCI REMOTE, V59, P5114, DOI 10.1109/TGRS.2020.3022029
   Xin J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212499
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang SQ, 2018, LECT NOTES COMPUT SC, V11165, P232, DOI 10.1007/978-3-030-00767-6_22
   Yao QL, 2019, INT GEOSCI REMOTE SE, V0, PP1450, DOI 10.1109/IGARSS.2019.8897851
   Yi YN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151774
   Yu F., 2015, P 4 INT C LEARNING R, V0, P0
   Yue K, 2019, ISPRS J PHOTOGRAMM, V156, P1, DOI 10.1016/j.isprsjprs.2019.07.007
   Zhang J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040701
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang M, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050500
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zheng XW, 2020, ISPRS J PHOTOGRAMM, V170, P15, DOI 10.1016/j.isprsjprs.2020.09.019
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 66
TC 8
Z9 8
U1 3
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4530
EP 4546
DI 10.1109/JSTARS.2021.3071353
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SC1VT
UT WOS:000650468700008
DA 2023-04-26
ER

PT J
AU Wang, LQ
   Lin, Y
   Liu, JY
   Li, ZW
   Wu, CL
AF Wang, Leiquan
   Lin, Yao
   Liu, Jinyun
   Li, Zhongwei
   Wu, Chunlei
TI Siamese Spectral Attention With Channel Consistency for Hyperspectral Image Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Hyperspectral imaging; Feature extraction; Task analysis; Convolutional neural networks; Training; Convolution; Training data; Channel consistency; double-branch; hyperspectral image (HSI) classification; spectral siamese
ID cnn
AB Abundant spectral features are the precious wealth of hyperspectral images (HSI). Nevertheless, well-designed spectral feature is still a challenge that affects the performance of the classifier, especially with insufficient number of training samples. To make up the poor discriminability of spectral feature, double-branch methods are proposed by fusing parallel spectral and spatial branches. However, this structure does nothing to improve the quality of spectral feature, which is regarded as the most valuable information for HSI information. In this article, we propose a siamese spectral attention network with channel consistency (SSACC) to focus on obtaining discriminative spectral features, thus improving the generalization ability of the classifier. Two kinds of HSI cubes with different patch sizes are generated as the input of SSACC. The two cubes are divided into top and bottom branches and then be fed into the siamese network to obtain the refined spectral features. Then, self-attention is conducted to interacting with each channel for the spectral features enhancement. Meanwhile, two attention maps are obtained to display the spectral structures of each branch. A channel consistency regularization is performed on the two attention maps by enforcing the two branches to possess similar spectral patterns when identifying the same centric pixel. Extensive experiments conducted on the three HSI datasets verify the superiority of the obtained spectral feature. Furthermore, the proposed method applying convolution only on the spectral domain outperforms the state-of-the-art double-branch methods which integrate the spectral and spatial features simultaneously.
C1 [Wang, Leiquan; Wu, Chunlei] China Univ Petr, Coll Comp Sci & Technol, Qingdao 266555, Peoples R China.
   [Lin, Yao; Li, Zhongwei] China Univ Petr, Coll Oceanog & Space Informat, Qingdao 266555, Peoples R China.
   [Liu, Jinyun] SINO Pipeline Int Co Ltd, Beijing 100028, Peoples R China.
C3 China University of Petroleum; China University of Petroleum
RP Li, ZW (corresponding author), China Univ Petr, Coll Oceanog & Space Informat, Qingdao 266555, Peoples R China.
EM richiewlq@gmail.com; 2795561928@qq.com; jinyun.liu@cnpc.com.cn; lizhongwei@upc.edu.cn; wuchunlei@upc.edu.cn
FU National Natural Science Foundation of China [62071491, U1906217]; Fundamental Research Funds for the Central Universities [19CX05003A-11]
CR Ahmad, 2021, ARXIV210106116, V0, P0
   Anderson P, 2018, PROC CVPR IEEE, V0, PP3674, DOI 10.1109/CVPR.2018.00387
   Arabi B, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2020.111632
   Arun PV, 2019, IEEE J-STARS, V12, P1849, DOI 10.1109/JSTARS.2019.2913097
   Bandos TV, 2009, IEEE T GEOSCI REMOTE, V47, P862, DOI 10.1109/TGRS.2008.2005729
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Cao Y, 2019, IEEE INT CONF COMP V, V0, PP1971, DOI 10.1109/ICCVW.2019.00246
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   CHOE J, 1900, DOI 10.1109/TPAMI.2020.2999099, V0, P0
   Deng C, 2019, IEEE T GEOSCI REMOTE, V57, P1741, DOI 10.1109/TGRS.2018.2868851
   Fang B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020159
   Gao HM, 2019, IEEE ACCESS, V7, P176587, DOI 10.1109/ACCESS.2019.2957163
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P2281, DOI 10.1109/TGRS.2020.3007921
   Haut JM, 2019, IEEE T GEOSCI REMOTE, V57, P8065, DOI 10.1109/TGRS.2019.2918080
   He L, 2018, IEEE T GEOSCI REMOTE, V56, P1579, DOI 10.1109/TGRS.2017.2765364
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hu W, 2015, J SENSORS, V2015, P0, DOI 10.1155/2015/258619
   Hu WS, 2020, IEEE T GEOSCI REMOTE, V58, P4237, DOI 10.1109/TGRS.2019.2961947
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Jia S, 2020, IEEE T GEOSCI REMOTE, V58, P5077, DOI 10.1109/TGRS.2020.2972294
   Kaushik P, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, V0, P350
   Khodadadzadeh M, 2014, IEEE GEOSCI REMOTE S, V11, P2105, DOI 10.1109/LGRS.2014.2320258
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lai QX, 2021, IEEE T MULTIMEDIA, V23, P2086, DOI 10.1109/TMM.2020.3007321
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li R, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030582
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li ZK, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3052346
   Liang L, 2015, REMOTE SENS ENVIRON, V165, P123, DOI 10.1016/j.rse.2015.04.032
   Liu QS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121330
   Lu ZY, 2020, IEEE J-STARS, V13, P4311, DOI 10.1109/JSTARS.2020.3011992
   Ma WP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111307
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mohanty PC, 2016, PROC SPIE, V9880, P0, DOI 10.1117/12.2227991
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P110, DOI 10.1109/TGRS.2019.2933609
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Pan ET, 2019, INT GEOSCI REMOTE SE, V0, PP413, DOI 10.1109/IGARSS.2019.8898758
   Pande S, 2021, PATTERN RECOGN LETT, V144, P6, DOI 10.1016/j.patrec.2021.01.015
   Roy SK, 2021, IEEE T GEOSCI REMOTE, V59, P7831, DOI 10.1109/TGRS.2020.3043267
   Sellars P, 2020, IEEE T GEOSCI REMOTE, V58, P4180, DOI 10.1109/TGRS.2019.2961599
   Shi C, 2018, PATTERN RECOGN, V74, P600, DOI 10.1016/j.patcog.2017.09.007
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P3232, DOI 10.1109/TGRS.2019.2951160
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Q., 2020, CVF C COMP VIS PATT, V0, P0, DOI DOI 10.1109/CVPR42600.2020.01155
   Wang SL, 2018, PROC CVPR IEEE, V0, PP2589, DOI 10.1109/CVPR.2018.00274
   Wang WJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071068
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P7232, DOI 10.1109/TGRS.2019.2912468
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yuxiang Zhang, 2021, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V59, P9646, DOI 10.1109/TGRS.2020.3046756
   Zhan Y, 2018, IEEE GEOSCI REMOTE S, V15, P212, DOI 10.1109/LGRS.2017.2780890
   Zhang CJ, 2019, IEEE T GEOSCI REMOTE, V57, P9201, DOI 10.1109/TGRS.2019.2925615
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhou F, 2019, NEUROCOMPUTING, V328, P39, DOI 10.1016/j.neucom.2018.02.105
   Zhu MH, 2021, IEEE T GEOSCI REMOTE, V59, P449, DOI 10.1109/TGRS.2020.2994057
   Zoran Daniel, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP9480, DOI 10.1109/CVPR42600.2020.00950
NR 61
TC 2
Z9 2
U1 7
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10226
EP 10241
DI 10.1109/JSTARS.2021.3115129
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WJ5GX
UT WOS:000709074200006
DA 2023-04-26
ER

PT J
AU Cui, XD
   Yang, FL
   Wang, X
   Ai, B
   Luo, Y
   Ma, D
AF Cui, Xiaodong
   Yang, Fanlin
   Wang, Xin
   Ai, Bo
   Luo, Yu
   Ma, Dan
TI Deep learning model for seabed sediment classification based on fuzzy ranking feature optimization
SO MARINE GEOLOGY
LA English
DT Article
DE Seabed sediment classification; Multibeam echo-sounding system; Feature selection; Deep belief network; Supervised classification
ID multibeam acoustic data; scale; shelf; identification; backscatter; bathymetry; curves
AB Accurate acquisition of information on seabed sediment distributions plays an important role in the construction of basic marine geographic databases. Although a multibeam echo-sounding system (MBES) can satisfy large-scale seafloor mapping with high precision and high resolution, the development of a consistent, stable, repeatable and validated seabed sediment classification method based on swath acoustic data is still in its infancy. To achieve accurate prediction and mapping of geographic seabed sediment information, this paper developed a deep learning model based on feature optimization. First, faced with high-dimensional features extracted from multibeam bathymetry and backscatter intensity measurement data, a fuzzy ranking (FR) feature optimization method was proposed. By combining the physical properties of actual sediment samples, the multidimensional features derived from terrain and intensity data are ranked and optimally selected according to the mean square error to eliminate redundant and irrelevant features. Second, the deep belief network (DBN) deep learning method was used to build a supervised seabed sediment classification model. The optimized features and actual sediment samples participate in model training, which further enhances the prediction ability of acoustic data to seabed sediments. Finally, to evaluate the performance of the DBN model, this experiment used large-scale multibeam survey data and ground-truth data (acquired by grabbers, core samplers, dredges, etc.) in the southern Irish Sea to achieve accurate prediction of 10 sediment types (slightly gravelly muddy sand, slightly gravelly sand, gravelly mud, gravelly muddy sand, gravelly sand, muddy sand, muddy sandy gravel, sand, sandy gravel and sandy mud). The experiment results show that by using the optimal feature combination based on FR, the overall classification accuracy and Kappa coefficient reached 86.20% and 0.834, respectively, which are significantly improved compared to the evaluation metrics of other feature selection methods. In addition, compared with the current five typical supervised classification methods (i.e., the random forests, BP neural network, support vector machine, maximum likelihood and decision trees methods), the proposed DBN classification model achieves a better performance, highlighting its application potential in seabed sediment detection and mapping.
C1 [Cui, Xiaodong; Yang, Fanlin; Ai, Bo; Luo, Yu] Shandong Univ Sci & Technol, Coll Geodesy & Geomat, Qingdao 266590, Peoples R China.
   [Yang, Fanlin] Minist Nat Resources, Key Lab Surveying & Mapping Technol Isl & Reef, Qingdao 266590, Peoples R China.
   [Wang, Xin] Univ Calgary, Dept Geomat Engn, Calgary, AB T2N 1N4, Canada.
   [Ma, Dan] Natl Marine Data & Informat Serv, Tianjin 300171, Peoples R China.
C3 Shandong University of Science & Technology; Ministry of Natural Resources of the People's Republic of China; University of Calgary; National Marine Data & Information Service
RP Yang, FL (corresponding author), 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
EM flyang@126.com
FU National Natural Science Foundation of China [41930535, 41830540]; National Key R&D Program of China [2018YFF0212203, 2017YFC1405006, 2018YFC1405900, 2016YFC1401210]; SDUST Research Fund [2019TDJH103]
CR AITCHISON J, 1982, J ROY STAT SOC B, V44, P139
   [Anonymous], 1976, INT J NUMER METHODS, V0, P0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Blondel P, 2009, APPL ACOUST, V70, P1288, DOI 10.1016/j.apacoust.2008.07.015
   Boswarva K, 2018, CONT SHELF RES, V168, P39, DOI 10.1016/j.csr.2018.09.005
   British Geological Survey, 2012, OPENGEOSCIENCE OFFSH, V0, P0
   Brown CJ, 2002, ESTUAR COAST SHELF S, V54, P263, DOI 10.1006/ecss.2001.0841
   Brown CJ, 2011, ESTUAR COAST SHELF S, V92, P502, DOI 10.1016/j.ecss.2011.02.007
   Brown CJ, 2009, APPL ACOUST, V70, P1242, DOI 10.1016/j.apacoust.2008.08.004
   Buhl-Mortensen P, 2009, ICES J MAR SCI, V66, P2026, DOI 10.1093/icesjms/fsp200
   CHE HR, 2012, REMOTE SENS, V4, P3427
   Clarke JEH, 1996, MAR GEOPHYS RES, V18, P607, DOI 10.1007/BF00313877
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cui XD, 2020, APPL ACOUST, V157, P0, DOI 10.1016/j.apacoust.2019.107029
   De Leo Fabio C, 2010, PROC BIOL SCI, V277, P2783, DOI 10.1098/rspb.2010.0462
   Demarchi L, 2014, ISPRS J PHOTOGRAMM, V87, P166, DOI 10.1016/j.isprsjprs.2013.10.012
   Diesing M, 2016, ICES J MAR SCI, V73, P2425, DOI 10.1093/icesjms/fsw118
   Diesing M, 2014, CONT SHELF RES, V84, P107, DOI 10.1016/j.csr.2014.05.004
   Elvenes S, 2014, ICES J MAR SCI, V71, P867, DOI 10.1093/icesjms/fst154
   Evans, 1995, TECHNICAL REPORT, V0, P0
   FOLK RL, 1970, NEW ZEAL J GEOL GEOP, V13, P937, DOI 10.1080/00288306.1970.10418211
   Glynn B, 2008, J GEOL SOC LONDON, V165, P597, DOI 10.1144/0016-76492006-186
   Guichard F, 1998, MAR ECOL PROG SER, V171, P59, DOI 10.3354/meps171059
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hosack GR, 2006, ESTUAR COAST, V29, P1150, DOI 10.1007/BF02781816
   Huang Z, 2012, INT J GEOGR INF SCI, V26, P283, DOI 10.1080/13658816.2011.590139
   Huang Z, 2011, CONT SHELF RES, V31, PS4, DOI 10.1016/j.csr.2010.03.012
   ICES, 2007, ICES COOP RES REP, V0, P1
   Ierodiaconou D, 2011, CONT SHELF RES, V31, PS28, DOI 10.1016/j.csr.2010.01.012
   Jensen H, 2005, TLS-TIMES LIT SUPPL, V0, P3
   Jianwei Qin, 2008, SENSING AND INSTRUMENTATION FOR FOOD QUALITY AND SAFETY, V2, P168, DOI 10.1007/s11694-008-9043-3
   Jordi A, 2005, PROG OCEANOGR, V66, P120, DOI 10.1016/j.pocean.2004.07.009
   Lanier A, 2007, MAR GEOD, V30, P51, DOI 10.1080/01490410701296143
   Lin YH, 1998, IEEE T SYST MAN CY A, V28, P678, DOI 10.1109/3468.709615
   Lin YH, 1996, FUZZY SET SYST, V82, P65, DOI 10.1016/0165-0114(95)00223-5
   Lucieer V, 2013, ESTUAR COAST SHELF S, V117, P94, DOI 10.1016/j.ecss.2012.11.001
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Marsh I, 2009, APPL ACOUST, V70, P1269, DOI 10.1016/j.apacoust.2008.07.012
   Max, 2013, R PACKAGE VERSION 5, V0, P0
   McGonigle C, 2014, ESTUAR COAST SHELF S, V147, P123, DOI 10.1016/j.ecss.2014.05.025
   McGonigle C, 2011, ESTUAR COAST SHELF S, V91, P87, DOI 10.1016/j.ecss.2010.10.016
   Michaels William, 2007, ACOUSTIC SEABED CLAS, V0, P0
   Robinson KA, 2012, ELSEV INSIGHT, V0, PP523, DOI 10.1016/B978-0-12-385140-6.00037-2
   Simons DG, 2009, APPL ACOUST, V70, P1258, DOI 10.1016/j.apacoust.2008.07.013
   SIMPSON JH, 1981, DEEP-SEA RES, V28, P727, DOI 10.1016/0198-0149(81)90132-1
   Stephens D, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0142502
   Su DP, 2019, IEEE T GEOSCI REMOTE, V57, P815, DOI 10.1109/TGRS.2018.2860931
   Wang BJ, 2013, COMPUT GEOSCI-UK, V57, P1, DOI 10.1016/j.cageo.2013.03.016
   Webb J., 2011, ENCY MACHINE LEARNIN, V0, PP267, DOI 10.1007/978-0-387-30164-8
   Wulsin DF, 2011, J NEURAL ENG, V8, P0, DOI 10.1088/1741-2560/8/3/036015
   Zajac RN, 2020, SEAFLOOR GEOMORPHOLOGY AS BENTHIC HABITAT: GEOHAB ATLAS OF SEAFLOOR GEOMORPHIC FEATURES AND BENTHIC HABITATS, V0, P199, DOI 10.1016/B978-0-12-814960-7.00010-5
   Zhi H, 2014, MAR GEOL, V357, P37, DOI 10.1016/j.margeo.2014.07.012
NR 52
TC 10
Z9 11
U1 4
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0025-3227
EI 1872-6151
J9 MAR GEOL
JI Mar. Geol.
PD FEB 15
PY 2021
VL 432
IS 
BP 
EP 
DI 10.1016/j.margeo.2020.106390
PG 14
WC Geosciences, Multidisciplinary; Oceanography
SC Geology; Oceanography
GA PS7YD
UT WOS:000608140700003
DA 2023-04-26
ER

PT J
AU Zang, AD
   Zhu, XF
   Guo, YX
   Zhou, F
   Trajcevski, G
AF Zang, Andi
   Zhu, Xiaofeng
   Guo, Yuxiang
   Zhou, Fan
   Trajcevski, Goce
TI Towards Predicting Vehicular Data Consumption
SO 2021 22ND IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2021)
LA English
DT Proceedings Paper
DE High Definition Maps; Data Consumption
ID time
AB Combining in-car multiple sensors measuring parameters that can be used to improve both safety and efficiency with a plethora of external data sources (e.g., traffic conditions, weather) which, if properly used, can significantly improve the overall trip experience. One source that can help the navigation and provide "context awareness", especially for autonomous driving, are the High Definition (HD) maps, which have recently witnessed a tremendous growth of popularity in vehicular technology and use. As they are limited to a particular geographic area with respect to a given point along a trip, different portions need to be downloaded (and processed) on multiple occasions throughout a given trip, along with the other data from internal and external sources. We take a first step towards formalizing the problem of Predicting Map Data Consumption (PMDC) in the future time instants for a given trip, based on a (time) window from its history, and investigate the use of Long Short-Term Memory (LSTM) networks - a special type of Recurrent Neural Networks (RNN). Significant efforts were focused on generating an appropriate dataset for this study, towards which we fused the information available in multiple heterogeneous data sources. We conducted experimental observations demonstrating the benefits of the proposed approach.
C1 [Zang, Andi; Guo, Yuxiang] Northwestern Univ, Dept Comp Sci, Evanston, IL 60208 USA.
   [Zhu, Xiaofeng] Microsoft, Redmond, WA USA.
   [Zhou, Fan] Univ Elect Sci & Technol, Sch Informat & SW Engn, Chengdu, Peoples R China.
   [Trajcevski, Goce] Iowa State Univ, Dept Elect & Comp Engn, Ames, IA USA.
C3 Northwestern University; Microsoft; University of Electronic Science & Technology of China; Iowa State University
RP Zang, AD (corresponding author), Northwestern Univ, Dept Comp Sci, Evanston, IL 60208 USA.
EM andi.zang@u.northwestern.edu; yuxiangguo2021@u.northwestern.edu; xiaofzhu@microsoft.com; fan.zhou@uestc.edu.cn; gocet25@iastate.edu
FU National Science Foundation grant [SWIFT 2030249]; National Natural Science Foundation of China [62072077]
CR Alahi A, 2016, PROC CVPR IEEE, V0, PP961, DOI 10.1109/CVPR.2016.110
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, V0, P225, DOI 10.1109/RAM.2013.6758588
   [Anonymous], 2016, XIAN CIT 2 RING ROAD, V0, P0
   Bracciale L., 2014, CRAWDAD DATASET ROMA, V0, P0, DOI DOI 10.15783/C7QC7M
   Gaikwad T.D., 2019, VEHICLE VELOCITY P 2, V0, P0
   Gao J, 2018, APPL INTELL, V48, P3523, DOI 10.1007/s10489-018-1163-9
   Gao Q, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1689
   Hartenstein H, 2008, IEEE COMMUN MAG, V46, P164, DOI 10.1109/MCOM.2008.4539481
   Hu QL, 2001, DISTRIB PARALLEL DAT, V9, P151, DOI 10.1023/A:1018944523033
   Kesting A, 2008, COMPUT-AIDED CIV INF, V23, P125, DOI 10.1111/j.1467-8667.2007.00529.x
   Kong DJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2341
   Li Liang., 2016, INT C INT AUT SYST, V0, P0
   Liu K, 2019, PROC INT CONF SOFTW, V0, PP1, DOI 10.1186/s13007-019-0416-x
   Liu R, 2020, J NAVIGATION, V73, P324, DOI 10.1017/S0373463319000638
   Morton Jeremy., 2016, IEEE T INTELL TRANSP, V18, P0
   Rusu RB, 2009, IEEE INT CONF ROBOT, V0, P1848
   Schonberger JL, 2018, PROC CVPR IEEE, V0, PP6896, DOI 10.1109/CVPR.2018.00721
   Seif Heiko G., 1900, V2, V0, P0
   Shcherbakov MV, 2013, WORLD APPL SCI J, V24, P171, DOI 10.5829/idosi.wasj.2013.24.itmies.80032
   Smagulova K, 2019, EUR PHYS J-SPEC TOP, V228, P2313, DOI 10.1140/epjst/e2019-900046-x
   Taxi and Limousine Commission, 2019, NEW YORK CITY TAXI T, V0, P0
   Trajcevski G, 2011, COMPUTING WITH SPATIAL TRAJECTORIES, V0, P63
   Wang D, 2018, 2018 6TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSIC AND SECURITY (ISDFS), V0, P1
   Weiss T, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, V0, P284
   Weng LH, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), V0, PP96, DOI 10.1109/RCAR.2018.8621688
   Xue H, 2018, IEEE WINT CONF APPL, V0, PP1186, DOI 10.1109/WACV.2018.00135
   Yuan J., 2010, PROC 18 SIGSPATIAL I, V0, P99
   Zang A., 2017, P AUTONOMOUSGIS SIGS, V0, P2
   Zang AD, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), V0, PP229, DOI 10.1145/3347146.3359353
   Zhao Pengpeng., 2018, ARXIV180606671, V0, P0
   Zimmermann M, 2020, SOFTWARE QUAL J, V28, P1189, DOI 10.1007/s11219-020-09519-w
NR 31
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1551-6245
EI 
J9 IEEE INT CONF MOB DA
PD JUN 15
PY 2021
VL 0
IS 
BP 109
EP 114
DI 10.1109/MDM52706.2021.00025
PG 6
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA BS3SQ
UT WOS:000714954400013
DA 2023-04-26
ER

PT J
AU Xu, F
   Li, H
   Yao, HG
   An, MS
AF Xu, Fei
   Li, He
   Yao, Hongge
   An, MingShou
TI Detection method of tunnel lining voids based on guided anchoring mechanism
SO COMPUTERS & ELECTRICAL ENGINEERING
LA English
DT Article
DE Tunnel void disease; Neural network; Guide anchoring; GIoU
AB In tunnel construction engineering, the form of tunnel void diseases are complex and easily affected by the geographical environment. The traditional manual interpretation of image data has the characteristics of heavy workload, high probability of missing, and misjudgment. This paper constructs a convolution neural network that integrates the mechanism of guiding anchoring to detect tunnel voids. The network is composed of four parts: Feature extraction network extracts disease features from the enriched samples; Region proposal by guided anchoring join the generalized intersection over union (GIoU) evaluation criteria, and predict the shape of the anchor point through learning; The obtained feature maps are fixed in the region of interest pooling; Finally, the disease features are classified and bounding box regression. Compared with the existing target detection algorithm, the experimental results show that the improved network achieves an average classification accuracy of 92.74%, and the trained model has good generalization ability and robustness.
C1 [Xu, Fei; Li, He; Yao, Hongge; An, MingShou] Xian Technol Univ, Xian, Peoples R China.
   [Xu, Fei; Yao, Hongge; An, MingShou] State & Prov Joint Engn Lab Adv Network Monitorin, Xian, Peoples R China.
C3 Xi'an Technological University
RP Li, H (corresponding author), Xian Technol Univ, Xian, Peoples R China.
EM 1003294436@qq.com
FU Natural Science Project of Shaanxi Education Department [18JK0399]; fund of the State and Provincial Joint Engineering Lab of Advanced Network, Monitoring and Control, China [GSYSJ2018006]; Natural Science Foundation of Shaanxi Provincial Department of Education (CN) [19JK0396]
CR Abu Alhaija H, 2018, INT J COMPUT VISION, V126, P961, DOI 10.1007/s11263-018-1070-x
   Artagan SS, 2020, SURV GEOPHYS, V41, P447, DOI 10.1007/s10712-019-09544-w
   Byeon YH, 2017, 2017 6TH IIAI INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS (IIAI-AAI), V0, PP858, DOI 10.1109/IIAI-AAI.2017.196
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fawzi A, 2016, IEEE IMAGE PROC, V0, PP3688, DOI 10.1109/ICIP.2016.7533048
   Feng Yang, 2020, COMPUTER ENG APPL, V0, P1
   Giannakis I, 2019, IEEE T GEOSCI REMOTE, V57, P4417, DOI 10.1109/TGRS.2019.2891206
   He T, 2019, PROC CVPR IEEE, V0, PP558, DOI 10.1109/CVPR.2019.00065
   Khan RU, 2019, P 2019 2 INT C ALG C, V0, P78
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P1443, DOI 10.1109/TCYB.2020.2970104
   Lemley J, 2017, IEEE ACCESS, V5, P5858, DOI 10.1109/ACCESS.2017.2696121
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Pham MT, 2018, INT GEOSCI REMOTE SE, V0, P6804
   Qi XQ, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON MECHANICAL, V0, P151, DOI 10.1109/ICMCCE.2017.49
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Reichman D, 2017, PROC 9 INT WORKSHOP, V28, P1, DOI 10.1109/IWAGPR.2017.7996100
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, V0, PP658, DOI 10.1109/CVPR.2019.00075
   SimonYan K, 2014, VERY DEEP CONVOLUTIO, V34, P0
   Soldovieri F, 2017, IEEE J-STARS, V10, P562, DOI 10.1109/JSTARS.2016.2543840
   The Professional Standards Compilation Group of People s Republic of China, 2015, JTG H12 2015 TECHN S, V0, P0
   Wang JQ, 2019, PROC CVPR IEEE, V0, PP2960, DOI 10.1109/CVPR.2019.00308
   Xisto L., 2018, APPL COMPUT INFORM, V17, P296, DOI 10.1016/j.aci.2018.10.001
   Yao L, 2016, ROCK SOIL MECH, V37, P3627
   Yong L., 2019, CHINA RAILW SCI, V40, P72
NR 25
TC 1
Z9 1
U1 1
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0045-7906
EI 1879-0755
J9 COMPUT ELECTR ENG
JI Comput. Electr. Eng.
PD OCT 15
PY 2021
VL 95
IS 
BP 
EP 
DI 10.1016/j.compeleceng.2021.107462
EA SEP 2021
PG 16
WC Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WA1NU
UT WOS:000702661400010
DA 2023-04-26
ER

PT J
AU Lu, YJ
   Zhang, Z
   Shangguan, DH
   Yang, JH
AF Lu, Yijie
   Zhang, Zhen
   Shangguan, Donghui
   Yang, Junhua
TI Novel Machine Learning Method Integrating Ensemble Learning and Deep Learning for Mapping Debris-Covered Glaciers
SO REMOTE SENSING
LA English
DT Article
DE random forest; convolutional neural network; debris-covered glacier; Eastern Pamir; Nyainqentanglha; glacier mapping
ID convolutional neural-network; random forest; tibetan plateau; eastern pamir; classification; basin; images; model; inventory; accuracy
AB Glaciers in High Mountain Asia (HMA) have a significant impact on human activity. Thus, a detailed and up-to-date inventory of glaciers is crucial, along with monitoring them regularly. The identification of debris-covered glaciers is a fundamental and yet challenging component of research into glacier change and water resources, but it is limited by spectral similarities with surrounding bedrock, snow-affected areas, and mountain-shadowed areas, along with issues related to manual discrimination. Therefore, to use fewer human, material, and financial resources, it is necessary to develop better methods to determine the boundaries of debris-covered glaciers. This study focused on debris-covered glacier mapping using a combination of related technologies such as random forest (RF) and convolutional neural network (CNN) models. The models were tested on Landsat 8 Operational Land Imager (OLI)/Thermal Infrared Sensor (TIRS) data and the Advanced Spaceborne Thermal Emission and Reflection Radiometer Global Digital Elevation Model (ASTER GDEM), selecting Eastern Pamir and Nyainqentanglha as typical glacier areas on the Tibetan Plateau to construct a glacier classification system. The performances of different classifiers were compared, the different classifier construction strategies were optimized, and multiple single-classifier outputs were obtained with slight differences. Using the relationship between the surface area covered by debris and the machine learning model parameters, it was found that the debris coverage directly determined the performance of the machine learning model and mitigated the issues affecting the detection of active and inactive debris-covered glaciers. Various classification models were integrated to ascertain the best model for the classification of glaciers.
C1 [Lu, Yijie; Zhang, Zhen] Anhui Univ Sci & Technol, Sch Geomat, Huainan 232001, Peoples R China.
   [Lu, Yijie; Zhang, Zhen; Shangguan, Donghui; Yang, Junhua] Chinese Acad Sci, Northwest Inst Ecoenvironm & Resources, State Key Lab Cryospher Sci, Lanzhou 730000, Peoples R China.
C3 Anhui University of Science & Technology; Chinese Academy of Sciences
RP Zhang, Z (corresponding author), Anhui Univ Sci & Technol, Sch Geomat, Huainan 232001, Peoples R China.; Zhang, Z (corresponding author), Chinese Acad Sci, Northwest Inst Ecoenvironm & Resources, State Key Lab Cryospher Sci, Lanzhou 730000, Peoples R China.
EM 2019200937@aust.edu.cn; zhangzhen@aust.edu.cn; dhguan@lzb.ac.cn; yangjunhua@lzb.ac.cn
FU National Natural Science Foundation of China [42071085]; Open Project of the State Key Laboratory of Cryospheric Science; SKLCS [2020-10]; National Nature Science Foundation of China [41701087]
CR Abdollahi A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091444
   Alifu H, 2020, GEOMORPHOLOGY, V369, P0, DOI 10.1016/j.geomorph.2020.107365
   Alpaydin E., 2020, INTRO MACHINE LEARNI, V0, P0
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bera S, 2020, INT J REMOTE SENS, V41, P2664, DOI 10.1080/01431161.2019.1694725
   Biddle D., 2015, THESIS U LOUISVILLE, V0, P0
   Blothe JH, 2021, EARTH SURF PROC LAND, V46, P504, DOI 10.1002/esp.5042
   Bolch T, 2010, CRYOSPHERE, V4, P419, DOI 10.5194/tc-4-419-2010
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brun F, 2019, J GEOPHYS RES-EARTH, V124, P1331, DOI 10.1029/2018JF004838
   Buchroithner M.F., 2006, P 9 INT S HIGH MOUNT, V0, P0
   Cohen J., 2003, APPL MULTIPLE REGRES, V0, P0
   Congalton R.G., 2019, ASSESSING ACCURACY R, V0, P0
   Cordeiro MCR, 2021, REMOTE SENS ENVIRON, V253, P0, DOI 10.1016/j.rse.2020.112209
   DEFRIES RS, 1994, INT J REMOTE SENS, V15, P3567, DOI 10.1080/01431169408954345
   Dirscherl M, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13020197
   Fleischer F, 2021, EARTH SURF PROC LAND, V46, P1673, DOI 10.1002/esp.5065
   [耿艳磊 Geng Yanlei], 2020, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V49, P499
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hoekstra M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091425
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12183053
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101667
   Huang C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071163
   Huang L, 2021, REMOTE SENS ENVIRON, V258, P0, DOI 10.1016/j.rse.2021.112376
   Huo D, 2021, WATER-SUI, V13, P0, DOI 10.3390/w13010101
   Immerzeel WW, 2020, NATURE, V577, P364, DOI 10.1038/s41586-019-1822-y
   Immerzeel WW, 2010, SCIENCE, V328, P1382, DOI 10.1126/science.1183188
   Kaplan NH, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES (RAST), V0, P447
   Khan AA, 2020, IEEE ACCESS, V8, P12725, DOI 10.1109/ACCESS.2020.2965768
   Leprince S, 2007, INT GEOSCI REMOTE SE, V0, PP1943, DOI 10.1109/IGARSS.2007.4423207
   Li WS, 2021, INT J REMOTE SENS, V42, P1973, DOI 10.1080/01431161.2020.1809742
   Liang L, 2020, IEEE J-STARS, V13, P1494, DOI 10.1109/JSTARS.2020.2984608
   Liu SY, 2020, SCI COLD ARID REG, V12, P343, DOI 10.3724/SP.J.1226.2020.00343
   [刘时银 Liu Shiyin], 2015, 地理学报 ACTA GEOGRAPHICA SINICA, V70, P3
   Liu W, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010056
   Lu YJ, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12113231
   Lv XW, 2019, INT J REMOTE SENS, V40, P506, DOI 10.1080/01431161.2018.1513666
   Marochov M., 2020, CRYOSPHERE DISCUSS, V0, PP1, DOI 10.5194/tc-2020-310
   Martins VS, 2020, ISPRS J PHOTOGRAMM, V168, P56, DOI 10.1016/j.isprsjprs.2020.08.004
   Miles KE, 2020, EARTH-SCI REV, V207, P0, DOI 10.1016/j.earscirev.2020.103212
   Mohajerani Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010074
   Mohammadimanesh F, 2019, ISPRS J PHOTOGRAMM, V151, P223, DOI 10.1016/j.isprsjprs.2019.03.015
   Nagapawan Y.V.R., 2021, EAI SPRINGER INNOVAT, V0, P45
   Nie Y, 2021, NAT REV EARTH ENV, V2, P91, DOI 10.1038/s43017-020-00124-w
   Nijhawan R, 2018, J INDIAN SOC REMOTE, V46, P981, DOI 10.1007/s12524-018-0750-x
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Pandey A, 2021, SCI TOTAL ENVIRON, V779, P0, DOI 10.1016/j.scitotenv.2021.146492
   Paul F, 2013, ANN GLACIOL, V54, P171, DOI 10.3189/2013AoG63A296
   Paul F, 2015, REMOTE SENS ENVIRON, V162, P408, DOI 10.1016/j.rse.2013.07.043
   Petrovska B, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20143906
   Racoviteanu A.E., 2021, CRYOSPHERE DISC, V0, PP1, DOI 10.5194/tc-2020-372
   Regine H., 2019, IPCC SPECIAL REPORT, V0, P0
   Robson BA, 2020, REMOTE SENS ENVIRON, V250, P0, DOI 10.1016/j.rse.2020.112033
   Sakai A, 2015, CRYOSPHERE, V9, P865, DOI 10.5194/tc-9-865-2015
   Scherler D, 2011, NAT GEOSCI, V4, P156, DOI 10.1038/ngeo1068
   Shangguan DH, 2016, J GLACIOL, V62, P944, DOI 10.1017/jog.2016.81
   Singh DK, 2021, SPAT INF RES, V29, P281, DOI 10.1007/s41324-020-00352-8
   Wang G., 2020, P 10 INT C COMP ENG, V0, P409
   Wang J, 2021, IEEE J-STARS, V14, P283, DOI 10.1109/JSTARS.2020.3041859
   Wang L, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030497
   Wang YZ, 2020, CAN J REMOTE SENS, V46, P501, DOI 10.1080/07038992.2020.1805729
   Watson CS, 2018, REMOTE SENS ENVIRON, V217, P414, DOI 10.1016/j.rse.2018.08.020
   Wu KP, 2021, J GLACIOL, V67, P186, DOI 10.1017/jog.2020.98
   Wu KP, 2019, J GLACIOL, V65, P422, DOI 10.1017/jog.2019.20
   Xie FM, 2020, FRONT EARTH SC-SWITZ, V8, P0, DOI 10.3389/feart.2020.00308
   Xie Z., 2019, AGU FALL M, V2019, P0
   Xie ZY, 2020, IEEE ACCESS, V8, P136794, DOI 10.1109/ACCESS.2020.3011587
   Xie ZY, 2020, IEEE ACCESS, V8, P83495, DOI 10.1109/ACCESS.2020.2991187
   Ye QH, 2017, J GLACIOL, V63, P273, DOI 10.1017/jog.2016.137
   Yousuf B, 2020, IEEE J-STARS, V13, P601, DOI 10.1109/JSTARS.2019.2955955
   Zhang JX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040452
   [张鲜鹤 Zhang Xianhe], 2017, 地理学报 ACTA GEOGRAPHICA SINICA, V72, P397
   Zhang Z, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030421
   Zhang Z, 2016, J MT SCI-ENGL, V13, P276, DOI 10.1007/s11629-014-3172-4
   Zhao LY, 2014, GLOBAL PLANET CHANGE, V122, P197, DOI 10.1016/j.gloplacha.2014.08.006
   Zhao QD, 2019, J HYDROL, V573, P60, DOI 10.1016/j.jhydrol.2019.03.043
   Zhao XM, 2019, IEEE GEOSCI REMOTE S, V16, P1145, DOI 10.1109/LGRS.2019.2890996
   Zhong YF, 2020, REMOTE SENS LETT, V11, P515, DOI 10.1080/2150704X.2020.1731768
   Zhou ZH, 2020, J ARID LAND, V12, P357, DOI 10.1007/s40333-020-0061-2
NR 79
TC 14
Z9 14
U1 10
U2 54
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL 15
PY 2021
VL 13
IS 13
BP 
EP 
DI 10.3390/rs13132595
PG 28
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TG3GN
UT WOS:000671296600001
DA 2023-04-26
ER

PT J
AU Shinde, RC
   Durbha, SS
   Potnis, AV
AF Shinde, Rajat C.
   Durbha, Surya S.
   Potnis, Abhishek, V
TI LidarCSNet: A Deep Convolutional Compressive Sensing Reconstruction Framework for 3D Airborne Lidar Point Cloud
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Compressive sensing; Deep learning for point cloud classification; 3D airborne lidar point cloud; Deep network-based optimization; Lidar for forests; Urban environment; Convolutional sparse coding; Ensemble deep learning
ID leaf-area index; inverse problems; forest; segmentation; classification
AB Lidar scanning is a widely used surveying and mapping technique ranging across remote-sensing applications involving topological, and topographical information. Typically, lidar point clouds, unlike images, lack inherent consistent structure and store redundant information thus requiring huge processing time. The Compressive Sensing (CS) framework leverages this property to generate sparse representations and accurately reconstructs the signals from very few linear, non-adaptive measurements. The reconstruction is based on valid assumptions on the following parameters- (1) sampling function governed by sampling ratio for generating samples, and (2) measurement function for sparsely representing the data in a low-dimensional subspace. In our work, we address the following motivating scientific questions- Is it possible to reconstruct dense point cloud data from a few sparse measurements? And, what could be the optimal limit for CS sampling ratio with respect to overall classification metrics? Our work proposes a novel Convolutional Neural Network based deep Compressive Sensing Network (named LidarCSNet) for generating sparse representations using publicly available 3D lidar point clouds of the Philippines. We have performed extensive evaluations for analysing the reconstruction for different sampling ratios {4%, 10%, 25%, 50% and 75%} and we observed that our proposed LidarCSNet reconstructed the 3D lidar point cloud with a maximum PSNR of 54.47 dB for a sampling ratio of 75%. We investigate the efficacy of our novel LidarCSNet framework with 3D airborne lidar point clouds for two domains - forests and urban environment on the basis of Peak Signal to Noise Ratio, Haussdorf distance, Pearson Correlation Coefficient and Kolmogorov-Smirnov Test Statistic as evaluation metrics for 3D reconstruction. The results relevant to forests such as Canopy Height Model and 2D vertical profile are compared with the ground truth to investigate the robustness of the LidarCSNet framework. In the urban environment, we extend our work to propose two novel 3D lidar point cloud classification frameworks, LidarNet and LidarNet++, achieving maximum classification accuracy of 90.6% as compared to other prominent lidar classification frameworks. The improved classification accuracy is attributed to ensemble-based learning on the proposed novel 3D feature stack and justifies the robustness of using our proposed LidarCSNet for near-perfect reconstruction followed by classification. We document our classification results for the original dataset along with the point clouds reconstructed by using LidarCSNet for five different measurement ratios - based on overall accuracy and mean Intersection over Union as evaluation metrics for 3D classification. It is envisaged that our proposed deep network based convolutional sparse coding approach for rapid lidar point cloud processing finds huge potential across vast applications, either as a plug-and-play (reconstruction) framework or as an end-to-end (reconstruction followed by classification) system for scalability.
C1 [Shinde, Rajat C.; Durbha, Surya S.; Potnis, Abhishek, V] Indian Inst Technol, Ctr Studies Resources Engn CSRE, Mumbai, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay
RP Shinde, RC (corresponding author), Indian Inst Technol, Ctr Studies Resources Engn CSRE, Mumbai, Maharashtra, India.
EM rajatshinde@iitb.ac.in
FU Prime Minister's Research Fellowship by the Ministry of Education, Government of India
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Adler A, 2017, IEEE INT WORKSH MULT, V0, P0
   Ahmed R, 2013, REMOTE SENS ENVIRON, V130, P121, DOI 10.1016/j.rse.2012.11.015
   Alonzo M, 2015, REMOTE SENS ENVIRON, V162, P141, DOI 10.1016/j.rse.2015.02.025
   An YL, 2020, SYMMETRY-BASEL, V12, P0, DOI 10.3390/sym12050748
   Andaya K.J, 2015, ACRS 2015, V0, P0
   Andersen HE, 2005, REMOTE SENS ENVIRON, V94, P441, DOI 10.1016/j.rse.2004.10.013
   Antonarakis AS, 2008, REMOTE SENS ENVIRON, V112, P2988, DOI 10.1016/j.rse.2008.02.004
   Bater CW, 2011, IEEE T GEOSCI REMOTE, V49, P2385, DOI 10.1109/TGRS.2010.2099232
   Bhangale U, 2017, REMOTE SENS ENVIRON, V202, P28, DOI 10.1016/j.rse.2017.03.024
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Candes E. J., 2008, J FOURIER ANAL APPL, V0, P0
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chen XX, 2019, OPT QUANT ELECTRON, V51, P0, DOI 10.1007/s11082-019-2038-y
   Chen Y, 2020, IEEE T IMAGE PROCESS, V29, P6813, DOI 10.1109/TIP.2020.2994411
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duncanson LI, 2015, REMOTE SENS ENVIRON, V168, P102, DOI 10.1016/j.rse.2015.06.021
   Duncanson L, 2020, REMOTE SENS ENVIRON, V242, P0, DOI 10.1016/j.rse.2020.111779
   Durbha SS, 2007, REMOTE SENS ENVIRON, V107, P348, DOI 10.1016/j.rse.2006.09.031
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Gamba P, 2000, IEEE T GEOSCI REMOTE, V38, P1959, DOI 10.1109/36.851777
   Goodwin NR, 2006, REMOTE SENS ENVIRON, V103, P140, DOI 10.1016/j.rse.2006.03.003
   Graham L, 2012, PHOTOGRAMM ENG REM S, V0, P0
   Gregor K., 2010, PROC 27 INT C INT C, V0, PP399, DOI 10.5555/3104322.3104374
   Guan HY, 2015, REMOTE SENS LETT, V6, P864, DOI 10.1080/2150704X.2015.1088668
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Holmgren J, 2004, REMOTE SENS ENVIRON, V90, P415, DOI 10.1016/S0034-4257(03)00140-8
   Hyyppa J, 2001, IEEE T GEOSCI REMOTE, V39, P969, DOI 10.1109/36.921414
   Iliadis M, 2018, DIGIT SIGNAL PROCESS, V72, P9, DOI 10.1016/j.dsp.2017.09.010
   Jiang Mingyang, 2018, ABS180700652 CORR, V0, P0
   Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099
   Klasing K, 2009, IEEE INT CONF ROBOT, V0, P2011
   Kulkarni K, 2016, PROC CVPR IEEE, V0, PP449, DOI 10.1109/CVPR.2016.55
   Kutynoik G., 2013, GAMM MITTEILUNGEN, V36, P79, DOI 10.1002/GAMM.201310005
   Laurin GV, 2014, ISPRS J PHOTOGRAMM, V89, P49, DOI 10.1016/j.isprsjprs.2014.01.001
   Li ST, 2013, IEEE T GEOSCI REMOTE, V51, P4779, DOI 10.1109/TGRS.2012.2230332
   Li Y, 2020, IEEE T GEOSCI REMOTE, V58, P3588, DOI 10.1109/TGRS.2019.2958517
   Lian Y, 2019, INT GEOSC REM SENS S, V0, P0, DOI DOI 10.1109/IGARSS.2019.8898177
   Lovell JL, 2003, CAN J REMOTE SENS, V29, P607, DOI 10.5589/m03-026
   Lu X., 2018, ARXIV180110342, V0, P0
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Miura N, 2010, REMOTE SENS ENVIRON, V114, P1069, DOI 10.1016/j.rse.2009.12.017
   Mousavi A, 2017, INT CONF ACOUST SPEE, V0, PP2272, DOI 10.1109/ICASSP.2017.7952561
   Mousavi A, 2015, ANN ALLERTON CONF, V0, PP1336, DOI 10.1109/ALLERTON.2015.7447163
   Mun S, 2009, IEEE IMAGE PROC, V0, PP3021, DOI 10.1109/ICIP.2009.5414429
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Nurunnabi A, 2016, IEEE T GEOSCI REMOTE, V54, P4790, DOI 10.1109/TGRS.2016.2551546
   Pan B, 2017, IEEE T GEOSCI REMOTE, V55, P4177, DOI 10.1109/TGRS.2017.2689805
   Papyan V, 2017, J MACH LEARN RES, V18, P1
   Potapov P, 2021, REMOTE SENS ENVIRON, V253, P0, DOI 10.1016/j.rse.2020.112165
   Qi CR, 2017, PROC CVPR IEEE, V0, PP77, DOI 10.1109/CVPR.2017.16
   Qi Charles Ruizhongtai, 2017, POINTNET DEEP HIERAR, V0, P5099
   Chen Q, 2006, PHOTOGRAMM ENG REM S, V72, P923, DOI 10.14358/PERS.72.8.923
   Qi HC, 2012, IEEE IMAGE PROC, V0, PP937, DOI 10.1109/ICIP.2012.6467015
   Riegler G, 2016, LECT NOTES COMPUT SC, V9907, P268, DOI 10.1007/978-3-319-46487-9_17
   Roussel J.R, 2018, REMOTE SENS ENVIRON, V0, P0
   Ruohomaki T, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), V0, PP155, DOI 10.1109/IS.2018.8710517
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Schwenker F., 2013, IEEE COMPUT INTELL M, V8, P77
   Shinde R.C, 2019, COMPRESSIVE SENSING, V0, P0
   Silva CA, 2021, REMOTE SENS ENVIRON, V253, P0, DOI 10.1016/j.rse.2020.112234
   Sulam J, 2016, IEEE T SIGNAL PROCES, V64, P3180, DOI 10.1109/TSP.2016.2540599
   Tchapmi LP, 2017, INT CONF 3D VISION, V0, PP537, DOI 10.1109/3DV.2017.00067
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang AL, 2018, IEEE GEOSCI REMOTE S, V15, P774, DOI 10.1109/LGRS.2018.2810276
   Wang L, 2009, C P IEEE INT C SYST, V0, P0, DOI DOI 10.1109/ICSMC.2009.5345938
   Wang S., 2016, P 30 ANN C NEURAL IN, V0, P865
   Wang YJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131540
   Wu WX, 2019, PROC CVPR IEEE, V0, PP9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, V0, PP1912, DOI 10.1109/CVPR.2015.7298801
   Xin B, 2016, ADV NEUR IN, V29, P0
   Yan WY, 2015, REMOTE SENS ENVIRON, V158, P295, DOI 10.1016/j.rse.2014.11.001
   Yu YT, 2015, IEEE J-STARS, V8, P709, DOI 10.1109/JSTARS.2014.2347276
   Zhang J, 2018, PROC CVPR IEEE, V0, PP1828, DOI 10.1109/CVPR.2018.00196
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 77
TC 6
Z9 6
U1 3
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD OCT 15
PY 2021
VL 180
IS 
BP 313
EP 334
DI 10.1016/j.isprsjprs.2021.08.019
EA SEP 2021
PG 22
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA US0ZU
UT WOS:000697167200021
DA 2023-04-26
ER

PT J
AU Konapala, G
   Kumar, SV
   Ahmad, SK
AF Konapala, Goutam
   Kumar, Sujay, V
   Ahmad, Shahryar Khalique
TI Exploring Sentinel-1 and Sentinel-2 diversity for flood inundation mapping using deep learning
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Flood inundation mapping; Deep learning; Segmentation; Hydrology
ID water index ndwi; surface-water; time-series; sar; resolution; satellite; dem; delineation; imagery; areas
AB Identification of flood water extent from satellite images has historically relied on either synthetic aperture radar (SAR) or multi-spectral (MS) imagery. MS sensors are limited to cloud free conditions, whereas SAR imagery is plagued by noise-like speckle. Prior studies that use combinations of MS and SAR data to overcome individual limitations of these sensors have not fully examined sensitivity of flood mapping performance to different combinations of SAR and MS derived spectral indices or band transformations in color space. This study explores the use of diverse bands of Sentinel 2 (S2) through well-established water indices and Sentinel 1 (S1) derived SAR imagery along with their combinations to assess their capability for generating accurate flood inundation maps. The robustness in performance of S-1 and S-2 band combinations was evaluated using 446 hand labeled flood inundation images spanning across 11 flood events from Sen1Floods11 dataset which are highly diverse in terms of land cover as well as location. A modified K-fold cross validation approach is used to evaluate the performance of 32 combinations of S1 and S2 bands using a fully connected deep convolutional neural network known as U-Net. Our results indicated that usage of elevation information has improved the capability of S1 imagery to produce more accurate flood inundation maps. Compared to a median F1 score of 0.62 when using only S1 bands, the combined use of S1 and elevation information led to an improved median F1 score of 0.73. Water extraction indices based on S2 bands have a statistically significant superior performance in comparison to S1. Among all the band combinations, HSV (Hue, Saturation, Value) transformation of S2 bands provides a median F1 score of 0.9, outperforming the commonly used water spectral indices owing to HSV's transformation's superior contrast distinguishing abilities. Additionally, U-Net algorithm was able to learn the relationship between raw S2 based water extraction indices and their corresponding raw S2 bands, but not of HSV owing to relatively complex computation involved in the latter. Results of the paper establishes important benchmarks for the extension of S1 and S2 data-based flood inundation mapping efforts over large spatial extents.
C1 [Konapala, Goutam; Kumar, Sujay, V; Ahmad, Shahryar Khalique] NASA, Hydrol Sci Lab, Goddard Space Flight Ctr, Greenbelt, MD 20771 USA.
   [Konapala, Goutam] Univ Space Res Assoc, Greenbelt, MD USA.
   [Ahmad, Shahryar Khalique] Sci Applicat Int Corp, Greenbelt, MD USA.
C3 National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center; Universities Space Research Association (USRA); Science Applications International Corporation (SAIC)
RP Konapala, G (corresponding author), NASA, Hydrol Sci Lab, Goddard Space Flight Ctr, Greenbelt, MD 20771 USA.
EM goutam.konapala@nasa.gov
FU NASA Earth Science Technology Office
CR BARTON IJ, 1989, REMOTE SENS ENVIRON, V30, P89, DOI 10.1016/0034-4257(89)90050-3
   Betbeder J, 2014, J APPL REMOTE SENS, V8, P0, DOI 10.1117/1.JRS.8.083648
   Binh PD, 2017, WATER-SUI, V9, P0, DOI 10.3390/w9060366
   Bioresita F, 2019, INT J REMOTE SENS, V40, P9026, DOI 10.1080/01431161.2019.1624869
   Bonafilia D, 2020, IEEE COMPUT SOC CONF, V0, PP835, DOI 10.1109/CVPRW50498.2020.00113
   Boschetti M, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0088741
   Clement MA, 2018, J FLOOD RISK MANAG, V11, P152, DOI 10.1111/jfr3.12303
   Colson D, 2018, INT J APPL EARTH OBS, V73, P262, DOI 10.1016/j.jag.2018.06.011
   DeVries B, 2020, REMOTE SENS ENVIRON, V240, P0, DOI 10.1016/j.rse.2020.111664
   Du GT, 2020, J IMAGING SCI TECHN, V64, P0, DOI 10.2352/J.ImagingSci.Technol.2020.64.2.020508
   Dusseux P, 2014, REMOTE SENS-BASEL, V6, P6163, DOI 10.3390/rs6076163
   Fereshtehpour M, 2018, WATER RESOUR RES, V54, P4965, DOI 10.1029/2017WR022318
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   Gao Q, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17091966
   Gebrehiwot A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071486
   Gevaert CM, 2015, IEEE J-STARS, V8, P3140, DOI 10.1109/JSTARS.2015.2406339
   Goffi A, 2020, INT J APPL EARTH OBS, V84, P0, DOI 10.1016/j.jag.2019.101951
   Haile A.T., 2005, P ISPRS WG III3 III4, VVolume 3, P12
   Huang C, 2018, REV GEOPHYS, V56, P333, DOI 10.1029/2018RG000598
   Iannelli GC, 2018, INT GEOSCI REMOTE SE, V0, P8209
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   Irwin K, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090890
   Jain P, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC20), V0, PP617, DOI 10.1145/3341105.3374023
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   King DB, 2015, ACS SYM SER, V1214, P1
   Klein I, 2017, REMOTE SENS ENVIRON, V198, P345, DOI 10.1016/j.rse.2017.06.045
   Li SM, 2013, INT J REMOTE SENS, V34, P5487, DOI 10.1080/01431161.2013.792969
   Li YQ, 2018, IMMS 2019: 2019 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND MANAGEMENT SCIENCES, V0, PP123, DOI 10.1145/3357292.3357320
   Liang JY, 2020, ISPRS J PHOTOGRAMM, V159, P53, DOI 10.1016/j.isprsjprs.2019.10.017
   Manakos I, 2020, EUR J REMOTE SENS, V53, P53, DOI 10.1080/22797254.2019.1596757
   Manfreda S, 2015, NAT HAZARDS, V79, P735, DOI 10.1007/s11069-015-1869-5
   Martinis S, 2013, REMOTE SENS-BASEL, V5, P5598, DOI 10.3390/rs5115598
   Mason DC, 2014, INT J APPL EARTH OBS, V28, P150, DOI 10.1016/j.jag.2013.12.002
   Mateo-Garcia G, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-86650-z
   Matgen P, 2007, INT J APPL EARTH OBS, V9, P247, DOI 10.1016/j.jag.2006.03.003
   Matgen P, 2011, PHYS CHEM EARTH, V36, P241, DOI 10.1016/j.pce.2010.12.009
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   McNairn H, 2009, ISPRS J PHOTOGRAMM, V64, P434, DOI 10.1016/j.isprsjprs.2008.07.006
   Mosavi A, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10111536
   Musa ZN, 2015, HYDROL EARTH SYST SC, V19, P3755, DOI 10.5194/hess-19-3755-2015
   Nemni E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162532
   Oberstadler R, 1997, HYDROL PROCESS, V11, P1415, DOI 10.1002/(SICI)1099-1085(199708)11:10&lt;1415::AID-HYP532&gt;3.0.CO;2-2
   Pekel JF, 2014, REMOTE SENS ENVIRON, V140, P704, DOI 10.1016/j.rse.2013.10.008
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Peng B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212492
   Potnis AV, 2019, INT GEOSCI REMOTE SE, V0, PP9741, DOI 10.1109/IGARSS.2019.8900250
   Rajah P., 2018, REMOTE SENS APPL SOC, V10, P198, DOI 10.1016/J.RSASE.2018.04.007
   Rambour C., 2020, INT ARCH PHOTOGRAMM, V0, PP1343, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2020-1343
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saksena S, 2015, J HYDROL, V530, P180, DOI 10.1016/j.jhydrol.2015.09.069
   Samela C, 2016, J HYDROL ENG, V21, P0, DOI 10.1061/(ASCE)HE.1943-5584.0001272
   Schmitt M, 2020, PFG-J PHOTOGRAMM REM, V88, P271, DOI 10.1007/s41064-020-00111-2
   Schratz P, 2019, ECOL MODEL, V406, P109, DOI 10.1016/j.ecolmodel.2019.06.002
   Shen XY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070879
   Shen XY, 2019, REMOTE SENS ENVIRON, V221, P302, DOI 10.1016/j.rse.2018.11.008
   Slagter B, 2020, INT J APPL EARTH OBS, V86, P0, DOI 10.1016/j.jag.2019.102009
   Smith, 1978, COMPUTER GRAPHICS, V12, P12, DOI 10.1145/965139.807361
   Soergel U, 2003, 2ND GRSS/ISPRS JOINT WORKSHOP ON REMOTE SENSING AND DATA FUSION OVER URBAN AREAS, V0, PP120, DOI 10.1109/DFUA.2003.1219970
   Twele A, 2016, INT J REMOTE SENS, V37, P2990, DOI 10.1080/01431161.2016.1192304
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Yang LP, 2011, INT J REMOTE SENS, V32, P3875, DOI 10.1080/01431161003786016
   Zheng X, 2018, WATER RESOUR RES, V54, P10013, DOI 10.1029/2018WR023457
NR 62
TC 18
Z9 18
U1 11
U2 54
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD OCT 15
PY 2021
VL 180
IS 
BP 163
EP 173
DI 10.1016/j.isprsjprs.2021.08.016
EA AUG 2021
PG 11
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA US0ZU
UT WOS:000697167200011
DA 2023-04-26
ER

PT J
AU Zamboni, P
   Junior, JM
   Silva, JD
   Miyoshi, GT
   Matsubara, ET
   Nogueira, K
   Goncalves, WN
AF Zamboni, Pedro
   Junior, Jose Marcato
   Silva, Jonathan de Andrade
   Miyoshi, Gabriela Takahashi
   Matsubara, Edson Takashi
   Nogueira, Keiller
   Goncalves, Wesley Nunes
TI Benchmarking Anchor-Based and Anchor-Free State-of-the-Art Deep Learning Methods for Individual Tree Detection in RGB High-Resolution Images
SO REMOTE SENSING
LA English
DT Article
DE object detection; convolutional neural network; remote sensing
AB Urban forests contribute to maintaining livability and increase the resilience of cities in the face of population growth and climate change. Information about the geographical distribution of individual trees is essential for the proper management of these systems. RGB high-resolution aerial images have emerged as a cheap and efficient source of data, although detecting and mapping single trees in an urban environment is a challenging task. Thus, we propose the evaluation of novel methods for single tree crown detection, as most of these methods have not been investigated in remote sensing applications. A total of 21 methods were investigated, including anchor-based (one and two-stage) and anchor-free state-of-the-art deep-learning methods. We used two orthoimages divided into 220 non-overlapping patches of 512 x 512 pixels with a ground sample distance (GSD) of 10 cm. The orthoimages were manually annotated, and 3382 single tree crowns were identified as the ground-truth. Our findings show that the anchor-free detectors achieved the best average performance with an AP50 of 0.686. We observed that the two-stage anchor-based and anchor-free methods showed better performance for this task, emphasizing the FSAF, Double Heads, CARAFE, ATSS, and FoveaBox models. RetinaNet, which is currently commonly applied in remote sensing, did not show satisfactory performance, and Faster R-CNN had lower results than the best methods but with no statistically significant difference. Our findings contribute to a better understanding of the performance of novel deep-learning methods in remote sensing applications and could be used as an indicator of the most suitable methods in such applications.
C1 [Zamboni, Pedro; Junior, Jose Marcato; Goncalves, Wesley Nunes] Univ Fed Mato Grosso do Sul, Fac Engn Architecture & Urbanism & Geog, BR-79070900 Campo Grande, MS, Brazil.
   [Silva, Jonathan de Andrade; Matsubara, Edson Takashi; Goncalves, Wesley Nunes] Univ Fed Mato Grosso do Sul, Fac Comp Sci, BR-79070900 Campo Grande, MS, Brazil.
   [Miyoshi, Gabriela Takahashi] Sao Paulo State Univ UNESP, Dept Cartog, BR-19060900 Presidente Prudente, Brazil.
   [Nogueira, Keiller] Univ Stirling, Fac Nat Sci, Comp Sci & Math Div, Stirling FK9 4LA, Scotland.
C3 Universidade Federal de Mato Grosso do Sul; Universidade Federal de Mato Grosso do Sul; Universidade Estadual Paulista; University of Stirling
RP Zamboni, P (corresponding author), Univ Fed Mato Grosso do Sul, Fac Engn Architecture & Urbanism & Geog, BR-79070900 Campo Grande, MS, Brazil.
EM pedro.zamboni@ufms.br; jose.marcato@ufms.br; jonathan.andrade@ufms.br; gabriela.t.miyoshi@unesp.br; edsontm@facom.ufms.br; keiller.nogueira@stir.ac.uk; wesley.goncalves@ufms.br
FU CNPq [p: 433783/2018-4, 303559/2019-5, 304052/2019-1]; CAPES Print [p: 88881.311850/2018-01]; Fundect [59/300.066/2015]
CR Abass K, 2020, INT J DISAST RISK RE, V51, P0, DOI 10.1016/j.ijdrr.2020.101915
   Ampatzidis Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040410
   [Anonymous], 2010, CAMPO GRANDE URBAN A, V0, P0
   Arnpatzidis Y, 2019, COMPUT ELECTRON AGR, V164, P0, DOI 10.1016/j.compag.2019.104900
   Biffi LJ, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010054
   Chen K., 2019, ARXIV190607155, V0, P0
   Chen XX, 2021, FORESTS, V12, P0, DOI 10.3390/f12020131
   Courtrai L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12193152
   CRED and UNISDR, 2015, HUM COST WEATH REL D, V0, P0
   Csillik O, 2018, DRONES-BASEL, V2, P0, DOI 10.3390/drones2040039
   Culman M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213476
   dos Santos AA, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19163595
   Endreny TA, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-03622-0
   Fasihi H, 2020, J ENVIRON MANAGE, V260, P0, DOI 10.1016/j.jenvman.2020.110122
   Fassnacht FE, 2016, REMOTE SENS ENVIRON, V186, P64, DOI 10.1016/j.rse.2016.08.013
   Ghiasi G, 2019, PROC CVPR IEEE, V0, PP7029, DOI 10.1109/CVPR.2019.00720
   Gomes M, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20216070
   Hartling S, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19061284
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Heinz A, 2013, WORLD PSYCHIATRY, V12, P187, DOI 10.1002/wps.20056
   Intergov Panel Clim Chg, 2012, MANAGING THE RISKS OF EXTREME EVENTS AND DISASTERS TO ADVANCE CLIMATE CHANGE ADAPTATION, V0, PP1, DOI 10.1017/CBO9781139177245
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Jiaqi Wang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12349), V0, PP403, DOI 10.1007/978-3-030-58548-8_24
   Kang Kim, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12370), V0, PP355, DOI 10.1007/978-3-030-58595-2_22
   Ke JL, 2021, J CLEAN PROD, V295, P0, DOI 10.1016/j.jclepro.2021.126250
   Khomenko S, 2021, LANCET PLANET HEALTH, V5, PE121, DOI 10.1016/S2542-5196(20)30272-2
   Kong T., 2019, ARXIV190403797, V0, P0
   Li B., 2019, P AAAI C ART INT HON, V0, P0
   Li H, 2020, ENVIRON RES, V191, P0, DOI 10.1016/j.envres.2020.110214
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li WJ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010022
   Li X., 2020, ARXIV200604388, V0, P0
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Torres DL, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20020563
   Lu X., 2020, MIMICDET BRIDGING GA, V0, P0
   Lumnitz S, 2021, ISPRS J PHOTOGRAMM, V175, P144, DOI 10.1016/j.isprsjprs.2021.01.016
   McDonald RI, 2020, NAT SUSTAIN, V3, P16, DOI 10.1038/s41893-019-0436-6
   Micikevicius P., 2017, ARXIV171003740, V0, P0
   Miyoshi GT, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081294
   Nezami S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071070
   Nielsen Anders B., 2014, ARBORICULTURE & URBAN FORESTRY, V40, P96
   Oh S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182981
   Osco LP, 2021, ISPRS J PHOTOGRAMM, V174, P1, DOI 10.1016/j.isprsjprs.2021.01.024
   Padayachee AL, 2017, BIOL INVASIONS, V19, P3557, DOI 10.1007/s10530-017-1596-9
   Plesoianu AI, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152426
   Qiao S., 2021, PROC IEEECVF C COMPU, V0, P10213
   Qiao S., 2019, ARXIV, V0, P0
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Roslan Z., 2020, P 14 INT C UB INF MA, V0, PP1, DOI 10.1109/IMCOM48794.2020.9001817
   Roslan Z, 2021, INT CONF UBIQUIT INF, V0, P0, DOI DOI 10.1109/IMCOM51814.2021.9377360
   Roy S, 2012, URBAN FOR URBAN GREE, V11, P351, DOI 10.1016/j.ufug.2012.06.006
   Santos A, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20164450
   Stocker TF, 2014, CLIMATE CHANGE 2013: THE PHYSICAL SCIENCE BASIS, V0, PP1, DOI 10.1017/cbo9781107415324
   Wagner FH, 2018, ISPRS J PHOTOGRAMM, V145, P362, DOI 10.1016/j.isprsjprs.2018.09.013
   Wang J, 2019, IEEE I CONF COMP VIS, V0, PP8200, DOI 10.1109/ICCV.2019.00829
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111309
   Wu JT, 2020, COMPUT ELECTRON AGR, V174, P0, DOI 10.1016/j.compag.2020.105504
   Wu Y., 2019, AAAI, V0, P0
   Zhang H, 2020, J THERM ANAL CALORIM, V0, P0
   Zhang S., 2019, ARXIV191202424, V0, P0
   Zhu CC, 2019, PROC CVPR IEEE, V0, PP840, DOI 10.1109/CVPR.2019.00093
   Zhu X., 2018, ARXIV181111168, V0, P0
   Zhu XZ, 2019, IEEE I CONF COMP VIS, V0, PP6687, DOI 10.1109/ICCV.2019.00679
NR 65
TC 11
Z9 11
U1 0
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL 15
PY 2021
VL 13
IS 13
BP 
EP 
DI 10.3390/rs13132482
PG 25
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TG0UB
UT WOS:000671127300001
DA 2023-04-26
ER

PT J
AU Shebl, A
   Csamer, A
AF Shebl, Ali
   Csamer, Arpad
TI Stacked vector multi-source lithologic classification utilizing Machine Learning Algorithms: Data potentiality and dimensionality monitoring
SO REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT
LA English
DT Article
DE Lithologic classification; Support vector machine; Artificial neural network; Maximum likelihood classifier; Sentinel 2; Sentinel 1; ASTER
ID eastern desert; gold mineralization; aster; ali; hyperion; identification; kurdistan; imagery; area
AB Machine Learning Algorithms (MLAs) have recently introduced considerable lithologic mapping. Thus, this study scrutinizes the efficacy of Artificial Neural Network (ANN), Maximum Likelihood Classifier (MLC) and Support Vector Machine (SVM) over hybrid datasets including optical (Sentinel 2, ASTER, Landsat OLI and Earth-observing 1 Advanced Land Imager (ALI)), radar (Sentinel 1 and ALOS PALSAR), DEMs and their derivatives (Slope, and Aspect). The study aims to (1) monitor the effect of data dimensionality in enhancing categorization accuracy. (2) disclose the most efficient MLA and most powerful dataset in labeling rock units accurately. (3) highlight the impact of embedding topographical and radar data in lithologic classification. (4) outline the best relation between the number of training pixels and number of utilized bands, in delivering reliable allocation. To achieve these aims, we selected training and testing pixels meticulously, in concordance with a recently published geological map of the study area. We adopted a stacked vector approach for handling the implemented multi-sensor data. Results show that diversifying information sources raised the classification accuracy by approximately 10% for each classifier. SVM and MLC are much better than ANN. Slope is better than aspect and both are less qualified when compared to DEM. Sentinel 1 (C-band) and ALOS PALSAR (L-band) effects are not so different whatever the implemented polarization. Landsat OLI is less qualified in lithologic classification when compared to Sentinel 2, ASTER and ALI. The utilized training pixels should be at least 30N for (N) channels submitted to the classifiers.
C1 [Shebl, Ali; Csamer, Arpad] Univ Debrecen, Dept Mineral & Geol, Debrecen, Hungary.
   [Shebl, Ali] Tanta Univ, Dept Geol, Tanta, Egypt.
C3 University of Debrecen; Egyptian Knowledge Bank (EKB); Tanta University
RP Shebl, A (corresponding author), Univ Debrecen, Dept Mineral & Geol, Debrecen, Hungary.
EM ali.shebl@science.tanta.edu.eg
FU University of Debrecen; Stipendium Hungaricum scholarship
CR Aboelkhair H, 2010, J AFR EARTH SCI, V58, P141, DOI 10.1016/j.jafrearsci.2010.01.007
   [Anonymous], 2006, REMOTE SENSING DIGIT, V0, P0
   [Anonymous], 1999, NEURAL NETWORKS COMP, V0, P0
   Bachri I, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8060248
   Bayliss J, 1998, P SOC PHOTO-OPT INS, V3240, P133, DOI 10.1117/12.300050
   Bentahar I, 2021, ADV SPACE RES, V67, P945, DOI 10.1016/j.asr.2020.10.037
   Bryant R, 2003, IEEE T GEOSCI REMOTE, V41, P1204, DOI 10.1109/TGRS.2003.813213
   Chen XF, 2007, REMOTE SENS ENVIRON, V110, P344, DOI 10.1016/j.rse.2007.03.015
   Czapla-Myers J, 2016, IEEE J-STARS, V9, P816, DOI 10.1109/JSTARS.2015.2463101
   Davis S.M., 1978, REMOTE SENSING QUANT, V0, P0
   Dong YN, 2021, IEEE T CYBERNETICS, V51, P3185, DOI 10.1109/TCYB.2020.3004263
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Fatima K., 2013, INT J EARTH SCI ENG, V7, P964
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Ge WY, 2018, ADV SPACE RES, V62, P1702, DOI 10.1016/j.asr.2018.06.036
   Grebby S, 2011, REMOTE SENS ENVIRON, V115, P214, DOI 10.1016/j.rse.2010.08.019
   Hadigheh SMH, 2013, J INDIAN SOC REMOTE, V41, P921, DOI 10.1007/s12524-013-0284-1
   Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481
   He J, 2015, INT J REMOTE SENS, V36, P2252, DOI 10.1080/01431161.2015.1035410
   Helba HA, 2001, RESOUR GEOL, V51, P19, DOI 10.1111/j.1751-3928.2001.tb00078.x
   Hubbard BE, 2005, REMOTE SENS ENVIRON, V99, P173, DOI 10.1016/j.rse.2005.04.027
   Hubbard BE, 2003, IEEE T GEOSCI REMOTE, V41, P1401, DOI 10.1109/TGRS.2003.812906
   Jellouli A., 2016, EGUGA, V18, P0
   Karimzadeh S, 2021, ADV SPACE RES, V68, P2421, DOI 10.1016/j.asr.2021.05.002
   Kumar C., 1900, DOI 10.1080/10106049.2021.1920632, V0, P0
   Lee S, 2012, INT J REMOTE SENS, V33, P4937, DOI 10.1080/01431161.2011.649862
   Lencioni DE, 1999, P SOC PHOTO-OPT INS, V3870, P269, DOI 10.1117/12.373195
   Liesenberg V, 2013, INT J APPL EARTH OBS, V21, P122, DOI 10.1016/j.jag.2012.08.016
   Lobell DB, 2003, IEEE T GEOSCI REMOTE, V41, P1277, DOI 10.1109/TGRS.2003.812909
   Manap H.S., 2018, INT MULTIDISCIP SCI, V18, P551, DOI 10.5593/SGEM2018/2.2/S08.069
   Mehr SG, 2013, INT J REMOTE SENS, V34, P8803, DOI 10.1080/01431161.2013.853144
   Mendenhall J.A., 2000, EARTH OBSERVING 1 AD, V0, P0
   Othman AA, 2017, J ASIAN EARTH SCI, V146, P90, DOI 10.1016/j.jseaes.2017.05.005
   Othman AA, 2014, REMOTE SENS-BASEL, V6, P6867, DOI 10.3390/rs6086867
   Pal M, 2005, INT J REMOTE SENS, V26, P1007, DOI 10.1080/01431160512331314083
   Pour AB, 2014, SPRINGERPLUS, V3, P0, DOI 10.1186/2193-1801-3-130
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Shi Y, 2021, IEEE ACCESS, V9, P13643, DOI 10.1109/ACCESS.2021.3051015
   Wang F, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8010028
   Xie FD, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13050930
   Yu L, 2012, COMPUT GEOSCI-UK, V45, P229, DOI 10.1016/j.cageo.2011.11.019
   Yuan XF, 2020, NEUROCOMPUTING, V396, P375, DOI 10.1016/j.neucom.2018.11.107
   Zhou PC, 2019, IEEE T GEOSCI REMOTE, V57, P4823, DOI 10.1109/TGRS.2019.2893180
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zoheir B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11182122
   Zoheir B, 2019, ORE GEOL REV, V105, P236, DOI 10.1016/j.oregeorev.2018.12.030
   Zoheir B, 2014, J AFR EARTH SCI, V99, P165, DOI 10.1016/j.jafrearsci.2013.06.002
NR 47
TC 4
Z9 4
U1 3
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-9385
EI 
J9 REMOTE SENS APPL
JI Remote Sens. Appl.-Soc. Environ.
PD NOV 15
PY 2021
VL 24
IS 
BP 
EP 
DI 10.1016/j.rsase.2021.100643
EA OCT 2021
PG 9
WC Environmental Sciences; Remote Sensing
SC Environmental Sciences & Ecology; Remote Sensing
GA WZ2OL
UT WOS:000719811400005
DA 2023-04-26
ER

PT J
AU Yu, QT
   Liu, W
   Goncalves, WN
   Marcato, J
   Li, J
AF Yu, Qiutong
   Liu, Wei
   Goncalves, Wesley Nunes
   Marcato Junior, Jose
   Li, Jonathan
TI Spatial Resolution Enhancement for Large-Scale Land Cover Mapping via Weakly Supervised Deep Learning
SO PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING
LA English
DT Article
ID data fusion; segmentation; multisource; reflectance
AB Multispectral satellite imagery is the primary data source for monitoring land cover change and characterizing land cover globally. However, the consistency of land cover monitoring is limited by the spatial and temporal resolutions of the acquired satellite images. The public availability of daily highresolution images is still scarce. This paper aims to fill this gap by proposing a novel spatiotemporal fusion method to enhance daily low spatial resolution land cover mapping using a weakly supervised deep convolutional neural network. We merge Sentinel images and moderate resolution imaging spectroradiometer (MODIS)-derived thematic land cover maps under the application background of massive remote sensing data and the large spatial resolution gaps between MODIS data and Sentinel images. The neural network training was conducted on the public data set SEN12MS, while the validation and testing used ground truth data from the 2020 IEEE Geoscience and Remote Sensing Society data fusion contest. The proposed data fusion method shows that the synthesized land cover map has significantly higher spatial resolution than the corresponding MODIS-derived land cover map. The ensemble approach can be implemented for generating highresolution time series of satellite images by fusing fine images from Sentinel-1 and -2 and daily coarse images from MODIS.
C1 [Yu, Qiutong; Liu, Wei; Li, Jonathan] Univ Waterloo, Dept Geog & Environm Management, Waterloo, ON, Canada.
   [Goncalves, Wesley Nunes; Marcato Junior, Jose] Fed Univ Mato Grosso do Sul UFMS, Fac Engn Architecture & Urbanism & Geog, Campo Grande, MS, Brazil.
C3 University of Waterloo; Universidade Federal de Mato Grosso do Sul
RP Li, J (corresponding author), Univ Waterloo, Dept Geog & Environm Management, Waterloo, ON, Canada.
EM junli@uwaterloo.ca
CR Ayhan B, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081333
   Chan L, 2021, INT J COMPUT VISION, V129, P361, DOI 10.1007/s11263-020-01373-4
   Chen B, 2017, ISPRS J PHOTOGRAMM, V124, P27, DOI 10.1016/j.isprsjprs.2016.12.008
   Chen GS, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9091816
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen YY, 2018, PHOTOGRAMM ENG REM S, V84, P629, DOI 10.14358/PERS.84.10.629
   Di Gregorio A., 2005, LAND COVER CLASSIFIC, V0, P0
   Du ZR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070888
   Fung CH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11182077
   Gao F, 2006, IEEE T GEOSCI REMOTE, V44, P2207, DOI 10.1109/TGRS.2006.872081
   Gevaert CM, 2015, REMOTE SENS ENVIRON, V156, P34, DOI 10.1016/j.rse.2014.09.012
   Ghamisi P, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2018.2890023
   Hilker T, 2009, REMOTE SENS ENVIRON, V113, P1613, DOI 10.1016/j.rse.2009.03.007
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   LEE JS, 1981, COMPUT VISION GRAPH, V15, P380, DOI 10.1016/S0146-664X(81)80018-4
   Loveland TR, 1997, ACTA ASTRONAUT, V41, P681, DOI 10.1016/S0094-5765(98)00050-2
   Schmitt M., 2019, ISPRS ANN PHOTOGRAMM, V0, P0, DOI DOI 10.5194/isprs-annals-IV-2-W7-153-2019(
   Song HH, 2018, IEEE J-STARS, V11, P821, DOI 10.1109/JSTARS.2018.2797894
   Song XP, 2017, GEO-SPAT INF SCI, V20, P141, DOI 10.1080/10095020.2017.1323522
   Sulla-Menashe D, 2019, REMOTE SENS ENVIRON, V222, P183, DOI 10.1016/j.rse.2018.12.013
   Sun Y, 2019, PHOTOGRAMM ENG REM S, V85, P907, DOI 10.14358/PERS.85.12.907
   Wang BW, 2018, INTL CONF POWER SYST, V0, PP4573, DOI 10.1109/POWERCON.2018.8601672
   Wang J, 2015, INT J REMOTE SENS, V36, P3659, DOI 10.1080/01431161.2015.1047049
   Xie DF, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16020207
   Zhu XL, 2016, REMOTE SENS ENVIRON, V172, P165, DOI 10.1016/j.rse.2015.11.016
   Zhu XL, 2010, REMOTE SENS ENVIRON, V114, P2610, DOI 10.1016/j.rse.2010.05.032
   Zurita-Milla R, 2008, IEEE GEOSCI REMOTE S, V5, P453, DOI 10.1109/LGRS.2008.919685
NR 28
TC 1
Z9 2
U1 5
U2 17
PU AMER SOC PHOTOGRAMMETRY
PI BETHESDA
PA 5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA
SN 0099-1112
EI 2374-8079
J9 PHOTOGRAMM ENG REM S
JI Photogramm. Eng. Remote Sens.
PD JUN 15
PY 2021
VL 87
IS 6
BP 405
EP 412
DI 10.14358/PERS.87.6.405
PG 8
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UU0GF
UT WOS:000698483300007
DA 2023-04-26
ER

PT J
AU Valeh, S
   Motamedvairi, B
   Kiadaliri, H
   Ahmadi, H
AF Valeh, Sadegh
   Motamedvairi, Baharak
   Kiadaliri, Hadi
   Ahmadi, Hassan
TI Hydrological simulation of Ammameh basin by artificial neural network and SWAT models
SO PHYSICS AND CHEMISTRY OF THE EARTH
LA English
DT Article
DE Hydrological modeling; ANN; SWAT; Ammameh basin
ID climate-change; runoff simulation; water-resources; river-basin; stream-flow; ann models; impact; catchment; ihacres
AB The rainfall-runoff simulation provides the basis for the hydrological and climate change studies, and the climate studies are based on the rainfall-runoff simulation. In general, there are different models to simulate rainfall and runoff, each with different structures and inputs. In the present paper, two different models in terms of structure were selected: A) Artificial Neural network (ANN) that requires the rainfall, maximum temperature, minimum temperature and runoff data (6 ANN structures were formed based on the relations of partial auto-correlation and cross-correlation), B) Soil and Water Assessment Tool (SWAT) which requires the rainfall, maximum temperature, minimum temperature, and runoff data and the land use, Digital Elevation Model (DEM), and geological maps. In this study, the R2, NSE and MBE parameters were used to investigate the error, the monthly and annual averages to investigate the uncertainty, and the SWAT-CUP model of the SUFI-2 algorithm to select sensitive and important parameters for calibrating the SWAT model (in this study, 12 parameters were selected from the sensitive and important parameters). The results of this study showed that based on the error and uncertainty parameters, the ANN model performance (R2 = 0.76) during the validation period and the highest MBE = 0.09 in May) is better than the SWAT model (R2 = 0.67 in the validation period and the highest MBE = 1.24 in May). Also, the ANN model outperforms the SWAT model in estimating the extreme values. In general, this study found that it is a good practice to utilize the ANN model in the studies associated with climate change and the studies that do not have enough information, and to employ the SWAT model in the studies having a large amount of information and consider the routing and evaluation of the climate change effects on the erosion.
C1 [Valeh, Sadegh; Motamedvairi, Baharak; Kiadaliri, Hadi] Islamic Azad Univ, Fac Nat Resources & Environm, Sci & Res Branch, Dept Forest Range & Watershed Management, Tehran, Iran.
   [Ahmadi, Hassan] Univ Tehran, Coll Agr & Nat Resources, Tehran, Iran.
C3 Islamic Azad University; University of Tehran
RP Motamedvairi, B (corresponding author), Islamic Azad Univ, Fac Nat Resources & Environm, Sci & Res Branch, Dept Forest Range & Watershed Management, Tehran, Iran.
EM b-motamed@srbiau.ac.ir
CR Abbaspour KC, 2009, WATER RESOUR RES, V45, P0, DOI 10.1029/2008WR007615
   Ahmadi M, 2019, PHYS CHEM EARTH, V114, P0, DOI 10.1016/j.pce.2019.09.002
   Ahmadi M, 2019, PHYS CHEM EARTH, V111, P65, DOI 10.1016/j.pce.2019.05.002
   Al-Mukhtar M, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5929-2
   Alansi A. W., 2009, HYDROL EARTH SYST SC, V0, PP7581, DOI 10.5194/HESSD-6-7581-2009
   Board A.E., 2018, AM J CLIM CHANGE, V7, P3, DOI 10.4236/ajcc.2018.71002
   Carcano EC, 2008, J HYDROL, V362, P291, DOI 10.1016/j.jhydrol.2008.08.026
   Chaemiso SE, 2016, MODEL EARTH SYST ENV, V2, P0, DOI 10.1007/s40808-016-0257-9
   Deng ZM, 2015, ENVIRON EARTH SCI, V73, P1119, DOI 10.1007/s12665-014-3465-5
   Faramarzi M, 2017, J HYDROL-REG STUD, V9, P48, DOI 10.1016/j.ejrh.2016.11.003
   Gholami A., 2016, JOURNAL OF WATER AND LAND DEVELOPMENT, V0, P57
   Githui F, 2009, INT J CLIMATOL, V29, P1823, DOI 10.1002/joc.1828
   Grusson Y, 2015, J HYDROL, V531, P574, DOI 10.1016/j.jhydrol.2015.10.070
   Ha LT, 2017, REMOTE SENS HYDROL E, V251, P1, DOI 10.5194/HESS-2017-251
   Hosseini M., 2017, JWSS ISFAHAN U TECHN, V20, P183
   Huo AD, 2013, ENVIRON EARTH SCI, V69, P1931, DOI 10.1007/s12665-012-2025-0
   Jajarmizadeh M, 2015, KSCE J CIV ENG, V19, P345, DOI 10.1007/s12205-014-0060-y
   Jimeno-Saez P, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10020192
   Loyeh NS, 2017, COMP DIFFERENT RAINF, V0, P0
   Masih I, 2011, J AM WATER RESOUR AS, V47, P179, DOI 10.1111/j.1752-1688.2010.00502.x
   Narsimlu B, 2013, WATER RESOUR MANAG, V27, P3647, DOI 10.1007/s11269-013-0371-7
   Noori N, 2016, J HYDROL, V533, P141, DOI 10.1016/j.jhydrol.2015.11.050
   Park JY, 2014, PADDY WATER ENVIRON, V12, PS65, DOI 10.1007/s10333-014-0424-4
   Rahimi J., 2018, THEOR APPL CLIMATOL, V0, P1
   Singh V, 2013, CURR SCI INDIA, V104, P1187
   Tavakol-Davani H, 2013, INT J CLIMATOL, V33, P2561, DOI 10.1002/joc.3611
   Tegegne Getachew, 2017, JOURNAL OF HYDROLOGY-NEW ZEALAND, V56, P155
   Vaghefi SA, 2014, HYDROL PROCESS, V28, P2018, DOI 10.1002/hyp.9747
   Vaghefi SA, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-018-38071-8
   Zakizadeh H, 2020, PHYS CHEM EARTH, V120, P0, DOI 10.1016/j.pce.2020.102899
NR 30
TC 7
Z9 7
U1 3
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 1474-7065
EI 1873-5193
J9 PHYS CHEM EARTH
JI Phys. Chem. Earth
PD OCT 15
PY 2021
VL 123
IS 
BP 
EP 
DI 10.1016/j.pce.2021.103014
EA APR 2021
PG 10
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources
SC Geology; Meteorology & Atmospheric Sciences; Water Resources
GA UA7XH
UT WOS:000685371000002
DA 2023-04-26
ER

PT J
AU Zhang, K
   Zhao, J
   Liu, P
   Yin, CCA
AF Zhang, Kai
   Zhao, Jian
   Liu, Pei
   Yin, Changchuan
TI Radio Environment Map Enhanced Intelligent Reflecting Surface Systems Beyond 5G
SO 2021 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS WORKSHOPS (ICC WORKSHOPS)
LA English
DT Proceedings Paper
DE Intelligent reflecting surface; Sub-6GHz; radio environment map; channel prediction; long short-term memory recurrent neural network
AB The Sub-6GHz spectrum is crucial for outdoor coverage in the fifth generation (SG) mobile communication systems. Considering the typical urban outdoor environment, one of the fundamental challenges for Sub-6GHz system is its susceptibility to occlusion effects. One way to alleviate this influence is to establish another line of sight link by using an intelligent reflecting surface (IRS). Nevertheless, the performance degradation due to the delay and overhead of the channel feedback can not be neglected. To address this issue, in this paper we propose a radio environment map (REM) based method for occlusion and channel prediction to reduce the delay and overhead. Based on the image information captured by the REM constructor, the user equipments' (UEs') location at the next moment are predicted firstly. Then we make prediction for occlusion and channel condition and determine the transmission mode (TM) for each UE. Finally, the optimal phase is obtained by solving a phase optimization problem under a given TM selection matrix constraint. Compared to the state-of-the-art approaches, simulation results show that our proposed method significantly improve the link reliability and energy efficiency.
C1 [Zhang, Kai; Zhao, Jian; Liu, Pei; Yin, Changchuan] Beijing Univ Posts & Telecommun, Beijing Lab Adv Informat Networks, Beijing Key Lab Network Syst Architecture & Conve, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Zhang, K (corresponding author), Beijing Univ Posts & Telecommun, Beijing Lab Adv Informat Networks, Beijing Key Lab Network Syst Architecture & Conve, Beijing, Peoples R China.
EM kaizhang@bupt.edu.cn; zhaojian@bupt.edu.cn; liupei6618@bupt.edu.cn; ccyin@bupt.edu.cn
FU Beijing Natural Science Foundation-Haidian Original Innovation Foundation [L192003]; National Natural Science Foundation of China [62001051]; BUPT Basic Scientific Research Project [2020RC01]; 111 Project [B17007]; Beijing Laboratory Funding [2020BJLAB01]
CR Abeywickrama S, 2020, IEEE T COMMUN, V68, P5849, DOI 10.1109/TCOMM.2020.3001125
   Basar E, 2019, IEEE ACCESS, V7, P116753, DOI 10.1109/ACCESS.2019.2935192
   Chen MZ, 2021, P NATL ACAD SCI USA, V118, P0, DOI 10.1073/pnas.2024789118
   Chen MZ, 2021, IEEE T WIREL COMMUN, V20, P269, DOI 10.1109/TWC.2020.3024629
   Chen MZ, 2020, IEEE T WIREL COMMUN, V19, P177, DOI 10.1109/TWC.2019.2942929
   Chen MZ, 2019, IEEE COMMUN SURV TUT, V21, P3039, DOI 10.1109/COMST.2019.2926625
   Collonge S, 2004, IEEE T WIREL COMMUN, V3, P2396, DOI 10.1109/TWC.2004.837276
   Dong LA, 2001, GLOB TELECOMM CONF, V0, PP3287, DOI 10.1109/GLOCOM.2001.966294
   Huang CW, 2019, IEEE T WIREL COMMUN, V18, P4157, DOI 10.1109/TWC.2019.2922609
   Huang-Chih Chen, 2018, 2018 INTERNATIONAL AUTOMATIC CONTROL CONFERENCE (CACS), V0, P0, DOI DOI 10.1109/CACS.2018.8606763
   Jiang W, 2020, IEEE OPEN J COMM SOC, V1, P320, DOI 10.1109/OJCOMS.2020.2982513
   Krahenbuhl P, 2019, ABS190407850 CORR, V0, P0
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Staudemeyer R. C., 2019, ARXIV, V0, P0
NR 14
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2164-7038
EI 
J9 IEEE INT CONF COMM
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/ICCWorkshops50388.2021.9473634
PG 6
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA BT7GT
UT WOS:000848412200128
DA 2023-04-26
ER

PT J
AU Lima, B
   Ferreira, L
   Moura, JM
AF Lima, Bruno
   Ferreira, Luis
   Moura, Joao Martinho
TI Helping to detect legal swimming pools with Deep Learning and Data Visualization
SO INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS / INTERNATIONAL CONFERENCE ON PROJECT MANAGEMENT / INTERNATIONAL CONFERENCE ON HEALTH AND SOCIAL CARE INFORMATION SYSTEMS AND TECHNOLOGIES 2020 (CENTERIS/PROJMAN/HCIST 2020)
LA English
DT Proceedings Paper
DE Artificial Intelligence; Orthophotomaps; Detection; GIS; Data Visualization; Pattern Recognition
AB The municipalities have, as a primary responsibility, the administrative management of their territory. The use of geographic information systems (GIS) and orthophoto maps can help to handle this task. One of the great difficulties they face is related to the continuous and quick changes that the territory suffers, and whose inspection is challenging to support. An example of this is the maintenance of the swimming pool registration system, in order to validate or license them. Indeed, it requires a substantial manual intervention, yet. This paper describes a system prototype for helping on detecting swimming pools on aerial images. It explores and integrates artificial intelligence (AI), systems integration, GIS, and data visualization. The AI improves the detection of objects, and middleware supports the integration of the detection results with other municipality systems for georeferencing and private property data licensing data crossing. To the innovative interoperability services, visualization libraries were explored, and an advanced visualization and analysis system was constructed. A dataset of aerial images of swimming pools and correspondent classification metadata was created. The model was trained with several convolutional neural networks in order to obtain and compare the precision results. The more accurate model is described. (C) 2021 The Authors. Published by Elsevier B.V.
C1 [Ferreira, Luis] IPCA, 2Ai Sch Technol, Barcelos, Portugal.
   [Lima, Bruno; Ferreira, Luis; Moura, Joao Martinho] IPCA, Sch Technol, Barcelos, Portugal.
   [Moura, Joao Martinho] Univ Minho, Ctr ALGORITMI, P-4804533 Guimaraes, Portugal.
   [Lima, Bruno] Municipal Esposende, P-4740223 Esposende, Portugal.
C3 Instituto Politecnico do Cavado e do Ave - IPCA; Instituto Politecnico do Cavado e do Ave - IPCA; Universidade do Minho
RP Ferreira, L (corresponding author), IPCA, 2Ai Sch Technol, Barcelos, Portugal.; Ferreira, L (corresponding author), IPCA, Sch Technol, Barcelos, Portugal.
EM lufer@ipca.pt
FU National funds, through the Foundation for Science and Technology (FCT) [UIDB/05549/2020, UIDP/05549/2020]
CR Aldeborgh Nikki, 2017, DIGITALGLOBE POOLN, V0, P0
   Browne K., 2019, ARTIFICIALLY NEURAL, V0, P0
   Cresson R, 2019, IEEE GEOSCI REMOTE S, V16, P25, DOI 10.1109/LGRS.2018.2867949
   ERSI, 2018, ARCGIS ENT POOLD FUL, V0, P0
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Google, 2016, GOOGL AI BLOG INTR O, V0, P0
   Grizonnet M., 2017, OPEN GEOSPATIAL DATA, V2, P1
   Hui J., 2018, OBJECT DETECTION SPE, V0, P0
   Khursheed T., 2019, 2019 1 INT C UNM, V0, P0
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mahmood H., 2018, SOFTMAX FUNCTION SIM, V0, P0
   Mango, 2014, GIS MAPP THE BEG GUI, V0, P0
   MathWorks, 2016, MACH LEARN MATLAB, V0, P0
   Nielsen J, 2016, 10 USABILITY HEURIST, V0, P0
   Ren S., 2015, PROC INT C NEURAL IN, V0, PP91, DOI 10.1109/ICCV.2015.169.
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Vujkovic M., 2017, INT J MOL SCI, V0, P0, DOI DOI 10.1016/j.jcms.2021.02.007
   Zeng GD, 2019, LECT NOTES COMPUT SC, V11404, P35, DOI 10.1007/978-3-030-11166-3_4
   Zhang Q., 2017, LEARNING HUMANS DEEP, V0, P0
NR 20
TC 2
Z9 2
U1 1
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
EI 
J9 PROCEDIA COMPUT SCI
PD JUN 15
PY 2021
VL 181
IS 
BP 1058
EP 1065
DI 10.1016/j.procs.2021.01.301
PG 8
WC Computer Science, Information Systems; Computer Science, Theory & Methods; Information Science & Library Science; Management; Operations Research & Management Science; Medical Informatics
SC Computer Science; Information Science & Library Science; Business & Economics; Operations Research & Management Science; Medical Informatics
GA BR5HQ
UT WOS:000655346400130
DA 2023-04-26
ER

PT J
AU Prakash, N
   Manconi, A
   Loew, S
AF Prakash, Nikhil
   Manconi, Andrea
   Loew, Simon
TI A new strategy to map landslides with a generalized convolutional neural network
SO SCIENTIFIC REPORTS
LA English
DT Article
ID spatial-distribution; earthquake; performance; imagery
AB Rapid mapping of event landslides is crucial to identify the areas affected by damages as well as for effective disaster response. Traditionally, such maps are generated with visual interpretation of remote sensing imagery (manned/unmanned airborne systems or spaceborne sensors) and/or using pixel-based and object-based methods exploiting data-intensive machine learning algorithms. Recent works have explored the use of convolutional neural networks (CNN), a deep learning algorithm, for mapping landslides from remote sensing data. These methods follow a standard supervised learning workflow that involves training a model using a landslide inventory covering a relatively small area. The trained model is then used to predict landslides in the surrounding regions. Here, we propose a new strategy, i.e., a progressive CNN training relying on combined inventories to build a generalized model that can be applied directly to a new, unexplored area. We first prove the effectiveness of CNNs by training and validating on event landslides inventories in four regions after earthquakes and/or extreme meteorological events. Next, we use the trained CNNs to map landslides triggered by new events spread across different geographic regions. We found that CNNs trained on a combination of inventories have a better generalization performance, with a bias towards high precision and low recall scores. In our tests, the combined training model achieved the highest (Matthews correlation coefficient) MCC score of 0.69 when mapping landslides in new unseen regions. The mapping was done on images from different optical sensors, resampled to a spatial resolution of 6 m, 10 m, and 30 m. Despite a slightly reduced performance, the main advantage of combined training is to overcome the requirement of a local inventory for training a new deep learning model. This implementation can facilitate automated pipelines providing fast response for the generation of landslide maps in the post-disaster phase. In this study, the study areas were selected from seismically active zones with a high hydrological hazard distribution and vegetation coverage. Hence, future works should also include regions from less vegetated geographic locations.
C1 [Prakash, Nikhil; Manconi, Andrea; Loew, Simon] Swiss Fed Inst Technol, Engn Geol, Dept Earth Sci, CH-8092 Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Prakash, N (corresponding author), Swiss Fed Inst Technol, Engn Geol, Dept Earth Sci, CH-8092 Zurich, Switzerland.
EM nikhil.prakash@erdw.ethz.ch
FU European Union's Horizon 2020 Research and Innovation Program [776280]; European Space Agency and Planet labs [58294]
CR Abraham N., 2018, ARXIVABS181007842 CO, V0, P0
   Alvioli M, 2016, GEOSCI MODEL DEV, V9, P3975, DOI 10.5194/gmd-9-3975-2016
   Bickel VT, 2020, IEEE J-STARS, V13, P2831, DOI 10.1109/JSTARS.2020.2991588
   Catani F, 2021, LANDSLIDES, V18, P1025, DOI 10.1007/s10346-020-01513-4
   Chollet F., 2015, KERAS, V0, P0
   Coviello V, 2020, EARTH SURF DYN DISCU, V2020, P1
   Dilley M, 2005, DISAST RISK MANAGE, V0, P1
   Dinh L., 2017, ARXIV170304933, V0, P0
   Duhart P., 2019, ASS ENV ENG GEOLOGIS, V28, P653, DOI 10.25676/11124/173159
   Esposito G, 2020, NAT HAZARD EARTH SYS, V20, P2379, DOI 10.5194/nhess-20-2379-2020
   Fan XM, 2019, REV GEOPHYS, V57, P421, DOI 10.1029/2018RG000626
   Fan XM, 2018, LANDSLIDES, V15, P967, DOI 10.1007/s10346-018-0960-x
   Froude MJ, 2018, NAT HAZARD EARTH SYS, V18, P2161, DOI 10.5194/nhess-18-2161-2018
   Galli M, 2008, GEOMORPHOLOGY, V94, P268, DOI 10.1016/j.geomorph.2006.09.023
   GDAL/OGR contributors, 2020, GDAL OGR GEOSP DAT A, V0, P0
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Hagolle O, 2010, REMOTE SENS ENVIRON, V114, P1747, DOI 10.1016/j.rse.2010.03.002
   He K., 2015, ARXIVABS151203385 CO, V0, P0
   Kawaguchi K., 2020, ARXIV171005468, V0, P0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kukacka J., 2017, ARXIV171010686, V0, P0
   Liu P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050894
   Luque A, 2019, PATTERN RECOGN, V91, P216, DOI 10.1016/j.patcog.2019.02.023
   Martin A., 2015, TENSORFLOW LARGE SCA, V0, P0
   Massey C, 2018, B SEISMOL SOC AM, V108, P1630, DOI 10.1785/0120170305
   Meena SR, 2021, LANDSLIDES, V18, P1937, DOI 10.1007/s10346-020-01602-4
   Mon MM, 2018, J DISASTER RES, V13, P99
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Mondini AC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070760
   Mondini AC, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060554
   Peng DF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111382
   Prakash N, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030346
   Qi WW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152487
   Qiu S, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.024
   Rathje E., 2017, **DATA OBJECT**, V0, P0, DOI DOI 10.17603/DS2508W
   Roback K, 2018, GEOMORPHOLOGY, V301, P121, DOI 10.1016/j.geomorph.2017.01.030
   Ronneberger O., 2015, ARXIVABS150504597 CO, V0, P0
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Stanley T, 2017, NAT HAZARDS, V87, P145, DOI 10.1007/s11069-017-2757-y
   Stumpf A, 2011, REMOTE SENS ENVIRON, V115, P2564, DOI 10.1016/j.rse.2011.05.013
   Tajbakhsh N., 2018, ARXIVABS180710165 CO, V0, P0
   Tanyas H, 2017, J GEOPHYS RES-EARTH, V122, P1991, DOI 10.1002/2017JF004236
   Turner AK, 2018, INNOV INFRASTRUCT SO, V3, P0, DOI 10.1007/s41062-018-0175-y
   Wang FR, 2019, LANDSLIDES, V16, P1551, DOI 10.1007/s10346-019-01187-7
   Wang L., 2015, ARXIVABS150502496 CO, V0, P0
   Williams JG, 2018, NAT HAZARD EARTH SYS, V18, P185, DOI 10.5194/nhess-18-185-2018
   Xiong Z, 2010, INT J IMAGE DATA FUS, V1, P137, DOI 10.1080/19479831003802790
   Yi YN, 2020, IEEE J-STARS, V13, P6166, DOI 10.1109/JSTARS.2020.3028855
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 51
TC 30
Z9 30
U1 4
U2 19
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
EI 
J9 SCI REP-UK
JI Sci Rep
PD MAY 6
PY 2021
VL 11
IS 1
BP 
EP 
DI 10.1038/s41598-021-89015-8
PG 15
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA SL5WK
UT WOS:000656988100030
PM 33958656
DA 2023-04-26
ER

PT J
AU Patil, PS
   Holambe, RS
   Waghmare, LM
AF Patil, Parmeshwar S.
   Holambe, Raghunath S.
   Waghmare, Laxman M.
TI EffCDNet: Transfer learning with deep attention network for change detection in high spatial resolution satellite images
SO DIGITAL SIGNAL PROCESSING
LA English
DT Article
DE EfficientNet; Attention mechanism; Change detection; High resolution satellite imagery; Wavelet transform
ID sar images; classification; energy
AB High spatial resolution satellite (HRS) images are being extensively utilized for the detection of changes like urban dynamics, infrastructure surveillance, disaster management, and topographic map-making applications. The enormous information and challenging data are important for the change detection (CD) in these images. However, lack of training data and an excessive amount of information, which discourage the researcher from developing a deep-learning-based efficient algorithm for CD. Therefore we want to develop an efficient algorithm in terms of accuracy and speed. Hence, we gain attention on designing an optimized Convolution Neural Network (CNN) while maintaining the speed and segmentation accuracy of the network. We develop an optimized architecture called as EffCDNet which adopts a siamese-based pre-trained encoder with an Attention-based UNet decoder for semantic segmentation. The network is built with pre-trained EfficientNet architecture with shared weights for strong feature extraction and to overcome the limitations caused by insufficient training data. The attention-based UNet decoder uses the attention-gate layer mechanism right before concatenation operation. This obtains more discriminative relevant features for improving the segmentation performance. Also, it is used for the reconstruction of fine-grained feature maps with significant use of context information. For improvement in the change map, we used the Undecimated Discrete Wavelet Transform (UDWT) fusion as a post-processing technique for spatial and temporal analysis of multi-resolution images to obtain a much more enhanced information difference map. The resulting image is less affected by noise, shift-invariable, and overcomes the mixed pixel problem to detect small possible changes. Experimental results on LEVIR-CD, SZATKI AirChange (AC), and Onera Satellite Change Detection (OSCD) benchmark datasets proved that the proposed approach outperforms its superiority in terms of Intersection over Union (IoU) and inference time over the existing methods. (C) 2021 Elsevier Inc. All rights reserved.
C1 [Patil, Parmeshwar S.] Shri Guru Gobind Singhji Inst Engn & Technol, Dept Elect & Telecommun Engn, Nanded 431606, India.
   [Holambe, Raghunath S.; Waghmare, Laxman M.] Shri Guru Gobind Singhji Inst Engn & Technol, Dept Instrumentat Engn, Nanded 431606, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology; Shri Guru Gobind Singhji Institute of Engineering & Technology
RP Patil, PS (corresponding author), Shri Guru Gobind Singhji Inst Engn & Technol, Dept Elect & Telecommun Engn, Nanded 431606, India.
EM patilparam25@gmail.com
FU Ministry of Human Resource Development, Govt. of India; National Nodal Center
CR Ahmed T., 2020, CLASSIFICATION UNDER, V0, P0
   Akbarizadeh G, 2012, IEEE T GEOSCI REMOTE, V50, P4358, DOI 10.1109/TGRS.2012.2194787
   Attioui S, 2021, IET IMAGE PROCESS, V15, P974, DOI 10.1049/ipr2.12078
   Badue C., 2019, IEEE IJCNN, V0, P1
   Bahdanau D, 2016, ARXIV, V0, P0
   Baheti B, 2020, IEEE COMPUT SOC CONF, V0, PP1473, DOI 10.1109/CVPRW50498.2020.00187
   Banerjee T, 2021, IEEE T INFORM THEORY, V67, P2562, DOI 10.1109/TIT.2021.3053149
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Chen H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101662
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), V0, P0, DOI DOI 10.1145/3207677.3278067
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Chughtai AH, 2021, REMOTE SENS APPL, V22, P0, DOI 10.1016/j.rsase.2021.100482
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, V0, P2115
   Davari N, 2021, IEEE T POWER DELIVER, V36, P3640, DOI 10.1109/TPWRD.2020.3046161
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Heidary F., 1900, P2021, V0, P0
   Jetley S., 2018, ARXIV180402391, V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Li ZX, 2017, IEEE GEOSCI REMOTE S, V14, P783, DOI 10.1109/LGRS.2017.2681198
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Lucas B, 2021, MACH LEARN, V0, P0, DOI DOI 10.1007/s10994-020-05942-z
   Luong MT, 2015, EMNLP, V0, P0
   Noori M, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), V0, PP269, DOI 10.1109/ICCKE48569.2019.8964956
   Oktay O, 2018, ARXIV180403999, V0, P0
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Raja RAA, 2013, J INDIAN SOC REMOTE, V41, P35, DOI 10.1007/s12524-011-0199-7
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Samadi F, 2019, IET IMAGE PROCESS, V13, P2255, DOI 10.1049/iet-ipr.2018.6248
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Sefrin O, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010078
   Sharifzadeh F, 2019, J INDIAN SOC REMOTE, V47, P551, DOI 10.1007/s12524-018-0891-y
   Singh A., 2018, EGYPTIAN J REMOTE SE, V21, P345, DOI 10.1016/j.ejrs.2018.01.006
   Starck JL, 2007, IEEE T IMAGE PROCESS, V16, P297, DOI 10.1109/TIP.2006.887733
   Sun YL, 2021, PATTERN RECOGN, V109, P0, DOI 10.1016/j.patcog.2020.107598
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Tirandaz Z, 2016, IEEE J-STARS, V9, P1244, DOI 10.1109/JSTARS.2015.2492552
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou CS, 2020, IEEE T GEOSCI REMOTE, V58, P7705, DOI 10.1109/TGRS.2020.2983201
NR 52
TC 5
Z9 5
U1 4
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1051-2004
EI 1095-4333
J9 DIGIT SIGNAL PROCESS
JI Digit. Signal Prog.
PD NOV 15
PY 2021
VL 118
IS 
BP 
EP 
DI 10.1016/j.dsp.2021.103250
EA SEP 2021
PG 12
WC Engineering, Electrical & Electronic
SC Engineering
GA WC1PL
UT WOS:000704035900017
DA 2023-04-26
ER

PT J
AU Rahman, Z
   Roytman, L
   Kadik, A
   Rosy, D
   Nandi, P
   Rahman, S
   Mahmud, A
AF Rahman, Zahidur
   Roytman, Leonid
   Kadik, Abdelhamid
   Rosy, Dilara
   Nandi, Pradipta
   Rahman, Shahedur
   Mahmud, Ataul
TI Public health precautions for preventing malaria using environmental data
SO GEOSPATIAL INFORMATICS XI
LA English
DT Proceedings Paper
DE Malaria; GIS; ANN; AVHRR; VHI; Data; satellite remote sensing
ID vegetation
AB Considering the public health impact of a global pandemic, the reliance on data to understand disease outbreak is important now more than ever. Malaria is the most common mosquito-transmitted disease endemic to certain regions, leading to millions of serious illnesses and deaths each year. Because mosquito vectors are sensitive to environmental conditions such as temperature, precipitation, and humidity, it is possible to map areas currently or imminently at high risk for disease outbreaks using satellite remote sensing. In this paper the authors propose the development of an operational geospatial system for malaria early warning. This can be done by bringing together geographic information system (GIS) tools, artificial neural networks (ANN) for efficient pattern recognition, the best available ground-based environmental data such as epidemiological and vector ecology data, and current satellite remote sensing capabilities. The authors use Vegetation Health Indices (VHI) derived from visible and infrared radiances measured by satellite-mounted Advanced Very High Resolution Radiometers (AVHRR) and available weekly at 4-km resolution as one predictor of malaria risk in Bangladesh. As a study area, we focus on Bangladesh where malaria is a serious public health threat. The technology developed will, however, be largely portable to other countries in the world and applicable to other disease threats. A malaria early warning system will be a boon to international public health, enabling resources to be focused where they will do the most good for stopping pandemics, and will be an invaluable decision support tool for national security assessment and potential troop deployment in regions susceptible to disease outbreaks.
C1 [Rahman, Zahidur; Kadik, Abdelhamid] CUNY, LaGuardia Community Coll, Dept Math Engn & Comp Sci, 31-10 Thomson Ave, Long Isl City, NY 11101 USA.
   [Roytman, Leonid] CUNY, Dept Elect Engn, City Coll, 138 St & Convent Ave, New York, NY USA.
   [Rosy, Dilara] Marks Home Care, Rego Park, NY 11374 USA.
   [Nandi, Pradipta] All India Inst Med Sci, New Delhi, India.
   [Rahman, Shahedur] Get Well Med Care PC, Jamaica, NY 11432 USA.
   [Mahmud, Ataul] Dhaka Elect Supply Corp, Dhaka, Bangladesh.
C3 City University of New York (CUNY) System; City University of New York (CUNY) System; City College of New York (CUNY); All India Institute of Medical Sciences (AIIMS) New Delhi
RP Rahman, Z (corresponding author), CUNY, LaGuardia Community Coll, Dept Math Engn & Comp Sci, 31-10 Thomson Ave, Long Isl City, NY 11101 USA.
CR Curran P., 1980, PROGR PHYS GEOGRAPHY, V4, P315, DOI 10.1177/030913338000400301
   Gutman G., 1990, B AM MET SOC, V71, P1058
   Iyengar M. O. T., 1942, JOUR MALARIA INST INDIA, V4, P435
   Iyengar M. Q. T., 1944, JOUR MALARIA INST INDIA, V5, P435
   JUSTICE CO, 1985, INT J REMOTE SENS, V6, P1271, DOI 10.1080/01431168508948281
   Kogan F. N., 2002, AM GEOPHYS UNION EOS, V83, P557, DOI 10.1029/2002EO000382
   Kogan FN, 2001, ADV SPACE RES, V28, P149, DOI 10.1016/S0273-1177(01)00329-5
   KOGAN FN, 1990, INT J REMOTE SENS, V11, P1405, DOI 10.1080/01431169008955102
   MALINGREAU JP, 1986, INT J REMOTE SENS, V7, P1121, DOI 10.1080/01431168608948914
   McMichael A J., 1996, CLIMATE CHANGE HUMAN, V0, P297
   TARPLEY JD, 1984, J CLIM APPL METEOROL, V23, P491, DOI 10.1175/1520-0450(1984)023<0491:GVIFTN>2.0.CO;2
NR 11
TC 0
Z9 0
U1 0
U2 0
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
J9 PROC SPIE
PD JUN 15
PY 2021
VL 11733
IS 
BP 
EP 
DI 10.1117/12.2583919
PG 9
WC Computer Science, Information Systems; Remote Sensing; Optics; Imaging Science & Photographic Technology
SC Computer Science; Remote Sensing; Optics; Imaging Science & Photographic Technology
GA BS2VD
UT WOS:000706984300013
DA 2023-04-26
ER

PT J
AU Rodrigues, PM
   Bispo, BC
   Garrett, C
   Alves, D
   Teixeira, JP
   Freitas, D
AF Rodrigues, Pedro M.
   Bispo, Bruno C.
   Garrett, Carolina
   Alves, Dilio
   Teixeira, Joao P.
   Freitas, Diamantino
TI Lacsogram A New EEG Tool to Diagnose Alzheimer's Disease
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Alzheimer's disease; mild-cognitive impairment; diagnose; cepstrum; lacsogram; artificial neural networks
ID mild cognitive impairment; association workgroups; biomarker signature; national institute; dementia; guidelines; pet; recommendations; discrimination
AB This work proposes the application of a new electroencephalogram (EEG) signal processing tool - the lacsogram - to characterize the Alzheimer's disease (AD) activity and to assist on its diagnosis at different stages: Mild Cognitive Impairment (MCI), Mild and Moderate AD (ADM) and Advanced AD (ADA). Statistical analyzes are performed to lacstral distances between conventional EEG subbands to find measures capable of discriminating AD in all stages and characterizing the AD activity in each electrode. Cepstral distances are used for comparison. Comparing all AD stages and Controls (C), the most important significances are the lacstral distances between subbands theta and alpha (p = 0.0014 < 0.05). The topographic maps show significant differences in parietal, temporal and frontal regions as AD progresses. Machine learning models with a leave-one-out cross-validation process are applied to lacstral/cepstral distances to develop an automatic method for diagnosing AD. The following classification accuracies are obtained with an artificial neural network: 95.55% for All vs All, 98.06% for C vs MCI, 95.99% for C vs ADM, 93.85% for MCI vs ADM-ADA. In C vs MCI, C vs ADM and MCI vs ADM-ADA, the proposed method outperforms the state-of-art methods by 5%, 1%, and 2%, respectively. In All vs All, it outperforms the state-of-art EEG and non-EEG methods by 6% and 2%, respectively. These results indicate that the proposed method represents an improvement in diagnosing AD.
C1 [Rodrigues, Pedro M.] Catholic Univ Portugal, Fac Biotechnol, Associated Lab, Ctr Biotechnol & Fine Chem, Rua Diogo Botelho, Lisbon, Portugal.
   [Bispo, Bruno C.] Univ Fed Santa Catarina, Dept Elect & Elect Engn, BR-88040370 Florianopolis, SC, Brazil.
   [Garrett, Carolina] Univ Porto, Fac Med, P-4200319 Porto, Portugal.
   [Garrett, Carolina] Univ Hosp Ctr Sao Joao, Neurol Unity, P-4200319 Porto, Portugal.
   [Alves, Dilio] Univ Hosp Ctr Sao Joao, Neurol Unity, P-4200319 Porto, Portugal.
   [Teixeira, Joao P.] UNIAG Polytech Inst Braganca, CEDRI, P-5300253 Braganca, Portugal.
   [Freitas, Diamantino] Univ Porto, Fac Engn, P-4099002 Porto, Portugal.
C3 Universidade Catolica Portuguesa; Universidade Federal de Santa Catarina (UFSC); Universidade do Porto; Universidade do Porto
RP Rodrigues, PM (corresponding author), Catholic Univ Portugal, Fac Biotechnol, Associated Lab, Ctr Biotechnol & Fine Chem, Rua Diogo Botelho, Lisbon, Portugal.
EM prodrigues@porto.ucp.pt; bruno.bispo@ufsc.br; garrett.mc51@gmail.com; alvesdilio@gmail.com; joaopt@ipb.pt; dfreitas@fe.up.pt
FU National Funds from FCT -Fundacao para a Ciencia e a Tecnologia [UIDB/50016/2020, UIDB/05757/2020]; Faculty of Engineering of the University of Porto through the Doctoral Program of Biomedical Engineering; Fundação para a Ciência e a Tecnologia [UIDB/05757/2020, UIDB/50016/2020] Funding Source: FCT
CR Afshari S, 2017, IEEE J BIOMED HEALTH, V21, P949, DOI 10.1109/JBHI.2016.2578954
   Aghajani H, 2013, IEEE J BIOMED HEALTH, V17, P1039, DOI 10.1109/JBHI.2013.2253326
   AGNOLI A, 1983, CLIN NEUROPHARMACOL, V6, P311, DOI 10.1097/00002826-198312000-00005
   Akrofi K, 2010, INT CONF ACOUST SPEE, V0, PP606, DOI 10.1109/ICASSP.2010.5495193
   Ballard C, 2011, LANCET, V377, P1019, DOI 10.1016/S0140-6736(10)61349-9
   Barthel H, 2011, LANCET NEUROL, V10, P424, DOI 10.1016/S1474-4422(11)70077-1
   BESTHORN C, 1994, ELECTROEN CLIN NEURO, V90, P242, DOI 10.1016/0013-4694(94)90095-7
   BIRD TD, 2001, HARRISONS PRINCIPLES, V0, P2391
   Blennow K, 2010, EUR NEUROPSYCHOPHARM, V20, PS159, DOI 10.1016/S0924-977X(10)70115-2
   Bogert B. P., 1962, TIME SERIES ANAL, V0, P209
   Buscema M, 2007, ARTIF INTELL MED, V40, P127, DOI 10.1016/j.artmed.2007.02.006
   Cassani R., 2019, IEEE J BIOMED HLTH I, V24, P1
   Colliot O, 2008, RADIOLOGY, V248, P194, DOI 10.1148/radiol.2481070876
   Dauwels J, 2011, ADVANCES IN COGNITIVE NEURODYNAMICS (II), V0, PP709, DOI 10.1007/978-90-481-9695-1_106
   De Meyer G, 2010, ARCH NEUROL-CHICAGO, V67, P949, DOI 10.1001/archneurol.2010.179
   Ferrer I, 2012, PROG NEUROBIOL, V97, P38, DOI 10.1016/j.pneurobio.2012.03.005
   Forlenza Orestes V, 2015, ALZHEIMERS DEMENT (AMST), V1, P455, DOI 10.1016/j.dadm.2015.09.003
   Freitas S, 2011, J CLIN EXP NEUROPSYC, V33, P989, DOI 10.1080/13803395.2011.589374
   Gallego-Jutgla E, 2015, J NEURAL ENG, V12, P0, DOI 10.1088/1741-2560/12/1/016018
   GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849
   Hampel H, 2011, PROG NEUROBIOL, V95, P718, DOI 10.1016/j.pneurobio.2011.11.008
   Hampel H, 2010, NAT REV DRUG DISCOV, V9, P560, DOI 10.1038/nrd3115
   Haykin S., 2009, NEURAL NETWORKS LEAR, V3rd ed., P0
   Herholz K, 2003, ANN NUCL MED, V17, P79, DOI 10.1007/BF02988444
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hort J, 2010, EUR J NEUROL, V17, P1236, DOI 10.1111/j.1468-1331.2010.03040.x
   Huang C, 2000, CLIN NEUROPHYSIOL, V111, P1961, DOI 10.1016/S1388-2457(00)00454-5
   Jeong JS, 2004, CLIN NEUROPHYSIOL, V115, P1490, DOI 10.1016/j.clinph.2004.01.001
   Khatun S, 2019, IEEE T NEUR SYS REH, V27, P1063, DOI 10.1109/TNSRE.2019.2911970
   Knopman DS, 2001, NEUROLOGY, V56, P1143, DOI 10.1212/WNL.56.9.1143
   Knott V, 2001, J PSYCHIATR NEUROSCI, V26, P106
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Li W, 2019, IEEE J BIOMED HEALTH, V23, P1234, DOI 10.1109/JBHI.2018.2839771
   Malvar H. S, 1992, SIGNAL PROCESSINGWIT, V0, P0
   MCKHANN G, 1984, NEUROLOGY, V34, P939, DOI 10.1212/WNL.34.7.939
   McKhann GM, 2011, ALZHEIMERS DEMENT, V7, P263, DOI 10.1016/j.jalz.2011.03.005
   Melissant C, 2005, ARTIF INTELL MED, V33, P209, DOI 10.1016/j.artmed.2004.07.003
   Mesulam MM., 2000, PRINCIPLES BEHAV COG, V0, P432
   Nestor PJ, 2004, NAT MED, V10, PS34, DOI 10.1038/nrn1433
   OBryant SE, 2008, ARCH NEUROL-CHICAGO, V65, P963, DOI 10.1001/archneur.65.7.963
   Paliwal K. K., 1982, SPEECH COMMUNICATION, V1, P151, DOI 10.1016/0167-6393(82)90034-6
   Palmqvist S, 2015, NEUROLOGY, V85, P1240, DOI 10.1212/WNL.0000000000001991
   Patterson C., 2018, WORLD ALZHEIMER REPO, V0, P0, DOI DOI 10.1111/j.0033-0124.1950.24_14.x
   Petrosian AA, 2001, CLIN NEUROPHYSIOL, V112, P1378, DOI 10.1016/S1388-2457(01)00579-X
   Poil SS, 2013, FRONT AGING NEUROSCI, V5, P0, DOI 10.3389/fnagi.2013.00058
   Priddy K.L., 2005, SPIE, V0, P0
   Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217
   Rodrigues P.M., 2018, INT J RELIABLE QUALI, V7, P40, DOI 10.4018/IJRQEH.2018010104
   Rodrigues PM, 2018, PROCEDIA COMPUT SCI, V138, P209, DOI 10.1016/j.procs.2018.10.030
   Rodrigues PM, 2017, ADV HEALTHC INF SYST, V0, PP112, DOI 10.4018/978-1-5225-1724-5.ch007
   Sanei S., 2007, EEG SIGNAL PROCESSIN, V0, P0, DOI DOI 10.1002/9780470511923
   Shaw LM, 2009, ANN NEUROL, V65, P403, DOI 10.1002/ana.21610
   Smit S. K., 2010, EXPT METHODS ANAL OP, V0, PP287, DOI 10.1007/978-3-642-02538-9_12
   Sperling RA, 2011, ALZHEIMERS DEMENT, V7, P280, DOI 10.1016/j.jalz.2011.03.003
   Strang G., 1996, WAVELETS FILTER BANK, V0, P0
   TOHKURA Y, 1987, IEEE T ACOUST SPEECH, V35, P1414, DOI 10.1109/TASSP.1987.1165058
   Tolboom N, 2010, J NEUROL NEUROSUR PS, V81, P882, DOI 10.1136/jnnp.2009.194779
   Tong T, 2017, IEEE T BIO-MED ENG, V64, P155, DOI 10.1109/TBME.2016.2549363
   Trappenberg TP, 2019, FUNDAMENTALS MACHINE, V0, P0
   Vetterli M., 1995, WAVELETS SUBBAND COD, V0, P0
   Vialatte F, 2005, LECT NOTES COMPUT SC, V3696, P683, DOI 10.1007/11550822_106
   Williams CJ, 1999, APPL STOCH MODEL BUS, V15, P89, DOI 10.1002/(SICI)1526-4025(199904/06)15:2<89::AID-ASMB366>3.0.CO;2-K
NR 62
TC 10
Z9 10
U1 3
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD SEP 15
PY 2021
VL 25
IS 9
BP 3384
EP 3395
DI 10.1109/JBHI.2021.3069789
PG 12
WC Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics
SC Computer Science; Mathematical & Computational Biology; Medical Informatics
GA UL4AS
UT WOS:000692596400019
PM 33784628
DA 2023-04-26
ER

PT J
AU Yu, CS
   Chang, SS
   Chang, TH
   Wu, JL
   Lin, YJ
   Chien, HF
   Chen, RJ
AF Yu, Cheng-Sheng
   Chang, Shy-Shin
   Chang, Tzu-Hao
   Wu, Jenny L.
   Lin, Yu-Jiun
   Chien, Hsiung-Fei
   Chen, Ray-Jade
TI A COVID-19 Pandemic Artificial Intelligence-Based System With Deep Learning Forecasting and Automatic Statistical Data Acquisition: Development and Implementation Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE COVID-19; artificial intelligence; time series; deep learning; machine learning; statistical analysis; pandemic; data visualization
AB Background: More than 79.2 million confirmed COVID-19 cases and 17 million deaths were caused by SARS-CoV-2; the disease was named COVID-19 by the World Health Organization Control of the COVID-19 epidemic has become a crucial issue around the globe, but there are limited studies that investigate the global trend of the COVID-19 pandemic together with each country's policy measures. Objective: We aimed to develop an online artificial intelligence (AI) system to analyze the dynamic trend of the COVID-19 pandemic, facilitate forecasting and predictive modeling, and produce a heat map visualization of policy measures in 171 countries. Methods: The COVID-19 Pandemic AI System (CPAIS) integrated two data sets: the data set from the Oxford COVID-19 Government Response Tracker from the Blavatnik School of Government, which is maintained by the University of Oxford, and the data set from the COVID-19 Data Repository, which was established by the Johns Hopkins University Center for Systems Science and Engineering. This study utilized four statistical and deep learning techniques for forecasting: autoregressive integrated moving average (ARIMA), feedforward neural network (FNN), multilayer perceptron (MLP) neural network, and long short-term memory (LSTM). With regard to 1-year records (ie, whole time series data), records from the last 14 days served as the validation set to evaluate the performance of the forecast, whereas earlier records served as the training set. Results: A total of 171 countries that featured in both databases were included in the online system. The CPAIS was developed to explore variations, trends, and forecasts related to the COVID-19 pandemic across several counties. For instance, the number of confirmed monthly cases in the United States reached a local peak in July 2020 and another peak of 6,368,591 in December 2020. A dynamic heat map with policy measures depicts changes in COVID-19 measures for each country. A total of 19 measures were embedded within the three sections presented on the website, and only 4 of the 19 measures were continuous measures related to financial support or investment. Deep learning models were used to enable COVID-19 forecasting; the performances of ARIMA, FNN, and the MLP neural network were not stable because their forecast accuracy was only better than LSTM for a few countries. LSTM demonstrated the best forecast accuracy for Canada, as the root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) were 2272.551, 1501.248, and 0.2723075, respectively. ARIMA (RMSE=317.53169; MAPE=0.4641688) and FNN (RMSE=181.29894; MAPE=0.2708482) demonstrated better performance for South Korea. Conclusions: The CPAIS collects and summarizes information about the COVID-19 pandemic and offers data visualization and deep learning-based prediction. It might be a useful reference for predicting a serious outbreak or epidemic. Moreover, the system undergoes daily updates and includes the latest information on vaccination, which may change the dynamics of the pandemic.
C1 [Yu, Cheng-Sheng; Chang, Shy-Shin; Wu, Jenny L.; Lin, Yu-Jiun] Taipei Med Univ, Coll Med, Sch Med, Dept Family Med, Taipei, Taiwan.
   [Yu, Cheng-Sheng; Chang, Shy-Shin; Lin, Yu-Jiun] Taipei Med Univ Hosp, Dept Family Med, Taipei, Taiwan.
   [Yu, Cheng-Sheng; Chang, Tzu-Hao; Wu, Jenny L.] Taipei Med Univ, Coll Med Sci & Technol, Grad Inst Biomed Informat, Taipei, Taiwan.
   [Yu, Cheng-Sheng; Chen, Ray-Jade] Taipei Med Univ, Coll Med, Profess Master Program Artificial Intelligence Me, Taipei, Taiwan.
   [Chang, Tzu-Hao] Taipei Med Univ Hosp, Clin Big Data Res Ctr, Taipei, Taiwan.
   [Chien, Hsiung-Fei] Taipei Med Univ, Taipei Med Univ Hosp, Dept Surg, Div Plast Surg, Taipei, Taiwan.
   [Chien, Hsiung-Fei] Taipei Med Univ, Sch Med, Coll Med, Taipei, Taiwan.
   [Chen, Ray-Jade] Taipei Med Univ, Coll Med, Sch Med, Dept Surg, 250 Wuxing St, Taipei 11031, Taiwan.
   [Chen, Ray-Jade] Taipei Med Univ Hosp, Dept Surg, Div Gen Surg, Taipei, Taiwan.
C3 Taipei Medical University; Taipei Medical University; Taipei Medical University Hospital; Taipei Medical University; Taipei Medical University; Taipei Medical University; Taipei Medical University Hospital; Taipei Medical University; Taipei Medical University Hospital; Taipei Medical University; Taipei Medical University; Taipei Medical University; Taipei Medical University Hospital
RP Chen, RJ (corresponding author), Taipei Med Univ, Coll Med, Sch Med, Dept Surg, 250 Wuxing St, Taipei 11031, Taiwan.
EM rayjchen@tmu.edu.tw
CR Abedi V, 2021, J RACIAL ETHN HEALTH, V8, P732, DOI 10.1007/s40615-020-00833-4
   Alwan NA, 2020, LANCET, V396, PE71, DOI 10.1016/S0140-6736(20)32153-X
   [Anonymous], 2019, WORLD POPULATION PRO, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0
   [Anonymous], 1996, PATTERN RECOGN, V0, P0
   [Anonymous], 2020, WEEKLY EPIDEMIOLOGIC, V0, P0
   [Anonymous], 2002, INTRO TIME SERIES FO, V0, P0
   [Anonymous], 2020, ARCHIVED WHO TIMELIN, V0, P0
   Ayyoubzadeh SM, 2020, JMIR PUBLIC HLTH SUR, V6, P192, DOI 10.2196/18828
   Baker MG, 2020, NEW ENGL J MED, V383, P0, DOI 10.1056/NEJMc2025203
   Chassagnon G, 2021, MED IMAGE ANAL, V67, P0, DOI 10.1016/j.media.2020.101860
   Chen CM, 2020, J MED INTERNET RES, V22, P0, DOI 10.2196/19540
   Crone SF, 2010, NEUROCOMPUTING, V73, P1923, DOI 10.1016/j.neucom.2010.01.017
   Dong ES, 2020, LANCET INFECT DIS, V20, P533, DOI 10.1016/S1473-3099(20)30120-1
   Gal Y, 2016, ADV NEUR IN, V29, P0
   Graves A, 2012, STUD COMPUT INTELL, V385, P37
   Hale T, 2021, NAT HUM BEHAV, V5, P529, DOI 10.1038/s41562-021-01079-8
   Hamilton J.D., 1994, TIME SERIES ANAL, V0, P0
   Hastie T., 2009, ELEMENTS STAT LEARNI, V2, P0
   Haykin S, 1999, NEURAL NETWORKS COMP, V0, P0
   Hyndman RJ, 2018, OTEXTS, Vsecond, P0
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Hyndman RJ, 2008, J STAT SOFTW, V27, P1, DOI 10.18637/jss.v027.i03
   Imtyaz Ayman, 2020, J ORAL BIOL CRANIOFAC RES, V10, P504, DOI 10.1016/j.jobcr.2020.08.005
   Kadi Nadjat, 2020, BULL NATL RES CENT, V44, P138, DOI 10.1186/s42269-020-00393-x
   Khalatbari-Soltani S, 2020, J EPIDEMIOL COMMUN H, V74, P620, DOI 10.1136/jech-2020-214297
   Kim S, 2020, INT J INFECT DIS, V98, P328, DOI 10.1016/j.ijid.2020.07.004
   Kostoff RN, 2020, INT J MOL MED, V46, P1599, DOI 10.3892/ijmm.2020.4733
   Kourentzes N, 2014, EXPERT SYST APPL, V41, P4235, DOI 10.1016/j.eswa.2013.12.011
   Lin YJ, 2019, J CLIN MED, V8, P0, DOI 10.3390/jcm8111775
   Ord K., 2017, PRINCIPLES BUSINESS, V2nd, P0
   Papoulis A., 2001, PROBABILITY RANDOM V, V0, P0
   Phillips N, 2021, NATURE, V590, P382, DOI 10.1038/d41586-021-00396-2
   Prata DN, 2020, SCI TOTAL ENVIRON, V729, P0, DOI 10.1016/j.scitotenv.2020.138862
   Ramasubramanian Karthik., 2019, MACH LEARN USING R, V0, PP667, DOI 10.1007/978-1-4842-4215-5_11
   Rosenblatt F., 1961, TECHNICAL REPORT, V0, P0, DOI DOI 10.21236/AD0256582
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Scudellari M, 2020, NATURE, V584, P22, DOI 10.1038/d41586-020-02278-5
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, P0, DOI 10.1016/j.chaos.2020.110212
   Shastri S, 2020, CHAOS SOLITON FRACT, V140, P0, DOI 10.1016/j.chaos.2020.110227
   Venables W. N., 2002, MODERN APPL STAT S, V4th, P0, DOI 10.1007/978-0-387-21706-2
   Wang XZ, 2006, DATA MIN KNOWL DISC, V13, P335, DOI 10.1007/s10618-005-0039-x
   WHO, 2020, WHO DIRECTOR GEN OPE, V0, P0
   Yang ZF, 2020, J THORAC DIS, V12, P165, DOI 10.21037/jtd.2020.02.64
   Yeung AYS, 2021, J MED INTERNET RES, V23, P0, DOI 10.2196/26628
   Yu CS, 2020, J MED INTERNET RES, V22, P0, DOI 10.2196/18585
   Zell A., 1994, SIMULATION NEURONALE, V0, P0
NR 48
TC 11
Z9 12
U1 3
U2 15
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
EI 
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD MAY 20
PY 2021
VL 23
IS 5
BP 
EP 
DI 10.2196/27806
PG 18
WC Health Care Sciences & Services; Medical Informatics
SC Health Care Sciences & Services; Medical Informatics
GA SG0FR
UT WOS:000653122500008
PM 33900932
DA 2023-04-26
ER

PT J
AU Gao, RY
   Wang, CM
   Liang, Z
   Han, SL
   Li, BL
AF Gao, Ruiyuan
   Wang, Changming
   Liang, Zhu
   Han, Songling
   Li, Bailong
TI A Research on Susceptibility Mapping of Multiple Geological Hazards in Yanzi River Basin, China
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE collapse; landslide; debris flow; support vector machine; susceptibility mapping
ID support vector machine; landslide susceptibility; neural-network; gis; classification; algorithm; province; models; maps; area
AB Collapses, landslides, and debris flows are the main geological hazards faced by mankind, which bring heavy losses of life and property to people every year. The purpose of this paper is to establish a method for determining the optimal weighting scheme for multiple geological hazard susceptibility mapping. The information gain ratio (IGR) method was used to analyze the predictive ability of the conditioning factors. The support vector machine (SVM) algorithm was used to evaluate the susceptibility to collapse, landslide, and debris flow of the study area. The receiver operating characteristic curves (ROC) and classification statistics of geological hazard samples were applied to evaluate the performance of the models. The analytic hierarchy process (AHP) and frequency ratio (FR) method were combined to determine the optimal weighting scheme for collapse, landslide, and debris flow. All the conditioning factors have shown a certain predictive ability, making the models of collapse, landslide, and debris flow achieve very good performance. The multiple geological hazard susceptibility maps with the weights of 0.297, 0.539, and 0.164 for collapse, landslide, and debris flow was optimal for this study area with high-precision classification of all the geological hazard samples. The conclusions of this paper could provide meaningful references for risk migration and land use in the study area.
C1 [Gao, Ruiyuan; Wang, Changming; Liang, Zhu; Han, Songling; Li, Bailong] Jilin Univ, Coll Construct Engn, Changchun 130012, Peoples R China.
C3 Jilin University
RP Wang, CM (corresponding author), Jilin Univ, Coll Construct Engn, Changchun 130012, Peoples R China.
EM gaory18@mails.jlu.edu.cn; wangcm@jlu.edu.cn; liangzhu19@mails.jlu.edu.cn; hansl20@mails.jlu.edu.cn; lbl19@mails.jlu.edu.cn
FU National Natural Science Foundation of China [41972267]; Graduate Innovation Fund of Jilin University
CR Bathrellos GD, 2017, SCI TOTAL ENVIRON, V575, P119, DOI 10.1016/j.scitotenv.2016.10.025
   Bathrellos GD, 2013, STOCH ENV RES RISK A, V27, P573, DOI 10.1007/s00477-012-0602-0
   Berger J, 2014, PHILOS PSYCHOL, V27, P829, DOI 10.1080/09515089.2013.771241
   Pham BT, 2020, CATENA, V195, P0, DOI 10.1016/j.catena.2020.104805
   Pham BT, 2020, GEOCARTO INT, V35, P1267, DOI 10.1080/10106049.2018.1559885
   Pham BT, 2018, INT J SEDIMENT RES, V33, P157, DOI 10.1016/j.ijsrc.2017.09.008
   Carpignano A, 2009, J RISK RES, V12, P513, DOI 10.1080/13669870903050269
   Chen W, 2018, B ENG GEOL ENVIRON, V77, P647, DOI 10.1007/s10064-017-1010-y
   Chen W, 2017, GEOMAT NAT HAZ RISK, V8, P950, DOI 10.1080/19475705.2017.1289250
   Corominas J, 2014, B ENG GEOL ENVIRON, V73, P209, DOI 10.1007/s10064-013-0538-8
   Dai FC, 2002, ENG GEOL, V64, P65, DOI 10.1016/S0013-7952(01)00093-X
   Delmonaco G., 2006, NEW METHODOLOGY MULT, V0, P0
   Bui DT, 2019, FORESTS, V10, P0, DOI 10.3390/f10090743
   Bui DT, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5919-4
   Dou J, 2020, LANDSLIDES, V17, P641, DOI 10.1007/s10346-019-01286-5
   Gallina V, 2016, J ENVIRON MANAGE, V168, P123, DOI 10.1016/j.jenvman.2015.11.011
   Gruber FE, 2013, NAT HAZARD EARTH SYS, V13, P2779, DOI 10.5194/nhess-13-2779-2013
   Guzzetti F, 2006, NAT HAZARD EARTH SYS, V6, P115, DOI 10.5194/nhess-6-115-2006
   Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007
   Hong HY, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4866-9
   Karaman H, 2014, NAT HAZARDS, V73, P685, DOI 10.1007/s11069-014-1099-2
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Chang KT, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-48773-2
   Liang Z, 2020, NAT HAZARD EARTH SYS, V20, P1287, DOI 10.5194/nhess-20-1287-2020
   Marzocchi W, 2012, NAT HAZARDS, V62, P551, DOI 10.1007/s11069-012-0092-x
   Merghadi A, 2020, EARTH-SCI REV, V207, P0, DOI 10.1016/j.earscirev.2020.103225
   Nguyen MD., 2019, OPEN CONSTR BUILD TE, V13, P178, DOI 10.2174/1874836801913010178
   Oh HJ, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7101000
   Oh HJ, 2011, COMPUT GEOSCI-UK, V37, P1264, DOI 10.1016/j.cageo.2010.10.012
   Peng SzuHsien, 2012, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V4, P403, DOI 10.4236/jgis.2012.45046
   Pourghasemi HR, 2013, J EARTH SYST SCI, V122, P349, DOI 10.1007/s12040-013-0282-2
   Pourghasemi HR, 2012, CATENA, V97, P71, DOI 10.1016/j.catena.2012.05.005
   Pradhan AMS, 2014, NAT HAZARDS, V72, P1189, DOI 10.1007/s11069-014-1065-z
   Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Rozos D, 2011, ENVIRON EARTH SCI, V63, P49, DOI 10.1007/s12665-010-0687-z
   SAATY TL, 1990, EUR J OPER RES, V48, P9, DOI 10.1016/0377-2217(90)90057-I
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Sun LW, 2019, GEOMAT NAT HAZ RISK, V10, P2009, DOI 10.1080/19475705.2019.1658648
   Tate E, 2010, ENVIRON PLANN B, V37, P646, DOI 10.1068/b35157
   Varnes D.J., 1984, LANDSLIDE HAZARD ZON, V0, P63
   [王佳佳 Wang Jiajia], 2014, 岩石力学与工程学报 CHINESE JOURNAL OF ROCK MECHANICS AND ENGINEERING, V33, P797
   Wang LJ, 2016, GEOSCI J, V20, P117, DOI 10.1007/s12303-015-0026-1
   Xu C, 2012, GEOMORPHOLOGY, V145, P70, DOI 10.1016/j.geomorph.2011.12.040
   Yang Q., 2019, J ENG GEOL, V27, P289
   Yang Q., 2018, GEOL CHINA, V45, P156
   Yao X, 2008, GEOMORPHOLOGY, V101, P572, DOI 10.1016/j.geomorph.2008.02.011
   Ye Z.N., 2020, J LIAONING TECH U NA, V39, P145, DOI 10.11956/j.issn.1008-0562.2020.02.007
NR 49
TC 8
Z9 8
U1 14
U2 48
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD APR 15
PY 2021
VL 10
IS 4
BP 
EP 
DI 10.3390/ijgi10040218
PG 25
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA RR4MN
UT WOS:000643074500001
DA 2023-04-26
ER

PT J
AU Ren, J
   Shao, Y
   Wan, H
   Xie, YH
   Campos, A
AF Ren, Jie
   Shao, Yang
   Wan, Heng
   Xie, Yanhua
   Campos, Adam
TI A two-step mapping of irrigated corn with multi-temporal MODIS and Landsat analysis ready data
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Multi-temporal classification; Landsat ARD; Gap-filling; Annual irrigation mapping
ID support vector machine; conterminous united-states; neural-network; ancillary data; random forest; cropland; classification; classifiers; fusion; trends
AB Timely and reliable information about irrigated croplands is important for crop water stress analysis and studies of water, energy, and food security. This study mapped irrigated and non-irrigated corn at 30 m resolution for the state of Nebraska using a two-step multi-temporal image classification of MODIS and Landsat Analysis Ready Data (ARD). Starting from the drought year of 2012, when there was a high contrast between irrigated and non-irrigated fields, we first conducted image classification using the 250 m MODIS multi-temporal NDVI data. Training pixels were automatically derived, based on counties with predominant irrigated and non-irrigated cornfields. The MODIS-derived irrigated vs. non-irrigated map was further spatially filtered to generate training data covering the entire Nebraska to support automated Landsat ARD classification, footprint-by-footprint. Three classification algorithms of multi-layer perceptron (MLP) neural network, Random Forest (RF), and Support Vector Machine (SVM) were implemented to classify all available Landsat ARD images within the growing season (i.e. May to November). Given the issues of scanline corrector (SLC) error and cloud contamination, the provisional Landsat-based classifications were finally gap-filled to generate a seamless statewise irrigation map guided by decreasing cross-validation accuracy. Pixel-wise accuracy assessments showed similar overall accuracies of 89.6%, 89.3%, and 90.0% for MLP, RF, and SVM, respectively. They are 3-6% higher than a commonly used gap-filing procedure based on valid (cloud free) pixel count for growing season images. The estimated areas of irrigated corn from Landsat-based mapping were consistent with the 2012 USDA county level census data (R-2 = 0.97 and RMSE = 37.70 km(2)). Using the 2012 Landsat-derived irrigation map and the USDA's annual Cropland Data Layer as inputs, we further developed training data for annual irrigation mapping between 2013 and 2018. Pixel-wise assessment of the 2016 map showed reasonable overall accuracies of 78.4-79.6% for three classification algorithms. The annual maps yielded R-2 of 0.94-0.98 and RMSE values of 37.70-57.62 km(2) for various mapping years compared with USDA county statistics. These results suggest that our proposed two-step analytical method has a high potential for automated annual irrigation mapping at 30 m spatial resolution (especially for the arid and semi-arid western U.S.), providing clear field boundaries and irrigation frequency information that are vitally important for accurate agricultural water use analysis.
C1 [Ren, Jie] Nanjing Univ, Sch Geog & Ocean Sci, 163 Xianlin Ave, Nanjing 210023, Peoples R China.
   [Shao, Yang; Wan, Heng; Campos, Adam] Virginia Tech, Geog Dept, Coll Nat Resources & Environm, Blacksburg, VA 24061 USA.
   [Xie, Yanhua] Univ Wisconsin, Ctr Sustainabil & Global Environm, Nelson Inst Environm Studies, 1710 Univ Ave, Madison, WI 53726 USA.
C3 Nanjing University; Virginia Polytechnic Institute & State University; University of Wisconsin System; University of Wisconsin Madison
RP Shao, Y (corresponding author), Virginia Tech, Geog Dept, Coll Nat Resources & Environm, Blacksburg, VA 24061 USA.
EM yshao@vt.edu
FU National Natural Science Foundation of China [41901231]
CR [Anonymous], 2014, ESTIMATED USE WATER, V0, P0
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Ban YF, 2015, ISPRS J PHOTOGRAMM, V103, P1, DOI 10.1016/j.isprsjprs.2015.01.001
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Brown JF, 2014, AGR SYST, V127, P28, DOI 10.1016/j.agsy.2014.01.004
   Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1350, DOI 10.1109/36.763299
   Deines JM, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111400
   Deines JM, 2017, GEOPHYS RES LETT, V44, P9350, DOI 10.1002/2017GL074071
   Dwyer JL, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091363
   Egorov AV, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040447
   Gao F, 2006, IEEE T GEOSCI REMOTE, V44, P2207, DOI 10.1109/TGRS.2006.872081
   Gao F, 2017, REMOTE SENS ENVIRON, V188, P9, DOI 10.1016/j.rse.2016.11.004
   Irmak S, 2000, AGRON J, V92, P1221, DOI 10.2134/agronj2000.9261221x
   Johnson B.B., 2011, NEBRASKA IRRIGATION, V0, P0
   Kenny J.F., 2017, ESTIMATED USE WATER, V0, P0
   Kucharik CJ, 2005, EARTH INTERACT, V9, P0, DOI 10.1175/EI098.1
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Lark TJ, 2017, INT J APPL EARTH OBS, V62, P224, DOI 10.1016/j.jag.2017.06.007
   Luan XB, 2018, HYDROL EARTH SYST SC, V22, P5111, DOI 10.5194/hess-22-5111-2018
   Maxwell SK, 2007, INT J REMOTE SENS, V28, P5339, DOI 10.1080/01431160601034902
   McDowell RW, 2011, AGR WATER MANAGE, V98, P877, DOI 10.1016/j.agwat.2010.12.014
   Ozdogan M, 2008, REMOTE SENS ENVIRON, V112, P3520, DOI 10.1016/j.rse.2008.04.010
   Pervez MS, 2010, REMOTE SENS-BASEL, V2, P2388, DOI 10.3390/rs2102388
   Noi PT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010018
   Pimentel D, 1998, ECOSYSTEMS, V1, P416, DOI 10.1007/s100219900035
   Pringle MJ, 2009, ISPRS J PHOTOGRAMM, V64, P654, DOI 10.1016/j.isprsjprs.2009.06.001
   Raczko E, 2017, EUR J REMOTE SENS, V50, P144, DOI 10.1080/22797254.2017.1299557
   Rasul G, 2016, CLIM POLICY, V16, P682, DOI 10.1080/14693062.2015.1029865
   Roy DP, 2008, REMOTE SENS ENVIRON, V112, P3112, DOI 10.1016/j.rse.2008.03.009
   Schmidt M, 2015, REMOTE SENS ENVIRON, V158, P156, DOI 10.1016/j.rse.2014.11.015
   Shao Y, 2016, ISPRS J PHOTOGRAMM, V122, P116, DOI 10.1016/j.isprsjprs.2016.10.009
   Shao Y, 2015, INT J APPL EARTH OBS, V38, P78, DOI 10.1016/j.jag.2014.12.017
   Shao Y, 2012, ISPRS J PHOTOGRAMM, V70, P78, DOI 10.1016/j.isprsjprs.2012.04.001
   Shao Y, 2011, IEEE J-STARS, V4, P336, DOI 10.1109/JSTARS.2010.2062173
   Shao Y, 2010, PHOTOGRAMM ENG REM S, V76, P73, DOI 10.14358/PERS.76.1.73
   Siebert S, 2010, HYDROL EARTH SYST SC, V14, P1863, DOI 10.5194/hess-14-1863-2010
   Thenkabail PS, 2009, INT J REMOTE SENS, V30, P3679, DOI 10.1080/01431160802698919
   Wan H, 2019, PHOTOGRAMM ENG REM S, V85, P715, DOI 10.14358/PERS.85.10.715
   Wardlow BD, 2014, GISCI REMOTE SENS, V51, P575, DOI 10.1080/15481603.2014.952546
   Wei XL, 2018, J HYDROL ENG, V23, P0, DOI 10.1061/(ASCE)HE.1943-5584.0001696
   White JC, 2014, CAN J REMOTE SENS, V40, P192, DOI 10.1080/07038992.2014.945827
   Xie YH, 2019, ISPRS J PHOTOGRAMM, V155, P136, DOI 10.1016/j.isprsjprs.2019.07.005
   Zheng BJ, 2013, SOIL SCI SOC AM J, V77, P1755, DOI 10.2136/sssaj2013.03.0108
   Zhu BW, 2020, J ADV MODEL EARTH SY, V12, P0, DOI 10.1029/2019MS001953
   Zhu LK, 2017, INT J APPL EARTH OBS, V58, P1, DOI 10.1016/j.jag.2017.01.012
NR 46
TC 7
Z9 7
U1 7
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUN 15
PY 2021
VL 176
IS 
BP 69
EP 82
DI 10.1016/j.isprsjprs.2021.04.007
EA APR 2021
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SJ4AV
UT WOS:000655474600007
DA 2023-04-26
ER

PT J
AU Wang, WB
   Li, Y
   Wang, SH
   Ye, XY
AF Wang, Wenbo
   Li, Yi
   Wang, Shaohua
   Ye, Xinyue
TI QA4GIS: A novel approach learning to answer GIS developer questions with API documentation
SO TRANSACTIONS IN GIS
LA English
DT Article
ID ontology
AB Community-based question answering websites have attracted more and more scholars and developers to discuss domain knowledge and software development. In this article, we focus on the GIS section of the Stack Exchange website and develop a novel approach, QA4GIS, a deep learning-based system for question answering tasks with a deep neural network (DNN) model to extract the representation of the query-API document pair. We use the LambdaMART model to rerank the candidate API documents. We begin with an empirical analysis of the questions and answers, demonstrating that API documents could answer 52.93% of the questions. Then we evaluate QA4GIS by comparing it with 10 other baselines. The experiment results show that QA4GIS can improve 21.39% on the MAP score and 22.34% on the MRR score compared with the best baseline SIF.
C1 [Wang, Wenbo; Li, Yi; Wang, Shaohua] New Jersey Inst Technol, Dept Informat, Newark, NJ 07102 USA.
   [Ye, Xinyue] Texas A&M Univ, Dept Landscape Architecture & Urban Planning, College Stn, TX 77840 USA.
C3 New Jersey Institute of Technology; Texas A&M University System; Texas A&M University College Station
RP Ye, XY (corresponding author), Texas A&M Univ, Dept Landscape Architecture & Urban Planning, College Stn, TX 77840 USA.; Wang, SH (corresponding author), New Jersey Inst Technol, Dept Informat, Ying Wu Coll Comp, Newark, NJ 07102 USA.
EM davidsw@njit.edu; xinyue.ye@tamu.edu
FU National Science Foundation [1937908]; Office of Integrative Activities; Office Of The Director [1937908] Funding Source: National Science Foundation
CR [Anonymous], 2005, P 2005 ACM CIKM INT, V0, P0, DOI DOI 10.1145/1099554.1099572
   Arora S, 2017, PROCESS BIOCHEM, V61, P12, DOI 10.1016/j.procbio.2017.06.009
   Bennett B, 2008, FRONT ARTIF INTEL AP, V183, P280, DOI 10.3233/978-1-58603-923-3-280
   Bridle JS., 1990, NEUROCOMPUTING, V0, PP227, DOI 10.1007/978-3-642-76153-9_28
   Brokos G.I., 2016, ARXIV160803905, V0, P0
   Burges C., 2005, P 22 INT C MACH LEAR, V0, PP89, DOI 10.1145/1102351.1102363
   Burges C.J., 2007, ADV NEURAL INFORM PR, V19, P193
   Cao Zhe, 2007, PROC INT C MACH LEAR, V0, PP129, DOI 10.1145/1273496.1273513
   Cliche M., 2017, P 11 INT WORKSH SEM, V0, PP573, DOI 10.18653/V1/S17-2094
   Cohen D, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1025, DOI 10.1145/3209978.3210141
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Cossock D, 2006, LECT NOTES ARTIF INT, V4005, P605, DOI 10.1007/11776420_44
   Crammer K, 2002, ADV NEUR IN, V14, P641
   Dai ZY, 2018, WSDM18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP126, DOI 10.1145/3159652.3159659
   Dehghani M, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP65, DOI 10.1145/3077136.3080832
   Devlin J, 2018, ARXIV, V0, P0
   Dwarampudi M., 2019, ARXIV190307288, V0, P0
   Elbassuoni S, 2011, LECT NOTES COMPUT SC, V6644, P62, DOI 10.1007/978-3-642-21064-8_5
   Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916
   Gao S, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING FOR GEOSPATIAL RESEARCH AND APPLICATION (COM.GEO), V0, PP106, DOI 10.1109/COMGEO.2013.18
   Guo JF, 2016, CIKM16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP701, DOI 10.1145/2983323.2983768
   Hamilton WL, 2018, ADV NEUR IN, V31, P0
   Hamzei E, 2020, LECT NOTES GEOINF CA, V0, PP3, DOI 10.1007/978-3-030-14745-7_1
   He H., 2019, ARXIV190900333, V0, P0
   Herbrich R, 2000, ADV NEUR IN, V0, P115
   Ho Chung Wu, 2008, ACM TRANSACTIONS ON INFORMATION SYSTEMS, V26, P0
   Jansen BJ, 2010, J AM SOC INF SCI TEC, V61, P1517, DOI 10.1002/asi.21358
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Jun Xu, 2007, 30TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P391
   Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), V0, P6769
   Li H., 2011, SYNTHESIS LECT HUMAN, V0, P0, DOI DOI 10.2200/S00348ED1V01Y201104HLT012
   Li H., 2009, ADV NEURAL INFORM PR, V22, P315
   Li H, 2011, IEICE T INF SYST, VE94D, P1854, DOI 10.1587/transinf.E94.D.1854
   Li J, 2018, INFORM SCIENCES, V448, P36, DOI 10.1016/j.ins.2018.03.014
   Li WW, 2019, ISPRS INT GEO-INF, V8, P0, DOI 10.3390/ijgi8110496
   MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 19), V0, PP1101, DOI 10.1145/3331184.3331317
   Mai GC, 2020, T GIS, V24, P623, DOI 10.1111/tgis.12629
   Mai GC, 2020, LECT NOTES GEOINF CA, V0, PP21, DOI 10.1007/978-3-030-14745-7_2
   Mikolov T, 2013, ADV NEURAL INFORM PR, V26, P3111, DOI 10.1162/JMLR.2003.3.4-5.951
   Mitra B, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1291, DOI 10.1145/3038912.3052579
   Mitra B, 2018, FOUND TRENDS INF RET, V13, P1, DOI 10.1561/1500000061
   Nassif H., 2016, P 1 WORKSH REPR LEAR, V0, P137
   NOGUEIRA R, 2017, P 2017 C EMP METH NA, V0, PP574, DOI 10.18653/V1/D17-1061
   Pennington J, 2014, P 2014 C EMP METH NA, V0, PP1532, DOI 10.3115/v1/d14-1162
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P1499
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Radford Alec., 2019, LANGUAGE MODELS ARE, V1, P9
   Rajpurkar P., 2016, ARXIV160605250, V0, P0, DOI DOI 10.18653/V1/D16-1264
   Robertson Stephen, 2009, FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL, V3, P333, DOI 10.1561/1500000019
   Robertson S. E., 1994, SIGIR 94. PROCEEDINGS OF THE SEVENTEENTH ANNUAL INTERNATIONAL ACM-SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P232
   Rosset C, 2018, ACM/SIGIR PROCEEDINGS 2018, V0, PP1193, DOI 10.1145/3209978.3210127
   Sanh Victor, 2019, ARXIV191001108, V0, P0
   Scheider S, 2019, INT J DIGIT EARTH, V12, P594, DOI 10.1080/17538947.2018.1470688
   Scheider S, 2020, J SPAT INT SCI, V0, PP167, DOI 10.5311/JOSIS.2020.20.555
   Scheider S, 2021, INT J DIGIT EARTH, V14, P1, DOI 10.1080/17538947.2020.1738568
   Schelter, 2020, ARXIV200710296, V0, P0
   Severyn A., 2016, ARXIV160401178, V0, P0
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP373, DOI 10.1145/2766462.2767738
   Shashua A, 2003, ADV NEURAL INFORM PR, V0, P961
   Taylor M., 2008, PROC INT C WEB SEARC, V0, PP77, DOI 10.1145/1341531.1341544
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, V0, P384
   Wu QA, 2010, INFORM RETRIEVAL, V13, P254, DOI 10.1007/s10791-009-9112-1
   Xia Fen, 2008, P 25 INT C MACH LEAR, V0, PP1192, DOI 10.1145/1390156.1390306
   Xiong CY, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP55, DOI 10.1145/3077136.3080809
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), V0, P2369
   Yisong Yue, 2007, 30TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P271
   Yunbo Cao, 2006, PROCEEDINGS OF THE TWENTY-NINTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, P186
   Zheng Zhaohui, 2008, ADV NEURAL INFORM PR, V0, P1697
NR 68
TC 2
Z9 2
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1361-1682
EI 1467-9671
J9 T GIS
JI Trans. GIS
PD OCT 15
PY 2021
VL 25
IS 5
BP 2675
EP 2700
DI 10.1111/tgis.12798
EA JUL 2021
PG 26
WC Geography
SC Geography
GA WJ9WC
UT WOS:000674329000001
DA 2023-04-26
ER

PT J
AU Song, Q
   Yang, F
   Yang, L
   Liu, C
   Hu, MJ
   Xia, LR
AF Song, Qing
   Yang, Fan
   Yang, Lu
   Liu, Chun
   Hu, Mengjie
   Xia, Lurui
TI Learning Point-Guided Localization for Detection in Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Detectors; Proposals; Object detection; Task analysis; Estimation; Pipelines; Convolutional neural network; deep learning; oriented object detection; remote sensing
ID region proposal; network; objects
AB Object detection in remote sensing images is challenging due to the dense distribution and arbitrary angle of the objects. It is a consensus that the oriented bounding box (OBB) is more suitable to represent the aerial objects. However, there are some extreme cases in regression-based OBB detection that make the regression target discontinuous, resulting in the poor performance. In this article, an analysis of the formats of OBB and the problems in its regression is presented, following with an exploration of transform localization from regression to keypoint estimation, which could be applied to avoid the problem of discontinuous regression target. Our novel method is called Object-wise Point-guided Localization Detector (OPLD). Continuously, a new prediction of center-point is introduced to refine the results, as the truncation problem caused by the cut graph. Lastly, in order to figure the problem of inconsistency between the localization quality and the classification score, both the endpoint scores and the classification score are adopted weighting as a result score. Experimental results are based on two widely used datasets, i.e., DOTA and HRSC2016. OPLD achieve 76.43% mAP and 78.35% mAP in OBB and horizontal bounding boxes tasks of DOTA-v1.0, which achieves state-of-the-art performance, respectively. Project page at https://github.com/yf19970118/OPLD-Pytorch.
C1 [Song, Qing; Yang, Fan; Yang, Lu; Liu, Chun; Hu, Mengjie] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Vis Lab, Beijing 100876, Peoples R China.
   [Xia, Lurui] Space Engn Univ, Beijing 101416, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Aerospace Engineering University
RP Song, Q (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Vis Lab, Beijing 100876, Peoples R China.
EM priv@bupt.edu.cn; yangfan1997@bupt.edu.cn; soeaver@bupt.edu.cn; chun.liu@bupt.edu.cn; mengjie.hu@bupt.edu.cn; xlrui522@163.com
CR Azimi SM, 2019, LECT NOTES COMPUT SC, V11363, P150, DOI 10.1007/978-3-030-20893-6_10
   Bodla N, 2017, IEEE I CONF COMP VIS, V0, PP5562, DOI 10.1109/ICCV.2017.593
   Carter T, 2017, ASHRAE CONF PAPER, V0, P0
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), V0, PP1796, DOI 10.1109/ICIT.2016.7475036
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003
   Ding J, 2019, PROC CVPR IEEE, V0, PP2844, DOI 10.1109/CVPR.2019.00296
   Duan KW, 2019, IEEE I CONF COMP VIS, V0, PP6568, DOI 10.1109/ICCV.2019.00667
   Fu C.-Y., 2017, DSSD DECONVOLUTIONAL, V0, P0
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Jiang SL, 2020, IEEE J-STARS, V13, P1068, DOI 10.1109/JSTARS.2020.2975606
   Kong T, 2016, PROC CVPR IEEE, V0, PP845, DOI 10.1109/CVPR.2016.98
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li CZ, 2019, IEEE IMAGE PROC, V0, PP3886, DOI 10.1109/ICIP.2019.8803521
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li YH, 2019, IEEE I CONF COMP VIS, V0, PP6053, DOI 10.1109/ICCV.2019.00615
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu ZK, 2017, IEEE IMAGE PROC, V0, P900
   Lu X, 2019, PROC CVPR IEEE, V0, PP7355, DOI 10.1109/CVPR.2019.00754
   Lu Yang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12357), V0, PP421, DOI 10.1007/978-3-030-58610-2_25
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrivastava A, 2016, PROC CVPR IEEE, V0, PP761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, ARXIV, V0, P0
   Singh B, 2018, PROC CVPR IEEE, V0, PP3578, DOI 10.1109/CVPR.2018.00377
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tian Z, 2019, IEEE I CONF COMP VIS, V0, PP9626, DOI 10.1109/ICCV.2019.00972
   Tian ZZ, 2019, IEEE J-STARS, V12, P3480, DOI 10.1109/JSTARS.2019.2924086
   Tychsen-Smith L, 2018, PROC CVPR IEEE, V0, PP6877, DOI 10.1109/CVPR.2018.00719
   Wang JQ, 2019, PROC CVPR IEEE, V0, PP2960, DOI 10.1109/CVPR.2019.00308
   Wang JW, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242930
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wang SL, 2018, PROC CVPR IEEE, V0, PP2589, DOI 10.1109/CVPR.2018.00274
   Wang YS, 2019, IEEE ACCESS, V7, P173855, DOI 10.1109/ACCESS.2019.2956569
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Xiang, 2018, P IEEE C COMP VIS PA, V15, P1745
   Xie SN, 2017, PROC CVPR IEEE, V0, PP5987, DOI 10.1109/CVPR.2017.634
   XU Y, 1900, DOI 10.1109/TPAMI.2020.2974745, V0, P0
   Yan JQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030286
   Yang L, 2019, PROC CVPR IEEE, V0, PP364, DOI 10.1109/CVPR.2019.00045
   Yang L, 2019, IEEE T NEUR NET LEAR, V30, P1744, DOI 10.1109/TNNLS.2018.2873722
   Yang X, 2019, IEEE I CONF COMP VIS, V0, PP8231, DOI 10.1109/ICCV.2019.00832
   Yang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010132
   Yang Z, 2019, IEEE I CONF COMP VIS, V0, PP9656, DOI 10.1109/ICCV.2019.00975
   Yu B, 2018, IEEE J-STARS, V11, P3252, DOI 10.1109/JSTARS.2018.2860989
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang S, 2018, PROC CVPR IEEE, V0, PP4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P1745, DOI 10.1109/LGRS.2018.2856921
   Zhaowei Cai, 2018, 2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION. PROCEEDINGS, V0, PP6154, DOI 10.1109/CVPR.2018.00644
   Zhou XY, 2019, PROC CVPR IEEE, V0, PP850, DOI 10.1109/CVPR.2019.00094
   Zhou XY, 2017, PROC CVPR IEEE, V0, PP2642, DOI 10.1109/CVPR.2017.283
   Zhu B, 2020, ARXIV200303570, V0, P0
   Zhu YX, 2020, IEEE T GEOSCI REMOTE, V58, P7247, DOI 10.1109/TGRS.2020.2981203
NR 61
TC 19
Z9 19
U1 4
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 1084
EP 1094
DI 10.1109/JSTARS.2020.3036685
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UR0EE
UT WOS:000696430600021
DA 2023-04-26
ER

PT J
AU Feizizadeh, B
   Alajujeh, KM
   Lakes, T
   Blaschke, T
   Omarzadeh, D
AF Feizizadeh, Bakhtiar
   Alajujeh, Keyvan Mohammadzade
   Lakes, Tobia
   Blaschke, Thomas
   Omarzadeh, Davoud
TI A comparison of the integrated fuzzy object-based deep learning approach and three machine learning techniques for land use/cover change monitoring and environmental impacts assessment
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Integrated approach; fuzzy object-base; deep learning CNN; machine learning algorithms; spatial uncertainty; land use; cover; change detection; urmia lake
ID convolutional neural-network; urmia lake basin; image-analysis; cover classification; random forest; optimization; segmentation; uncertainty; landslides; extraction
AB Recent improvements in the spatial, temporal, and spectral resolution of satellite images necessitate (semi-)automated classification and information extraction approaches. Therefore, we developed an integrated fuzzy object-based image analysis and deep learning (FOBIA-DL) approach for monitoring the land use/cover (LULC) and respective changes and compared it to three machine learning (ML) algorithms, namely the support vector machine (SVM), random forest (RF), and classification and regression tree (CART). We investigated LULC impacts on drought by analyzing Landsat satellite images from 1990 to 2020 for the Urmia Lake area in northern Iran. In the FOBIA-DL approach, following the initial segmentation steps, object features were identified for each LULC class. We then derived their respective attributes using fuzzy membership functions and deep convolutional neural networks (DCNNs), a deep learning method. The Fuzzy Synthetic Evaluation and Dempster-Shafer Theory (FSE-DST) also applied to validate and carryout the spatial uncertainties. Our results indicate that the FOBIA-DL, with an accuracy of 90.1% to 96.4% and a spatial certainty of 0.93 to 0.97, outperformed the other approaches, closely followed by the SVM. Our results also showed that the integration of Fuzzy-OBIA and DCNNs could improve the strength and robustness of the OBIA's decision rules, while the FSE-DST approach notably improved the spatial accuracy of the object-based classification maps. While object-based image analysis (OBIA) is already considered a paradigm shift in GIScience, the integration of OBIA with fuzzy and deep learning creates more flexibility and robust OBIA decision rules for image analysis and classification. This research integrated popular data-driven approaches and developed a novel methodology for image classification and spatial accuracy assessment. From the environmental perspective, the results of this research support lake restoration initiatives by decision-makers and authorities in applications such as drought mitigation, land use management and precision agriculture programs.
C1 [Feizizadeh, Bakhtiar; Alajujeh, Keyvan Mohammadzade; Omarzadeh, Davoud] Univ Tabriz, Dept Remote Sensing & GIS, Tabriz, Iran.
   [Feizizadeh, Bakhtiar; Lakes, Tobia] Humboldt Univ, Dept Geog, Lab Geoinformat Sci, Berlin, Germany.
   [Blaschke, Thomas] Univ Salzburg, Dept Geoinformat Z GIS, Salzburg, Austria.
C3 University of Tabriz; Humboldt University of Berlin; Salzburg University
RP Feizizadeh, B (corresponding author), Univ Tabriz, Dept Remote Sensing & GIS, Tabriz, Iran.; Feizizadeh, B (corresponding author), Humboldt Univ, Dept Geog, Lab Geoinformat Sci, Berlin, Germany.
EM Feizizadeh@Tabrizu.ac.ir
FU University of Tabriz [s818]; Alexander von Humboldt Foundation
CR Abedi Gheshlaghi H., 2021, GIS BASED ENSEMBLE M, V0, P0, DOI DOI 10.1007/s11069-021-04673-1
   AghaKouchak A, 2015, J GREAT LAKES RES, V41, P307, DOI 10.1016/j.jglr.2014.12.007
   Aksoy B, 2012, COMPUT GEOSCI-UK, V38, P87, DOI 10.1016/j.cageo.2011.05.010
   ALHASSAN V, 2019, NEURAL COMPUTING APP, V0, P0
   [Anonymous], 1994, REMOTE SENSING IMAGE, V0, P0
   Araki S, 2018, SCI TOTAL ENVIRON, V634, P1269, DOI 10.1016/j.scitotenv.2018.03.324
   ARONOFF S, 1985, PHOTOGRAMM ENG REM S, V51, P99
   BAATZ M., 2004, ECOGNITION PROFESSIO, V0, P0
   Balkanlou KR, 2020, SCI TOTAL ENVIRON, V716, P0, DOI 10.1016/j.scitotenv.2020.137100
   Baraldi P, 2010, RISK ANAL, V30, P1139, DOI 10.1111/j.1539-6924.2010.01416.x
   Betts MG, 2017, NATURE, V547, P441, DOI 10.1038/nature23285
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Blaschke T., 2015, REMOTELY SENSED DATA, V0, P0
   Blaschke T, 2014, IEEE J-STARS, V7, P4806, DOI 10.1109/JSTARS.2014.2350036
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   BUI DT, 2020, MATH PROBL ENG, V0, P0
   Cai YP, 2018, REMOTE SENS ENVIRON, V210, P35, DOI 10.1016/j.rse.2018.02.045
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Comber A, 2012, REMOTE SENS ENVIRON, V127, P237, DOI 10.1016/j.rse.2012.09.005
   Cresson R., 2018, IEEE GEOSCI REMOTE S, V16, P1
   Das M, 2016, IEEE GEOSCI REMOTE S, V13, P1984, DOI 10.1109/LGRS.2016.2619984
   Delju AH, 2013, THEOR APPL CLIMATOL, V111, P285, DOI 10.1007/s00704-012-0651-9
   Doyle C, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030379
   Dragut L, 2010, INT J GEOGR INF SCI, V24, P859, DOI 10.1080/13658810903174803
   Dutta D, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7645-3
   Ebrahimy H, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app112110309
   Eisank C, 2014, GEOMORPHOLOGY, V214, P452, DOI 10.1016/j.geomorph.2014.02.028
   FEIZIZADEH B, 2021, J ENVIRON PLANN MAN, V0, P0
   Feizizadeh B, 2021, CATENA, V198, P0, DOI 10.1016/j.catena.2020.105073
   Feizizadeh B, 2019, CAN J REMOTE SENS, V45, P847, DOI 10.1080/07038992.2019.1704622
   Feizizadeh B, 2018, IEEE GEOSCI REMOTE S, V15, P18, DOI 10.1109/LGRS.2017.2763979
   Feizizadeh B, 2017, GEOMORPHOLOGY, V293, P240, DOI 10.1016/j.geomorph.2017.06.002
   Feizizadeh B, 2017, J ENVIRON PLANN MAN, V60, P2013, DOI 10.1080/09640568.2016.1269643
   Feizizadeh B, 2014, INT J GEOGR INF SCI, V28, P610, DOI 10.1080/13658816.2013.869821
   Foody G.M., 2006, 7 INT S SPAT ACC ASS, V0, PP18, DOI 10.1016/J.JHSB.2006.07.007
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Garajeh MK, 2021, SCI TOTAL ENVIRON, V778, P0, DOI 10.1016/j.scitotenv.2021.146253
   Ghasemi M, 2021, EARTH SCI INFORM, V14, P1745, DOI 10.1007/s12145-021-00617-2
   Ghorbanzadeh O, 2021, EUR J REMOTE SENS, V54, P127, DOI 10.1080/22797254.2020.1759456
   Ghorbanzadeh O, 2019, J ECOTOURISM, V18, P261, DOI 10.1080/14724049.2019.1597876
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Guirado E, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121220
   Hamidi-Razi H, 2019, J GREAT LAKES RES, V45, P87, DOI 10.1016/j.jglr.2018.10.002
   Henry CJ, 2019, INT J REMOTE SENS, V40, P4416, DOI 10.1080/01431161.2018.1563840
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hofmann P, 2011, INT J REMOTE SENS, V32, P7359, DOI 10.1080/01431161.2010.523727
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   JANSSEN LLF, 1994, PHOTOGRAMM ENG REM S, V60, P419
   Kamran KV, 2021, APPL GEOMAT, V13, P837, DOI 10.1007/s12518-021-00393-0
   Kassouk Z, 2014, GEOMORPHOLOGY, V221, P18, DOI 10.1016/j.geomorph.2014.04.022
   Kucharczyk M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122012
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lang S., 2010, INT ARCH PHOTOGRAM R, V38, P4
   LEES B, 2006, APPL GIS, V2, P0
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu ZG, 2017, IEEE T SYST MAN CY-S, V47, P2783, DOI 10.1109/TSMC.2016.2622247
   Liu ZG, 2015, KNOWL-BASED SYST, V74, P119, DOI 10.1016/j.knosys.2014.11.013
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma L, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6020051
   Maboudi M, 2018, ISPRS J PHOTOGRAMM, V138, P151, DOI 10.1016/j.isprsjprs.2017.11.014
   Mardi AH, 2018, SCI TOTAL ENVIRON, V633, P42, DOI 10.1016/j.scitotenv.2018.03.148
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Mas JF, 2017, EUR J REMOTE SENS, V50, P626, DOI 10.1080/22797254.2017.1387505
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   Moradpour H, 2022, GEOCARTO INT, V37, P1971, DOI 10.1080/10106049.2020.1810327
   Naboureh A, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-3012-2
   Najafi P, 2018, INT J REMOTE SENS, V39, P6117, DOI 10.1080/01431161.2018.1454621
   Najafi P, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13050937
   Najafi P, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212583
   Namatevs I., 2018, INFORM TECHNOL MANAG, V20, P40, DOI 10.1515/ITMS-2017-0007
   Hoan NT, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121965
   Nitze I, 2015, INT J APPL EARTH OBS, V34, P136, DOI 10.1016/j.jag.2014.08.001
   OMARZADEH D, 2021, J ENVIRON PLANN MAN, V0, P0
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sarmento P, 2008, PROCEEDINGS OF THE 8TH INTERNATIONAL SYMPOSIUM ON SPATIAL ACCURACY ASSESSMENT IN NATURAL RESOURCES AND ENVIRONMENTAL SCIENCES, VOL I, P348
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Shokati B, 2019, J ENVIRON PLANN MAN, V62, P517, DOI 10.1080/09640568.2018.1427561
   Singh P, 2016, ADV INTELL SYST, V434, P551, DOI 10.1007/978-81-322-2752-6_54
   Sudmanns M, 2020, INT J DIGIT EARTH, V13, P832, DOI 10.1080/17538947.2019.1585976
   Talukdar S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071135
   Tong X.-Y., 2018, ARXIV180705713, V0, P0
   Tsagkatakis G, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19183929
   Vetrivel A, 2018, ISPRS J PHOTOGRAMM, V140, P45, DOI 10.1016/j.isprsjprs.2017.03.001
   Vieira S, 2017, NEUROSCI BIOBEHAV R, V74, P58, DOI 10.1016/j.neubiorev.2017.01.002
   Woznicki SA, 2019, SCI TOTAL ENVIRON, V647, P942, DOI 10.1016/j.scitotenv.2018.07.353
   Xia M, 2020, INT J REMOTE SENS, V41, P7779, DOI 10.1080/01431161.2020.1763511
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yu XR, 2017, GISCI REMOTE SENS, V54, P741, DOI 10.1080/15481603.2017.1323377
   Zhao WZ, 2017, ISPRS J PHOTOGRAMM, V132, P48, DOI 10.1016/j.isprsjprs.2017.08.011
   Zhou W, 2008, INT J REMOTE SENS, V29, P3119, DOI 10.1080/01431160701469065
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 97
TC 11
Z9 11
U1 6
U2 27
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD NOV 17
PY 2021
VL 58
IS 8
BP 1543
EP 1570
DI 10.1080/15481603.2021.2000350
EA DEC 2021
PG 28
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA XN8NW
UT WOS:000724069000001
DA 2023-04-26
ER

PT J
AU Hasegawa, Y
   Haga, A
   Sakata, D
   Kanazawa, Y
   Tominaga, M
   Sasaki, M
   Imae, T
   Nakagawa, K
AF Hasegawa, Yu
   Haga, Akihiro
   Sakata, Dousatsu
   Kanazawa, Yuki
   Tominaga, Masahide
   Sasaki, Motoharu
   Imae, Toshikazu
   Nakagawa, Keiichi
TI Estimation of X-ray Energy Spectrum of Cone-Beam Computed Tomography Scanner Using Percentage Depth Dose Measurements and Machine Learning Approach
SO JOURNAL OF THE PHYSICAL SOCIETY OF JAPAN
LA English
DT Article
ID monte-carlo-simulation; reconstruction; radiation; resolution
AB This study presents, for the first time, a method to indirectly estimate the cone-beam computed tomography (CBCT) x-ray spectrum in the diagnostic energy range from the percentage depth dose (PDD) using machine learning (ML) algorithms. Assuming that the measured PDD is a weighted mean of monochromatic PDDs (mPDDs) resulting from monochromatic x-ray energies, mPDDs from the diagnostic energy range of 10 to 140 keV are simulated at 1 keV intervals by Monte Carlo (MC) calculation. Then, x-ray spectrum prediction models are constructed using two different ML approaches, namely the artificial neural network (ANN) based on a generative model and a maximum a posterior (MAP) model. Both models account for more than 80% of the x-ray photons obtained by full MC simulations in commercial CBCT systems. The present method is expected to be applied into a beam hardening reduction in CBCT reconstruction, CBCT dose calculation, and a material decomposition which require exact information on the x-ray energy spectrum.
C1 [Hasegawa, Yu; Haga, Akihiro; Kanazawa, Yuki; Tominaga, Masahide; Sasaki, Motoharu] Tokushima Univ, Grad Sch Biomed Sci, Tokushima 7708503, Japan.
   [Sakata, Dousatsu] Inst Quantum Med Sci, Dept Accelerator & Med Phys, Chiba 2638555, Japan.
   [Imae, Toshikazu; Nakagawa, Keiichi] Univ Tokyo Hosp, Dept Radiol, Bunkyo, Tokyo 1138655, Japan.
C3 Tokushima University
RP Haga, A (corresponding author), Tokushima Univ, Grad Sch Biomed Sci, Tokushima 7708503, Japan.
EM haga@tokushima-u.ac.jp
FU KAKENHI [19K08201]; Grants-in-Aid for Scientific Research [19K08201] Funding Source: KAKEN
CR Abadi M., 2016, TENSORFLOW LARGE SCA, V0, P0
   Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8
   Allison J, 2006, IEEE T NUCL SCI, V53, P270, DOI 10.1109/TNS.2006.869826
   Allison J, 2016, NUCL INSTRUM METH A, V835, P186, DOI 10.1016/j.nima.2016.06.125
   ALVAREZ RE, 1976, PHYS MED BIOL, V21, P733, DOI 10.1088/0031-9155/21/5/002
   [Anonymous], 2006, MACH LEARN, V0, P0
   Armbruster B, 2004, PHYS MED BIOL, V49, P5087, DOI 10.1088/0031-9155/49/22/005
   Bazalova M, 2007, PHYS MED BIOL, V52, P5945, DOI 10.1088/0031-9155/52/19/015
   BIRCH R, 1979, PHYS MED BIOL, V24, P505, DOI 10.1088/0031-9155/24/3/002
   COLEMAN AJ, 1985, PHYS MED BIOL, V30, P1251, DOI 10.1088/0031-9155/30/11/007
   Duan XH, 2011, MED PHYS, V38, P993, DOI 10.1118/1.3547718
   Duisterwinkel HA, 2015, MED PHYS, V42, P1884, DOI 10.1118/1.4915497
   FRANCOIS P, 1993, MED PHYS, V20, P1695, DOI 10.1118/1.596956
   Ha W, 2019, MED PHYS, V46, P81, DOI 10.1002/mp.13257
   Hioki K, 2014, PHYS MED BIOL, V59, P7297, DOI 10.1088/0031-9155/59/23/7297
   Jaffray DA, 2002, INT J RADIAT ONCOL, V53, P1337, DOI 10.1016/S0360-3016(02)02884-5
   Kong HH, 2018, IEEE ACCESS, V6, P21314, DOI 10.1109/ACCESS.2018.2820500
   Leinweber C, 2017, MED PHYS, V44, P6183, DOI 10.1002/mp.12607
   Letourneau D, 2005, RADIOTHER ONCOL, V75, P279, DOI 10.1016/j.radonc.2005.03.001
   Long Y, 2014, IEEE T MED IMAGING, V33, P1614, DOI 10.1109/TMI.2014.2320284
   Maeda K, 2005, MED PHYS, V32, P1542, DOI 10.1118/1.1921647
   MATSCHEKO G, 1989, PHYS MED BIOL, V34, P185, DOI 10.1088/0031-9155/34/2/003
   Perkhounkov B, 2016, PROC SPIE, V9783, P0, DOI 10.1117/12.2217100
   Posiewnik M, 2019, PHYS MEDICA, V59, P13, DOI 10.1016/j.ejmp.2019.02.014
   Punnoose J, 2016, MED PHYS, V43, P4711, DOI 10.1118/1.4955438
   Ruth C, 1997, MED PHYS, V24, P695, DOI 10.1118/1.598159
   Sakata D, 2017, PHYS MEDICA, V39, P9, DOI 10.1016/j.ejmp.2017.06.010
   Sidky EY, 2005, J APPL PHYS, V97, P0, DOI 10.1063/1.1928312
   Silberstein L, 1932, J OPT SOC AM, V22, P265, DOI 10.1364/JOSA.22.000265
   Sonoda S, 2017, APPL COMPUT HARMON A, V43, P233, DOI 10.1016/j.acha.2015.12.005
   Spezi E, 2009, MED PHYS, V36, P127, DOI 10.1118/1.3031113
   Stampanoni M, 2001, MED PHYS, V28, P325, DOI 10.1118/1.1350585
   Taguchi K, 2013, MED PHYS, V40, P0, DOI 10.1118/1.4820371
   Taleei R, 2009, APPL RADIAT ISOTOPES, V67, P266, DOI 10.1016/j.apradiso.2008.10.007
   Waggener RG, 1999, MED PHYS, V26, P1269, DOI 10.1118/1.598622
   Wu WW, 2019, PHYS MED BIOL, V64, P0, DOI 10.1088/1361-6560/ab51db
   Zhao W, 2017, J MED IMAGING, V4, P0, DOI 10.1117/1.JMI.4.2.023506
NR 37
TC 4
Z9 4
U1 0
U2 3
PU PHYSICAL SOC JAPAN
PI TOKYO
PA YUSHIMA URBAN BUILDING 5F, 2-31-22 YUSHIMA, BUNKYO-KU, TOKYO, 113-0034, JAPAN
SN 0031-9015
EI 
J9 J PHYS SOC JPN
JI J. Phys. Soc. Jpn.
PD JUL 15
PY 2021
VL 90
IS 7
BP 
EP 
DI 10.7566/JPSJ.90.074801
PG 7
WC Physics, Multidisciplinary
SC Physics
GA TD7XG
UT WOS:000669534200028
DA 2023-04-26
ER

PT J
AU Yu, DW
   Ji, SP
   Liu, J
   Wei, SQ
AF Yu, Dawen
   Ji, Shunping
   Liu, Jin
   Wei, Shiqing
TI Automatic 3D building reconstruction from multi-view aerial images with deep learning
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE 3D building reconstruction; Multi-view aerial images; Convolutional neural network; Earth surface reconstruction; Building segmentation; Building footprint regularization
ID semantic segmentation; dsm; models; extraction; networks
AB The study presented in this paper introduced a new fully automatic three-dimensional building reconstruction method that can generate first level of detail (LoD 1) building models from multi-view aerial images without any assistance from other data. The accuracy and completeness of our reconstructed models have approached that of manually delineated models to a large extent. The presented method consists of three parts: (1) efficient dense matching and Earth surface reconstruction, (2) reliable building footprint extraction and polygon regularization, and (3) highly accurate height inference of building roofs and bases. First, our novel deep learning-based multi-view matching method, composed of a convolutional neural network, gated recurrent convolutions, and a multi-scale pyramid matching structure, is used to reconstruct the digital surface model (DSM) and digital orthophoto map (DOM) efficiently without generating epipolarly rectified images. Second, our three-stage 2D building extraction method is introduced to deliver reliable and accurate building contours. Deep-learning based segmentation, assisted with DSM, is used to segment buildings from backgrounds; and the generated building maps are fused with a terrain classification algorithm to reach better segmentation results. A polygon regularization algorithm and a level set algorithm are thereafter employed to transfer the binary segmentation maps to structured vector-form building polygons. Third, a novel method is introduced to infer the height of building roofs and bases using adaptive local terrain filtering and neighborhood buffer analysis. We tested our method on a large experimental area that covered 2284 aerial images and 782 various types of buildings. Our results as far as correctness and completeness exceeded the results of other similar methods in a between-method comparison by at least 15% for individual 3D building models with many of them comparable to manual delineation results.
C1 [Yu, Dawen; Ji, Shunping; Liu, Jin; Wei, Shiqing] Wuhan Univ, Sch Remote Sensing Informat & Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Ji, SP (corresponding author), Wuhan Univ, Sch Remote Sensing Informat & Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
EM yudawen@whu.edu.cn; jishunping@whu.edu.cn; wei_sq@whu.edu.cn
FU National Key Research and Development Program of China [2018YFB0505003]; Huawei Company [YBN2018095106]
CR Aanaes H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9
   Alidoost F, 2015, INT ARCH PHOTOGRAMM, V41, P43, DOI 10.5194/isprsarchives-XL-1-W5-43-2015
   Alidoost F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192219
   Anders, 1996, INT ARCH PHOTOGRAM R, V31, P285
   [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   [Anonymous], 2012, ISPRS ANN PHOTOGRAM, V0, P0
   Arefi H, 2013, REMOTE SENS-BASEL, V5, P1681, DOI 10.3390/rs5041681
   Bethmann F, 2017, PFG-J PHOTOGRAMM REM, V85, P349, DOI 10.1007/s41064-017-0034-z
   Bittner K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121926
   Bittner K, 2018, IEEE J-STARS, V11, P2615, DOI 10.1109/JSTARS.2018.2849363
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, V0, P0, DOI DOI 10.5244/C.25.14
   Bulatov D, 2014, ISPRS J PHOTOGRAMM, V93, P157, DOI 10.1016/j.isprsjprs.2014.02.016
   Cao ZY, 2019, IEEE GEOSCI REMOTE S, V16, P1766, DOI 10.1109/LGRS.2019.2907009
   Cavegn S., 2015, EXTRACTING 3D URBAN, V0, P1
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang JR, 2018, PROC CVPR IEEE, V0, PP5410, DOI 10.1109/CVPR.2018.00567
   Chen D., 2020, ARXIV200309934, V0, P0
   Collins RT, 1996, PROC CVPR IEEE, V0, PP358, DOI 10.1109/CVPR.1996.517097
   Douglas D. H., 1973, CARTOGRAPHICA INT J, V10, P112, DOI 10.3138/FM57-6770-U75U-7727
   Geiger A., 2012, C COMP VIS PATT REC, V0, P0
   Groger G, 2012, ISPRS J PHOTOGRAMM, V71, P12, DOI 10.1016/j.isprsjprs.2012.04.004
   Groger G., 2007, OPENGIS CITY GEOGRAP, V0, P0
   Gu XD, 2020, PROC CVPR IEEE, V0, PP2492, DOI 10.1109/CVPR42600.2020.00257
   Haala N, 2010, ISPRS J PHOTOGRAMM, V65, P570, DOI 10.1016/j.isprsjprs.2010.09.006
   Hammoudi K, 2011, SENSORS-BASEL, V11, P228, DOI 10.3390/s110100228
   Hansen, 2005, INT ARCH PHOTOGRAM 3, V36, P0
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jayaraj P., 2018, INT ARCH PHOTOGRAMM, V5, P175, DOI 10.5194/isprs-archives-XLII-5-175-2018
   Ji SP, 2019, INT J REMOTE SENS, V40, P3308, DOI 10.1080/01431161.2018.1528024
   Jia B, 2012, IEEE IMAGE PROC, V0, PP1781, DOI 10.1109/ICIP.2012.6467226
   Kendall A, 2017, IEEE I CONF COMP VIS, V0, PP66, DOI 10.1109/ICCV.2017.17
   Li ML, 2016, COMPUT GRAPH-UK, V54, P84, DOI 10.1016/j.cag.2015.07.004
   Liu J, 2020, PROC CVPR IEEE, V0, PP6049, DOI 10.1109/CVPR42600.2020.00609
   Lorensen W.E., 1987, P 14 ANN C COMPUTER, V0, PP163, DOI 10.1145/37402.37422
   Moreira JMM, 2013, INT ARCH PHOTOGRAMM, V40-1, P213
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   MALIHI S, 2016, ISPRS INT ARCH PHO B, V3, P71
   Maltezos E, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042620
   Mayer H., 2019, ISPRS ANN PHOTOGRAM, V4, P0
   Mayer N, 2016, PROC CVPR IEEE, V0, PP4040, DOI 10.1109/CVPR.2016.438
   McClune AP, 2016, INT ARCH PHOTOGRAMM, V41, P641, DOI 10.5194/isprsarchives-XLI-B3-641-2016
   Mousa YA, 2019, PHOTOGRAMM REC, V34, P85, DOI 10.1111/phor.12275
   Nan LL, 2017, IEEE I CONF COMP VIS, V0, PP2372, DOI 10.1109/ICCV.2017.258
   Neumann U., 2010, COMP VIS ECCV 2010 3, V0, P0
   Perko R, 2015, ISPRS ANN PHOTO REM, V2-3, P165, DOI 10.5194/isprsannals-II-3-W4-165-2015
   Pohl Melanie, 2016, VISIGRAPP 2016. 11TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, V0, P59
   Pohl M, 2017, LECT NOTES COMPUT SC, V10270, P3, DOI 10.1007/978-3-319-59129-2_1
   Qin Z., 2018, INT ARCH PHOTOGRAMME, V42, P0
   Rothermel M., 2012, P P LC3D WORKSH BERL, V8, P0
   Rottensteiner F, 2014, ISPRS J PHOTOGRAMM, V93, P256, DOI 10.1016/j.isprsjprs.2013.10.004
   Rutzinger M, 2009, IEEE J-STARS, V2, P11, DOI 10.1109/JSTARS.2009.2012488
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Schonberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Shamos M.I., 1985, COMPUTATIONAL GEOMET, V0, P0
   Stucker C., 2020, P IEEE CVF C COMP VI, V0, P184
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tack F, 2012, ISPRS J PHOTOGRAMM, V67, P52, DOI 10.1016/j.isprsjprs.2011.10.003
   Wei SQ, 2020, IEEE T GEOSCI REMOTE, V58, P2178, DOI 10.1109/TGRS.2019.2954461
   Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131
   Wu ZY, 2019, IEEE I CONF COMP VIS, V0, PP7483, DOI 10.1109/ICCV.2019.00758
   Xiong B, 2015, ISPRS J PHOTOGRAMM, V101, P275, DOI 10.1016/j.isprsjprs.2015.01.002
   Xu HF, 2020, PROC CVPR IEEE, V0, PP1956, DOI 10.1109/CVPR42600.2020.00203
   Yan YM, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17020222
   Yang, 2019, IEEE ACCESS, V7, P0
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yao Y, 2019, PROC CVPR IEEE, V0, PP5520, DOI 10.1109/CVPR.2019.00567
   Yu D., 2020, ISPRS INT ARCH PHOTO, V43, P541, DOI 10.5194/isprs-archives-XLIII-B2-2020-541-2020
   Zbontar J, 2016, J MACH LEARN RES, V17, P0
   Zeng CQ, 2014, INT J REMOTE SENS, V35, P7614, DOI 10.1080/01431161.2014.975375
   Zhang FH, 2019, PROC CVPR IEEE, V0, PP185, DOI 10.1109/CVPR.2019.00027
NR 72
TC 39
Z9 42
U1 39
U2 114
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN 15
PY 2021
VL 171
IS 
BP 155
EP 170
DI 10.1016/j.isprsjprs.2020.11.011
PG 16
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PN3UD
UT WOS:000604406500011
DA 2023-04-26
ER

PT J
AU Bravo, DT
   Lima, GA
   Alves, WAL
   Colombo, VP
   Djogbenou, L
   Pamboukian, SVD
   Quaresma, CC
   de Araujo, SA
AF Bravo, Daniel Trevisan
   Lima, Gustavo Araujo
   Luz Alves, Wonder Alexandre
   Colombo, Vitor Pessoa
   Djogbenou, Luc
   Denser Pamboukian, Sergio Vicente
   Quaresma, Cristiano Capellani
   de Araujo, Sidnei Alves
TI Automatic detection of potential mosquito breeding sites from aerial images acquired by unmanned aerial vehicles
SO COMPUTERS ENVIRONMENT AND URBAN SYSTEMS
LA English
DT Article
DE Vector control; Mosquito; Unmanned aerial vehicle; Objects detection; Convolutional neural network; Support vector machine; Bag of visual words
ID dengue
AB The World Health Organization (WHO) has stated that effective vector control measures are critical to achieving and sustaining reduction of vector-borne infectious disease incidence. Unmanned aerial vehicles (UAVs), popularly known as drones, can be an important technological tool for health surveillance teams to locate and eliminate mosquito breeding sites in areas where vector-borne diseases such as dengue, zika, chikungunya or malaria are endemic, since they allow the acquisition of aerial images with high spatial and temporal resolution. Currently, though, such images are often analyzed through manual processes that are excessively time-consuming when implementing vector control interventions. In this work we propose computational approaches for the automatic identification of objects and scenarios suspected of being potential mosquito breeding sites from aerial images acquired by drones. These approaches were developed using convolutional neural networks (CNN) and Bag of Visual Words combined with the Support Vector Machine classifier (BoVW + SVM), and their performances were evaluated in terms of mean Average Precision - mAP-50. In the detection of objects using a CNN YOLOv3 model the rate of 0.9651 was obtained for the mAP-50. In the detection of scenarios, in which the performances of BoVW+SVM and a CNN YOLOv3 were compared, the respective rates of 0.6453 and 0.9028 were obtained. These findings indicate that the proposed CNN-based approaches can be used to identify potential mosquito breeding sites from images acquired by UAVs, providing substantial improvements in vector control programs aiming the reduction of mosquito-breeding sources in the environment.
C1 [Bravo, Daniel Trevisan; Lima, Gustavo Araujo; Luz Alves, Wonder Alexandre; de Araujo, Sidnei Alves] Nove Julho Univ, Informat & Knowledge Management Postgrad Program, Vergueiro St 235-249, BR-235249 Sao Paulo, SP, Brazil.
   [Colombo, Vitor Pessoa] Ecole Polytech Fed Lausanne, Communaute Etud Amenagement Terr CEAT, Batiment BP Stn 16, CH-1015 Lausanne, VD, Switzerland.
   [Djogbenou, Luc] Univ Abomey Calavi UAC, Ctr Rech Lutte Malad Infect CReMIT, Campus Abomey Calavi BP 526, Cotonou, Benin.
   [Denser Pamboukian, Sergio Vicente] Univ Prebiteriana Mackenzie, Sci & Geospatial Applicat Postgrad Program, Consolacao St,896 Bldg 45,7th Floor Consolacao, Sao Paulo, SP, Brazil.
   [Quaresma, Cristiano Capellani] Nove Julho Univ, Smart & Sustainable Cities Postgrad Program, Vergueiro St 235-249, BR-235249 Sao Paulo, SP, Brazil.
C3 Universidade Nove de Julho; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Abomey Calavi; Universidade Presbiteriana Mackenzie; Universidade Nove de Julho
RP de Araujo, SA (corresponding author), Nove Julho Univ, Informat & Knowledge Management Postgrad Program, Vergueiro St 235-249, BR-235249 Sao Paulo, SP, Brazil.
EM saraujo@uni9.pro.br
FU FAPESP -Fundacao de Amparo a Pesquisa do Estado de Sao Paulo [2019/05748-0]; CNPq -Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
CR Agrawal A, 2014, PROC SPIE, V9089, P0, DOI 10.1117/12.2058121
   Albawi S, 2017, I C ENG TECHNOL, V0, P0
   Ammour N, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040312
   Araujo RV, 2015, BRAZ J INFECT DIS, V19, P146, DOI 10.1016/j.bjid.2014.10.004
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Barrera R, 1995, BULL PAN AM HEALTH ORGAN, V29, P193
   Bejiga MB, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9020100
   Benjdira B, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON UNMANNED VEHICLE SYSTEMS-OMAN (UVS), V0, P0
   Bhatt S, 2013, NATURE, V496, P504, DOI 10.1038/nature12060
   Bhola R, 2018, J ENVIRON MANAGE, V206, P1233, DOI 10.1016/j.jenvman.2017.09.036
   Carrasco-Escobar G, 2019, PLOS NEGLECT TROP D, V13, P0, DOI 10.1371/journal.pntd.0007105
   Colwell RN, 1997, MANUAL PHOTOGRAPHIC, V0, P3
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   de Araujo SA, 2011, INTEGR COMPUT-AID E, V18, P75, DOI 10.3233/ICA-2011-0358
   De Silva PM, 2012, J TROP MED-US, V2012, P0, DOI 10.1155/2012/819563
   DECEA-Department of Airspace Control, 2021, 10040 DECEA ICA, V0, P0
   Diniz M. T. M., 2018, REV GEONORDESTE, V2, P196
   Espinosa MO, 2016, GEOSPATIAL HEALTH, V11, P307, DOI 10.4081/gh.2016.471
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Grubesic TH, 2018, LANDSCAPE URBAN PLAN, V169, P148, DOI 10.1016/j.landurbplan.2017.09.001
   Haas-Stapleton EJ, 2019, J AM MOSQUITO CONTR, V35, P228, DOI 10.2987/19-6835.1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hardy A, 2017, PARASITE VECTOR, V10, P0, DOI 10.1186/s13071-017-1973-3
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Kabaria CW, 2017, MALARIA J, V16, P0, DOI 10.1186/s12936-017-1694-2
   Keiser J, 2004, AM J TROP MED HYG, V71, P118, DOI 10.4269/ajtmh.2004.71.118
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Madzlan F, 2016, PROCD SOC BEHV, V234, P164, DOI 10.1016/j.sbspro.2016.10.231
   Mehra M., 2016, IEEE INT C SENS COMM, V0, PP1, DOI 10.1109/SECONW.2016.7746808
   Nelson J, 2019, TECHNOL SOC, V59, P0, DOI 10.1016/j.techsoc.2019.04.007
   Passos W. L., 2018, P 36 BRAZ S TEL SIGN, V0, P1
   Pisner D.A., 2019, MACHINE LEARNING MET, V0, P101
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, V0, P185
   PMSP-Prefeitura Municipal de S ~ao Paulo, 2016, PREF PROM MOB COMB A, V0, P0
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Schafrick NH, 2013, AM J TROP MED HYG, V89, P758, DOI 10.4269/ajtmh.12-0485
   Simmons CP, 2012, NEW ENGL J MED, V366, P1423, DOI 10.1056/NEJMra1110265
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Tun-Lin W, 2009, TROP MED INT HEALTH, V14, P1143, DOI 10.1111/j.1365-3156.2009.02341.x
   UN-Habitat, 2016, URBANIZATION DEV EME, V0, P0
   Warren M., 1999, 71 ENV HLTH PROJ, V0, P0
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   WHO, 2011, WORLD MALARIA REPORT 2011, V0, P1
   World Health Organisation (WHO), 2012, GLOB STRAT DENG PREV, V0, P0
   World Health Organization, 2021, LASSA FEVER, V0, P0
   World Health Organization, 2017, KEEP VECT OUT HOUS I, V0, P0
   Xu YZ, 2017, J ADV TRANSPORT, V0, P0, DOI DOI 10.1155/2017/2823617
   Xu ZF, 2020, APPL INTELL, V50, P4670, DOI 10.1007/s10489-020-01818-w
   Yan Xia, 2020, JOURNAL OF PHYSICS: CONFERENCE SERIES, V1550, P0, DOI 10.1088/1742-6596/1550/3/032075
   Yi Zhang, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
NR 55
TC 4
Z9 4
U1 2
U2 11
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0198-9715
EI 1873-7587
J9 COMPUT ENVIRON URBAN
JI Comput. Environ. Urban Syst.
PD NOV 15
PY 2021
VL 90
IS 
BP 
EP 
DI 10.1016/j.compenvurbsys.2021.101692
EA AUG 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research & Management Science; Regional & Urban Planning
SC Computer Science; Engineering; Environmental Sciences & Ecology; Geography; Operations Research & Management Science; Public Administration
GA UZ7PN
UT WOS:000702393800005
DA 2023-04-26
ER

PT J
AU Zhao, WF
   Persello, C
   Stein, A
AF Zhao, Wufan
   Persello, Claudio
   Stein, Alfred
TI Building outline delineation: From aerial images to polygons with an improved end-to-end learning framework
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Building outline delineation; Polygon prediction; Convolutional neural networks; Recurrent neural networks; Optical remote sensing imagery
ID segmentation; networks
AB Deep learning methods based upon convolutional neural networks (CNNs) have demonstrated impressive performance in the task of building outline delineation from very high resolution (VHR) remote sensing (RS) imagery. In this paper, we introduce an improved method that is able to predict regularized building outline in a vector format within an end-to-end deep learning framework. The main idea of our framework is to learn to predict the location of key vertices of the buildings and connect them in sequence. The proposed method is based on PolyMapper. We upgrade the feature extraction by introducing global context and boundary refinement blocks and add channel and spatial attention modules to improve the effectiveness of the detection module. In addition, we introduce stacked conv-GRU to further preserve the geometric relationship between vertices and accelerate inference. We tested our method on two large-scale VHR-RS building extraction dataset. The results on both COCO and PoLiS metrics demonstrate better performance compared with Mask R-CNN and PolyMapper. Specifically, we achieve 4.2 mask mean average precision (mAP) and 3.7 mean average recall (mAR) absolute improvements compared to PolyMapper. Also, the qualitative comparison shows that our method significantly improves the instance segmentation of buildings of various shapes.
C1 [Zhao, Wufan; Persello, Claudio; Stein, Alfred] Univ Twente, Fac ITC, Dept Earth Observat Sci, NL-7500 AE Enschede, Netherlands.
C3 University of Twente
RP Zhao, WF (corresponding author), Univ Twente, Fac ITC, Dept Earth Observat Sci, NL-7500 AE Enschede, Netherlands.
EM wufan.zhao@utwente.nl; c.persello@utwente.nl; a.stein@utwente.nl
CR Acuna D, 2018, PROC CVPR IEEE, V0, PP859, DOI 10.1109/CVPR.2018.00096
   Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Avbelj J, 2015, IEEE GEOSCI REMOTE S, V12, P170, DOI 10.1109/LGRS.2014.2330695
   Ballas N., 2015, ARXIV151106432, V0, P0
   Cao Y, 2019, IEEE INT CONF COMP V, V0, PP1971, DOI 10.1109/ICCVW.2019.00246
   Castrejon L, 2017, PROC CVPR IEEE, V0, PP4485, DOI 10.1109/CVPR.2017.477
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng D, 2019, PROC CVPR IEEE, V0, PP7423, DOI 10.1109/CVPR.2019.00761
   Douglas D. H., 1973, CARTOGRAPHICA INT J, V10, P112, DOI 10.3138/FM57-6770-U75U-7727
   Girard N, 2018, INT GEOSCI REMOTE SE, V0, P2083
   Griffiths D, 2019, ISPRS J PHOTOGRAMM, V154, P70, DOI 10.1016/j.isprsjprs.2019.05.013
   Gupta A., 2016, 2016 IEEE S SERIES C, V0, PP1, DOI 10.1109/ssci.2016.7850038
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Ji SP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111343
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Li WJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040403
   Li ZY, 2019, IEEE I CONF COMP VIS, V0, PP1715, DOI 10.1109/ICCV.2019.00180
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Marcos D, 2018, PROC CVPR IEEE, V0, PP8877, DOI 10.1109/CVPR.2018.00925
   Mohanty S.P, 2018, CROWDAI DATASET, V0, P0
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Pang JM, 2019, PROC CVPR IEEE, V0, PP821, DOI 10.1109/CVPR.2019.00091
   Partovi T, 2017, IEEE J-STARS, V10, P933, DOI 10.1109/JSTARS.2016.2611861
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Shi YL, 2020, ISPRS J PHOTOGRAMM, V159, P184, DOI 10.1016/j.isprsjprs.2019.11.004
   Sida Peng, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8530, DOI 10.1109/CVPR42600.2020.00856
   Sklansky J, 1982, PATTERN RECOGN LETT, V1, P79, DOI 10.1016/0167-8655(82)90016-2
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Turker M, 2015, INT J APPL EARTH OBS, V34, P58, DOI 10.1016/j.jag.2014.06.016
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Wang Y. B., 2018, INT C MACHINE LEARNI, V80, P5110, DOI 10.48550/ARXIV.1804.06300
   Wei SQ, 2020, IEEE T GEOSCI REMOTE, V58, P2178, DOI 10.1109/TGRS.2019.2954461
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu CQ, 2018, PROC CVPR IEEE, V0, PP1857, DOI 10.1109/CVPR.2018.00199
   Zhang Y, 1999, ISPRS J PHOTOGRAMM, V54, P50, DOI 10.1016/S0924-2716(98)00027-6
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 41
TC 38
Z9 39
U1 20
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY 15
PY 2021
VL 175
IS 
BP 119
EP 131
DI 10.1016/j.isprsjprs.2021.02.014
EA MAR 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT8HA
UT WOS:000644695700009
DA 2023-04-26
ER

PT J
AU Chaudhuri, U
   Dey, S
   Datcu, M
   Banerjee, B
   Bhattacharya, A
AF Chaudhuri, Ushasi
   Dey, Subhadip
   Datcu, Mihai
   Banerjee, Biplab
   Bhattacharya, Avik
TI Interband Retrieval and Classification Using the Multilabeled Sentinel-2 BigEarthNet Archive
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Vegetation mapping; Spatial resolution; Feature extraction; Sensors; Satellites; Task analysis; Soil; Interband retrieval; multilabel classification; multilabel cross triplet loss; multimodal classification; Sentinel-2; land-cover classification
ID graph convolutional network; spatial-resolution; driven; net
AB Conventional remote sensing data analysistechniques have a significant bottleneck of operating on a selectively chosen small-scale dataset. Availability of an enormous volume of data demands handling large-scale, diverse data, which have been made possible with neural network-based architectures. This article exploits the contextual information capturing ability of deep neural networks, particularly investigating multispectral band properties from Sentinel-2 image patches. Besides, an increase in the spatial resolution often leads to nonlinear mixing of land-cover types within a target resolution cell. We recognize this fact and group the bands according to their spatial resolutions, and propose a classification and retrieval framework. We design a representation learning framework for classifying the multispectral data by first utilizing all the bands and then using the grouped bands according to their spatial resolutions. We also propose a novel triplet-loss function for multilabeled images and use it to design an interband group retrieval framework. We demonstrate its effectiveness over the conventional triplet-loss function. Finally, we present a comprehensive discussion of the obtained results. We thoroughly analyze the performance of the band groups on various land-cover and land-use areas from agro-forestry regions, water bodies, and human-made structures. Experimental results for the classification and retrieval framework on the benchmarked BigEarthNet dataset exhibit marked improvements over existing studies.
C1 [Chaudhuri, Ushasi; Dey, Subhadip; Banerjee, Biplab; Bhattacharya, Avik] Indian Inst Technol, Ctr Studies Resources Engn, Mumbai 400076, Maharashtra, India.
   [Datcu, Mihai] German Aerospace Ctr DLR, D-82234 Wessling, Germany.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay; Helmholtz Association; German Aerospace Centre (DLR)
RP Chaudhuri, U (corresponding author), Indian Inst Technol, Ctr Studies Resources Engn, Mumbai 400076, Maharashtra, India.
EM ushasi2cool@gmail.com; subhadipdey23071994@gmail.com; mihai.datcu@dlr.de; getbiplab@.com; avikb@csre.iitb.ac.in
FU Conservatoire National des Arts et Metiers (CNAM), Paris, France
CR Aghdam Hamed Habibi, 2017, GUIDE CONVOLUTIONAL, V10, P978
   [Anonymous], 2017, ARXIV170707321, V0, P0
   Bahmanyar R, 2018, IEEE GEOSCI REMOTE S, V15, P459, DOI 10.1109/LGRS.2018.2794511
   Barandela R, 2003, LECT NOTES COMPUT SC, V2905, P424
   Berman EE, 2018, REMOTE SENS ENVIRON, V216, P635, DOI 10.1016/j.rse.2018.07.029
   Blondeau-Patissier D, 2014, PROG OCEANOGR, V123, P123, DOI 10.1016/j.pocean.2013.12.008
   Caballero I, 2019, ESTUAR COAST SHELF S, V226, P0, DOI 10.1016/j.ecss.2019.106277
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chaudhuri Ushasi, 2022, IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, V19, P0, DOI 10.1109/LGRS.2021.3056392
   Chaudhuri U., 2020, P IEEECVF C COMPUTER, V0, P182
   Chaudhuri U, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3105448
   Chaudhuri U, 2021, INT C PATT RECOG, V0, PP7335, DOI 10.1109/ICPR48806.2021.9412344
   Chaudhuri U, 2020, IMAGE VISION COMPUT, V104, P0, DOI 10.1016/j.imavis.2020.104003
   Chaudhuri U, 2020, PATTERN RECOGN LETT, V131, P456, DOI 10.1016/j.patrec.2020.02.006
   Chaudhuri U, 2019, COMPUT VIS IMAGE UND, V184, P22, DOI 10.1016/j.cviu.2019.04.004
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen D, 2004, INT J REMOTE SENS, V25, P2177, DOI 10.1080/01431160310001618464
   Chen SW, 2018, IEEE GEOSCI REMOTE S, V15, P627, DOI 10.1109/LGRS.2018.2799877
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cui SY, 2015, IEEE J-STARS, V8, P5158, DOI 10.1109/JSTARS.2015.2495267
   Delegido J, 2011, SENSORS-BASEL, V11, P7063, DOI 10.3390/s110707063
   Demir B, 2016, IEEE T GEOSCI REMOTE, V54, P892, DOI 10.1109/TGRS.2015.2469138
   Duan PH, 2021, IEEE T GEOSCI REMOTE, V59, P7726, DOI 10.1109/TGRS.2020.3031928
   Dutta Titir, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12350), V0, PP349, DOI 10.1007/978-3-030-58558-7_21
   Fan RY, 2020, IEEE J-STARS, V13, P4973, DOI 10.1109/JSTARS.2020.3019410
   Ferecatu M., 2004, P 6 ACM SIGMM INT WO, V0, P23
   Green CA, 2019, PHARMACOEPIDEM DR S, V28, P1127, DOI 10.1002/pds.4772
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P2281, DOI 10.1109/TGRS.2020.3007921
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang ZL, 2020, ISPRS J PHOTOGRAMM, V161, P179, DOI 10.1016/j.isprsjprs.2020.01.016
   IRONS JR, 1985, INT J REMOTE SENS, V6, P1385, DOI 10.1080/01431168508948285
   Janhall S, 2015, ATMOS ENVIRON, V105, P130, DOI 10.1016/j.atmosenv.2015.01.052
   Jaremenko SA, 2017, IOP CONF SER-MAT SCI, V262, P0, DOI 10.1088/1757-899X/262/1/012189
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Jiang JH, 2019, IEEE ACCESS, V7, P20607, DOI 10.1109/ACCESS.2019.2896128
   Kakogeorgiou I, 2021, INT J APPL EARTH OBS, V103, P0, DOI 10.1016/j.jag.2021.102520
   Khan N, 2019, NEUROCOMPUTING, V357, P36, DOI 10.1016/j.neucom.2019.05.024
   Klemas V, 2012, J COASTAL RES, V28, P34, DOI 10.2112/JCOASTRES-D-11-00051.1
   Lee J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071097
   Li N, 2018, IEEE J-STARS, V11, P1348, DOI 10.1109/JSTARS.2018.2814617
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P6521, DOI 10.1109/TGRS.2018.2839705
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Pflugmacher D, 2019, REMOTE SENS ENVIRON, V221, P583, DOI 10.1016/j.rse.2018.12.001
   Robinson C., 2019, PROC CVPR IEEE, V0, PP12726, DOI 10.1109/CVPR.2019.01301
   Sahadevan AS, 2014, IEEE J-STARS, V7, P2490, DOI 10.1109/JSTARS.2013.2280894
   Schmitt M., 2019, ISPRS ANN PHOTOGRAMM, V0, P0, DOI DOI 10.5194/isprs-annals-IV-2-W7-153-2019(
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Sebastia-Frasquet MT, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242926
   Simonyan K, 2015, ARXIV, V0, P0
   Sumbul G, 2021, ARXIV200106372, V0, P0
   Sumbul G, 2020, IEEE ACCESS, V8, P95934, DOI 10.1109/ACCESS.2020.2995805
   Sumbul G, 2019, INT GEOSCI REMOTE SE, V0, PP5901, DOI 10.1109/IGARSS.2019.8900532
   Sumbul G, 2019, INT GEOSCI REMOTE SE, V0, PP5726, DOI 10.1109/IGARSS.2019.8898188
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tanase R, 2017, IEEE GEOSCI REMOTE S, V14, P237, DOI 10.1109/LGRS.2016.2636663
   Ulmas P., 2020, ARXIV PREPRINT ARXIV, V0, P0
   van der Meer FD, 2014, REMOTE SENS ENVIRON, V148, P124, DOI 10.1016/j.rse.2014.03.022
   Vincenzi Stefano, 2020, 2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR), V0, PP3034, DOI 10.1109/ICPR48806.2021.9413112
   Wu J, 2017, INTRO CONVOLUTIONAL, V5, P978
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xian YQ, 2018, PROC CVPR IEEE, V0, PP5542, DOI 10.1109/CVPR.2018.00581
   Xu ZW, 2018, ISPRS J PHOTOGRAMM, V144, P423, DOI 10.1016/j.isprsjprs.2018.08.005
   Yang X., 2011, URBAN REMOTE SENSING, V0, P0
   Yessou H, 2020, INT GEOSCI REMOTE SE, V0, PP1349, DOI 10.1109/IGARSS39084.2020.9323583
   Zhang GC, 2019, IEEE T GEOSCI REMOTE, V57, P7623, DOI 10.1109/TGRS.2019.2914967
   Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19
   Zhang YZ, 2013, IEEE J-STARS, V6, P746, DOI 10.1109/JSTARS.2013.2245405
   Zhao JP, 2019, IEEE T GEOSCI REMOTE, V57, P10116, DOI 10.1109/TGRS.2019.2931620
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zotov Michael, 2019, ARXIV191014567, V0, P0
NR 73
TC 5
Z9 5
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9884
EP 9898
DI 10.1109/JSTARS.2021.3112209
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WJ5GX
UT WOS:000709074200001
DA 2023-04-26
ER

PT J
AU Avdeeva, ZK
   Grebenyuk, EA
   Kovriga, SV
AF Avdeeva, Zinaida K.
   Grebenyuk, Elena A.
   Kovriga, Svetlana, V
TI Construction of Multi-step Price Forecasts in Commodity Markets Based on Qualitative and Quantitative Data Analysis Methods
SO ADVANCES IN PRODUCTION MANAGEMENT SYSTEMS: ARTIFICIAL INTELLIGENCE FOR SUSTAINABLE AND RESILIENT PRODUCTION SYSTEMS, APMS 2021, PT I
LA English
DT Article; Proceedings Paper
DE Manufacturing system; Multi-step forecasting quantitative and qualitative forecasting; Cognitive map; Monitoring; Time series
ID cognitive maps; neural-networks; prediction; model
AB The article proposes a method for constructing and correcting a multistep forecast for the year ahead (with a monthly breakdown) of prices for raw materials and products of industrial enterprises. The proposed approach consists in the formation of a price forecast taking into account 1) the price of the predicted indicator, the prices of goods participating in the product value chain, and macro indicators (time series); 2) information about the strength and direction of environmental factors affecting the market. Structured information about the effects of the external environment is the result of processing expert knowledge and hypotheses from heterogeneous information sources, through analysis and modeling on a cognitive map of the situation (CCS). We form a forecast by constructing an ensemble of time series models, each of which reflects the dependence of the target indicator on its past values and the prices of related products, the composition of which is determined by the results of cognitive modeling and time series analysis. Based on the results of monitoring on the cognitive map of the situation, conducting in order to analyze possible changes in the external environment and digital monitoring of prices, to identify changes in prices modes, we perform a forecast correction. The results obtained in this study show that the use of cognitive modeling and monitoring of changes improve the accuracy of predictions.
C1 [Avdeeva, Zinaida K.; Grebenyuk, Elena A.; Kovriga, Svetlana, V] RAS, Trapeznikov VA Inst Control Sci, Moscow, Russia.
C3 Russian Academy of Sciences
RP Avdeeva, ZK (corresponding author), RAS, Trapeznikov VA Inst Control Sci, Moscow, Russia.
EM kovriga@ipu.ru
CR Byrne JP, 2013, J DEV ECON, V101, P16, DOI 10.1016/j.jdeveco.2012.09.002
   Froelich W, 2014, INT J APPROX REASON, V55, P1319, DOI 10.1016/j.ijar.2014.02.006
   Grebenyuk E.A., 2020, P 13 INT C MLSD, V0, P0
   Homenda W, 2017, NEUROCOMPUTING, V232, P3, DOI 10.1016/j.neucom.2016.08.119
   Hong T, 2004, EXPERT SYST, V21, P243, DOI 10.1111/j.1468-0394.2004.00282.x
   Jiang H, 2011, CONSTR MANAG ECON, V29, P969, DOI 10.1080/01446193.2011.611522
   Lin L, 2020, PHYSICA A, V543, P0, DOI 10.1016/j.physa.2019.123532
   Liu C, 2021, RES INT BUS FINANC, V55, P0, DOI 10.1016/j.ribaf.2020.101318
   Makarenko DI, 2018, IFAC PAPERSONLINE, V51, P522, DOI 10.1016/j.ifacol.2018.11.273
   Nikiforov IV, 2000, IEEE T INFORM THEORY, V46, P2740, DOI 10.1109/18.887891
   Papageorgiou EI, 2017, NEUROCOMPUTING, V232, P113, DOI 10.1016/j.neucom.2016.10.072
   Parot A, 2019, INTELL SYST ACCOUNT, V26, P3, DOI 10.1002/isaf.1440
   Sa-ngasoongsong A, 2012, INT J PROD ECON, V140, P875, DOI 10.1016/j.ijpe.2012.07.009
   Shan D, 2018, INT J INNOV COMPUT I, V14, P1583, DOI 10.24507/ijicic.14.05.1583
   Tang L, 2020, APPL ENERG, V257, P0, DOI 10.1016/j.apenergy.2019.114033
   Tang L, 2015, INT J INF TECH DECIS, V14, P141, DOI 10.1142/S0219622015400015
   Zhang X, 2009, ENERG ECON, V31, P768, DOI 10.1016/j.eneco.2009.04.003
NR 17
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1868-4238
EI 1868-422X
J9 IFIP ADV INF COMM TE
PD JUN 15
PY 2021
VL 630
IS 
BP 623
EP 631
DI 10.1007/978-3-030-85874-2_68
PG 9
WC Computer Science, Information Systems; Telecommunications
SC Computer Science; Telecommunications
GA BS4DM
UT WOS:000717630100068
DA 2023-04-26
ER

PT J
AU Nath, SK
   Sengupta, A
   Srivastava, A
AF Nath, Sankar Kumar
   Sengupta, Arnab
   Srivastava, Anand
TI Remote sensing GIS-based landslide susceptibility & risk modeling in Darjeeling-Sikkim Himalaya together with FEM-based slope stability analysis of the terrain
SO NATURAL HAZARDS
LA English
DT Article
DE Landslide susceptibility zones; Vulnerability risk; Static dynamic slope stability; Darjeeling-Sikkim Himalaya
ID analytical hierarchy process; evidential belief function; ground-penetrating radar; information value method; logistic-regression; frequency ratio; process ahp; spectral information; urban areas; earthquake
AB Landslide susceptibility (LSI) modeling of Darjeeling-Sikkim Himalaya is performed by integrating 28 causative factors on C-28(28) combinations on Geographical Information System (GIS) following analytic hierarchy process (AHP)-based multicriteria decision protocol, logistic regression (LR)-based multivariate technique, machine learning data-driven random forest (RF) and artificial neural network (ANN) methods wherein the terrain is classified into 'None' (with: 0.0 < LSI <= 0.17), 'Low' (with: 0.17 < LSI <= 0.34), 'Moderate' (with: 0.34 < LSI <= 0.51), 'High' (with: 0.51 < LSI <= 0.68),'Very High' (with: 0.68 < LSI <= 0.85) and 'Severe' (with: 0.85 < LSI <= 1.00) susceptible zones as validated through standard statistical accuracy tests and direct cross-correlation analysis of all the susceptible zonation maps generated by drawing comparison with the 30% landslide inventory test data. The best integrated thematic RF-based LSI vector layer with an accuracy level of 0.871, in turn, on integration with the vulnerability components like population density, number of households, building types, building height and building density has demarketed approximately 21% of the region under 'Very High' to 'Severe' socioeconomic risk zone while about 36% area are classified under 'Very High' to 'Severe' structural risk zone as implicated by devastating landslide hazards in the region. Ground Penetrating Radar Survey has been conducted on all the slopes in the 'Very High to Severe' landslide susceptible zones wherein near-surface lithologic setting, presence of paleo-slopes and microstructural features like fractures/faults and poorly stratified debris flow have been imaged that provided favorable subsurface conditions for slope failure. Finite element method-based slope failure analysis for Newmark displacement estimates factor of safety (FoS) value that acts as the proxy in defining the degree of slope instability is seen to vary between 1.905 and 2.357 in the 'Low to Moderate' landslide susceptible zone while it ranges between 1.051 and 1.652 in the 'High' landslide susceptible zone and between 0.649 and 1.349 in the 'Very High to Severe' landslide inventory subset along the slopes under both gravity loading and seismic shaking in the terrain. The slope stability analysis puts the yield acceleration between 0.0012 and 0.11984 m/s(2) and the total deformation between 0.0027 and 1.4484 m. All these parameters in the classified landslide susceptible zones in unison demonstrate how unstable are the terrain slopes in the 'High to Severe' landslide susceptible zones.
C1 [Nath, Sankar Kumar; Sengupta, Arnab; Srivastava, Anand] Indian Inst Technol Kharagpur, Dept Geol & Geophys, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Kharagpur
RP Nath, SK (corresponding author), Indian Inst Technol Kharagpur, Dept Geol & Geophys, Kharagpur 721302, W Bengal, India.
EM nath@gg.iitkgp.ac.in; arnabsengupta958@gmail.com; anandsrivastava533@gmail.com
FU Geoscience Division of the Ministry of Earth Sciences, Government of India [MoES/ P.O. (Seismo)/1(207)/2013]
CR Achour Y, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2980-6
   Adepelumi AA, 2012, J GEOPHYS ENG, V9, P397, DOI 10.1088/1742-2132/9/4/397
   Adhikari MD, 2018, THESIS IIT KHARAGPUR, V0, P0
   Aleotti P., 1999, B ENG GEOL ENVIRON, V58, P21, DOI 10.1007/s100640050066
   Althuwaynee OF, 2014, CATENA, V114, P21, DOI 10.1016/j.catena.2013.10.011
   Althuwaynee OF, 2012, COMPUT GEOSCI-UK, V44, P120, DOI 10.1016/j.cageo.2012.03.003
   American Society of Civil Engineers ASCE, 2000, PRESTANDARD COMMENTA, V0, P0
   Anbalagan R., 2015, GEOENVIRONMENTAL DIS, V2, P6, DOI 10.1186/s40677-014-0009-y
   Annan A. P., 2003, GROUND PENETRATING R, V0, P0
   [Anonymous], 2000, APPL LOGISTIC REGRES, V0, P0, DOI DOI 10.1002/0471722146
   Ayalew L, 2004, LANDSLIDES, V1, P73, DOI 10.1007/s10346-003-0006-9
   Baeza C, 2001, EARTH SURF PROC LAND, V26, P1251, DOI 10.1002/esp.263
   Bai SB, 2011, ENVIRON EARTH SCI, V62, P139, DOI 10.1007/s12665-010-0509-3
   Banerjee P, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3488-4
   Bera A, 2019, NAT HAZARDS, V96, P935, DOI 10.1007/s11069-019-03580-w
   BMTPC, 1997, VULNERABILITY ATLAS, V0, P0
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   CEOS, 2001, CEOS REPORT, V0, P0
   Chawla A, 2018, ADV CIV ENG, V2018, P0, DOI 10.1155/2018/6416492
   Choi J, 2012, ENG GEOL, V124, P12, DOI 10.1016/j.enggeo.2011.09.011
   Corominas J, 2014, B ENG GEOL ENVIRON, V73, P209, DOI 10.1007/s10064-013-0538-8
   Cruden D.M., 1990, B INT ASS ENG GEOL, V41, P13, DOI 10.1007/BF02590202
   Dai FC, 2002, GEOMORPHOLOGY, V42, P213, DOI 10.1016/S0169-555X(01)00087-3
   Das Adhikari M, 2016, J INDIAN GEOPHYS UNI, V20, P151
   Das AM, 2011, DISASTER ADV, V4, P26
   Dasgupta S, 2000, GEOLOGICAL SURVEY IN, V59, P87
   DAVIS JL, 1989, GEOPHYS PROSPECT, V37, P531, DOI 10.1111/j.1365-2478.1989.tb02221.x
   Elkadiri R, 2014, IEEE J-STARS, V7, P4818, DOI 10.1109/JSTARS.2014.2337273
   Franke D, 2015, SEDIMENTOLOGY, V62, P57, DOI 10.1111/sed.12139
   Garcia-Rodriguez MJ, 2010, NAT HAZARD EARTH SYS, V10, P1307, DOI 10.5194/nhess-10-1307-2010
   Garevski M, 2013, LANDSLIDES, V10, P729, DOI 10.1007/s10346-012-0360-6
   Geneletti D, 2003, INT J REMOTE SENS, V24, P1273, DOI 10.1080/01431160210144499
   Ghosh S, 2014, B ENG GEOL ENVIRON, V73, P931, DOI 10.1007/s10064-014-0586-8
   Ghosh S, 2011, GEOMORPHOLOGY, V131, P35, DOI 10.1016/j.geomorph.2011.04.019
   Goetz JN, 2015, COMPUT GEOSCI-UK, V81, P1, DOI 10.1016/j.cageo.2015.04.007
   Hasekiogullari GD, 2012, NAT HAZARDS, V63, P1157, DOI 10.1007/s11069-012-0218-1
   Hecht R, 2014, RHOMBOS VERL, V63, P0
   Hecht R, 2015, INT J CARTOGRAPHY, V1, P18, DOI https://doi.org/10.1080/23729333.2015.1055644
   Hemasinghe H, 2018, PROCEDIA ENGINEER, V212, P1046, DOI 10.1016/j.proeng.2018.01.135
   Huang Y, 2018, CATENA, V165, P520, DOI 10.1016/j.catena.2018.03.003
   Iannelli GC, 2017, URBAN SCI, V1, P0, DOI 10.3390/urbansci1020016
   Jol HM, 2009, GROUND PENETRATING RADAR THEORY AND APPLICATIONS, V0, P1
   Kainthola A, 2015, GEOSCI FRONT, V6, P837, DOI 10.1016/j.gsf.2014.03.002
   Kanungo DP, 2006, ENG GEOL, V85, P347, DOI 10.1016/j.enggeo.2006.03.004
   Kayastha P, 2013, COMPUT GEOSCI-UK, V52, P398, DOI 10.1016/j.cageo.2012.11.003
   Kirschbaum D, 2015, GEOMORPHOLOGY, V249, P4, DOI 10.1016/j.geomorph.2015.03.016
   Komac M, 2006, GEOMORPHOLOGY, V74, P17, DOI 10.1016/j.geomorph.2005.07.005
   Krahn J, 2007, PROC MONOGR ENG WATE, V0, PP311, DOI 10.1201/NOE0415444019-c38
   Kumar R, 2016, J GEOL SOC INDIA, V87, P271, DOI 10.1007/s12594-016-0395-8
   Lange K., 2003, MATH STAT METHODS GE, V0, P0
   Hung LQ, 2016, LANDSLIDES, V13, P1285, DOI 10.1007/s10346-015-0657-3
   Lee S, 2007, LANDSLIDES, V4, P33, DOI 10.1007/s10346-006-0047-y
   Lu DS, 2005, PHOTOGRAMM ENG REM S, V71, P1275, DOI 10.14358/PERS.71.11.1275
   Mandal S, 2018, MODEL EARTH SYST ENV, V4, P69, DOI 10.1007/s40808-018-0426-0
   Matsuoka M, 2014, J DISASTER RES, V9, P1032, DOI 10.20965/jdr.2014.p1032
   Mehrotra GS, 1996, J GEOL SOC INDIA, V47, P491
   Meng FY, 2015, KNOWL-BASED SYST, V73, P111, DOI 10.1016/j.knosys.2014.09.011
   Mondal S, 2018, GEORISK, V12, P29, DOI 10.1080/17499518.2017.1347949
   Mondal S, 2013, INT J DISAST RISK SC, V4, P200, DOI 10.1007/s13753-013-0021-y
   Nath SK, 2015, NAT HAZARD EARTH SYS, V15, P1103, DOI 10.5194/nhess-15-1103-2015
   Nath SK, 2017, NAT HAZARDS, V85, P1787, DOI 10.1007/s11069-016-2665-6
   Nath SK, 2004, NAT HAZARDS, V31, P319
   Nefeslioglu HA, 2008, GEOMORPHOLOGY, V94, P401, DOI 10.1016/j.geomorph.2006.10.036
   NEWMARK NM, 1965, GEOTECHNIQUE, V15, P139, DOI 10.1680/geot.1965.15.2.139
   NRSC, 2011, ASSESSMENT 18 SEPTEM, V0, P0
   Ohlmacher GC, 2003, ENG GEOL, V69, P331, DOI 10.1016/S0013-7952(03)00069-3
   Ozdemir A, 2011, J HYDROL, V405, P123, DOI 10.1016/j.jhydrol.2011.05.015
   Pal SC, 2019, J INDIAN SOC REMOTE, V47, P1643, DOI 10.1007/s12524-019-01009-2
   Pascale S, 2013, LECT NOTES COMPUT SC, V7974, P473
   Pradhan B, 2010, ENVIRON MODELL SOFTW, V25, P747, DOI 10.1016/j.envsoft.2009.10.016
   Pradhan B, 2010, LANDSLIDES, V7, P13, DOI 10.1007/s10346-009-0183-2
   Qi F, 2016, ENERG BUILDINGS, V118, P123, DOI 10.1016/j.enbuild.2016.02.044
   Rasyid A.R., 2016, GEOENVIRONMENTAL DIS, V3, P19, DOI 10.1186/s40677-016-0053-x
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Rossetti DF, 2003, AN ACAD BRAS CIENC, V75, P235, DOI 10.1590/S0001-37652003000200009
   Roy J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232866
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Saaty TL., 1970, OPTIMIZATION INTEGER, V0, P0
   Sarkar K, 2016, J GEOL SOC INDIA, V88, P387, DOI 10.1007/s12594-016-0500-z
   Sarkar S, 2013, J GEOL SOC INDIA, V82, P351, DOI 10.1007/s12594-013-0162-z
   Sastry G, 1981, THE B, VR8, P0
   Schicker R, 2012, GEOMORPHOLOGY, V161, P40, DOI 10.1016/j.geomorph.2012.03.036
   Sengupta A, 2010, NAT HAZARDS, V52, P31, DOI 10.1007/s11069-009-9352-9
   SENTHILKUMAR V, 2017, WORKSHOP WORLD LANDS, V0, P0
   Shahabi H, 2015, SCI REP-UK, V5, P0, DOI 10.1038/srep09899
   Shahabi H, 2014, CATENA, V115, P55, DOI 10.1016/j.catena.2013.11.014
   Shano L, 2020, GEOENVIRONMENTAL DIS, V7, P0, DOI 10.1186/s40677-020-00152-0
   Sharma LP, 2013, APPL GEOMAT, V5, P271, DOI 10.1007/s12518-013-0115-7
   Sharma LP, 2014, GEOCARTO INT, V29, P128, DOI 10.1080/10106049.2012.748830
   Shiny NR, 2015, IIITTR20151, V0, P497
   Sikkim State Disaster Management Authority (SSDMA), 2015, MULTIHAZARDS RISK VU, V0, P0
   Sritarapipat Tanakorn, 2017, REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT, V6, P46, DOI 10.1016/j.rsase.2017.04.001
   Terzaghi K., 1950, GEOL SOC AM, V0, P0, DOI DOI 10.1130/Berkey.1950.83
   Van Westen CJ, 1996, TRANSPORTATION RES B, V247, P129
   Verma PN., 1983, GEOTECHNICAL REPORT, V0, P84
   Wang HB, 2005, PROG PHYS GEOG, V29, P548, DOI 10.1191/0309133305pp462ra
   Yalcin A, 2011, CATENA, V85, P274, DOI 10.1016/j.catena.2011.01.014
   Yalcin A, 2008, CATENA, V72, P1, DOI 10.1016/j.catena.2007.01.003
   Yilmaz I, 2009, COMPUT GEOSCI-UK, V35, P1125, DOI 10.1016/j.cageo.2008.08.007
   Youssef AM, 2021, GEOSCI FRONT, V12, P639, DOI 10.1016/j.gsf.2020.05.010
   Yuan RM, 2016, FRONT EARTH SCI-PRC, V10, P740, DOI 10.1007/s11707-015-0547-y
   Zha Y, 2003, INT J REMOTE SENS, V24, P583, DOI 10.1080/01431160304987
   Zhang J, 2011, CAN GEOTECH J, V48, P1138, DOI 10.1139/T11-009
   Zhang Q, 2002, INT J REMOTE SENS, V23, P3057, DOI 10.1080/01431160110104728
NR 104
TC 4
Z9 4
U1 10
U2 33
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0921-030X
EI 1573-0840
J9 NAT HAZARDS
JI Nat. Hazards
PD SEP 15
PY 2021
VL 108
IS 3
BP 3271
EP 3304
DI 10.1007/s11069-021-04823-5
EA JUN 2021
PG 34
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources
SC Geology; Meteorology & Atmospheric Sciences; Water Resources
GA TV7AB
UT WOS:000660800200001
DA 2023-04-26
ER

PT J
AU Heo, J
   Song, K
   Han, S
   Lee, DE
AF Heo, Jae
   Song, Kwonsik
   Han, SangUk
   Lee, Dong-Eun
TI Multi-channel convolutional neural network for integration of meteorological and geographical features in solar power forecasting
SO APPLIED ENERGY
LA English
DT Article
DE Solar energy; Photovoltaic power prediction; Multi-channel convolutional neural network; Geographic information system; Photovoltaic site selection
ID radiation; output; irradiance; prediction; generation; models; system; ann
AB The forecasting of potential photovoltaic power is essential to investigate suitable regions for power plant installation where high levels of electricity can be produced. However, it remains challenging to integrate the meteorological and geographical features at a regional level into the modeling process of solar forecasting, through which the model trained can be extended to predict at other regions. In particular, regional effects resulting from adjacent topography and weather conditions have rarely been considered in solar energy forecasting. Thus, this paper proposes a multi-channel convolutional neural network that is designed to forecast the monthly photovoltaic power with raster image data representing various regional effects. In particular, the network model with multi-channels allows for training with input data of elevation, solar irradiation, temperature, wind speed, and precipitation in a map format, and output data of corresponding photovoltaic power outputs from 164 sites. The results show that the proposed network model achieves a mean absolute percent error of 8.639%, which outperforms conventional methods such as multiple linear regression (e.g., 16.187%) and artificial neural networks (e.g., 15.991%). This implies that learning regional patterns of both geographical and meteorological features may lead to better performance in solar forecasting, and that the trained model can be applied to other regions-the data of which is not used for the training. Thus, this study may help to identify suitable regions with high electricity potential in a large area.
C1 [Heo, Jae; Han, SangUk] Hanyang Univ, Dept Civil & Environm Engn, 222 Wangsimni Ro, Seoul 04763, South Korea.
   [Song, Kwonsik; Lee, Dong-Eun] KyungPook Natl Univ, Sch Architectural Civil Environm & Energy Engn, 1370 Sangyegk Dong, Daegu 702701, South Korea.
C3 Hanyang University; Kyungpook National University
RP Han, S (corresponding author), Hanyang Univ, Dept Civil & Environm Engn, 222 Wangsimni Ro, Seoul 04763, South Korea.
EM heojae1234@hanyang.ac.kr; kssong85@gmail.com; sanguk@hanyang.ac.kr; dolee@knu.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT) [NRF2018R1A5A1025137]
CR [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Bajpai P, 2012, RENEW SUST ENERG REV, V16, P2926, DOI 10.1016/j.rser.2012.02.009
   Balki I, 2019, CAN ASSOC RADIOL J, V70, P344, DOI 10.1016/j.carj.2019.06.002
   Besharat F, 2013, RENEW SUST ENERG REV, V21, P798, DOI 10.1016/j.rser.2012.12.043
   Bhattacharya T., 2014, J SOL ENERGY, V2014, P1, DOI 10.1155/2014/817078
   Chupong C, 2011, ENRGY PROCED, V9, P0, DOI 10.1016/j.egypro.2011.09.024
   Ding M, 2011, PROCEDIA ENVIRON SCI, V11, P1308, DOI 10.1016/j.proenv.2011.12.196
   Fadare DA, 2009, APPL ENERG, V86, P1410, DOI 10.1016/j.apenergy.2008.12.005
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gueymard CA, 2009, SOL ENERGY, V83, P1998, DOI 10.1016/j.solener.2009.07.011
   GWANDU BAL, 1995, RENEW ENERG, V6, P313, DOI 10.1016/0960-1481(95)00073-S
   Hailegnaw B, 2015, J PHYS CHEM LETT, V6, P1543, DOI 10.1021/acs.jpclett.5b00504
   Heo J, 2020, APPL ENERG, V262, P0, DOI 10.1016/j.apenergy.2020.114588
   HOFIERKA J., 2002, P OP SOURC GIS GRASS, V0, P1
   Jang HS, 2016, IEEE T SUSTAIN ENERG, V7, P1255, DOI 10.1109/TSTE.2016.2535466
   Jeung YS, 2016, AM J TROP MED HYG, V94, P22, DOI 10.4269/ajtmh.15-0474
   Jung J, 2019, APPL ENERG, V242, P57, DOI 10.1016/j.apenergy.2019.03.101
   Jung Y, 2020, J CLEANER PROD, V250, P0
   Kandirmaz HM, 2004, INT J REMOTE SENS, V25, P2159, DOI 10.1080/01431160310001618743
   Kang MC, 2011, MIDWEST SYMP CIRCUIT, V0, P0
   Khatib T, 2012, INT J PHOTOENERGY, V2012, P0, DOI 10.1155/2012/419504
   Kim SG, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11051501
   Koca A, 2011, EXPERT SYST APPL, V38, P8756, DOI 10.1016/j.eswa.2011.01.085
   Koehl M, 2011, SOL ENERG MAT SOL C, V95, P1638, DOI 10.1016/j.solmat.2011.01.020
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kumar L, 1997, INT J GEOGR INF SCI, V11, P475, DOI 10.1080/136588197242266
   Liashchynskyi P, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Liu M, 2012, INT J GEOGR INF SCI, V26, P1281, DOI 10.1080/13658816.2011.641969
   Meenal R, 2018, P 2 INT C COMM EL SY, V0, P302
   Mellit Adel, 2008, INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING, V1, P52, DOI 10.1504/IJAISC.2008.021264
   Meral ME, 2011, RENEW SUST ENERG REV, V15, P2176, DOI 10.1016/j.rser.2011.01.010
   Ouammi A, 2012, RENEW SUST ENERG REV, V16, P4876, DOI 10.1016/j.rser.2012.03.071
   Reddy KS, 2003, ENERG CONVERS MANAGE, V44, P2519, DOI 10.1016/S0196-8904(03)00009-8
   Ruiz-Arias JA, 2011, J APPL METEOROL CLIM, V50, P2460, DOI 10.1175/2011JAMC2571.1
   Ryu Anto, 2019, 2019 IEEE PES GTD GRAND INTERNATIONAL CONFERENCE AND EXPOSITION ASIA (GTD ASIA), V0, PP627, DOI 10.1109/GTDAsia.2019.8715984
   Sahin M, 2013, ADV SPACE RES, V51, P891, DOI 10.1016/j.asr.2012.10.010
   Schwingshackl C, 2013, ENRGY PROCED, V40, P77, DOI 10.1016/j.egypro.2013.08.010
   Senkal O, 2009, APPL ENERG, V86, P1222, DOI 10.1016/j.apenergy.2008.06.003
   Solar Power Europe, 2016, GLOBAL MARKET OUTLOO, V0, P0
   Solar Power Europe, 2019, GLOBAL MARKET OUTLOO, V0, P0
   Srivastava S, 2018, SOL ENERGY, V162, P232, DOI 10.1016/j.solener.2018.01.005
   Sun YC, 2019, SOL ENERGY, V188, P730, DOI 10.1016/j.solener.2019.06.041
   Sun YC, 2018, ENERG ENVIRON SCI, V11, P1811, DOI 10.1039/c7ee03420b
   SURI M., 2004, T GIS, V8, P175, DOI 10.1111/J.1467-9671.2004.00174.X
   Tahri M, 2015, RENEW SUST ENERG REV, V51, P1354, DOI 10.1016/j.rser.2015.07.054
   Tovar-Pescador J, 2006, METEOROL APPL, V13, P279, DOI 10.1017/S1350482706002258
   Tymvios FS, 2005, SOL ENERGY, V78, P752, DOI 10.1016/j.solener.2004.09.007
   Yadav AK, 2014, RENEW SUST ENERG REV, V33, P772, DOI 10.1016/j.rser.2013.08.055
   Yang DZ, 2012, SOL ENERGY, V86, P3531, DOI 10.1016/j.solener.2012.07.029
   Yeom JM, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19092082
   Zaccone G, 2017, DEEP LEARNING TENSOR, V0, P0
NR 51
TC 15
Z9 15
U1 8
U2 10
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-2619
EI 1872-9118
J9 APPL ENERG
JI Appl. Energy
PD AUG 1
PY 2021
VL 295
IS 
BP 
EP 
DI 10.1016/j.apenergy.2021.117083
EA MAY 2021
PG 13
WC Energy & Fuels; Engineering, Chemical
SC Energy & Fuels; Engineering
GA WI1NJ
UT WOS:000708132400005
DA 2023-04-26
ER

PT J
AU Ma, YX
   Minasny, B
   McBratney, A
AF Ma, Yuxin
   Minasny, Budiman
   McBratney, Alex
TI Identifying soil provenance based on portable X-ray fluorescence measurements using similarity and inverse-mapping approaches-A case in the Lower Hunter Valley, Australia
SO GEODERMA REGIONAL
LA English
DT Article
DE Soil provenance; Environmental similarity; Digital soil mapping; Principal component; Artificial neural network
ID neural-network; pxrf; spectroscopy; spectrometry; sample
AB There is a growing interest in the use of soil composition as a form of evidence in food provenance, forensics, biosecurity, and archaeology. Given a soil sample of unknown origin, we should like to know the likely geographical source of that material. In this study, we investigated whether data provided from a rapid and nondestructive sensor can be used to identify the provenance of a soil sample. A portable X-ray fluorescence (pXRF) spectrometer was used to measure the elemental abundance of 0-10 cm soil samples from a part of the Lower Hunter Valley, NSW, Australia (an area of 328 km(2)). Three methods, namely, two similarity methods (points of similarity and regions of similarity) based on distances to the unlocated specimen in the principal component (PC) space of the geochemical data, and an artificial neural network (ANN) method, effectively an inverse digital soilmapping (DSM) approach, which predicts location from the set of geochemical variables, were tested to determine the provenance of soil samples. In the PC approach, digital soil maps of the PC scores of eight major elements and two elemental ratios were created. The locations predicted by the PC approach seemed to follow the pattern of topography. In the ANN approach, the geographical coordinates (Eastings and Northings) of a sample were predicted simultaneously using the elemental concentrations and ratios. Using maps of elemental concentration classes (regions of similarity based on PC) provided a mean RMSE of 8.6 km for the 147 validation samples. The different effects of identification of geographical locations were compared using a 95% spatial confidence interval of prediction on a validation dataset. The points of similarity based on PC approach showed that the predicted search areas can capture 59% of the true locations of the test data. Meanwhile, the ANN approach can capture 69% of the true locations of the data. The mean RMSE for ANN prediction (2.8 km) was smaller than that for points of similarity prediction (4.3 km). Both soil provenancing approaches are potentially useful in identifying geographical areas of origin or similarity. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Ma, Yuxin; Minasny, Budiman; McBratney, Alex] Univ Sydney, Sydney Inst Agr, Sch Life & Environm Sci, 1 Cent Ave, Eveleigh, NSW 2015, Australia.
   [Ma, Yuxin] Landcare Res, Manawatu Mail Ctr, Private Bag 11052, Palmerston North 4442, New Zealand.
C3 University of Sydney; Landcare Research - New Zealand
RP Ma, YX (corresponding author), Landcare Res, Manawatu Mail Ctr, Private Bag 11052, Palmerston North 4442, New Zealand.
EM yuxin.ma@sydney.edu.au
FU Australian Research Council's Discovery Project [DP190103005]; LE STUDIUM Loire Valley Institute for Advanced Studies through its LE STUDIUM Research Consortium Programme
CR Adisa OM, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11041145
   Aitkenhead MJ, 2014, ENVIRON FORENSICS, V15, P281, DOI 10.1080/15275922.2014.930764
   [Anonymous], 1975, CLUSTERING ALGORITHM, V0, P0
   [Anonymous], 1941, FACTORS SOIL FORMATI, V0, P0
   [Anonymous], 2002, AUSTR SOIL CLASSIFIC, V0, P0
   Caritat P., 2019, J FORENSIC SCI, V0, P1
   Conrad O, 2015, GEOSCI MODEL DEV, V8, P1991, DOI 10.5194/gmd-8-1991-2015
   El Mujtar V, 2019, GLOB FOOD SECUR-AGR, V20, P132, DOI 10.1016/j.gfs.2019.01.007
   Fitzpatrick R. W., 2012, SOIL HORIZONS, V53, P14
   Flojgaard C, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0202844
   Forster N, 2012, J ARCHAEOL SCI, V39, P728, DOI 10.1016/j.jas.2011.11.004
   Goovaerts, 1997, GEOSTATISTICS NATURA, V0, P0
   Goovaerts P, 2001, GEODERMA, V103, P3, DOI 10.1016/S0016-7061(01)00067-2
   Grave P, 2014, ANTIQUITY, V88, P1180, DOI 10.1017/S0003598X0011539X
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888
   Hsieh W.W., 2009, MACHINE LEARNING MET, V0, P0, DOI DOI 10.1017/CBO9780511627217
   Kavzoglu T, 2003, INT J REMOTE SENS, V24, P4907, DOI 10.1080/0143116031000114851
   Kelly S, 2005, TRENDS FOOD SCI TECH, V16, P555, DOI 10.1016/j.tifs.2005.08.008
   Lark RM, 2008, EUR J SOIL SCI, V59, P1000, DOI 10.1111/j.1365-2389.2008.01064.x
   Ma YX, 2019, GEODERMA, V341, P195, DOI 10.1016/j.geoderma.2019.01.049
   Mancini M, 2019, GEODERMA, V337, P718, DOI 10.1016/j.geoderma.2018.10.026
   MAYNARD JB, 1992, J GEOL, V100, P279, DOI 10.1086/629632
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   Minasny B, 2002, SOIL SCI SOC AM J, V66, P352, DOI 10.2136/sssaj2002.0352
   MURRAY R.C., 2011, EVIDENCE EARTH FOREN, V2nd, P0
   Nampanya S, 2012, TRANSBOUND EMERG DIS, V59, P117, DOI 10.1111/j.1865-1682.2011.01247.x
   Ng W, 2019, GEODERMA, V352, P251, DOI 10.1016/j.geoderma.2019.06.016
   Padarian J, 2020, SOIL-GERMANY, V6, P35, DOI 10.5194/soil-6-35-2020
   Padarian J, 2019, SOIL-GERMANY, V5, P79, DOI 10.5194/soil-5-79-2019
   R CORE TEAM, 2017, R LANG ENV STAT COMP, V0, P0
   Ross A, 2015, AUST J FORENSIC SCI, V47, P8, DOI 10.1080/00450618.2014.916753
   Smith HG, 2015, J SOIL SEDIMENT, V15, P2033, DOI 10.1007/s11368-015-1231-2
   Stenberg B, 2010, ADV AGRON, V107, P163, DOI 10.1016/S0065-2113(10)07005-7
   Stockmann U, 2016, CATENA, V139, P220, DOI 10.1016/j.catena.2016.01.007
   Thermofisher.com, 2017, NIT XL3T XRF AN, V0, P0
   Tighe M, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-21530-7
   Weindorf DC, 2014, ADV AGRON, V128, P1, DOI 10.1016/B978-0-12-802139-2.00001-9
   WRB, 2014, WORLD SOIL RESOURCES, V106, P0
   Yang H, 2012, EUR J SOIL SCI, V63, P410, DOI 10.1111/j.1365-2389.2012.01443.x
   Zell A., 1994, NEURAL NETWORK SIMUL, V0, P165
   Zeng R., 2020, FORENSIC SCI INT, V317, P0
NR 41
TC 4
Z9 4
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-0094
EI 
J9 GEODERMA REG
JI Geoderma Reg.
PD JUN 15
PY 2021
VL 25
IS 
BP 
EP 
DI 10.1016/j.geodrs.2021.e00368
EA FEB 2021
PG 11
WC Soil Science
SC Agriculture
GA SU8UG
UT WOS:000663406200010
DA 2023-04-26
ER

PT J
AU Du, BJ
   Mao, DH
   Wang, ZM
   Qiu, ZQ
   Yan, HQ
   Feng, KD
   Zhang, ZB
AF Du, Baojia
   Mao, Dehua
   Wang, Zongming
   Qiu, Zhiqiang
   Yan, Hengqi
   Feng, Kaidong
   Zhang, Zhongbin
TI Mapping Wetland Plant Communities Using Unmanned Aerial Vehicle Hyperspectral Imagery by Comparing Object/Pixel-Based Classifications Combining Multiple Machine-Learning Algorithms
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Wetlands; Hyperspectral imaging; Unmanned aerial vehicles; Support vector machines; Classification algorithms; Spatial resolution; Monitoring; Community classification; hyperspectral remote sensing; machine learning; unmanned aerial vehicle (UAV); wetland
ID chlorophyll content; vegetation index; nature-reserve; land-cover; performance; habitat; china
AB Understanding the spatial patterns of plant communities is important for sustainable wetland ecosystem management and biodiversity conservation. With the rapid development of unmanned aerial vehicle (UAV) technology, UAV-borne hyperspectral data with high spatial resolution have become ideal for accurate classification of wetland plant communities. In this article, four dominant plant communities (Phragmites australis, Typha orientalis, Suaeda glauca, and Scirpus triqueter) and two unvegetated cover types (water and bare land) in the Momoge Ramsar wetland site were classified. This was achieved using UAV hyperspectral images and three object- and pixel-based machine-learning classification algorithms [random forest (RF), convolutional neural network (CNN), and support vector machine (SVM)]. First, spectral derivative analysis, logarithmic analysis, and continuum removal analysis identified the wavelength at which the greatest difference in reflectance occurs. Second, dimensionality reduction of hyperspectral images was conducted using principal component analysis. Subsequently, an optimal feature combination for community mapping was formed based on data transformation (spectral features, vegetation indices, and principal components). Image objects were obtained by segmenting the optimum object feature subsets. Finally, distribution maps of communities were produced by using three machine-learning classification algorithms. Our results reveal that object-based image analysis outperforms pixel-based methods, with overall accuracies (OAs) of 80.29-87.75%; RF has the highest OA of 87.75% (Kappa = 0.864), followed consecutively by CNN (OA = 83.31%, Kappa = 0.829) and SVM (OA = 80.29%, Kappa = 0.813). Phragmites australis dominates the plant community (55.9%) at the study area, followed by Typha orientalis (16.2%), Suaeda glauca (16.2%), and Scirpus triqueter (4.6%). The results highlight the importance of spectral transformation features in red-edge regions. The mapping results will help establish basic information for subsequent studies involving habitat suitability assessment at this study site.
C1 [Du, Baojia; Mao, Dehua; Wang, Zongming; Qiu, Zhiqiang; Feng, Kaidong] Chinese Acad Sci, Northeast Inst Geog & Agroecol, Key Lab Wetland Ecol & Environm, Changchun 130102, Peoples R China.
   [Du, Baojia; Qiu, Zhiqiang; Feng, Kaidong] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Mao, Dehua] Chinese Acad Sci, Changchun Jingyuetan Remote Sensing Observat Stn, Changchun 130102, Peoples R China.
   [Wang, Zongming] Natl Earth Syst Sci Data Ctr, Beijing 100101, Peoples R China.
   [Yan, Hengqi] YanBian Univ, Yanji 133002, Peoples R China.
   [Zhang, Zhongbin] Jilin Geol Surveying & Mapping Inst, Changchun 130062, Peoples R China.
C3 Chinese Academy of Sciences; Northeast Institute of Geography & Agroecology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Yanbian University
RP Mao, DH (corresponding author), Chinese Acad Sci, Northeast Inst Geog & Agroecol, Key Lab Wetland Ecol & Environm, Changchun 130102, Peoples R China.
EM dubaojia@iga.ac.cn; maodehua@iga.ac.cn; zongmingwang@iga.ac.cn; qiuzhiqiang@iga.ac.cn; yanhengqi1991@163.com; fengkaidong20@mails.ucas.ac.cn; zzb0206@126.com
FU National Natural Science Foundation of China [41771383]; Science and Technology Development Program of Jilin Province [20200301014RQ]; Scientific Research Instrument and Equipment Development Project of Chinese Academy of Sciences [YJKYYQ2019004]
CR Aasen H., 2014, INT ARCH PHOTOGRAMM, V40, P1, DOI 10.5194/isprsarchives-XL
   Aasen H, 2018, REMOTE SENS ENVIRON, V205, P374, DOI 10.1016/j.rse.2017.10.043
   Abdi AM, 2020, GISCI REMOTE SENS, V57, P1, DOI 10.1080/15481603.2019.1650447
   Abeysinghe T, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111380
   Adam E, 2017, J ARID ENVIRON, V145, P43, DOI 10.1016/j.jaridenv.2017.05.001
   Adam E, 2010, WETL ECOL MANAG, V18, P281, DOI 10.1007/s11273-009-9169-z
   Adao T, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111110
   Banerjee BP, 2020, INT J REMOTE SENS, V41, P4136, DOI 10.1080/01431161.2020.1714771
   BARET F, 1991, REMOTE SENS ENVIRON, V35, P161, DOI 10.1016/0034-4257(91)90009-U
   BIRTH GS, 1968, AGRON J, V60, P640, DOI 10.2134/agronj1968.00021962006000060016x
   Boyden J, 2013, J SPAT SCI, V58, P53, DOI 10.1080/14498596.2012.759086
   Broge NH, 2001, REMOTE SENS ENVIRON, V76, P156, DOI 10.1016/S0034-4257(00)00197-8
   Cai YT, 2019, ADV SPACE RES, V64, P2233, DOI 10.1016/j.asr.2019.08.042
   Cao JJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10122047
   Cao JJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010089
   Cao YL, 2020, PLOS ONE, V15, P0, DOI 10.1371/journal.pone.0238530
   Chen YQ, 2020, PEERJ, V8, P0, DOI 10.7717/peerj.8616
   Colgan MS, 2012, REMOTE SENS-BASEL, V4, P3462, DOI 10.3390/rs4113462
   Gitelson AA, 1996, J PLANT PHYSIOL, V148, P501, DOI 10.1016/S0176-1617(96)80285-9
   Grenier M, 2008, CAN J REMOTE SENS, V34, PS398, DOI 10.5589/m08-049
   Haboudane D, 2002, REMOTE SENS ENVIRON, V81, P416, DOI 10.1016/S0034-4257(02)00018-4
   Harken J, 2005, CAN J REMOTE SENS, V31, P167, DOI 10.5589/m05-003
   Harris JR, 2015, COMPUT GEOSCI-UK, V80, P9, DOI 10.1016/j.cageo.2015.03.013
   Hernandez-Clemente R, 2011, REMOTE SENS ENVIRON, V115, P2360, DOI 10.1016/j.rse.2011.04.036
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2
   HUETE AR, 1988, REMOTE SENS ENVIRON, V25, P295, DOI 10.1016/0034-4257(88)90106-X
   Hunt ER, 2011, AGRON J, V103, P1090, DOI 10.2134/agronj2010.0395
   Jiang HB, 2016, ECOL ENG, V96, P170, DOI 10.1016/j.ecoleng.2016.01.016
   Klemas V, 2013, J COASTAL RES, V29, P1016, DOI 10.2112/JCOASTRES-D-12-00237.1
   Kumar L, 2014, GISCI REMOTE SENS, V51, P483, DOI 10.1080/15481603.2014.947838
   Kumar T, 2019, GEOCARTO INT, V34, P415, DOI 10.1080/10106049.2017.1408699
   Laba M, 2008, REMOTE SENS ENVIRON, V112, P286, DOI 10.1016/j.rse.2007.05.003
   Liu M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010146
   Liu MY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121933
   Ma Y, 2016, PROC SPIE, V9796, P0, DOI 10.1117/12.2229746
   Mabhungu L, 2019, APPL ECOL ENV RES, V17, P7957, DOI 10.15666/aeer/1704_79577972
   Mao DH, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19102308
   Mao DH, 2018, SCI TOTAL ENVIRON, V634, P550, DOI 10.1016/j.scitotenv.2018.04.009
   Meneguzzo DM, 2013, ENVIRON MONIT ASSESS, V185, P6261, DOI 10.1007/s10661-012-3022-1
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Petropoulos GP, 2012, COMPUT GEOSCI-UK, V41, P99, DOI 10.1016/j.cageo.2011.08.019
   Poona NK, 2016, APPL SPECTROSC, V70, P322, DOI 10.1177/0003702815620545
   QI J, 1994, REMOTE SENS ENVIRON, V48, P119, DOI 10.1016/0034-4257(94)90134-1
   Rondeaux G, 1996, REMOTE SENS ENVIRON, V55, P95, DOI 10.1016/0034-4257(95)00186-7
   Roodposhti MS, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21010078
   ROUJEAN JL, 1995, REMOTE SENS ENVIRON, V51, P375, DOI 10.1016/0034-4257(94)00114-3
   Salas EAL, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0213356
   Sankey TT, 2018, REMOTE SENS ECOL CON, V4, P20, DOI 10.1002/rse2.44
   Majdar RS, 2020, EARTH SCI INFORM, V13, P55, DOI 10.1007/s12145-019-00411-1
   Sothe C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111338
   Underwood EC, 2006, ENVIRON MONIT ASSESS, V121, P47, DOI 10.1007/s10661-005-9106-4
   Verrelst J, 2009, INT J APPL EARTH OBS, V11, P83, DOI 10.1016/j.jag.2008.09.001
   Wang JN, 1998, P SOC PHOTO-OPT INS, V3502, P280, DOI 10.1117/12.317781
   Wang Y, 2013, CHINESE GEOGR SCI, V23, P708, DOI 10.1007/s11769-013-0641-6
   White L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12183024
   Wu YS, 2020, FORESTS, V11, P0, DOI 10.3390/f11010032
   Yan YA, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232753
   Yin WX, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0180534
   Yue JB, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9070708
   Yue Q, 2016, J SENSORS, V2016, P0, DOI 10.1155/2016/3150632
   Zhang N, 2020, PLANT METHODS, V16, P0, DOI 10.1186/s13007-020-00678-2
   Zhang YL, 2011, INT J REMOTE SENS, V32, P545, DOI 10.1080/01431160903475241
   Zhang Y, 2017, J ENVIRON ENG LANDSC, V25, P367, DOI 10.3846/16486897.2017.1316982
   Zhou XC, 2017, IEEE GEOSCI REMOTE S, V14, P97, DOI 10.1109/LGRS.2016.2630045
   Zhou X, 2020, CHEMOMETR INTELL LAB, V200, P0, DOI 10.1016/j.chemolab.2020.103996
   Zomer RJ, 2009, J ENVIRON MANAGE, V90, P2170, DOI 10.1016/j.jenvman.2007.06.028
NR 66
TC 11
Z9 11
U1 18
U2 50
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 8249
EP 8258
DI 10.1109/JSTARS.2021.3100923
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UK8JJ
UT WOS:000692210900012
DA 2023-04-26
ER

PT J
AU Pradhan, AMS
   Kim, YT
AF Pradhan, Ananta Man Singh
   Kim, Yun-Tae
TI An artificial intelligence-based approach to predicting seismic hillslope stability under extreme rainfall events in the vicinity of Wolsong nuclear power plant, South Korea
SO BULLETIN OF ENGINEERING GEOLOGY AND THE ENVIRONMENT
LA English
DT Article
DE Deep learning neural network; Extreme rainfall; GIS; Gyeongju earthquake; Landslide susceptibility; Sampling points
AB Rainfall and earthquakes are two significant triggering factors of mass movement. Since the Gyeongju earthquake on 12 September 2016, which took place near the Wolsong nuclear power plant, many concerns have been raised about the threat posed by landslides during intense rainfall. In this study, we developed a new methodological approach to assess the stability of hillslopes at the catchment scale. We applied a geographical information system (GIS)-based pseudo-static model to 10,000 representative sample points by coupling the steady state infiltration corresponding to extreme rainfall and seismic force. Thus, we obtained the factor of safety of the representative sample points and set it as our target variable. The target variable was divided into two subsets: 80% of the data was used to train the model and 20% was reserved for testing purposes. We then applied a deep learning neural network method to incorporate other spatial geo-environmental data such as topographic, hydrologic, soil. forest, and geology, i.e., independent variables that can be used to predict the factor of safety in the catchment scale. The accuracy of the model was assessed using Pearson's correlation coefficient, which was 0.97 and 0.98 and root mean square error 0.301 and 0.290 in the cases of the training and testing darn, respectively. The prediction results indicate that the integration approach produces reliable, accurate landslide susceptibility maps, which may be helpful to researchers working on landslide management strategies.
C1 [Pradhan, Ananta Man Singh] Govt Nepal, Water Resources Res & Dev Ctr, Pulchowk 44700, Lalitpur, Nepal.
   [Kim, Yun-Tae] Pukyong Natl Univ, Dept Ocean Engn, Geosyst s Engn Lab, 599-1 Daeyeon3 Dong, Busan 48513, South Korea.
C3 Pukyong National University
RP Kim, YT (corresponding author), Pukyong Natl Univ, Dept Ocean Engn, Geosyst s Engn Lab, 599-1 Daeyeon3 Dong, Busan 48513, South Korea.
EM yuntkim@pknu.ac.kr
FU Korea Agency for Infrastructure Technology Advancement (KAIA) - Ministry of Land, Infrastructure and Transport [19TSRD-B151228-01]
CR Acharya KP, 2016, GEOMAT NAT HAZ RISK, V7, P156, DOI 10.1080/19475705.2014.880856
   AMBRASEYS NN, 1988, EARTHQUAKE ENG STRUC, V16, P985, DOI 10.1002/eqe.4290160704
   [Anonymous], 1966, J ENG MECH DIV, V0, P0
   Bird JF, 2004, ENG GEOL, V75, P147, DOI 10.1016/j.enggeo.2004.05.006
   Biswas A, 2018, PEDOSPHERE, V28, P1, DOI 10.1016/S1002-0160(18)60001-3
   Braunisch V, 2013, ECOGRAPHY, V36, P971, DOI 10.1111/j.1600-0587.2013.00138.x
   Castellanos Abella E.A., 2007, LANDSLIDES, V4, P311, DOI 10.1007/s10346-007-0087-y
   Catani F, 2013, NAT HAZARD EARTH SYS, V13, P2815, DOI 10.5194/nhess-13-2815-2013
   Catani F, 2010, WATER RESOUR RES, V46, P0, DOI 10.1029/2008WR007450
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Chollet, 2019, KERAS R INTERFACE KE, V2, P0
   Conforti M, 2014, CATENA, V113, P236, DOI 10.1016/j.catena.2013.08.006
   Cortez P., 2011, PROCEEDINGS 2011 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING (CIDM 2011), V0, PP341, DOI 10.1109/CIDM.2011.5949423
   Cortez P, 2013, INFORM SCIENCES, V225, P1, DOI 10.1016/j.ins.2012.10.039
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI 10.1561/2000000039
   DIETRICH WE, 1995, HYDROL PROCESS, V9, P383, DOI 10.1002/hyp.3360090311
   Bui DT, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104426
   Bui DT, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8090395
   Dao DV, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104451
   Ercanoglu M, 2004, NAT HAZARDS, V32, P1, DOI 10.1023/B:NHAZ.0000026786.85589.4a
   Erzin Y, 2012, SCI IRAN, V19, P188, DOI 10.1016/j.scient.2012.02.008
   Erzin Y, 2014, GEOMECH ENG, V6, P1
   Florian A, 1992, PROBALISTIC ENG MECH, V7, P123, DOI 10.1016/0266-8920(92)90015-A
   Garson DG., 1991, AI EXPERT, V6, P47, DOI 10.5555/129449.129452
   Gedeon TD, 1997, INT J NEURAL SYST, V8, P209, DOI 10.1142/S0129065797000227
   Goetz JN, 2011, GEOMORPHOLOGY, V129, P376, DOI 10.1016/j.geomorph.2011.03.001
   Gokceoglu C, 1996, ENG GEOL, V44, P147, DOI 10.1016/S0013-7952(97)81260-4
   Huang L, 2018, NEURAL PROCESS LETT, V48, P1243, DOI 10.1007/s11063-017-9778-0
   Huang MW, 2012, J MT SCI-ENGL, V9, P601, DOI 10.1007/s11629-012-2434-2
   Iida T., 1984, JPN GEOMORPH UNION T, V5, P1
   Iverson RM, 2000, WATER RESOUR RES, V36, P1897, DOI 10.1029/2000WR900090
   Jibson RW, 2011, ENG GEOL, V122, P43, DOI 10.1016/j.enggeo.2010.09.017
   Kim MS, 2016, GEOMORPHOLOGY, V271, P40, DOI 10.1016/j.geomorph.2016.07.031
   Kim Y, 2016, GEOSCI J, V20, P747, DOI 10.1007/s12303-016-0033-x
   Kim YT, 2018, EGUGA, V0, P17502
   Kwag S, 2018, NUCL ENG TECHNOL, V50, P1372, DOI 10.1016/j.net.2018.07.016
   Lee K, 2006, B SEISMOL SOC AM, V96, P846, DOI 10.1785/0120050050
   Lee S, 2006, NAT HAZARD EARTH SYS, V6, P687, DOI 10.5194/nhess-6-687-2006
   Lin GW, 2019, B ENG GEOL ENVIRON, V78, P497, DOI 10.1007/s10064-017-1083-7
   Lin ML, 2004, ENG GEOL, V71, P63, DOI 10.1016/S0013-7952(03)00126-1
   Lin Z., 2015, ARXIV PREPRINT ARXIV, V0, P0
   Luong H. T., 2020, CIGOS 2019, V0, P0
   Marblestone AH, 2016, FRONT COMPUT NEUROSC, V10, P0, DOI 10.3389/fncom.2016.00094
   Marcuson WF, 1981, INT C REC ADV GEOT E, V0, P0
   Matasovic N, 1991, P 2 INT C REC ADV GE, V0, P1057
   Minasny B, 2006, COMPUT GEOSCI-UK, V32, P1378, DOI 10.1016/j.cageo.2005.12.009
   MOORE ID, 1986, WATER RESOUR RES, V22, P1350, DOI 10.1029/WR022i008p01350
   MOORE ID, 1991, HYDROL PROCESS, V5, P3, DOI 10.1002/hyp.3360050103
   NEWMARK NM, 1965, GEOTECHNIQUE, V15, P139, DOI 10.1680/geot.1965.15.2.139
   Oliveira SC, 2017, NAT HAZARD EARTH SYS, V17, P1091, DOI 10.5194/nhess-17-1091-2017
   PACHAURI AK, 1992, ENG GEOL, V32, P81, DOI 10.1016/0013-7952(92)90020-Y
   Park NW, 2015, ENVIRON EARTH SCI, V73, P937, DOI 10.1007/s12665-014-3442-z
   Park S, 2016, B SEISMOL SOC AM, V106, P499, DOI 10.1785/0120150158
   Pearson K, 1920, BIOMETRIKA, V13, P25, DOI 10.1093/biomet/13.1.25
   Pearson K., 1895, P R SOC LONDON, V58, P240, DOI 10.1098/RSPL.1895.0041
   Pradhan AMS, 2019, LANDSLIDES, V16, P647, DOI 10.1007/s10346-018-1112-z
   Pradhan AMS, 2019, B ENG GEOL ENVIRON, V78, P131, DOI 10.1007/s10064-017-1055-y
   Pradhan AMS, 2014, NAT HAZARDS, V72, P1189, DOI 10.1007/s11069-014-1065-z
   Roda-Boluda DC, 2018, EARTH SURF PROC LAND, V43, P956, DOI 10.1002/esp.4281
   Roudier P, 2012, DIGITAL SOIL ASSESSMENTS AND BEYOND, V0, P227
   Russell S., 2002, ARTIF INTELL, V0, P0
   Saygili G, 2008, J GEOTECH GEOENVIRON, V134, P790, DOI 10.1061/(ASCE)1090-0241(2008)134:6(790)
   Schmidt J, 2003, INT J GEOGR INF SCI, V17, P797, DOI 10.1080/13658810310001596058
   Shrestha S., 2017, NEPAL B ENG GEOL ENV, V78, P1
   Sidle R. C., 1985, HILLSLOPE STABILITY AND LAND USE., V0, P0
   Stewart JP, 2003, EARTHQ SPECTRA, V19, P697, DOI 10.1193/1.1597877
   Tajima F, 2013, TECTONOPHYSICS, V586, P15, DOI 10.1016/j.tecto.2012.09.014
   Tang C, 2011, ENG GEOL, V122, P22, DOI 10.1016/j.enggeo.2011.03.013
   Taniguchi E, 1985, P 11 INT C SOIL MECH, V0, P1
   Wang M, 2010, J MT SCI-ENGL, V7, P339, DOI 10.1007/s11629-010-2054-7
   Wasowski J, 2011, ENG GEOL, V122, P1, DOI 10.1016/j.enggeo.2011.06.001
   Wilson JP, 2000, TERRAIN ANAL PRINCIP, V0, P0
   Yalcin A, 2007, APPL CLAY SCI, V38, P77, DOI 10.1016/j.clay.2007.01.007
   Yang BB, 2019, LANDSLIDES, V16, P677, DOI 10.1007/s10346-018-01127-x
NR 74
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1435-9529
EI 1435-9537
J9 B ENG GEOL ENVIRON
JI Bull. Eng. Geol. Environ.
PD MAY 15
PY 2021
VL 80
IS 5
BP 3629
EP 3646
DI 10.1007/s10064-021-02138-0
EA FEB 2021
PG 18
WC Engineering, Environmental; Engineering, Geological; Geosciences, Multidisciplinary
SC Engineering; Geology
GA RO4OF
UT WOS:000621700100001
DA 2023-04-26
ER

PT J
AU Aroonsri, I
   Sangpradid, S
AF Aroonsri, Ilada
   Sangpradid, Satith
TI ARTIFICIAL NEURAL NETWORKS FOR THE CLASSIFICATION OF SHRIMP FARM FROM SATELLITE IMAGERY
SO GEOGRAPHIA TECHNICA
LA English
DT Article
DE Key- Sentinel-2 imagery; Supervise classification; Land use change detection; artificial neural networks (ANN)
ID sentinel-2
AB Shrimp production was the high demand for the popular in the global market in Thailand. The change of land use is important for the management and monitoring of land use changed. The objectives of this paper to (1) classification of shrimp farm using artificial neural networks (ANN) technique from the Sentinel-2 imagery. (2) change detection of land use changes map among 2015, 2018, and 2020. The land use classification based on ANN technique and the accuracy assessment by used the confusion matrices and kappa coefficient. The classify of land use classes divide into built-up, forest, water bodies, paddy field, shrimp farm, and field crop. The change detection methods used was the image differencing technique was performed to the land use changes map. The result of land use classification show that the field crop area was 80% cover the most area. The result of land use changed show that built-up, paddy field, and shrimp farm increased throughout between year 2015 to 2020. The shrimp farm between year 2015 to 2020 to increasing trend of related with the shrimp production was the high demand for the popular in the global market.
C1 [Aroonsri, Ilada] Valaya Alongkorn Rajabhat Univ Royal Patronage, Fac Management Sceinces, Dept Business Digital, 1,Moo 10,Klong 1, Klongluang 13180, Pathum Thani, Thailand.
   [Sangpradid, Satith] Mahasarakham Univ, Fac Informat, Res Unit Geoinformat Local Dev, Maha Sarakham 44150, Thailand.
   [Sangpradid, Satith] Mahasarakham Univ, Fac Informat, Dept Geoinformat, Maha Sarakham 44150, Thailand.
C3 Valaya Alongkorn Rajabhat University; Mahasarakham University; Mahasarakham University
RP Aroonsri, I (corresponding author), Valaya Alongkorn Rajabhat Univ Royal Patronage, Fac Management Sceinces, Dept Business Digital, 1,Moo 10,Klong 1, Klongluang 13180, Pathum Thani, Thailand.
EM ilada@vru.ac.th; satith.s@msu.ac.th
FU Faculty of Informatics, Mahasarakham University; Research unit of Geo-informatics for Local Development; Faculty of Management Sciences, Valaya Alongkorn Rajabhat University Under the Royal Patronage
CR Ahmad A, 2013, APPL MATH SCI, V7, P3681, DOI 10.12988/AMS.2013.34214
   Alonso-Perez F, 2003, OCEAN COAST MANAGE, V46, P583, DOI 10.1016/S0964-5691(03)00036-X
   Costantino D, 2020, GEOGR TECH, V15, P171, DOI 10.21163/GT_2020.152.17
   Dorber M, 2020, REMOTE SENS APPL, V20, P0, DOI 10.1016/j.rsase.2020.100416
   Erbek FS, 2004, INT J REMOTE SENS, V25, P1733, DOI 10.1080/0143116031000150077
   FOODY GM, 1995, PHOTOGRAMM ENG REM S, V61, P391
   Ge GBT, 2020, GLOB ECOL CONSERV, V22, P0, DOI 10.1016/j.gecco.2020.e00971
   Jomsrekrayom N, 2021, GEOGR TECH, V16, P70, DOI 10.21163/GT_2021.163.06
   Kovacs KD, 2019, GEOGR TECH, V14, P20, DOI 10.21163/GT_2019.142.03
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Mahmon NA, 2014, 2014 IEEE 5TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), V0, PP153, DOI 10.1109/ICSGRC.2014.6908713
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Maung WS, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010052
   Migas-Mazur R, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13163314
   Ottinger M, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050440
   Panuju DR, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111781
   Pradabmook P., 2021, ARPN J ENG APPL SCI, V16, P823
   Punalekar SM, 2021, AGRONOMY-BASEL, V11, P0, DOI 10.3390/agronomy11081661
   Rajitha K, 2007, AQUACULT ENG, V36, P1, DOI 10.1016/j.aquaeng.2006.05.003
   Sangpradid S., 2018, INT J GEOINFORMATICS, V14, P71
   Santaga FS, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13173379
   Shrestha S., 2012, 1 SENT 2 PREP S FRAS, V0, P0
   Stiller D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141707
   Thai Shrimp Association, 2019, SHRIMP SIT THAIL 202, V0, P0
   Toosi NB, 2019, GLOB ECOL CONSERV, V19, P0, DOI 10.1016/j.gecco.2019.e00662
   Toshniwal M., 2005, 3 INT C SCI EL TECHN, V0, P0
   Urban M, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13173342
   Vanderhoof M.K., 1900, V4, V0, P52
   Varghese D, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13173355
   Xiong Y., 2010, INT C COMP APPL SYST, V0, P52
   Yaday P., 2010, INT J REMOTE SENSING, V1, P90
NR 32
TC 0
Z9 0
U1 1
U2 2
PU CLUJ UNIV PRESS
PI CLUJ NAPOCA
PA STRADA B P HASDEU NR 51, CLUJ NAPOCA, 400371, ROMANIA
SN 1842-5135
EI 2065-4421
J9 GEOGR TECH
JI Geogr. Tech.
PD OCT 15
PY 2021
VL 16
IS 2
BP 149
EP 159
DI 10.21163/GT_2021.162.12
PG 11
WC Geography, Physical
SC Physical Geography
GA WL7WI
UT WOS:000710611000012
DA 2023-04-26
ER

PT J
AU Mansouri, T
   ZareRavasan, A
   Ashrafi, A
AF Mansouri, Taha
   ZareRavasan, Ahad
   Ashrafi, Amir
TI A LEARNING FUZZY COGNITIVE MAP (LFCM) APPROACH TO PREDICT STUDENT PERFORMANCE
SO JOURNAL OF INFORMATION TECHNOLOGY EDUCATION-RESEARCH
LA English
DT Article
DE e-learning; Learning Analytics (LA); Learning Fuzzy Cognitive Map (LFCM); Learning Management System (LMS); Student Engagement; Student Performance
ID structural equation model; higher-education; satisfaction; optimization; engagement; quality; determinants; antecedents; information; achievement
AB Aim/Purpose This research aims to present a brand-new approach for student performance prediction using the Learning Fuzzy Cognitive Map (LFCM) approach. Background Predicting student academic performance has long been an important research topic in many academic disciplines. Different mathematical models have been employed to predict student performance. Although the available sets of common prediction approaches, such as Artificial Neural Networks (ANN) and regression, work well with large datasets, they face challenges dealing with small sample sizes, limiting their practical applications in real practices. Methodology Six distinct categories of performance antecedents are adopted here as course characteristics, LMS characteristics, student characteristics, student engagement, student support, and institutional factors, along with measurement items within each category. Furthermore, we assessed the student's overall performance using three items of student satisfaction score, knowledge construction level, and student GPA. We have collected longitudinal data from 30 postgraduates in four subsequent semesters and analyzed data using the Learning Fuzzy Cognitive Map (LFCM) technique. Contribution This research proposes a brand new approach, Learning Fuzzy Cognitive Map (LFCM), to predict student performance. Using this approach, we identified the most influential determinants of student performance, such as student engagement. Besides, this research depicts a model of interrelations among the student performance determinants. Findings The results suggest that the model reasonably predicts the incoming sequence when there is a limited sample size. The results also reveal that students' total online time and the regularity of learning interval in LMS have the largest effect on overall performance. The student engagement category also has the highest direct effect on student's overall performance. Recommendations Academic institutions can use the results and approach developed in this paper for Practitioners to identify students' performance antecedents, predict the performance, and establish action plans to resolve the shortcomings in the long term. Instructors can adjust their learning methods based on the feedback from students in the short run on the operational level. Recommendations Researchers can use the proposed approach in this research to deal with the for Researchers problems in other domains, such as using LMS for organizational/institutional education. Besides, they can focus on specific dimensions of the proposed model, such as exploring ways to boost student engagement in the learning process. Impact on Society Our results revealed that students are at the center of the learning process. The degree to which they are dedicated to learning is the most crucial determinant of the learning outcome. Therefore, learners should consider this finding in order the gain value from the learning process. Future Research As a potential for future works, the proposed approach could be used in other contexts to test its applicability. Future studies could also improve the performance level of the proposed LFMC model by tuning the model's elements.
C1 [Mansouri, Taha] Univ Salford, Sch Sci Engn & Environm, Salford, Lancs, England.
   [ZareRavasan, Ahad] Masaryk Univ, Fac Econ & Adm, Dept Corp Econ, Brno, Czech Republic.
   [Ashrafi, Amir] Univ Manchester, Business & Management, Alliance Manchester Business Sch, Manchester, Lancs, England.
C3 University of Salford; Masaryk University Brno; University of Manchester; Alliance Manchester Business School
RP ZareRavasan, A (corresponding author), Masaryk Univ, Fac Econ & Adm, Dept Corp Econ, Brno, Czech Republic.
EM T.Mansouri@salford.ac.uk; Ahad.ZareRavasan@econ.muni.cz; Amir.Ashrafi@postgrad.manchester.ac.uk
CR Abdous M, 2012, EDUC TECHNOL SOC, V15, P77
   Abdulwahhab R. S., 2017, 6 INT C INF COMM TEC, V0, PP1, DOI 10.1109/ICTA.2017.8336060
   Al Breiki B., 2019, 2019 INT C EL COMP T, V0, P1
   Al-Azawei A, 2016, INT REV RES OPEN DIS, V17, P126
   [Anonymous], 2010, 2010 6 INT C WIRELES, V0, P0, DOI DOI 10.1016/J.NEULET.2010.03.079.PUBMED
   Anusha G., 2015, STUDY SYMPTOMS STRES, V0, P0
   Ashrafi A, 2022, INTERACT LEARN ENVIR, V30, P1475, DOI 10.1080/10494820.2020.1734028
   Baloyi G. P, 2014, MEDITERRANEAN J SOCI, V5, P1251
   Baloyi G.P., 2014, J COMMUN, V5, P127
   Baykasoglu A, 2015, INFORM SCIENCES, V301, P75, DOI 10.1016/j.ins.2014.12.048
   Baron HB, 2015, SOFT COMPUT, V19, P1037, DOI 10.1007/s00500-014-1313-x
   Bueno S, 2009, EXPERT SYST APPL, V36, P5221, DOI 10.1016/j.eswa.2008.06.072
   Castellano Emilio J., 2008, E LEARNING, V0, P38
   Chawinga WD, 2016, INT REV RES OPEN DIS, V17, P1
   Cheng G, 2016, BRIT J EDUC TECHNOL, V47, P257, DOI 10.1111/bjet.12243
   Chrysafiadi K, 2015, IEEE T FUZZY SYST, V23, P164, DOI 10.1109/TFUZZ.2014.2310242
   Chrysafiadi K, 2013, SPRINGERPLUS, V2, P0, DOI 10.1186/2193-1801-2-81
   Clow D, 2013, TEACH HIGH EDUC, V18, P683, DOI 10.1080/13562517.2013.827653
   Dias SB, 2015, EXPERT SYST APPL, V42, P7399, DOI 10.1016/j.eswa.2015.05.048
   Farasat A, 2010, APPL SOFT COMPUT, V10, P1284, DOI 10.1016/j.asoc.2010.05.011
   Fatahi S, 2016, COMPUT HUM BEHAV, V63, P272, DOI 10.1016/j.chb.2016.05.041
   Ferguson JM, 2010, INT REV RES OPEN DIS, V11, P73, DOI 10.19173/irrodl.v11i2.772
   Georgiou DA, 2008, IEEE INT CONF FUZZY, V0, P2204
   Georgopoulos VC, 2014, IEEE ENG MED BIO, V0, PP1813, DOI 10.1109/EMBC.2014.6943961
   Gowda S.M., 2013, PROC INT C LEARN ANA, V0, P117
   Grant-Vallone E., 2003, J COLL STUD RETENT-R, V5, P255, DOI 10.2190/C0T7-YX50-F71V-00CW
   Hadullo K., 2017, INT J ED DEV USING I, V13, P0
   Hobbs BF, 2002, ECOL APPL, V12, P1548, DOI 10.1890/1051-0761(2002)012[1548:FCMAAT]2.0.CO;2
   Holmes T, 2019, 2019 IEEE FRONT ED C, V0, PP1, DOI 10.1109/FIE43999.2019.9028350
   Hossain S, 2008, COMPUT EDUC, V51, P1569, DOI 10.1016/j.compedu.2008.03.002
   Hu PJH, 2012, DECIS SUPPORT SYST, V53, P782, DOI 10.1016/j.dss.2012.05.014
   Huang S, 2013, COMPUT EDUC, V61, P133, DOI 10.1016/j.compedu.2012.08.015
   Hughes JN, 2006, J SCHOOL PSYCHOL, V43, P465, DOI 10.1016/j.jsp.2005.10.001
   Hwang GJ, 2015, AUSTRALAS J EDUC TEC, V31, P400
   Kaba B, 2013, INT J INFORM MANAGE, V33, P441, DOI 10.1016/j.ijinfomgt.2013.01.010
   Kahvandi Z., 2018, LEAN CONSTRUCTION J, V2018, P63
   Kashorda M., 2014, E READINESS SURVEY K, V0, P0
   Kireev V. S., 2016, INT C DAT AN MAN DAT, V0, P0, DOI DOI 10.1007/978-3-319-57135-5_4
   Kisanga DH, 2016, INT REV RES OPEN DIS, V17, P109
   Knight S, 2020, INTERNET HIGH EDUC, V45, P0, DOI 10.1016/j.iheduc.2020.100729
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kumar A. N. V., 2009, EUR J SCI RES, V34, P526
   Lai MM, 2015, J MARK HIGH EDUC, V25, P45, DOI 10.1080/08841241.2015.1042097
   Lang C., 2017, HDB LEARNING ANAL, V0, P0, DOI DOI 10.18608/hla17
   Long Phil, 2011, EDUCAUSE REVIEW, V46, P31
   Lykourentzou I, 2009, J AM SOC INF SCI TEC, V60, P372, DOI 10.1002/asi.20970
   Macfadyen LP, 2010, COMPUT EDUC, V54, P588, DOI 10.1016/j.compedu.2009.09.008
   Makokha GL, 2016, INT REV RES OPEN DIS, V17, P341
   Mansouri T, 2011, EXPERT SYST APPL, V38, P4866, DOI 10.1016/j.eswa.2010.09.084
   Masood MF, 2019, INT CONF SOFT COMP, V0, PP12, DOI 10.1109/ISCMI47871.2019.9004299
   Mayoka K., 2012, INFORM TECHNOLOGY RE, V2, P1
   Meghji A. F., 2018, P 2018 5 INT MULT IC, V0, P1
   Misopoulos F., 2018, LINE, V0, PP235, DOI 10.1007/978-3-319-62776-2_18
   Mohammadi M, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), V0, PP124, DOI 10.1109/ICAIIC.2019.8669085
   Moridis CN, 2009, COMPUT EDUC, V53, P644, DOI 10.1016/j.compedu.2009.04.002
   Muntean CI, 2011, PROC INT C VIRTUAL L, V0, P323
   Muuro ME, 2014, INT REV RES OPEN DIS, V15, P132
   Mwalumbwe I, 2017, ELECTR J INF SYS DEV, V79, P0
   Ngandu M. R., 2015, C EM TECHN AUTH LEAR, V0, P0
   Nguyen Thai-Nghe, 2011, 2011 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES (ICALT 2011), V0, PP412, DOI 10.1109/ICALT.2011.130
   Nguyen TN, 2010, PROCEDIA COMPUT SCI, V1, P2811, DOI 10.1016/j.procs.2010.08.006
   Nownaisin P., 2012, P IEEE INT C TEACH A, V0, P0, DOI DOI 10.1109/TALE.2012.6360392
   PANDEY H, 2015, INT J COMPUTER APPL, V122, P18, DOI 10.5120/21793-5140
   Panigrahi R, 2018, INT J INFORM MANAGE, V43, P1, DOI 10.1016/j.ijinfomgt.2018.05.005
   Papageorgiou EI, 2012, APPL SOFT COMPUT, V12, P3798, DOI 10.1016/j.asoc.2012.03.064
   Papamitsiou Z, 2014, EDUC TECHNOL SOC, V17, P49
   Pappas C, 2015, SHORT ANSWER QUESTIO, V0, P0
   Pena A, 2007, LECT NOTES ARTIF INT, V4496, P328
   Pye G, 2016, AUSTRALAS J INF SYST, V20, P0, DOI 10.3127/ajis.v19i0.1251
   Queiros DR, 2016, INT REV RES OPEN DIS, V17, P165
   Raga RC, 2019, 2019 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET 2019), V0, PP39, DOI 10.1109/ISET.2019.00018
   Raspopovic M, 2014, INT REV RES OPEN DIS, V15, P1
   Ravasan AZ, 2016, PROD PLAN CONTROL, V27, P65, DOI 10.1080/09537287.2015.1064551
   Ravasan AZ, 2014, INT J ENTERP INF SYS, V10, P32, DOI 10.4018/ijeis.2014010103
   Romero-Zaldivar VA, 2012, COMPUT EDUC, V58, P1058, DOI 10.1016/j.compedu.2011.12.003
   Ros S, 2015, BRIT J EDUC TECHNOL, V46, P1250, DOI 10.1111/bjet.12199
   Roy R., 2004, DISTANCE ED TECHNOLO, V0, P129
   Salik E. D., 2019, 2019 IEEE 30 ANN INT, V0, P1
   Salmeron JL, 2019, KNOWL-BASED SYST, V163, P723, DOI 10.1016/j.knosys.2018.09.034
   Salmeron JL, 2016, KNOWL-BASED SYST, V105, P29, DOI 10.1016/j.knosys.2016.04.023
   Salmeron JL, 2009, KNOWL-BASED SYST, V22, P275, DOI 10.1016/j.knosys.2009.01.002
   Sharma SK, 2017, BEHAV INFORM TECHNOL, V36, P1053, DOI 10.1080/0144929X.2017.1340973
   Sheshadri A., 2018, P 11 INT C ED DATA M, V0, P411
   Siegle D, 2010, GIFTED CHILD QUART, V54, P92, DOI 10.1177/0016986209355975
   Ssekakubo Grace, 2011, P S AFR I COMP SCI I, V0, PP231, DOI 10.1145/2072221.2072248
   Sweta S., 2016, IOSR J COMPUTER ENG, V18, P18, DOI 10.9790/0661-1802041824
   Takacs M, 2014, INT CONF SYST SCI EN, V0, PP284, DOI 10.1109/ICSSE.2014.6887950
   Tarus JK, 2015, INT REV RES OPEN DIS, V16, P120
   Thai-Nghe N, 2009, INT CONF INTELL SYST, V0, PP878, DOI 10.1109/ISDA.2009.15
   TOSCHER A, 2010, P KDD CUP, V0, P0
   Tsadiras A., 2008, P 6 INT C NETW LEARN, V0, P376
   Turabieh H., 2019, 2019 2 INT C NEW TRE, V0, P0, DOI DOI 10.1109/ICTCS.2019.8923093
   Umer R, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, V0, P0
   van Vliet M, 2010, FUTURES, V42, P1, DOI 10.1016/j.futures.2009.08.005
   Vialardi C, 2011, USER MODEL USER-ADAP, V21, P217, DOI 10.1007/s11257-011-9098-4
   Yang F., 2011, ADV WEBBASED LEARNIN, V0, P0, DOI DOI 10.1007/978-3-642-25813-8_19
   Yesil E, 2013, INT CONF INFO TECH, V0, P0
   ZareRavasan A., 2018, IT MANAGEMENT STUDIE, V6, P87
   Zareravasan A, 2019, PROCEEDINGS OF 9TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2019), V0, PP165, DOI 10.1145/3357419.3357429
   Zhang WY, 2012, INT REV RES OPEN DIS, V13, P66, DOI 10.19173/irrodl.v13i3.1181
   Zhu C, 2012, EDUC TECHNOL SOC, V15, P127
NR 101
TC 4
Z9 4
U1 7
U2 17
PU INFORMING SCIENCE INST
PI SANTA ROSA
PA 131 BROOKHILL CT, SANTA ROSA, CA 95409 USA
SN 1547-9714
EI 1539-3585
J9 J INF TECHNOL EDUC-R
JI J. Inf. Technol. Educ.-Res.
PD JUN 15
PY 2021
VL 20
IS 
BP 
EP 
DI 10.28945/4760
PG 23
WC Education & Educational Research
SC Education & Educational Research
GA TD9CY
UT WOS:000669616700001
DA 2023-04-26
ER

PT J
AU Paliwal, S
   Sharma, M
   Vig, L
AF Paliwal, Shubham
   Sharma, Monika
   Vig, Lovekesh
TI OSSR-PID: One-Shot Symbol Recognition in P&ID Sheets using Path Sampling and GCN
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
LA English
DT Proceedings Paper
AB In this paper, we focus on recognition of line-drawn symbols in engineering drawings with only one prototypical example per symbol available for training. In particular, Piping and Instrumentation Diagrams (P&ID) are ubiquitous in several manufacturing, oil and gas enterprises for representing engineering schematics and equipment layout. There is an urgent need to extract and digitize information from P&IDs without the cost of annotating a varying set of symbols for each new use case. A robust one-shot learning approach for symbol recognition i.e., localization followed by classification, would therefore go a long way towards this goal. Our method works by sampling pixels sequentially along the different contour boundaries in the image. These sampled points form paths which are used in the prototypical line diagram to construct a graph that captures the structure of the contours. Subsequently, the prototypical graphs are fed into a Dynamic Graph Convolutional Neural Network (DGCNN) which is trained to classify graphs into one of the given symbol classes. Further, we append embeddings from a Resnet-34 network which is trained on symbol images containing sampled points to make the classification network more robust. Since, many symbols in P&ID are structurally very similar to each other, we utilize Arcface loss during DGCNN training which helps in maximizing symbol class separability by producing highly discriminative embeddings. During inference time, a similar line based sampling procedure is adopted for generating sampled points across P&ID image. The images consist of components attached on the pipeline (straight line). The sampled points segregated around the symbol regions are used for the classification task. The proposed pipeline, named OSSR-PID, is fast and gives outstanding performance for recognition of symbols on a synthetic dataset of 100 P&ID diagrams. We also compare our method against prior-work that uses full supervision (not one-shot) on a real-world private dataset of 12 P&ID sheets and obtain comparable/superior results. Remarkably, it is able to achieve such excellent performance using only one prototypical example per symbol.
C1 [Paliwal, Shubham; Sharma, Monika; Vig, Lovekesh] TCS Res, Pune, Maharashtra, India.
RP Paliwal, S (corresponding author), TCS Res, Pune, Maharashtra, India.
EM shubham.p3@tcs.com; monika.sharma1@tcs.com; lovekesh.vig@tcs.com
CR Arroyo E., 2014, P 2014 IEEE EM TECHN, V0, PP1, DOI 10.1109/ETFA.2014.7005098
   Arroyo E., 2015, PROCEEDING IEEE INT, V0, PP1, DOI 10.1109/
   BENJAMIN D, 1988, 1988 PROCEEDINGS 9TH, V1, P119
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Deng J., 2019, P IEEE CVF C COMP VI, V0, P4690
   DONG X, 2019, ARXIV, V0, P0
   FAHN CS, 1988, COMPUT VISION GRAPH, V44, P119, DOI 10.1016/S0734-189X(88)80001-X
   Gonzalez R C, 2004, DIGITAL IMAGE PROCES, V0, P0
   GUPTA G, 2017, ICDAR 2017, V0, P33
   JOSEPH SH, 1992, IEEE T PATTERN ANAL, V14, P928, DOI 10.1109/34.161351
   KATO H, 1990, PROCEEDINGS 10TH INT, V1, P578
   Khan A, 2019, IEEE INT C INT ROBOT, V0, PP7558, DOI 10.1109/IROS40897.2019.8968483
   Li Z., 2017, FSSD FEATURE FUSION, V0, P0
   Liu MY, 2019, IEEE I CONF COMP VIS, V0, PP10550, DOI 10.1109/ICCV.2019.01065
   MAINI R, 2009, INT J IMAGE PROCESSI, V0, P0
   RAHUL R, 2018, COMPUTER VISION ACCV, V0, P159
   Rahul R, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, V0, PP163, DOI 10.5220/0007376401630172
   Ren MY, 2018, PROC CVPR IEEE, V0, PP8711, DOI 10.1109/CVPR.2018.00908
   SATORRAS VG, 2018, ICLR 2018, V0, P0
   SELINGER P, 2003, POTRACE A POLYGONBAS, V0, P0
   Snell J, 2017, CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE (UAI2017), V0, P0
   Vinyals O., 2016, P ADV NEURAL INFORM, V29, P3630, DOI 10.48550/arXiv.1606.04080
   WANG DM, 1995, PATTERN RECOGN, V28, P1783, DOI 10.1016/0031-3203(95)00036-Y
   Wang X., 2019, IEEE CVPR, V0, P0
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Wojke N, 2018, IEEE WINT CONF APPL, V0, PP748, DOI 10.1109/WACV.2018.00087
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yan L, 2003, PROC INT CONF DOC, V0, P190
   Zhihu H, 2010, 2010 2 INT C COMP EN, V0, P0, DOI DOI 10.1109/ICCET.2010.5485542
NR 30
TC 2
Z9 2
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-4393
EI 
J9 IEEE IJCNN
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/IJCNN52387.2021.9534122
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA BS4TO
UT WOS:000722581706074
DA 2023-04-26
ER

PT J
AU Manso-Callejo, MA
   Cira, CI
   Garrido, RPA
   Matesanz, FJG
AF Manso-Callejo, Miguel-Angel
   Cira, Calimanut-Ionut
   Garrido, Ramon Pablo Alcarria
   Matesanz, Francisco Javier Gonzalez
TI First Dataset of Wind Turbine Data Created at National Level With Deep Learning Techniques From Aerial Orthophotographs With a Spatial Resolution of 0.5 M/Pixel
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Wind turbines; Feature extraction; Image segmentation; Training; Semantics; Task analysis; Production; Feature extraction; feature recognition; image classification; semantic segmentation; wind turbines
ID convolutional neural-network; building detection; object detection; recognition
AB Deep learning applied to feature extraction and mapping from high-resolution images is demonstrating the potential of this branch of data-intensive Artificial Intelligence to improve terrain mapping processes. The documented experiences have been applied on a small scale and there is a great expectation about its applicability on a country scale. For example, when extracting wind turbines using semantic segmentation models from a region of 28 km x 19 km containing unseen data, we obtained a commission rate of 1.4% and an omission rate of 0.38%. In this article, we present a methodology generated on the basis of two iterations. In these iterations, processing and postprocessing time, energy consumption, and finally results have been optimized to map wind turbines for the first time throughout the Spanish peninsular territory. In addition to adding a binary classification neural network prior to the semantic segmentation that extracts the turbines, a third multiclass recognition network has been used to classify the turbines by their power capacity complementing the features extracted with attributes. The proposed methodology can be adapted in the vectorization phase and applied to other types of features with linear or polygon representation to achieve a large-scale efficient extraction of geospatial elements using automated procedures.
C1 [Manso-Callejo, Miguel-Angel; Cira, Calimanut-Ionut; Garrido, Ramon Pablo Alcarria] Univ Politecn Madrid, Dept Ingn Topog & Cartog, Madrid 28031, Spain.
   [Matesanz, Francisco Javier Gonzalez] Direcc Gen Inst Geog Nacl, Subdirecc Gen Geodesia & Cartog, Madrid 28003, Spain.
C3 Universidad Politecnica de Madrid
RP Cira, CI (corresponding author), Univ Politecn Madrid, Dept Ingn Topog & Cartog, Madrid 28031, Spain.
EM m.manso@upm.es; ionut.cira@upm.es; ramon.alcarria@upm.es; fjgmatesanz@mitma.es
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Alidoost F, 2018, PFG-J PHOTOGRAMM REM, V86, P235, DOI 10.1007/s41064-018-0060-5
   Anaconda Inc, 2020, AN DOC, V0, P0
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP), V0, P0
   Chen Q., 2018, ARXIV180709532, V0, P0
   Chen X., 2019, PROC 7 INT C LEARN R, V0, P1
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Chollet F., 2017, DEEP LEARNING PYTHON, V0, P0
   Cira CI, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10207272
   Cira CI, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050765
   Castillo VD, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10113953
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   GDAL/OGR contributors, 2020, GDAL OGR GEOSP DAT A, V0, P0
   Gill J., 2019, P IEEE C COMP VIS PA, V0, P1
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Instituto Geografico Nacional, 2020, CTR DESC CNIG IGN CT, V0, P0
   Instituto Geografico Nacional, 2019, PLAN NAC ORT AER, V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020243
   Ma JJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152350
   Manso-Callejo MA, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223743
   Ronneberger O., 2015, INT C MED IM COMP CO, V0, PP234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shorter N, 2009, REMOTE SENS-BASEL, V1, P731, DOI 10.3390/rs1040731
   Simonyan K., 2015, INT C LEARN REPRESEN, V0, P0
   Sirotkovic J., 2014, P IEEE S COMP COMM F, V0, P1
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Vali A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152495
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Van Rossum G., 2009, PYTHON 3 REFERENCE M, V0, P0
   Yakubovskiy P., 2019, SEGMENTATION MODELS, V0, P0
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yuan JY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), V0, PP2703, DOI 10.1109/BigData.2016.7840915
   Zuo JW, 2018, IEEE GEOSCI REMOTE S, V15, P282, DOI 10.1109/LGRS.2017.2786232
NR 38
TC 1
Z9 1
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7968
EP 7980
DI 10.1109/JSTARS.2021.3101934
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UK8JJ
UT WOS:000692210900001
DA 2023-04-26
ER

PT J
AU Chen, F
   Wang, CX
   Zhang, YS
   Yi, ZS
   Fan, QC
   Liu, L
   Song, YJ
AF Chen, Feng
   Wang, Chenxing
   Zhang, Yuansheng
   Yi, Zhenshi
   Fan, Qiancong
   Liu, Lin
   Song, Yuejun
TI Inconsistency among Landsat Sensors in Land Surface Mapping: A Comprehensive Investigation Based on Simulation
SO REMOTE SENSING
LA English
DT Article
DE Landsat; NDVI; classification; time series; random forest; OLI; change detection; JM distance
ID support vector machines; time-series; random forest; cover classification; vegetation index; etm plus; learning classification; neural-networks; urban; mss
AB Comprehensive investigations on the between-sensor comparability among Landsat sensors have been relatively limited compared with the increasing use of multi-temporal Landsat records in time series analyses. More seriously, the sensor-related difference has not always been considered in applications. Accordingly, comparisons were conducted among all Landsat sensors available currently, including Multispectral Scanner (MSS), Thematic Mappers (TM), Enhanced Thematic Mappers (ETM+), and Operational Land Imager (OLI)) in land cover mapping, based on a collection of synthesized, multispectral data. Compared to TM, OLI showed obvious between-sensor differences in channel reflectance, especially over the near infrared (NIR) and shortwave infrared (SWIR) channels, and presented positive bias in vegetation spectral indices. OLI did not always outperform TM and ETM+ in classification, which related to the methods used. Furthermore, the channels over SWIR of TM and its successors contributed largely to enhancement of inter-class separability and to improvement of classification. Currently, the inclusion of MSS data is confronted with significant challenges regarding the consistency of surface mapping. Considering the inconsistency among the Landsat sensors, it is applicable to generate a consistent time series of spectral indices through proper transformation models. Meanwhile, it suggests the generation of specific class(es) based on interest instead of including all classes simultaneously.
C1 [Chen, Feng; Zhang, Yuansheng; Yi, Zhenshi] Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
   [Chen, Feng] Xiamen Univ Technol, Big Data Inst Digital Nat Disaster Monitoring Fuj, Xiamen 361024, Peoples R China.
   [Chen, Feng; Fan, Qiancong] Xiamen Univ, Fujian Key Lab Sensing & Comp Smart Cities, Xiamen 361005, Peoples R China.
   [Wang, Chenxing] Chinese Acad Sci, Res Ctr Ecoenvironm Sci, State Key Lab Urban & Reg Ecol, Beijing 100085, Peoples R China.
   [Liu, Lin] Huazhong Univ Sci & Technol, Sch Phys, Wuhan 430074, Peoples R China.
   [Song, Yuejun] Jiangxi Inst Soil & Water Conservat, Jiangxi Key Lab Soil Eros & Prevent, Nanchang 330029, Jiangxi, Peoples R China.
C3 Xiamen University of Technology; Xiamen University of Technology; Xiamen University; Chinese Academy of Sciences; Research Center for Eco-Environmental Sciences (RCEES); Huazhong University of Science & Technology
RP Song, YJ (corresponding author), Jiangxi Inst Soil & Water Conservat, Jiangxi Key Lab Soil Eros & Prevent, Nanchang 330029, Jiangxi, Peoples R China.
EM chenfeng@xmu.edu.cn; cxwang@rcees.ac.cn; zhangys@stu.xmut.edu.cn; yizhenshi@stu.xmut.edu.cn; fanqc@stu.xmu.edu.cn; liulin616@hust.edu.cn; kygl2021@jxsl.gov.cn
FU High level talents research project of Xiamen University of Technology [4010520004]; Fujian educational research projects of young and middle-aged teachers [JAT200453]; National Natural Science Foundation of China [41907611]; Fujian Key Lab on Sensing and Computing for Smart Cities (Xiamen University); Jiangxi Provincial Key Laboratory of Soil Erosion and Prevention, Jiangxi Institute of Soil and Water Conservation
CR Baker BA, 2013, INT J REMOTE SENS, V34, P1633, DOI 10.1080/01431161.2012.724540
   Baumgardner M.F., 2015, **DATA OBJECT**, V0, P0, DOI DOI 10.4231/R7RX991C
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Berk A., 2008, MODTRAN 5 2 0 0 USER, V0, P0
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Cai SS, 2013, REMOTE SENS LETT, V4, P998, DOI 10.1080/2150704X.2013.828180
   Chander G, 2003, IEEE T GEOSCI REMOTE, V41, P2674, DOI 10.1109/TGRS.2003.818464
   Chander G, 2009, REMOTE SENS ENVIRON, V113, P893, DOI 10.1016/j.rse.2009.01.007
   Chen F., 2012, DATA ACQUISITION APP, V0, P317
   Chen F, 2020, IEEE T GEOSCI REMOTE, V58, P8967, DOI 10.1109/TGRS.2020.2992609
   Chen F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141681
   Chen F, 2017, J ENVIRON SCI, V59, P80, DOI 10.1016/j.jes.2017.02.009
   Chen F, 2016, ISPRS J PHOTOGRAMM, V114, P53, DOI 10.1016/j.isprsjprs.2016.01.007
   Chen J, 2015, ISPRS J PHOTOGRAMM, V103, P7, DOI 10.1016/j.isprsjprs.2014.09.002
   Corcoran JM, 2013, REMOTE SENS-BASEL, V5, P3212, DOI 10.3390/rs5073212
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dannenberg MP, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080691
   Dash J, 2007, INT J REMOTE SENS, V28, P1137, DOI 10.1080/01431160600784259
   De Leeuw J, 2006, INT J REMOTE SENS, V27, P223, DOI 10.1080/01431160500275762
   Dixon B, 2008, INT J REMOTE SENS, V29, P1185, DOI 10.1080/01431160701294661
   Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Franklin SE, 2015, CAN J REMOTE SENS, V41, P293, DOI 10.1080/07038992.2015.1089401
   Gao Y., 2008, ONLINE J EARTH SCI, V2, P27
   Gascon F, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060584
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   Gomez C, 2016, ISPRS J PHOTOGRAMM, V116, P55, DOI 10.1016/j.isprsjprs.2016.03.008
   Gong P, 2019, SCI BULL, V64, P370, DOI 10.1016/j.scib.2019.03.002
   HAACK B, 1987, REMOTE SENS ENVIRON, V21, P201, DOI 10.1016/0034-4257(87)90053-8
   Hao PY, 2015, REMOTE SENS-BASEL, V7, P5347, DOI 10.3390/rs70505347
   He T, 2018, REMOTE SENS ENVIRON, V204, P181, DOI 10.1016/j.rse.2017.10.031
   Holden CE, 2016, REMOTE SENS ENVIRON, V185, P16, DOI 10.1016/j.rse.2016.02.052
   Hossain MD, 2019, ISPRS J PHOTOGRAMM, V150, P115, DOI 10.1016/j.isprsjprs.2019.02.009
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2
   Jiang ZY, 2008, REMOTE SENS ENVIRON, V112, P3833, DOI 10.1016/j.rse.2008.06.006
   Joachims T, 2005, P 22 INT C MACHINE L, V0, P377
   Kavzoglu T, 2009, INT J APPL EARTH OBS, V11, P352, DOI 10.1016/j.jag.2009.06.002
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   KHORRAM S, 1987, IEEE T GEOSCI REMOTE, V25, P238, DOI 10.1109/TGRS.1987.289823
   Kindu M, 2013, REMOTE SENS-BASEL, V5, P2411, DOI 10.3390/rs5052411
   KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Li CC, 2014, REMOTE SENS-BASEL, V6, P964, DOI 10.3390/rs6020964
   Lu DS, 2006, REMOTE SENS ENVIRON, V102, P146, DOI 10.1016/j.rse.2006.02.010
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Manandhar R, 2009, REMOTE SENS-BASEL, V1, P330, DOI 10.3390/rs1030330
   Mancino G, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020291
   Markogianni V, 2016, DESALIN WATER TREAT, V57, P29092, DOI 10.1080/19443994.2016.1188734
   Masek JG, 2001, REMOTE SENS ENVIRON, V78, P118, DOI 10.1016/S0034-4257(01)00254-1
   Maselli F, 2005, INT J REMOTE SENS, V26, P3781, DOI 10.1080/01431160500166433
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mohajane M, 2018, ENVIRONMENTS, V5, P0, DOI 10.3390/environments5120131
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Otukei JR, 2010, INT J APPL EARTH OBS, V12, PS27, DOI 10.1016/j.jag.2009.11.002
   Pakhale GK., 2010, INT J ENG TECHNOLOGY, V2, P245, DOI 10.7763/IJET.2010.V2.128
   Pal M, 2005, INT J REMOTE SENS, V26, P1007, DOI 10.1080/01431160512331314083
   Pasquarella VJ, 2018, REMOTE SENS ENVIRON, V210, P193, DOI 10.1016/j.rse.2018.02.064
   Peng Li, 2014, REMOTE SENSING, V6, P310, DOI 10.3390/rs6010310
   Phiri D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090967
   Platt RV, 2004, PHOTOGRAMM ENG REM S, V70, P813, DOI 10.14358/PERS.70.7.813
   Poursanidis D, 2015, INT J APPL EARTH OBS, V35, P259, DOI 10.1016/j.jag.2014.09.010
   Richards J.A., 2013, REMOTE SENSING DIGIT, V5th ed., P350
   Robertson LD, 2011, INT J REMOTE SENS, V32, P1505, DOI 10.1080/01431160903571791
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Roy DP, 2016, REMOTE SENS ENVIRON, V185, P57, DOI 10.1016/j.rse.2015.12.024
   Sanchez-Hernandez C, 2007, IEEE T GEOSCI REMOTE, V45, P1061, DOI 10.1109/TGRS.2006.890414
   Sibanda M, 2016, J LAND USE SCI, V11, P384, DOI 10.1080/1747423X.2015.1130756
   Song DX, 2015, ISPRS J PHOTOGRAMM, V103, P81, DOI 10.1016/j.isprsjprs.2014.09.005
   Thomlinson JR, 1999, REMOTE SENS ENVIRON, V70, P16, DOI 10.1016/S0034-4257(99)00055-3
   Thuillier G, 2003, SOL PHYS, V214, P1, DOI 10.1023/A:1024048429145
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Van Niel TG, 2005, REMOTE SENS ENVIRON, V98, P468, DOI 10.1016/j.rse.2005.08.011
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Wang J, 2015, ISPRS J PHOTOGRAMM, V103, P38, DOI 10.1016/j.isprsjprs.2014.03.007
   Woodcock CE, 2008, SCIENCE, V320, P1011, DOI 10.1126/science.320.5879.1011a
   Wulder MA, 2019, REMOTE SENS ENVIRON, V225, P127, DOI 10.1016/j.rse.2019.02.015
   Wulder MA, 2016, REMOTE SENS ENVIRON, V185, P271, DOI 10.1016/j.rse.2015.11.032
   Xu ZG, 2018, IEEE GEOSCI REMOTE S, V15, P789, DOI 10.1109/LGRS.2018.2806223
   Yan L, 2021, REMOTE SENS ENVIRON, V252, P0, DOI 10.1016/j.rse.2020.112181
   Yoo C, 2019, ISPRS J PHOTOGRAMM, V157, P155, DOI 10.1016/j.isprsjprs.2019.09.009
   Yu L, 2014, INT J REMOTE SENS, V35, P4573, DOI 10.1080/01431161.2014.930206
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zhu Z, 2019, REMOTE SENS ENVIRON, V224, P382, DOI 10.1016/j.rse.2019.02.016
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
NR 90
TC 0
Z9 0
U1 4
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD APR 15
PY 2021
VL 13
IS 7
BP 
EP 
DI 10.3390/rs13071383
PG 25
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RL2CU
UT WOS:000638788500001
DA 2023-04-26
ER

PT J
AU Compernolle, S
   Argyrouli, A
   Lutz, R
   Sneep, M
   Lambert, JC
   Fjaeraa, AM
   Hubert, D
   Keppens, A
   Loyola, D
   O'Connor, E
   Romahn, F
   Stammes, P
   Verhoelst, T
   Wang, P
AF Compernolle, Steven
   Argyrouli, Athina
   Lutz, Ronny
   Sneep, Maarten
   Lambert, Jean-Christopher
   Fjaeraa, Ann Mari
   Hubert, Daan
   Keppens, Arno
   Loyola, Diego
   O'Connor, Ewan
   Romahn, Fabian
   Stammes, Piet
   Verhoelst, Tijl
   Wang, Ping
TI Validation of the Sentinel-5 Precursor TROPOMI cloud data with Cloudnet, Aura OMI O-2-O-2, MODIS, and Suomi-NPP VIIRS
SO ATMOSPHERIC MEASUREMENT TECHNIQUES
LA English
DT Article
AB Accurate knowledge of cloud properties is essential to the measurement of atmospheric composition from space. In this work we assess the quality of the cloud data from three Copernicus Sentinel-5 Precursor (S5P) TROPOMI cloud products: (i) S5P OCRA/ROCINN_CAL (Optical Cloud Recognition Algorithm/Retrieval of Cloud Information using Neural Networks;Clouds-As-Layers), (ii) S5P OCRA/ROCINN_CRB (Clouds-as-Reflecting Boundaries), and (iii) S5P FRESCO-S (Fast Retrieval Scheme for Clouds from Oxygen absorption bands - Sentinel). Target properties of this work are cloud-top height and cloud optical thickness (OCRA/ROCINN_CAL), cloud height (OCRA/ROCINN_CRB and FRESCO-S), and radiometric cloud fraction (all three algorithms). The analysis combines (i) the examination of cloud maps for artificial geographical patterns, (ii) the comparison to other satellite cloud data (MODIS, NPP-VIIRS, and OMI O-2-O-2), and (iii) ground-based validation with respect to correlative observations (30 April 2018 to 27 February 2020) from the Cloudnet network of ceilometers, lidars, and radars. Zonal mean latitudinal variation of S5P cloud properties is similar to that of other satellite data. S5P OCRA/ROCINN_CAL agrees well with NPP VIIRS cloud-top height and cloud optical thickness and with Cloudnet cloud-top height, especially for the low (mostly liquid) clouds. For the high clouds, S5P OCRA/ROCINN_CAL cloud-top height is below the cloud-top height of VIIRS and of Cloudnet, while its cloud optical thickness is higher than that of VIIRS. S5P OCRA/ROCINN_CRB and S5P FRESCO cloud height are well below the Cloudnet cloud mean height for the low clouds but match on average better with the Cloudnet cloud mean height for the higher clouds. As opposed to S5P OCRA/ROCINN_CRB and S5P FRESCO, S5P OCRA/ROCINN_CAL is well able to match the lowest CTH mode of the Cloudnet observations. Peculiar geographical patterns are identified in the cloud products and will be mitigated in future releases of the cloud data products.
C1 [Compernolle, Steven; Lambert, Jean-Christopher; Hubert, Daan; Keppens, Arno; Verhoelst, Tijl] Royal Belgian Inst Space Aeron BIRA IASB, Atmospher Data Synergies Atmospher React Gases, Ringlaan 3, B-1180 Uccle, Brussels, Belgium.
   [Argyrouli, Athina] Tech Univ Munich, Chair Remote Sensing Technol, TUM Dept Civil Geo & Environm Engn, Munich, Germany.
   [Argyrouli, Athina; Lutz, Ronny; Loyola, Diego; Romahn, Fabian] German Aerosp Ctr DLR, Atmospher Processors Remote Sensing Technol Inst, Munchener Str 20, D-82234 Wassling, Germany.
   [Sneep, Maarten; Stammes, Piet; Wang, Ping] Royal Netherlands Meteorol Inst KNMI, Res & Dev Satellite Observat, Utrechtseweg 297, NL-3730 AE De Bilt, Netherlands.
   [Fjaeraa, Ann Mari] Norsk Inst Luftforskning NILU, Atmospher & Climate Res, Inst Veien 18, N-2007 Kjeller, Norway.
   [O'Connor, Ewan] Finnish Meteorol Inst FMI, Helsinki, Finland.
   [O'Connor, Ewan] Univ Reading, Dept Meteorol, POB 217, Reading RG6 6AH, Berks, England.
C3 Technical University of Munich; Helmholtz Association; German Aerospace Centre (DLR); Royal Netherlands Meteorological Institute; Norwegian Institute for Air Research; Finnish Meteorological Institute; University of Reading
RP Compernolle, S (corresponding author), Royal Belgian Inst Space Aeron BIRA IASB, Atmospher Data Synergies Atmospher React Gases, Ringlaan 3, B-1180 Uccle, Brussels, Belgium.
EM steven.compernolle@aeronomie.be
FU ESA/ESRIN of the ESA/EU Copernicus Sentinel-5 Precursor Mission Performance Centre [4000117151/16/I-LG]; BELSPO/ESA through the ProDEx project TROVA-E2 [PEA 4000116692]
CR Acarreta JR, 2004, J GEOPHYS RES-ATMOS, V109, P0, DOI 10.1029/2003JD003915
   Anderson G, 1986, AFGLTR860110, V0, P0
   [Anonymous], 2012, INT VOCABULARY METRO, V0, P0
   [Anonymous], 2018, COP SENT 5P PROC ESA, V0, P0
   [Anonymous], 2015, MODIS ATMOSPHERE L3, V0, P0
   [Anonymous], 2020, COPERNICUS SENTINEL, V0, P0
   [Anonymous], 2018, COPERNICUS SENTINEL, V0, P0
   Bovensmann H, 1999, J ATMOS SCI, V56, P127, DOI 10.1175/1520-0469(1999)056<0127:SMOAMM>2.0.CO;2
   Burrows JP, 1999, J ATMOS SCI, V56, P151, DOI 10.1175/1520-0469(1999)056<0151:TGOMEG>2.0.CO;2
   Chimot J, 2019, ATMOS MEAS TECH, V12, P491, DOI 10.5194/amt-12-491-2019
   Copernicus Sentinel-5P, 2018, TROPOMI LEV 2 NITR D, V0, P0, DOI DOI 10.5270/S5P-s4ljg54
   Desmons M, 2017, J APPL METEOROL CLIM, V56, P1121, DOI 10.1175/JAMC-D-16-0159.1
   ESA, 2017, EOPSM2413BVBV ESA, V0, P0
   FISHMAN J, 1990, J GEOPHYS RES-ATMOS, V95, P3599, DOI 10.1029/JD095iD04p03599
   Grzegorski M, 2006, ATMOS CHEM PHYS, V6, P4461, DOI 10.5194/acp-6-4461-2006
   Heidinger A., 2011, NOAA NESDIS CENTER F, V0, P0
   Heidinger AK, 2019, J ATMOS OCEAN TECH, V36, P1331, DOI 10.1175/JTECH-D-18-0079.1
   Illingworth AJ, 2007, B AM METEOROL SOC, V88, P883, DOI 10.1175/BAMS-88-6-883
   Ingmann P, 2012, REMOTE SENS ENVIRON, V120, P58, DOI 10.1016/j.rse.2012.01.023
   Joiner J, 2006, IEEE T GEOSCI REMOTE, V44, P1272, DOI 10.1109/TGRS.2005.861385
   Joiner J, 2010, ATMOS MEAS TECH, V3, P233, DOI 10.5194/amt-3-233-2010
   Joint Committee for Guides in Metrology (JCGM), 2008, EV MEAS DAT GUID EXP, V0, P0
   Keppens A, 2019, ATMOS MEAS TECH, V12, P4379, DOI 10.5194/amt-12-4379-2019
   KNMI, 2019, S5PKNMIL20005RP, V0, P0
   KNMI, 2018, KNMIESAS5L299ATBD005, V0, P0
   Koelemeijer RBA, 2001, J GEOPHYS RES-ATMOS, V106, P3475, DOI 10.1029/2000JD900657
   Lambert JC, 2013, ISSI SCI REP SER, V10, P215, DOI 10.1007/978-1-4614-3909-7_10
   Levelt PF, 2018, ATMOS CHEM PHYS, V18, P5699, DOI 10.5194/acp-18-5699-2018
   Liang LS, 2013, J GEOPHYS RES-ATMOS, V118, P2389, DOI 10.1029/2012JD018201
   Loew A, 2017, REV GEOPHYS, V55, P779, DOI 10.1002/2017RG000562
   Loyola D, 1998, INT GEOSCI REMOTE SE, V0, PP572, DOI 10.1109/IGARSS.1998.699514
   Loyola DG, 2004, INT GEOSCI REMOTE SE, V0, P2530
   Loyola DG, 2020, ATMOS MEAS TECH, V13, P985, DOI 10.5194/amt-13-985-2020
   Loyola DG, 2018, ATMOS MEAS TECH, V11, P409, DOI 10.5194/amt-11-409-2018
   Loyola RDG, 2016, NEURAL NETWORKS, V78, P75, DOI 10.1016/j.neunet.2015.09.001
   Loyola DG, 2010, INT J REMOTE SENS, V31, P4295, DOI 10.1080/01431160903246741
   Lutz R, 2016, ATMOS MEAS TECH, V9, P2357, DOI 10.5194/amt-9-2357-2016
   McPeters RD, 2013, J GEOPHYS RES-ATMOS, V118, P8032, DOI 10.1002/jgrd.50597
   MINNIS P, 1989, J GEOPHYS RES-ATMOS, V94, P2303, DOI 10.1029/JD094iD02p02303
   Molina Garcia V, 2018, J QUANT SPECTROSC RA, V213, P228, DOI 10.1016/j.jqsrt.2018.03.014
   NAKAJIMA T, 1990, J ATMOS SCI, V47, P1878, DOI 10.1175/1520-0469(1990)047<1878:DOTOTA>2.0.CO;2
   Platnick S., 2017, VIIRS ATMOSPHERE L2, V0, P0, DOI DOI 10.5067/VIIRS/CLDPROP_L2_VIIRS_SNPP.001
   Platnick S, 2017, IEEE T GEOSCI REMOTE, V55, P502, DOI 10.1109/TGRS.2016.2610522
   Popp C, 2011, ATMOS MEAS TECH, V4, P463, DOI 10.5194/amt-4-463-2011
   Rozanov VV, 2004, J GEOPHYS RES-ATMOS, V109, P0, DOI 10.1029/2003JD004104
   SCHIFFER RA, 1983, B AM METEOROL SOC, V64, P779
   Schuessler O, 2014, IEEE T GEOSCI REMOTE, V52, P3246, DOI 10.1109/TGRS.2013.2271986
   Siddans R., 2016, S5PNPPCRALATBD0001, V0, P0
   Sihler H., 2020, ATMOS MEAS TECH DISC, V0, P0, DOI DOI 10.5194/amt-2020-182
   Sneep M, 2008, J GEOPHYS RES-ATMOS, V113, P0, DOI 10.1029/2007JD008694
   Spurr RJD, 2006, J QUANT SPECTROSC RA, V102, P316, DOI 10.1016/j.jqsrt.2006.05.005
   Stammes P, 2008, J GEOPHYS RES-ATMOS, V113, P0, DOI 10.1029/2007JD008820
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Tilstra LG, 2017, J GEOPHYS RES-ATMOS, V122, P4084, DOI 10.1002/2016JD025940
   Tuinder O., 2010, EUMCO0946000000655RM, V0, P0
   van Diedenhoven B, 2007, J GEOPHYS RES-ATMOS, V112, P0, DOI 10.1029/2006JD008155
   Veefkind J., 2009, SDOMIEKNMI325, V0, P0
   Veefkind JP, 2012, REMOTE SENS ENVIRON, V120, P70, DOI 10.1016/j.rse.2011.09.027
   Veefkind J. P., 2006, OMI AURA CLOUD PRESS, V0, P0, DOI DOI 10.5067/Aura/OMI/DATA2007
   Verhoelst T, 2015, ATMOS MEAS TECH, V8, P5039, DOI 10.5194/amt-8-5039-2015
   Wang P, 2008, ATMOS CHEM PHYS, V8, P6565, DOI 10.5194/acp-8-6565-2008
   Wang P, 2014, ATMOS MEAS TECH, V7, P1331, DOI 10.5194/amt-7-1331-2014
   Wang P, 2012, ATMOS CHEM PHYS, V12, P9057, DOI 10.5194/acp-12-9057-2012
   Zeng S, 2012, ATMOS CHEM PHYS, V12, P11245, DOI 10.5194/acp-12-11245-2012
NR 68
TC 14
Z9 13
U1 4
U2 7
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1867-1381
EI 1867-8548
J9 ATMOS MEAS TECH
JI Atmos. Meas. Tech.
PD MAR 31
PY 2021
VL 14
IS 3
BP 2451
EP 2476
DI 10.5194/amt-14-2451-2021
PG 26
WC Meteorology & Atmospheric Sciences
SC Meteorology & Atmospheric Sciences
GA RI0VK
UT WOS:000636627500001
DA 2023-04-26
ER

PT J
AU Arellano-Verdejo, J
   Lazcano-Hernandez, HE
AF Arellano-Verdejo, Javier
   Lazcano-Hernandez, Hugo E.
TI Collective view: mapping Sargassum distribution along beaches
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Crowdsourcing; Convolutional neural networks; Artificial intelligence; Beach monitoring; GIS; Ecological application; Crowd-mapping; Geotagged images
AB The atypical arrival of pelagic Sargassum to the Mexican Caribbean beaches has caused considerable economic and ecological damage. Furthermore, it has raised new challenges for monitoring the coastlines. Historically, satellite remote-sensing has been used for Sargassum monitoring in the ocean; nonetheless, limitations in the temporal and spatial resolution of available satellite platforms do not allow for near real-time monitoring of this macro-algae on beaches. This study proposes an innovative approach for monitoring Sargassum on beaches using Crowdsourcing for imagery collection, deep learning for automatic classification, and geographic information systems for visualizing the results. We have coined this collaborative process "Collective View". It offers a geotagged dataset of images illustrating the presence or absence of Sargassum on beaches located along the northern and eastern regions in the Yucatan Peninsula, in Mexico. This new dataset is the largest of its kind in surrounding areas. As part of the design process for Collective View, three convolutional neural networks (LeNet-5, AlexNet and VGG16) were modified and retrained to classify images, according to the presence or absence of Sargassum. Findings from this study revealed that AlexNet demonstrated the best performance, achieving a maximum recall of 94%. These results are good considering that the training was carried out using a relatively small set of unbalanced images. Finally, this study provides a first approach to mapping the Sargassum distribution along the beaches using the classified geotagged images and offers novel insight into how we can accurately map the arrival of algal blooms along the coastline.
C1 [Arellano-Verdejo, Javier] Colegio Frontera Sur, Dept Observat & Study Earth Atmosphere & Ocean, Chetmal, Quintana Roo, Mexico.
   [Lazcano-Hernandez, Hugo E.] Colegio Frontera Sur, Catedras CONACYT, Chetmal, Quintana Roo, Mexico.
C3 El Colegio de la Frontera Sur (ECOSUR); El Colegio de la Frontera Sur (ECOSUR)
RP Arellano-Verdejo, J (corresponding author), Colegio Frontera Sur, Dept Observat & Study Earth Atmosphere & Ocean, Chetmal, Quintana Roo, Mexico.; Lazcano-Hernandez, HE (corresponding author), Colegio Frontera Sur, Catedras CONACYT, Chetmal, Quintana Roo, Mexico.
EM javier.arellano@mail.ecosur.mx; hlazcanoh@ecosur.mx
CR Abiodun OI, 2018, HELIYON, V4, P0, DOI 10.1016/j.heliyon.2018.e00938
   Alvarez-Carranza G., 2019, COMMUN COMPUT PHYS, VVolume 1053, P25, DOI 10.1007/978-3-030-33229-7-3
   [Anonymous], 2015, ICLR, V0, P0
   Arellano-Verdejo J., 2020, GIS LATAM, V0, PP49, DOI 10.1007/
   Arellano-Verdejo J., 2019, P INT C TELEMATICS C, V0, P61
   Arellano-Verdejo J, 2019, PEERJ, V7, P0, DOI 10.7717/peerj.6842
   Cabanillas-Teran N, 2019, PEERJ, V7, P0, DOI 10.7717/peerj.7589
   Duffy JE, 2019, FRONT MAR SCI, V6, P0, DOI 10.3389/fmars.2019.00317
   Frias-Martinez V., 2014, WORKSH DAT SCI SOC G, V0, P0
   Good BM, 2013, BIOINFORMATICS, V29, P1925, DOI 10.1093/bioinformatics/btt333
   Gower J, 2013, REMOTE SENS LETT, V4, P764, DOI 10.1080/2150704X.2013.796433
   Grabler F, 2008, ACM T GRAPHIC, V27, P0, DOI 10.1145/1360612.1360699
   Howe J., 2006, WIRED MAGAZINE, V14, P1, DOI 10.1086/599595
   Hu CM, 2009, REMOTE SENS ENVIRON, V113, P2118, DOI 10.1016/j.rse.2009.05.012
   Hu Y, 2016, Z PHYS CHEM, V230, P97, DOI 10.1515/zpch-2015-0630
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Karasov O, 2020, LAND-BASEL, V9, P0, DOI 10.3390/land9050158
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Marechal Jean-Philippe, 2017, REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT, V5, P54, DOI 10.1016/j.rsase.2017.01.001
   Maurer AS, 2015, FRONT ECOL ENVIRON, V13, P394
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Qiu SH, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), V0, PP1521, DOI 10.1145/3308558.3313651
   Rodriguez-Martinez RE, 2019, MAR POLLUT BULL, V146, P201, DOI 10.1016/j.marpolbul.2019.06.015
   Rodriguez-Martinez RE, 2020, PEERJ, V8, P0, DOI 10.7717/peerj.8667
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, ARXIV, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Uribe-Martinez A., 2020, GOBERNANZA MANEJO CO, V0, P743
   van der Graaf S, 2018, MEDIA COMMUN-LISBON, V6, P153, DOI 10.17645/mac.v6i4.1710
   van Tussenbroek BI, 2017, MAR POLLUT BULL, V122, P272, DOI 10.1016/j.marpolbul.2017.06.057
   Wang MQ, 2021, IEEE T GEOSCI REMOTE, V59, P2579, DOI 10.1109/TGRS.2020.3002929
   Wang MQ, 2016, REMOTE SENS ENVIRON, V183, P350, DOI 10.1016/j.rse.2016.04.019
   Webster R.K., 2013, SHORE BEACH, V81, P1
NR 34
TC 10
Z9 10
U1 0
U2 11
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD MAY 13
PY 2021
VL 0
IS 
BP 
EP 
DI 10.7717/peerj-cs.528
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods
SC Computer Science
GA SE1QC
UT WOS:000651848600001
PM 34084930
DA 2023-04-26
ER

PT J
AU Chen, JL
   Huang, GR
   Chen, WJ
AF Chen, Jialei
   Huang, Guoru
   Chen, Wenjie
TI Towards better flood risk management: Assessing flood risk and investigating the potential mechanism based on machine learning models
SO JOURNAL OF ENVIRONMENTAL MANAGEMENT
LA English
DT Article
DE Flood risk assessment; The Pearl River Delta; Machine learning; Gradient boosting decision tree; Risk management
ID metro systems; algorithm
AB Integrating powerful machine learning models with flood risk assessment and determining the potential mechanism between risk and the driving factors are crucial for improving flood management. In this study, six machine learning models were utilized for flood risk assessment of the Pearl River Delta, in which the Gradient Boosting Decision Tree (GBDT), eXtreme Gradient Boosting (XGBoost), and Convolutional Neural Network (CNN) models were firstly applied in this field. Twelve indices were chosen and 2000 sample points were created for model training and testing. Hyperparameter optimization of the models was conducted to ensure fair comparisons. Due to uncertainty in the sample dataset, recorded inundation hot-spots were utilized to validate the rationality of the flood risk zoning maps. After determining the optimal model, the driving factors of different flood risk levels were investigated. Urban and rural areas and coastal and inland areas were also compared to determine the flood risk mechanism in different highest-risk areas. The results showed that the GBDT performed best and provided the most reasonable flood risk result among the six models. A comparison of the driving factors at different risk levels indicated that the disaster-inducing factor, disaster-breeding environment, and disasterbearing body were not definitely becoming more serious as the flood risk increased. In the highest-risk areas, rural areas were featured by worse disaster-breeding environment than urban areas, and the disaster-inducing factors of coastal areas were more serious than those of inland areas. Moreover, the Digital Elevation Model (DEM), maximum 1-day precipitation (M1DP), and road density (RD) were the top three significant driving factors and contributed 52% to flood risk. This study not only expands the application of machine learning and deep learning methods for flood risk assessment, but also deepens our understanding of the potential mechanism of flood risk and provides insights into better flood risk management.
C1 [Chen, Jialei; Huang, Guoru; Chen, Wenjie] South China Univ Technol, Sch Civil Engn & Transportat, Guangzhou 510640, Peoples R China.
   [Huang, Guoru] South China Univ Technol, State Key Lab Subtrop Bldg Sci, Guangzhou 510640, Peoples R China.
   [Huang, Guoru; Chen, Wenjie] Guangdong Engn Technol Res Ctr Safety & Greenizat, Guangzhou 510640, Peoples R China.
C3 South China University of Technology; South China University of Technology
RP Chen, WJ (corresponding author), South China Univ Technol, Sch Civil Engn & Transportat, Guangzhou 510640, Peoples R China.
EM wjchen@scut.edu.cn
FU National Key Research and Development Program of China [2018YFC1508203]; National Natural Science Foundation of China [51879108]; China Postdoctoral Science Foundation [2020M682708]
CR Ahmadlou M, 2021, J FLOOD RISK MANAG, V14, P0, DOI 10.1111/jfr3.12683
   [Anonymous], 2016, GEOENVIRONMENTAL DIS, V0, P0, DOI DOI 10.1186/S40677-016-0044-Y
   Berndtsson R, 2019, J ENVIRON MANAGE, V240, P47, DOI 10.1016/j.jenvman.2019.03.094
   Botalb A, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AND ADVANCED SYSTEM (ICIAS 2018) / WORLD ENGINEERING, V0, P0
   Chan FKS, 2018, J CLEAN PROD, V187, P576, DOI 10.1016/j.jclepro.2018.03.217
   Chen XL, 2021, SCI TOTAL ENVIRON, V762, P0, DOI 10.1016/j.scitotenv.2020.143144
   Chowdhuri I, 2020, ADV SPACE RES, V65, P1466, DOI 10.1016/j.asr.2019.12.003
   Elshorbagy A, 2017, HYDROL EARTH SYST SC, V21, P2219, DOI 10.5194/hess-21-2219-2017
   Ghosh S, 2020, J CLEAN PROD, V275, P0, DOI 10.1016/j.jclepro.2020.123475
   Hong Y, 2008, INT J REMOTE SENS, V29, P471, DOI 10.1080/01431160701264292
   [黄国如 Huang Guoru], 2019, 水科学进展 ADVANCES IN WATER SCIENCE, V30, P643
   Huang T., 2017, J GUANGDONG U TECHNO, V34, P24, DOI 10.12052/gdutxb.160102
   Jia Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141655
   Kabir S, 2020, J HYDROL, V590, P0, DOI 10.1016/j.jhydrol.2020.125481
   Khan T.A., 2019, P 13 INT C MATH ACT, V0, PP1, DOI 10.1109/MACS48846.2019.9024796
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Khosravi K, 2018, SCI TOTAL ENVIRON, V627, P744, DOI 10.1016/j.scitotenv.2018.01.266
   Kiranyaz S, 2015, IEEE ENG MED BIO, V0, PP2608, DOI 10.1109/EMBC.2015.7318926
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai CG, 2016, J HYDROL, V542, P268, DOI 10.1016/j.jhydrol.2016.09.003
   Li B., 2019, S TO N WATER TRANSF, V17, P20, DOI 10.13476/j.cnki.nsbdqk.2019.0105
   Li SS, 2020, J HYDROL, V588, P0, DOI 10.1016/j.jhydrol.2020.125051
   Lin KR, 2020, J HYDROL, V584, P0, DOI 10.1016/j.jhydrol.2020.124696
   Liu B, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2287
   Lyu HM, 2019, HYDROL EARTH SYST SC, V23, P4293, DOI 10.5194/hess-23-4293-2019
   Lyu HM, 2018, SCI TOTAL ENVIRON, V626, P1012, DOI 10.1016/j.scitotenv.2018.01.138
   Mahmoud SH, 2018, J CLEAN PROD, V196, P216, DOI 10.1016/j.jclepro.2018.06.047
   Mohanty MP, 2020, J ENVIRON MANAGE, V255, P0, DOI 10.1016/j.jenvman.2019.109733
   Pal SC, 2021, GONDWANA RES, V94, P164, DOI 10.1016/j.gr.2021.02.021
   Ngo PTT, 2021, J ENVIRON MANAGE, V280, P0, DOI 10.1016/j.jenvman.2020.111858
   Rezende OM, 2020, J CLEAN PROD, V255, P0, DOI 10.1016/j.jclepro.2020.120251
   Roy P, 2020, J CLEAN PROD, V272, P0, DOI 10.1016/j.jclepro.2020.122757
   Sado-Inamura Y, 2019, LAND USE POLICY, V82, P13, DOI 10.1016/j.landusepol.2018.11.031
   Sorensen R, 2006, HYDROL EARTH SYST SC, V10, P101, DOI 10.5194/hess-10-101-2006
   Switzer A., 2012, PROC ANN INT C GEOL, V0, P0, DOI DOI 10.5176/2251-3361_GEOS12.10
   Tehrany MS, 2015, CATENA, V125, P91, DOI 10.1016/j.catena.2014.10.017
   Wagenaar D, 2020, NAT HAZARD EARTH SYS, V20, P1149, DOI 10.5194/nhess-20-1149-2020
   Wang XN, 2017, QUATERN INT, V453, P1, DOI 10.1016/j.quaint.2016.12.025
   Wang ZL, 2015, J HYDROL, V527, P1130, DOI 10.1016/j.jhydrol.2015.06.008
   Widiasari IR, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE AND CREATIVE INFORMATION TECHNOLOGY (ICITECH), V0, P0
   Wu ZN, 2020, SCI TOTAL ENVIRON, V716, P0, DOI 10.1016/j.scitotenv.2020.137077
   Xu HS, 2018, J HYDROL, V563, P975, DOI 10.1016/j.jhydrol.2018.06.060
   Zarekarizi M, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-19188-9
   Zeng ZY, 2017, REMOTE SENS LETT, V8, P528, DOI 10.1080/2150704X.2017.1297544
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhao G, 2019, SCI TOTAL ENVIRON, V659, P940, DOI 10.1016/j.scitotenv.2018.12.217
   Zhi GZ, 2020, J ENVIRON MANAGE, V268, P0, DOI 10.1016/j.jenvman.2020.110521
NR 48
TC 25
Z9 28
U1 54
U2 158
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0301-4797
EI 1095-8630
J9 J ENVIRON MANAGE
JI J. Environ. Manage.
PD SEP 1
PY 2021
VL 293
IS 
BP 
EP 
DI 10.1016/j.jenvman.2021.112810
EA MAY 2021
PG 12
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA TP8PQ
UT WOS:000677857000001
PM 34029980
DA 2023-04-26
ER

PT J
AU Salem, H
   Soria, D
   Lund, JN
   Awwad, A
AF Salem, Hesham
   Soria, Daniele
   Lund, Jonathan N.
   Awwad, Amir
TI A systematic review of the applications of Expert Systems (ES) and machine learning (ML) in clinical urology
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
LA English
DT Review
ID artificial neural-network; prostate-specific antigen; predicting pathological stage; decision-support-systems; bladder outlet obstruction; shock-wave lithotripsy; resonance-imaging variables; cancer detection rate; fuzzy cognitive map; radical prostatectomy
AB Background Testing a hypothesis for 'factors-outcome effect' is a common quest, but standard statistical regression analysis tools are rendered ineffective by data contaminated with too many noisy variables. Expert Systems (ES) can provide an alternative methodology in analysing data to identify variables with the highest correlation to the outcome. By applying their effective machine learning (ML) abilities, significant research time and costs can be saved. The study aims to systematically review the applications of ES in urological research and their methodological models for effective multi-variate analysis. Their domains, development and validity will be identified. Methods The PRISMA methodology was applied to formulate an effective method for data gathering and analysis. This study search included seven most relevant information sources: WEB OF SCIENCE, EMBASE, BIOSIS CITATION INDEX, SCOPUS, PUBMED, Google Scholar and MEDLINE. Eligible articles were included if they applied one of the known ML models for a clear urological research question involving multivariate analysis. Only articles with pertinent research methods in ES models were included. The analysed data included the system model, applications, input/output variables, target user, validation, and outcomes. Both ML models and the variable analysis were comparatively reported for each system. Results The search identified n = 1087 articles from all databases and n = 712 were eligible for examination against inclusion criteria. A total of 168 systems were finally included and systematically analysed demonstrating a recent increase in uptake of ES in academic urology in particular artificial neural networks with 31 systems. Most of the systems were applied in urological oncology (prostate cancer = 15, bladder cancer = 13) where diagnostic, prognostic and survival predictor markers were investigated. Due to the heterogeneity of models and their statistical tests, a meta-analysis was not feasible. Conclusion ES utility offers an effective ML potential and their applications in research have demonstrated a valid model for multi-variate analysis. The complexity of their development can challenge their uptake in urological clinics whilst the limitation of the statistical tools in this domain has created a gap for further research studies. Integration of computer scientists in academic units has promoted the use of ES in clinical urological research.
C1 [Salem, Hesham] Univ Nottingham, NIHR Nottingham Biomed Res Ctr, Sch Med, Urol Dept, Nottingham NG7 2UH, England.
   [Salem, Hesham; Lund, Jonathan N.] Univ Nottingham, Royal Derby Hosp, Univ Hosp Derby & Burton NHS Fdn Trust, Derby DE22 3DT, England.
   [Soria, Daniele] Univ Westminster, Sch Comp Sci & Engn, London W1W 6UW, England.
   [Awwad, Amir] Univ Nottingham, Sch Med, NIHR Nottingham Biomed Res Ctr, Sir Peter Mansfield Imaging Ctr, Nottingham NG7 2UH, England.
   [Awwad, Amir] Western Univ, Schulich Sch Med & Dent, London Hlth Sci Ctr, Dept Med Imaging,Univ Hosp, London, ON, Canada.
C3 University of Nottingham; University of Nottingham; University of Westminster; University of Nottingham; London Health Sciences Centre; Western University (University of Western Ontario)
RP Awwad, A (corresponding author), Univ Nottingham, Sch Med, NIHR Nottingham Biomed Res Ctr, Sir Peter Mansfield Imaging Ctr, Nottingham NG7 2UH, England.; Awwad, A (corresponding author), Western Univ, Schulich Sch Med & Dent, London Hlth Sci Ctr, Dept Med Imaging,Univ Hosp, London, ON, Canada.
EM amir.awwad@lhsc.on.ca
CR Abbod M. F., 2004, BIOMEDICAL ENGINEERING, V0, P0
   Abbod M F, 2006, 2006 3 INT IEEE C IN, V0, P0
   Altunay S, 2009, EXPERT SYST APPL, V36, P4891, DOI 10.1016/j.eswa.2008.05.051
   Ammenwerth E, 2013, ARTIF INTELL MED, V59, P1, DOI 10.1016/j.artmed.2013.05.001
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Arlen AM, 2016, J PEDIATR UROL, V12, P0, DOI 10.1016/j.jpurol.2016.03.005
   Babaian RJ, 2000, UROLOGY, V56, P1000, DOI 10.1016/S0090-4295(00)00830-X
   Lopes MHBD, 2013, INT J MED INFORM, V82, P201, DOI 10.1016/j.ijmedinf.2012.05.012
   Bagli DJ, 1998, J UROLOGY, V160, P980, DOI 10.1016/S0022-5347(01)62675-2
   Bassi P, 2007, BJU INT, V99, P1007, DOI 10.1111/j.1464-410X.2007.06755.x
   Batuello JT, 2001, UROLOGY, V57, P481, DOI 10.1016/S0090-4295(00)01039-6
   Beligiannis G, 2006, LECT NOTES ARTIF INT, V4251, P968
   Benbasat I., 1989, KNOWL ACQUIS, V1, P215, DOI 10.1016/S1042-8143(89)80020-2
   Benecchi L, 2006, UROLOGY, V68, P357, DOI 10.1016/j.urology.2006.03.003
   BINIK YM, 1988, J NERV MENT DIS, V176, P387, DOI 10.1097/00005053-198807000-00001
   Bologna G, 2017, J ARTIF INTELL SOFT, V7, P265, DOI 10.1515/jaiscr-2017-0019
   Borque A, 2001, J UROLOGY, V166, P1672, DOI 10.1016/S0022-5347(05)65651-0
   Botoca C, 2009, PROCEEDINGS OF THE 8TH WSEAS INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, V0, P108
   Boyington AR, 2004, NURS OUTLOOK, V52, P241, DOI 10.1016/j.outlook.2004.04.014
   Buchner A, 2013, EJSO-EUR J SURG ONC, V39, P372, DOI 10.1016/j.ejso.2013.02.009
   Buchner A, 2012, CLIN GENITOURIN CANC, V10, P37, DOI 10.1016/j.clgc.2011.10.001
   Cabitza F, 2020, ANN TRANSL MED, V8, P0, DOI 10.21037/atm.2020.03.63
   Cabitza F, 2019, ANN TRANSL MED, V7, P0, DOI 10.21037/atm.2019.04.07
   Cai T, 2007, ANN ONCOL, V18, P604, DOI 10.1093/annonc/mdl411
   Cai T, 2007, ONCOL REP, V18, P959
   Cai T, 2011, J SURG RES, V167, P267, DOI 10.1016/j.jss.2009.05.004
   Castanho MJP, 2013, EXPERT SYST APPL, V40, P466, DOI 10.1016/j.eswa.2012.07.046
   Catto JWF, 2010, EUR UROL, V57, P398, DOI 10.1016/j.eururo.2009.10.029
   Catto JWF, 2009, CLIN CANCER RES, V15, P3150, DOI 10.1158/1078-0432.CCR-08-1960
   Catto JWF, 2006, J UROLOGY, V175, P474, DOI 10.1016/S0022-5347(05)00246-6
   Catto JWF, 2003, CLIN CANCER RES, V9, P4172
   Chang PL, 1999, MED DECIS MAKING, V19, P419
   Chang TC, 2021, UROL CLIN N AM, V48, P151, DOI 10.1016/j.ucl.2020.09.004
   Chiu JS, 2009, J MED SYST, V33, P91, DOI 10.1007/s10916-008-9168-2
   Cinar M, 2009, EXPERT SYST APPL, V36, P6357, DOI 10.1016/j.eswa.2008.08.010
   Cosma G, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0155856
   Cummings JM, 2000, J UROLOGY, V164, P326, DOI 10.1016/S0022-5347(05)67351-X
   Dal Moro F, 2006, KIDNEY INT, V69, P157, DOI 10.1038/sj.ki.5000010
   Castanho MJD, 2008, APPL MATH COMPUT, V202, P78, DOI 10.1016/j.amc.2007.11.055
   Djavan B, 2004, UROLOGY, V64, P1144, DOI 10.1016/j.urology.2004.08.049
   Djavan B, 2002, J CLIN ONCOL, V20, P921, DOI 10.1200/JCO.20.4.921
   Ecke TH, 2012, UROL ONCOL-SEMIN ORI, V30, P139, DOI 10.1016/j.urolonc.2009.12.009
   El-Mekresh M, 2009, J UROLOGY, V182, P466, DOI 10.1016/j.juro.2009.04.018
   Eminaga O., 2021, ARTIF INTELL MED, V0, PP309, DOI 10.1016/B978-0-12-821259-2.00016-8
   Eminaga O, 2018, JCO CLIN CANCER INFO, V2, P0, DOI 10.1200/CCI.17.00126
   Filella X, 2014, CLIN CHIM ACTA, V436, P303, DOI 10.1016/j.cca.2014.06.019
   Finne P, 2000, UROLOGY, V56, P418, DOI 10.1016/S0090-4295(00)00672-5
   Fujikawa K, 2003, INT J UROL, V10, P149, DOI 10.1046/j.1442-2042.2003.00589.x
   Garg AX, 2005, JAMA-J AM MED ASSOC, V293, P1223, DOI 10.1001/jama.293.10.1223
   Gatidis S, 2015, NMR BIOMED, V28, P914, DOI 10.1002/nbm.3329
   Gil D, 2012, EXPERT SYST APPL, V39, P12564, DOI 10.1016/j.eswa.2012.05.028
   Gil D, 2010, EXPERT SYST APPL, V37, P4713, DOI 10.1016/j.eswa.2009.12.055
   Gil D, 2009, EXPERT SYST APPL, V36, P5754, DOI 10.1016/j.eswa.2008.06.065
   Girela JL, 2013, BIOL REPROD, V88, P0, DOI 10.1095/biolreprod.112.104653
   Gomha MA, 2004, J UROLOGY, V172, P175, DOI 10.1097/01.ju.0000128646.20349.27
   Gorman R, 1995, PROC ANNU SYMP COMPUT APPL MED CARE, V0, P527
   Goyal NK, 2007, INDIAN J UROL, V23, P14, DOI 10.4103/0970-1591.30258
   Green WJF, 2016, BRIT J CANCER, V115, P236, DOI 10.1038/bjc.2016.169
   Hamid A, 2003, BJU INT, V91, P821, DOI 10.1046/j.1464-410X.2003.04230.x
   Han M, 2001, CANCER, V91, P1661, DOI 10.1002/1097-0142(20010415)91:8+<1661::AID-CNCR1180>3.3.CO;2-X
   Han M, 2000, UROLOGY, V56, P994, DOI 10.1016/S0090-4295(00)00815-3
   Hao ATH, 2013, INT J MED INFORM, V82, P604, DOI 10.1016/j.ijmedinf.2013.02.006
   Hassanien AE, 2011, APPL SOFT COMPUT, V11, P2035, DOI 10.1016/j.asoc.2010.07.001
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, P0, DOI 10.1002/widm.1312
   Hu XH, 2014, ASIAN J ANDROL, V16, P897, DOI 10.4103/1008-682X.129940
   Hurst RE, 1997, CYTOMETRY, V27, P36, DOI 10.1002/(SICI)1097-0320(19970101)27:1<36::AID-CYTO5>3.3.CO;2-4
   JACKSON P, 1999, INTRO EXPERT SYSTEMS, V0, P0
   Kalra P, 2003, CANCER, V98, P1849, DOI 10.1002/cncr.11748
   Kattan MW, 1996, UROLOGY, V47, P14, DOI 10.1016/S0090-4295(99)80375-6
   Kawakami S, 2008, EUR UROL, V54, P601, DOI 10.1016/j.eururo.2008.01.017
   Kawamoto K, 2005, BMJ-BRIT MED J, V330, P765, DOI 10.1136/bmj.38398.500764.8F
   Keles A, 2007, COMPUT BIOL MED, V37, P1617, DOI 10.1016/j.compbiomed.2007.03.006
   Kim M, 2014, INT NEUROUROL J, V18, P198, DOI 10.5213/inj.2014.18.4.198
   Kim SY, 2011, KOREAN J RADIOL, V12, P588, DOI 10.3348/kjr.2011.12.5.588
   Kolasa M, 2009, ADV INTEL SOFT COMPU, V65, P113
   Koutsojannis C, 2004, LECT NOTES COMPUT SC, V3214, P1106
   Koutsojannis C, 2012, COMPUT METH PROG BIO, V107, P84, DOI 10.1016/j.cmpb.2012.02.012
   Koutsojannis C, 2009, INT CONF INTELL SYST, V0, PP341, DOI 10.1109/ISDA.2009.110
   Koutsojannis C, 2008, ELE COM ENG, V0, P254
   Krongrad A, 1997, J UROLOGY, V157, P534, DOI 10.1016/S0022-5347(01)65195-4
   Kshirsagar A, 2006, INT J IMPOT RES, V18, P47, DOI 10.1038/sj.ijir.3901369
   Kuo RJ, 2015, ARTIF INTELL MED, V63, P119, DOI 10.1016/j.artmed.2014.12.008
   Lakkaraju HKE, 2017, 170701154 ARXIV, V0, P0
   LAMB DJ, 1993, WORLD J UROL, V11, P129
   Lawrentschuk N, 2011, INT UROL NEPHROL, V43, P23, DOI 10.1007/s11255-010-9750-7
   Lee HJ, 2006, J ULTRAS MED, V25, P815, DOI 10.7863/jum.2006.25.7.815
   Lee HJ, 2010, EUR RADIOL, V20, P1476, DOI 10.1007/s00330-009-1686-x
   Liao SH, 2005, EXPERT SYST APPL, V28, P93, DOI 10.1016/j.eswa.2004.08.003
   Llobet R, 2007, INT J MED INFORM, V76, P547, DOI 10.1016/j.ijmedinf.2006.03.001
   Loch T, 1999, PROSTATE, V39, P198
   Logvinenko T, 2015, J PEDIATR UROL, V11, P0, DOI 10.1016/j.jpurol.2015.03.006
   Marszall MP, 2012, CENT EUR J MED, V7, P672, DOI 10.2478/s11536-012-0027-7
   Matsui Y, 2004, JPN J CLIN ONCOL, V34, P602, DOI 10.1093/jjco/hyh112
   Matsui Y, 2002, JPN J CLIN ONCOL, V32, P530, DOI 10.1093/jjco/hyf114
   Mattfeldt T, 1999, BJU INT, V84, P316
   Mattfeldt T, 2001, EUR UROL, V39, P530, DOI 10.1159/000052499
   Matulewicz L, 2014, J MAGN RESON IMAGING, V40, P1414, DOI 10.1002/jmri.24487
   McCarthy J, 2006, AI MAG, V27, P12
   Meijer RP, 2009, WORLD J UROL, V27, P593, DOI 10.1007/s00345-009-0444-7
   Michaels EK, 1998, UROLOGY, V51, P335, DOI 10.1016/S0090-4295(97)00611-0
   Moons KGM, 2019, ANN INTERN MED, V170, PW1, DOI 10.7326/M18-1377
   MOUL JW, 1995, J UROLOGY, V153, P1674, DOI 10.1016/S0022-5347(01)67502-5
   Nagendran M, 2020, BMJ-BRIT MED J, V368, P0, DOI 10.1136/bmj.m689
   Naguib RNG, 1997, P ANN INT IEEE EMBS, V19, P1007, DOI 10.1109/IEMBS.1997.756515
   Naguib RNG, 1998, BRIT J CANCER, V78, P246, DOI 10.1038/bjc.1998.472
   NICE, 2014, PROSTATE CANC DIAGNO, V0, P0
   NICE, 2008, PROSTATE CANC DIAGNO, V0, P0
   OKEEFE RM, 1993, ARTIF INTELL REV, V7, P3, DOI 10.1007/BF00849196
   Pandey B, 2009, COMPUT BIOL MED, V39, P215, DOI 10.1016/j.compbiomed.2008.12.008
   Pantazopoulos D, 1998, BRIT J UROL, V81, P574
   Pantazopoulos D, 1998, J UROLOGY, V159, P1619, DOI 10.1097/00005392-199805000-00057
   Papageorgiou EI, 2012, COMPUT METH PROG BIO, V105, P233, DOI 10.1016/j.cmpb.2011.09.006
   Parekattil SJ, 2005, J UROLOGY, V174, P1380, DOI 10.1097/01.ju.0000173921.67597.e8
   Parekattil SJ, 2003, J UROLOGY, V169, P917, DOI 10.1097/01.ju.0000051322.60266.06
   Pereira MA, 2004, P ANN INT IEEE EMBS, V26, P3412
   Petrovic S, 2011, EXPERT SYST APPL, V38, P10759, DOI 10.1016/j.eswa.2011.01.109
   Petrucci K, 1991, P ANN S COMP APPL ME, V0, P0
   Porter C, 2001, MOL UROL, V5, P159, DOI 10.1089/10915360152745830
   Porter CR, 2005, UROLOGY, V65, P937, DOI 10.1016/j.urology.2004.11.049
   Potter SR, 1999, UROLOGY, V54, P791, DOI 10.1016/S0090-4295(99)00328-3
   Poulakis V, 2004, UROLOGY, V64, P516, DOI 10.1016/j.urology.2004.04.027
   Poulakis V, 2004, J UROLOGY, V172, P1306, DOI 10.1097/01.ju.0000139881.04126.b6
   Poulakis V, 2002, UROLOGE A, V41, P583, DOI 10.1007/s00120-002-0194-2
   Powell CR, 2008, INT J IMPOT RES, V20, P79, DOI 10.1038/sj.ijir.3901593
   Qureshi KN, 2000, J UROLOGY, V163, P630, DOI 10.1016/S0022-5347(05)67948-7
   Ramasamy R, 2013, J UROLOGY, V189, P638, DOI 10.1016/j.juro.2012.09.038
   Regnier-Coudert O, 2012, ARTIF INTELL MED, V55, P25, DOI 10.1016/j.artmed.2011.11.003
   Remzi M, 2003, UROLOGY, V62, P456, DOI 10.1016/S0090-4295(03)00409-6
   Ronco AL, 1999, ULTRASOUND MED BIOL, V25, P729, DOI 10.1016/S0301-5629(99)00011-3
   Samli MM, 2004, J UROLOGY, V171, P2354, DOI 10.1097/01.ju.0000125272.03182.c3
   Saritas I, 1900, P345, V0, P0
   Saritas I, 2010, EXPERT SYST APPL, V37, P6646, DOI 10.1016/j.eswa.2010.03.056
   Seckiner Ilker, 2011, CAN UROL ASSOC J, V5, PE152, DOI 10.5489/cuaj.10043
   Seker H, 2003, IEEE T INF TECHNOL B, V7, P114, DOI 10.1109/TITB.2003.811876
   Serati M, 2011, EUR UROL, V60, P253, DOI 10.1016/j.eururo.2011.03.010
   Serrano-Durba A, 2004, BJU INT, V94, P120, DOI 10.1111/j.1464-410X.2004.04912.x
   SHORTLIFFE EH, 1975, CLIN RES, V23, P0
   Stephan C, 2005, BJU INT, V96, P521, DOI 10.1111/j.1464-410X.2005.05677.x
   Stephan C, 2002, CLIN CHEM, V48, P1279
   Stephan C, 2008, BJU INT, V102, P799, DOI 10.1111/j.1464-410X.2008.07765.x
   Stephan C, 2006, BIOL CHEM, V387, P801, DOI 10.1515/BC.2006.101
   Stephan C, 2006, EUR UROL, V50, P1014, DOI 10.1016/j.eururo.2006.04.011
   Stephan C, 2007, UROLOGY, V70, P596, DOI 10.1016/j.urology.2007.04.004
   Stephan C, 2013, CLIN CHEM, V59, P306, DOI 10.1373/clinchem.2012.195784
   Stephan C, 2010, INT J UROL, V17, P62, DOI 10.1111/j.1442-2042.2009.02417.x
   Stephan C, 2009, PROSTATE, V69, P198, DOI 10.1002/pros.20872
   SUCEVIC D, 1991, 6TH MEDITERRANEAN ELECTROTECHNICAL CONFERENCE, V0, P741, DOI 10.1109/MELCON.1991.161944
   Sun Chi-Cheng, 2006, AMIA ANNU SYMP PROC, V0, P1113
   Tanthanuch Monthira, 2004, JOURNAL OF THE MEDICAL ASSOCIATION OF THAILAND, V87, P515
   Tewari A, 1998, J UROLOGY, V160, P430, DOI 10.1016/S0022-5347(01)62916-1
   Tewari A, 2001, MOL UROL, V5, P163, DOI 10.1089/10915360152745849
   Torshizi AD, 2014, COMPUT METH PROG BIO, V113, P301, DOI 10.1016/j.cmpb.2013.09.021
   Tsao CW, 2014, J CHIN MED ASSOC, V77, P513, DOI 10.1016/j.jcma.2014.06.014
   Turing AM, 1950, MIND, V49, P433, DOI 10.1093/MIND/LIX.236.433
   Veltri RW, 2002, CLIN CHEM, V48, P1828
   VOLMER M, 1994, CLIN CHEM, V40, P1692
   von der Maase H, 2005, J CLIN ONCOL, V23, P4602, DOI 10.1200/JCO.2005.07.757
   Vukicevic AM, 2014, EXPERT SYST APPL, V41, P8092, DOI 10.1016/j.eswa.2014.07.006
   Herr HW, 2007, J UROLOGY, V177, P437, DOI 10.1016/j.juro.2006.09.027
   Wadie BS, 2006, UROLOGY, V68, P1211, DOI 10.1016/j.urology.2006.08.1079
   Wadie BS, 2001, J UROLOGY, V165, P35, DOI 10.1097/00005392-200101000-00009
   Wang GJ, 2015, COMPUT BIOL MED, V63, P124, DOI 10.1016/j.compbiomed.2015.05.015
   Wells DM, 1998, INT J RADIAT ONCOL, V41, P173, DOI 10.1016/S0360-3016(98)00035-2
   Xiao D, 2016, INT J COMPUT ASS RAD, V11, P89, DOI 10.1007/s11548-015-1234-x
   Yuksel S, 2013, J INEQUAL APPL, V0, P0, DOI DOI 10.1186/1029-242X-2013-229
   Zlotta AR, 2003, J UROLOGY, V169, P1724, DOI 10.1097/01.ju.0000062548.28015.f6
NR 167
TC 5
Z9 5
U1 1
U2 7
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 
EI 1472-6947
J9 BMC MED INFORM DECIS
JI BMC Med. Inform. Decis. Mak.
PD JUL 22
PY 2021
VL 21
IS 1
BP 
EP 
DI 10.1186/s12911-021-01585-9
PG 36
WC Medical Informatics
SC Medical Informatics
GA TR3HM
UT WOS:000678859800001
PM 34294092
DA 2023-04-26
ER

PT J
AU Makarov, OL
   Bilousov, KH
   Svynarenko, DN
   Khoroshylov, VS
   Mozgovoy, DK
   Popel, VM
AF Makarov, O. L.
   Bilousov, K. H.
   Svynarenko, D. N.
   Khoroshylov, V. S.
   Mozgovoy, D. K.
   Popel, V. M.
TI AUTOMATIZED RECOGNITION OF URBAN VEGETATION AND WATER BODIES BYJILIN-1A SATELLITE IMAGES
SO SPACE SCIENCE AND TECHNOLOGY-KOSMICNA NAUKA I TEHNOLOGIA
LA Ukrainian
DT Article
DE satellite monitoring; multispectral images; image processing; spectral indices; map renewal
AB The results of testing the developed techniques for automatized recognition of vegetation and water bodies on the urban territory by multispectral images from the Jilin-1A satellite are given. The research included automatized recognition of vegetation and water bodies on the selected observation territory based on images with super high spatial resolution in the visual and infrared range and consequent comparison of the obtained results with the results of visual decoding. The obtained results of processing the images from the Jilin-1A satellite in accordance with the proposed techniques confirmed the sufficiently high accuracy of automatized edge enhancement of recognized objects as compared to the results of interactive visual recognition of these images. Different test areas provided a good separation of vegetation and water types with the same thresholding customization. The accuracy of automatized classification of vegetation and water bodies (without considering the standard errors) for different test areas was within 81...92 %, and values of kappa-coefficient were within 0.68 to 0.85. Comparison of normalized index images received from Jilin-1A and Sentinel-2A satellites showed slight discordance in NDVI values and significant discordances for NDWI and MNDWI that are caused by the usage of different spectral channels (SWIR and NIR). These discordances can be sufficiently reduced when using correction coefficients. Analysis of the influence of output image resolution reduction (from 10 to 8 bit) and subsequent informational compressing (JPEG lossy and JPEG2000 lossless) on results of automatized recognition of vegetation and water bodies confirmed the validity and efficiency of these techniques. The volume of saved and transmitted files significantly decreased (in 80 ...100 times) with a slight reduction of classification accuracy (by 1 ...2 %). The proposed techniques make it possible to increase significantly the efficiency and probability of renewing maps of big cities and to reduce financial expenditures as compared to the traditional ground GPS-surveying and aerosurveying. The high-level automatization of image processing and minimization of necessary calculations (as compared to techniques that use complex classifiers and neural networks) allow to implement the developed technique as a geographic information web service that satisfies the needs of a wide circle of government services and commercial structures and can be useful for megalopolis population and tourists.
C1 [Makarov, O. L.; Bilousov, K. H.; Khoroshylov, V. S.; Popel, V. M.] Yangel Yuzhnoye State Design Off, 3 Kryvorizka Str, UA-49008 Dnipro, Ukraine.
   [Khoroshylov, V. S.; Popel, V. M.] Yangel Yuzhnoye State Design Off, Dept Design Off Spacecrafts & Sites Syst Engn, 3 Kryvorizka Str, UA-49008 Dnipro, Ukraine.
   [Svynarenko, D. N.; Mozgovoy, D. K.] Oles Honchar Dnipro Natl Univ, 72 Gagarina Ave, UA-49010 Dnipro, Ukraine.
   [Svynarenko, D. N.] Oles Honchar Dnipro Natl Univ, Dept Telecommun Syst & Networks, 72 Gagarina Ave, UA-49010 Dnipro, Ukraine.
   [Mozgovoy, D. K.] Oles Honchar Dnipro Natl Univ, Dept Phys Elect & Comp Syst, 72 Gagarina Ave, UA-49010 Dnipro, Ukraine.
C3 Ministry of Education & Science of Ukraine; Oles Honchar Dnipro National University; Ministry of Education & Science of Ukraine; Oles Honchar Dnipro National University; Ministry of Education & Science of Ukraine; Oles Honchar Dnipro National University
RP Makarov, OL (corresponding author), Yangel Yuzhnoye State Design Off, 3 Kryvorizka Str, UA-49008 Dnipro, Ukraine.
EM info@yuzhnoye.com; m-d-k@i.ua
CR Bardysh B., 2014, SUCHASNI DOSYAGNENNY, V2, P82
   Belenok V. Yu., 2017, VISNYK ASTRON SHKOLY, V13, P54
   Burshtynska Kh. V., 2013, GEODEZIYA KARTOGRAFI, V78, P101
   Fedorovskyi OD, 2017, SPACE SCI TECHNOL, V23, P11, DOI 10.15407/knit2017.02.011
   Filipovych V. Ye., 2013, PHYS GEOGR GEOMORPHO, V3, P143
   Khyzhnyak A. V., 2016, EMERGING TECHNOLOGIE, V1, P13
   Kravchenko O. M., 2013, WORKS DONNTU ICCS, V2, P71
   Kussul NM, 2019, SPACE SCI TECHNOL, V25, P51, DOI 10.15407/knit2019.06.051
   Mozgovoj D. K., 2018, UKR J REMOTE SENSING, V17, P18
   Mozgovoy D., 2018, ISPRS ANN PHOTOGRAMM, VIV -3, P167
   Mozgovoy D. K., 2016, B DNU ROCKET SPACE T, V24, P95
   Mozgovoy D, 2018, PROC SPIE, V10806, P0, DOI 10.1117/12.2502905
   Pazinich N. V., 2015, UKR J REMOTE SENSING, V5, P33
   Pestova I. O., 2015, METHODS ESTIMATING S, V0, P0
   Reva K. V., 2014, PROGRAMMING PROBLEMS, V2-3, P303
   Shapar A. H., 2018, ECOLOGICAL SAFETY, V2, P61
   Shevchuk S. A., 2013, LAND RECLAMATION WAT, V100, P42
   Sokolovska AV, 2013, SPACE SCI TECHNOL, V19, P44, DOI 10.15407/knit2013.04.044
   [Станкевич С.А. Stankevich S.A.], 2014, СОВРЕМЕННЫЕ ПРОБЛЕМЫ ДИСТАНЦИОННОГО ЗОНДИРОВАНИЯ ЗЕМЛИ ИЗ КОСМОСА CURRENT PROBLEMS IN REMOTE SENSING OF THE EARTH FROM SPACE SOVREMENNYE PROBLEMY DISTANTSIONNOGO ZONDIROVANIYA ZEMLI IZ KOSMOSA, V11, P187
   Stankevich S. A., 2014, B GEODESY CARTOGRAPH, V3, P23
   Ulytsky O, 2019, SPACE SCI TECHNOL, V25, P48, DOI 10.15407/knit2019.04.048
   Vyshnevskyi V. I., 2016, UKRAINIAN J REMOTE S, V11, P9
   Yailymov BY, 2018, SPACE SCI TECHNOL, V24, P24, DOI 10.15407/knit2018.04.026
   Zatserkovnyi V. I., 2017, SCI BASED TECHNOLOGI, V1, P78
NR 24
TC 0
Z9 0
U1 0
U2 0
PU PUBLISHING HOUSE AKADEMPERIODYKA
PI KYIV
PA PUBLISHING HOUSE AKADEMPERIODYKA, KYIV, 00000, UKRAINE
SN 1561-8889
EI 2518-1459
J9 SPACE SCI TECHNOL
JI Space Sci. Technol.
PD JUN 15
PY 2021
VL 27
IS 4
BP 42
EP 53
DI 10.15407/knit2021.04.042
PG 12
WC Astronomy & Astrophysics
SC Astronomy & Astrophysics
GA WE9QJ
UT WOS:000705951900005
DA 2023-04-26
ER

PT J
AU Sang, QB
   Zhuang, Y
   Dong, S
   Wang, GQ
   Chen, H
   Li, LL
AF Sang, Qianbo
   Zhuang, Yin
   Dong, Shan
   Wang, Guanqun
   Chen, He
   Li, Lianlin
TI Improved Land Cover Classification of VHR Optical Remote Sensing Imagery Based Upon Detail Injection Procedure
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Optical imaging; Optical sensors; Semantics; Decoding; Convolution; Feature extraction; Encoding-to-decoding; land cover classification; optical remote sensing; refinement module; unmanned aerial vehicles (UAVs); very high resolution (VHR)
ID convolutional neural-network; semantic segmentation
AB Development of very-high-resolution (VHR) remote sensing imaging platforms have resulted in a requirement for developing refined land cover classification maps for various applications. Therefore, aiming at exploring the accurate boundary and complex interior texture retrieval in VHR optical remote sensing images, a novel detail injection network (DI-Net) is proposed in this article, which is composed of three aspects. First, the decoupling refinement module embedded with a multiscale representation is designed to improve the feature extraction capabilities that precede the encoding-to-decoding process. Second, we pay attention to the hard examples of boundary and complex interior texture in land cover classification and design two detail injection attention modules to solve the feature inactivation phenomenon in gradually convolutional encoding-to-decoding process. Third, a specific stage grading loss is proposed to adaptively regulate the structural-level weights of the encoding and decoding stages, which facilitates the details retrieval and produce refined land cover classification results. Finally, various datasets [<italic>incl.</italic> International Society for Photogrammetry and Remote Sensing (ISPRS) and Gaofen Image Dataset (GID)] are employed to demonstrate that the proposed DI-Net achieves better performance than state-of-the-art methods. DI-Net provides more accurate boundaries and more consistent interior textures, and it achieves 86.86x0025; <italic>PA</italic> and 68.37x0025; <italic>mIoU</italic> on ISPRS dataset as well as 77.04x0025; <italic>PA</italic> and 64.38x0025; <italic>mIoU</italic> on GID dataset, respectively.
C1 [Sang, Qianbo; Zhuang, Yin; Wang, Guanqun; Chen, He] Beijing Key Lab Embedded Real Time Informat Proc, Beijing 100081, Peoples R China.
   [Dong, Shan] Commun Univ China, Engn Ctr Digital Audio & Video, Beijing 100024, Peoples R China.
   [Li, Lianlin] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.
C3 Communication University of China; Peking University
RP Zhuang, Y (corresponding author), Beijing Key Lab Embedded Real Time Informat Proc, Beijing 100081, Peoples R China.
EM sangqianbo@126.com; zhuangyin640829@163.com; dongshan@cuc.edu.cn; wgq@bit.edu.cn; chenhe@bit.edu.cn; lianlin.li@pku.edu.cn
FU Chang Jiang Scholars Program [T2012122]; Hundred Leading Talent Project of Beijing Science and Technology [Z141101001514005, 2019M650345]; Fundamental Research Funds for the Central Universities [CUC200D052]
CR Badrinarayanan Vijay, 2015, SEGNET DEEP CONVOLUT, V0, PP1, DOI 10.1109/TPAMI.2016.2644615
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen WT, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010015
   Cui GQ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081238
   Garg L, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, V0, P0
   Gomez C, 1900, V115, V0, P55
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Howard Andrew G., 2017, PROC IEEE C COMPUT V, V0, P0
   Hu YF, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10122053
   Joshi N, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010070
   Joyce KE, 2009, PROG PHYS GEOG, V33, P183, DOI 10.1177/0309133309339563
   Jung JH, 2014, IEEE J-STARS, V7, P491, DOI 10.1109/JSTARS.2013.2292032
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kroupi E, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.024525
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lin HN, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050480
   Liu Y, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18103232
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Luo HF, 2019, IEEE J-STARS, V12, P3492, DOI 10.1109/JSTARS.2019.2930724
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mehta S, 2019, PROC CVPR IEEE, V0, PP9182, DOI 10.1109/CVPR.2019.00941
   Mou L., 2018, ARXIV180502091, V0, P0
   Pan XR, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113774
   Peng C, 2017, PROC CVPR IEEE, V0, PP1743, DOI 10.1109/CVPR.2017.189
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sang QB, 2020, IEEE GEOSCI REMOTE S, V17, P1057, DOI 10.1109/LGRS.2019.2938555
   Simonyan K, 2015, ARXIV, V0, P0
   Stefanov WL, 2001, REMOTE SENS ENVIRON, V77, P173, DOI 10.1016/S0034-4257(01)00204-8
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   TUCKER CJ, 1985, SCIENCE, V227, P369, DOI 10.1126/science.227.4685.369
   Wan LM, 2019, ANN GIS, V25, P45, DOI 10.1080/19475683.2018.1564791
   Wang YH, 2018, PROC SPIE, V10764, P0, DOI 10.1117/12.2318930
   Wurm M, 2019, ISPRS J PHOTOGRAMM, V150, P59, DOI 10.1016/j.isprsjprs.2019.02.006
   Xie ZL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020164
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yuan M, 2019, REMOTE SENS LETT, V10, P506, DOI 10.1080/2150704X.2019.1574990
   Zhang H, 2019, PR MACH LEARN RES, V97, P0
   Zhang H, 2018, PROC CVPR IEEE, V0, PP7151, DOI 10.1109/CVPR.2018.00747
   Zhang X, 2018, PROC CVPR IEEE, V0, PP6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
NR 40
TC 4
Z9 4
U1 5
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 18
EP 31
DI 10.1109/JSTARS.2020.3032423
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TS9GU
UT WOS:000679956300001
DA 2023-04-26
ER

PT J
AU Wang, HY
   Cheng, YH
   Chen, CLP
   Wang, XS
AF Wang, Haoyu
   Cheng, Yuhu
   Chen, C. L. Philip
   Wang, Xuesong
TI Semisupervised Classification of Hyperspectral Image Based on Graph Convolutional Broad Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Data mining; Training; Deep learning; Principal component analysis; Earth; Eigenvalues and eigenfunctions; Broad learning; classification; hyperspectral image (HSI); sample expansion; semisupervised learning
ID neural-networks; superpixel
AB Hyperspectral image (HSI) classification has attracted much attention in the field of remote sensing. However, the lack of sufficient labeled training samples is a huge challenge for HSI classification. To face this challenge, we propose a semisupervised HSI classification method based on graph convolutional broad network (GCBN). First, to avoid the underfitting problem caused by the insufficient linear sparse feature representation ability of broad learning system (BLS), graph convolution operation is applied to extract nonlinear and discriminative spectral-spatial features from the original HSI to replace the linear mapping features in the traditional BLS. Second, to solve the problem of insufficient model classification ability caused by limited labeled samples, the combinatorial average method (CAM) is proposed to use valuable paired samples to generate sample expansion set for GCBN model training. Third, BLS is used to perform broad expansion on spectral-spatial features extracted by GCN and extended by CAM, which further enhances the feature representation ability. Finally, the output weights can be easily calculated by the ridge regression theory. Experimental results on three real HSI datasets demonstrate the effectiveness of our proposed GCBN.
C1 [Wang, Haoyu; Cheng, Yuhu; Wang, Xuesong] China Univ Min & Technol, Engn Res Ctr Intelligent Control Underground Spac, Minist Educ, Xuzhou 221116, Jiangsu, Peoples R China.
   [Wang, Haoyu; Cheng, Yuhu; Wang, Xuesong] China Univ Min & Technol, Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
   [Wang, Haoyu; Cheng, Yuhu; Wang, Xuesong] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Chen, C. L. Philip] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Chen, C. L. Philip] Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Macau 999078, Peoples R China.
C3 China University of Mining & Technology; China University of Mining & Technology; China University of Mining & Technology; South China University of Technology; University of Macau
RP Wang, XS (corresponding author), China Univ Min & Technol, Engn Res Ctr Intelligent Control Underground Spac, Minist Educ, Xuzhou 221116, Jiangsu, Peoples R China.; Wang, XS (corresponding author), China Univ Min & Technol, Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
EM 2540854800@qq.com; chengyuhu@163.com; Philip.Chen@ieee.org; wangxuesongcumt@163.com
FU National Natural Science Foundation of China [61976215, 61772532]
CR Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Chen CLP, 2018, IEEE T NEUR NET LEAR, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Chu F, 2020, IEEE T NEUR NET LEAR, V31, P3017, DOI 10.1109/TNNLS.2019.2935033
   Delalieux S, 2012, REMOTE SENS ENVIRON, V126, P222, DOI 10.1016/j.rse.2012.08.029
   Fang LY, 2015, IEEE T GEOSCI REMOTE, V53, P6663, DOI 10.1109/TGRS.2015.2445767
   Fauvel M, 2012, PATTERN RECOGN, V45, P381, DOI 10.1016/j.patcog.2011.03.035
   Feng S, 2020, IEEE T CYBERNETICS, V50, P414, DOI 10.1109/TCYB.2018.2857815
   Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481
   Hamilton W, 2017, P 31 INT C NEURAL IN, V0, P1025
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Kang XD, 2018, IEEE J-STARS, V11, P1166, DOI 10.1109/JSTARS.2017.2767185
   Kipf T. N., 2017, ICLR, V0, P0
   Kong Y, 2019, IEEE GEOSCI REMOTE S, V16, P1741, DOI 10.1109/LGRS.2019.2907598
   Kong Y, 2018, IEEE J-STARS, V11, P4128, DOI 10.1109/JSTARS.2018.2869210
   Kong Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050685
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P4816, DOI 10.1109/TGRS.2012.2230268
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li ST, 2018, IEEE T IMAGE PROCESS, V27, P4118, DOI 10.1109/TIP.2018.2836307
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Liang L, 2015, REMOTE SENS ENVIRON, V165, P123, DOI 10.1016/j.rse.2015.04.032
   Liu C, 2019, IEEE J-STARS, V12, P357, DOI 10.1109/JSTARS.2018.2880562
   Liu P, 2017, IEEE J-STARS, V10, P712, DOI 10.1109/JSTARS.2016.2598859
   Lunga D, 2014, IEEE SIGNAL PROC MAG, V31, P55, DOI 10.1109/MSP.2013.2279894
   Ma L, 2010, IEEE T GEOSCI REMOTE, V48, P4099, DOI 10.1109/TGRS.2010.2055876
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Nalepa J, 2020, IEEE GEOSCI REMOTE S, V17, P292, DOI 10.1109/LGRS.2019.2921011
   Qin AY, 2019, IEEE GEOSCI REMOTE S, V16, P241, DOI 10.1109/LGRS.2018.2869563
   Sellami A, 2020, PATTERN RECOGN LETT, V138, P594, DOI 10.1016/j.patrec.2020.08.020
   Tu B, 2021, IEEE GEOSCI REMOTE S, V18, P861, DOI 10.1109/LGRS.2020.2988124
   Tu B, 2020, IEEE T GEOSCI REMOTE, V58, P4116, DOI 10.1109/TGRS.2019.2961141
   Wan S, 2020, IEEE T GEOSCI REMOTE, V58, P3162, DOI 10.1109/TGRS.2019.2949180
   Wang C, 2020, IEEE GEOSCI REMOTE S, V17, P1420, DOI 10.1109/LGRS.2019.2945848
   Wang HY, 2020, IEEE J-STARS, V13, P3006, DOI 10.1109/JSTARS.2020.3001198
   Wang XS, 2017, IEEE J-STARS, V10, P1552, DOI 10.1109/JSTARS.2016.2624303
   Wu H, 2018, IEEE T IMAGE PROCESS, V27, P1259, DOI 10.1109/TIP.2017.2772836
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhang SQ, 2018, IEEE T GEOSCI REMOTE, V56, P5767, DOI 10.1109/TGRS.2018.2825457
   Zhou X, 2018, IEEE T GEOSCI REMOTE, V56, P5863, DOI 10.1109/TGRS.2018.2827308
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
NR 45
TC 9
Z9 9
U1 5
U2 36
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2995
EP 3005
DI 10.1109/JSTARS.2021.3062642
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RD7EO
UT WOS:000633636500009
DA 2023-04-26
ER

PT J
AU Naimi, S
   Ayoubi, S
   Zeraatpisheh, M
   Dematte, JAM
AF Naimi, Salman
   Ayoubi, Shamsollah
   Zeraatpisheh, Mojtaba
   Dematte, Jose Alexandre Melo
TI Ground Observations and Environmental Covariates Integration for Mapping of Soil Salinity: A Machine Learning-Based Approach
SO REMOTE SENSING
LA English
DT Article
DE soil salinization; machine learning; remote and proximal sensing; Sentinel-2 MSI; SySI; soil health
ID spatial-distribution; sentinel-2 msi; random forest; wet seasons; regression; prediction; region; classification; reflectance; plain
AB Soil salinization is a severe danger to agricultural activity in arid and semi-arid areas, reducing crop production and contributing to land destruction. This investigation aimed to utilize machine learning algorithms to predict spatial soil salinity (dS m(-1)) by combining environmental covariates derived from remotely sensed (RS) data, a digital elevation model (DEM), and proximal sensing (PS). The study is located in an arid region, southern Iran (52 degrees 51 '-53 degrees 02 ' E; 28 degrees 16 '-28 degrees 29 ' N), in which we collected 300 surface soil samples and acquired the spectral data with RS (Sentinel-2) and PS (electromagnetic induction instrument (EMI) and portable X-ray fluorescence (pXRF)). Afterward, we analyzed the data using five machine learning methods as follows: random forest-RF, k-nearest neighbors-kNN, support vector machines-SVM, partial least squares regression-PLSR, artificial neural networks-ANN, and the ensemble of individual models. To estimate the electrical conductivity of the saturated paste extract (ECe), we built three scenarios, including Scenario (1): Synthetic Soil Image (SySI) bands and salinity indices derived from it; Scenario (2): RS data, PS data, topographic attributes, and geology and geomorphology maps; and Scenario (3): the combination of Scenarios (1) and (2). The best prediction accuracy was obtained for the RF model in Scenario (3) (R-2 = 0.48 and RMSE = 2.49), followed by Scenario (2) (RF model, R-2 = 0.47 and RMSE = 2.50) and Scenario (1) for the SVM model (R-2 = 0.26 and RMSE = 2.97). According to ensemble modeling, a combined strategy with the five models exceeded the performance of all the single ones and predicted soil salinity in all scenarios. The results revealed that the ensemble modeling method had higher reliability and more accurate predictive soil salinity than the individual approach. Relative improvement (RI%) showed that the R-2 index in the ensemble model improved compared to the most precise prediction for the Scenarios (1), (2), and (3) with 120.95%, 56.82%, and 66.71%, respectively. We applied the best model in each scenario for mapping the soil salinity in the selected area, which indicated that ECe tended to increase from the northwestern to south and southeastern regions. The area with high ECe was located in the regions that mainly had low elevations and playa. The areas with low ECe were located in the higher elevations with steeper slopes and alluvial fans, and thus, relief had great importance. This study provides a precise, cost-effective, and scientific base prediction for decision-making purposes to map soil salinity in arid regions.
C1 [Naimi, Salman; Ayoubi, Shamsollah] Isfahan Univ Technol, Coll Agr, Dept Soil Sci, Esfahan 84115683111, Iran.
   [Zeraatpisheh, Mojtaba] Henan Univ, Henan Key Lab Earth Syst Observat & Modeling, Kaifeng 475004, Peoples R China.
   [Zeraatpisheh, Mojtaba] Henan Univ, Coll Geog & Environm Sci, Kaifeng 475004, Peoples R China.
   [Dematte, Jose Alexandre Melo] Luiz de Queiroz Coll Agr, Dept Soil Sci, BR-13418900 Piracicaba, SP, Brazil.
C3 Henan University; Henan University
RP Zeraatpisheh, M (corresponding author), Henan Univ, Henan Key Lab Earth Syst Observat & Modeling, Kaifeng 475004, Peoples R China.; Zeraatpisheh, M (corresponding author), Henan Univ, Coll Geog & Environm Sci, Kaifeng 475004, Peoples R China.
EM s.naimi@ag.iut.ac.ir; ayoubi@cc.iut.ac.ir; mojtaba.zeraatpisheh@henu.edu.cn; jamdemat@usp.br
FU Iran National Science Foundation (INSF) [98001941];  [2014-2262-0];  [2017YFA0604302];  [2018YFA0606500]
CR Akramkhanov A, 2011, GEODERMA, V163, P55, DOI 10.1016/j.geoderma.2011.04.001
   Aldabaa AAA, 2015, GEODERMA, V239, P34, DOI 10.1016/j.geoderma.2014.09.011
   Allbed A., 2013, ADV REMOTE SENS, V2, P373, DOI 10.4236/ARS.2013.24040
   Allbed A, 2014, GEODERMA, V230, P1, DOI 10.1016/j.geoderma.2014.03.025
   Amirian-Chakan A, 2019, SOIL TILL RES, V194, P0, DOI 10.1016/j.still.2019.06.006
   [Anonymous], 2014, SOIL SURV STAFF KEYS, V12th, P0
   Bannari A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060855
   Bilgili AV, 2011, ARID LAND RES MANAG, V25, P19, DOI 10.1080/15324982.2010.528153
   Borujeni IE, 2010, CATENA, V82, P1, DOI 10.1016/j.catena.2010.03.006
   Brevik Eric C., 2004, PRECISION AGRICULTURE, V5, P145, DOI 10.1023/B:PRAG.0000022359.79184.92
   Bui EN, 2013, J ARID ENVIRON, V92, P14, DOI 10.1016/j.jaridenv.2012.12.014
   Cho KH, 2018, GEODERMA, V321, P42, DOI 10.1016/j.geoderma.2018.01.031
   Clay DE, 2001, COMMUN SOIL SCI PLAN, V32, P2993, DOI 10.1081/CSS-120001102
   Dematte JAM, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-61408-1
   Ding JL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162601
   Ding JL, 2014, GEODERMA, V235, P316, DOI 10.1016/j.geoderma.2014.07.028
   Douaoui AEK, 2006, GEODERMA, V134, P217, DOI 10.1016/j.geoderma.2005.10.009
   El Harti A, 2016, INT J APPL EARTH OBS, V50, P64, DOI 10.1016/j.jag.2016.03.008
   Emadi M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142234
   Fan X, 2012, LAND DEGRAD DEV, V23, P175, DOI 10.1002/ldr.1071
   Farahmand N, 2020, J INDIAN SOC REMOTE, V48, P675, DOI 10.1007/s12524-019-01100-8
   Forkuor G, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0170478
   Silva SHG, 2017, CIENC AGROTEC, V41, P648, DOI 10.1590/1413-70542017416010317
   Gorji T, 2020, ECOL INDIC, V112, P0, DOI 10.1016/j.ecolind.2020.106173
   Gorji T, 2017, ECOL INDIC, V74, P384, DOI 10.1016/j.ecolind.2016.11.043
   Goydaragh MG, 2021, CATENA, V202, P0, DOI 10.1016/j.catena.2021.105280
   Grunwald S, 2015, ADV AGRON, V131, P1, DOI 10.1016/bs.agron.2014.12.004
   Guo L, 2020, SOIL TILL RES, V196, P0, DOI 10.1016/j.still.2019.104477
   Guo Y, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0127996
   Han LJ, 2019, CATENA, V177, P22, DOI 10.1016/j.catena.2019.01.040
   Hengl T, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0169748
   Hengl T, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0125814
   Heung B, 2016, GEODERMA, V265, P62, DOI 10.1016/j.geoderma.2015.11.014
   Hosseini M, 2017, APPL SOIL ECOL, V114, P123, DOI 10.1016/j.apsoil.2017.02.011
   Jafari A, 2012, EUR J SOIL SCI, V63, P284, DOI 10.1111/j.1365-2389.2012.01425.x
   Kuo S., 1996, METHODS OF SOIL ANALYSIS. PART 3 - CHEMICAL METHODS., V0, P869
   Li JG, 2015, CHINESE GEOGR SCI, V25, P213, DOI 10.1007/s11769-014-0693-2
   Liess M, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0153673
   Ma G., 2021, REGIONAL SUSTAINABIL, V2, P177, DOI 10.1016/j.regsus.2021.06.001
   Ma YX, 2019, GEODERMA, V341, P195, DOI 10.1016/j.geoderma.2019.01.049
   Main-Knorn M, 2017, PROC SPIE, V10427, P0, DOI 10.1117/12.2278218
   Mansuy N, 2014, GEODERMA, V235, P59, DOI 10.1016/j.geoderma.2014.06.032
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   McBratney AB, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11123350
   Dematte JAM, 2018, REMOTE SENS ENVIRON, V212, P161, DOI 10.1016/j.rse.2018.04.047
   Metternicht GI, 2003, REMOTE SENS ENVIRON, V85, P1, DOI 10.1016/S0034-4257(02)00188-8
   Minasny B, 2006, COMPUT GEOSCI-UK, V32, P1378, DOI 10.1016/j.cageo.2005.12.009
   Mohammed S, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12092529
   Mondal A, 2017, EGYPT J REMOTE SENS, V20, P61, DOI 10.1016/j.ejrs.2016.06.004
   Naimi S, 2021, GEOCARTO INT, V0, P0, DOI DOI 10.1080/10106049.2021.1996639
   Nouri H, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10082826
   Pakparvar M, 2012, INT J REMOTE SENS, V33, P6215, DOI 10.1080/01431161.2012.676688
   Peng J, 2019, GEODERMA, V337, P1309, DOI 10.1016/j.geoderma.2018.08.006
   Peng Jie, 2014, TRANSACTIONS OF THE CHINESE SOCIETY OF AGRICULTURAL ENGINEERING, V30, P167
   Poppiel RR, 2021, GEODERMA, V385, P0, DOI 10.1016/j.geoderma.2020.114890
   Pozdnyakova L., 1999, PRECISION AGRICULTURE, V1, P153, DOI 10.1023/A:1009947506264
   Qiu YuanLin, 2019, WATER SAVING IRRIGATION / JIESHUI GUANGAI, V0, P108
   RICHARDS L. A., 1954, DIAGNOSIS AND IMPROVEMENT OF SALINE AND ALKALI SOILS., V0, P0
   Rossel RAV, 2016, EARTH-SCI REV, V155, P198, DOI 10.1016/j.earscirev.2016.01.012
   Rossel RAV, 2011, ADV AGRON, V113, P237, DOI 10.1016/B978-0-12-386473-4.00010-5
   Scull P, 2005, ECOL MODEL, V181, P1, DOI 10.1016/j.ecolmodel.2004.06.036
   Shen QS, 2019, CATENA, V174, P59, DOI 10.1016/j.catena.2018.10.052
   Sidike A, 2014, INT J APPL EARTH OBS, V26, P156, DOI 10.1016/j.jag.2013.06.002
   Silva SHG, 2021, PEDOSPHERE, V31, P615, DOI 10.1016/S1002-0160(21)60007-3
   Simko V., 2021, CORRPLOT VISUALIZATI, V0, P0
   Sugimori Y, 2008, LAND DEGRAD DEV, V19, P305, DOI 10.1002/ldr.843
   Sun YR, 2013, J PLANT NUTR SOIL SC, V176, P209, DOI 10.1002/jpln.201200104
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Swanhart S, 2014, SOIL SCI, V179, P417, DOI 10.1097/SS.0000000000000088
   Taghadosi MM, 2019, EUR J REMOTE SENS, V52, P138, DOI 10.1080/22797254.2019.1571870
   Taghizadeh-Mehrjardi R, 2014, GEODERMA, V213, P15, DOI 10.1016/j.geoderma.2013.07.020
   Taghizadeh-Mehrjardi R, 2019, SOIL SYST, V3, P0, DOI 10.3390/soilsystems3020037
   Tajik S, 2020, GEODERMA REG, V20, P0, DOI 10.1016/j.geodrs.2020.e00256
   Toomanian N, 2006, GEOMORPHOLOGY, V81, P376, DOI 10.1016/j.geomorph.2006.04.016
   Vasques GM, 2020, SOIL SYST, V4, P0, DOI 10.3390/soilsystems4030052
   Walker, 2014, CURR OPIN AGRIC, V3, P10
   Wang F, 2020, GEODERMA, V365, P0, DOI 10.1016/j.geoderma.2020.114211
   Wang JQ, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13020305
   Wang JZ, 2020, SCI TOTAL ENVIRON, V707, P0, DOI 10.1016/j.scitotenv.2019.136092
   Wang JZ, 2019, GEODERMA, V353, P172, DOI 10.1016/j.geoderma.2019.06.040
   Wang JZ, 2019, CATENA, V177, P189, DOI 10.1016/j.catena.2019.02.020
   Xu C, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010042
   Yang L, 2015, CHINESE GEOGR SCI, V25, P283, DOI 10.1007/s11769-015-0740-7
   Yao RJ, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0153377
   Zaman M., 2018, GUIDELINE SALINITY A, V0, PP91, DOI 10.1007/978-3-319-96190-3_4
   Zeraatpisheh M, 2022, CATENA, V208, P0, DOI 10.1016/j.catena.2021.105723
   Zeraatpisheh M, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104424
NR 90
TC 7
Z9 7
U1 8
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 15
PY 2021
VL 13
IS 23
BP 
EP 
DI 10.3390/rs13234825
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XV6SK
UT WOS:000735069300001
DA 2023-04-26
ER

PT J
AU Wang, J
   Wang, YH
   Chen, B
   Liu, HW
AF Wang, Jian
   Wang, Yinghua
   Chen, Bo
   Liu, Hongwei
TI LCS-EnsemNet: A Semisupervised Deep Neural Network for SAR Image Change Detection With Dual Feature Extraction and Label-Consistent Self-Ensemble
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Radar polarimetry; Training; Synthetic aperture radar; Feature extraction; Speckle; Clustering algorithms; Classification algorithms; Change detection (CD); deep neural network (DNN); label-consistent self-ensemble; semisupervised learning (SSL); spatially enhanced (SE) difference image (DI); synthetic aperture radar (SAR)
ID unsupervised change detection; automatic change detection; classification; fusion; svm
AB Change detection (CD) in synthetic aperture radar (SAR) images faces two challenging problems limiting the detection performance: inherent speckle noise in SAR data causes the overlapping nature of changed and unchanged classes and, thus, affects the image understanding for inferring category of each image pixel; and adequate labeled samples are quite laborious and time-consuming to collect, which is the major limitation for supervised methods. In this article, we develop a novel deep learning-based semisupervised method to address these challenges. The method first incorporates a pixel-wise log-ratio difference image (DI) and its saliency map to produce a spatially enhanced (SE) DI using a reweighting scheme based on the fact that changed pixels exhibit higher saliency than unchanged pixels. As a result, prominent changed regions are highlighted, and the class separability is significantly increased. We construct pixel-wise and context-wise features based on the log-ratio DI and SE DI, which respectively provide image detail cue and spatial context cue, as dual input features to jointly characterize the change information at each pixel position. Second, we propose a label-consistent self-ensemble network (LCS-EnsemNet), which can take advantage of the unlabeled samples to learn discriminative high-level features for the precise identification of changed pixels. By enforcing a label consistency between dual features and a label consistency across multiple classifiers, the label-consistent self-ensemble strategy enables the proposed network to selectively transform unlabeled samples into pseudo-labeled samples in an unsupervised manner and ensures that the selected pseudo-labels are reliably and stably predicted. Finally, the cross-entropy loss is calculated with the limited labeled data and selected pseudo-labeled samples to optimize the LCS-EnsemNet in a supervised way. The proposed method is evaluated on three low/medium-resolution SAR datasets and one high-resolution SAR dataset, and experimental results have demonstrated its efficiency and effectiveness.
C1 [Wang, Jian; Wang, Yinghua; Chen, Bo; Liu, Hongwei] Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Peoples R China.
C3 Xidian University
RP Wang, YH; Liu, HW (corresponding author), Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Peoples R China.
EM wj_xidian@163.com; yhwang@xidian.edu.cn; bchen@mail.xidian.edu.cn; hwliu@xidian.edu.cn
FU National Natural Science Foundation of China [61671354]; 111 Project; Shaanxi Innovation Team Project
CR An L, 2016, IEEE J-STARS, V9, P3395, DOI 10.1109/JSTARS.2015.2483320
   [Anonymous], 2004, UNDERSTANDING SYNTHE, V0, P0
   [Anonymous], 1998, STAT LEARNING THEORY, V0, P0
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   BERGAMASCO L, 2019, SPIE REMOTE SENS, V1155, P0
   Berthelot David, 2019, ARXIV190502249, V0, P5050
   Bi HX, 2019, IEEE T GEOSCI REMOTE, V57, P2116, DOI 10.1109/TGRS.2018.2871504
   Blum A., 1998, PROCEEDINGS OF THE ELEVENTH ANNUAL CONFERENCE ON COMPUTATIONAL LEARNING THEORY, V0, PP92, DOI 10.1145/279943.279962
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bovolo F, 2013, IEEE T GEOSCI REMOTE, V51, P2042, DOI 10.1109/TGRS.2012.2223219
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Bruzzone L., 2019, IEEE GEOSCI REMOTE S, V16, P1240
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P3363, DOI 10.1109/TGRS.2006.877950
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Camps-Valls G, 2007, IEEE T GEOSCI REMOTE, V45, P3044, DOI 10.1109/TGRS.2007.895416
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P820, DOI 10.1109/LGRS.2009.2026188
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chatelain F, 2008, IEEE T IMAGE PROCESS, V17, P249, DOI 10.1109/TIP.2008.916047
   Dekker RJ, 1998, INT J REMOTE SENS, V19, P1133, DOI 10.1080/014311698215649
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P2769, DOI 10.1109/TIP.2014.2319735
   Gao YH, 2021, IEEE GEOSCI REMOTE S, V18, P484, DOI 10.1109/LGRS.2020.2977838
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Glorot X., 2011, P 14 INT C ART INT S, V0, P315
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jia L, 2016, IEEE GEOSCI REMOTE S, V13, P856, DOI 10.1109/LGRS.2016.2550666
   Jia L, 2014, IEEE GEOSCI REMOTE S, V11, P1443, DOI 10.1109/LGRS.2013.2295216
   Jie Geng, 2019, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Laine Samuli, 2017, 5 INT C LEARN REPR I, V0, P0
   Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71
   Lee D.-H., 2013, WORKSH CHALL REPR LE, V3, P896
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li J, 2010, IEEE T GEOSCI REMOTE, V48, P4085, DOI 10.1109/TGRS.2010.2060550
   Li L, 2018, IEEE T GEOSCI REMOTE, V56, P4605, DOI 10.1109/TGRS.2018.2829630
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li XM, 2021, IEEE T NEUR NET LEAR, V32, P523, DOI 10.1109/TNNLS.2020.2995319
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Liu C, 2019, IEEE J-STARS, V12, P357, DOI 10.1109/JSTARS.2018.2880562
   Liu J, 2019, SPRINGER SER GEOMECH, V0, PP74, DOI 10.1007/978-981-10-7560-5_7
   Maulik U, 2017, IEEE GEOSC REM SEN M, V5, P33, DOI 10.1109/MGRS.2016.2641240
   Maulik U, 2011, PATTERN RECOGN, V44, P615, DOI 10.1016/j.patcog.2010.09.021
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Moser G, 2009, IEEE T GEOSCI REMOTE, V47, P2114, DOI 10.1109/TGRS.2009.2012407
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Qin AY, 2019, IEEE GEOSCI REMOTE S, V16, P241, DOI 10.1109/LGRS.2018.2869563
   Ratle F, 2010, IEEE T GEOSCI REMOTE, V48, P2271, DOI 10.1109/TGRS.2009.2037898
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P607, DOI 10.1109/LGRS.2020.2985340
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Santurkar S, 2018, ADV NEUR IN, V31, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun YL, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3053571
   Sun YL, 2020, IEEE J-STARS, V13, P293, DOI 10.1109/JSTARS.2019.2960518
   Tarvainen A., 2017, ADV NEURAL INFORM PR, V0, P1195
   TOKUI S, 2019, ARXIV190800213, V0, P0
   Wan LJ, 2015, IEEE T GEOSCI REMOTE, V53, P2384, DOI 10.1109/TGRS.2014.2359933
   Wang BL, 2021, IEEE SIGNAL PROC LET, V28, P503, DOI 10.1109/LSP.2021.3061289
   Wang RF, 2020, INT GEOSCI REMOTE SE, V0, PP2551, DOI 10.1109/IGARSS39084.2020.9323964
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Wang ZY, 2015, IEEE T GEOSCI REMOTE, V53, P1161, DOI 10.1109/TGRS.2014.2335177
   Xiaofan Qu, 2022, IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, V19, P0, DOI 10.1109/LGRS.2021.3073900
   Yang MJ, 2021, IEEE T GEOSCI REMOTE, V59, P2188, DOI 10.1109/TGRS.2020.3001584
   Yang W, 2014, IEEE J-STARS, V7, P3318, DOI 10.1109/JSTARS.2014.2347334
   Yousif O. A., 2002, IEEE J-STARS, V5, P1087
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zhang Y, 2018, IEEE J-STARS, V11, P4701, DOI 10.1109/JSTARS.2018.2866540
   Zhou SG, 2019, IEEE T GEOSCI REMOTE, V57, P3813, DOI 10.1109/TGRS.2018.2888485
NR 83
TC 3
Z9 3
U1 4
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11903
EP 11925
DI 10.1109/JSTARS.2021.3122461
PG 23
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XI0GL
UT WOS:000725801600008
DA 2023-04-26
ER

PT J
AU Chalmers, C
   Fergus, P
   Montanez, CAC
   Longmore, SN
   Wich, SA
AF Chalmers, C.
   Fergus, P.
   Montanez, C. Aday Curbelo
   Longmore, Steven N.
   Wich, Serge A.
TI Video analysis for the detection of animals using convolutional neural networks and consumer-grade drones
SO JOURNAL OF UNMANNED VEHICLE SYSTEMS
LA English
DT Article
DE conservation; deep learning; convolutional neural networks; inferencing; drone technology
ID wildlife research; deep; cnn
AB Determining animal distribution and density is important in conservation. The process is both time-consuming and labour-intensive. Drones have been used to help mitigate human-intensive tasks by covering large geographical areas over a much shorter timescale. In this paper we investigate this idea further using a proof of concept to detect rhinos and cars from drone footage. The proof of concept utilises off-the-shelf technology and consumer-grade drone hardware. The study demonstrates the feasibility of using machine learning (ML) to automate routine conservation tasks, such as animal detection and tracking. The prototype has been developed using a DJI Mavic Pro 2 and tested over a global system for mobile communications (GSM) network. The Faster-RCNN Resnet 101 architecture is used for transfer learning. Inference is performed with a frame sampling technique to address the required trade-off between precision, processing speed, and live video feed synchronisation. Inference models are hosted on a web platform and video streams from the drone (using OcuSync) are transmitted to a real-time messaging protocol (RTMP) server for subsequent classification. During training, the best model achieves a mean average precision (mAP) of 0.83 intersection over union (@IOU) 0.50 and 0.69 @IOU 0.75, respectively. On testing the system in Knowsley Safari our prototype was able to achieve the following: sensitivity (Sen), 0.91 (0.869, 0.94); specificity (Spec), 0.78 (0.74, 0.82); and an accuracy (ACC), 0.84 (0.81, 0.87) when detecting rhinos, and Sen, 1.00 (1.00, 1.00); Spec, 1.00 (1.00, 1.00); and an ACC, 1.00 (1.00, 1.00) when detecting cars.
C1 [Chalmers, C.; Fergus, P.; Montanez, C. Aday Curbelo] Liverpool John Moores Univ, Sch Comp Sci, Liverpool L2 2QP, Merseyside, England.
   [Longmore, Steven N.] Liverpool John Moores Univ, Astrophys Res Inst, Liverpool L3 5RF, Merseyside, England.
   [Wich, Serge A.] Liverpool John Moores Univ, Sch Biol & Environm Sci, Liverpool L2 2QP, Merseyside, England.
C3 Liverpool John Moores University; Liverpool John Moores University; Liverpool John Moores University
RP Wich, SA (corresponding author), Liverpool John Moores Univ, Sch Biol & Environm Sci, Liverpool L2 2QP, Merseyside, England.
EM s.a.wich@ljmu.ac.uk
FU Research Council UK (RCUK) Science and Technology Facilities Council (STFC) [ST/R002673/1]
CR Agapito L., 1900, V8925, V0, P0
   [Anonymous], 2004, ADV DISTANCE SAMPLIN, V0, P0
   Ba J., 2013, ADV NEURAL INFORM PR, V0, P3084
   Banerjee DS, 2016, INT CONF CLOUD COMP, V0, PP144, DOI 10.1109/CloudCom.2016.33
   Bondi E, 2018, AAAI CONF ARTIF INTE, V0, P7741
   Bondi E, 2019, ARTIF INT SOC GOOD, V0, P77
   Buckland S.T., 2001, PI, V0, P0
   Chabot D, 2015, J UNMANNED VEH SYST, V3, P137, DOI 10.1139/juvs-2015-0021
   Christie KS, 2016, FRONT ECOL ENVIRON, V14, P242, DOI 10.1002/fee.1281
   Commercial Software Engineering (CSE) group at Microsoft, 2020, VOTT VIS OBJ TAGG TO, V0, P0
   Crunchant AS, 2020, METHODS ECOL EVOL, V11, P542, DOI 10.1111/2041-210X.13362
   Fang YF, 2016, PROCEDIA COMPUT SCI, V92, P13, DOI 10.1016/j.procs.2016.07.316
   Hazelwood K, 2018, INT S HIGH PERF COMP, V0, PP620, DOI 10.1109/HPCA.2018.00059
   Hensel M, 2017, ADV NEUR IN, V30, P0
   Jakobs S., 2019, ATZHEAVY DUTY WORLDW, V12, P44, DOI 10.1007/s41321-019-0024-8
   Kanai Sekitoshi, 2017, P 31 INT C NEURAL IN, V0, P435
   King DB, 2015, ACS SYM SER, V1214, P1
   Lamba A, 2019, CURR BIOL, V29, PR977, DOI 10.1016/j.cub.2019.08.016
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Lee J, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), V0, PP36, DOI 10.1109/IRC.2017.77
   Lim K, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0173317
   Longmore SN, 2017, INT J REMOTE SENS, V38, P2623, DOI 10.1080/01431161.2017.1280639
   Maire F, 2015, LECT NOTES ARTIF INT, V9457, P379, DOI 10.1007/978-3-319-26350-2_33
   Martinez P, 2019, AUTOMAT CONSTR, V97, P151, DOI 10.1016/j.autcon.2018.10.021
   Maxwell S, 2016, NATURE, V536, P143, DOI 10.1038/536143a
   Nichols JD, 2006, TRENDS ECOL EVOL, V21, P668, DOI 10.1016/j.tree.2006.08.007
   Peng JB, 2020, ISPRS J PHOTOGRAMM, V169, P364, DOI 10.1016/j.isprsjprs.2020.08.026
   Rampasek Ladislav, 2016, CELL SYST, V2, P12, DOI 10.1016/j.cels.2016.01.009
   Saria S, 2018, PLOS MED, V15, P0, DOI 10.1371/journal.pmed.1002721
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Talukdar J, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), V0, P78
   van Gemert JC, 2015, LECT NOTES COMPUT SC, V8925, P255, DOI 10.1007/978-3-319-16178-5_17
   Wich SA, 2018, CONSERVATION DRONES: MAPPING AND MONITORING BIODIVERSITY, V0, PP1, DOI 10.1093/oso/9780198787617.001.0001
NR 35
TC 6
Z9 6
U1 2
U2 2
PU CANADIAN SCIENCE PUBLISHING
PI OTTAWA
PA 65 AURIGA DR, SUITE 203, OTTAWA, ON K2E 7W6, CANADA
SN 2291-3467
EI 
J9 J UNMANNED VEH SYST
JI J. Unmanned Veh. Syst.
PD JUN 15
PY 2021
VL 9
IS 2
BP 112
EP 127
DI 10.1139/juvs-2020-0018
PG 16
WC Remote Sensing
SC Remote Sensing
GA UP5XS
UT WOS:000695453500003
DA 2023-04-26
ER

PT J
AU Shi, JW
   Jiang, ZG
   Zhang, HP
AF Shi, Jiawei
   Jiang, Zhiguo
   Zhang, Haopeng
TI Few-Shot Ship Classification in Optical Remote Sensing Images Using Nearest Neighbor Prototype Representation
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Marine vehicles; Prototypes; Training; Remote sensing; Measurement; Optical sensors; Convolutional neural network (CNN); few-shot learning; nearest neighbor; remote sensing image (RSI); ship classification
AB With the development of ship detection in optical remote sensing images, it is convenient to obtain accurate detection results and ship images. Owing to the superior performance of convolutional neural networks (CNNs), one way to acquire the category of ship is to train a classifier using numerous ship images. However, the classification performance of CNN may degrade in the case of a small number of training samples. To solve this problem, we propose a metric-based few-shot method to generate novel concept (class) representation using nearest neighbor prototype. Different from image-to-image measure in common few-shot methods, we use an image-to-feature measure. We map small number of samples to the feature space through CNN, and generate prototypes by computing nearest neighbor value on each dimension of the feature separately. Our method is validated on patch-level ship image dataset, a reproduced ship classification dataset based on HRSC2016. The experimental results demonstrate the accuracy and robustness of our method for ship classification with a small amount of labeled data.
C1 [Shi, Jiawei; Jiang, Zhiguo; Zhang, Haopeng] Beihang Univ, Dept Aerosp Informat Engn, Sch Astronaut, Beijing Key Lab Digital Media,Minist Educ,Image P, Beijing 102206, Peoples R China.
   [Shi, Jiawei; Jiang, Zhiguo; Zhang, Haopeng] Beihang Univ, Minist Educ, Key Lab Spacecraft Design Optimizat & Dynam Simul, Beijing 102206, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, HP (corresponding author), Beihang Univ, Dept Aerosp Informat Engn, Sch Astronaut, Beijing Key Lab Digital Media,Minist Educ,Image P, Beijing 102206, Peoples R China.; Zhang, HP (corresponding author), Beihang Univ, Minist Educ, Key Lab Spacecraft Design Optimizat & Dynam Simul, Beijing 102206, Peoples R China.
EM shijiawei@buaa.edu.cn; jiangzg@buaa.edu.cn; zhanghaopeng@huaa.edu.cn
FU National Key Research and Development Program of China [2016YFB0501300, 2016YFB0501302]; Fundamental Research Funds for the Central Universities
CR Banerjee A, 2005, J MACH LEARN RES, V6, P1705
   Bertinetto L., 2019, ICLR, V0, P0
   Cai Q, 2018, PROC CVPR IEEE, V0, PP4080, DOI 10.1109/CVPR.2018.00429
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Finn C, 2017, PR MACH LEARN RES, V70, P0
   Garcia V., 2018, P ICLR, V0, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090907
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Koch GR, 2015, SIAMESE NEURAL NETWO, V0, P0
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lake B., 2011, P ANN M COGN SCI SOC, V33, P1
   Lang HT, 2018, IEEE GEOSCI REMOTE S, V15, P439, DOI 10.1109/LGRS.2018.2792683
   Li AX, 2019, IEEE I CONF COMP VIS, V0, PP9714, DOI 10.1109/ICCV.2019.00981
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li JW, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.035010
   Li QP, 2018, IEEE T GEOSCI REMOTE, V56, P7147, DOI 10.1109/TGRS.2018.2848901
   Li WB, 2019, PROC CVPR IEEE, V0, PP7253, DOI 10.1109/CVPR.2019.00743
   Liu ZK, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, V0, PP324, DOI 10.5220/0006120603240331
   Lu CC, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19010063
   Mishra Nikhil, 2018, ICLR, V0, P0
   Ramalho Tiago, 2018, 7 INT C LEARN REPR I, V0, P0
   Ravi S., 2017, INT C LEARN REPR, V0, P0
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rostami M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111374
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, ARXIV, V0, P0
   Snell J., 2017, P ADV NEUR INF PROC, V1703, P0
   Sung F, 2018, PROC CVPR IEEE, V0, PP1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Vinyals O., 2016, ADV NEURAL INFORM PR, V29, P3630
   Wang YY, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18092929
   Ward CM, 2018, OCEANS 2018 MTS/IEEE CHARLESTON, V0, P0
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Yang F, 2017, IEEE GEOSCI REMOTE S, V14, P602, DOI 10.1109/LGRS.2017.2664118
   Yosinski J, 2014, ADV NEUR IN, V27, P0
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P5832, DOI 10.1109/TGRS.2016.2572736
NR 43
TC 9
Z9 10
U1 7
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3581
EP 3590
DI 10.1109/JSTARS.2021.3066539
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RK6JR
UT WOS:000638400600009
DA 2023-04-26
ER

PT J
AU Li, YH
   Gu, ST
AF Li, Yihai
   Gu, Shaotang
TI Detecting Post Hurricane House Damage Using Geographic Information Related Multi-Resource Classification Model
SO 2021 2ND INTERNATIONAL CONFERENCE ON BIG DATA & ARTIFICIAL INTELLIGENCE & SOFTWARE ENGINEERING (ICBASE 2021)
LA English
DT Proceedings Paper
DE convolutional neural networks (CNNs); SCNN; image classification; geographic coordinate; multi- resource knowledge; multi resource CNN (MICNN); super resolution CNN with up sampling (SRCNN-US); Lota
AB Hurricane, like other natural cataclysms that threaten human life and houses' damage detection after a hurricane, is always a problem that needs to be solved. It is vital to retrieving the building damage status for planning rescue and reconstruction after the cataclysm. In this study, the convolutional neural networks (CNN) were utilized to identify collapsed buildings from post hurricane satellite imagery with the proposed workflow. Test accuracy (TeA), training accuracy (TrA), bootstrap algorithm, Grad-CAM, and feature maps (FM) were used as evaluation metrics. To overcome the imbalance, problems like overfitting, random flip, random sheer and zoom, and early stopping approach were tested on the investigations. The results demonstrated that the building collapsed information can be retrieved by utilizing post-event imagery. Simple convolutional neural network (SCNN) is the standard to compare the other two architectures, which achieved TrA 74.39% and TeA 76.91%, spend 18.22s per epoch. After adding an additional super resolution block specifically designed. The super resolution CNN with up sampling (SRCNN-US) reached lower TrA 78.01% but higher TeA 73.80% by spending nearly 4 times more (78.14s). Moreover, the multi input redesigned SCNN (MICNN) architecture showed better performance, with TrA value from 74.39% to 84.97% and TeA from 76.91% to 78.81% but consumed only 0.22s more per epoch. Combining MICNN and SRCNN-US, the MI-SRCNN-US model achieved the highest accuracy on the test set, 80.36%, and time-consuming, 83.50s/epoch. The 50 times bootstrap investigation shows that the MICNN makes predictions under more certainty with more accuracy. In subsequent evaluations, Grad-CAM and feature maps also prove that MICNN pays more attention to the building's region rather than its surroundings. Therefore, the suitable method to promote classification performance is by using post-hurricane cataclysm satellite imagery together with related geographic coordinates information as the input of CNN.
C1 [Li, Yihai] Shanxi Univ, Inst Math Sci & Appl Math, Taiyuan, Peoples R China.
   [Gu, Shaotang] Univ Sydney USYD, Sch Comp Sci, Camperdown, NSW 2006, Australia.
C3 Shanxi University
RP Li, YH (corresponding author), Shanxi Univ, Inst Math Sci & Appl Math, Taiyuan, Peoples R China.
EM pokemonarrive@gmail.com; shgu2901@uni.sydney.edu.au
CR Albelwi S, 2016, 2016 15 IEEE INT C M, V0, P0
   An Mai, 2020, 2020 7TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), V0, PP118, DOI 10.1109/NICS51282.2020.9335842
   Bottou L, 2010, COMPSTAT2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, V0, PP177, DOI 10.1007/978-3-7908-2604-3_16
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dong X, 2013, NAT HAZARD EARTH SYS, V13, P3211, DOI 10.5194/nhess-13-3211-2013
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Jaynes E. T., 2003, PROBABILITY THEORY L, V0, P0
   Ji M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101202
   Krizhevsky A, 2014, ABS14045997 CORR, V0, P0
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, V0, P1
   Powers D. M. W., 2011, J MACH LEARN TECHNOL, V2, P37
   Rosenblatt W., 2015, POLY CANYON BRIDGE H, V0, P0
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Soni A, 2020, LECT NOTES CIVIL ENG, V33, P489, DOI 10.1007/978-981-13-7067-0_38
   Yang WT, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030504
NR 21
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 492
EP 501
DI 10.1109/ICBASE53849.2021.00098
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods
SC Computer Science
GA BT1CC
UT WOS:000796392500089
DA 2023-04-26
ER

PT J
AU Hu, XD
   Zhang, PL
   Zhang, Q
   Wang, JQ
AF Hu, Xudong
   Zhang, Penglin
   Zhang, Qi
   Wang, Junqiang
TI Improving wetland cover classification using artificial neural networks with ensemble techniques
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Wetlands; classification; ensemble learning; artificial neural network; remote sensing
ID machine learning algorithms; high-spatial-resolution; land-cover; image-analysis; fusion methods; climate-change; random forest; sar data; vegetation; model
AB Wetland cover classification grows out of the need for management and protection for wetland sources to depict wetland landscapes. Exploring improved classification methods is important to derive good-quality wetland mapping products. This study investigates and applies two artificial neural network (ANN) based ensemble methods, namely, the MultiBoost artificial neural network (MBANN) and the rotation artificial neural network (RANN), for wetland cover classification, taking the Zoige wetland sited in the Qinghai-Tibet Plateau, China as the case area. The RANN trains and combines diverse ANNs by constructing a series of sparse rotation matrices, whereas the MBANN is developed from the sequential iteration in combination with the parallel sampling technique. Sixteen features related to wetland covers were extracted based on the digital elevation model data and Landsat 8 OLI images. The deep visual geometry group (VGG11) and random forests (RF) were implemented for comparison with our methods. The classification capability evaluation shows that our ensemble methods significantly improve the single ANN and outperform the VGG11 and RF. The RANN yields the highest overall accuracy (0.961), followed by the MBANN (0.942), VGG11 (0.934), RF (0.931), and ANN (0.916). We further concern and evaluate the classifier's robustness because it reflects the uniformity of classification capability. The RANN and the MBANN are insensitive to the reduction in data size, resistant to feature variability, and not influenced by data noise. Overall, the use of ensemble techniques can refine single ANN in classification capability and stability. The results from this study attest the important role of ensemble learning, which provides a promising scheme for wetland cover classification.
C1 [Hu, Xudong; Zhang, Penglin; Zhang, Qi] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
   [Zhang, Penglin] Minist Land & Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen, Peoples R China.
   [Wang, Junqiang] China Special Equipment Inspection & Res Inst, Div Pressure Pipelines, Beijing, Peoples R China.
   [Wang, Junqiang] Technol Innovat Ctr Oil & Gas Pipeline & Storage, Beijing, Peoples R China.
C3 Wuhan University; Ministry of Natural Resources of the People's Republic of China
RP Wang, JQ (corresponding author), China Special Equipment Inspection & Res Inst, Div Pressure Pipelines, Beijing, Peoples R China.; Wang, JQ (corresponding author), Technol Innovat Ctr Oil & Gas Pipeline & Storage, Beijing, Peoples R China.
EM wjqiang418@sina.com
FU National Key Research and Development Program of China [NQI-2018YFF0215003]; Key Laboratory of Urban Land Resources Monitoring and Simulation, Ministry of Land and Resources [KF-2019-04-046]
CR Adam E, 2014, INT J REMOTE SENS, V35, P693, DOI 10.1080/01431161.2013.870676
   Adam E, 2010, WETL ECOL MANAG, V18, P281, DOI 10.1007/s11273-009-9169-z
   Amani M, 2018, INT J REMOTE SENS, V39, P7370, DOI 10.1080/01431161.2018.1468117
   Amani M, 2017, GISCI REMOTE SENS, V54, P779, DOI 10.1080/15481603.2017.1331510
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169
   Berberoglu S, 2004, BIODIVERS CONSERV, V13, P615, DOI 10.1023/B:BIOC.0000009493.34669.ec
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Cai YT, 2020, INT J APPL EARTH OBS, V92, P0, DOI 10.1016/j.jag.2020.102164
   Chen H, 2013, GLOBAL CHANGE BIOL, V19, P2940, DOI 10.1111/gcb.12277
   Chen W, 2019, J HYDROL, V575, P864, DOI 10.1016/j.jhydrol.2019.05.089
   Chen YB, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101055
   CONGALTON RG, 1983, PHOTOGRAMM ENG REM S, V49, P1671
   Cui Q, 2012, PROCEDIA ENVIRON SCI, V13, P1527, DOI 10.1016/j.proenv.2012.01.145
   Cui Q, 2015, ECOL ENG, V76, P158, DOI 10.1016/j.ecoleng.2014.03.035
   Dai L., 2010, P 2010 2 INT C INF, V0, P0
   Cordeiro CLD, 2015, INT J REMOTE SENS, V36, P3397, DOI 10.1080/01431161.2015.1060644
   De Steven D, 2004, WETLANDS, V24, P23, DOI 10.1672/0277-5212(2004)024[0023:VOUCPD]2.0.CO;2
   DeLancey ER, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010002
   Di Vittorio CA, 2018, REMOTE SENS ENVIRON, V204, P1, DOI 10.1016/j.rse.2017.11.001
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Dronova I, 2015, REMOTE SENS-BASEL, V7, P6380, DOI 10.3390/rs70506380
   Dubeau P, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101056
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Eeti LN, 2021, GEOCARTO INT, V36, P1820, DOI 10.1080/10106049.2019.1678680
   Feng M, 2016, INT J DIGIT EARTH, V9, P113, DOI 10.1080/17538947.2015.1026420
   Fluet-Chouinard E, 2015, REMOTE SENS ENVIRON, V158, P348, DOI 10.1016/j.rse.2014.10.015
   Franklin SE, 2017, PHOTOGRAMM ENG REM S, V83, P27, DOI 10.14358/PERS.83.1.27
   Freund Y., 1996, ICML, V0, PP148, DOI 10.5555/3091696.3091715
   Gallant AL, 2015, REMOTE SENS-BASEL, V7, P10938, DOI 10.3390/rs70810938
   Ghimire B, 2012, GISCI REMOTE SENS, V49, P623, DOI 10.2747/1548-1603.49.5.623
   Glanz H, 2014, ISPRS J PHOTOGRAMM, V97, P219, DOI 10.1016/j.isprsjprs.2014.09.004
   GORHAM E, 1991, ECOL APPL, V1, P182, DOI 10.2307/1941811
   Gosselin G, 2014, CAN J REMOTE SENS, V39, P491, DOI 10.5589/m14-002
   Halmy MWA, 2015, INT J REMOTE SENS, V36, P5613, DOI 10.1080/01431161.2015.1103915
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong SH, 2015, REMOTE SENS-BASEL, V7, P8563, DOI 10.3390/rs70708563
   Hou MJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030368
   Hu XD, 2021, NAT HAZARDS, V105, P1663, DOI 10.1007/s11069-020-04371-4
   Hu XD, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10114016
   Jozdani SE, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141713
   Kesikoglu MH, 2019, WATER SCI TECHNOL, V80, P466, DOI 10.2166/wst.2019.290
   Kumar L, 2014, GISCI REMOTE SENS, V51, P483, DOI 10.1080/15481603.2014.947838
   Lagos NA, 2008, WETLANDS, V28, P938, DOI 10.1672/07-119.1
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lei GB, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060987
   Li HL, 2015, CONSERV PHYSIOL, V3, P0, DOI 10.1093/conphys/cov046
   Liu GS, 2016, SCI COLD ARID REG, V8, P125, DOI 10.3724/SP.J.1226.2016.00125
   Ma MJ, 2011, PLANT SOIL, V346, P19, DOI 10.1007/s11104-011-0790-2
   Mahdavi S, 2018, GISCI REMOTE SENS, V55, P623, DOI 10.1080/15481603.2017.1419602
   Mahdianpari M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010043
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   Mandianpari M, 2017, ISPRS J PHOTOGRAMM, V130, P13, DOI 10.1016/j.isprsjprs.2017.05.010
   Mohammadimanesh F, 2018, INT J APPL EARTH OBS, V73, P450, DOI 10.1016/j.jag.2018.06.005
   Niu B, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070592
   Niu KC, 2014, AGR ECOSYST ENVIRON, V182, P106, DOI 10.1016/j.agee.2013.07.015
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Palubinskas G, 2016, INT J IMAGE DATA FUS, V7, P203, DOI 10.1080/19479832.2016.1180326
   Poiani KA, 1996, LIMNOL OCEANOGR, V41, P871, DOI 10.4319/lo.1996.41.5.0871
   Polikar R., 2006, IEEE CIRCUITS AND SYSTEMS MAGAZINE, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Pouliot D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070772
   Rezaee M, 2018, IEEE J-STARS, V11, P3030, DOI 10.1109/JSTARS.2018.2846178
   Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Schapire R. E., 1997, P 14 INT C MACH LEAR, V0, P322
   Simonyan K, 2015, ARXIV, V0, P0
   Szantoi Z, 2015, ENVIRON MONIT ASSESS, V187, P0, DOI 10.1007/s10661-015-4426-5
   Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121
   Thomas C, 2008, IEEE T GEOSCI REMOTE, V46, P1301, DOI 10.1109/TGRS.2007.912448
   Wang G, 2011, EXPERT SYST APPL, V38, P223, DOI 10.1016/j.eswa.2010.06.048
   Wang XX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161927
   Wang YL, 2012, PROCEDIA ENVIRON SCI, V13, P1585, DOI 10.1016/j.proenv.2012.01.150
   Wang YF, 2019, J VIS COMMUN IMAGE R, V59, P210, DOI 10.1016/j.jvcir.2018.12.049
   Warner BG, 1997, CANADIAN WETLAND CLA, V0, P0
   Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849
   Wen L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101683
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111593
   Zhang SY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010066
   Zhang YL, 2010, J GEOGR SCI, V20, P375, DOI 10.1007/s11442-010-0375-7
   Zhao L, 2010, BIOGEOSCIENCES, V7, P1207, DOI 10.5194/bg-7-1207-2010
   Zhao Q., 2010, P 2010 3 INT C IM, V0, P0
   Zhao XM, 2019, IEEE GEOSCI REMOTE S, V16, P1145, DOI 10.1109/LGRS.2019.2890996
   Zhou Z.H., 2009, ENCY BIOMETRICS, V1, P270, DOI 10.1007/978-0-387-73003-5_293
   Zhu LQ, 2018, ACTA GEOPHYS, V66, P983, DOI 10.1007/s11600-018-0180-8
NR 85
TC 14
Z9 14
U1 16
U2 82
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD MAY 19
PY 2021
VL 58
IS 4
BP 603
EP 623
DI 10.1080/15481603.2021.1932126
EA JUN 2021
PG 21
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA SX2QJ
UT WOS:000657220700001
DA 2023-04-26
ER

PT J
AU Xu, L
   Ma, AL
AF Xu, Lei
   Ma, Ailong
TI Coarse-to-fine waterlogging probability assessment based on remote sensing image and social media data
SO GEO-SPATIAL INFORMATION SCIENCE
LA English
DT Article
DE Remote sensing; social media; urban waterlogging; data fusion
ID random forest classifier; difference water index; flood extent; resolution; twitter; surface; ndwi
AB Urban waterlogging probability assessment is critical to emergency response and policymaking. Remote Sensing (RS) is a rich and reliable data source for waterlogging monitoring and evaluation through water body extraction derived from the pre- and post-disaster RS images. However, RS images are usually limited to the revisit cycle and cloud cover. To solve this issue, social media data have been considered as another data source which are immune to the weather such as clouds and can reflect the real-time public response for disaster, which leads itself a compensation for RS images. In this paper, we propose a coarse-to-fine waterlogging probability assessment framework based on multisource data including real-time social media data, near real-time RS image and historical geographic information, in which a coarse waterlogging probability map is refined by using the real-time information extracted from social media data to acquire a more accurate waterlogging probability. Firstly, to generate a coarse waterlogging probability map, the historical inundated areas are derived from Digital Elevation Model (DEM) and historical waterlogging points, then the geographic features are extracted from DEM and RS image, which will be input to a Random Forest (RF) classifier to estimate the likelihood of hazards. Secondly, the real-time waterlogging-related information is extracted from social media data, where the Convolutional Neural Network (CNN) model is applied to exploit the semantic information of sentences by capturing the local and position-invariant features using convolution kernel. Finally, fine waterlogging probability map scan be generated based on morphological method, in which real-time waterlogging-related social media data are taken as isolated highlight point and used to refine the coarse waterlogging probability map by a gray dilation pattern considering the distance-decay effect. The 2016 Wuhan waterlogging and 2018 Chengdu waterlogging are taken as case studies to demonstrate the effectiveness of the proposed framework. It can be concluded from the results that by integrating RS image and social media data, more accurate waterlogging probability maps can be generated, which can be further applied for inundated areas identification and disaster monitoring.
C1 [Xu, Lei; Ma, Ailong] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Peoples R China.
   [Xu, Lei; Ma, Ailong] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan, Peoples R China.
C3 Wuhan University; Wuhan University
RP Ma, AL (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Peoples R China.; Ma, AL (corresponding author), Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan, Peoples R China.
EM maailong007@whu.edu.cn
FU China Postdoctoral Science Foundation [2017M622522]
CR Abel F., 2012, WWW 12 P 21 ANN C WO, V0, PP305, DOI 10.1145/2187980.2188035
   Atkinson GM, 2007, SEISMOL RES LETT, V78, P362, DOI 10.1785/gssrl.78.3.362
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Brivio PA, 2002, INT J REMOTE SENS, V23, P429, DOI 10.1080/01431160010014729
   Carlson TN, 1997, REMOTE SENS ENVIRON, V62, P241, DOI 10.1016/S0034-4257(97)00104-1
   Cervone G, 2016, INT J REMOTE SENS, V37, P100, DOI 10.1080/01431161.2015.1117684
   Chae J, 2012, IEEE CONF VIS ANAL, V0, PP143, DOI 10.1109/VAST.2012.6400557
   Chowdhury S. R., 2013, PROC 10 INT ISCRAM C, V0, P1
   de Albuquerque JP, 2015, INT J GEOGR INF SCI, V29, P667, DOI 10.1080/13658816.2014.996567
   Feng QL, 2015, WATER-SUI, V7, P1437, DOI 10.3390/w7041437
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   Foresti GL, 2015, J AMB INTEL HUM COMP, V6, P239, DOI 10.1007/s12652-014-0227-x
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   GOWARD SN, 1991, REMOTE SENS ENVIRON, V35, P257, DOI 10.1016/0034-4257(91)90017-Z
   Herfort B, 2014, LECT NOTES GEOINF CA, V0, PP55, DOI 10.1007/978-3-319-03611-3_4
   Huang X, 2018, ANN GIS, V24, P113, DOI 10.1080/19475683.2018.1450787
   Huang X, 2018, IEEE T GEOSCI REMOTE, V56, P4691, DOI 10.1109/TGRS.2018.2835306
   Ilieva RT, 2018, NAT SUSTAIN, V1, P553, DOI 10.1038/s41893-018-0153-6
   Islam MM, 2000, HYDROL PROCESS, V14, P605, DOI 10.1002/(SICI)1099-1085(20000228)14:3&lt;605::AID-HYP957&gt;3.0.CO;2-L
   Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009
   Jony R. I., 2018, 2018 DIGITAL IMAGE C, V0, P1
   Kim Y., 2014, CONVOLUTIONAL NEURAL, V0, P0, DOI DOI 10.3115/V1/D14-1181
   Li J, 2017, P IEEE, V105, P1900, DOI 10.1109/JPROC.2017.2684460
   Lopez-Fuentes L., 2017, MEDIAEVAL, V0, P1
   Miller HJ, 2004, ANN ASSOC AM GEOGR, V94, P284, DOI 10.1111/j.1467-8306.2004.09402005.x
   Mosavi A, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10111536
   Nie LQ, 2020, ACM T INFORM SYST, V38, P0, DOI 10.1145/3380954
   Okolloh O., 2009, PARTICIPATORY LEARN, V59, P65
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Panteras G, 2018, INT J REMOTE SENS, V39, P1459, DOI 10.1080/01431161.2017.1400193
   Power R, 2014, LECT NOTES BUS INF P, V196, P218
   Robinson B., 2013, P WORKSH LANG PROC C, V0, P0
   Robinson B, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW13 COMPANION), V0, P999
   Rogstadius J, 2013, IBM J RES DEV, V57, P0, DOI 10.1147/JRD.2013.2260692
   Rosser JF, 2017, NAT HAZARDS, V87, P103, DOI 10.1007/s11069-017-2755-0
   Sakai T, 2011, PANCREAS, V40, P403, DOI 10.1097/MPA.0b013e318204e815
   Smith L, 2017, J FLOOD RISK MANAG, V10, P370, DOI 10.1111/jfr3.12154
   Sun DL, 2011, IEEE J-STARS, V4, P814, DOI 10.1109/JSTARS.2011.2125778
   Tyshchuk Y., 2012, 2012 45TH HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), V0, PP818, DOI 10.1109/HICSS.2012.536
   Wald DJ, 2011, ANN GEOPHYS-ITALY, V54, P688, DOI 10.4401/ag-5354
   Wang Y, 2002, INT J REMOTE SENS, V23, P3681, DOI 10.1080/01431160110114484
   Weng QH, 2008, INT J APPL EARTH OBS, V10, P68, DOI 10.1016/j.jag.2007.05.002
   Xie C, 2016, INT J DIGIT EARTH, V9, P925, DOI 10.1080/17538947.2016.1170215
   Xu F., 2015, THESIS, V0, P0
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Xu Z., 2015, P 1 ACM SIGSPATIAL I, V0, P1
   Yang HB, 2011, PROCEDIA ENVIRON SCI, V10, P2619, DOI 10.1016/j.proenv.2011.09.407
   Yin J, 2012, IEEE INTELL SYST, V27, P52, DOI 10.1109/MIS.2012.6
   Zhang FF, 2011, PROCEDIA ENVIRON SCI, V11, P1482, DOI 10.1016/j.proenv.2011.12.223
   Zhang NY, 2016, COMPUT INTEL NEUROSC, V2016, P0, DOI 10.1155/2016/3264587
   Zhang Y., 2015, SENSITIVITY ANAL AND, V0, P0
NR 52
TC 8
Z9 8
U1 13
U2 57
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1009-5020
EI 1993-5153
J9 GEO-SPAT INF SCI
JI Geo-Spat. Inf. Sci.
PD APR 3
PY 2021
VL 24
IS 2
BP 279
EP 301
DI 10.1080/10095020.2020.1812445
EA SEP 2020
PG 23
WC Remote Sensing
SC Remote Sensing
GA SM1HW
UT WOS:000570782600001
DA 2023-04-26
ER

PT J
AU Pickell, PD
   Chavardes, RD
   Li, SJ
   Daniels, LD
AF Pickell, Paul D.
   Chavardes, Raphael D.
   Li, Shuojie
   Daniels, Lori D.
TI FuelNet: An Artificial Neural Network for Learning and Updating Fuel Types for Fire Research
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Fuels; Forestry; Remote sensing; Neural networks; Meteorology; Indexes; Earth; Artificial neural network; Canadian forest fire danger rating system; fire behavior; fuel types; megafire; wildfire
ID spatial-resolution; image-analysis; national-park; time-series; mega-fires; models; management; severity
AB Wildfire is a significant driver of forest and land cover change in the central interior of British Columbia, Canada. Fuel type maps are a primary input to fire behavior calculations and simulation studies that assess wildfire threat at the landscape level. However, these thematic maps are not easily produced at the scale and speed needed to assess and mitigate wildfire threat on an annual basis. The objective of this research was to explore how an artificial neural network could be used with remotely sensed satellite imagery to map and update fuel types on an annual basis. We applied the artificial neural network over a 40 000-km(2) landscape in central interior British Columbia that burned from a megafire in 2017. Fuel maps were generated for the years 2014-2018, assessed through an independent validation, and evaluated against an existing fuel type map. The highest cross-validation overall accuracy during training was 66.5% and overall accuracy from the independent validation was 63.1%. Generally, the maps had fair agreement with the existing fuel type map (circa 2016), with Cohen's Kappa ranging from 0.28 in 2018 to 0.35 in 2015. Several recommendations are provided for future research using artificial neural networks for fuel typing such as assuring quality of training samples through rigorous standards, designing the network architecture, choosing appropriate cost functions and regularization, incorporating learning of temporal features, and identifying novel fuel types from the output activations.
C1 [Pickell, Paul D.; Li, Shuojie] Univ British Columbia, Dept Forest Resources Management, Vancouver, BC V6T 1Z4, Canada.
   [Chavardes, Raphael D.] Univ Quebec Abitibi Temiscamingue, Inst Rech Sur Forets, Rouyn Noranda, PQ J9X 5E4, Canada.
   [Daniels, Lori D.] Univ British Columbia, Dept Forest & Conservat Sci, Vancouver, BC V6T 1Z4, Canada.
C3 University of British Columbia; University of Quebec; University Quebec Abitibi-Temiscamingue; University of British Columbia
RP Pickell, PD (corresponding author), Univ British Columbia, Dept Forest Resources Management, Vancouver, BC V6T 1Z4, Canada.
EM paul.pickell@ubc.ca; raphael.chavardes@uqat.ca; shuojie.li@ubc.ca; lori.daniels@ubc.ca
FU British Columbia Forest Improvement and Research Management Branch; Work Learn International Undergraduate Research Award from The University of British Columbia; Intact Foundation
CR Alonso-Benito A, 2016, PROC SPIE, V9998, P0, DOI 10.1117/12.2241990
   Alonso-Benito A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080669
   Alonso-Benito A, 2013, INT J WILDLAND FIRE, V22, P306, DOI 10.1071/WF11068
   [Anonymous], 1995, BRIT COL FOR PRACT C, V0, P0
   [Anonymous], 2020, ADV FOREST FIRE RES, V0, P0
   [Anonymous], 2020, NATL BURNED AREA COM, V0, P0
   Arellano-Perez S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101645
   Arkin J, 2019, INT J WILDLAND FIRE, V28, P840, DOI 10.1071/WF19008
   Arroyo LA, 2008, FOREST ECOL MANAG, V256, P1239, DOI 10.1016/j.foreco.2008.06.048
   Bonazountas M, 2012, FOREST FIRES, V158, P67
   Bridle J. S., 1990, NEUROCOMPUTING, V0, P0
   British Columbia Forest Analysis and Inventory Branch, 2019, HARV AR BC CONS CUTB, V0, P0
   British Columbia Forest Inventory and Analysis Branch, 2019, VRI 2019 FOR VEG COM, V0, P0
   British Columbia Wildfire Service, 2020, FIR PER HIST DAT SET, V0, P0
   Cary GJ, 2006, LANDSCAPE ECOL, V21, P121, DOI 10.1007/s10980-005-7302-9
   Chollet F., 2017, US, V0, P0
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Coluzzi R, 2007, PROC SPIE, V6742, P0, DOI 10.1117/12.748033
   Coops NC, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0197218
   Demarchi D.A., 2011, INTRO ECOREGIONS BRI, V0, P0
   Doerr SH, 2016, PHILOS T R SOC B, V371, P0, DOI 10.1098/rstb.2015.0345
   Falkowski MJ, 2005, FOREST ECOL MANAG, V217, P129, DOI 10.1016/j.foreco.2005.06.013
   Fernandez-Alvarez M, 2019, FORESTS, V10, P0, DOI 10.3390/f10020148
   Flannigan M, 2013, FOREST ECOL MANAG, V294, P54, DOI 10.1016/j.foreco.2012.10.022
   Giakoumakis M. N., 2002, FOREST FIRE RESEARCH AND WILDLAND FIRE SAFETY: PROCEEDINGS OF IV INTERNATIONAL CONFERENCE ON FOREST FIRE RESEARCH 2002 WILDLAND FIRE SAFETY SUMMIT, V0, P66
   Gitas I.Z., 2006, FOREST ECOL MANAG, V234, PS228, DOI 10.1016/J.FORECO.2005.08.255
   Gong WB, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6100292
   Goodbody TRH, 2019, CURR FOR REP, V5, P55, DOI 10.1007/s40725-019-00087-2
   Goodbody TRH, 2018, INT J REMOTE SENS, V39, P5246, DOI 10.1080/01431161.2017.1402387
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Hermosilla T, 2018, CAN J REMOTE SENS, V44, P67, DOI 10.1080/07038992.2018.1437719
   Hermosilla T, 2015, REMOTE SENS ENVIRON, V170, P121, DOI 10.1016/j.rse.2015.09.004
   Hobart G. W., 2016, INT J DIGIT EARTH, V9, P1035, DOI 10.1080/17538947.2016.1187673
   Johnson JM, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0192-5
   Keane RE, 2001, INT J WILDLAND FIRE, V10, P301, DOI 10.1071/WF01028
   Keane RE, 2012, EXPERT KNOWLEDGE AND ITS APPLICATION IN LANDSCAPE ECOLOGY, V0, PP211, DOI 10.1007/978-1-4614-1034-8_11
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lasaponara R, 2006, INT J REMOTE SENS, V27, P587, DOI 10.1080/01431160500227631
   Lasaponara R, 2007, INT J APPL EARTH OBS, V9, P225, DOI 10.1016/j.jag.2006.08.001
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Maffei C, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111777
   Mallinis G, 2014, REMOTE SENS-BASEL, V6, P1684, DOI 10.3390/rs6021684
   Perrakis DDB., 2018, BRIT COLUMBIA WILDFI, V0, P0
   Peterson SH, 2013, CAN J FOREST RES, V43, P7, DOI 10.1139/cjfr-2012-0213
   Pierce AD, 2012, FOREST ECOL MANAG, V279, P77, DOI 10.1016/j.foreco.2012.05.010
   Riano D, 2002, CAN J FOREST RES, V32, P1301, DOI 10.1139/X02-052
   Roerink GJ, 2000, INT J REMOTE SENS, V21, P1911, DOI 10.1080/014311600209814
   San-Miguel-Ayanz J, 2013, FOREST ECOL MANAG, V294, P11, DOI 10.1016/j.foreco.2012.10.050
   Scudder G., 2011, ASSESSMENT SPECIES D, V0, P1
   Sesnie SE, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091358
   Stavros E. Natasha, 2018, REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT, V11, P41, DOI 10.1016/j.rsase.2018.04.010
   Stefanidou A, 2018, GEOCARTO INT, V33, P1064, DOI 10.1080/10106049.2017.1333532
   Stefanidou A, 2020, GEOCARTO INT, V5, P1
   Stephens SL, 2014, FRONT ECOL ENVIRON, V12, P115, DOI 10.1890/120332
   Stocks BJ, 2002, J GEOPHYS RES-ATMOS, V108, P0, DOI 10.1029/2001JD000484
   Tachikawa T, 2011, ASTER GLOBAL DIGITAL, V0, P0
   Tanase MA, 2008, IEEE J-STARS, V1, P220, DOI 10.1109/JSTARS.2009.2012475
   Tian Xiao-rui, 2005, JOURNAL OF FORESTRY RESEARCH (HARBIN), V16, P311, DOI 10.1007/BF02858198
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Van Wagner C.E., 1987, DEV STRUCTURE CANADI, V0, P0
   Van Wagtendonk JW, 2003, INT J REMOTE SENS, V24, P1639, DOI 10.1080/01431160210144679
   Varga TA, 2008, ECOL APPL, V18, P613, DOI 10.1890/07-1280.1
   Vasconcelos M. J. P, 1998, P 14 C FIR MET, V0, P2111
   Veraverbeke S, 2018, REMOTE SENS ENVIRON, V216, P105, DOI 10.1016/j.rse.2018.06.020
   Vermote E, 2015, NASA EOSDIS LAND PRO, V0, P0, DOI DOI 10.5067/MODIS/MYD09GQ.006
   Wang TL, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0150717
   Wen J, 2004, MT RES DEV, V24, P348, DOI 10.1659/0276-4741(2004)024[0348:ROACVI]2.0.CO;2
   White JC, 2014, CAN J REMOTE SENS, V40, P192, DOI 10.1080/07038992.2014.945827
   Williams J, 2013, FOREST ECOL MANAG, V294, P4, DOI 10.1016/j.foreco.2012.06.030
   Wulder MA, 2019, REMOTE SENS ENVIRON, V225, P127, DOI 10.1016/j.rse.2019.02.015
   Wulder MA, 2018, INT J REMOTE SENS, V39, P4254, DOI 10.1080/01431161.2018.1452075
   Yu SZ, 2006, IEEE T SIGNAL PROCES, V54, P1947, DOI 10.1109/TSP.2006.872540
NR 72
TC 1
Z9 1
U1 1
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD SEP 15
PY 2021
VL 59
IS 9
BP 7338
EP 7352
DI 10.1109/TGRS.2020.3037160
PG 15
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology
GA UJ0EQ
UT WOS:000690968800020
DA 2023-04-26
ER

PT J
AU Monteiro, J
   Martins, B
   Costa, M
   Pires, JM
AF Monteiro, Joao
   Martins, Bruno
   Costa, Miguel
   Pires, Joao M.
TI Geospatial Data Disaggregation through Self-Trained Encoder-Decoder Convolutional Models
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE geospatial data disaggregation; dasymetric disaggregation; self-supervised learning; encoder-decoder neural networks; convolutional neural networks; deep learning
ID interpolation
AB Datasets collecting demographic and socio-economic statistics are widely available. Still, the data are often only released for highly aggregated geospatial areas, which can mask important local hotspots. When conducting spatial analysis, one often needs to disaggregate the source data, transforming the statistics reported for a set of source zones into values for a set of target zones, with a different geometry and a higher spatial resolution. This article reports on a novel dasymetric disaggregation method that uses encoder-decoder convolutional neural networks, similar to those adopted in image segmentation tasks, to combine different types of ancillary data. Model training constitutes a particular challenge. This is due to the fact that disaggregation tasks are ill-posed and do not entail the direct use of supervision signals in the form of training instances mapping low-resolution to high-resolution counts. We propose to address this problem through self-training. Our method iteratively refines initial estimates produced by disaggregation heuristics and training models with the estimates from previous iterations together with relevant regularization strategies. We conducted experiments related to the disaggregation of different variables collected for Continental Portugal into a raster grid with a resolution of 200 m. Results show that the proposed approach outperforms common alternative methods, including approaches that use other types of regression models to infer the dasymetric weights.
C1 [Monteiro, Joao; Martins, Bruno] Univ Lisbon, IST INESC ID, P-1049001 Lisbon, Portugal.
   [Costa, Miguel] Vodafone, P-1998017 Lisbon, Portugal.
   [Pires, Joao M.] Univ Nova Lisboa, FCT NOVA LINCS, P-2829526 Caparica, Portugal.
C3 INESC-ID; Universidade de Lisboa; Universidade Nova de Lisboa
RP Monteiro, J (corresponding author), Univ Lisbon, IST INESC ID, P-1049001 Lisbon, Portugal.
EM joao.miguel.monteiro@tecnico.ulisboa.pt; bruno.g.martins@tecnico.ulisboa.pt; miguel.costa2@vodafone.com; jmp@fct.unl.pt
FU Thales Portugal; Fundacao para a Ciencia e Tecnologia (FCT), under the MIMU project [PTDC/CCI-CIF/32607/2017]; PIDDAC program [UIDB/50021/2020]; Fundação para a Ciência e a Tecnologia [PTDC/CCI-CIF/32607/2017] Funding Source: FCT
CR [Anonymous], 2015, ARXIV, V0, P0
   Balk D., 2005, URBAN RE MOTE SENSIN, V0, P0
   Belagiannis V, 2015, IEEE I CONF COMP VIS, V0, PP2830, DOI 10.1109/ICCV.2015.324
   Briggs DJ, 2007, REMOTE SENS ENVIRON, V108, P451, DOI 10.1016/j.rse.2006.11.020
   Chen RX, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9110637
   Cheng ZF, 2022, INT J GEOGR INF SCI, V36, P1166, DOI 10.1080/13658816.2020.1854767
   Corbane C, 2017, BIG EARTH DATA, V1, P118, DOI 10.1080/20964471.2017.1397899
   DOXSEYWHITFIELD E, 2015, PAP APPL GEOGR, V0001, P0
   Florczyk AJ, 2016, IEEE J-STARS, V9, P1978, DOI 10.1109/JSTARS.2015.2485662
   Freire S., 2016, ASS GEOGRAPHIC INFOR, V0, P0
   Freire S, 2015, INT GEOSCI REMOTE SE, V0, PP2541, DOI 10.1109/IGARSS.2015.7326329
   Gallego FJ, 2010, POPUL ENVIRON, V31, P460, DOI 10.1007/s11111-010-0108-y
   Gaughan AE, 2015, INT J DIGIT EARTH, V8, P989, DOI 10.1080/17538947.2014.965761
   Gaughan AE, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0055882
   Goerlich FJ, 2013, INT J GEOGR INF SCI, V27, P2247, DOI 10.1080/13658816.2013.799283
   GOODCHILD MF, 1993, ENVIRON PLANN A, V25, P383, DOI 10.1068/a250383
   HEYMANN Y, 1994, CORINE LAND COVER TE, V0, P0
   Huang X, 2019, GEOHUMANITIES 2019: PROCEEDINGS OF THE 3RD ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON GEOSPATIAL HUMANITIES (GEOHUMANITIES 2019), V0, P0, DOI DOI 10.1145/3356991.3365469
   Jacobs N, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), V0, PP33, DOI 10.1145/3274895.3274934
   Kingma D. P., 2015, P 3 INT C LEARNING R, V0, P0
   Klemmer K., 2021, P ACM SIGSPATIAL INT, V0, P0
   Lanaras C, 2018, ISPRS J PHOTOGRAMM, V146, P305, DOI 10.1016/j.isprsjprs.2018.09.018
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Linard C, 2012, PLOS ONE, V7, P0, DOI 10.1371/journal.pone.0031743
   Malone BP, 2012, COMPUT GEOSCI-UK, V41, P119, DOI 10.1016/j.cageo.2011.08.021
   Martino P, 2016, OPERATING PROCEDURE, V0, P0
   Monteiro J, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8080327
   Monteiro J, 2018, INT J DATA SCI ANAL, V5, P189, DOI 10.1007/s41060-017-0080-z
   Peng ZH, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9060344
   Qiu G, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101618
   Qiu Y, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8080356
   Qizhe Xie, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP10684, DOI 10.1109/CVPR42600.2020.01070
   Robinson C, 2017, GEOHUMANITIES17: PROCEEDINGS OF THE 1ST ACM SIGSPATIAL WORKSHOP ON GEOSPATIAL HUMANITIES, V0, PP47, DOI 10.1145/3149858.3149863
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sapena M, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9070436
   Stevens FR, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0107042
   Tiecke T.G., 2017, MAPP WORLD POPUL ONE, V0, P0, DOI DOI 10.1596/33700
   Tin Kam Ho, 1995, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, V0, PP278, DOI 10.1109/ICDAR.1995.598994
   TOBLER WR, 1979, J AM STAT ASSOC, V74, P519, DOI 10.2307/2286968
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Zamir AR, 2017, PROC CVPR IEEE, V0, PP1808, DOI 10.1109/CVPR.2017.196
   Zhang C., 2011, ANN GIS, V17, P1, DOI 10.1080/19475683.2010.540258
   Zhao YC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212502
   Zhu D, 2020, INT J GEOGR INF SCI, V34, P735, DOI 10.1080/13658816.2019.1599122
NR 44
TC 0
Z9 0
U1 1
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD SEP 15
PY 2021
VL 10
IS 9
BP 
EP 
DI 10.3390/ijgi10090619
PG 28
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA UV9VR
UT WOS:000699817700001
DA 2023-04-26
ER

PT J
AU Kamran, KV
   Feizizadeh, B
   Khorrami, B
   Ebadi, Y
AF Kamran, Khalil Valizadeh
   Feizizadeh, Bakhtiar
   Khorrami, Behnam
   Ebadi, Yousef
TI A comparative approach of support vector machine kernel functions for GIS-based landslide susceptibility mapping
SO APPLIED GEOMATICS
LA English
DT Article
DE Landslide susceptibility mapping; Support vector machine; Kernel functions; GIS; Tabriz Basin
ID artificial neural-networks; logistic-regression; multicriteria decision; hierarchy process; frequency ratio; area; svm; prediction; selection; models
AB Landslides are among the most destructive natural hazards with severe socio-economic ramifications all around the world. Understanding the critical combination of geoenvironmental factors involved in the occurrence of landslides can mitigate the adverse impacts ascribed to them. Among the several scenarios for studying and investigating this phenomenon, landslide susceptibility mapping (LSM) is the most prominent method. Applying the machine learning (ML) algorithms integrated with the geographic information systems (GIS) has become a trending means for accurate and rapid landslide mapping practices in the scientific community. Support vector machine (SVM) has been the most commonly applied ML algorithm for LSM in recent years. The current study aims to implement different SVM kernel functions including polynomial kernel function (PKF) (degree 1 to 5), radial basis function (RBF), sigmoid, and linear kernels, for a GIS-based LSM over the Tabriz Basin (TB). To this end, a total number of 9 conditioning parameters being involved in the occurrence of the landslide events were determined and utilized. The LSM maps of the TB were generated based on the different SVM kernels and were statistically validated according to the landslide inventory. The findings revealed that the polynomial-degree-2 (PKF-2) model (AUC = 0.9688) outperforms the rest of the utilized kernels. According to the SLM map generated through PKF-2, the northernmost parts of the TB are extremely susceptible to slope failures than the rest; therefore, the developmental policies over these parts have to be taken into account with privileged priority to hinder any humanitarian as well as environmental catastrophes.
C1 [Kamran, Khalil Valizadeh; Feizizadeh, Bakhtiar; Ebadi, Yousef] Univ Tabriz, Dept Remote Sensing & GIS, Tabriz, Iran.
   [Feizizadeh, Bakhtiar] Humboldt Univ, Dept Geog, GISci Lab, Berlin, Germany.
   [Khorrami, Behnam] Dokus Eylul Univ, Grad Sch Nat & Appl Sci, Dept GIS, Izmir, Turkey.
C3 University of Tabriz; Humboldt University of Berlin; Dokuz Eylul University
RP Kamran, KV (corresponding author), Univ Tabriz, Dept Remote Sensing & GIS, Tabriz, Iran.
EM Valizadeh@tabrizu.ac.ir; feizizadeh@tabriz.ac.ir; behnam.khorrami@ogr.deu.edu.tr; yousef.ebadi1373@gmail.com
FU research center Tabriz of University
CR Abedi Gheshlaghi H., 2021, GIS BASED ENSEMBLE M, V0, P0, DOI DOI 10.1007/s11069-021-04673-1
   Akgun A, 2012, LANDSLIDES, V9, P93, DOI 10.1007/s10346-011-0283-7
   Alijane B., 2000, CLIMATOLOGY OF IRAN, V0, P0
   Alizadeh A, 2021, SN APPL SCI, V3, P0, DOI 10.1007/s42452-021-04535-2
   Bai SB., 2008, GEOPHY RES ABS, V10, P06367
   Bak M, 2009, ADV INTEL SOFT COMPU, V59, P399
   Ben-Hur A, 2010, METHODS MOL BIOL, V609, P223, DOI 10.1007/978-1-60327-241-4_13
   Pham BT, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11164386
   Pham BT, 2020, GEOCARTO INT, V35, P1267, DOI 10.1080/10106049.2018.1559885
   Pham BT, 2016, ENVIRON MODELL SOFTW, V84, P240, DOI 10.1016/j.envsoft.2016.07.005
   Campbell WM, 2006, INT CONF ACOUST SPEE, V0, P97
   CHEN W, 2018, B ENG GEOL ENVIRON, V77, P0
   Chen W, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-5093-0
   Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2
   Conoscenti C, 2014, GEOMORPHOLOGY, V204, P399, DOI 10.1016/j.geomorph.2013.08.021
   Constantin M, 2011, ENVIRON EARTH SCI, V63, P397, DOI 10.1007/s12665-010-0724-y
   Corominas J, 2005, LANDSLIDES, V2, P83, DOI 10.1007/s10346-005-0049-1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cristianini N, 2000, INTRO SUPPORT VECTOR, V0, P0
   Crosta GB, 2002, PHYS CHEM EARTH, V27, P1557, DOI 10.1016/S1474-7065(02)00177-8
   Dai FC, 2001, ENVIRON GEOL, V40, P381, DOI 10.1007/s002540000163
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Ercanoglu M, 2004, ENG GEOL, V75, P229, DOI 10.1016/j.enggeo.2004.06.001
   Fan Jerome, 2006, CJEM, V8, P19
   Feizizadeh B., 2011, J EARTH SCI ENG, V1, P66
   FEIZIZADEH B, 2021, SCI TOTAL ENV, V0, P0
   Feizizadeh B, 2012, GIS BASED PROCEDURES, V0, P0
   Feizizadeh B, 2021, CATENA, V207, P0, DOI 10.1016/j.catena.2021.105585
   Feizizadeh B, 2021, CATENA, V198, P0, DOI 10.1016/j.catena.2020.105073
   Feizizadeh B, 2018, IEEE GEOSCI REMOTE S, V15, P18, DOI 10.1109/LGRS.2017.2763979
   Feizizadeh B, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2918-z
   Feizizadeh B, 2013, NAT HAZARDS, V65, P2105, DOI 10.1007/s11069-012-0463-3
   Feng XT, 2004, INT J ROCK MECH MIN, V41, P1087, DOI 10.1016/j.ijrmms.2004.04.003
   Gao, 2006, COMPUT METHODS ENG S, V0, PP275, DOI 10.1109/AEMCSE50948.2020.00056
   Garajeh MK, 2021, SCI TOTAL ENVIRON, V778, P0, DOI 10.1016/j.scitotenv.2021.146253
   Gomez H, 2005, ENG GEOL, V78, P11, DOI 10.1016/j.enggeo.2004.10.004
   Gunn S. R., 1998, ISIS TECHNICAL REPOR, V14, P5, DOI 10.1039/B918972F
   Helmstetter A, 2004, J GEOPHYS RES-SOL EA, V109, P0, DOI 10.1029/2002JB002160
   Hong HY, 2017, GEOMAT NAT HAZ RISK, V8, P544, DOI 10.1080/19475705.2016.1250112
   Hong HY, 2015, CATENA, V133, P266, DOI 10.1016/j.catena.2015.05.019
   Hong Y, 2006, GEOPHYS RES LETT, V33, P0, DOI 10.1029/2006GL028010
   Hsu C.H., 2010, PRACTICAL GUIDE SUPP, V0, P1
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Kalantar B, 2018, GEOMAT NAT HAZ RISK, V9, P49, DOI 10.1080/19475705.2017.1407368
   Karimzadeh S, 2016, ACTA GEOD GEOPHYS, V51, P181, DOI 10.1007/s40328-015-0118-4
   Kavzoglu T, 2014, LANDSLIDES, V11, P425, DOI 10.1007/s10346-013-0391-7
   Li CD, 2014, STOCH ENV RES RISK A, V28, P1465, DOI 10.1007/s00477-014-0848-9
   Li XZ, 2014, NAT HAZARD EARTH SYS, V14, P525, DOI 10.5194/nhess-14-525-2014
   Ma JS, 2003, NEURAL COMPUT, V15, P2683, DOI 10.1162/089976603322385117
   Melchiorre C, 2011, COMPUT GEOSCI-UK, V37, P410, DOI 10.1016/j.cageo.2010.10.004
   Mihalic S., 2011, P 15 EUR C SOIL MECH, V0, P1377
   Moradi AS, 2011, TECTONOPHYSICS, V506, P22, DOI 10.1016/j.tecto.2011.04.008
   Hoang ND, 2016, APPL SOFT COMPUT, V45, P173, DOI 10.1016/j.asoc.2016.04.031
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Nohani E, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11071402
   Park S, 2013, ENVIRON EARTH SCI, V68, P1443, DOI 10.1007/s12665-012-1842-5
   Galve JP, 2015, LANDSLIDES, V12, P101, DOI 10.1007/s10346-014-0478-9
   Peethambaran B, 2020, CATENA, V195, P0, DOI 10.1016/j.catena.2020.104751
   Peethambaran B, 2019, NAT HAZARDS, V96, P121, DOI 10.1007/s11069-018-3532-4
   Peethambaran B, 2019, ENVIRON EARTH SCI, V78, P0, DOI 10.1007/s12665-019-8225-0
   Polemio M, 2010, Q J ENG GEOL HYDROGE, V43, P403, DOI 10.1144/1470-9236/09-006
   Pourghasemi HR, 2012, NAT HAZARDS, V63, P965, DOI 10.1007/s11069-012-0217-2
   Pradhan B, 2013, COMPUT GEOSCI-UK, V51, P350, DOI 10.1016/j.cageo.2012.08.023
   Samui P, 2008, ENVIRON GEOL, V56, P255, DOI 10.1007/s00254-007-1161-4
   Shirzadi A, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113777
   Singh SK, 2018, J ENVIRON MANAGE, V211, P125, DOI 10.1016/j.jenvman.2018.01.044
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Solaimani K, 2013, ARAB J GEOSCI, V6, P2557, DOI 10.1007/s12517-012-0526-5
   Sornette D, 2004, PHYSICA A, V338, P605, DOI 10.1016/j.physa.2004.02.065
   Sujatha ER, 2012, J EARTH SYST SCI, V121, P1337, DOI 10.1007/s12040-012-0230-6
   SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615
   Ting-ting Dai, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON ADVANCED ELECTRONIC MATERIALS, V0, P230, DOI 10.1109/AEMCSE50948.2020.00056
   Phong TV, 2021, GEOCARTO INT, V36, P1685, DOI 10.1080/10106049.2019.1665715
   Vapnik VN, 1998, STAT LEARNING THEORY, V0, P0
   Wang XY, 2003, SECOND IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, V0, P55
   Xu C, 2012, GEOMORPHOLOGY, V145, P70, DOI 10.1016/j.geomorph.2011.12.040
   Yan G, 2019, GEOCARTO INT, V34, P1408, DOI 10.1080/10106049.2018.1499816
   Yilmaz I, 2010, ENVIRON EARTH SCI, V61, P821, DOI 10.1007/s12665-009-0394-9
   Youssef AM, 2015, ENVIRON EARTH SCI, V73, P3745, DOI 10.1007/s12665-014-3661-3
   ZHAO S, 2021, MATH PROBL ENG, V0, P0
NR 80
TC 12
Z9 12
U1 2
U2 6
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1866-9298
EI 1866-928X
J9 APPL GEOMAT
JI Appl. Geomat.
PD DEC 15
PY 2021
VL 13
IS 4
BP 837
EP 851
DI 10.1007/s12518-021-00393-0
EA AUG 2021
PG 15
WC Remote Sensing
SC Remote Sensing
GA XA5EZ
UT WOS:000690722200001
DA 2023-04-26
ER

PT J
AU Lundine, MA
   Trembanis, AC
AF Lundine, Mark A.
   Trembanis, Arthur C.
TI Using Convolutional Neural Networks for Detection and Morphometric Analysis of Carolina Bays from Publicly Available Digital Elevation Modelss
SO REMOTE SENSING
LA English
DT Article
DE Faster R-CNN; Mask R-CNN; object detection; Atlantic Coastal Plain; k-means classifier; multi-scale detection; digital elevation model
ID coastal-plain; land-use; classification; evolution; kansas; permafrost; area
AB Carolina Bays are oriented and sandy-rimmed depressions that are ubiquitous throughout the Atlantic Coastal Plain (ACP). Their origin has been a highly debated topic since the 1800s and remains unsolved. Past population estimates of Carolina Bays have varied vastly, ranging between as few as 10,000 to as many as 500,000. With such a large uncertainty around the actual population size, mapping these enigmatic features is a problem that requires an automated detection scheme. Using publicly available LiDAR-derived digital elevation models (DEMs) of the ACP as training images, various types of convolutional neural networks (CNNs) were trained to detect Carolina bays. The detection results were assessed for accuracy and scalability, as well as analyzed for various morphologic, land-use and land cover, and hydrologic characteristics. Overall, the detector found over 23,000 Carolina Bays from southern New Jersey to northern Florida, with highest densities along interfluves. Carolina Bays in Delmarva were found to be smaller and shallower than Bays in the southeastern ACP. At least a third of Carolina Bays have been converted to agricultural lands and almost half of all Carolina Bays are forested. Few Carolina Bays are classified as open water basins, yet almost all of the detected Bays were within 2 km of a water body. In addition, field investigations based upon detection results were performed to describe the sedimentology of Carolina Bays. Sedimentological investigations showed that Bays typically have 1.5 m to 2.5 m thick sand rims that show a gradient in texture, with coarser sand at the bottom and finer sand and silt towards the top. Their basins were found to be 0.5 m to 2 m thick and showed a mix of clayey, silty, and sandy deposits. Last, the results compiled during this study were compared to similar depressional features (i.e., playa-lunette systems) to pinpoint any similarities in origin processes. Altogether, this study shows that CNNs are valuable tools for automated geomorphic feature detection and can lead to new insights when coupled with various forms of remotely sensed and field-based datasets.
C1 [Lundine, Mark A.; Trembanis, Arthur C.] Univ Delaware, Sch Marine Sci & Policy, Lewes, DE 19958 USA.
C3 University of Delaware
RP Lundine, MA (corresponding author), Univ Delaware, Sch Marine Sci & Policy, Lewes, DE 19958 USA.
EM mlundine@udel.edu; art@udel.edu
FU Unidel Foundation Graduate Fellowship; Geological Society of America Graduate Student Research Grant
CR Bochkovskiy A, 2020, PREPRINT, V0, P0
   Bonhage A, 2021, ARCHAEOL PROSPECT, V28, P177, DOI 10.1002/arp.1806
   Bowen M.W., 2011, THESIS U KANSAS LAWR, V0, P0
   Bowen MW, 2018, PHYS GEOGR, V39, P21, DOI 10.1080/02723646.2017.1319683
   Bowen MW, 2012, GEOL SOC AM BULL, V124, P146, DOI 10.1130/B30382.1
   Bowen MW, 2010, WETLANDS, V30, P675, DOI 10.1007/s13157-010-0077-z
   Brooks M.J., 2001, SOUTHEAST GEOL, V40, P241
   Brooks M.J., 1996, GEOARCHAEOLOGY, V11, P481, DOI 3.0.CO;2-4
   Brooks M.J., 2010, SE ARCHAEOLOGY, V29, P146, DOI 10.1179/SEA.2010.29.1.010
   Campagnolo ML, 2007, PROC MONOGR ENG WATE, V0, P123
   CARVER RE, 1989, PALAEOGEOGR PALAEOCL, V74, P205, DOI 10.1016/0031-0182(89)90061-8
   Chen Z., 2021, P IEEE RSJ INT C INT, V0, P1276
   Cooke C.W., 1934, J GEOL, V42, P88, DOI 10.1086/624133
   de Jong SM., 2001, INT J APPL EARTH OBS, V3), P176, DOI 10.1016/S0303
   Eyton J.R., 1975, REEVALUATION EXTRATE, V0, P0
   Fenstermacher DE, 2014, WETLANDS, V34, P1219, DOI 10.1007/s13157-014-0583-5
   Fenstermacher D.E., 2012, THESIS U MARYLAND CO, V0, P0
   Firestone RB, 2007, P NATL ACAD SCI USA, V104, P16016, DOI 10.1073/pnas.0706977104
   French HM, 2014, BOREAS, V43, P667, DOI 10.1111/bor.12036
   Gao Y., 2008, ONLINE J EARTH SCI, V2, P27
   Gevana D, 2015, FOR SCI TECHNOL, V11, P197, DOI 10.1080/21580103.2014.996611
   Glenn L C, 1895, SCIENCE, V2, P472, DOI 10.1126/science.2.41.472
   Goudie A., 2016, DESERT, V21, P1
   Guo W, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010131
   He KL, 2019, IEEE T MED IMAGING, V38, P585, DOI 10.1109/TMI.2018.2867837
   Hou FF, 2021, AUTOMAT CONSTR, V121, P0, DOI 10.1016/j.autcon.2020.103414
   Howell N, 2016, BIODIVERS DATA J, V4, P0, DOI 10.3897/BDJ.4.e7964
   Hussey T., 1993, THESIS U MAINE ORONO, V0, P0
   Ivester A.H., 2007, GEOL SOC AM ABSTR PR, V39, P5
   Ivester A.H., 2009, S CAROL ANTIQ, V41, P1
   Johnson D, 1937, SCIENCE, V86, P255, DOI 10.1126/science.86.2229.255
   Johnson D.W., 1942, ORIGIN CAROLINA BAYS, V0, P0
   Kaczorowski R.T., 1976, ORIGIN CAROLINA BAYS, V0, P0
   Kaczorowski R.T., 1977, THESIS U S CAROLINA, V0, P0
   Kauffman G.J, 2018, SOCIOECONOMIC VALUE, V0, P0
   Lindgren A, 2016, PERMAFROST PERIGLAC, V27, P6, DOI 10.1002/ppp.1851
   Markewich HW, 2015, AEOLIAN RES, V17, P139, DOI 10.1016/j.aeolia.2015.01.011
   Maxwell AE, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030547
   Melton FA, 1933, J GEOL, V41, P52, DOI 10.1086/624004
   Moore C. R., 2016, SOUTHEAST GEOL, V51, P145
   OMahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Otukei JR, 2010, INT J APPL EARTH OBS, V12, PS27, DOI 10.1016/j.jag.2009.11.002
   Piovan SE, 2017, CARTOGR GEOGR INF SC, V44, P310, DOI 10.1080/15230406.2016.1162670
   PROUTY WF, 1952, GEOL SOC AM BULL, V63, P167, DOI 10.1130/0016-7606(1952)63[167:CBATO]2.0.CO;2
   Quillin J.P., 2005, TEX J AGRIC NAT RESO, V18, P1
   Ramsey K.W, 1996, RADIOCARBON DATES DE, V0, P1
   Rasmussen C, 2017, IEEE INT CONF COMP V, V0, PP2865, DOI 10.1109/ICCVW.2017.338
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Richardson Curtis J., 1993, P257, V0, P0
   Rodriguez AB, 2012, QUATERNARY RES, V77, P171, DOI 10.1016/j.yqres.2011.11.004
   Sekovski I, 2014, INT J REMOTE SENS, V35, P3556, DOI 10.1080/01431161.2014.907939
   Semlitsch R., 2000, NATL WETL NEWSL, V22, P5
   Smith LL, 1931, J GEOL, V39, P641, DOI 10.1086/623891
   Spadafora E, 2016, RESTOR ECOL, V24, P463, DOI 10.1111/rec.12352
   Stopar JD, 2017, ICARUS, V298, P34, DOI 10.1016/j.icarus.2017.05.022
   Sun SJ, 2018, ICARUS, V309, P61, DOI 10.1016/j.icarus.2018.02.031
   Swezey C.S., 2020, INLAND DUNES N AM DU, V0, P0
   THOM BG, 1970, GEOL SOC AM BULL, V81, P783, DOI 10.1130/0016-7606(1970)81[783:CBIHAM]2.0.CO;2
   Tomlinson J.L., 2014, P 49 ANN M NE SECT G, V0, P0
   Tuomey M., 1848, REPORT GEOLOGY S CAR, V0, P0
   U.S. Environmental Protection Agency and U.S. Army Corps of Engineers, 2020, NAV WAT PROT RUL DEF, V0, P0
   U.S. Environmental Protection Agency and U.S. Army Corps of Engineers, 2015, CLEAN WAT RUL DEF WA, V0, P0
   U.S. Geological Survey Gap Analysis Program, 2016, GAP LANDFIRE NAT TER, V0, P0
   Van De Genachte E., 2002, CAR BAYS GEORG THEIR, V0, P0
   Van de Voorde T., 2003, P 23 S EUR ASS REM S, V0, P237
   WATTS WA, 1980, QUATERNARY RES, V13, P187, DOI 10.1016/0033-5894(80)90028-9
   Weih R., 2010, INT ARCH PHOTOGRAMME, V38, P0
   White MP, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-44097-3
   Zamora A, 2017, GEOMORPHOLOGY, V282, P209, DOI 10.1016/j.geomorph.2017.01.019
   Zhang WX, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091487
NR 78
TC 0
Z9 0
U1 1
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2021
VL 13
IS 18
BP 
EP 
DI 10.3390/rs13183770
PG 27
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UZ3HC
UT WOS:000702098400001
DA 2023-04-26
ER

PT J
AU Dey, S
   Chaudhuri, U
   Bhogapurapu, N
   Lopez-Sanchez, JM
   Banerjee, B
   Bhattacharya, A
   Mandal, D
   Rao, YS
AF Dey, Subhadip
   Chaudhuri, Ushasi
   Bhogapurapu, Narayanarao
   Lopez-Sanchez, Juan M.
   Banerjee, Biplab
   Bhattacharya, Avik
   Mandal, Dipankar
   Rao, Yalamanchili Subrahmanyeswara
TI Synergistic Use of TanDEM-X and Landsat-8 Data for Crop-Type Classification and Monitoring
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Agriculture; classification; crop-type mapping; Landsat-8; phenology; TanDEM-X
ID time-series; sar; polarization; fusion
AB Classification of crop types using Earth Observation (EO) data is a challenging task. The challenge increases many folds when we have diverse crops within a resolution cell. In this regard, optical and Synthetic Aperture Radar (SAR) data provide complementary information to characterize a target. Therefore, we propose to leverage the synergy between multispectral and Synthetic Aperture Radar (SAR) data for crop classification. We aim to use the newly developed model-free three-component scattering power components to quantify changes in scattering mechanisms at different phenological stages. By incorporating interferometric coherence information, we consider the morphological characteristics of the crops that are not available with only polarimetric information. We also utilize the reflectance values from Landsat-8 spectral hands as complementary biochemical information of crops. The classification accuracy is enhanced by using these two pieces of information combined using a neural network-based architecture with an attention mechanism. We utilize the time series dual co-polarimetric (i.e., HH-VV) TanDEM-X SAR data and the multispectral Landsat-8 data acquired over an agricultural area in Seville, Spain. The use of the proposed attention mechanism for fusing SAR and optical data shows a significant improvement in classification accuracy by 6.0% to 9.0% as compared to the sole use of either the optical or SAR data. Besides, we also demonstrate that the utilization of single-pass interferometric coherence maps in the fusion framework enhances the overall classification accuracy by approximate to 3.0%. Therefore, the proposed synergistic approach will facilitate accurate and robust crop mapping with high-resolution EO data at larger scales.
C1 [Dey, Subhadip; Chaudhuri, Ushasi; Bhogapurapu, Narayanarao; Banerjee, Biplab; Bhattacharya, Avik; Mandal, Dipankar; Rao, Yalamanchili Subrahmanyeswara] Indian Inst Technol, Microwave Remote Sensing Lab, Ctr Studies Resources Engn, Mumbai 400076, Maharashtra, India.
   [Lopez-Sanchez, Juan M.] Univ Alicante, Inst Comp Res IUII, E-03080 Alicante, Spain.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay; Universitat d'Alacant
RP Bhattacharya, A (corresponding author), Indian Inst Technol, Microwave Remote Sensing Lab, Ctr Studies Resources Engn, Mumbai 400076, Maharashtra, India.
EM subhadipdey23071994@gmail.com; ushasi2cool@gmail.com; narayanarao.bhogapurapu@gmail.com; juanma-lopez@ieee.org; getbiplab@gmail.com; avikb@csre.iitb.ac.in; dipankar.agrilengg@gmail.com; ysrao@csre.iitb.ac.in
FU German Aerospace Center (DLR) [POLI6736]; State Research Agency (AEI); Spanish Ministry of Science and Innovation; EU EFDR funds [TEC2017-85244-C2-1-P]; Ministry of Education, Government of India
CR BARAKAT R, 1977, OPT COMMUN, V23, P147, DOI 10.1016/0030-4018(77)90292-9
   Bargiel D, 2011, REMOTE SENS-BASEL, V3, P859, DOI 10.3390/rs3050859
   Bhogapurapu N., 1900, V6, V0, P2021
   Blaes X, 2005, REMOTE SENS ENVIRON, V96, P352, DOI 10.1016/j.rse.2005.03.010
   Brisco B., 1989, CANADIAN J REMOTE SE, V15, P44
   Busquier M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111774
   Busquier M, 2020, IEEE GEOSCI REMOTE S, V17, P819, DOI 10.1109/LGRS.2019.2933738
   Dey S, 2021, INT J REMOTE SENS, V42, P5519, DOI 10.1080/01431161.2021.1921876
   Dey S, 2021, IEEE T GEOSCI REMOTE, V59, P3981, DOI 10.1109/TGRS.2020.3010840
   Dey S, 2021, IEEE J-STARS, V14, P3887, DOI 10.1109/JSTARS.2021.3069299
   Fukui H, 2019, PROC CVPR IEEE, V0, PP10697, DOI 10.1109/CVPR.2019.01096
   Gallardo JF, 2015, THE SOILS OF SPAIN, V0, P0
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Hong G, 2011, CAN J REMOTE SENS, V37, P45, DOI 10.5589/m11-026
   Hutt C, 2018, EUR J REMOTE SENS, V51, P62, DOI 10.1080/22797254.2017.1401909
   Inglada J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050362
   Kussul N, 2016, IEEE J-STARS, V9, P2500, DOI 10.1109/JSTARS.2016.2560141
   Martone M, 2016, IEEE GEOSCI REMOTE S, V13, P1812, DOI 10.1109/LGRS.2016.2614103
   McNairn H, 2009, ISPRS J PHOTOGRAMM, V64, P434, DOI 10.1016/j.isprsjprs.2008.07.006
   Mirzaee S, 2014, INT ARCH PHOTOGRAMM, V40, P191, DOI 10.5194/isprsarchives-XL-2-W3-191-2014
   Park S, 2016, INT ARCH PHOTOGRAMM, V41, P703, DOI 10.5194/isprsarchives-XLI-B7-703-2016
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Qi JG, 2003, P SOC PHOTO-OPT INS, V5153, P153
   Sandholt I., 2001, GEOGRAFISK TIDSSKRIF, V101, P21, DOI 10.1080/00167223.2001.10649448
   Sheoran A, 2013, GISCI REMOTE SENS, V50, P50, DOI 10.1080/15481603.2013.778555
   Skakun S, 2016, IEEE J-STARS, V9, P3712, DOI 10.1109/JSTARS.2015.2454297
   Sonobe R, 2015, PHYS CHEM EARTH, V83-84, P2, DOI 10.1016/j.pce.2014.11.001
   Sonobe R, 2014, REMOTE SENS LETT, V5, P157, DOI 10.1080/2150704X.2014.889863
   Torbick N, 2011, CAN J REMOTE SENS, V37, P17, DOI 10.5589/m11-020
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang GG, 2013, SCI WORLD J, V0, P0, DOI DOI 10.1155/2013/632437
   Wang LL, 2008, INT J REMOTE SENS, V29, P7065, DOI 10.1080/01431160802226034
NR 32
TC 4
Z9 4
U1 4
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 8744
EP 8760
DI 10.1109/JSTARS.2021.3103911
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UR3RU
UT WOS:000696669900001
DA 2023-04-26
ER

PT J
AU Chen, ST
   Wu, CQ
   Mukherjee, M
   Zheng, YJ
AF Chen, Suting
   Wu, Chaoqun
   Mukherjee, Mithun
   Zheng, Yujie
TI HA-MPPNet: Height Aware-Multi Path Parallel Network for High Spatial Resolution Remote Sensing Image Semantic Seg-Mentation
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE remote sensing image; semantic segmentation; high spatial resolution; gated feature fusion; digital surface model (DSM); height features
ID segmentation; classification
AB Semantic segmentation of remote sensing images (RSI) plays a significant role in urban management and land cover classification. Due to the richer spatial information in the RSI, existing convolutional neural network (CNN)-based methods cannot segment images accurately and lose some edge information of objects. In addition, recent studies have shown that leveraging additional 3D geometric data with 2D appearance is beneficial to distinguish the pixels' category. However, most of them require height maps as additional inputs, which severely limits their applications. To alleviate the above issues, we propose a height aware-multi path parallel network (HA-MPPNet). Our proposed MPPNet first obtains multi-level semantic features while maintaining the spatial resolution in each path for preserving detailed image information. Afterward, gated high-low level feature fusion is utilized to complement the lack of low-level semantics. Then, we designed the height feature decode branch to learn the height features under the supervision of digital surface model (DSM) images and used the learned embeddings to improve semantic context by height feature guide propagation. Note that our module does not need a DSM image as additional input after training and is end-to-end. Our method outperformed other state-of-the-art methods for semantic segmentation on publicly available remote sensing image datasets.
C1 [Chen, Suting; Wu, Chaoqun] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Chen, Suting] Nanjing Univ Informat Sci & Technol, Wuxi Inst Technol NUIST WIT, Wuxi 214100, Jiangsu, Peoples R China.
   [Mukherjee, Mithun] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing 210044, Peoples R China.
   [Zheng, Yujie] 28th Res Inst China Elect Technology Grp Corp, Nanjing 210008, Peoples R China.
C3 Nanjing University of Information Science & Technology; Wuxi University; Nanjing University of Information Science & Technology; China Electronics Technology Group
RP Chen, ST (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.; Chen, ST (corresponding author), Nanjing Univ Informat Sci & Technol, Wuxi Inst Technol NUIST WIT, Wuxi 214100, Jiangsu, Peoples R China.
EM sutingchen@nuist.edu; mithun@nuist.edu.cn; zhengyujie@cetc.com.cn
FU National Natural Science Foundation of China [61906097, 41875184]; Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD)
CR Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen L. C., 2014, COMPUT SCI, V4, P357
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Damos MA, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10080530
   Dauphin YN, 2017, PR MACH LEARN RES, V70, P0
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Ding C, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10040245
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Ghamisi P, 2018, IEEE GEOSCI REMOTE S, V15, P794, DOI 10.1109/LGRS.2018.2806945
   Guo R, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7030110
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hong DF, 2021, IEEE T CYBERNETICS, V51, P3602, DOI 10.1109/TCYB.2020.3028931
   Hu B, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10080533
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang ZL, 2019, IEEE I CONF COMP VIS, V0, PP603, DOI 10.1109/ICCV.2019.00069
   Jiang J, 2020, INT J REMOTE SENS, V41, P487, DOI 10.1080/01431161.2019.1643937
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, V0, PP680, DOI 10.1109/CVPRW.2016.90
   Li HF, 2021, IEEE GEOSCI REMOTE S, V18, P905, DOI 10.1109/LGRS.2020.2988294
   Li XT, 2020, AAAI CONF ARTIF INTE, V34, P11418
   Lichao M., 2018, ARXIV180210249, V0, P0
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu S, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10030170
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Niu RG, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3065112
   Peng Y., 2020, 2020 6 INT C BIG DAT, V0, P0, DOI DOI 10.1109/BigDIA51454.2020.00031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Srivastava S, 2017, INT GEOSCI REMOTE SE, V0, P5173
   Sun S., 2018, P 2018 10 IAPR WORKS, V0, P0, DOI DOI 10.1109/PRRS.2018.8486170
   Takikawa T, 2019, IEEE I CONF COMP VIS, V0, PP5228, DOI 10.1109/ICCV.2019.00533
   Tao A., 2020, ARXIV, V0, P0
   Volpi M, 2018, ISPRS J PHOTOGRAMM, V144, P48, DOI 10.1016/j.isprsjprs.2018.06.007
   Wang JC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11131617
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang P, 2015, PROC CVPR IEEE, V0, PP2800, DOI 10.1109/CVPR.2015.7298897
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wurm M, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10010023
   Xie FD, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7070284
   Yang MK, 2018, PROC CVPR IEEE, V0, PP3684, DOI 10.1109/CVPR.2018.00388
   Zhang Z., 2018, P EUROPEAN C COMPUTE, V0, P269
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
NR 45
TC 0
Z9 0
U1 7
U2 19
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD OCT 15
PY 2021
VL 10
IS 10
BP 
EP 
DI 10.3390/ijgi10100672
PG 18
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA WN2VH
UT WOS:000711631000001
DA 2023-04-26
ER

PT J
AU Concepcion, L
   Napoles, G
   Falcon, R
   Vanhoof, K
   Bello, R
AF Concepcion, Leonardo
   Napoles, Gonzalo
   Falcon, Rafael
   Vanhoof, Koen
   Bello, Rafael
TI Unveiling the Dynamic Behavior of Fuzzy Cognitive Maps
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Neurons; Transfer functions; Biological system modeling; Mathematical model; Numerical models; Fuzzy cognitive maps; Recurrent neural networks; Fuzzy cognitive maps; nonlinear systems; recurrent neural networks; shrinking state spaces
ID adaptive estimation; convergence
AB Fuzzy cognitive maps (FCMs) are recurrent neural networks comprised of well-defined concepts and causal relations. While the literature about real-world FCM applications is prolific, the studies devoted to understanding the foundations behind these neural networks are rather scant. In this article, we introduce several definitions and theorems that unveil the dynamic behavior of FCM-based models equipped with transfer F-functions. These analytical expressions allow estimating bounds for the activation value of each neuron and analyzing the covering and proximity of feasible activation spaces. The main theoretical findings suggest that the state space of any FCM model equipped with transfer F-functions shrinks infinitely with no guarantee for the FCM to converge to a fixed point but to its limit state space. This result in conjunction with the covering and proximity values of FCM-based models helps understand their poor performance when solving complex simulation problems.
C1 [Concepcion, Leonardo; Bello, Rafael] Univ Cent Las Villas, Dept Comp Sci, Santa Clara 54830, Cuba.
   [Napoles, Gonzalo; Vanhoof, Koen] Hasselt Univ, Fac Business Econ, B-3500 Hasselt, Belgium.
   [Napoles, Gonzalo] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, NL-5037 Tilburg, Netherlands.
   [Falcon, Rafael] Shopify Inc, Data Sci & Engn Div, Ottawa, ON K2P 1L4, Canada.
   [Falcon, Rafael] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada.
C3 Universidad Central "Marta Abreu" de Las Villas; Hasselt University; Tilburg University; Shopify Inc.; University of Ottawa
RP Napoles, G (corresponding author), Hasselt Univ, Fac Business Econ, B-3500 Hasselt, Belgium.
EM lcperez@uclv.cu; gonzalo.napoles@uhasselt.be; rfalcon@ieee.org; koen.vanhoof@uhasselt.be; rbellop@uclv.edu.cu
CR Binmore K.G., 1977, MATH ANAL STRAIGHTFO, V0, P0
   Boutalis Y, 2009, IEEE T FUZZY SYST, V17, P874, DOI 10.1109/TFUZZ.2009.2017519
   Bueno S, 2009, EXPERT SYST APPL, V36, P5221, DOI 10.1016/j.eswa.2008.06.072
   Felix G, 2019, ARTIF INTELL REV, V52, P1707, DOI 10.1007/s10462-017-9575-1
   Froelich W, 2017, NEUROCOMPUTING, V232, P1, DOI 10.1016/j.neucom.2016.11.058
   Froelich W, 2017, KNOWL-BASED SYST, V115, P110, DOI 10.1016/j.knosys.2016.10.017
   Harmati IA, 2018, COMM COM INF SC, V853, P490, DOI 10.1007/978-3-319-91473-2_42
   Homenda W, 2017, NEUROCOMPUTING, V232, P3, DOI 10.1016/j.neucom.2016.08.119
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Kosko B., 1988, INTERNATIONAL JOURNAL OF APPROXIMATE REASONING, V2, P377, DOI 10.1016/0888-613X(88)90111-9
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kottas T, 2012, APPL SOFT COMPUT, V12, P3736, DOI 10.1016/j.asoc.2012.01.025
   Napoles G, 2018, IEEE T FUZZY SYST, V26, P2479, DOI 10.1109/TFUZZ.2017.2768327
   Napoles G, 2017, NEURAL PROCESS LETT, V45, P431, DOI 10.1007/s11063-016-9534-x
   Napoles G, 2016, INFORM SCIENCES, V349, P154, DOI 10.1016/j.ins.2016.02.040
   Napoles G, 2014, INTELL DATA ANAL, V18, PS77, DOI 10.3233/IDA-140710
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Salmeron JL, 2019, KNOWL-BASED SYST, V163, P723, DOI 10.1016/j.knosys.2018.09.034
   Tsadiras AK, 2008, INFORM SCIENCES, V178, P3880, DOI 10.1016/j.ins.2008.05.015
   Wu K, 2017, IEEE T FUZZY SYST, V25, P1546, DOI 10.1109/TFUZZ.2017.2741444
   Yang Z, 2019, APPL SOFT COMPUT, V74, P356, DOI 10.1016/j.asoc.2018.10.038
   Zhang L, 1999, IEEE T NEURAL NETWOR, V10, P925, DOI 10.1109/72.774263
NR 22
TC 5
Z9 5
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD MAY 15
PY 2021
VL 29
IS 5
BP 1252
EP 1261
DI 10.1109/TFUZZ.2020.2973853
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA RZ1BM
UT WOS:000648333700025
DA 2023-04-26
ER

PT J
AU Zhou, YM
   Wei, T
   Zhu, XL
   Collin, M
AF Zhou, Yimin
   Wei, Tao
   Zhu, Xiaolin
   Collin, Melissa
TI A Parcel-Based Deep-Learning Classification to Map Local Climate Zones From Sentinel-2 Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Buildings; Training; Roads; Meteorology; Urban areas; Shape; Image segmentation; Classification; deep learning; local climate zone (LCZ); parcel; sentinel-2
ID urban; wudapt; cnn
AB Local climate zones (LCZ) describe urban surface structures, supporting studies of urban heat islands, sustainable urbanization, and energy balance. The existing studies mapped LCZs from satellite images using scene-based classification, which trained deep-learning classifiers by labeled image patches, segmented satellite images into patches by sliding windows to match the size of training data, and finally classified the segmented patches to obtain LCZ maps. However, sliding windows are different from the real footprints of LCZs, which leads to large errors in classification. To address this problem, this article proposes a parcel-based method for LCZ classification using Sentinel-2 images, road networks, and elevation data. First, the Sentinel-2 images are segmented by the road network to obtain the land parcels as classification units. Second, each image parcel is standardized to match the training dataset, So2Sat LCZ42. Third, the trained convolutional neural network (CNN) is used to classify the standardized parcels into LCZs. Finally, the building height information derived from elevation data is used to refine the LCZs by a rule-based classifier. The results of the four test sites show that the overall accuracy of our method is 0.75, higher than the sliding-window-based method's accuracy of 0.47. Additional simulation experiments demonstrated that parcels derived from road networks can reduce the mixture effect in image patches, and parcel standardization can ensure the transferability of the CNN model trained by regular image patches. Considering that the road network and elevation data are widely available, the proposed method has the potential of mapping LCZs in large areas.
C1 [Zhou, Yimin; Wei, Tao] Shenzhen Univ, Sch Psychol, Shenzhen 518060, Peoples R China.
   [Zhou, Yimin; Zhu, Xiaolin] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong 999077, Peoples R China.
   [Zhu, Xiaolin] Hong Kong Polytech Univ, Res Inst Sustainable Urban Dev, Hong Kong 999077, Peoples R China.
   [Collin, Melissa] Humboldt State Univ, Dept Environm Sci & Management, Arcata, CA 95521 USA.
C3 Shenzhen University; Hong Kong Polytechnic University; Hong Kong Polytechnic University; California State University System; California State Polytechnic University, Humboldt
RP Wei, T (corresponding author), Shenzhen Univ, Sch Psychol, Shenzhen 518060, Peoples R China.
EM pmyimin.zhou@polyu.edu.hk; taowei@bnu.edu.cn; xiaolin.zhu@polyu.edu.hk; melissa.collin@humboldt.edu
FU Shenzhen Peacock Plan [000517]; National Natural Science Foundation of China [31700999]; Research Institute for Sustainable Urban Development, the Hong Kong Polytechnic University, under Project BBWD
CR Bechtel B, 2015, ISPRS INT J GEO-INF, V4, P199, DOI 10.3390/ijgi4010199
   Brousse O, 2016, URBAN CLIM, V17, P116, DOI 10.1016/j.uclim.2016.04.001
   Cai M, 2016, PROCEDIA ENVIRON SCI, V36, P82, DOI 10.1016/j.proenv.2016.09.017
   Chai D, 2019, REMOTE SENS ENVIRON, V225, P307, DOI 10.1016/j.rse.2019.03.007
   Chen XH, 2016, SCI CHINA EARTH SCI, V59, P2295, DOI 10.1007/s11430-016-5291-y
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu SJ, 2020, ISPRS J PHOTOGRAMM, V164, P229, DOI 10.1016/j.isprsjprs.2020.04.008
   LOWRY WP, 1977, J APPL METEOROL, V16, P129, DOI 10.1175/1520-0450(1977)016<0129:EEOUEO>2.0.CO;2
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   OKE TR, 1982, Q J ROY METEOR SOC, V108, P1, DOI 10.1002/qj.49710845502
   Qiu CP, 2020, IEEE J-STARS, V13, P2793, DOI 10.1109/JSTARS.2020.2995711
   Qiu CP, 2019, ISPRS J PHOTOGRAMM, V154, P151, DOI 10.1016/j.isprsjprs.2019.05.004
   Qiu CP, 2018, INT GEOSCI REMOTE SE, V0, P4681
   Ren CG, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-39463-0
   Rosentreter J, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111472
   Stewart ID, 2012, B AM METEOROL SOC, V93, P1879, DOI 10.1175/BAMS-D-11-00019.1
   Szegedy, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Takaku J., 2014, ISPRS ANN PHOTOGRAMM, V4, P243, DOI 10.5194/ISPRSARCHIVES-XL-4-243-2014
   Tian JQ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010117
   Wei J, 2020, REMOTE SENS ENVIRON, V248, P0, DOI 10.1016/j.rse.2020.112005
   Xu G, 2019, PROG PHYS GEOG, V43, P410, DOI 10.1177/0309133319837711
   Zhang HK, 2019, IEEE T GEOSCI REMOTE, V57, P5813, DOI 10.1109/TGRS.2019.2902568
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhu XX, 2020, IEEE GEOSC REM SEN M, V8, P76, DOI 10.1109/MGRS.2020.2964708
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zhu XL, 2014, ISPRS J PHOTOGRAMM, V96, P1, DOI 10.1016/j.isprsjprs.2014.06.012
NR 30
TC 10
Z9 10
U1 5
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4194
EP 4204
DI 10.1109/JSTARS.2021.3071577
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RU3XE
UT WOS:000645081200014
DA 2023-04-26
ER

PT J
AU Adamiak, M
   Bedkowski, K
   Majchrowska, A
AF Adamiak, Maciej
   Bedkowski, Krzysztof
   Majchrowska, Anna
TI Aerial Imagery Feature Engineering Using Bidirectional Generative Adversarial Networks: A Case Study of the Pilica River Region, Poland
SO REMOTE SENSING
LA English
DT Article
DE machine learning; generative adversarial networks; feature engineering; orthophoto; unsupervised segmentation
AB Generative adversarial networks (GANs) are a type of neural network that are characterized by their unique construction and training process. Utilizing the concept of the latent space and exploiting the results of a duel between different GAN components opens up interesting opportunities for computer vision (CV) activities, such as image inpainting, style transfer, or even generative art. GANs have great potential to support aerial and satellite image interpretation activities. Carefully crafting a GAN and applying it to a high-quality dataset can result in nontrivial feature enrichment. In this study, we have designed and tested an unsupervised procedure capable of engineering new features by shifting real orthophotos into the GAN's underlying latent space. Latent vectors are a low-dimensional representation of the orthophoto patches that hold information about the strength, occurrence, and interaction between spatial features discovered during the network training. Latent vectors were combined with geographical coordinates to bind them to their original location in the orthophoto. In consequence, it was possible to describe the whole research area as a set of latent vectors and perform further spatial analysis not on RGB images but on their lower-dimensional representation. To accomplish this goal, a modified version of the big bidirectional generative adversarial network (BigBiGAN) has been trained on a fine-tailored orthophoto imagery dataset covering the area of the Pilica River region in Poland. Trained models, precisely the generator and encoder, have been utilized during the processes of model quality assurance and feature engineering, respectively. Quality assurance was performed by measuring model reconstruction capabilities and by manually verifying artificial images produced by the generator. The feature engineering use case, on the other hand, has been presented in a real research scenario that involved splitting the orthophoto into a set of patches, encoding the patch set into the GAN latent space, grouping similar patches latent codes by utilizing hierarchical clustering, and producing a segmentation map of the orthophoto.
C1 [Adamiak, Maciej] SoftwareMill, PL-02791 Warsaw, Poland.
   [Bedkowski, Krzysztof] Univ Lodz, Fac Geog Sci, Inst Urban Geog Tourism & Geoinformat, PL-90139 Lodz, Poland.
   [Majchrowska, Anna] Univ Lodz, Fac Geog Sci, Dept Phys Geog, PL-90139 Lodz, Poland.
C3 University of Lodz; University of Lodz
RP Adamiak, M (corresponding author), SoftwareMill, PL-02791 Warsaw, Poland.
EM maciej.adamiak@softwaremill.com; krzysztof.bedkowski@geo.uni.lodz.pl; anna.majchrowska@geo.uni.lodz.pl
CR Adamczyk J., 2013, ECOLOGICAL QUESTIONS, V17, P9, DOI 10.12775/ecoq-2013-0012
   Adamczyk J., 2006, ROCZ GEOMATYKI ANN G, V4, P37
   Adamiak M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162628
   [Anonymous], 2021, ARXIV151106434, V0, P0
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Bialousz S., 2010, ARCHIWUM FOTOGRAM KA, V21, P21
   Brock A., 2019, 18091109 ARXIV, V0, P0
   Burdziakowski P, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162586
   Cabezas M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203431
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Deora P., 2020, 19100606 ARXIV, V0, P0
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Donahue J., 2017, 16050978 ARXIV, V0, P0
   Donahue J., 2019, 19070254 ARXIV, V0, P0
   Dong RM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091418
   DOWSON DC, 1982, J MULTIVARIATE ANAL, V12, P450, DOI 10.1016/0047-259X(82)90077-X
   elaniewicz A., 2011, TECTONIC REGIONALIZA, V0, P0
   Frogner C., 2015, 15060543 ARXIV, V0, P0
   Gulrajani I., 2017, 17040002 ARXIV, V0, P0
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Iwaniak A., 2002, ACTA SCIENTIARUM POL, V1, P5
   Goodfellow IJ, 2014, ARXIV, V0, P0, DOI DOI 10.1145/3422622
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Kondracki J., 1977, PHYS GEOGRAPHIC REGI, V0, P0
   Korhonen J, 2012, INT WORK QUAL MULTIM, V0, PP37, DOI 10.1109/QoMEX.2012.6263880
   Kosinski K, 2007, ARCHIWUM FOTOGRAM KA, V17a, P385
   Kosinski K, 2005, ROCZ GEOMATYKI ANN G, V3, P69
   Kot R, 2012, PROBLEMY EKOLOGII KR, V33, P87
   Krawiec K., 2006, ARCHIWUM FOTOGRAM KA, V16, P361
   Krysiak S, 2008, PROBL EKOL KRAJ, V21, P299
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lang S, 2004, EKOL BRATISLAVA, V23, P148
   Lewinski S, 2007, ROCZ GEOMATYKI ANN G, V5, P63
   Lewinski S., 2006, ROCZNIKI GEOMETYKI, V4, P139
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Miyato T., 2018, 18020595 ARXIV, V0, P0
   Mukherjee S, 2019, AAAI CONF ARTIF INTE, V0, P4610
   Oledzki J.R., 1992, GEOGRAPHICAL CONDITI, V0, P0
   Oledzki J.R, 2001, TELEDETEKCJA SRODOWI, V38, P302
   Salimans T., 2016, 16060349 ARXIV, V0, P0
   Sobczak M., 2005, IMAGING SPECTROSCOPY, V0, P763
   Solon J, 2002, PR GEOGR, V185, P193
   Solon J, 2018, GEOGR POL, V91, P143, DOI 10.7163/GPol.0115
   Szegedy C., 2014, GOING DEEPER CONVOLU, V0, P0
   Thanh-Tung H., 2020, 18070401 ARXIV, V0, P0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Weyk P., 2006, ROCZ GEOMATYKI ANN G, V4, P227
   Zagajewski B, 2010, TELEDETEKCJA SRODOWI, V43, P1
   Zhao WZ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050843
   Zhou S., 2019, 190401121 ARXIV, V0, P0
NR 54
TC 3
Z9 3
U1 0
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN 15
PY 2021
VL 13
IS 2
BP 
EP 
DI 10.3390/rs13020306
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PY3LD
UT WOS:000611947900001
DA 2023-04-26
ER

PT J
AU Gupta, J
   Molnar, C
   Xie, YQ
   Knight, J
   Shekhar, S
AF Gupta, Jayant
   Molnar, Carl
   Xie, Yiqun
   Knight, Joe
   Shekhar, Shashi
TI Spatial Variability Aware Deep Neural Networks (SVANN): A General Approach
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE Neural networks; spatial variability
AB Spatial variability is a prominent feature of various geographic phenomena such as climatic zones, USDA plant hardiness zones, and terrestrial habitat types (e.g., forest, grasslands, wetlands, and deserts). However, current deep learning methods follow a spatial-one-size-fits-all (OSFA) approach to train single deep neural network models that do not account for spatial variability. Quantification of spatial variability can be challenging due to the influence of many geophysical factors. In preliminary work, we proposed a spatial variability aware neural network (SVANN-I, formerly called SVANN) approach where weights are a function of location but the neural network architecture is location independent. In this work, we explore a more flexible SVANNE approach where neural network architecture varies across geographic locations. In addition, we provide a taxonomy of SVANN types and a physics inspired interpretation model. Experiments with aerial imagery based wetland mapping show that SVANN-I outperforms OSFA and SVANN-E performs the best of all.
C1 [Gupta, Jayant; Molnar, Carl; Shekhar, Shashi] Univ Minnesota, Dept Comp Sci & Engn, 4-192 Keller Hall,200 Union St SE, Minneapolis, MN 55455 USA.
   [Xie, Yiqun] Univ Maryland, Ctr Geospatial Informat Sci, Dept Geog Sci, 1124 Lefrak Hall,7251 Preinkert Dr, College Pk, MD 20742 USA.
   [Knight, Joe] Univ Minnesota, Dept Forest Resources, 1530 Cleveland Ave N, St Paul, MN 55108 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities; University System of Maryland; University of Maryland College Park; University of Minnesota System; University of Minnesota Twin Cities
RP Gupta, J (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, 4-192 Keller Hall,200 Union St SE, Minneapolis, MN 55455 USA.
EM gupta423@umn.edu; molna018@umn.edu; xie@umd.edu; jknight@umn.edu; shekhar@umn.edu
FU National nce Foundation [1737633]
CR [Anonymous], 2015, ICLR, V0, P0
   [Anonymous], 2010, WETLAND ECOLOGY PRIN, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Conant RT, 2003, J ENVIRON QUAL, V32, P278, DOI 10.2134/jeq2003.0278
   Cowardin LM, 1979, CLASSIFICATION WETLA, V0, P0
   Cybenko G., 1989, MATHEMATICS OF CONTROL, V0, P0
   ENGLAND WL, 1988, MED DECIS MAKING, V8, P120, DOI 10.1177/0272989X8800800208
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Freund Y., 1996, MACHINE LEARNING. PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE (ICML 96), V0, P148
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Gupta Jayant, 2020, P WORKSH DEEP LEARN, V0, P0
   Heindl A, 2015, LAB INVEST, V95, P377, DOI 10.1038/labinvest.2014.155
   Iglovikov V., 2018, TERNAUSNET U NET VGG, V0, P0
   Jiang Z, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3337798
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kloiber SM, 2015, WETLANDS, V35, P335, DOI 10.1007/s13157-014-0621-3
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lee S., 2019, EARTH RESOUR ENV REM, V11156, P313
   Leitner M., 2018, OXFORD RES ENCY CRIM, V0, PP1, DOI 10.1093/acrefore/9780190264079.013.325
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Norvig P., 2016, ARTIF INTELL, V0, P0
   Nusser SM, 1997, ENVIRON ECOL STAT, V4, P181, DOI 10.1023/A:1018574412308
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Shekhar S., 2012, P 11 ACM INT WORKSH, V0, PP1, DOI 10.1145/2258056.2258058
   Silvertown J, 2009, TRENDS ECOL EVOL, V24, P467, DOI 10.1016/j.tree.2009.03.017
   Sitterson J, 2018, P IEMSS 2018 9 INT C, V0, P0
   Stewart Fotheringham A., 2003, GEOGRAPHICALLYWEIGHT, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   TINER RW, 1990, FOREST ECOL MANAG, V33-4, P593, DOI 10.1016/0378-1127(90)90221-V
   Turner MG, 2005, ECOSYSTEM FUNCTION IN HETEROGENEOUS LANDSCAPES, V0, PP9, DOI 10.1007/0-387-24091-8_2
   U.S. Department of Agriculture, 2012, USDA PLANT HARD ZON, V0, P0
   U. S. Fish and Wildlife Service, 2020, NAT WETL INV SURF WA, V0, P0
   WAGNER CH, 1982, AM STAT, V36, P46, DOI 10.2307/2684093
   Xie YQ, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), V0, PP71, DOI 10.1145/3347146.3359066
   Xie YQ, 2020, INT J GEOGR INF SCI, V34, P777, DOI 10.1080/13658816.2019.1624761
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 42
TC 2
Z9 2
U1 1
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2157-6904
EI 2157-6912
J9 ACM T INTEL SYST TEC
JI ACM Trans. Intell. Syst. Technol.
PD NOV 15
PY 2021
VL 12
IS 6
BP 
EP 
DI 10.1145/3466688
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA YY1AN
UT WOS:000754524700009
DA 2023-04-26
ER

PT J
AU Choe, H
   Chi, J
   Thorne, JH
AF Choe, Hyeyeong
   Chi, Junhwa
   Thorne, James H.
TI Mapping Potential Plant Species Richness over Large Areas with Deep Learning, MODIS, and Species Distribution Models
SO REMOTE SENSING
LA English
DT Article
DE biodiversity; data fusion; deep learning; LAI; MODIS; multilayer perceptron (MLP); NDVI; remote sensing; species richness; S-SDMs
ID neural-networks; biodiversity; diversity; forest; prediction; ndvi; performance; satellite; framework; index
AB The spatial patterns of species richness can be used as indicators for conservation and restoration, but data problems, including the lack of species surveys and geographical data gaps, are obstacles to mapping species richness across large areas. Lack of species data can be overcome with remote sensing because it covers extended geographic areas and generates recurring data. We developed a Deep Learning (DL) framework using Moderate Resolution Imaging Spectroradiometer (MODIS) products and modeled potential species richness by stacking species distribution models (S-SDMs) to ask, "What are the spatial patterns of potential plant species richness across the Korean Peninsula, including inaccessible North Korea, where survey data are limited?" First, we estimated plant species richness in South Korea by combining the probability-based SDM results of 1574 species and used independent plant surveys to validate our potential species richness maps. Next, DL-based species richness models were fitted to the species richness results in South Korea, and a time-series of the normalized difference vegetation index (NDVI) and leaf area index (LAI) from MODIS. The individually developed models from South Korea were statistically tested using datasets that were not used in model training and obtained high accuracy outcomes (0.98, Pearson correlation). Finally, the proposed models were combined to estimate the richness patterns across the Korean Peninsula at a higher spatial resolution than the species survey data. From the statistical feature importance tests overall, growing season NDVI-related features were more important than LAI features for quantifying biodiversity from remote sensing time-series data.
C1 [Choe, Hyeyeong] Seoul Natl Univ, Dept Agr Forestry & Bioresources, Seoul 08826, South Korea.
   [Chi, Junhwa] Korea Polar Res Inst, Ctr Remote Sensing & GIS, Incheon 21990, South Korea.
   [Thorne, James H.] Univ Calif Davis, Dept Environm Sci & Policy, Davis, CA 95616 USA.
C3 Seoul National University (SNU); Korea Polar Research Institute (KOPRI); University of California System; University of California Davis
RP Chi, J (corresponding author), Korea Polar Res Inst, Ctr Remote Sensing & GIS, Incheon 21990, South Korea.
EM hy.choe@snu.ac.kr; jhchi@kopri.re.kr; jhthorne@ucdavis.edu
FU National Research Foundation of Korea (NRF) grant - Korean government (MSIT) [2019R1G1A1005770, 2021R1A4A1025553]; Korea Polar Research Institute grant [PE21420]; Seoul National University
CR Aguirre-Gutierrez J, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0063708
   Amano T, 2016, BIOSCIENCE, V66, P393, DOI 10.1093/biosci/biw022
   [Anonymous], 2012, COURSERA NEURAL NETW, V0, P0, DOI DOI 10.1007/S12654-012-0173-1
   [Anonymous], 2007, REMOTE SENSING ENV E, V0, P0
   [Anonymous], 2008, HOLE FILLED SEAMLESS, V0, P0
   [Anonymous], 2012, HARM WORLD SOIL DAT, V0, P0
   Benito BM, 2013, METHODS ECOL EVOL, V4, P327, DOI 10.1111/2041-210x.12022
   Bhatnagar S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162602
   Breiner FT, 2015, METHODS ECOL EVOL, V6, P1210, DOI 10.1111/2041-210X.12403
   Camathias L, 2013, APPL VEG SCI, V16, P539, DOI 10.1111/avsc.12028
   Campillo C, 2010, HORTSCIENCE, V45, P1459, DOI 10.21273/HORTSCI.45.10.1459
   Carlson TN, 1997, REMOTE SENS ENVIRON, V62, P241, DOI 10.1016/S0034-4257(97)00104-1
   Choe Hyeyeong, 2020, JOURNAL OF THE KOREA SOCIETY OF ENVIRONMENTAL RESTORATION TECHNOLOGY 한국환경복원기술학회지, V23, P77
   Choe H, 2019, ECOL EVOL, V9, P1353, DOI 10.1002/ece3.4851
   Choe H, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0190754
   Choe H, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0149511
   Chollet F., 2018, DEEP LEARNING WITH R, V0, P0
   Cord AF, 2014, J BIOGEOGR, V41, P736, DOI 10.1111/jbi.12225
   DAmen M, 2015, J BIOGEOGR, V42, P1255, DOI 10.1111/jbi.12485
   Del Toro I, 2019, AUSTRAL ECOL, V44, P105, DOI 10.1111/aec.12658
   Dinerstein E, 2017, BIOSCIENCE, V67, P534, DOI 10.1093/biosci/bix014
   Dormann CF, 2013, ECOGRAPHY, V36, P27, DOI 10.1111/j.1600-0587.2012.07348.x
   Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x
   Elith J, 2009, ANNU REV ECOL EVOL S, V40, P677, DOI 10.1146/annurev.ecolsys.110308.120159
   Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Gotelli Nicholas J., 2011, P39, V0, P0
   Gotelli NJ, 2001, ECOL LETT, V4, P379, DOI 10.1046/j.1461-0248.2001.00230.x
   Grenie M, 2020, ECOL INDIC, V111, P0, DOI 10.1016/j.ecolind.2019.105970
   Guralnick RP, 2007, ECOL LETT, V10, P663, DOI 10.1111/j.1461-0248.2007.01063.x
   Hakkenberg CR, 2018, ECOLOGY, V99, P474, DOI 10.1002/ecy.2109
   Hernandez PA, 2006, ECOGRAPHY, V29, P773, DOI 10.1111/j.0906-7590.2006.04700.x
   Hijmans RJ, 2005, INT J CLIMATOL, V25, P1965, DOI 10.1002/joc.1276
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Huete AR, 2012, GEOGR COMPASS, V6, P513, DOI 10.1111/j.1749-8198.2012.00507.x
   Ince T, 2016, IEEE T IND ELECTRON, V63, P7067, DOI 10.1109/TIE.2016.2582729
   Joharestani MZ, 2019, ATMOSPHERE-BASEL, V10, P0, DOI 10.3390/atmos10070373
   Justice CO, 2002, REMOTE SENS ENVIRON, V83, P3, DOI 10.1016/S0034-4257(02)00084-6
   Kang JH, 2009, ATMOS-KOREA, V19, P169
   Kim KC, 1997, SCIENCE, V278, P242, DOI 10.1126/science.278.5336.242
   Kim YJ, 2020, CRYOSPHERE, V14, P1083, DOI 10.5194/tc-14-1083-2020
   Korea Forest Service, 2016, 6 NAT FOR INV MON, V0, P0
   Korotcov A, 2017, MOL PHARMACEUT, V14, P4462, DOI 10.1021/acs.molpharmaceut.7b00578
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kuhl HS, 2020, ONE EARTH, V3, P462, DOI 10.1016/j.oneear.2020.09.010
   La Sorte FA, 2020, LANDSCAPE URBAN PLAN, V203, P0, DOI 10.1016/j.landurbplan.2020.103892
   Ledig C, 2017, PROC CVPR IEEE, V0, PP105, DOI 10.1109/CVPR.2017.19
   Lomba A, 2010, BIOL CONSERV, V143, P2647, DOI 10.1016/j.biocon.2010.07.007
   Lopatin J, 2016, REMOTE SENS ENVIRON, V173, P200, DOI 10.1016/j.rse.2015.11.029
   Hernandez-Stefanoni JL, 2012, INT J APPL EARTH OBS, V19, P359, DOI 10.1016/j.jag.2012.04.002
   Madonsela S, 2018, INT J APPL EARTH OBS, V66, P106, DOI 10.1016/j.jag.2017.11.005
   Malhi Y, 2020, PHILOS T R SOC B, V375, P0, DOI 10.1098/rstb.2019.0104
   Manzoor SA, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-25437-1
   Mateo RG, 2012, PLOS ONE, V7, P0, DOI 10.1371/journal.pone.0032586
   Ministry of Environment, 2016, 3 MAST PLANS PROT WI, V0, P0
   Myneni R., 2015, NASA EOSDIS LAND PRO, V0, P0, DOI DOI 10.5067/MODIS/MCD15A2H.006
   Naimi B, 2016, ECOGRAPHY, V39, P368, DOI 10.1111/ecog.01881
   Pau S, 2012, J BIOGEOGR, V39, P1678, DOI 10.1111/j.1365-2699.2012.02731.x
   Pausas JG, 2001, J VEG SCI, V12, P153, DOI 10.2307/3236601
   Peng DD, 2019, IEEE ACCESS, V7, P10278, DOI 10.1109/ACCESS.2018.2888842
   Pereira HM, 2013, SCIENCE, V339, P277, DOI 10.1126/science.1229931
   Pettorelli N, 2014, PHILOS T R SOC B, V369, P0, DOI 10.1098/rstb.2013.0190
   Phillips SJ, 2006, ECOL MODEL, V190, P231, DOI 10.1016/j.ecolmodel.2005.03.026
   Randin CF, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111626
   Rocchini D, 2017, ECOL INDIC, V72, P234, DOI 10.1016/j.ecolind.2016.07.039
   Rocchini D, 2010, ECOL INFORM, V5, P318, DOI 10.1016/j.ecoinf.2010.06.001
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sak H, 2014, INTERSPEECH, V0, P338
   Scherrer D, 2020, METHODS ECOL EVOL, V11, P51, DOI 10.1111/2041-210X.13312
   Schmeller D, 2017, BIODIVERS CONSERV, V26, P2765, DOI 10.1007/s10531-017-1388-7
   Scholes R.J., 2017, GEO HDB BIODIVERSITY, V0, PP1, DOI 10.1007/978-3-319-27288-7_1
   Soto-Navarro C, 2020, PHILOS T R SOC B, V375, P0, DOI 10.1098/rstb.2019.0128
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sullivan BL, 2009, BIOL CONSERV, V142, P2282, DOI 10.1016/j.biocon.2009.05.006
   Sun Y, 2019, FORESTS, V10, P0, DOI 10.3390/f10111047
   Turner W, 2015, BIOL CONSERV, V182, P173, DOI 10.1016/j.biocon.2014.11.048
   Turner W, 2014, SCIENCE, V346, P301, DOI 10.1126/science.1256014
   van Proosdij ASJ, 2016, ECOGRAPHY, V39, P542, DOI 10.1111/ecog.01509
   Wich SA, 2018, CONSERVATION DRONES: MAPPING AND MONITORING BIODIVERSITY, V0, PP1, DOI 10.1093/oso/9780198787617.001.0001
   Wu JH, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050739
   Xu HQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202345
   Zarnetske PL, 2019, GLOBAL ECOL BIOGEOGR, V28, P548, DOI 10.1111/geb.12887
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 85
TC 2
Z9 2
U1 10
U2 42
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL 15
PY 2021
VL 13
IS 13
BP 
EP 
DI 10.3390/rs13132490
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TF9TF
UT WOS:000671056500001
DA 2023-04-26
ER

PT J
AU Kong, YP
   Wang, Y
   Guo, S
   Wang, JJ
AF Kong, Yueping
   Wang, Yun
   Guo, Song
   Wang, Jiajing
TI A Mountain Summit Recognition Method Based on Improved Faster R-CNN
SO COMPLEXITY
LA English
DT Article
ID multiscale; peaks
AB Mountain summits are vital topographic feature points, which are essential for understanding landform processes and their impacts on the environment and ecosystem. Traditional summit detection methods operate on handcrafted features extracted from digital elevation model (DEM) data and apply parametric detection algorithms to locate mountain summits. However, these methods may no longer be effective to achieve desirable recognition results in small summits and suffer from the objective criterion lacking problem. Thus, to address these problems, we propose an improved Faster region-convolutional neural network (R-CNN) to accurately detect the mountain summits from DEM data. Based on Faster R-CNN, the improved network adopts a residual convolution block to replace the traditional part and adds a feature pyramid network (FPN) to fuse the features with adjacent layers to better address the mountain summit detection task. The residual convolution is employed to capture the deep correlation between visual and physical morphological features. The FPN is utilized to integrate the location and semantic information in the extracted feature maps to effectively represent the mountain summit area. The experimental results demonstrate that the proposed network could achieve the highest recall and precision without manually designed summit features and accurately identify small summits.
C1 [Kong, Yueping; Wang, Yun; Guo, Song; Wang, Jiajing] Xian Univ Architecture & Technol, Sch Informat & Control, Xian 710055, Peoples R China.
C3 Xi'an University of Architecture & Technology
RP Kong, YP (corresponding author), Xian Univ Architecture & Technol, Sch Informat & Control, Xian 710055, Peoples R China.
EM kongyp@xauat.edu.cn
FU Foundation of State Key Laboratory of Geo-Information Engineering [SKLGIE2018-Z-4-1]; Natural Science Foundation of Shaanxi Province [2019JM-183]; National Key R&D Program of China [2019YFD1100901]
CR [Anonymous], 2000, EOS T AM GEOPHYS UN, V0, P0
   Chang ZL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030502
   De Jong C., 2008, P ESA SURF WAT STOR, V0, P0
   de Lima RP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010086
   Deng Y, 2008, INT J GEOGR INF SCI, V22, P205, DOI 10.1080/13658810701405623
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fedorov R, 2016, IEEE T MULTIMEDIA, V18, P1187, DOI 10.1109/TMM.2016.2535356
   Fisher P, 1998, GEOGRAPHY, V83, P247
   Fu K, 2020, ISPRS J PHOTOGRAMM, V161, P294, DOI 10.1016/j.isprsjprs.2020.01.025
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, V0, PP3588, DOI 10.1109/CVPR.2018.00378
   Huang ZJ, 2020, COMPLEXITY, V2020, P0, DOI 10.1155/2020/1520872
   Korner C, 2017, ALPINE BOT, V127, P1, DOI 10.1007/s00035-016-0182-6
   Li W., 2017, P 1 WORKSH ART INT D, V0, P33
   Li WW, 2020, INT J GEOGR INF SCI, V34, P637, DOI 10.1080/13658816.2018.1542697
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281
   Naghibi SA, 2016, ENVIRON MONIT ASSESS, V188, P0, DOI 10.1007/s10661-015-5049-6
   Podobnikar T, 2010, GEOGR TECH, V5, P111
   Redmon J, 2018, YOLOV3 INCREMENTAL I, V0, P0, DOI DOI 10.48550/ARXIV.1804.02767
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sang HT, 2020, COMPLEXITY, V2020, P0, DOI 10.1155/2020/6180317
   Tarvainen A, 2017, ADV NEUR IN, V30, P0
   Torres RN, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), V0, PP212, DOI 10.1109/AIKE.2018.00049
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Wood J, 2009, DEV SOIL SCI, V33, P333, DOI 10.1016/S0166-2481(08)00014-7
   Wood J., 1996, GEOMORPHOLOGICAL CHA, V0, P0
   Yamada S, 1999, EARTH SURF PROC LAND, V24, P653, DOI 10.1002/(SICI)1096-9837(199907)24:7<653::AID-ESP984>3.0.CO;2-A
   Zhang X, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030417
NR 32
TC 1
Z9 1
U1 2
U2 15
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1076-2787
EI 1099-0526
J9 COMPLEXITY
JI Complexity
PD AUG 12
PY 2021
VL 2021
IS 
BP 
EP 
DI 10.1155/2021/8235108
PG 10
WC Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences
SC Mathematics; Science & Technology - Other Topics
GA UD8QK
UT WOS:000687467200002
DA 2023-04-26
ER

PT J
AU Zhao, GY
   He, HD
   Huang, YF
   Ren, JD
AF Zhao, Guyu
   He, Hongdou
   Huang, Yifang
   Ren, Jiadong
TI Near-surface PM2.5 prediction combining the complex network characterization and graph convolution neural network
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Air pollution; Graph theory; Deep learning; Graph convolution neural network; PM2.5 Forecasting
ID air-quality; health; ozone; model
AB Massive studies focus on the prediction of main pollutants, to improve air quality by revealing the evolution of pollutants. However, existing prediction methods mostly emphasize the fitting analysis of time series, but ignore the spatial propagation effect among nearby places, resulting in a low prediction accuracy. To address this issue, this paper proposes a novel synthesis prediction method to simultaneously excavate the time series changing law and the spatial propagation effect. This method combines a characterization model named air quality spatial-temporal network (AQSTN) and a neural network model called graph convolution neural network (GCN). Firstly, by calculating three correlation coefficients, the time series of most related meteorological factors and aerosol data are gained for feature construction. The geographic distances between locations are computed to evaluate the spatial propagation cost. After that, AQSTN with locations as nodes and propagation relations as edges is constructed, compositing the temporal and spatial relationships. The network is regarded as graph data and input into GCN in chronological order. Secondly, GCN processing graph-structured data fits the optimal parameters in the training stage, simultaneously analyzes the spatial and temporal dimensions of the target site and its adjacent sites. And, the predicted PM2.5 concentration is gained in the test stage. The near-surface monitoring data of Beijing-Tianjin-Hebei area are adopted for experiment. Compared with the second-best model, the RMSE value of AQSTN-GCN is 6.85% lower, MAE value is 13.79% lower, MSE value is 13.23% lower, and MAPE value is 21.53% lower.
C1 [Zhao, Guyu; He, Hongdou; Huang, Yifang; Ren, Jiadong] Yanshan Univ, Sch Software, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University
RP He, HD (corresponding author), Yanshan Univ, Sch Software, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM gaiazhao@163.com; hhd@ysu.edu.cn
FU National Natural Science Foundation of China [61772451]; Graduate Innovative Funding Project of Hebei Province [CXZZBS2020061]
CR [Anonymous], 1986, PARALLEL DISTRIBUTED, V0, P0
   [Anonymous], 2020, AMBIENT AIR POLLUTIO, V0, P0
   [Anonymous], 1968, 1968 ACM NATL C, V0, P0
   [Anonymous], 2020, GLOBAL METRICS ENV T, V0, P0
   Athira V., 2018, INT C COMPUTATIONAL, V132, P1394
   Bahdanau D, 2016, ARXIV, V0, P0
   Bai Y, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030262
   Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Bell ML, 2007, CLIMATIC CHANGE, V82, P61, DOI 10.1007/s10584-006-9166-7
   Bruna J., 2013, ARXIV13126203, V0, P0
   Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575
   Burges C.J.C, 2004, P 8 INT C SPOK LANG, V0, P0
   Byun D, 2006, APPL MECH REV, V59, P51, DOI 10.1115/1.2128636
   Cabaneros SM, 2019, ENVIRON MODELL SOFTW, V119, P285, DOI 10.1016/j.envsoft.2019.06.014
   Dincer NG, 2018, ECOL INFORM, V43, P157, DOI 10.1016/j.ecoinf.2017.12.001
   Du SD, 2021, IEEE T KNOWL DATA EN, V33, P2412, DOI 10.1109/TKDE.2019.2954510
   Feng F, 2018, LECT NOTES COMPUT SC, V10987, P349, DOI 10.1007/978-3-319-96890-2_29
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Fu BT, 2019, J CLEAN PROD, V209, P595, DOI 10.1016/j.jclepro.2018.10.192
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   GOODIN WR, 1980, J APPL METEOROL, V19, P98, DOI 10.1175/1520-0450(1980)019<0098:AOATFC>2.0.CO;2
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Gu K, 2018, IEEE T IND INFORM, V14, P3946, DOI 10.1109/TII.2018.2793950
   Hernandez RA, 2015, SAPI S SURVEYS PERSP, V8, P0
   Huang CJ, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18072220
   Huang GB, 2004, IEEE IJCNN, V0, P985
   Jiang Zhifang, 2010, PROCEEDINGS 2010 SIXTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC 2010), V0, PP1523, DOI 10.1109/ICNC.2010.5582643
   Jin YN, 2016, INT J ENV RES PUB HE, V13, P0, DOI 10.3390/ijerph13121219
   Kindap T, 2006, ATMOS ENVIRON, V40, P3536, DOI 10.1016/j.atmosenv.2006.01.055
   Lelieveld J, 2015, NATURE, V525, P367, DOI 10.1038/nature15371
   Li C, 2011, ATMOS ENVIRON, V45, P3663, DOI 10.1016/j.atmosenv.2011.04.032
   LIPPMANN M, 1989, JAPCA J AIR WASTE MA, V39, P672, DOI 10.1080/08940630.1989.10466554
   Liu DR, 2020, EXPERT SYST, V37, P0, DOI 10.1111/exsy.12511
   Lu ZM, 2012, PHYSICA A, V391, P87, DOI 10.1016/j.physa.2011.08.002
   Mahajan S, 2018, IEEE ACCESS, V6, P19193, DOI 10.1109/ACCESS.2018.2820164
   Mendes GA, 2012, PHYSICA A, V391, P362, DOI 10.1016/j.physa.2011.07.046
   Nel A, 2005, SCIENCE, V308, P804, DOI 10.1126/science.1108752
   Nguyen-Tuong Duy, 2009, ADV NEURAL INFORM PR, V0, P1193
   Ong BT, 2016, NEURAL COMPUT APPL, V27, P1553, DOI 10.1007/s00521-015-1955-3
   Pisoni E, 2017, ENVIRON MODELL SOFTW, V90, P68, DOI 10.1016/j.envsoft.2017.01.001
   Pope CA, 2011, J AIR WASTE MANAGE, V61, P858, DOI 10.3155/1047-3289.61.8.858
   Qi ZG, 2018, IEEE T KNOWL DATA EN, V30, P2285, DOI 10.1109/TKDE.2018.2823740
   Qin DM, 2019, IEEE ACCESS, V7, P20050, DOI 10.1109/ACCESS.2019.2897028
   Reyes J, 2013, INT CONF ELECTR COMM, V0, PP27, DOI 10.1109/CONIELECOMP.2013.6525752
   Saide PE, 2011, ATMOS ENVIRON, V45, P2769, DOI 10.1016/j.atmosenv.2011.02.001
   Sefidmazgi MG, 2015, MACHINE LEARNING DAT, V0, PP185, DOI 10.1007/978-3-319-17220-0_17
   Soh PW, 2018, IEEE ACCESS, V6, P38186, DOI 10.1109/ACCESS.2018.2849820
   Stadlober E, 2008, ATMOS ENVIRON, V42, P1098, DOI 10.1016/j.atmosenv.2007.10.073
   Strogatz SH, 2001, NATURE, V410, P268, DOI 10.1038/35065725
   Tang MF, 2017, IEEE T MULTIMEDIA, V19, P408, DOI 10.1109/TMM.2016.2613639
   Vardoulakis S, 2003, ATMOS ENVIRON, V37, P155, DOI 10.1016/S1352-2310(02)00857-9
   Wang B, 2018, LECT NOTES COMPUT SC, V11305, P93, DOI 10.1007/978-3-030-04221-9_9
   Wang Y, 2013, PHYSICA A, V392, P5824, DOI 10.1016/j.physa.2013.07.067
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wen CC, 2019, SCI TOTAL ENVIRON, V654, P1091, DOI 10.1016/j.scitotenv.2018.11.086
   Zhao GY, 2019, IEEE ACCESS, V7, P134903, DOI 10.1109/ACCESS.2019.2941732
   Zhao GY, 2019, IEEE ACCESS, V7, P26241, DOI 10.1109/ACCESS.2019.2900997
   Zheng Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD13), V0, PP1436, DOI 10.1145/2487575.2488188
   Zhou YL, 2019, J CLEAN PROD, V209, P134, DOI 10.1016/j.jclepro.2018.10.243
NR 62
TC 5
Z9 5
U1 8
U2 47
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD DEC 15
PY 2021
VL 33
IS 24
BP 17081
EP 17101
DI 10.1007/s00521-021-06300-3
EA JUL 2021
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA WS1UA
UT WOS:000674551700003
DA 2023-04-26
ER

PT J
AU Kikumoto, C
   Harimoto, Y
   Isogaya, K
   Yoshida, T
   Urakubo, T
AF Kikumoto, Chihiro
   Harimoto, Yoh
   Isogaya, Kazuki
   Yoshida, Takeshi
   Urakubo, Takateru
TI Landing Site Detection for UAVs Based on CNNs Classification and Optical Flow from Monocular Camera Images
SO JOURNAL OF ROBOTICS AND MECHATRONICS
LA English
DT Article
DE unmanned aerial vehicle; autonomous landing; land cover classification; topographic mapping
AB The increased use of UAVs (Unmanned Aerial Vehicles) has heightened demands for an automated landing system intended for a variety of tasks and emergency landings. A key challenge of this system is finding a safe landing site in an unknown environment using on-board sensors. This paper proposes a method to generate a heat map for safety evaluation using images from a single on-board camera. The proposed method consists of the classification of ground surface by CNNs (Convolutional Neural Networks) and the estimation of surface flatness from optical flow. We present the results of applying this method to a video obtained from an on-board camera and discuss ways of improving the method.
C1 [Kikumoto, Chihiro; Harimoto, Yoh; Isogaya, Kazuki; Urakubo, Takateru] Kobe Univ, Dept Informat Sci, Grad Sch Syst Informat, Nada Ku, 1-1 Rokkodai Cho, Kobe, Hyogo 6578501, Japan.
   [Yoshida, Takeshi] Ritsumeikan Univ, Res Org Sci & Technol, 1-1-1 Noji Higashi, Kusatsu, Shiga 5258577, Japan.
C3 Kobe University; Ritsumeikan University
RP Kikumoto, C (corresponding author), Kobe Univ, Dept Informat Sci, Grad Sch Syst Informat, Nada Ku, 1-1 Rokkodai Cho, Kobe, Hyogo 6578501, Japan.
EM kikumoto@al.cs.kobe-u.ac.jp; harimoto@al.cs.kobe-u.ac.jp; isogaya@al.cs.kobe-u.ac.jp; yoshi-da@fc.ritsumei.ac.jp; t.urakubo@silver.kobe-u.ac.jp
FU Futaba Foundation
CR Adarve JD, 2016, IEEE ROBOT AUTOM LET, V1, P1192, DOI 10.1109/LRA.2016.2532928
   Bosch S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5522, DOI 10.1109/IROS.2006.282188
   Cesetti A, 2010, J INTELL ROBOT SYST, V57, P233, DOI 10.1007/s10846-009-9373-3
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Farneback G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Forster C, 2015, IEEE INT CONF ROBOT, V0, PP111, DOI 10.1109/ICRA.2015.7138988
   Ghiasi M, 2013, IRAN CONF MACH, V0, PP324, DOI 10.1109/IranianMVIP.2013.6780004
   Guo X., 2014, 2014 INT C DIGITAL I, V0, P1
   Guo XF, 2016, INT C PATT RECOG, V0, PP1659, DOI 10.1109/ICPR.2016.7899875
   Hinzmann T, 2018, IEEE ROBOT AUTOM LET, V3, P2545, DOI 10.1109/LRA.2018.2809962
   Hinzmann T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), V0, PP3261, DOI 10.1109/IROS.2016.7759503
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0
   Humenberger M, 2014, ROBOTICS SCI SYSTEMS, V0, P0, DOI DOI 10.15607/RSS.2014.X.044
   Ilg E, 2017, PROC CVPR IEEE, V0, PP1647, DOI 10.1109/CVPR.2017.179
   Laiacker M, 2013, IEEE INT C INT ROBOT, V0, PP2971, DOI 10.1109/IROS.2013.6696777
   Miyamoto R, 2020, J ROBOT MECHATRON, V32, P1137, DOI 10.20965/jrm.2020.p1137
   Nonami K, 2016, J ROBOT MECHATRON, V28, P262, DOI 10.20965/jrm.2016.p0262
   Rabah M, 2018, INT J CONTROL AUTOM, V16, P3013, DOI 10.1007/s12555-018-0017-x
   Sanket NJ, 2018, IEEE ROBOT AUTOM LET, V3, P2799, DOI 10.1109/LRA.2018.2843445
   Thurrowgood S, 2014, J FIELD ROBOT, V31, P699, DOI 10.1002/rob.21527
   Warren M, 2013, P 9 C FIELD SERV ROB, V12, P1, DOI 10.1007/978-3-319-07488-7
   Yan L, 2020, CHIN CONTR CONF, V0, PP6497, DOI 10.23919/CCC50068.2020.9189499
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 24
TC 1
Z9 1
U1 2
U2 3
PU FUJI TECHNOLOGY PRESS LTD
PI TOKYO
PA 1-15-7, UCHIKANDA, CHIYODA-KU, UNIZO UCHIKANDA 1-CHOME BLDG 2F, TOKYO, 101-0047, JAPAN
SN 0915-3942
EI 1883-8049
J9 J ROBOT MECHATRON
JI J. Robot. Mechatron.
PD APR 15
PY 2021
VL 33
IS 2
BP 292
EP 300
DI 10.20965/jrm.2021.p0292
PG 9
WC Robotics
SC Robotics
GA RP9OJ
UT WOS:000642051000012
DA 2023-04-26
ER

PT J
AU Raiyani, K
   Goncalves, T
   Rato, L
   Salgueiro, P
   da Silva, JRM
AF Raiyani, Kashyap
   Goncalves, Teresa
   Rato, Luis
   Salgueiro, Pedro
   Marques da Silva, Jose R.
TI Sentinel-2 Image Scene Classification: A Comparison between Sen2Cor and a Machine Learning Approach
SO REMOTE SENSING
LA English
DT Article
DE Sentinel-2; high-resolution imagery; scene classification; Sen2Cor; surface reflectance; artificial intelligence; machine learning
ID remote-sensing images; land-cover; decision tree; cloud shadow; benchmark; vulnerability; scale
AB Given the continuous increase in the global population, the food manufacturers are advocated to either intensify the use of cropland or expand the farmland, making land cover and land usage dynamics mapping vital in the area of remote sensing. In this regard, identifying and classifying a high-resolution satellite imagery scene is a prime challenge. Several approaches have been proposed either by using static rule-based thresholds (with limitation of diversity) or neural network (with data-dependent limitations). This paper adopts the inductive approach to learning from surface reflectances. A manually labeled Sentinel-2 dataset was used to build a Machine Learning (ML) model for scene classification, distinguishing six classes (Water, Shadow, Cirrus, Cloud, Snow, and Other). This models was accessed and further compared to the European Space Agency (ESA) Sen2Cor package. The proposed ML model presents a Micro-F1 value of 0.84, a considerable improvement when compared to the Sen2Cor corresponding performance of 0.59. Focusing on the problem of optical satellite image scene classification, the main research contributions of this paper are: (a) an extended manually labeled Sentinel-2 database adding surface reflectance values to an existing dataset; (b) an ensemble-based and a Neural-Network-based ML models; (c) an evaluation of model sensitivity, biasness, and diverse ability in classifying multiple classes over different geographic Sentinel-2 imagery, and finally, (d) the benchmarking of the ML approach against the Sen2Cor package.
C1 [Raiyani, Kashyap; Goncalves, Teresa; Rato, Luis; Salgueiro, Pedro] Univ Evora, Sch Sci & Technol, Dept Informat, P-7000671 Evora, Portugal.
   [Marques da Silva, Jose R.] Univ Evora, Sch Sci & Technol, Dept Rural Engn, Mediterranean Inst Agr Environm & Dev MED, P-7000671 Evora, Portugal.
   [Marques da Silva, Jose R.] Agroinsider Lda, PITE, NERE, Sala 18, P-7005841 Evora, Portugal.
C3 University of Evora; University of Evora
RP Raiyani, K (corresponding author), Univ Evora, Sch Sci & Technol, Dept Informat, P-7000671 Evora, Portugal.
EM d41720@alunos.uevora.pt; tcg@uevora.pt; lmr@uevora.pt; pds@uevora.pt; jmsilva@uevora.pt
FU Project NIIAA: Nucleo de Investigacao em Inteligencia Artificial em Agricultura (Alentejo 2020) [ALT20-03-0247-FEDER-036981]
CR Abdel-Hamid Ossama, 2013, 14 ANN C INT SPEECH, V11, P73
   Al-Khaier F., 2003, SOIL SALINITY DETECT, V0, P0
   Al-Obeidat F, 2015, PROCEDIA COMPUT SCI, V52, P1192, DOI 10.1016/j.procs.2015.05.157
   Alonso, 2018, P 2 SENT 2 VAL TEAM, V0, P29
   [Anonymous], 2016, SPIE REMOTE SENSING, V0, P0
   Baetens L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040433
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   BOWKER AH, 1948, J AM STAT ASSOC, V43, P572, DOI 10.2307/2280710
   CRIST EP, 1984, IEEE T GEOSCI REMOTE, V22, P256, DOI 10.1109/TGRS.1984.350619
   Dao PD, 2015, REMOTE SENS-BASEL, V7, P5077, DOI 10.3390/rs70505077
   Elith J, 2008, J ANIM ECOL, V77, P802, DOI 10.1111/j.1365-2656.2008.01390.x
   Frantz D, 2018, REMOTE SENS ENVIRON, V215, P471, DOI 10.1016/j.rse.2018.04.046
   Friedman J., 2009, ELEMENTS STAT LEARNI, V0, P0
   Gabrani M., 1996, PROC C REC 30 ASILOM, V1, P501
   GDAL/OGR contributors, 2020, GDAL OGR GEOSPATIAL, V0, P0
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Hagolle O, 2010, REMOTE SENS ENVIRON, V114, P1747, DOI 10.1016/j.rse.2010.03.002
   Hansen MC, 2013, SCIENCE, V342, P850, DOI 10.1126/science.1244693
   Hashem Nadeem, 2015, ANNALS OF GIS, V21, P233, DOI 10.1080/19475683.2014.992369
   HELBER P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/IGARSS.2018.8519248
   Henrich V., 2009, 6 EARSEL IMAGING SPE, V0, P0
   Hollstein A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080666
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Nguyen KA, 2019, METHODSX, V6, P862, DOI 10.1016/j.mex.2019.03.023
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kramer O, 2016, STUD BIG DATA, V20, P45, DOI 10.1007/978-3-319-33383-0_5
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kuhn M., 2013, APPL PREDICTIVE MODE, V0, P0, DOI DOI 10.1007/978-1-4614-6849-3
   Lancaster H. O., 2005, ENCY BIOSTATISTICS, V2, P0, DOI 10.1002/0470011815.B2A15018
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li ZW, 2019, ISPRS J PHOTOGRAMM, V150, P197, DOI 10.1016/j.isprsjprs.2019.02.017
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), V0, PP1, DOI 10.1109/ICMB.2014.8
   Liou YIA, 2017, ECOL INDIC, V80, P52, DOI 10.1016/j.ecolind.2017.04.055
   LIU YF, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030444
   Louis J., 2016, P LIVING PLANET S 20, V0, P1
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mohajerani S., 2018, ARXIV 2018 1810 0578, V0, P0
   Mohri M., 2012, FDN MACHINE LEARNING, V31, P32
   Moustakidis S, 2012, IEEE T GEOSCI REMOTE, V50, P149, DOI 10.1109/TGRS.2011.2159726
   Munoz-Mari J, 2012, IEEE T GEOSCI REMOTE, V50, P3751, DOI 10.1109/TGRS.2012.2185504
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Penatti Otavio A. B., 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP44, DOI 10.1109/CVPRW.2015.7301382
   Petrucci B, 2015, PROC SPIE, V9643, P0, DOI 10.1117/12.2194797
   Qiu S, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.024
   Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346
   Rahman A, 2012, J INDIAN SOC REMOTE, V40, P689, DOI 10.1007/s12524-011-0165-4
   Raiyani K., 2020, READY USE MACHINE LE, V0, P0
   Richardson AD, 2002, NEW PHYTOL, V153, P185, DOI 10.1046/j.0028-646X.2001.00289.x
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Russell S.J., 2010, ARTIF INTELL, V0, P0, DOI DOI 10.5555/1671238
   San BT, 2014, INT J APPL EARTH OBS, V26, P399, DOI 10.1016/j.jag.2013.09.010
   Simonyan K, 2015, ARXIV, V0, P0
   Sumbul G, 2019, INT GEOSCI REMOTE SE, V0, PP5901, DOI 10.1109/IGARSS.2019.8900532
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Wright C, 2007, REMOTE SENS ENVIRON, V107, P582, DOI 10.1016/j.rse.2006.10.019
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang Y, 2010, PROC 18 SIGSPATIAL I, V0, P0, DOI DOI 10.1145/1869790.1869829
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhou WX, 2018, ISPRS J PHOTOGRAMM, V145, P197, DOI 10.1016/j.isprsjprs.2018.01.004
   Zhu Z, 2014, REMOTE SENS ENVIRON, V152, P217, DOI 10.1016/j.rse.2014.06.012
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 64
TC 13
Z9 14
U1 2
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN 15
PY 2021
VL 13
IS 2
BP 
EP 
DI 10.3390/rs13020300
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PX7TZ
UT WOS:000611558200001
DA 2023-04-26
ER

PT J
AU Muneer, AS
   Sayl, KN
   Kamal, AH
AF Muneer, Ahmed Shahadha
   Sayl, Khamis Naba
   Kamal, Ammar Hatem
TI Modeling of spatially distributed infiltration in the Iraqi Western Desert
SO APPLIED GEOMATICS
LA English
DT Article
DE Infiltration rate; Double ring infiltrometer; ANN model; RS; GIS; ASAR
ID spectral reflectance property; soil; crusts
AB Infiltration process tends to be one of the most essential elements of the hydrological cycle. Comprehensive and thorough information on soil infiltration in both temporal and spatial territories can support maintaining environmental and hydrological development. Traditional methods to measure soil infiltration are costly, time-consuming, and their facility to regain the spatial and temporal inconsistency, particularly in large scale areas. In this context, remote sensing is capable of providing meaningful information for counting preliminary soil infiltration on various spatial scales via spectral reflectance variability. The present study aims at developing a mathematical model to determine the spatially distributed infiltration using artificial neural networks (ANN) combined with geographical information system (GIS), remote sensing (RS), and field infiltration measurements using a double ring infiltrometer in the Wadi Al-Ratga in the Iraqi western desert. The performance of the proposed model was assessed both qualitatively and quantitatively by comparing the results measured against estimated infiltration rate values for each sample. The distribution of estimated infiltration rate values in dry season varies from 56 to 215 mm/h while the distribution of estimated IR values in wet season varies from 12 to 27 mm/h. The results indicate a good agreement between estimated and measured infiltration (R-2 = 0.8443, mean absolute percent error (MAPE) = 0.0996, root mean square error (RMSE) = 16.8 mm/h, and relative error (RE) less than 20%). Therefore, this comparative method plays for a considerable role in detecting and mapping soil infiltration by providing timely, fast, reparative, and relatively cheap data.
C1 [Muneer, Ahmed Shahadha; Sayl, Khamis Naba; Kamal, Ammar Hatem] Univ Anbar, Coll Engn, Dept Dams & Water Resources Engn, Univ Campus, Ramadi, Anbar, Iraq.
C3 University of Anbar
RP Muneer, AS (corresponding author), Univ Anbar, Coll Engn, Dept Dams & Water Resources Engn, Univ Campus, Ramadi, Anbar, Iraq.
EM ahmedshahadha_ded@uoanbar.edu.iq; khamis.naba@gmail.com; ammar.kamel@uoanbar.edu.iq
CR AL-Rawi, 2008, IRAQI J DESERT STUD, V1, P0
   [Anonymous], 2003, ANN BOOK ASTM STAND, V0, P0
   Ben-Dor E, 2003, SOIL SCI SOC AM J, V67, P289, DOI 10.2136/sssaj2003.0289
   Bouma, 2002, METHODS SOIL ANAL 4, V0, PP797, DOI 10.2136/SSSABOOKSER5.4.C30
   Bouwer H., 1986, METHODS SOIL ANAL, V9, P825, DOI 10.2136/SSSAB00KSER5.1.2ED.C32
   Chang DH, 2000, REMOTE SENS ENVIRON, V74, P534, DOI 10.1016/S0034-4257(00)00144-9
   DEJONG SM, 1992, SOIL TECHNOL, V5, P199, DOI 10.1016/0933-3630(92)90022-S
   Dematte JAM, 2004, GEODERMA, V121, P95, DOI 10.1016/j.geoderma.2003.09.012
   Demuth H., 2001, MATLAB USERS GUIDE, V0, P0
   Eshel G, 2004, SOIL SCI SOC AM J, V68, P1982, DOI 10.2136/sssaj2004.1982
   FAO, 1990, ROM FAO LAND WAT DEV, V0, P0
   Farid HU, 2019, INT J AGR BIOL ENG, V12, P84, DOI 10.25165/j.ijabe.20191203.4015
   Fouad SF., 2010, IRAQI B GEOL MIN, V6, P41
   Goldshleger N, 2009, EUR J SOIL SCI, V60, P1038, DOI 10.1111/j.1365-2389.2009.01162.x
   Goldshleger N., 2012, APPL ENVIRON SOIL SC, V2012, P439567, DOI 10.1155/2012/439567
   Gorunescu F, 2011, INTEL SYST REF LIBR, V0, PP1, DOI 10.1007/978-3-642-19721-5
   Govindaraju RS, 2000, J HYDROL ENG, V5, P115
   Hamza NM, 2007, IRAQI B GEOL MIN, V0, P9
   Hashim H. Q., 2020, INTERNATIONAL JOURNAL OF DESIGN AND NATURE AND ECODYNAMICS, V15, P441, DOI 10.18280/ijdne.150318
   Hashim HQ, 2021, APPL GEOMAT, V13, P235, DOI 10.1007/s12518-020-00342-3
   Hillel D., 1980, APPLICATIONS OF SOIL PHYSICS., V0, P0
   Johonson, 1991, FIELD METHOD MEASURE, V0, P0
   Karandish F, 2016, J HYDROL, V543, P892, DOI 10.1016/j.jhydrol.2016.11.007
   Khudhair M. A., 2020, IOP CONFERENCE SERIES: MATERIALS SCIENCE AND ENGINEERING, V881, P0, DOI 10.1088/1757-899X/881/1/012170
   LAN M, 2020, HYDROL RES, V0, P0
   Moraes AGD, 2020, GEODERMA REG, V20, P0, DOI 10.1016/j.geodrs.2019.e00242
   Mumby PJ, 1999, J ENVIRON MANAGE, V55, P157, DOI 10.1006/jema.1998.0255
   Muneer A. S., 2020, INTERNATIONAL JOURNAL OF DESIGN AND NATURE AND ECODYNAMICS, V15, P691, DOI 10.18280/ijdne.150511
   Padeepz, 2018, INFILTRATION, V0, P0
   PHILIP JR, 1954, SOIL SCI, V77, P153, DOI 10.1097/00010694-195402000-00009
   Raghunath HM, 2006, HYDROLOGY PRINCIPLES, V0, P70
   Sayl KN, 2020, IOP CONF SER-MAT SCI, V737, P0, DOI 10.1088/1757-899X/737/1/012246
   Sayl K, 2020, HYDROLOGY-BASEL, V7, P0, DOI 10.3390/hydrology7030051
   Sayl KN, 2019, P I CIVIL ENG-WAT M, V172, P135, DOI 10.1680/jwama.16.00109
   Sayl KN, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-3193-8
   Sayl KN, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-017-6699-1
   Sayl KN, 2017, HYDROL EARTH SYST SC, V0, PP1, DOI 10.5194/HESS-2017-13
   Sharma SK, 2006, SOIL SCI SOC AM J, V70, P1430, DOI 10.2136/sssaj2005.0087
   Sims DA, 2002, REMOTE SENS ENVIRON, V81, P337, DOI 10.1016/S0034-4257(02)00010-X
   Sissakian VK., 2011, IRAQI B GEOL MIN, V7, P1
   Siyal A., 2002, ASIAN J PLANT SCI, V1, P3, DOI 10.3923/AJPS.2002.3.4
   Sobrinho TA, 2008, SOIL USE MANAGE, V24, P163, DOI 10.1111/j.1475-2743.2008.00150.x
   Sulaiman SO, 2019, ENVIRON EARTH SCI, V78, P0, DOI 10.1007/s12665-019-8510-y
   Thakur JK, 2017, APPL WATER SCI, V7, P1595, DOI 10.1007/s13201-016-0384-5
   TRICKER AS, 1978, J HYDROL, V36, P383, DOI 10.1016/0022-1694(78)90156-7
   USDA (United States Department of Agriculture), 1998, SOIL QUAL INF SHEET, V0, P0
NR 47
TC 7
Z9 7
U1 2
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1866-9298
EI 1866-928X
J9 APPL GEOMAT
JI Appl. Geomat.
PD SEP 15
PY 2021
VL 13
IS 3
BP 467
EP 479
DI 10.1007/s12518-021-00363-6
EA MAR 2021
PG 13
WC Remote Sensing
SC Remote Sensing
GA UC8JK
UT WOS:000623699300001
DA 2023-04-26
ER

PT J
AU Ouzerbane, Z
   Aifa, T
   El Hmaidi, A
   Essahlaoui, A
   Najine, A
AF Ouzerbane, Zakaria
   Aifa, Tahar
   El Hmaidi, Abdellah
   Essahlaoui, Ali
   Najine, Abdessamad
TI A geoelectric study of aquifers in the Essaouira coastal region, Morocco
SO JOURNAL OF AFRICAN EARTH SCIENCES
LA English
DT Article
DE Essaouira Basin; Qsob River; Plio-Pleistocene; Cretaceous; Groundwater; Vertical electrical sounding; Apparent resistivity
ID vertical electrical soundings; artificial neural-networks; resistivity tomography; hydraulic parameters; groundwater; basin; delineation; inversion; zones; ves
AB A geophysical study carried out in the framework of the water resources recognition within the Essaouira coastal area (Morocco) enabled to outline the spatial distribution of the Plio-Pleistocene and Cretaceous formations. It helped to determine the thickness and extension of the main aquifer used for irrigation purpose. The overall aim of this study is to highlight the hydrogeological structures of Essaouira Basin. A total of 45 vertical electrical soundings (VES) were measured using linear Schlumberger array configuration with a maximum half-length (AB/2) of 1000 m along eight sections of 126 km total length. The number of soundings constituting the eight VES profiles depends on the topography and the obstacles encountered. The VES data were processed and interpreted. According to the thematic maps of the study area, the results indicate the existence of three types of VES with apparent resistivity values ranging from 44 to 320 Omega m. In relationship with wells and mechanical drillings existing in the area, the analysis of the results obtained made it possible to derive from the quantitative and qualitative maps the different apparent resistivity variations of the aquifer and aquiclude geological layers. The careful examination of these maps shows that the region around the Qsob River is of interest from a hydrogeological point of view. It is represented by a significant thick layer given the large extension of the resistive Plio-Pleistocene and Cretaceous formations. Geophysical studies show that this region is partially protected from marine intrusion given its location between Tidzi Diapir and hidden diapir from Essaouira which little plays the role of barrier. It is crossed by the Qsob River which lends itself as the main source of both these layers. The electrical discontinuities emerging from the superposition of the different maps, E-W, NE-SW and NNE-SSW oriented, are abundant and dense in the north Haha region (Qsob River). Generally, the salt water circulates along these discontinuities from West to North and Northeast which explains the abundance of low apparent resistivity values recorded northeastwards. This geophysical reconnaissance is the most important for water supply of this area affected by increasingly long periods of drought.
C1 [Ouzerbane, Zakaria; El Hmaidi, Abdellah; Essahlaoui, Ali] Moulay Ismail Univ, Dept Geol, Water Sci & Environm Engn, Fac Sci, BP 11201 Zitoune, Meknes 50070, Morocco.
   [Aifa, Tahar] Univ Rennes, Geosci Rennes, CNRS UMR 6118, Bat 15,Campus Beaulieu, F-35042 Rennes, France.
   [Najine, Abdessamad] Sultan Moulay Slimane Univ, Fac Sci & Technol, Dept Earth Sci, BP 523 Mghila, Beni Mellal 23000, Morocco.
C3 Moulay Ismail University of Meknes; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Earth Sciences & Astronomy (INSU); Universite de Rennes; Sultan Moulay Slimane University of Beni Mellal
RP Aifa, T (corresponding author), Univ Rennes, Geosci Rennes, CNRS UMR 6118, Bat 15,Campus Beaulieu, F-35042 Rennes, France.
EM tahar.aifa@univ-rennes1.fr
FU NATO [983954]; Faculty of Science and Technology, Sultan Moulay Slimane University Beni Mellal (Morocco)
CR Aifa T., 2021, 4 C INT UT SIG MEKN, V0, P141
   Akintorinwa O. J., 2011, JOURNAL OF EMERGING TRENDS IN ENGINEERING AND APPLIED SCIENCES, V2, P858
   Alfaifi H, 2019, ARAB J GEOSCI, V12, P0, DOI 10.1007/s12517-019-4540-8
   Anechana R., 2015, J ENV EARTH SCI, V5, P0
   [Anonymous], 1968, DIRECT CURRENT GEOEL, V0, P0
   Arisona A, 2020, SN APPL SCI, V2, P0, DOI 10.1007/s42452-020-2967-x
   Asfahani J, 2016, J AFR EARTH SCI, V117, P196, DOI 10.1016/j.jafrearsci.2016.01.018
   Attwa M, 2020, J APPL GEOPHYS, V175, P0, DOI 10.1016/j.jappgeo.2020.103992
   Atzemoglou A, 2012, J GEOPHYS ENG, V9, P50, DOI 10.1088/1742-2132/9/1/006
   Bahir M., 2001, J ENV HYDROL, V18, P1
   Bahir M, 2019, CARBONATE EVAPORITE, V34, P709, DOI 10.1007/s13146-019-00497-0
   Basokur AT, 1999, GEOPHYS PROSPECT, V47, P149, DOI 10.1046/j.1365-2478.1999.00123.x
   Bersi M, 2020, J AFR EARTH SCI, V172, P0, DOI 10.1016/j.jafrearsci.2020.104014
   BOSE RN, 1978, J HYDROL, V38, P209, DOI 10.1016/0022-1694(78)90068-9
   Bouhaddioui MEL, 2016, J AFR EARTH SCI, V123, P110, DOI 10.1016/j.jafrearsci.2016.07.015
   BROUGHTON P, 1993, AAPG BULL, V77, P999
   Calow RC, 2010, GROUND WATER, V48, P246, DOI 10.1111/j.1745-6584.2009.00558.x
   Chafouq D, 2018, J AFR EARTH SCI, V139, P1, DOI 10.1016/j.jafrearsci.2017.11.007
   Chamchati H., 2013, JOURNAL OF ENVIRONMENT AND EARTH SCIENCE, V3, P170
   Chandra S, 2012, J EARTH SYST SCI, V121, P1455, DOI 10.1007/s12040-012-0238-y
   Cohen KM, 2013, EPISODES, V36, P199, DOI 10.18814/epiiugs/2013/v36i3/002
   Devi PDS, 2001, ENVIRON GEOL, V40, P1252, DOI 10.1007/s002540100304
   DEY A, 1979, GEOPHYS PROSPECT, V27, P106, DOI 10.1111/j.1365-2478.1979.tb00961.x
   Ebraheem AM, 2012, ENVIRON EARTH SCI, V67, P845, DOI 10.1007/s12665-012-1527-0
   Eluwole AB, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3652-x
   Essahlaoui A., 2003, B ENG GEOL ENVIRON, V62, P155
   Fekri A., 1993, THESIS MARRAKECH, V0, P172
   Flathe H, 1955, GEOPHYS PROSPECT, V3, P95, DOI 10.1111/J.1365-2478.1955.TB01363.X
   Fon A.N, 2012, E CAMEROUN INT J GEO, V3, P960
   Francese R, 2009, HYDROGEOL J, V17, P1233, DOI 10.1007/s10040-009-0435-1
   Fuh S.C., 2019, SEG INT EXP 89 ANN M, V0, PP1179, DOI 10.1190/segam2019-3200645.1
   Geoscan-M Ltd, 2001, IPI2WIN V 2 1 IPI RE, V0, P0
   Ghosh D.P., 1971, GEOPHYS PROSPECT, V19, P192, DOI /10.1111/j.1365-2478.1971.tb00593.x
   Gupta PK, 1997, GEOPHYSICS, V62, P775, DOI 10.1190/1.1444187
   Hafid M, 2000, MAR PETROL GEOL, V17, P409, DOI 10.1016/S0264-8172(98)00081-6
   Himi M, 2017, J AFR EARTH SCI, V126, P136, DOI 10.1016/j.jafrearsci.2016.11.011
   Hodlur GK, 2006, GEOPHYSICS, V71, PG11, DOI 10.1190/1.2169847
   Karroum M, 2017, SCI TOTAL ENVIRON, V609, P1140, DOI 10.1016/j.scitotenv.2017.07.199
   KOSINSKI WK, 1981, GROUND WATER, V19, P163, DOI 10.1111/j.1745-6584.1981.tb03455.x
   Kumar D, 2014, J EARTH SYST SCI, V123, P531, DOI 10.1007/s12040-014-0408-1
   Kumar D, 2010, CURR SCI INDIA, V98, P803
   Mader NK, 2017, J AFR EARTH SCI, V130, P293, DOI 10.1016/j.jafrearsci.2017.02.012
   Manu E., 2016, ELIXIR ENV FOR, V95, P40714
   Mashhadi SR, 2020, ACTA GEOPHYS, V68, P105, DOI 10.1007/s11600-019-00384-1
   MAZAC O, 1985, J HYDROL, V79, P1, DOI 10.1016/0022-1694(85)90178-7
   Medina F., 1994, THESIS, V0, P0
   Ogungbe A. S., 2012, INTERNATIONAL JOURNAL OF GEOMATICS AND GEOSCIENCES, V3, P30
   Okrah C., 2012, JOURNAL OF THE GHANA SCIENCE ASSOCIATION, V14, P56
   Ouhamdouch S., 2018, REVUE DES SCIENCES DE LEAU: JOURNAL OF WATER SCIENCE, V31, P13, DOI 10.7202/1047050ar
   Ouhamdouch S, 2020, CARBONATE EVAPORITE, V36, P0, DOI 10.1007/s13146-020-00663-9
   Ouzerbane Z., 2018, J INT SCI TECHNIQUE, V3, P29
   Ouzerbane Z, 2015, THESIS U MOULAY ISMA, V0, P304
   Ouzerbane Z., 2013, J HYDROCARBONS MINES, V0, P0
   Ouzerbane Z., 2019, J WATER SCI ENV TECH, V4, P480
   Owen RJ, 2006, HYDROGEOL J, V14, P244, DOI 10.1007/s10040-004-0420-7
   Perrone A, 2004, J APPL GEOPHYS, V56, P17, DOI 10.1016/j.jappgeo.2004.03.004
   Piatti C, 2010, NEAR SURF GEOPHYS, V8, P117, DOI 10.3997/1873-0604.2009055
   Pique A, 1998, J GEOL SOC LONDON, V155, P913, DOI 10.1144/gsjgs.155.6.0913
   Pique A, 1996, J GEODYN, V21, P235, DOI 10.1016/0264-3707(95)00022-4
   Pique A., 1994, GEOLOGIE MAROC DOMAI, V0, P0
   Redouani F., 2013, J HYDROCARBONS MINES, V4, P33
   Sainato C, 2003, J S AM EARTH SCI, V16, P177, DOI 10.1016/S0895-9811(03)00027-0
   Sajinkumar KS, 2015, NAT HAZARDS, V75, P755, DOI 10.1007/s11069-014-1342-x
   Sharma P., 1997, ENV ENG GEOPHYS, V0, P0
   Sharma SP, 2005, J APPL GEOPHYS, V57, P155, DOI 10.1016/j.jappgeo.2004.10.003
   Sherif M, 2006, ENVIRON GEOL, V49, P536, DOI 10.1007/s00254-005-0081-4
   Sikah J.N., 2016, J ENV EARTH SCI, V6, P55
   Sinan M., 2009, SEM INT DESS EAUX RE, V0, P12
   Singh UK, 2005, COMPUT GEOSCI-UK, V31, P99, DOI 10.1016/j.cageo.2004.09.014
   Singh UK, 2013, COMPUT GEOSCI-UK, V52, P246, DOI 10.1016/j.cageo.2012.09.018
   Souid A., 1983, THESIS U MONTPELLIER, V0, P0
   Srinivas Y, 2012, GEOSCI FRONT, V3, P729, DOI 10.1016/j.gsf.2012.02.003
   Storz H, 2000, GEOPHYS PROSPECT, V48, P455
   Taj-Eddine K., 1991, THESIS U CADY AYYAD, V0, P285
   URISH DW, 1990, GEOEXPLORATION, V26, P267, DOI 10.1016/0016-7142(90)90008-G
   Wafiq A., 2019, J WATER SCI ENV TECH, V4, P2508
   Yadav GS, 2007, J APPL GEOPHYS, V62, P301, DOI 10.1016/j.jappgeo.2007.01.003
   Yadav GS, 1998, J APPL GEOPHYS, V39, P35, DOI 10.1016/S0926-9851(98)00003-2
   Yadav GS, 1997, J APPL GEOPHYS, V37, P45, DOI 10.1016/S0926-9851(97)00009-8
   Zaidi FK, 2012, ARAB J GEOSCI, V5, P327, DOI 10.1007/s12517-010-0165-7
   ZOHDY AAR, 1989, GEOPHYSICS, V54, P245, DOI 10.1190/1.1442648
NR 82
TC 2
Z9 2
U1 0
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 1464-343X
EI 1879-1956
J9 J AFR EARTH SCI
JI J. Afr. Earth Sci.
PD NOV 15
PY 2021
VL 183
IS 
BP 
EP 
DI 10.1016/j.jafrearsci.2021.104309
EA JUL 2021
PG 18
WC Geosciences, Multidisciplinary
SC Geology
GA UM2JO
UT WOS:000693162900001
DA 2023-04-26
ER

PT J
AU Liu, W
   Xu, JW
   Guo, ZH
   Li, EZ
   Li, X
   Zhang, LP
   Liu, WS
AF Liu, Wei
   Xu, Jiawei
   Guo, Zihui
   Li, Erzhu
   Li, Xing
   Zhang, Lianpeng
   Liu, Wensong
TI Building Footprint Extraction From Unmanned Aerial Vehicle Images Via PRU-Net: Application to Change Detection
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Buildings; Licenses; Semantics; Predictive models; Image segmentation; Data mining; Building footprint change detection; deep convolutional neural network (DCNN); U-Net; unmanned aerial vehicle (UAV) image
ID remote-sensing imagery
AB As the manual detection of building footprint is inefficient and labor-intensive, this study proposed a method of building footprint extraction and change detection based on deep convolutional neural networks. The study modified the existing U-Net model to develop the "PRU-Net" model. PRU-Net incorporates pyramid scene parsing (PSP) to allow multiscale scene parsing, a residual block (RB) in ResNet for feature extraction, and focal loss to address sample imbalance. Within the proposed method, building footprint extraction is conducted as follows: 1) unmanned aerial vehicle images are cropped, denoised, and semantically marked, and datasets are created (including training/validation and prediction datasets); 2) the training/validation and prediction datasets are input into the full convolutional neural network PRU-Net for model training/validation and prediction. Compared with the U-Net, PSP+U-Net (PU-Net), and U-Net++ models, PRU-Net offers improved footprint extraction of buildings with a range of sizes and shapes. The large-scale experimental results demonstrated the effectiveness of the PSP module for multiscale scene analysis and the RB module for feature extraction. After demonstrating the improvements in building extraction offered by PRU-Net, the building footprint results were further processed to generate a building change map.
C1 [Liu, Wei; Xu, Jiawei; Guo, Zihui; Li, Erzhu; Li, Xing; Zhang, Lianpeng; Liu, Wensong] Jiangsu Normal Univ, Sch Geog Geomat & Planning, Xuzhou 221116, Jiangsu, Peoples R China.
C3 Jiangsu Normal University
RP Liu, W (corresponding author), Jiangsu Normal Univ, Sch Geog Geomat & Planning, Xuzhou 221116, Jiangsu, Peoples R China.
EM liuw@jsnu.eud.cn; xujiawei@jsnu.edu.cn; guozihui@jsnu.edu.cn; liezrs2018@jsnu.edu.cn; lixing@jsnu.edu.cn; zhanglp2000@126.com; liuwensongupc@163.com
FU Xuzhou Science and Technology Key R&D Program (Social Development) [KC20172]; Priority Academic Program Development of Jiangsu Higher Education Institutions; State Key Laboratory of Resources and Environmental Information System
CR Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Beumier Charles, 2012, PROGRESS IN PATTERN RECOGNITION, V0, P0
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   [顾炼 Gu Lian], 2020, 自动化学报 ACTA AUTOMATICA SINICA, V46, P1291
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Jabari S, 2019, ISPRS J PHOTOGRAMM, V147, P163, DOI 10.1016/j.isprsjprs.2018.11.014
   Jaturapitpornchai R, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121444
   Ji HY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172832
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Li QY, 2020, IEEE T GEOSCI REMOTE, V58, P7502, DOI 10.1109/TGRS.2020.2973720
   [李炜明 LI Wei-Ming], 2009, 自动化学报 ACTA AUTOMATICA SINICA, V35, P449
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu B, 2017, IEEE GEOSCI REMOTE S, V14, P926, DOI 10.1109/LGRS.2017.2687946
   Liu S., 1900, V10, V0, P4124
   Liu W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242912
   Liu YB, 2018, IEEE J-STARS, V11, P3688, DOI 10.1109/JSTARS.2018.2866284
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lukashevich P, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION AND DIGITAL TECHNOLOGIES (IDT), V0, PP246, DOI 10.1109/DT.2017.8024304
   Majd RD, 2019, IEEE J-STARS, V12, P2627, DOI 10.1109/JSTARS.2019.2924582
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), V0, PP1, DOI 10.1109/ICPHM.2017.7998297
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shi YL, 2019, IEEE GEOSCI REMOTE S, V16, P603, DOI 10.1109/LGRS.2018.2878486
   Solano-Correa YT, 2019, IEEE GEOSCI REMOTE S, V16, P1334, DOI 10.1109/LGRS.2019.2896385
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su HJ, 2020, IEEE T GEOSCI REMOTE, V58, P3778, DOI 10.1109/TGRS.2019.2957135
   Turker M, 2008, INT J REMOTE SENS, V29, P3073, DOI 10.1080/01431160701442096
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Xie C.-W., 2018, VORTEX POOLING IMPRO, V0, P0
   Yang L., 1900, V11, V0, P2600
   Yu F., 2016, INT C LEARN REPR ICL, V0, P1
   Yuan J., 2016, ARXIV PREPRINT ARXIV, V0, P0
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 41
TC 8
Z9 9
U1 3
U2 41
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2236
EP 2248
DI 10.1109/JSTARS.2021.3052495
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QG1UD
UT WOS:000617374800007
DA 2023-04-26
ER

PT J
AU Wittkuhn, L
   Chien, S
   Hall-McMaster, S
   Schuck, NW
AF Wittkuhn, Lennart
   Chien, Samson
   Hall-McMaster, Sam
   Schuck, Nicolas W.
TI Replay in minds and machines
SO NEUROSCIENCE AND BIOBEHAVIORAL REVIEWS
LA English
DT Article
DE Replay; Reinforcement learning; Machine learning; Representation learning; Decision-making
ID sharp-wave-ripple; hippocampal place cells; complementary learning-systems; high-frequency oscillations; memory trace reactivation; medial prefrontal cortex; cognitive map; episodic memory; neural-networks; spatial memory
AB Experience-related brain activity patterns reactivate during sleep, wakeful rest, and brief pauses from active behavior. In parallel, machine learning research has found that experience replay can lead to substantial performance improvements in artificial agents. Together, these lines of research suggest that replay has a variety of computational benefits for decision-making and learning. Here, we provide an overview of putative computational functions of replay as suggested by machine learning and neuroscientific research. We show that replay can lead to faster learning, less forgetting, reorganization or augmentation of experiences, and support planning and generalization. In addition, we highlight the benefits of reactivating abstracted internal representations rather than veridical memories, and discuss how replay could provide a mechanism to build internal representations that improve learning and decision-making.
C1 [Wittkuhn, Lennart; Chien, Samson; Hall-McMaster, Sam; Schuck, Nicolas W.] Max Planck Inst Human Dev, Max Planck Res Grp NeuroCode, Lentzeallee 94, D-14195 Berlin, Germany.
   [Wittkuhn, Lennart; Chien, Samson; Hall-McMaster, Sam; Schuck, Nicolas W.] Max Planck UCL Ctr Computat Psychiat & Ageing Res, Lentzeallee 94, D-14195 Berlin, Germany.
C3 Max Planck Society
RP Wittkuhn, L; Schuck, NW (corresponding author), Max Planck Inst Human Dev, Max Planck Res Grp NeuroCode, Lentzeallee 94, D-14195 Berlin, Germany.; Wittkuhn, L; Schuck, NW (corresponding author), Max Planck UCL Ctr Computat Psychiat & Ageing Res, Lentzeallee 94, D-14195 Berlin, Germany.
EM wittkuhn@mpib-berlin.mpg.de; schuck@mpib-berlin.mpg.de
FU Independent Max Planck Research Group grant - Max Planck Society [M.TN.A. BILD0004]; European Union [ERC-2019-StG REPLAY-852669]; Humboldt Research Fellowship - Alexander von Humboldt Foundation
CR Abdolmaleki Abbas, 2019, ARXIV190912238, V0, P0
   Ambrose RE, 2016, NEURON, V91, P1124, DOI 10.1016/j.neuron.2016.07.047
   Amemiya S, 2016, J NEUROSCI, V36, P814, DOI 10.1523/JNEUROSCI.2595-15.2016
   Andre D, 1998, ADV NEUR IN, V10, P1001
   Andrychowicz M., 2017, ADV NEURAL INFORM PR, V0, P5055
   [Anonymous], 1997, NEURAL COMPUT, V0, P0
   Anthony Thomas, 2017, ADV NEURAL INFORM PR, V0, P0
   Antony JW, 2019, NAT REV NEUROSCI, V20, P506, DOI 10.1038/s41583-019-0191-8
   Aronov D, 2017, NATURE, V543, P719, DOI 10.1038/nature21692
   Atkinson C, 2021, NEUROCOMPUTING, V428, P291, DOI 10.1016/j.neucom.2020.11.050
   Aubin L, 2018, LECT NOTES ARTIF INT, V10928, P16, DOI 10.1007/978-3-319-95972-6_4
   Axmacher N, 2008, BRAIN, V131, P1806, DOI 10.1093/brain/awn103
   Bakkour A, 2019, ELIFE, V8, P0, DOI 10.7554/eLife.46080
   Balaji Yogesh, 2020, ARXIV201002418, V0, P0
   Baram AB, 2021, NEURON, V109, P713, DOI 10.1016/j.neuron.2020.11.024
   Baran B, 2010, EXP BRAIN RES, V203, P471, DOI 10.1007/s00221-010-2242-2
   Barron HC, 2020, CELL, V183, P228, DOI 10.1016/j.cell.2020.08.035
   Bartol TM, 2015, ELIFE, V4, P0, DOI 10.7554/eLife.10778
   Behrens TEJ, 2018, NEURON, V100, P490, DOI 10.1016/j.neuron.2018.10.002
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Bellmund JLS, 2018, SCIENCE, V362, P0, DOI 10.1126/science.aat6766
   Bendor D, 2012, NAT NEUROSCI, V15, P1439, DOI 10.1038/nn.3203
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bhattarai Baburam, 2019, P NATL ACAD SCI, V117, P0
   Bird CM, 2020, CURR OPIN BEHAV SCI, V32, P120, DOI 10.1016/j.cobeha.2020.01.020
   BLISS TVP, 1993, NATURE, V361, P31, DOI 10.1038/361031a0
   Bornstein AM, 2017, NAT COMMUN, V8, P0, DOI 10.1038/ncomms15958
   Bornstein AM, 2017, NAT NEUROSCI, V20, P997, DOI 10.1038/nn.4573
   Bottini R, 2020, TRENDS COGN SCI, V24, P606, DOI 10.1016/j.tics.2020.05.008
   Botvinick M, 2020, NEURON, V107, P603, DOI 10.1016/j.neuron.2020.06.014
   Botvinick M, 2019, TRENDS COGN SCI, V23, P408, DOI 10.1016/j.tics.2019.02.006
   Bragin A, 1999, HIPPOCAMPUS, V9, P137
   Brogden WJ, 1939, J EXP PSYCHOL, V25, P323, DOI 10.1037/h0058944
   Brown TI, 2016, SCIENCE, V352, P1323, DOI 10.1126/science.aaf0784
   Brunec IK, 2018, TRENDS COGN SCI, V22, P637, DOI 10.1016/j.tics.2018.03.013
   Buckner RL, 2010, ANNU REV PSYCHOL, V61, P27, DOI 10.1146/annurev.psych.60.110707.163508
   Budden D., 2018, P INT C LEARN REPR I, V0, P0
   Buhry L, 2011, NEURAL PLAST, V2011, P0, DOI 10.1155/2011/203462
   Bush D, 2015, NEURON, V87, P507, DOI 10.1016/j.neuron.2015.07.006
   BUZSAKI G, 1989, NEUROSCIENCE, V31, P551, DOI 10.1016/0306-4522(89)90423-5
   Buzsaki G, 2015, HIPPOCAMPUS, V25, P1073, DOI 10.1002/hipo.22488
   Cabral HO, 2014, NEURON, V81, P402, DOI 10.1016/j.neuron.2013.11.010
   Caccia Lucas, 2019, ARXIV191108019, V0, P0
   Carey AA, 2019, NAT NEUROSCI, V22, P1450, DOI 10.1038/s41593-019-0464-6
   Carr MF, 2011, NAT NEUROSCI, V14, P147, DOI 10.1038/nn.2732
   Caselles-Dupr Hugo, 2019, ARXIV190209434, V0, P0
   Caselles-Dupre Hugo, 2018, ARXIV181003880, V0, P0
   Caze R, 2018, J NEUROPHYSIOL, V120, P2877, DOI 10.1152/jn.00145.2018
   Cazin N, 2019, PLOS COMPUT BIOL, V15, P0, DOI 10.1371/journal.pcbi.1006624
   Chaudhry A, 2018, LECT NOTES COMPUT SC, V11215, P556, DOI 10.1007/978-3-030-01252-6_33
   Cheng S, 2008, NEURON, V57, P303, DOI 10.1016/j.neuron.2007.11.035
   Clewett D, 2019, HIPPOCAMPUS, V29, P162, DOI 10.1002/hipo.23074
   Cohen N. J., 1993, MEMORY AMNESIA HIPPO, V0, P0
   Constantinescu AO, 2016, SCIENCE, V352, P1464, DOI 10.1126/science.aaf0941
   Corneil D, 2015, ADV NEUR IN, V28, P0
   Csicsvari J, 2007, EUR J NEUROSCI, V26, P704, DOI 10.1111/j.1460-9568.2007.05684.x
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), V0, P2978
   Davidson TJ, 2009, NEURON, V63, P497, DOI 10.1016/j.neuron.2009.07.027
   Daw ND, 2005, NAT NEUROSCI, V8, P1704, DOI 10.1038/nn1560
   DAYAN P, 1993, NEURAL COMPUT, V5, P613, DOI 10.1162/neco.1993.5.4.613
   Deng Xinyi, 2020, VARIABLE CLOCK UNDER, V0, P0, DOI DOI 10.1101/2020.04.10.035980
   Denovellis Eric L., 2020, HIPPOCAMPAL REPLAY E, V0, P0, DOI DOI 10.20.347708
   Deuker L, 2013, J NEUROSCI, V33, P19373, DOI 10.1523/JNEUROSCI.0414-13.2013
   Diba K, 2007, NAT NEUROSCI, V10, P1241, DOI 10.1038/nn1961
   Diekelmann S, 2010, NAT REV NEUROSCI, V11, P114, DOI 10.1038/nrn2762
   Dolan RJ, 2013, NEURON, V80, P312, DOI 10.1016/j.neuron.2013.09.007
   Dragoi G, 2013, P NATL ACAD SCI USA, V110, P9100, DOI 10.1073/pnas.1306031110
   Dragoi G, 2011, NATURE, V469, P397, DOI 10.1038/nature09633
   DuBrow S, 2017, CURR OPIN BEHAV SCI, V17, P141, DOI 10.1016/j.cobeha.2017.08.003
   Duncan KD, 2016, J EXP PSYCHOL GEN, V145, P1420, DOI 10.1037/xge0000231
   Dupret D, 2010, NAT NEUROSCI, V13, P995, DOI 10.1038/nn.2599
   Ego-Stengel V, 2010, HIPPOCAMPUS, V20, P1, DOI 10.1002/hipo.20707
   Eichenbaum H, 2015, NAT NEUROSCI, V18, P1701, DOI 10.1038/nn.4180
   Eldar E, 2020, ELIFE, V9, P0, DOI 10.7554/eLife.56911
   Epstein RA, 2017, NAT NEUROSCI, V20, P1504, DOI 10.1038/nn.4656
   Erdem UM, 2012, EUR J NEUROSCI, V35, P916, DOI 10.1111/j.1460-9568.2012.08015.x
   Eschenko O, 2008, LEARN MEMORY, V15, P222, DOI 10.1101/lm.726008
   Espeholt L, 2018, PR MACH LEARN RES, V80, P0
   Euston DR, 2007, SCIENCE, V318, P1147, DOI 10.1126/science.1148979
   Evans Talfan, 2019, ADV NEURAL INFORM PR, V0, P1729
   Farooq U, 2019, NEURON, V103, P719, DOI 10.1016/j.neuron.2019.05.040
   Favila SE, 2020, TRENDS NEUROSCI, V43, P939, DOI 10.1016/j.tins.2020.09.006
   Favila SE, 2016, NAT COMMUN, V7, P0, DOI 10.1038/ncomms11066
   Fedus W, 2020, PR MACH LEARN RES, V119, P0
   Feld GB, 2017, CURR OPIN NEUROBIOL, V44, P20, DOI 10.1016/j.conb.2017.02.012
   Findlay Graham, 2020, SLEEP ADV, V1, Pzpab002, DOI 10.1093/sleepadvances/zpab002
   Flesch T, 2018, P NATL ACAD SCI USA, V115, PE10313, DOI 10.1073/pnas.1800755115
   Foster DJ, 2017, ANNU REV NEUROSCI, V40, P581, DOI 10.1146/annurev-neuro-072116-031538
   Foster DJ, 2012, CURR OPIN NEUROBIOL, V22, P294, DOI 10.1016/j.conb.2011.12.005
   Foster DJ, 2006, NATURE, V440, P680, DOI 10.1038/nature04587
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Fyhn M, 2007, NATURE, V446, P190, DOI 10.1038/nature05601
   Gagne C, 2018, CURR OPIN BEHAV SCI, V24, P89, DOI 10.1016/j.cobeha.2018.03.013
   Garcia J, 2015, J MACH LEARN RES, V16, P1437
   Gardner MPH, 2018, P ROY SOC B-BIOL SCI, V285, P0, DOI 10.1098/rspb.2018.1645
   Garvert MM, 2017, ELIFE, V6, P0, DOI 10.7554/eLife.17086
   Gaussier P, 2002, BIOL CYBERN, V86, P15, DOI 10.1007/s004220100269
   Genzel L, 2020, PHILOS T R SOC B, V375, P0, DOI 10.1098/rstb.2020.0001
   Gerrard JL, 2001, BEHAV NEUROSCI, V115, P1180, DOI 10.1037//0735-7044.115.6.1180
   Gershman SJ, 2017, ANNU REV PSYCHOL, V68, P101, DOI 10.1146/annurev-psych-122414-033625
   Gershman SJ, 2014, PLOS COMPUT BIOL, V10, P0, DOI 10.1371/journal.pcbi.1003939
   Gershman SJ, 2010, CURR OPIN NEUROBIOL, V20, P251, DOI 10.1016/j.conb.2010.02.008
   Girardeau G, 2017, NAT NEUROSCI, V20, P1634, DOI 10.1038/nn.4637
   Girardeau G, 2009, NAT NEUROSCI, V12, P1222, DOI 10.1038/nn.2384
   Gomperts SN, 2015, ELIFE, V4, P0, DOI 10.7554/eLife.05360
   Gridchyn I, 2020, NEURON, V106, P291, DOI 10.1016/j.neuron.2020.01.021
   Gruber MJ, 2016, NEURON, V89, P1110, DOI 10.1016/j.neuron.2016.01.017
   Gulati T, 2017, NAT NEUROSCI, V20, P1277, DOI 10.1038/nn.4601
   Guo XX, 2014, ADV NEUR IN, V27, P0
   Guo Zhaohan Daniel, 2020, PROC INT C MACH LEAR, V119, P3875
   Gupta AS, 2010, NEURON, V65, P695, DOI 10.1016/j.neuron.2010.01.034
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Haga T, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.34171
   Hardt O, 2013, TRENDS COGN SCI, V17, P111, DOI 10.1016/j.tics.2013.01.001
   Harvey CD, 2012, NATURE, V484, P62, DOI 10.1038/nature10918
   Hassabis D, 2007, TRENDS COGN SCI, V11, P299, DOI 10.1016/j.tics.2007.05.001
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011
   Hausknecht M., 2015, PROC AAAI FALL S SER, V0, P0
   Hayes Tyler L., 2019, ARXIV191002509, V0, P0
   Helfrich RF, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-11444-x
   Heller AS, 2020, JAMA PSYCHIAT, V77, P431, DOI 10.1001/jamapsychiatry.2019.4788
   Herszage J, 2018, NEUROSCIENCE, V392, P270, DOI 10.1016/j.neuroscience.2018.08.006
   Hessel M, 2018, AAAI CONF ARTIF INTE, V0, P3215
   HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831
   Hoffman KL, 2002, SCIENCE, V297, P2070, DOI 10.1126/science.1073538
   Hoydal OA, 2019, NATURE, V568, P400, DOI 10.1038/s41586-019-1077-7
   Igloi K, 2015, ELIFE, V4, P0, DOI 10.7554/eLife.07903
   Iscen Ahmet, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12361), V0, PP699, DOI 10.1007/978-3-030-58517-4_41
   Jackson JC, 2006, J NEUROSCI, V26, P12415, DOI 10.1523/JNEUROSCI.4118-06.2006
   Jadhav SP, 2016, NEURON, V90, P113, DOI 10.1016/j.neuron.2016.02.010
   Jadhav SP, 2012, SCIENCE, V336, P1454, DOI 10.1126/science.1217230
   Jafarpour A, 2017, ENEURO, V4, P0, DOI 10.1523/ENEURO.0171-17.2017
   Ji DY, 2007, NAT NEUROSCI, V10, P100, DOI 10.1038/nn1825
   Johnson A, 2007, J NEUROSCI, V27, P12176, DOI 10.1523/JNEUROSCI.3761-07.2007
   Joo HR, 2018, NAT REV NEUROSCI, V19, P744, DOI 10.1038/s41583-018-0077-1
   Kaefer K, 2020, NEURON, V106, P154, DOI 10.1016/j.neuron.2020.01.015
   Kaiser L, 2019, INT C LEARN REPR, V0, P0
   Kaplan R, 2020, COGN NEUROSCI-UK, V11, P122, DOI 10.1080/17588928.2019.1676711
   Kaplan R, 2017, TRENDS NEUROSCI, V40, P256, DOI 10.1016/j.tins.2017.03.002
   Kapturowski S., 2019, INT C LEARN REPR, V0, P1
   Karlsson MP, 2009, NAT NEUROSCI, V12, P913, DOI 10.1038/nn.2344
   Kay K, 2020, CELL, V180, P552, DOI 10.1016/j.cell.2020.01.014
   Khamassi M, 2020, BIOL CYBERN, V114, P231, DOI 10.1007/s00422-020-00817-x
   Khamassi M, 2012, FRONT BEHAV NEUROSCI, V6, P0, DOI 10.3389/fnbeh.2012.00079
   King C, 1999, J PHYSIOL-LONDON, V521, P159, DOI 10.1111/j.1469-7793.1999.00159.x
   Klinzing JG, 2019, NAT NEUROSCI, V22, P1598, DOI 10.1038/s41593-019-0467-3
   Kudrimoti HS, 1999, J NEUROSCI, V19, P4090
   Kuhl BA, 2010, NAT NEUROSCI, V13, P501, DOI 10.1038/nn.2498
   Kumaran D, 2016, TRENDS COGN SCI, V20, P512, DOI 10.1016/j.tics.2016.05.004
   Kumaran D, 2012, PSYCHOL REV, V119, P573, DOI 10.1037/a0028681
   Kumaran D, 2012, FRONT HUM NEUROSCI, V6, P0, DOI 10.3389/fnhum.2012.00157
   Kurth-Nelson Z, 2016, NEURON, V91, P194, DOI 10.1016/j.neuron.2016.05.028
   Lansink CS, 2008, J NEUROSCI, V28, P6372, DOI 10.1523/JNEUROSCI.1054-08.2008
   Lansink CS, 2009, PLOS BIOL, V7, P0, DOI 10.1371/journal.pbio.1000173
   Lee AK, 2002, NEURON, V36, P1183, DOI 10.1016/S0896-6273(02)01096-6
   Lee SW, 2015, PLOS BIOL, V13, P0, DOI 10.1371/journal.pbio.1002137
   Leibold C, 2020, NEURAL NETWORKS, V124, P328, DOI 10.1016/j.neunet.2020.01.014
   Lengyel Mate, 2007, ADV NEURAL INFORM PR, V0, P889
   Leong YC, 2017, NEURON, V93, P451, DOI 10.1016/j.neuron.2016.12.040
   Lewis PA, 2019, CURR BIOL, V29, PR906, DOI 10.1016/j.cub.2019.08.019
   Lewis PA, 2018, TRENDS COGN SCI, V22, P491, DOI 10.1016/j.tics.2018.03.009
   LIN LJ, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P781
   LIN LJ, 1992, MACH LEARN, V8, P293, DOI 10.1007/BF00992699
   Lin Long-Ji, 1993, P TECHN REP DTIC DOC, V0, P0, DOI DOI 10.5555/168871
   Lipton Zachary C., 2016, ARXIVCSLG161101211, V0, P0
   Liu BY, 2019, CONFERENCE PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON CONTROL, V0, P336, DOI 10.1109/ICCAR.2019.8813352
   Liu YZ, 2021, ELIFE, V10, P0, DOI 10.7554/eLife.66917
   Liu YZ, 2021, SCIENCE, V372, P807, DOI 10.1126/science.abf1357
   Liu YZ, 2019, CELL, V178, P640, DOI 10.1016/j.cell.2019.06.012
   Louie K, 2001, NEURON, V29, P145, DOI 10.1016/S0896-6273(01)00186-6
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   MacDonald CJ, 2011, NEURON, V71, P737, DOI 10.1016/j.neuron.2011.07.012
   Magee JC, 1997, SCIENCE, V275, P209, DOI 10.1126/science.275.5297.209
   Mahadevan S, 2007, J MACH LEARN RES, V8, P2169
   MARR D, 1971, PHILOS T ROY SOC B, V262, P23, DOI 10.1098/rstb.1971.0078
   Mattar MG, 2018, NAT NEUROSCI, V21, P1609, DOI 10.1038/s41593-018-0232-z
   Maurer AP, 2021, TRENDS COGN SCI, V25, P187, DOI 10.1016/j.tics.2020.12.007
   McClelland James Lloyd, 2020, PSYARXIV, V0, P0, DOI DOI 10.31234/osf.io/3m5sb
   MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419
   Mccloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI 10.1016/S0079-7421(08)60536-8
   McDevitt EA, 2015, NEUROBIOL LEARN MEM, V122, P51, DOI 10.1016/j.nlm.2014.11.015
   McNamara CG, 2014, NAT NEUROSCI, V17, P1658, DOI 10.1038/nn.3843
   Michon F, 2019, CURR BIOL, V29, P1436, DOI 10.1016/j.cub.2019.03.048
   Miller KJ, 2021, CURR OPIN BEHAV SCI, V38, P29, DOI 10.1016/j.cobeha.2020.07.003
   MINSKY M, 1961, P IRE, V49, P8, DOI 10.1109/JRPROC.1961.287775
   Mnih V., 2016, PROC INT C MACH LEAR, V48, P1928
   Mnih V., 2013, PLAYING ATARI DEEP R, V0, P0, DOI DOI 10.1038/NATURE14236
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mobbs D, 2020, TRENDS COGN SCI, V24, P228, DOI 10.1016/j.tics.2019.12.016
   Moerland Thomas M., 2020, ARXIV200616712, V0, P0
   Momennejad I, 2017, NAT HUM BEHAV, V1, P680, DOI 10.1038/s41562-017-0180-8
   Momennejad I, 2020, CURR OPIN BEHAV SCI, V32, P155, DOI 10.1016/j.cobeha.2020.02.017
   Momennejad I, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.32548
   Monaco JD, 2014, NAT NEUROSCI, V17, P725, DOI 10.1038/nn.3687
   MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1023/A:1022635613229
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723
   Muenzinger KF, 1936, J COMP PSYCHOL, V22, P79, DOI 10.1037/h0057664
   Munos Remi, 2016, ARXIV160602647, V0, P0
   Nadasdy Z, 1999, J NEUROSCI, V19, P9497
   Nieh EH, 2021, NATURE, V595, P80, DOI 10.1038/s41586-021-03652-7
   Niethard N, 2020, NEURON, V106, P204, DOI 10.1016/j.neuron.2020.03.034
   Niv Y, 2019, NAT NEUROSCI, V22, P1544, DOI 10.1038/s41593-019-0470-8
   Niv Y, 2015, J NEUROSCI, V35, P8145, DOI 10.1523/JNEUROSCI.2978-14.2015
   Norman Y, 2019, SCIENCE, V365, P657, DOI 10.1126/science.aax1030
   OKeefe J., 1974, NEW SCIENTIST, V62, P749
   OKeefe J, 2021, PHYSIOL REV, V101, P1427, DOI 10.1152/physrev.00014.2020
   ONeill J, 2017, SCIENCE, V355, P184, DOI 10.1126/science.aag2787
   ONeill J, 2008, NAT NEUROSCI, V11, P209, DOI 10.1038/nn2037
   ONeill J, 2010, TRENDS NEUROSCI, V33, P220, DOI 10.1016/j.tins.2010.01.006
   OReilly RC, 2014, COGNITIVE SCI, V38, P1229, DOI 10.1111/j.1551-6709.2011.01214.x
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   OKEEFE J, 1978, EXP BRAIN RES, V31, P573
   Olafsdottir HF, 2018, CURR BIOL, V28, PR37, DOI 10.1016/j.cub.2017.10.073
   Olafsdottir HF, 2017, NEURON, V96, P925, DOI 10.1016/j.neuron.2017.09.035
   Olafsdottir HF, 2016, NAT NEUROSCI, V19, P792, DOI 10.1038/nn.4291
   Olafsdottir HF, 2015, ELIFE, V4, P0, DOI 10.7554/eLife.06063
   OREILLY RC, 1994, HIPPOCAMPUS, V4, P661, DOI 10.1002/hipo.450040605
   Oudiette D, 2013, TRENDS COGN SCI, V17, P142, DOI 10.1016/j.tics.2013.01.006
   Pan YC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P4794
   Papale AE, 2016, NEURON, V92, P975, DOI 10.1016/j.neuron.2016.10.028
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Parisotto E., 2019, ARXIV191006764, V0, P0
   PAVLIDES C, 1989, J NEUROSCI, V9, P2907
   Peer M, 2021, TRENDS COGN SCI, V25, P37, DOI 10.1016/j.tics.2020.10.004
   Pellegrini L., 2019, ARXIV191201100, V0, P0
   Peng J., 1993, ADAPT BEHAV, V1, P437, DOI 10.1177/105971239300100403
   Pennartz CMA, 2004, J NEUROSCI, V24, P6446, DOI 10.1523/JNEUROSCI.0575-04.2004
   Peyrache A, 2009, NAT NEUROSCI, V12, P919, DOI 10.1038/nn.2337
   Pezzulo G, 2019, CURR OPIN BEHAV SCI, V29, P69, DOI 10.1016/j.cobeha.2019.04.009
   Pezzulo G, 2014, TRENDS COGN SCI, V18, P647, DOI 10.1016/j.tics.2014.06.011
   Pfeiffer BE, 2013, NATURE, V497, P74, DOI 10.1038/nature12112
   Plaunt Christian, 2010, ICAPS 10 POMDP PRACT, V0, P0
   Pomponi J, 2020, NEUROCOMPUTING, V397, P139, DOI 10.1016/j.neucom.2020.01.093
   Pong V., 2018, ICLR, V0, P1
   Qin YL, 1997, PHILOS T R SOC B, V352, P1525, DOI 10.1098/rstb.1997.0139
   Ramanathan DS, 2015, PLOS BIOL, V13, P0, DOI 10.1371/journal.pbio.1002263
   Rasch B, 2007, CURR OPIN NEUROBIOL, V17, P698, DOI 10.1016/j.conb.2007.11.007
   RATCLIFF R, 1990, PSYCHOL REV, V97, P285, DOI 10.1037/0033-295X.97.2.285
   Redish A D, 1999, COGNITIVE MAP PLACE, V0, P0
   Redish AD, 2016, NAT REV NEUROSCI, V17, P147, DOI 10.1038/nrn.2015.30
   Redish AD, 1998, NEURAL COMPUT, V10, P73, DOI 10.1162/089976698300017908
   Richmond LL, 2017, TRENDS COGN SCI, V21, P962, DOI 10.1016/j.tics.2017.08.005
   Roscow E., 2019, BIORXIV PREPR, V0, P0, DOI DOI 10.1101/716290
   Rothschild G, 2017, NAT NEUROSCI, V20, P251, DOI 10.1038/nn.4457
   Rouhani N, 2020, COGNITION, V203, P0, DOI 10.1016/j.cognition.2020.104269
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russek EM, 2017, PLOS COMPUT BIOL, V13, P0, DOI 10.1371/journal.pcbi.1005768
   Salakhutdinov Ruslan, 2019, P C NEUR INF PROC SY, V0, P0
   Schafer M, 2018, NEURON, V100, P476, DOI 10.1016/j.neuron.2018.10.006
   Schapiro AC, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-06213-1
   Schapiro AC, 2017, PHILOS T R SOC B, V372, P0, DOI 10.1098/rstb.2016.0049
   Schapiro AC, 2013, NAT NEUROSCI, V16, P486, DOI 10.1038/nn.3331
   Schaul T., 2016, INT C LEARN REPR ICL, V0, P0
   Schmidt B, 2019, J NEUROPHYSIOL, V121, P1981, DOI 10.1152/jn.00793.2018
   Schmidt C, 2006, J NEUROSCI, V26, P8976, DOI 10.1523/JNEUROSCI.2464-06.2006
   Schuck N.W., 2018, GOAL DIRECTED DECISI, V0, PP259, DOI 10.1016/B978-0-12-812098-9.00012-7
   Schuck NW, 2019, SCIENCE, V364, P1254, DOI 10.1126/science.aaw5181
   Schuck NW, 2016, NEURON, V91, P1402, DOI 10.1016/j.neuron.2016.08.019
   Schuck NW, 2015, NEURON, V86, P331, DOI 10.1016/j.neuron.2015.03.015
   SCOVILLE WB, 1957, J NEUROL NEUROSUR PS, V20, P11, DOI 10.1136/jnnp.20.1.11
   Sharpe MJ, 2017, NAT NEUROSCI, V20, P735, DOI 10.1038/nn.4538
   Shin H., 2017, ADV NEURAL INFORM PR, V0, P0
   Shin JD, 2019, NEURON, V104, P1110, DOI 10.1016/j.neuron.2019.09.012
   Shin YS, 2021, TOP COGN SCI, V13, P106, DOI 10.1111/tops.12505
   Silva D, 2015, NAT NEUROSCI, V18, P1772, DOI 10.1038/nn.4151
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Singer AC, 2013, NEURON, V77, P1163, DOI 10.1016/j.neuron.2013.01.027
   Singer AC, 2009, NEURON, V64, P910, DOI 10.1016/j.neuron.2009.11.016
   Skaggs WE, 1996, SCIENCE, V271, P1870, DOI 10.1126/science.271.5257.1870
   Spiers HJ, 2020, TRENDS COGN SCI, V24, P168, DOI 10.1016/j.tics.2019.12.013
   SQUIRE LR, 1992, PSYCHOL REV, V99, P195, DOI 10.1037/0033-295X.99.2.195
   Staba RJ, 2002, J NEUROPHYSIOL, V88, P1743, DOI 10.1152/jn.2002.88.4.1743
   Stachenfeld KL, 2017, NAT NEUROSCI, V20, P1643, DOI 10.1038/nn.4650
   Staresina BP, 2015, NAT NEUROSCI, V18, P1679, DOI 10.1038/nn.4119
   Staresina BP, 2013, P NATL ACAD SCI USA, V110, P21159, DOI 10.1073/pnas.1311989110
   Steiner AP, 2012, FRONT NEUROSCI-SWITZ, V6, P0, DOI 10.3389/fnins.2012.00131
   Stella F, 2019, NEURON, V102, P450, DOI 10.1016/j.neuron.2019.01.052
   Stoianov I., 2021, PROG NEUROBIOL, V0, P0, DOI DOI 10.1101/2020.01.16.908889
   Sun C, 2020, NAT NEUROSCI, V23, P651, DOI 10.1038/s41593-020-0614-x
   Sutherland GR, 2000, CURR OPIN NEUROBIOL, V10, P180, DOI 10.1016/S0959-4388(00)00079-9
   Sutton R. S., 1990, MACHINE LEARNING: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE (1990), V0, P216
   Sutton R.S., 1991, ACM SIGART B, V2, P160, DOI 10.1145/122344.122377
   Sutton Richard S., 2012, ARXIV12063285, V0, P0
   Sutton RS, 2018, ADAPT COMPUT MACH LE, V0, P1
   Swanson RA, 2020, CURR OPIN BEHAV SCI, V32, P126, DOI 10.1016/j.cobeha.2020.02.008
   Tambini A, 2019, TRENDS COGN SCI, V23, P876, DOI 10.1016/j.tics.2019.07.008
   Tambini A, 2017, SCI REP-UK, V7, P0, DOI 10.1038/s41598-017-15608-x
   Tambini A, 2013, P NATL ACAD SCI USA, V110, P19591, DOI 10.1073/pnas.1308499110
   Tambini A, 2010, NEURON, V65, P280, DOI 10.1016/j.neuron.2010.01.001
   Tang WB, 2021, ELIFE, V10, P0, DOI 10.7554/eLife.66227
   Tang WB, 2019, NEUROBIOL LEARN MEM, V160, P11, DOI 10.1016/j.nlm.2018.01.002
   Tang WB, 2017, J NEUROSCI, V37, P11789, DOI 10.1523/JNEUROSCI.2291-17.2017
   Tang Y, 2001, SYNAPSE, V41, P258, DOI 10.1002/syn.1083
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343
   Tolman EC, 1938, PSYCHOL REV, V45, P1, DOI 10.1037/h0062733
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Tolman EC, 1926, PSYCHOL REV, V33, P352, DOI 10.1037/h0070532
   Tompary A, 2017, NEURON, V96, P228, DOI 10.1016/j.neuron.2017.09.005
   Trettel SG, 2019, NAT NEUROSCI, V22, P609, DOI 10.1038/s41593-019-0359-6
   van de Ven GM, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-17866-2
   van de Ven GM, 2016, NEURON, V92, P968, DOI 10.1016/j.neuron.2016.10.020
   Van de Ven Gido M, 2018, ARXIV180910635, V0, P0
   van Hasselt, 2019, ARXIV190605243, V0, P0
   van Seijen H, 2015, PR MACH LEARN RES, V37, P2314
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vaz AP, 2020, SCIENCE, V367, P1131, DOI 10.1126/science.aba0672
   Vaz AP, 2019, SCIENCE, V363, P975, DOI 10.1126/science.aau8956
   Vertes Eszter, 2019, ADV NEURAL INFORM PR, V32, P13714
   Wang Shaoming, 2020, PSYARXIV, V0, P0, DOI DOI 10.31234/osf.io/5vksj
   Wang Z., 2016, ARXIV161101224, V0, P0
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wayne G., 2018, ARXIV180310760, V0, P0
   Whittington JCR, 2020, CELL, V183, P1249, DOI 10.1016/j.cell.2020.10.024
   Wikenheiser AM, 2017, NEURON, V95, P1197, DOI 10.1016/j.neuron.2017.08.003
   Wikenheiser AM, 2016, NAT REV NEUROSCI, V17, P513, DOI 10.1038/nrn.2016.56
   Wikenheiser AM, 2015, CURR OPIN NEUROBIOL, V32, P8, DOI 10.1016/j.conb.2014.10.002
   Wikenheiser AM, 2015, NAT NEUROSCI, V18, P289, DOI 10.1038/nn.3909
   Wikenheiser AM, 2013, HIPPOCAMPUS, V23, P22, DOI 10.1002/hipo.22049
   WILSON MA, 1994, SCIENCE, V265, P676, DOI 10.1126/science.8036517
   Wilson RC, 2014, NEURON, V81, P267, DOI 10.1016/j.neuron.2013.11.005
   Wimmer GE, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-10597-z
   Wimmer G. Elliott, 2020, REACTIVATION PAIN RE, V0, P0, DOI DOI 10.1101/2020.05.29.123893
   Wittkuhn L, 2021, NAT COMMUN, V12, P0, DOI 10.1038/s41467-021-21970-2
   Wolosin SM, 2012, J COGNITIVE NEUROSCI, V24, P1532, DOI 10.1162/jocn_a_00237
   Wood ER, 2000, NEURON, V27, P623, DOI 10.1016/S0896-6273(00)00071-4
   Wu CT, 2017, NAT NEUROSCI, V20, P571, DOI 10.1038/nn.4507
   Wu Qingyang, 2020, ARXIV201006891, V0, P0
   Yu JY, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-04498-w
   Yu JY, 2015, NEUROBIOL LEARN MEM, V117, P34, DOI 10.1016/j.nlm.2014.02.002
   Zhang H, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-06553-y
   Zhang H, 2017, STUD NEUROSCI, V0, PP251, DOI 10.1007/978-3-319-45066-7_15
   Zhang S, 2017, ARXIV171201275, V0, P0
   Zielinski MC, 2020, HIPPOCAMPUS, V30, P60, DOI 10.1002/hipo.22821
NR 335
TC 10
Z9 10
U1 8
U2 21
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0149-7634
EI 1873-7528
J9 NEUROSCI BIOBEHAV R
JI Neurosci. Biobehav. Rev.
PD OCT 15
PY 2021
VL 129
IS 
BP 367
EP 388
DI 10.1016/j.neubiorev.2021.08.002
EA AUG 2021
PG 22
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA UK8TW
UT WOS:000692239200009
PM 34371078
DA 2023-04-26
ER

PT J
AU Sood, V
   Gusain, HS
   Gupta, S
   Taloor, AK
   Singh, S
AF Sood, Vishakha
   Gusain, Hemendra Singh
   Gupta, Sheifali
   Taloor, Ajay Kumar
   Singh, Sartajvir
TI Detection of snow/ice cover changes using subpixel-based change detection approach over Chhota-Shigri glacier, Western Himalaya, India
SO QUATERNARY INTERNATIONAL
LA English
DT Article
DE Snow; ice cover; Subpixel based change detection; Glacier; Western Himalayas; Change vector analysis (CVA)
ID change vector analysis; himachal-pradesh; mass-balance; land-use; algorithm; performance; velocity; melt
AB Mapping and monitoring of the glacier changes over different regions of Earth surface is a challenging task due to regional rugged topography and climate conditions. This study focused on the monitoring of snow or ice cover changes over Chhota-Shigri glacier, Western Himalaya, India. A subpixel-based change detection (SCD) approach is proposed, aiming to identify the transition zones (mixed pixels) between the two class categories. The SCD approach involves the integration of subpixel classification and change vector analysis (CVA) to define the changes in the form of magnitude and direction between two multitemporal dates at the subpixel level. To check the efficacy of proposed SCD, experimental outcomes have also been compared with existing neural-network (NN) based SCD (NN-SCD). The result analysis has shown that proposed SCD achieved better accuracy (84.80%) as compared to NN-SCD (78.80%). In addition, a time series data was acquired using the Landsat series (Landsat 5, 7 and 8 as per availability) to perform the trend analysis over Chhota-Shigri glacier, during the period 2001?2019. This study offers the effective way of estimating the bi-temporal snow/ice changes especially over rugged terrains around the globe.
C1 [Sood, Vishakha; Gupta, Sheifali] Chitkara Univ, Inst Engn & Technol, Rajpura 140401, Punjab, India.
   [Gusain, Hemendra Singh] DRDO, Snow & Avalanche Study Estab, Chandigarh 160017, India.
   [Taloor, Ajay Kumar] Univ Jammu, Dept Remote Sensing, Jammu 180006, Jammu & Kashmir, India.
   [Taloor, Ajay Kumar] Univ Jammu, GIS, Jammu 180006, Jammu & Kashmir, India.
   [Singh, Sartajvir] Chitkara Univ, Sch Engn & Technol, Haryana 174103, Himachal Prades, India.
C3 Chitkara University, Punjab; Defence Research & Development Organisation (DRDO); Snow & Avalanche Study Establishment (SASE); University of Jammu; University of Jammu
RP Sood, V (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura 140401, Punjab, India.
EM vishakha.sood@chitkara.edu.in; hs.gusain@sase.drdo.in; sheifali.gupta@chitkara.edu.in; ajaytaloor@gmail.com; sartajvir.singh@chitkarauniversity.edu.in
CR Azam MF, 2019, J HYDROL, V574, P760, DOI 10.1016/j.jhydrol.2019.04.075
   Azam MF, 2014, ANN GLACIOL, V55, P69, DOI 10.3189/2014AoG66A104
   Berthier E, 2007, REMOTE SENS ENVIRON, V108, P327, DOI 10.1016/j.rse.2006.11.017
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Chen J, 2011, IEEE GEOSCI REMOTE S, V8, P317, DOI 10.1109/LGRS.2010.2068537
   Dewi RS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9020147
   Du PJ, 2020, ISPRS J PHOTOGRAMM, V161, P278, DOI 10.1016/j.isprsjprs.2020.01.026
   Du PJ, 2014, GEO-SPAT INF SCI, V17, P26, DOI 10.1080/10095020.2014.889268
   Gantayat P, 2017, ANN GLACIOL, V58, P136, DOI 10.1017/aog.2017.21
   Garg PK, 2017, GEOMORPHOLOGY, V284, P99, DOI 10.1016/j.geomorph.2016.10.022
   Gusain HS, 2016, COLD REG SCI TECHNOL, V126, P22, DOI 10.1016/j.coldregions.2016.02.012
   Kargel JS, 2005, REMOTE SENS ENVIRON, V99, P187, DOI 10.1016/j.rse.2005.07.004
   Kulkarni AV, 2011, INT J REMOTE SENS, V32, P601, DOI 10.1080/01431161.2010.517802
   Kumar V, 2011, INT J DIGIT EARTH, V4, P78, DOI 10.1080/17538940903521591
   Ling F, 2012, IEEE GEOSCI REMOTE S, V9, P408, DOI 10.1109/LGRS.2011.2169934
   Malila W. A., 1980, SIXTH ANNUAL SYMPOSIUM ON MACHINE PROCESSING OF REMOTELY SENSED DATA AND SOIL INFORMATION SYSTEMS AND REMOTE SENSING AND SOIL SURVEY, V0, P326
   Mishra VD, 2010, ANN GLACIOL, V51, P153, DOI 10.3189/172756410791386526
   Mishra VD, 2009, INT J REMOTE SENS, V30, P4707, DOI 10.1080/01431160802651959
   Nichol J, 2006, INT J REMOTE SENS, V27, P629, DOI 10.1080/02781070500293414
   Nijhawan R., 2016, PERSPECT SCI, V8, P381, DOI 10.1016/j.pisc.2016.04.081
   Ramsankaran RAAJ, 2018, INT J REMOTE SENS, V39, P3320, DOI 10.1080/01431161.2018.1441563
   Singh P, 2005, J HYDROL, V300, P140, DOI 10.1016/j.jhydrol.2004.06.005
   Singh S, 2019, ADV SPACE RES, V64, P314, DOI 10.1016/j.asr.2019.04.016
   Singh S, 2018, METEOROL ATMOS PHYS, V130, P125, DOI 10.1007/s00703-016-0494-5
   Singh S, 2017, J MT SCI-ENGL, V14, P1391, DOI 10.1007/s11629-016-4248-0
   Singh S, 2015, J GEOL SOC INDIA, V86, P52, DOI 10.1007/s12594-015-0280-x
   Sood V, 2018, J INDIAN SOC REMOTE, V46, P1991, DOI 10.1007/s12524-018-0861-4
   Sood V, 2018, HIMAL GEOL, V39, P223
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Tiwari RK, 2014, CURR SCI INDIA, V106, P853
   Varshney A, 2012, REMOTE SENS LETT, V3, P605, DOI 10.1080/01431161.2011.648281
   Wagnon P, 2007, J GLACIOL, V53, P603, DOI 10.3189/002214307784409306
   Wu K, 2017, IEEE GEOSCI REMOTE S, V14, P1750, DOI 10.1109/LGRS.2017.2733558
   Wu K, 2017, IEEE GEOSCI REMOTE S, V14, P796, DOI 10.1109/LGRS.2017.2657378
   Yellala A, 2019, INT J REMOTE SENS, V40, P5861, DOI 10.1080/01431161.2019.1584685
NR 35
TC 23
Z9 23
U1 3
U2 25
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 1040-6182
EI 1873-4553
J9 QUATERN INT
JI Quat. Int.
PD FEB 20
PY 2021
VL 575
IS 
BP 204
EP 212
DI 10.1016/j.quaint.2020.05.016
EA MAR 2021
PG 9
WC Geography, Physical; Geosciences, Multidisciplinary
SC Physical Geography; Geology
GA RB2LZ
UT WOS:000631947400001
DA 2023-04-26
ER

PT J
AU Hsu, SY
   Jura, B
   Shih, MH
   Meyrand, P
   Tsai, FS
   Bem, T
AF Hsu, Sheng-Yi
   Jura, Bartosz
   Shih, Mau-Hsiang
   Meyrand, Pierre
   Tsai, Feng-Sheng
   Bem, Tiaza
TI Recognition of post-learning alteration of hippocampal ripples by convolutional neural network differs in the wild-type and AD mice
SO SCIENTIFIC REPORTS
LA English
DT Article
ID sharp-wave-ripple; reactivation; disruption; memory; replay; age
AB Evidence indicates that sharp-wave ripples (SWRs) are primary network events supporting memory processes. However, some studies demonstrate that even after disruption of awake SWRs the animal can still learn spatial task or that SWRs may be not necessary to establish a cognitive map of the environment. Moreover, we have found recently that despite a deficit of sleep SWRs the APP/PS1 mice, a model of Alzheimer's disease, show undisturbed spatial reference memory. Searching for a learning-related alteration of SWRs that could account for the efficiency of memory in these mice we use convolutional neural networks (CNN) to discriminate pre- and post-learning 256 ms samples of LFP signals, containing individual SWRs. We found that the fraction of samples that were correctly recognized by CNN in majority of discrimination sessions was equal to -50% in the wild-type (WT) and only 14% in APP/PS1 mice. Moreover, removing signals generated in a close vicinity of SWRs significantly diminished the number of such highly recognizable samples in the WT but not in APP/PS1 group. These results indicate that in WT animals a large subset of SWRs and signals generated in their proximity may contain learning-related information whereas such information seem to be limited in the AD mice.
C1 [Hsu, Sheng-Yi; Tsai, Feng-Sheng] China Med Univ, Dept Biomed Imaging & Radiol Sci, Taichung 40402, Taiwan.
   [Hsu, Sheng-Yi; Shih, Mau-Hsiang; Tsai, Feng-Sheng] China Med Univ Hosp, Res Ctr Interneural Comp, Taichung 40447, Taiwan.
   [Jura, Bartosz; Bem, Tiaza] Polish Acad Sci, Nalecz Inst Biocybernet & Biomed Engn, Ks Trojdena 4, PL-02109 Warsaw, Poland.
   [Meyrand, Pierre] Univ Bordeaux, INSERM, U1215, Neuroctr Magendie, Bordeaux, France.
   [Jura, Bartosz] Jagiellonian Univ, Inst Appl Psychol, Krakow, Poland.
C3 China Medical University Taiwan; China Medical University Taiwan; China Medical University Hospital - Taiwan; Polish Academy of Sciences; Nalecz Institute of Biocybernetics & Biomedical Engineering of the Polish Academy of Sciences; Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; Universite de Bordeaux; Jagiellonian University
RP Bem, T (corresponding author), Polish Acad Sci, Nalecz Inst Biocybernet & Biomed Engn, Ks Trojdena 4, PL-02109 Warsaw, Poland.
EM tiaza.bem@ibib.waw.pl
FU Ministry of Science and Technology, Taiwan; China Medical University [CMU105-N-19]; Ministry of Education and Science, Poland
CR Altimus Cara, 2015, MOL NEUROPSYCHIATRY, V1, P52
   Bragin A, 2002, J NEUROSCI, V22, P2012, DOI 10.1523/JNEUROSCI.22-05-02012.2002
   Buzsaki G, 2015, HIPPOCAMPUS, V25, P1073, DOI 10.1002/hipo.22488
   Cho K, 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/V1/D14-1179
   Colgin LL, 2016, NAT REV NEUROSCI, V17, P239, DOI 10.1038/nrn.2016.21
   Ego-Stengel V, 2010, HIPPOCAMPUS, V20, P1, DOI 10.1002/hipo.20707
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Eschenko O, 2008, LEARN MEMORY, V15, P222, DOI 10.1101/lm.726008
   Gerrard JL, 2008, J NEUROSCI, V28, P7883, DOI 10.1523/JNEUROSCI.1265-08.2008
   Gillespie AK, 2016, NEURON, V90, P740, DOI 10.1016/j.neuron.2016.04.009
   Girardeau G, 2009, NAT NEUROSCI, V12, P1222, DOI 10.1038/nn.2384
   Goodfellow I., 2018, DEEP LEARNING, V1373, P68009
   Gupta AS, 2010, NEURON, V65, P695, DOI 10.1016/j.neuron.2010.01.034
   Jadhav SP, 2012, SCIENCE, V336, P1454, DOI 10.1126/science.1217230
   Joo HR, 2018, NAT REV NEUROSCI, V19, P744, DOI 10.1038/s41583-018-0077-1
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Jura B, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-56582-w
   Karlsson MP, 2009, NAT NEUROSCI, V12, P913, DOI 10.1038/nn.2344
   Kay K, 2019, HIPPOCAMPUS, V29, P184, DOI 10.1002/hipo.22956
   Kovacs KA, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0164675
   Lagadec S, 2012, NEUROBIOL AGING, V33, P0, DOI 10.1016/j.neurobiolaging.2010.07.023
   Laredo D., 2020, INT J DYN CONTROL, V8, P1063, DOI 10.1007/S40435-020-00708-W
   Nicole O, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep22728
   Nokia MS, 2012, FRONT BEHAV NEUROSCI, V6, P0, DOI 10.3389/fnbeh.2012.00084
   Pfeiffer BE, 2013, NATURE, V497, P74, DOI 10.1038/nature12112
   Poo MM, 2016, BMC BIOL, V14, P0, DOI 10.1186/s12915-016-0261-6
   Rothschild G, 2019, NEUROBIOL LEARN MEM, V160, P58, DOI 10.1016/j.nlm.2018.03.019
   Rothschild G, 2017, NAT NEUROSCI, V20, P251, DOI 10.1038/nn.4457
   Skelin I, 2019, NEUROBIOL LEARN MEM, V160, P21, DOI 10.1016/j.nlm.2018.04.004
   Valero M, 2017, NEURON, V94, P1234, DOI 10.1016/j.neuron.2017.05.032
   Wiegand JPL, 2016, J NEUROSCI, V36, P5650, DOI 10.1523/JNEUROSCI.3069-15.2016
   Witton J, 2016, J PHYSIOL-LONDON, V594, P4615, DOI 10.1113/jphysiol.2014.282889
   Zhang YC, 2017, PR MACH LEARN RES, V54, P83
NR 33
TC 0
Z9 0
U1 1
U2 3
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
EI 
J9 SCI REP-UK
JI Sci Rep
PD OCT 28
PY 2021
VL 11
IS 1
BP 
EP 
DI 10.1038/s41598-021-00598-8
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA WO6LX
UT WOS:000712564800021
PM 34711860
DA 2023-04-26
ER

PT J
AU Khalil, U
   Aslam, B
   Azam, U
   Khalid, HMD
AF Khalil, Umer
   Aslam, Bilal
   Azam, Umar
   Khalid, Hafiz Muhammad Daniyal
TI Time Series Analysis of Land Surface Temperature and Drivers of Urban Heat Island Effect Based on Remotely Sensed Data to Develop a Prediction Model
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
ID vegetation index; satellite data; cover; city; impacts; area
AB The local climate of cities is changing, and one of the primary reasons for this change is rapid urbanization. The Lahore district is situated in the Punjab province of Pakistan and is mainly comprised of Lahore city. This city is among the fastest expanding cities in Pakistan. Due to this rapid urbanization, the natural land surfaces are being altered, harming the local environment and thus causing the urban heat island (UHI) effect. For the analysis of the UHI effect, the fundamental and essential step is assessing the land surface temperature (LST). Therefore, the current investigation assessed LST to evaluate the UHI effect of the Lahore district. This study used the remote sensing data retrieved from the Advanced Spaceborne Thermal Emission and Reflection Radiometer Global Digital Elevation Model (ASTER GDEM) and Moderate-Resolution Imaging Spectroradiometer (MODIS) sensor. Different new generation algorithms were initially used, but a convolutional neural network (CNN) model was used based on the accuracy. The model was developed by utilizing the past 19 years' LST values along with elevation, road density (RD), and enhanced vegetation index (EVI) as input parameters for analyzing and predicting the LST. The LST data of the year 2020 was used for the validation of the outcomes of the CNN model. Among the model predicted LST and observed LST, a high correlation was noticed. The mean absolute percentage error (MAPE), mean absolute error (MAE), and mean squared error (MSE) for the considered two different periods (January and May) were also computed for both the training and validation processes. The prediction error for most parts of the district was within 0.1 K of the observed values. Hence, the formulated CNN model can be utilized as an essential tool for analyzing and predicting LST and thus for the evaluation of the UHI effect at any location.
C1 [Khalil, Umer] Comsats Univ Islamabad, Dept Civil Engn, Wah Campus, Wah Cantt, Pakistan.
   [Aslam, Bilal] Riphah Int Univ, Dept Data Sci, Islamabad Campus, Islamabad, Pakistan.
   [Azam, Umar] Comsats Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
   [Khalid, Hafiz Muhammad Daniyal] Natl Univ Modern Languages Islamabad, Dept Management Sci, Islamabad Campus, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI)
RP Aslam, B (corresponding author), Riphah Int Univ, Dept Data Sci, Islamabad Campus, Islamabad, Pakistan.
EM bilalaslam45@gmail.com
CR Ahmed B, 2013, REMOTE SENS-BASEL, V5, P5969, DOI 10.3390/rs5115969
   Akbari H, 1995, COOLING OUR COMMUNIT, V0, P0
   Al Rakib A, 2020, 1 INT STUD RES C, V0, P0
   [Anonymous], 2012, ADV NEURAL INFORM PR, V0, P0
   Bhattacharjee S, 2014, IEEE T GEOSCI REMOTE, V52, P4771, DOI 10.1109/TGRS.2013.2284489
   Buyantuyev A, 2010, LANDSCAPE ECOL, V25, P17, DOI 10.1007/s10980-009-9402-4
   Carlson TN, 1997, REMOTE SENS ENVIRON, V62, P241, DOI 10.1016/S0034-4257(97)00104-1
   Chen XL, 2006, REMOTE SENS ENVIRON, V104, P133, DOI 10.1016/j.rse.2005.11.016
   Cheval S, 2009, THEOR APPL CLIMATOL, V96, P145, DOI 10.1007/s00704-008-0019-3
   Fan C, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9070672
   Feng YJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020182
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gallo KP, 1996, INT J REMOTE SENS, V17, P3071, DOI 10.1080/01431169608949128
   Grimm NB, 2008, SCIENCE, V319, P756, DOI 10.1126/science.1150195
   Guha S, 2022, GEOCARTO INT, V37, P2252, DOI 10.1080/10106049.2020.1815867
   Hengl T, 2012, THEOR APPL CLIMATOL, V107, P265, DOI 10.1007/s00704-011-0464-2
   HUETE A, 1994, REMOTE SENS ENVIRON, V49, P224, DOI 10.1016/0034-4257(94)90018-3
   Hulley G, 2014, REMOTE SENS ENVIRON, V140, P755, DOI 10.1016/j.rse.2013.10.014
   Hung T, 2006, INT J APPL EARTH OBS, V8, P34, DOI 10.1016/j.jag.2005.05.003
   Imran M, 2020, ARAB J GEOSCI, V13, P0, DOI 10.1007/s12517-020-5214-2
   Khanderwal S, 2010, P EARSEL S PAR FRANC, V0, P177
   Landsberg H.E., 1981, URBAN CLIM, V0, P84
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lemus-Canovas M, 2020, SCI TOTAL ENVIRON, V699, P0, DOI 10.1016/j.scitotenv.2019.134307
   Levermore G, 2018, URBAN CLIM, V24, P360, DOI 10.1016/j.uclim.2017.02.004
   Liang BQ, 2008, J URBAN PLAN DEV, V134, P129, DOI 10.1061/(ASCE)0733-9488(2008)134:3(129)
   Mathew A, 2019, SOL ENERGY, V186, P404, DOI 10.1016/j.solener.2019.04.001
   Mathew A, 2018, ENERG BUILDINGS, V159, P271, DOI 10.1016/j.enbuild.2017.10.062
   Mathew A, 2016, ENERG BUILDINGS, V128, P605, DOI 10.1016/j.enbuild.2016.07.004
   Murmu L., 2018, ASIAN J GEOINFORM, V17, P14
   Mushore TD, 2017, BUILD ENVIRON, V122, P397, DOI 10.1016/j.buildenv.2017.06.033
   Notaro M, 2005, 2005B43B0261 AGUFM, V0, P0
   Owen TW, 1998, INT J REMOTE SENS, V19, P1663, DOI 10.1080/014311698215171
   Pu RL, 2006, REMOTE SENS ENVIRON, V104, P211, DOI 10.1016/j.rse.2005.09.022
   Rinner C, 2011, REMOTE SENS-BASEL, V3, P1251, DOI 10.3390/rs3061251
   Sarrat C, 2006, ATMOS ENVIRON, V40, P1743, DOI 10.1016/j.atmosenv.2005.11.037
   Sekertekin A, 2021, ECOL INDIC, V122, P0, DOI 10.1016/j.ecolind.2020.107230
   Shirazi S.A., 2016, ECOL PROCESS, V0, PP1, DOI 10.1186/s13717-016-0050-8
   Taha H, 1997, ENERG BUILDINGS, V25, P99, DOI 10.1016/S0378-7788(96)00999-1
   Tiangco M, 2008, INT J REMOTE SENS, V29, P2799, DOI 10.1080/01431160701408360
   Tsendbazar NE, 2015, REMOTE SENS-BASEL, V7, P15804, DOI 10.3390/rs71215804
   Ullah S, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11195492
   Van Leeuwen W, 1999, MODIS VEGETATION IND, V0, P1200
   Voogt JA, 2003, REMOTE SENS ENVIRON, V86, P370, DOI 10.1016/S0034-4257(03)00079-8
   Wang S, 1989, J S CHINA NORMAL U, V0, P41
   Weng Q, 2001, INT J REMOTE SENS, V22, P1999, DOI 10.1080/713860788
   Weng QH, 2004, REMOTE SENS ENVIRON, V89, P467, DOI 10.1016/j.rse.2003.11.005
   Weng QH, 2006, PHOTOGRAMM ENG REM S, V72, P1275, DOI 10.14358/PERS.72.11.1275
   Wu CS, 2004, REMOTE SENS ENVIRON, V93, P480, DOI 10.1016/j.rse.2004.08.003
   Yu X, 2020, MATH PROBL ENG, V2020, P0, DOI 10.1155/2020/6387173
   Yuan F, 2007, REMOTE SENS ENVIRON, V106, P375, DOI 10.1016/j.rse.2006.09.003
   Zhao HM, 2005, INT GEOSCI REMOTE SE, V0, P1666
NR 52
TC 6
Z9 6
U1 7
U2 22
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD DEC 15
PY 2021
VL 35
IS 15
BP 1803
EP 1828
DI 10.1080/08839514.2021.1993633
EA OCT 2021
PG 26
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA 0W9BU
UT WOS:000710037200001
DA 2023-04-26
ER

PT J
AU Wan, XC
   Wan, JH
   Xu, MM
   Liu, SW
   Sheng, H
   Chen, YL
   Zhang, XY
AF Wan, Xianci
   Wan, Jianhua
   Xu, Mingming
   Liu, Shanwei
   Sheng, Hui
   Chen, Yanlong
   Zhang, Xiyuan
TI Enteromorpha Coverage Information Extraction by 1D-CNN and Bi-LSTM Networks Considering Sample Balance From GOCI Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Data mining; Vegetation mapping; Indexes; Feature extraction; Satellites; Information retrieval; Monitoring; Enteromorpha prolifera (EP); geostationary ocean color imager (GOCI); neural network; sample balance
ID floating macroalgae blooms; convolutional neural-network; yellow sea; ulva-prolifera; green-algae; resolution; biomass
AB Remote sensing technology is widely used for the dynamic monitoring of Enteromorpha prolifera (EP) blooms due to its high temporal resolution and large scale monitoring. Recently, deep learning(DL) methods have been applied to EP analysis due to their excellent feature representation. However, EP information extraction methods based on DL from low-spatial-resolution satellite images are still immature. The main problems with such methods include the insufficiency of spectral and spatial feature learning in low-resolution satellite images, as well as the sample imbalance that DL-based neural networks face in EP information extraction. To solve the above problems, a neural network-based EP extraction method considering sample balance is proposed in this article and named EP rough-then-accurate extraction network. The method consists of two components: EP rough extraction, a strategy that attends to sample balance, and EP accurate extraction, a deep neural network based on one-dimensional convolutional neural network and bidirectional long short-term memory (Bi-LSTM), which fully considers the learned spectral information of each pixel and interpixel contextual dependencies. Geostationary Ocean Color Imager images with 500-m resolution were applied as the LR images in the experiments. The experimental results show that the proposed method has the capability to enhance adaptability in areas with different EP densities (achieving stable and excellent performance) and exhibits at least a 10% gain in F1-score and at least a 6% gain in IoU in extracting EP coverage information over other representative and traditional EP extraction methods in the Yellow Sea region.
C1 [Wan, Xianci; Wan, Jianhua; Xu, Mingming; Liu, Shanwei; Sheng, Hui; Zhang, Xiyuan] China Univ Petr East China, Coll Oceanog & Space Informat, Qingdao 266580, Peoples R China.
   [Chen, Yanlong] Natl Marine Environm Monitoring Ctr, Dalian 116023, Peoples R China.
C3 China University of Petroleum; National Marine Environmental Monitoring Center
RP Wan, JH; Xu, MM (corresponding author), China Univ Petr East China, Coll Oceanog & Space Informat, Qingdao 266580, Peoples R China.
EM z19160019@s.upc.edu.cn; wjh66310@163.com; xumingming900405@126.com; shanweiliu@163.com; sheng@upc.edu.cn; ylchen@nmemc.org.cn; 17685881565@163.com
FU National Natural Science Foundation of China [41776182]; Shandong Provincial Natural Science Foundation of China [ZR2019MD023, Y9I0300H22]
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cao HY, 2020, ECOL INFORM, V60, P0, DOI 10.1016/j.ecoinf.2020.101156
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen XY, 2019, ANAL METHODS-UK, V11, P5118, DOI 10.1039/c9ay01531k
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cui TW, 2020, APPL OPTICS, V59, PC70, DOI 10.1364/AO.382081
   Gao YH, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3097093
   Garcia RA, 2013, J GEOPHYS RES-OCEANS, V118, P26, DOI 10.1029/2012JC008292
   Hu C., 2008, EOS T AM GEOPHYS UN, V0, PP302, DOI 10.1029/2008EO330002
   Hu CM, 2009, REMOTE SENS ENVIRON, V113, P2118, DOI 10.1016/j.rse.2009.05.012
   Hu LB, 2019, REMOTE SENS ENVIRON, V223, P194, DOI 10.1016/j.rse.2019.01.014
   Huang X G., 2019, P SPIE 11150 REMOTE, V0, P297
   Kim E, 2020, KOREAN J REMOTE SENS, V36, P293, DOI 10.7780/kjrs.2020.36.2.2.6
   Kim SM, 2019, J COASTAL RES, V0, PP302, DOI 10.2112/SI90-038.1
   Lee J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071097
   Li L, 2018, ATMOS OCEAN, V56, P296, DOI 10.1080/07055900.2018.1509834
   Li L, 2018, IEEE J-STARS, V11, P1397, DOI 10.1109/JSTARS.2018.2806626
   Li XF, 2020, NATL SCI REV, V7, P1584, DOI 10.1093/nsr/nwaa047
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1264
   Liu X, 2017, IET IMAGE PROCESS, V11, P1068, DOI 10.1049/iet-ipr.2016.1095
   Luo CY, 2021, IEEE J-STARS, V14, P843, DOI 10.1109/JSTARS.2020.3040648
   Lyu H, 2017, INT J REMOTE SENS, V38, P4069, DOI 10.1080/01431161.2017.1312621
   Ng W, 2019, GEODERMA, V352, P251, DOI 10.1016/j.geoderma.2019.06.016
   Pan B, 2017, IEEE J-STARS, V10, P437, DOI 10.1109/JSTARS.2016.2585161
   Powers D. M. W., 2011, J MACH LEARN TECHNOL, V2, P37
   Qiu ZF, 2018, OPT EXPRESS, V26, P26810, DOI 10.1364/OE.26.026810
   Safari K, 2021, IEEE GEOSCI REMOTE S, V18, P167, DOI 10.1109/LGRS.2020.2966987
   Salah LB, 2019, INT RENEW ENERG CONG, V0, P0
   Shen H, 2014, MAR POLLUT BULL, V78, P190, DOI 10.1016/j.marpolbul.2013.10.044
   Simonyan K, 2015, ARXIV, V0, P0
   Son YB, 2015, REMOTE SENS ENVIRON, V156, P21, DOI 10.1016/j.rse.2014.09.024
   Son Young Baek, 2012, OCEAN SCIENCE JOURNAL, V47, P359, DOI 10.1007/s12601-012-0034-2
   Song DB, 2017, PROC SPIE, V10405, P0, DOI 10.1117/12.2272518
   Sun K, 2019, PROC CVPR IEEE, V0, PP5686, DOI 10.1109/CVPR.2019.00584
   Wang Q, 2022, IEEE T NEUR NET LEAR, V33, P1414, DOI 10.1109/TNNLS.2020.3042276
   Wang XP, 2017, SCI REP-UK, V7, P0, DOI 10.1038/s41598-017-12853-y
   Xiao YF, 2019, MAR POLLUT BULL, V140, P330, DOI 10.1016/j.marpolbul.2019.01.037
   Xiao YF, 2017, INT J REMOTE SENS, V38, P1626, DOI 10.1080/01431161.2017.1286056
   Xing QG, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111279
   Xing QG, 2017, IEEE GEOSCI REMOTE S, V14, P1815, DOI 10.1109/LGRS.2017.2737079
   Xu FX, 2018, MAR POLLUT BULL, V128, P408, DOI 10.1016/j.marpolbul.2018.01.061
   Xu FX, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.012007
   Yang J, 2019, P I MECH ENG E-J PRO, V233, P1217, DOI 10.1177/0954408919862718
   Zhang MM, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3093334
   Zhang YC, 2014, IEEE J-STARS, V7, P3060, DOI 10.1109/JSTARS.2014.2327076
   Zhao XD, 2020, IEEE T GEOSCI REMOTE, V58, P7355, DOI 10.1109/TGRS.2020.2982064
   Zhen Z, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8040333
NR 47
TC 5
Z9 5
U1 5
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9306
EP 9317
DI 10.1109/JSTARS.2021.3110854
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UU5SL
UT WOS:000698859700008
DA 2023-04-26
ER

PT J
AU Aydinoglu, AC
   Alturk, G
AF Aydinoglu, Arif Cagdas
   Alturk, Gehver
TI Producing Landslide Susceptibility Maps Using Statistics and Machine Learning Techniques: The Rize-Taslidere Basin Example
SO JOURNAL OF GEOGRAPHY-COGRAFYA DERGISI
LA English
DT Article
DE Landslide Susceptibility; Neural Networks; Logistic Regression
ID artificial neural-networks; logistic-regression; conditional-probability; sampling strategy; gis; turkey; region; river; roads
AB As a disaster type, landslides cause significant life and economic losses; hence, producing landslide susceptibility maps is a priority research topic. This study aims to perform a landslide susceptibility analysis for shallow landslides by using statistics and machine learning techniques and evaluate the model performance using the Rize-Talidere Basin as an example. First, literature was examined. Next, a detailed research was performed on the study area characteristics and the landslide inventory creation. Fifteen parameters (i.e., land use, lithology, elevation, slope, aspect, roughness, plan curvature, profile curvature, stream erosion index, topographic humidity index, sediment-carrying capacity, drainage density, distance to drainage, road density, and distance to road) produced by the geographic information system techniques were used as the input parameters in producing the landslide susceptibility map. Using the landslide inventory and input parameters, a parameter analysis was performed for the landslide susceptibility map in five classes by employing the frequency ratio (FR), logistic regression (LR), and artificial neural network (ANN) methods. The area under the curve and the area under the relative operating curve (AUC) were used to evaluate the model performance. The results show FR of 0.72, LR of 0.83, and ANN of 0.87. Although the ANN technique provided results with a higher accuracy, the LR technique that was near accurate was usable.
C1 [Aydinoglu, Arif Cagdas] Gebze Tekn Univ, Harita Muhendisligi Bolumu, Kocaeli, Turkey.
   [Alturk, Gehver] TC Tarim & Orman Bakanligi, Collesme & Erozyonla Mucadele Gen Mudurlugu, Ankara, Turkey.
C3 Gebze Technical University
RP Alturk, G (corresponding author), TC Tarim & Orman Bakanligi, Collesme & Erozyonla Mucadele Gen Mudurlugu, Ankara, Turkey.
EM gehveralturk@gmail.com
CR Aleotti P., 1999, B ENG GEOL ENVIRON, V58, P21, DOI 10.1007/s100640050066
   Alkevli T, 2015, HEYELAN DUYARLILIK H, V0, P0
   Alturk G., 2019, COGRAFYA DERGISI J G, V0, P0, DOI DOI 10.26650/JGEOG2021-814561
   [Anonymous], 2018, WEB, V0, P0
   [Anonymous], 1990, NEUROCOMPUTING, V0, P0
   Arca D, 2017, TMMOB HARITA KADASTR, V0, P0
   Ayalew L, 2005, GEOMORPHOLOGY, V65, P15, DOI 10.1016/j.geomorph.2004.06.010
   Ayalew L, 2004, LANDSLIDES, V1, P73, DOI 10.1007/s10346-003-0006-9
   Barling R., 1992, THESIS U MELBOURNE, V0, P0
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Beven K., 1979, HYDROLOG SCI J, V24, P43, DOI 10.1080/02626667909491834
   Bonham-Carter G. F., 1994, GEOGRAPHIC INFORM SY, V0, P0
   Can A., 2014, THESIS HACETTEPE U, V0, P0
   Can T., 2016, SINIRLARI BAZINDA HE, V0, P0
   CEMGM, 2016, GIR IL BUL HAVZ HEYE, V0, P0
   CEMGM, 2016, RIZ IL GUN MIKR HEYE, V0, P0
   Cruden D., 1991, B INT ASS ENG GEOL, V43, P27, DOI 10.1007/BF02590167
   DeLeo J. M., 1993, 1993 PROCEEDINGS SECOND INTERNATIONAL SYMPOSIUM ON UNCERTAINTY MODELING AND ANALYSIS, V0, PP318, DOI 10.1109/ISUMA.1993.366750
   Eker A., 2012, GAZI U MUH MIM FAK D, V27, P163
   Ercanoglu M, 2005, NAT HAZARD EARTH SYS, V5, P979, DOI 10.5194/nhess-5-979-2005
   Ercanoglu M, 2011, ENVIRON EARTH SCI, V64, P949, DOI 10.1007/s12665-011-0912-4
   Erinc S., 1965, YAGIS MUESSIRIYETI U, V0, P0
   Evans I. S, 1972, SPATIAL ANAL GEOMORP, V0, P17
   Frehner M., 2007, SUSTAINABILITY SUCCE, V0, P0
   Furniss M.J., 1991, AMERICAN FISHERIES SOCIETY SPECIAL PUBLICATION, V0, P297
   Gedikoglu A., 1979, TECTONIC EVOLUTION E, V0, P68
   Gokceoglu C., 2001, B EARTH SCI, V22, P189
   Gomez H, 2005, ENG GEOL, V78, P11, DOI 10.1016/j.enggeo.2004.10.004
   Guven, 1998, TRABZON C30 D30 PAFT, V0, P0
   HARR RD, 1993, FISHERIES, V18, P18, DOI 10.1577/1548-8446(1993)018<0018:SFRTHR>2.0.CO;2
   HORTON RE, 1945, GEOL SOC AM BULL, V56, P275, DOI 10.1130/0016-7606(1945)56[275:edosat]2.0.co;2
   Hosmer D, 2013, APPL LOGITIC REGRESS, V0, P0
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Kaastra I, 1996, NEUROCOMPUTING, V10, P215, DOI 10.1016/0925-2312(95)00039-9
   Konar A, 2005, COMPUTATIONAL INTELL, V0, P0
   Larsen MC, 1997, EARTH SURF PROC LAND, V22, P835, DOI 10.1002/(SICI)1096-9837(199709)22:9&lt;835::AID-ESP782&gt;3.0.CO;2-C
   Lee S, 2005, ENVIRON GEOL, V47, P982, DOI 10.1007/s00254-005-1228-z
   Lee S, 2003, EARTH SURF PROC LAND, V28, P1361, DOI 10.1002/esp.593
   Milewski I., 2009, SCI S GEOGRAPHY SUST, V0, P455
   MOORE ID, 1986, WATER RESOUR RES, V22, P1350, DOI 10.1029/WR022i008p01350
   MOORE ID, 1992, J SOIL WATER CONSERV, V47, P423
   MOORE ID, 1991, HYDROL PROCESS, V5, P3, DOI 10.1002/hyp.3360050103
   Nefeslioglu HA, 2008, ENG GEOL, V97, P171, DOI 10.1016/j.enggeo.2008.01.004
   Negnevitsky M., 2002, ARTIF INTELL, V0, P0
   OGM, 2007, ORM GEN MUD AM PLAN, V0, P0
   Okay I., 1997, AAPG MEMOIR, V0, P0
   Ozdemir A., 2008, ZEMIN MEKANIGI ZEMIN, V0, P0
   Ozsayar T., 1981, KARADENIZ TECH U J E, V0, P65
   Saha AK, 2002, INT J REMOTE SENS, V23, P357, DOI 10.1080/01431160010014260
   Saroglu F, 1986, MADEN TETKIK ARAMA D, V107, P70
   Soeters R., 1996, SLOPE INSTABILITY RE, V0, P0
   Tekin S, 2019, BILGE INT J SCI TECH, V3, P21
   Tekin S, 2015, MUHJEO 2015 UL MUH J, V0, P137
   Uzunsoy M, 1985, HAVZA ISLAHINDA TEME, V0, P0
   VARNES D. J., 1978, LANDSLIDES ANAL CONT, V0, PP11, DOI 10.4236/ADR.2017.53016
   Wang C., 1994, THEORY GEN LEARNING, V0, P0
   Wilson JP, 2000, TERRAIN ANAL PRINCIP, V0, P0
   WYTHOFF BJ, 1993, CHEMOMETR INTELL LAB, V18, P115, DOI 10.1016/0169-7439(93)80052-J
   Yalcin A, 2008, CATENA, V72, P1, DOI 10.1016/j.catena.2007.01.003
   Yeon YK, 2010, ENG GEOL, V116, P274, DOI 10.1016/j.enggeo.2010.09.009
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Yilmaz I., 1998, MTA DERGISI, V108, P0
   Yilmaz I, 2010, ENVIRON EARTH SCI, V61, P821, DOI 10.1007/s12665-009-0394-9
   Yilmaz I, 2010, ENVIRON EARTH SCI, V60, P505, DOI 10.1007/s12665-009-0191-5
   Yuksel N, 2007, EGE COGRAFYA DERGISI, V23, P19
NR 65
TC 0
Z9 0
U1 1
U2 5
PU ISTANBUL UNIV, FAC LETTERS, DEPT GEOGRAPHY
PI ISTANBUL
PA ORDU CAD. NO 196, 34459 LALEL, ISTANBUL, 00000, TURKEY
SN 1302-7212
EI 1305-2128
J9 J GEOGR-ISTANBUL
JI J. Geogr.
PD JUN 15
PY 2021
VL 0
IS 43
BP 159
EP 176
DI 10.26650/JGEOG2021-814561
PG 18
WC Geography
SC Geography
GA ZD3ZG
UT WOS:000758139000003
DA 2023-04-26
ER

PT J
AU Szwed, P
AF Szwed, Piotr
TI Classification and feature transformation with Fuzzy Cognitive Maps
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Fuzzy Cognitive Maps; Classification; Feature transformation
ID convergence; algorithms
AB Fuzzy Cognitive Maps (FCMs) are considered a soft computing technique combining elements of fuzzy logic and recurrent neural networks. They found multiple application in such domains as modeling of system behavior, prediction of time series, decision making and process control. Less attention, however, has been turned towards using them in pattern classification. In this work we propose an FCM based classifier with a fully connected map structure. In contrast to methods that expect reaching a steady system state during reasoning, we chose to execute a few FCM iterations (steps) before collecting output labels. Weights were learned with a gradient algorithm and logloss or cross-entropy were used as the cost function. Our primary goal was to verify, whether such design would result in a descent general purpose classifier, with performance comparable to off the shelf classical methods. As the preliminary results were promising, we investigated the hypothesis that the performance of d-step classifier can be attributed to a fact that in previous d - 1 steps it transforms the feature space by grouping observations belonging to a given class, so that they became more compact and separable. To verify this hypothesis we calculated three clustering scores for the transformed feature space. We also evaluated performance of pipelines built from FCM-based data transformer followed by a classification algorithm. The standard statistical analyzes confirmed both the performance of FCM based classifier and its capability to improve data. The supporting prototype software was implemented in Python using TensorFlow library. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Szwed, Piotr] AGH Univ Sci & Technol, Krakow, Poland.
C3 AGH University of Science & Technology
RP Szwed, P (corresponding author), AGH Univ Sci & Technol, Krakow, Poland.
EM pszwed@agh.edu.pl
CR Aguilar J., 2005, INT J COMPUT COGN, V3, P27
   Axelrod R.M, 1976, STRUCTURE DECISION C, V0, P404
   Bueno S, 2009, EXPERT SYST APPL, V36, P5221, DOI 10.1016/j.eswa.2008.06.072
   Chen G., 2016, ABS161002583 CORR, V0, P0
   Chen Y, 2015, APPL SOFT COMPUT, V37, P667, DOI 10.1016/j.asoc.2015.08.039
   Chmiel W, 2015, COMM COM INF SC, V566, P195, DOI 10.1007/978-3-319-26404-2_16
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Doborjeh MG, 2018, EVOL SYST-GER, V9, P195, DOI 10.1007/s12530-017-9178-8
   Felix G, 2019, ARTIF INTELL REV, V52, P1707, DOI 10.1007/s10462-017-9575-1
   Froelich W, 2017, NEUROCOMPUTING, V232, P83, DOI 10.1016/j.neucom.2016.11.059
   Gregor M., 2013, P 7 INT C INT MOD AN, V0, P78
   Gregor M, 2013, IFIP ADV INF COMM TE, V412, P547
   Japkowicz N., 2011, EVALUATING LEARNING, V0, P0, DOI DOI 10.1017/CBO9780511921803
   Jastriebow A, 2014, B POL ACAD SCI-TECH, V62, P735, DOI 10.2478/bpasts-2014-0079
   Jetter A, 2011, FUTURES, V43, P52, DOI 10.1016/j.futures.2010.05.002
   Knight CJK, 2014, APPL SOFT COMPUT, V15, P193, DOI 10.1016/j.asoc.2013.10.030
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kosko B., 1992, NEURAL NETWORKS FUZZ, V0, P449
   Larose D T, 2006, DATA MINING METHODS, V12, P0
   Lazzerini B, 2011, IEEE SYST J, V5, P288, DOI 10.1109/JSYST.2011.2134730
   Madeiro SS, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P344, DOI 10.1109/ICMLA.2012.64
   MILLIGAN GW, 1981, PSYCHOMETRIKA, V46, P187, DOI 10.1007/BF02293899
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, V0, P27
   Napoles G, 2018, STUD FUZZ SOFT COMP, V360, P83, DOI 10.1007/978-3-319-64286-4_5
   Napoles G, 2018, NEURAL NETWORKS, V97, P19, DOI 10.1016/j.neunet.2017.08.007
   Napoles G, 2017, INT J APPROX REASON, V85, P79, DOI 10.1016/j.ijar.2017.03.011
   Napoles G, 2016, INFORM SCIENCES, V349, P154, DOI 10.1016/j.ins.2016.02.040
   Napoles G, 2016, KNOWL-BASED SYST, V91, P46, DOI 10.1016/j.knosys.2015.10.015
   Napoles G, 2014, INTELL DATA ANAL, V18, PS77, DOI 10.3233/IDA-140710
   Ozesmi U, 2004, ECOL MODEL, V176, P43, DOI 10.1016/j.ecolmodel.2003.10.027
   Papageorgiou EI, 2008, APPL SOFT COMPUT, V8, P820, DOI 10.1016/j.asoc.2007.06.006
   Papageorgiou E.I., 2017, INT C INT DEC TECHN, V0, P501
   Papageorgiou EI, 2004, INT J APPROX REASON, V37, P219, DOI 10.1016/j.ijar.2004.01.001
   Papageorgiou EI, 2013, IEEE T FUZZY SYST, V21, P66, DOI 10.1109/TFUZZ.2012.2201727
   Papageorgiou EI, 2012, APPL SOFT COMPUT, V12, P3798, DOI 10.1016/j.asoc.2012.03.064
   Papageorgiou EI, 2012, IEEE T SYST MAN CY C, V42, P150, DOI 10.1109/TSMCC.2011.2138694
   Papakostas GA, 2012, EXPERT SYST APPL, V39, P10620, DOI 10.1016/j.eswa.2012.02.148
   Papakostas GA, 2010, STUD FUZZ SOFT COMP, V247, P291
   Papakostas GA, 2008, INT J PATTERN RECOGN, V22, P1461, DOI 10.1142/S0218001408006910
   Poczeta K, 2014, IEEE INT FUZZY SYST, V0, PP1029, DOI 10.1109/FUZZ-IEEE.2014.6891587
   Salmeron JL, 2012, APPL SOFT COMPUT, V12, P3818, DOI 10.1016/j.asoc.2012.02.003
   Stach W, 2007, IEEE IJCNN, V0, PP1584, DOI 10.1109/IJCNN.2007.4371194
   Stach W, 2008, IEEE INT CONF FUZZY, V0, P1977
   Szwed P., 2013, AUTOMATYKAAUTOMATICS, V17, P229
   Szwed P, 2016, MULTIMED TOOLS APPL, V75, P10667, DOI 10.1007/s11042-014-2047-6
   Szwed P, 2014, INT J AP MAT COM-POL, V24, P213, DOI 10.2478/amcs-2014-0016
   Wu KS, 2021, IEEE T MOBILE COMPUT, V20, P2281, DOI 10.1109/TMC.2020.2976007
   Zhang W., 2017, MATH PROBL ENG, V2017, P0
NR 49
TC 9
Z9 9
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUL 15
PY 2021
VL 105
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107271
EA MAR 2021
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SE0PT
UT WOS:000651778100012
DA 2023-04-26
ER

PT J
AU Ni, K
   Liu, PF
   Wang, P
AF Ni, Kang
   Liu, Pengfei
   Wang, Peng
TI Compact Global-Local Convolutional Network With Multifeature Fusion and Learning for Scene Classification in Synthetic Aperture Radar Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Radar polarimetry; Synthetic aperture radar; Remote sensing; Convolutional codes; Task analysis; Nickel; Affine subspace; convolutional feature learning; convolutional neural network (CNN); scene classification; synthetic aperture radar (SAR)
ID neural-network; sar
AB Feature learning of convolutional neural networks (CNNs) has gained considerable attention and achieved good performance on synthetic aperture radar (SAR) image scene classification. However, the performance of the existing convolutional feature learning methods is limited for generating the distinguishable feature representations because such techniques inherently suffer from shortcomings, i.e., they do not consider the local feature distribution of deep orderless feature statistics and deep orderless multifeature learning style. To alleviate these drawbacks, we propose a compact global-local convolutional network with multifeature fusion and learning (CGML) for SAR image scene classification, which contains double branches of convolutional feature learning net (C-net) and local feature distribution learning net (L-net). L-net employs the localized and parameterized affine subspace coding layer for local feature distribution learning and captures the feature statistics of each cluster center via detailed local feature division. The standard convolutional feature map is utilized for the convolutional feature learning in C-net. Subsequently, the compact multifeature fusion and learning strategy captures the compact global second-order orderless feature representation and allows the double branches to interact with each other via the tensor sketch algorithm. Especially, the feature learning strategy of L-net is defined in affine subspace which fully characterizes the feature distribution inside each cluster space. Finally, we concatenate the outputs of the multifeature fusion and learning network, then pool and feed them into softmax loss. Based on extensive evaluations on TerraSAR-X1 and TerraSAR-X2 image scene classification datasets, CGML can yield superior performances when compared with those of several state-of-the-art networks.
C1 [Ni, Kang; Liu, Pengfei] Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing 210023, Peoples R China.
   [Ni, Kang; Liu, Pengfei] Jiangsu Key Lab Big Data Secur & Intelligent Proc, Nanjing 210023, Peoples R China.
   [Wang, Peng] Nanjing Univ Aeronaut & Astronaut, Key Lab Radar Imaging & Microwave Photon, Minist Educ, Nanjing 210016, Peoples R China.
   [Wang, Peng] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of Aeronautics & Astronautics; China University of Geosciences
RP Ni, K (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing 210023, Peoples R China.
EM tznikang@163.com; liupengfei199091@163.com; pengwang-B614080003@hotmail.com
FU National Natural Science Foundation of China [61801211, 61802202]; Nanjing University of Posts, and Telecommunications Science Foundation (NUPTSF) [NY220135]; Open Research Project of The Hubei Key Laboratory of Intelligent Geo-Information Processing [KLIGIP-2019A05]
CR [Anonymous], 2015, ICLR, V0, P0
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI 10.1109/CVPR.2016.572
   Bai XR, 2019, IEEE T GEOSCI REMOTE, V57, P9223, DOI 10.1109/TGRS.2019.2925636
   Boualleg Y, 2019, IEEE GEOSCI REMOTE S, V16, P1944, DOI 10.1109/LGRS.2019.2911855
   Cai SJ, 2017, IEEE I CONF COMP VIS, V0, PP511, DOI 10.1109/ICCV.2017.63
   Cao YF, 2013, CONFERENCE PROCEEDINGS OF 2013 ASIA-PACIFIC CONFERENCE ON SYNTHETIC APERTURE RADAR (APSAR), V0, P342
   Charikar M., 2002, P INT C AUT LANG PRO, V0, PP693, DOI 10.1007/3-540-45465-9_59
   Chen BH, 2018, PATTERN RECOGN, V76, P339, DOI 10.1016/j.patcog.2017.10.039
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Dai DX, 2011, IEEE GEOSCI REMOTE S, V8, P225, DOI 10.1109/LGRS.2010.2058997
   Dede MA, 2019, IEEE GEOSCI REMOTE S, V16, P732, DOI 10.1109/LGRS.2018.2880136
   Gao Y, 2016, PROC CVPR IEEE, V0, PP317, DOI 10.1109/CVPR.2016.41
   Geng J, 2020, ISPRS J PHOTOGRAMM, V167, P201, DOI 10.1016/j.isprsjprs.2020.07.007
   Geng J, 2018, IEEE T GEOSCI REMOTE, V56, P2255, DOI 10.1109/TGRS.2017.2777868
   Geng J, 2015, IEEE GEOSCI REMOTE S, V12, P2351, DOI 10.1109/LGRS.2015.2478256
   Gou MR, 2018, PROC CVPR IEEE, V0, PP3175, DOI 10.1109/CVPR.2018.00335
   Gu J, 2020, IEEE T GEOSCI REMOTE, V58, P881, DOI 10.1109/TGRS.2019.2941288
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He NJ, 2020, IEEE T NEUR NET LEAR, V31, P1461, DOI 10.1109/TNNLS.2019.2920374
   He NJ, 2018, IEEE T GEOSCI REMOTE, V56, P6899, DOI 10.1109/TGRS.2018.2845668
   Hou B, 2016, IEEE GEOSCI REMOTE S, V13, P33, DOI 10.1109/LGRS.2015.2493242
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang ZL, 2021, IEEE GEOSCI REMOTE S, V18, P107, DOI 10.1109/LGRS.2020.2965558
   Ionescu C, 2015, IEEE I CONF COMP VIS, V0, PP2965, DOI 10.1109/ICCV.2015.339
   Kong S, 2017, PROC CVPR IEEE, V0, PP7025, DOI 10.1109/CVPR.2017.743
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li PH, 2018, PROC CVPR IEEE, V0, PP947, DOI 10.1109/CVPR.2018.00105
   Li PH, 2017, IEEE I CONF COMP VIS, V0, PP2089, DOI 10.1109/ICCV.2017.228
   Li PH, 2015, PROC CVPR IEEE, V0, PP2348, DOI 10.1109/CVPR.2015.7298848
   Lin TY, 2015, IEEE I CONF COMP VIS, V0, PP1449, DOI 10.1109/ICCV.2015.170
   Liu XL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161942
   Liu YF, 2018, IEEE T GEOSCI REMOTE, V56, P7109, DOI 10.1109/TGRS.2018.2848473
   Lu XQ, 2019, IEEE T GEOSCI REMOTE, V57, P7894, DOI 10.1109/TGRS.2019.2917161
   Ni K, 2020, IEEE GEOSCI REMOTE S, V17, P1717, DOI 10.1109/LGRS.2019.2953472
   Ni K, 2019, IEEE GEOSCI REMOTE S, V16, P1716, DOI 10.1109/LGRS.2019.2909312
   Ni K, 2020, INT J REMOTE SENS, V41, P1415, DOI 10.1080/01431161.2019.1667551
   Paul S, 2019, IEEE J-STARS, V12, P2958, DOI 10.1109/JSTARS.2019.2918211
   Reiche J, 2018, REMOTE SENS ENVIRON, V204, P147, DOI 10.1016/j.rse.2017.10.034
   Ren ZL, 2020, IEEE T GEOSCI REMOTE, V58, P3864, DOI 10.1109/TGRS.2019.2959120
   Ren ZL, 2018, IEEE J-STARS, V11, P3113, DOI 10.1109/JSTARS.2018.2851023
   Shahzad M, 2019, IEEE T GEOSCI REMOTE, V57, P1100, DOI 10.1109/TGRS.2018.2864716
   Wang JJ, 2010, PROC CVPR IEEE, V0, PP3360, DOI 10.1109/CVPR.2010.5540018
   Wang P, 2021, IEEE T GEOSCI REMOTE, V59, P2256, DOI 10.1109/TGRS.2020.3004353
   Wei X, 2018, LECT NOTES COMPUT SC, V11207, P365, DOI 10.1007/978-3-030-01219-9_22
   Wu ZT, 2021, IEEE T GEOSCI REMOTE, V59, P1200, DOI 10.1109/TGRS.2020.3004911
   Xie J, 2019, IEEE T GEOSCI REMOTE, V57, P6916, DOI 10.1109/TGRS.2019.2909695
   Yang SY, 2018, IEEE T NEUR NET LEAR, V29, P3919, DOI 10.1109/TNNLS.2017.2688466
   Yang SY, 2016, NEUROCOMPUTING, V184, P91, DOI 10.1016/j.neucom.2015.08.103
   Yu H, 2016, IEEE T GEOSCI REMOTE, V54, P2400, DOI 10.1109/TGRS.2015.2501162
   Zhang BB, 2020, PATTERN RECOGN, V100, P0, DOI 10.1016/j.patcog.2019.107167
   Zhang HS, 2015, IEEE GEOSCI REMOTE S, V12, P1061, DOI 10.1109/LGRS.2014.2377722
   Zhao JP, 2020, IEEE J-STARS, V13, P187, DOI 10.1109/JSTARS.2019.2954850
   Zhao ZQ, 2017, PATTERN RECOGN, V61, P686, DOI 10.1016/j.patcog.2016.05.028
   Zhao ZQ, 2016, NEUROCOMPUTING, V207, P772, DOI 10.1016/j.neucom.2016.05.065
NR 54
TC 2
Z9 3
U1 4
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7284
EP 7296
DI 10.1109/JSTARS.2021.3096941
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TS3CR
UT WOS:000679532200010
DA 2023-04-26
ER

PT J
AU Verschoof-van der Vaart, WB
   Landauer, J
AF Verschoof-van der Vaart, Wouter B.
   Landauer, Juergen
TI Using CarcassonNet to automatically detect and trace hollow roads in LiDAR data from the Netherlands
SO JOURNAL OF CULTURAL HERITAGE
LA English
DT Article
DE LiDAR; CNN; Machine learning; Archaeology; Hollow roads
ID remote-sensing imagery; archaeological features; extraction; object; models
AB The systematic mapping of hollow roads, traces of (post)medieval sunken cart tracks ways, can provide information on past human movement and historical route networks. However, the sheer amount of traces and of available high-quality data necessitates the use of computational methods for the automatic detection of these archaeological objects. Therefore, a novel approach, named CarcassonNet, has been developed that uses a combination of a Deep Learning convolutional neural network and image processing algorithms to detect and trace hollow roads in LiDAR data from the Netherlands. CarcassonNet has been specifically developed for the archaeological domain, focusing on being computationally light and suited for reconstructing partially preserved and intersected hollow roads. Instead of using the whole roads as input for the convolutional neural network, in CarcassonNet individual sections are used. This makes it much more cost-effective to create a sufficient training dataset, and makes the classification task (performed by the neural network) relatively simple, with better detection results. The output of CarcassonNet consists of two types of geospatial vectors that offer the opportunity to efficiently study the roads themselves and their precise location in the landscape (polygons), and the course of the roads and the resulting route network (lines). An experimental evaluation shows that CarcassonNet is able to effectively detect hollow roads, with a MCC score of 0.47. Furthermore, it is shown that using the Digital Terrain Model, instead of visualized LiDAR data (hillshade) improves the performance of the convolutional neural network. The results of this research offer opportunities to reconstruct vanished and abandoned (post)medieval routes and answer questions about human-landscape interactions. (C) 2020 L'Auteur(s). Publie par Elsevier Masson SAS. Cet article est publie en Open Access sous licence CC BY.
C1 [Verschoof-van der Vaart, Wouter B.] Leiden Univ, Fac Archaeol, POB 9514, NL-2300 RA Leiden, Netherlands.
   [Verschoof-van der Vaart, Wouter B.] Leiden Univ, Leiden Ctr Data Sci, Data Sci Res Programme, POB 9505, NL-2300 RA Leiden, Netherlands.
   [Landauer, Juergen] Landauer Res, Wimpfener St 10, D-71642 Ludwigsburg, Germany.
C3 Leiden University; Leiden University - Excl LUMC; Leiden University; Leiden University - Excl LUMC
RP Verschoof-van der Vaart, WB (corresponding author), Leiden Univ, Fac Archaeol, POB 9514, NL-2300 RA Leiden, Netherlands.
EM w.b.verschoof@arch.leidenuniv.nl; juergenlandauer@gmx.de
FU Data Science Research Programme (Leiden University)
CR Abdollahi A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091444
   Angelova A, 2005, PROC CVPR IEEE, V0, P494
   Ball JE, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042609
   Bennett R, 2014, ANTIQUITY, V88, P896, DOI 10.1017/S0003598X00050766
   Bevan A, 2015, ANTIQUITY, V89, P1473, DOI 10.15184/aqy.2015.102
   Blume HP, 2004, J PLANT NUTR SOIL SC, V167, P319, DOI 10.1002/jpln.200420905
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS), V0, P0
   Bourgeois Q, 2013, MONUMENTS HORIZON FO, V0, P0
   Brock A., 2017, FREEZEOUT ACCELERATE, V0, P0
   Brongers J.A., 1976, AIR PHOTOGRAPHY CELT, V0, P0
   Chicco D, 2020, BMC GENOMICS, V21, P0, DOI 10.1186/s12864-019-6413-7
   Cowley DC, 2012, PROC SPIE, V8532, P0, DOI 10.1117/12.981758
   Cowley DC, 2011, EAC OCCAS PAP, V0, P43
   Crutchley S., 2018, USING AIRBORNE LIDAR, V0, P0
   De Laet V, 2007, J ARCHAEOL SCI, V34, P830, DOI 10.1016/j.jas.2006.09.013
   der Vaart W.B. Verschoof-van, 2019, J COMPUTER APPL ARCH, V2, P0
   Devereux BJ, 2005, ANTIQUITY, V79, P648, DOI 10.1017/S0003598X00114589
   Ferraz A, 2016, ISPRS J PHOTOGRAMM, V112, P23, DOI 10.1016/j.isprsjprs.2015.12.002
   Figorito B, 2014, INT J APPL EARTH OBS, V26, P458, DOI 10.1016/j.jag.2013.04.005
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Groenewoudt B, 2007, BREPOLS PUB, V6, P327, DOI 10.1484/M.RURALIA-EB.3.1150
   Groenhuijzen M.R, 2019, FINDINGTHE LIMITS LI, V0, P0
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Guyot A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020225
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, V0, PP558, DOI 10.1109/CVPR.2019.00065
   Herfort B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151799
   Hesse, 2019, CHNT 24, V0, P1
   Hesse R, 2010, ARCHAEOL PROSPECT, V17, P67, DOI 10.1002/arp.374
   Howard J, 2020, INFORMATION, V11, P0, DOI 10.3390/info11020108
   Ibrahim Sameen M., 2020, LASER SCANNING SYSTE, V0, P61
   Jager S.W., 1985, PALAEOHISTORIA, V27, P185
   Johnson JM, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0192-5
   Kenzler H., 2015, CAA2014 21 CENTURY A, V0, P0
   Kirchner A, 2020, ERDKUNDE, V74, P1, DOI 10.3112/erdkunde.2020.01.01
   Kokalj Z., 2017, AIRBORNE LASER SCANN, V0, P0, DOI DOI 10.3986/9789612549848
   Lambers K, 2018, NAT SCI ARCHAEOL, V0, PP109, DOI 10.1007/978-3-319-25316-9_7
   Lambers K, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070794
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li PK, 2016, INT GEOSCI REMOTE SE, V0, PP1599, DOI 10.1109/IGARSS.2016.7729408
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), V0, P0, DOI DOI 10.1145/3173574.3173703
   Lovschal M., 2013, BARROWS CURRENT RES, V0, P225
   Luque A, 2019, PATTERN RECOGN, V91, P216, DOI 10.1016/j.patcog.2019.02.023
   Manning C.D., 2008, INTRO INFORM RETRIEV, V1, P0
   Meyer MF, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9030109
   Mlekuz D., 2013, ARCHAEOLOGY REMOTE S, V0, P37
   Nachmany Y., 2019, PROC IEEE C COMPUT V, V0, P83
   Nuninger L., 2020, J COMPUTER APPL ARCH, V3, P63, DOI 10.5334/jcaa.46
   Opitz R. S., 2013, INTERPRETING ARCHAEO, V0, P0
   Papadavid G., 2014, 2 INF C REM SENS GEO, V0, P0
   QGIS Development Team, 2009, QGIS GEOGR INF SYST, V0, P0
   Razavian A- S., 2014, P IEEE C COMP VIS PA, V1403, P6382, DOI 10.1109/cvprw.2014.131
   Ronneberger T, 2018, U NET CONVOLUTIONAL, V0, P0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sammut C., 2011, ENCY MACHINE LEARNIN, V0, P0, DOI DOI 10.1007/978-0-387-30164-8
   Sevara C, 2016, J ARCHAEOL SCI-REP, V5, P485, DOI 10.1016/j.jasrep.2015.12.023
   SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969
   Slamova M, 2014, PROCD SOC BEHV, V120, P213, DOI 10.1016/j.sbspro.2014.02.098
   Slappendel C.G, 2008, ANALECTA PRAEHISTORI, V40, P281
   Traviglia A, 2017, GEOSCIENCES, V7, P0, DOI 10.3390/geosciences7040128
   Trier O.D., 2018, CAA2016, V0, P219
   van der Schriek M, 2017, J CONFL ARCHAEOL, V12, P94, DOI 10.1080/15740773.2017.1440960
   van der Zon N., 2013, KWALITEITSDOCUMENT A, V0, P0
   Van Etten, 2019, CITY SCALE ROAD EXTR, V0, P0
   van Lanen RJ, 2015, J ARCHAEOL SCI-REP, V3, P144, DOI 10.1016/j.jasrep.2015.05.024
   Verschoof-van der Vaart WB, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9050293
   Vletter W, 2019, ARCHAOLOGIE GESCH GE, V36, P367
   Vletter W.F., 2018, HISTORY, V5, P1
   Wilkinson TJ, 2010, GEOARCHAEOLOGY, V25, P745, DOI 10.1002/gea.20331
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091461
   Yokoyama R, 2002, PHOTOGRAMM ENG REM S, V68, P257
NR 73
TC 13
Z9 13
U1 1
U2 9
PU ELSEVIER FRANCE-EDITIONS SCIENTIFIQUES MEDICALES ELSEVIER
PI ISSY-LES-MOULINEAUX
PA 65 RUE CAMILLE DESMOULINS, CS50083, 92442 ISSY-LES-MOULINEAUX, FRANCE
SN 1296-2074
EI 1778-3674
J9 J CULT HERIT
JI J. Cult. Herit.
PD JAN-FEB 15
PY 2021
VL 47
IS 
BP 143
EP 154
DI 10.1016/j.culher.2020.10.009
EA FEB 2021
PG 12
WC Archaeology; Art; Chemistry, Analytical; Geosciences, Multidisciplinary; Materials Science, Multidisciplinary; Spectroscopy
SC Archaeology; Art; Chemistry; Geology; Materials Science; Spectroscopy
GA QL0PQ
UT WOS:000620783300002
DA 2023-04-26
ER

PT J
AU Dogu, E
   Albayrak, YE
   Tuncay, E
AF Dogu, Elif
   Albayrak, Y. Esra
   Tuncay, Esin
TI Length of hospital stay prediction with an integrated approach of statistical-based fuzzy cognitive maps and artificial neural networks
SO MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING
LA English
DT Article
DE Medical decision-making; Length of hospital stay; COPD; Statistical-based fuzzy cognitive maps; Artificial neural networks
ID management; risk
AB Chronic obstructive pulmonary disease (COPD) is a global burden, which is estimated to be the third leading cause of death worldwide by 2030. The economic burden of COPD grows continuously because it is not a curable disease. These conditions make COPD an important research field of artificial intelligence (AI) techniques in medicine. In this study, an integrated approach of the statistical-based fuzzy cognitive maps (SBFCM) and artificial neural networks (ANN) is proposed for predicting length of hospital stay of patients with COPD, who admitted to the hospital with an acute exacerbation. The SBFCM method is developed to determine the input variables of the ANN model. The SBFCM conducts statistical analysis to prepare preliminary information for the experts and then collects expert opinions accordingly, to define a conceptual map of the system. The integration of SBFCM and ANN methods provides both statistical data and expert opinion in the prediction model. In the numerical application, the proposed approach outperformed the conventional approach and other machine learning algorithms with 79.95% accuracy, revealing the power of expert opinion involvement in medical decisions. A medical decision support framework is constructed for better prediction of length of hospital stay and more effective hospital management.
C1 [Dogu, Elif; Albayrak, Y. Esra] Galatasaray Univ, Ind Engn Dept, Ciragan Cad 36, TR-34349 Istanbul, Turkey.
   [Tuncay, Esin] Yedikule Chest Dis & Thorac Surg Training & Res H, Belgrad Kapi Yolu Cad 1, TR-34020 Istanbul, Turkey.
C3 Galatasaray University; Istanbul Yedikule Chest Diseases & Thoracic Surgery Training & Research Hospital
RP Dogu, E (corresponding author), Galatasaray Univ, Ind Engn Dept, Ciragan Cad 36, TR-34349 Istanbul, Turkey.
EM edogu@gsu.edu.tr; ealbayrak@gsu.edu.tr
FU Galatasaray University Research Fund
CR Adeyemi S, 2013, DECIS SUPPORT SYST, V55, P117, DOI 10.1016/j.dss.2012.12.039
   Agarwal A, 2018, IEEE J BIOMED HEALTH, V22, P588, DOI 10.1109/JBHI.2017.2684121
   Andres-Blanco AM, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0188094
   Apte C., 1998, TEXT MINING DECISION, V0, P0
   Badnjevic A, 2015, BMC MED INFORM DECIS, V15, P0, DOI 10.1186/1472-6947-15-S3-S1
   Barracchia EP, 2020, BMC BIOINFORMATICS, V21, P0, DOI 10.1186/s12859-020-3392-2
   Bestall JC, 1999, THORAX, V54, P581, DOI 10.1136/thx.54.7.581
   Buyukavcu A, 2016, APPL SOFT COMPUT, V38, P437, DOI 10.1016/j.asoc.2015.09.026
   CHARLSON ME, 1987, J CHRON DIS, V40, P373, DOI 10.1016/0021-9681(87)90171-8
   Corizzo R, 2021, INFORM SCIENCES, V546, P701, DOI 10.1016/j.ins.2020.08.003
   Corizzo R, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0207-2
   Georga EI, 2013, IEEE J BIOMED HEALTH, V17, P71, DOI 10.1109/TITB.2012.2219876
   Goker N, 2020, J INTELL FUZZY SYST, V38, P653, DOI 10.3233/JIFS-179438
   Jiang X, 2020, IEEE ACCESS, V8, P37352, DOI 10.1109/ACCESS.2020.2975585
   Karan B, 2020, BIOCYBERN BIOMED ENG, V40, P249, DOI 10.1016/j.bbe.2019.05.005
   Karsoliya S., 2012, INT J ENG TRENDS TEC, V3, P714
   Kim WO, 2000, J KOREAN MED SCI, V15, P25, DOI 10.3346/jkms.2000.15.1.25
   LaFaro RJ, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0145395
   Laskar MR, 2018, J INDIAN SOC REMOTE, V46, P873, DOI 10.1007/s12524-017-0724-4
   Launay CP, 2015, EUR J INTERN MED, V26, P478, DOI 10.1016/j.ejim.2015.06.002
   Li Z, 2020, IEEE ACCESS, V8, P14588, DOI 10.1109/ACCESS.2019.2961260
   MOBLEY BA, 1995, HEART LUNG, V24, P251, DOI 10.1016/S0147-9563(05)80045-7
   Mohktar MS, 2015, ARTIF INTELL MED, V63, P51, DOI 10.1016/j.artmed.2014.12.003
   Moretz C, 2015, J MANAG CARE SPEC PH, V21, P1149, DOI 10.18553/jmcp.2015.21.12.1149
   Mundt M, 2020, MED BIOL ENG COMPUT, V58, P211, DOI 10.1007/s11517-019-02061-3
   Nava R, 2014, MED BIOL ENG COMPUT, V52, P393, DOI 10.1007/s11517-014-1139-9
   Panchal G., 2014, COMPUTING, V3, P455
   Pio G, 2020, MACH LEARN, V109, P1231, DOI 10.1007/s10994-019-05861-8
   Raja BS., 2017, INT J PURE APPL MATH, V117, P283
   Reboucas PP, 2019, NEURAL COMPUT APPL, V31, P901, DOI 10.1007/s00521-017-3048-y
   Ross T. J., 2010, FUZZY LOGIC ENG APPL, V0, P0
   Rowan M, 2007, ARTIF INTELL MED, V40, P211, DOI 10.1016/j.artmed.2007.04.005
   Sanchez-Morillo D, 2015, MED BIOL ENG COMPUT, V53, P441, DOI 10.1007/s11517-015-1252-4
   Tsai PF, 2016, J HEALTHC ENG, V2016, P0, DOI 10.1155/2016/7035463
   van der Heijden M, 2013, ARTIF INTELL MED, V59, P143, DOI 10.1016/j.artmed.2013.09.003
   Vogelmeier CF, 2017, EUR RESPIR J, V49, P0, DOI 10.1111/resp.13012
   Walczak S, 1999, INFORM SOFTWARE TECH, V41, P107, DOI 10.1016/S0950-5849(98)00116-5
   World health Organization (WHO), 2007, GLOBAL SURVEILLANCE, V0, P0
   Yavuz E, 2020, MED BIOL ENG COMPUT, V58, P1583, DOI 10.1007/s11517-020-02187-9
   Yuan HJ, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep24036
NR 40
TC 2
Z9 2
U1 4
U2 23
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0140-0118
EI 1741-0444
J9 MED BIOL ENG COMPUT
JI Med. Biol. Eng. Comput.
PD MAR 15
PY 2021
VL 59
IS 3
BP 483
EP 496
DI 10.1007/s11517-021-02327-9
EA FEB 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology; Medical Informatics
SC Computer Science; Engineering; Mathematical & Computational Biology; Medical Informatics
GA QQ5QU
UT WOS:000615128800002
PM 33544271
DA 2023-04-26
ER

PT J
AU Yamada, W
   Zhao, W
   Digman, M
AF Yamada, William
   Zhao, Wei
   Digman, Matthew
TI Automated Bale Mapping Using Machine Learning and Photogrammetry
SO REMOTE SENSING
LA English
DT Article
DE computer vision; image processing; machine learning; photogrammetry
ID imagery
AB An automatic method of obtaining geographic coordinates of bales using monovision un-crewed aerial vehicle imagery was developed utilizing a data set of 300 images with a 20-megapixel resolution containing a total of 783 labeled bales of corn stover and soybean stubble. The relative performance of image processing with Otsu's segmentation, you only look once version three (YOLOv3), and region-based convolutional neural networks was assessed. As a result, the best option in terms of accuracy and speed was determined to be YOLOv3, with 80% precision, 99% recall, 89% F1 score, 97% mean average precision, and a 0.38 s inference time. Next, the impact of using lower-cost cameras was evaluated by reducing image quality to one megapixel. The lower-resolution images resulted in decreased performance, with 79% precision, 97% recall, 88% F1 score, 96% mean average precision, and 0.40 s inference time. Finally, the output of the YOLOv3 trained model, density-based spatial clustering, photogrammetry, and map projection were utilized to predict the geocoordinates of the bales with a root mean squared error of 2.41 m.
C1 [Yamada, William; Digman, Matthew] Univ Wisconsin, Dept Biol Syst Engn, Madison, WI 53706 USA.
   [Zhao, Wei] 3M Co, Maplewood, MN 55109 USA.
C3 University of Wisconsin System; University of Wisconsin Madison; 3M
RP Digman, M (corresponding author), Univ Wisconsin, Dept Biol Syst Engn, Madison, WI 53706 USA.
EM wyamada@wisc.edu; wzhao97@wisc.edu; digman@wisc.edu
CR Aboutalebi M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10122058
   Arantes MD, 2019, IEEE T ROBOT, V35, P433, DOI 10.1109/TRO.2018.2878996
   Chen A., 2018, P AMIA ANN FALL S, V2, P335
   Doughty CL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050540
   Drewry JL, 2019, COMPUT ELECTRON AGR, V165, P0, DOI 10.1016/j.compag.2019.104960
   Ester M, 1996, P 2 INT C KNOWL DISC, V96, P226
   Etienne A, 2019, PROC SPIE, V11008, P0, DOI 10.1117/12.2520536
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Goraj M, 2019, METEOROL HYDROL WATE, V7, P23, DOI 10.26491/mhwm/95086
   Han XZ, 2020, INVENTIONS-BASEL, V5, P0, DOI 10.3390/inventions5010012
   Helgesen HH, 2019, ISPRS J PHOTOGRAMM, V154, P84, DOI 10.1016/j.isprsjprs.2019.05.009
   Hou JW, 2016, PRECIS AGRIC, V17, P488, DOI 10.1007/s11119-016-9432-2
   Hu J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070736
   Hugenholtz C., 2016, GEOMATICA, V70, P21, DOI 10.5623/CIG2016-102
   Lev Bugayevskiy J.S., 1995, MAP PROJECTIONS A RE, V0, P0
   Mardani A, 2019, IEEE ACCESS, V7, P52609, DOI 10.1109/ACCESS.2019.2911018
   Martha TR, 2011, IEEE T GEOSCI REMOTE, V49, P4928, DOI 10.1109/TGRS.2011.2151866
   Mittal P, 2020, IMAGE VISION COMPUT, V104, P0, DOI 10.1016/j.imavis.2020.104046
   Mukherjee A, 2019, J NETW COMPUT APPL, V148, P0, DOI 10.1016/j.jnca.2019.102461
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Padro JC, 2019, INT J APPL EARTH OBS, V75, P130, DOI 10.1016/j.jag.2018.10.018
   Redmon J, 2018, ABS180402767 CORR, V0, P0, DOI DOI 10.48550/ARXIV.1804.02767
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Seyyedhasani H, 2021, COMPUT ELECTRON AGR, V180, P0, DOI 10.1016/j.compag.2020.105898
   Shinners KJ, 2010, T ASABE, V53, P359
   Shivers SW, 2019, REMOTE SENS ENVIRON, V222, P215, DOI 10.1016/j.rse.2018.12.030
   Snyder J.P, 1987, US GEOLOGICAL SURVEY, V0, P0
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Xu BB, 2020, COMPUT ELECTRON AGR, V171, P0, DOI 10.1016/j.compag.2020.105300
   Xu LM, 2019, BIOSYST ENG, V178, P264, DOI 10.1016/j.biosystemseng.2018.12.001
   Yadav Y., 2017, INT J SCI TECHNOL RE, V6, P191
   Yue JB, 2019, ISPRS J PHOTOGRAMM, V150, P226, DOI 10.1016/j.isprsjprs.2019.02.022
   Zhao W, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010023
   Zheng YY, 2018, CHIN AUTOM CONGR, V0, PP2223, DOI 10.1109/CAC.2018.8623610
   Zhu XD, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101208
NR 35
TC 0
Z9 0
U1 2
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV 15
PY 2021
VL 13
IS 22
BP 
EP 
DI 10.3390/rs13224675
PG 15
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XF2VK
UT WOS:000723933600001
DA 2023-04-26
ER

PT J
AU Liu, HQ
   Chen, N
   Wang, XH
AF Liu, Haiqing
   Chen, Na
   Wang, Xinhao
TI Comparing Regional Sustainability and Transportation Sustainability at the Metropolitan Level in the US using Artificial Neural Network Clustering Techniques
SO TRANSPORTATION RESEARCH RECORD
LA English
DT Article
ID indicators
AB Regional sustainability and transportation sustainability have been intensely discussed and analyzed in recent decades. Though the use of indicators has been adopted in those models, debates continue on what indicators should be used and how to optimize the number of indicators. This results in the lack of a comprehensive and efficient method to assess and compare the sustainability of a sub-system, such as transportation system, and overall regional sustainability. A thorough literature review is conducted to identify indicators used to assess regional sustainability and transportation sustainability. Then, based on the available data, two sets of indicators for regional sustainability and transportation sustainability are identified and calculated respectively for the 382 metropolitan statistical areas (MSAs) in the U.S. A self-organizing map, which is a type of artificial neural network, is used to cluster the MSAs and compare their regional sustainability and transportation sustainability as well as to investigate the relationships among indicators. The results show that MSAs with a higher score on regional sustainability do not necessarily have a higher score on transportation sustainability. Some MSAs that are geographically close to each other have similar scores in regional sustainability and transportation sustainability. These findings provide insights to decision makers that the assessment of sustainability should consider both correlation and heterogeneity of different indicators within a region. Therefore, it is important to develop a comprehensive and efficient method to evaluate the role of sustainability in one urban sub-system, such as transportation, in the overall regional sustainability.
C1 [Liu, Haiqing; Chen, Na; Wang, Xinhao] Univ Cincinnati, Sch Planning, Cincinnati, OH 45267 USA.
C3 University System of Ohio; University of Cincinnati
RP Liu, HQ (corresponding author), Univ Cincinnati, Sch Planning, Cincinnati, OH 45267 USA.
EM liu2hq@mail.uc.edu
FU University of Cincinnati Office of Research's University Research Council (URC) Program for Arts/Humanities & Social Sciences
CR Alam JB, 2005, TRANSPORT RES REC, V0, P79
   [Anonymous], 2001, GREEN IS CITY SUSTAI, V0, P0, DOI DOI 10.7312/DEVU11802
   Arribas-Bel D, 2013, ENVIRON PLANN B, V40, P362, DOI 10.1068/b37014
   Avin U., 2018, IMPACT SUSTAINABLE C, V0, P0
   BLACK W, 1997, J TRANSP GEOGR, V5, P163
   Canavese D, 2014, ECOL INDIC, V36, P711, DOI 10.1016/j.ecolind.2013.09.030
   Chapple K., 2013, PLANTING SEEDS SUSTA, V0, P1
   Chen N, 2020, TRANSPORT RES D-TR E, V84, P0, DOI 10.1016/j.trd.2020.102365
   Costanza R, 1995, ECOL ECON, V15, P193, DOI 10.1016/0921-8009(95)00048-8
   Cottrell M, 2001, ADVANCES IN SELF-ORGANISING MAPS, V0, P7
   Davidescu AAM, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11123331
   Ding Y., 2014, PROCEDIA ENV SCI, V22, P131, DOI 10.1016/J.PROENV.2014.11.013
   Environmental Protection Agency, 2020, 430R20002 EPA, V0, P0
   Farmer CJQ, 2011, ENVIRON PLANN A, V43, P2723, DOI 10.1068/a44136
   Frick K.T., 2015, CALIFORNIA J POLITIC, V7, P1
   Gilbert R., 2003, 82 ANN M TRANSP RES, V0, P0
   Goodall B., 1987, PENGUIN DICT HUMAN G, V0, P0
   Graymore MLM, 2010, ECOL ECON, V69, P459, DOI 10.1016/j.ecolecon.2009.08.016
   Graymore MLM, 2008, ECOL ECON, V67, P362, DOI 10.1016/j.ecolecon.2008.06.002
   Graymore MLM, 2009, ECOL COMPLEX, V6, P453, DOI 10.1016/j.ecocom.2009.08.006
   Grieco M, 2015, SOC RESPONSIB J, V11, P82, DOI 10.1108/SRJ-05-2014-0061
   Haghshenas H, 2012, ECOL INDIC, V15, P115, DOI 10.1016/j.ecolind.2011.09.010
   Jeon CM, 2005, J INFRASTRUCT SYST, V11, P31, DOI 10.1061/(ASCE)1076-0342(2005)11:1(31)
   Jeon CM, 2013, TRANSPORT POLICY, V25, P10, DOI 10.1016/j.tranpol.2012.10.004
   KANGAS J, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P1591
   Kohonen T., 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Laaksonen J., 1999, IJCNN99. INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS. PROCEEDINGS (CAT. NO.99CH36339), V0, PP2470, DOI 10.1109/IJCNN.1999.833459
   Li HX, 2015, SUSTAINABILITY-BASEL, V7, P9067, DOI 10.3390/su7079067
   Litman T, 2007, TRANSPORT RES REC, V0, PP10, DOI 10.3141/2017-02
   Mandinia I, 2018, ECOL INDIC, V89, P738, DOI 10.1016/j.ecolind.2017.12.019
   MATLAB, 2019, 9601174912 MATLAB, V0, P0
   Meila M, 2003, LECT NOTES ARTIF INT, V2777, P173, DOI 10.1007/978-3-540-45167-9_14
   Munda G, 2011, REG STUD, V45, P261, DOI 10.1080/00343401003713316
   Ramos TB, 2009, J CLEAN PROD, V17, P1101, DOI 10.1016/j.jclepro.2009.02.024
   Smetana S, 2015, REG SCI POLICY PRACT, V7, P163, DOI 10.1111/rsp3.12068
   Sultana S, 2019, URBAN GEOGR, V40, P279, DOI 10.1080/02723638.2017.1395635
   Tanguay GA, 2010, ECOL INDIC, V10, P407, DOI 10.1016/j.ecolind.2009.07.013
   UN (United Nations), 2019, WORLD URB PROSP 2018, V0, P0
   UNAIDS, 2021, UNAIDS DAT 2021, V0, P0
   Wachs M, 2010, TRANSPORT RES REC, V0, PP5, DOI 10.3141/2163-01
   Wang CD, 2016, J CLEAN PROD, V114, P189, DOI 10.1016/j.jclepro.2015.05.121
   Wood R, 2010, ECOL ECON, V69, P1877, DOI 10.1016/j.ecolecon.2010.05.006
   World Commission on Environment and Development, 1987, OUR COMMON FUTURE, V0, P0
   Yang Q, 2014, SUSTAINABILITY-BASEL, V6, P9282, DOI 10.3390/su6129282
   Zheng J, 2013, RES TRANSP BUS MANAG, V7, P4, DOI 10.1016/j.rtbm.2013.02.001
NR 46
TC 2
Z9 2
U1 3
U2 8
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0361-1981
EI 2169-4052
J9 TRANSPORT RES REC
JI Transp. Res. Record
PD SEP 15
PY 2021
VL 2675
IS 9
BP 1655
EP 1669
DI 10.1177/03611981211009519
EA APR 2021
PG 15
WC Engineering, Civil; Transportation; Transportation Science & Technology
SC Engineering; Transportation
GA WL1RH
UT WOS:000684966200001
DA 2023-04-26
ER

PT J
AU Arndt, J
   Lunga, D
AF Arndt, Jacob
   Lunga, Dalton
TI Large-Scale Classification of Urban Structural Units From Remote Sensing Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Urban areas; Remote sensing; Sociology; Support vector machines; Neural networks; Morphology; Satellites; Deep learning; image classification; remote sensing; settlements; urban; urban structural units (USUs); urban structure types (USTs)
ID convolutional networks; informal settlements; performance; features; city
AB Remote sensing in combination with deep learning has become instrumental for efficiently and accurately classifying land-use and land-cover across large geographic areas. These technologies have also been successful in characterizing urban environments in terms of their structural units, structure types, or morphological regions. In these approaches, an urban area is partitioned into regions that exhibit homogeneous physical characteristics. However, existing approaches are typically limited to a single city, use inconsistent typologies, and lack scalability and generalization capacity. In this article, we propose an urban structural units categorization scheme and demonstrate its utility by applying it to 13 cities. Inspired by the lack of scalability and generalization capacity in urban structural units mapping, we extend the reach of deep learning and conduct a set of classification experiments in all 13 cities. These experiments offer insights into the strengths and limitations of deep neural networks for classifying urban structural units over diverse geographic regions and on heterogeneous collections of satellite imagery. The efficacy of the proposed deep learning approach is compared to a baseline method of multiscale image features and support vector machines. Our validation on five cities shows that better performance is achieved with deep neural networks. Additionally, we evaluate the impact of input size, model depth, and spatial pyramid pooling to assess the generalization capacity of deep neural networks.
C1 [Arndt, Jacob; Lunga, Dalton] Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
C3 United States Department of Energy (DOE); Oak Ridge National Laboratory
RP Arndt, J (corresponding author), Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
EM arndtjw@ornl.gov; lungadd@ornl.gov
FU U.S. Department of Energy (DOE) [DE-AC05-00OR22725]
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Anderson J. R., 1976, LAND USE LAND COVER, V0, P964
   [Anonymous], 2019, WORLD POPULATION PRO, V0, P0
   [Anonymous], 2019, WORLD URB PROSP 2018, V0, P0
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arndt J, 2019, INT GEOSCI REMOTE SE, V0, PP9470, DOI 10.1109/IGARSS.2019.8900083
   Banzhaf E, 2008, IEEE J-STARS, V1, P129, DOI 10.1109/JSTARS.2008.2003310
   Bayram U, 2011, PROC SPIE, V8180, P0, DOI 10.1117/12.898292
   Bochow M, 2010, INT GEOSCI REMOTE SE, V0, PP1796, DOI 10.1109/IGARSS.2010.5652972
   Bradski G, 2000, DR DOBBS J, V25, P120
   Burgdorfer J., 2015, JOINT URBAN REMOTE S, V0, P1
   BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808
   Cao Y, 2019, IEEE ICC, V0, P0
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Christie G, 2018, PROC CVPR IEEE, V0, PP6172, DOI 10.1109/CVPR.2018.00646
   Dong P, 2000, INT J REMOTE SENS, V21, P3369, DOI 10.1080/014311600750019985
   Graesser J, 2012, IEEE J-STARS, V5, P1164, DOI 10.1109/JSTARS.2012.2190383
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hofer R., 2009, IEEE JOINT URBAN REM, V0, P1
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Jochem WC, 2018, COMPUT ENVIRON URBAN, V69, P104, DOI 10.1016/j.compenvurbsys.2018.01.004
   Kuffer M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060455
   Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9
   Lehner A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020173
   Lowe D. G., 1999, INT C COMP VIS, V0, P0
   Lunga D, 2020, IEEE J-STARS, V13, P271, DOI 10.1109/JSTARS.2019.2959707
   Lunga D, 2018, IEEE J-STARS, V11, P962, DOI 10.1109/JSTARS.2018.2795753
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mboga N, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111106
   Montanges A.P., 2015, IEEE, V0, PP1, DOI 10.1109/JURSE.2015.7120489
   Moon K., 2009, P 45 ISOCARP C, V0, P0
   Myint SW, 2006, GEOGR ANAL, V38, P371, DOI 10.1111/j.1538-4632.2006.00691.x
   Novack T, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060842
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pauleit S, 2000, LANDSCAPE URBAN PLAN, V52, P1, DOI 10.1016/S0169-2046(00)00109-2
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Pesaresi M, 2008, IEEE J-STARS, V1, P180, DOI 10.1109/JSTARS.2008.2002869
   PLOTNICK RE, 1993, LANDSCAPE ECOL, V8, P201, DOI 10.1007/BF00125351
   Sandborn A, 2016, IEEE J-STARS, V9, P1970, DOI 10.1109/JSTARS.2016.2519843
   Sheng GF, 2012, INT J REMOTE SENS, V33, P2395, DOI 10.1080/01431161.2011.608740
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Taubenbock H, 2018, APPL GEOGR, V92, P150, DOI 10.1016/j.apgeog.2018.02.002
   Taubenbock H, 2013, REMOTE SENS ENVIRON, V136, P386, DOI 10.1016/j.rse.2013.05.019
   Triggs, 2005, PROC CVPR IEEE, V1, P886, DOI 10.1109/CVPR.2005.177
   Unsalan C, 2004, IEEE T GEOSCI REMOTE, V42, P907, DOI 10.1109/TGRS.2003.818835
   van der Walt S, 2014, PEERJ, V2, P0, DOI 10.7717/peerj.453
   van Wyk M. A., 2008, P IEEE INT GEOSC REM, V3, P0
   Wang J, 2019, REMOTE SENS ENVIRON, V234, P0, DOI 10.1016/j.rse.2019.111448
   Wang SL, 2018, PROC CVPR IEEE, V0, PP2589, DOI 10.1109/CVPR.2018.00274
   Weber EM, 2018, REMOTE SENS ENVIRON, V204, P786, DOI 10.1016/j.rse.2017.09.024
   Wheeler SM, 2015, J AM PLANN ASSOC, V81, P167, DOI 10.1080/01944363.2015.1081567
   Wurm M., 2010, EARTH RESOURCES ENV, V7831, P123
   Wurm M., 2009, P JOINT URB REM SENS, V0, P1
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yang Y, 2010, PROC 18 SIGSPATIAL I, V0, P0, DOI DOI 10.1145/1869790.1869829
   Yu F., 2016, INT C LEARN REPR ICL, V0, P1
   Yuan JY, 2015, IEEE T IMAGE PROCESS, V24, P3488, DOI 10.1109/TIP.2015.2446948
   Zhang Q, 2003, INT J REMOTE SENS, V24, P4137, DOI 10.1080/0143116031000070445
   Zhao H., 2016, ARXIV161201105, V0, P0
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 69
TC 4
Z9 4
U1 12
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2634
EP 2648
DI 10.1109/JSTARS.2021.3052961
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QT3WH
UT WOS:000626519900003
DA 2023-04-26
ER

PT J
AU Zuo, YF
   Fu, X
   Liu, ZY
   Huang, D
AF Zuo, Yufan
   Fu, Xiao
   Liu, Zhiyuan
   Huang, Di
TI Short-term forecasts on individual accessibility in bus system based on neural network model
SO JOURNAL OF TRANSPORT GEOGRAPHY
LA English
DT Article
DE Individual accessibility; Bus system; Neural network model; Smart card records; Points of interest
ID rapid-transit; equity; travel; quality; time
AB Precise forecasts on individual accessibility in bus system can help make policies to accommodate fluctuating bus travel demand and promoting social equity. In this study, we propose a three-stage method for short-term forecasts on individual accessibility in bus system based on neural network (NN) model. In the first stage, a NN model is designed to tackle the nonlinear mapping between passengers' bus trip appearances in historical periods and those in the predicted period. A rate function, which considers bus trip generation rates of passengers, is then applied using outputs of the designed NN model. In the second stage, probabilities of origindestinations (ODs) chosen by passengers in the predicted period are calculated. In the third stage, land use information combined with results of previous two stages are used to obtain the individual accessibility in bus system in the predicted period. Compared to individual accessibility calculated by real data, it is found that the average errors of predicted results by the proposed method in weekdays and at weekends are only 8.37% and 10.13%, respectively. The results also demonstrate the capability of combining a NN model, traffic data and land use information to forecast the future spatial distribution of individual accessibility in transport system.
C1 [Zuo, Yufan; Fu, Xiao; Liu, Zhiyuan] Southeast Univ, Jiangsu Prov Collaborat Innovat Ctr Modern Urban, Sch Transportat, Jiangsu Key Lab Urban ITS, Nanjing 211189, Peoples R China.
   [Huang, Di] Hong Kong Polytech Univ, Dept Logist & Maritime Studies, Hong Kong, Peoples R China.
C3 Southeast University - China; Hong Kong Polytechnic University
RP Fu, X (corresponding author), Southeast Univ, Jiangsu Prov Collaborat Innovat Ctr Modern Urban, Sch Transportat, Jiangsu Key Lab Urban ITS, Nanjing 211189, Peoples R China.
EM fuxiao@seu.edu.cn
FU National Natural Science Foundation of China [71601045]; MOE (Ministry of Education in China) Project of Humanities, Social Sciences [20YJAZH083]; "Zhishan" Scholars Programs of Southeast University
CR [Anonymous], 2014, INT C LEARN REPR ICL, V0, P0
   Ben-Elia E, 2019, TRANSPORT RES A-POL, V120, P31, DOI 10.1016/j.tra.2018.11.017
   Cao XY, 2010, INT J SUSTAIN TRANSP, V4, P347, DOI 10.1080/15568310903145212
   Chen BY, 2019, TRANSPORT RES D-TR E, V75, P156, DOI 10.1016/j.trd.2019.08.027
   Chen BY, 2018, ANN AM ASSOC GEOGR, V108, P1115, DOI 10.1080/24694452.2017.1411244
   Cohen T, 2020, J TRANSP GEOGR, V88, P0, DOI 10.1016/j.jtrangeo.2020.102863
   Devkota B, 2012, J TRANSP GEOGR, V24, P282, DOI 10.1016/j.jtrangeo.2012.03.007
   El-Geneidy A, 2016, TRANSPORT RES A-POL, V91, P302, DOI 10.1016/j.tra.2016.07.003
   Fu X., 2020, TRANSP A TRANSP SCI, V2, P1
   Fu X, 2018, TRANSPORTATION, V45, P23, DOI 10.1007/s11116-016-9720-8
   Geurs K, 2010, TRANSPORT RES D-TR E, V15, P382, DOI 10.1016/j.trd.2010.04.006
   Gholamialam A, 2019, GEOGR ANAL, V51, P73, DOI 10.1111/gean.12159
   Hu LQ, 2015, PROF GEOGR, V67, P154, DOI 10.1080/00330124.2014.886920
   Huang J, 2019, CITIES, V86, P83, DOI 10.1016/j.cities.2018.11.021
   Huang J, 2015, J TRANSP GEOGR, V48, P145, DOI 10.1016/j.jtrangeo.2015.09.004
   Iacono M, 2010, J TRANSP GEOGR, V18, P133, DOI 10.1016/j.jtrangeo.2009.02.002
   Jia R, 2018, ACCIDENT ANAL PREV, V121, P223, DOI 10.1016/j.aap.2018.09.018
   Kim S, 2013, TRANSPORT RES REC, V0, PP109, DOI 10.3141/2357-13
   Kwan MP, 2003, GEOGR ANAL, V35, P341
   Lam WHK, 2018, IN C IND ENG ENG MAN, V0, PP1623, DOI 10.1109/IEEM.2018.8607359
   Lee K, 2019, GEOGR ANAL, V51, P339, DOI 10.1111/gean.12166
   Lessa DA, 2019, J TRANSP GEOGR, V77, P1, DOI 10.1016/j.jtrangeo.2019.04.004
   Levine J., 2006, ZONED OUT REGULATION, V0, P0
   Li HY, 2019, APPL SOFT COMPUT, V83, P0, DOI 10.1016/j.asoc.2019.105620
   Liu L, 2016, GEOJOURNAL, V81, P817, DOI 10.1007/s10708-016-9739-6
   Liu R., 2008, TRANSP RED, V59, P478
   Liu ZC, 2020, J TRANSP ENG A-SYST, V146, P0, DOI 10.1061/JTEPBS.0000429
   Liu ZY, 2019, TRANSPORT RES C-EMER, V108, P130, DOI 10.1016/j.trc.2019.09.006
   Lucas K, 2016, TRANSPORTATION, V43, P473, DOI 10.1007/s11116-015-9585-2
   Lucas K, 2012, TRANSPORT POLICY, V20, P107, DOI 10.1016/j.tranpol.2012.01.013
   Ma ZL, 2014, TRANSPORT RES C-EMER, V39, P148, DOI 10.1016/j.trc.2013.12.008
   Menon AK, 2017, CIKM17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, V0, PP2207, DOI 10.1145/3132847.3133058
   Miller H, 2007, GEOGR COMPASS, V1, P503, DOI 10.1111/j.1749-8198.2007.00025.x
   Mulley C, 2017, INT J SUSTAIN TRANSP, V11, P3, DOI 10.1080/15568318.2015.1106223
   Neutens T, 2015, J TRANSP GEOGR, V43, P14, DOI 10.1016/j.jtrangeo.2014.12.006
   Neutens T, 2010, APPL GEOGR, V30, P561, DOI 10.1016/j.apgeog.2010.05.006
   Oviedo D, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11102795
   Pan YJ, 2020, J TRANSP GEOGR, V83, P0, DOI 10.1016/j.jtrangeo.2020.102663
   Pereira RHM, 2017, TRANSPORT REV, V37, P170, DOI 10.1080/01441647.2016.1257660
   Polson NG, 2017, TRANSPORT RES C-EMER, V79, P1, DOI 10.1016/j.trc.2017.02.024
   Rodriguez C, 2017, TRANSPORT RES REC, V0, PP35, DOI 10.3141/2634-06
   Tsai TH, 2009, EXPERT SYST APPL, V36, P3728, DOI 10.1016/j.eswa.2008.02.071
   van Wee B, 2011, EUR J TRANSP INFRAST, V11, P350
   Xing HF, 2018, COMPUT ENVIRON URBAN, V72, P134, DOI 10.1016/j.compenvurbsys.2018.06.005
   Xu MY, 2017, J TRANSP GEOGR, V62, P38, DOI 10.1016/j.jtrangeo.2017.05.010
   Zhang JL, 2020, IET INTELL TRANSP SY, V14, P1210, DOI 10.1049/iet-its.2019.0873
   Zhu JZ, 2014, TRANSPORT RES C-EMER, V47, P139, DOI 10.1016/j.trc.2014.06.011
   Zuo YF, 2020, GEO-SPAT INF SCI, V23, P248, DOI 10.1080/10095020.2020.1783189
NR 48
TC 12
Z9 12
U1 12
U2 40
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0966-6923
EI 1873-1236
J9 J TRANSP GEOGR
JI J. Transp. Geogr.
PD MAY 15
PY 2021
VL 93
IS 
BP 
EP 
DI 10.1016/j.jtrangeo.2021.103075
EA MAY 2021
PG 9
WC Economics; Geography; Transportation
SC Business & Economics; Geography; Transportation
GA SO7RV
UT WOS:000659173600005
DA 2023-04-26
ER

PT J
AU He, JL
   Xing, ZR
   Xiang, TQ
   Zhang, X
   Zhou, YH
   Xi, CY
   Lu, H
AF He, Jialuan
   Xing, Zirui
   Xiang, Tianqi
   Zhang, Xin
   Zhou, Yinghai
   Xi, Chuanyu
   Lu, Hai
TI Wireless Signal Propagation Prediction Based on Computer Vision Sensing Technology for Forestry Security Monitoring
SO SENSORS
LA English
DT Article
DE CV sensing technology; wireless signal; forestry security monitoring; diffraction loss; shadow fading; convolutional neural network
ID neural-networks
AB In this paper, Computer Vision (CV) sensing technology based on Convolutional Neural Network (CNN) is introduced to process topographic maps for predicting wireless signal propagation models, which are applied in the field of forestry security monitoring. In this way, the terrain-related radio propagation characteristic including diffraction loss and shadow fading correlation distance can be predicted or extracted accurately and efficiently. Two data sets are generated for the two prediction tasks, respectively, and are used to train the CNN. To enhance the efficiency for the CNN to predict diffraction losses, multiple output values for different locations on the map are obtained in parallel by the CNN to greatly boost the calculation speed. The proposed scheme achieved a good performance in terms of prediction accuracy and efficiency. For the diffraction loss prediction task, 50% of the normalized prediction error was less than 0.518%, and 95% of the normalized prediction error was less than 8.238%. For the correlation distance extraction task, 50% of the normalized prediction error was less than 1.747%, and 95% of the normalized prediction error was less than 6.423%. Moreover, diffraction losses at 100 positions were predicted simultaneously in one run of CNN under the settings in this paper, for which the processing time of one map is about 6.28 ms, and the average processing time of one location point can be as low as 62.8 us. This paper shows that our proposed CV sensing technology is more efficient in processing geographic information in the target area. Combining a convolutional neural network to realize the close coupling of a prediction model and geographic information, it improves the efficiency and accuracy of prediction.
C1 [He, Jialuan] China Univ Min & Technol, Sch Mech Elect & Informat Engn, Beijing 100083, Peoples R China.
   [He, Jialuan; Xing, Zirui] Beijing Aerocim Technol Co Ltd, Beijing 102308, Peoples R China.
   [Xiang, Tianqi; Zhang, Xin] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
   [Zhou, Yinghai; Xi, Chuanyu; Lu, Hai] China Acad Engineer Phys, Inst Comp Applicat, Mianyang 621054, Sichuan, Peoples R China.
C3 China University of Mining & Technology; Beijing University of Posts & Telecommunications; Chinese Academy of Engineering Physics
RP Lu, H (corresponding author), China Acad Engineer Phys, Inst Comp Applicat, Mianyang 621054, Sichuan, Peoples R China.
EM hejialuan@163.com; xingzirui1001@126.com; xiangtianqi@bupt.edu.cn; zhangxin@bupt.edu.cn; zhouyinghai19@gscaep.ac.cn; xicy@caep.cn; luhai@caep.cn
FU National Natural Science Foundation Project [51674269]
CR Al-Da Bbagh R.K., 2017, P 2017 8 INT C NETW, V0, P0
   [Anonymous], 2015, ICLR, V0, P0
   Badola A, 2020, 2021 IEEE PHOTONICS, V0, PP1, DOI 10.1109/IPC48725.2021.9593006
   Chen XL, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), V0, P1628
   Deng G., 2016, P INT ROB SYST TOK J, V0, P0
   Ding TB, 2014, IEEE T NEUR NET LEAR, V25, P1686, DOI 10.1109/TNNLS.2014.2306420
   Jiang W, 2019, IEEE ACCESS, V7, P118112, DOI 10.1109/ACCESS.2019.2937588
   Kawabata W, 2019, INT SYMP WIREL, V0, P0
   Kuno N., 2018, P 2018 INT S ANT PRO, V0, P1
   Liao RF, 2018, WIREL COMMUN MOB COM, V0, P0, DOI DOI 10.1155/2018/6497340
   Luo CC, 2021, IEEE T IND INFORM, V17, P5810, DOI 10.1109/TII.2020.3038761
   Ma YY, 2018, CHINA COMMUN, V15, P30, DOI 10.1109/CC.2018.8424580
   Neskovic A., 2001, P EL C 2002 MELECON, V0, P0
   Ng KH, 2006, IEEE T ANTENN PROPAG, V54, P2669, DOI 10.1109/TAP.2006.880775
   Ogou K., 2018, P 2018 IEEE INT WORK, V0, P0
   Politanskyi R., 2019, P INT C ADV INF COMM, V0, P0
   Qiu J, 2020, IEEE INTERNET THINGS, V7, P4682, DOI 10.1109/JIOT.2020.2969326
   Qiu J, 2020, IEEE T COMPUT SOC SY, V7, P225, DOI 10.1109/TCSS.2019.2946181
   Qiu J, 2020, IEEE T IND INFORM, V16, P2659, DOI 10.1109/TII.2019.2943906
   Rappaport T. S., 2002, WIRELESS COMMUNICATI, V0, P0
   Ribero M, 2019, INT CONF ACOUST SPEE, V0, PP4519, DOI 10.1109/ICASSP.2019.8682491
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Seyedsalehi S, 2019, 190806767 ARXIV, V0, P0
   Taygur MM, 2020, IEEE T ANTENN PROPAG, V68, P6277, DOI 10.1109/TAP.2020.2983775
   Wang AL, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20041151
   Wang YH, 2021, IEEE T INTELL TRANSP, V22, P5028, DOI 10.1109/TITS.2020.2970610
   Xu DL, 2020, INFORM FUSION, V64, P1, DOI 10.1016/j.inffus.2020.06.002
   Yu Tian, 2021, IEEE OPEN JOURNAL OF THE COMMUNICATIONS SOCIETY, V2, P132, DOI 10.1109/OJCOMS.2020.3042630
   Zang B, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21134536
   Zhang YB, 2021, IEEE WIREL COMMUN LE, V10, P266, DOI 10.1109/LWC.2020.3027774
NR 31
TC 0
Z9 0
U1 1
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD SEP 15
PY 2021
VL 21
IS 17
BP 
EP 
DI 10.3390/s21175688
PG 17
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA UO2NT
UT WOS:000694537300001
PM 34502579
DA 2023-04-26
ER

PT J
AU Madhuanand, L
   Nex, F
   Yang, MY
AF Madhuanand, Logambal
   Nex, Francesco
   Yang, Michael Ying
TI Self-supervised monocular depth estimation from oblique UAV videos
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Depth estimation; Monocular; UAV video; Self-supervised learning; Scene Understanding
ID stereo; shape
AB Unmanned Aerial Vehicles (UAVs) have become an essential photogrammetric measurement as they are affordable, easily accessible and versatile. Aerial images captured from UAVs have applications in small and large scale texture mapping, 3D modelling, object detection tasks, Digital Terrain Model (DTM) and Digital Surface Model (DSM) generation etc. Photogrammetric techniques are routinely used for 3D reconstruction from UAV images where multiple images of the same scene are acquired. Developments in computer vision and deep learning techniques have made Single Image Depth Estimation (SIDE) a field of intense research. Using SIDE techniques on UAV images can overcome the need for multiple images for 3D reconstruction. This paper aims to estimate depth from a single UAV aerial image using deep learning. We follow a self-supervised learning approach, Self-Supervised Monocular Depth Estimation (SMDE), which does not need ground truth depth or any extra information other than images for learning to estimate depth. Monocular video frames are used for training the deep learning model which learns depth and pose information jointly through two different networks, one each for depth and pose. The predicted depth and pose are used to reconstruct one image from the viewpoint of another image utilising the temporal information from videos. We propose a novel architecture with two 2D Convolutional Neural Network (CNN) encoders and a 3D CNN decoder for extracting information from consecutive temporal frames. A contrastive loss term is introduced for improving the quality of image generation. Our experiments are carried out on the public UAVid video dataset. The experimental results demonstrate that our model outperforms the state-of-the-art methods in estimating the depths.
C1 [Madhuanand, Logambal; Nex, Francesco; Yang, Michael Ying] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
C3 University of Twente
RP Yang, MY (corresponding author), Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
EM logambal.eeg@gmail.com; f.nex@utwente.nl; michael.yang@utwente.nl
CR Aicardi I, 2016, INT ARCH PHOTOGRAMM, V41, P835, DOI 10.5194/isprsarchives-XLI-B1-835-2016
   Alagoz B.B, 2016, COMPUT SCI, V1, P8
   Amirkolaee HA, 2019, ISPRS J PHOTOGRAMM, V149, P50, DOI 10.1016/j.isprsjprs.2019.01.013
   [Anonymous], 2020, PIX4D VERSION 4 4 12, V0, P0
   Bhandare A., 2016, INT J COMPUT SCI INF, V7, P2206
   Bian J., 2019, ADV NEUR IN, V32, P35
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS), V0, P0
   Chen KQ, 2018, ISPRS ANN PHOTO REM, V4-1, P29, DOI 10.5194/isprs-annals-IV-1-29-2018
   Dai Q., 2019, ARXIV191204250, V0, P0
   Eigen D, 2014, ADV NEUR IN, V27, P0
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, V0, PP3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2019, IEEE I CONF COMP VIS, V0, PP3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, V0, PP6602, DOI 10.1109/CVPR.2017.699
   Guizilini V, 2020, PROC CVPR IEEE, V0, PP2482, DOI 10.1109/CVPR42600.2020.00256
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hermann M., 2020, ISPRS ANN PHOTOGRAMM, V0, PP357, DOI 10.5194/isprsannals-v-2-2020-357-2020
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Julian K., 2017, UAV DEPTH PERCEPTION, V0, P1
   KANATANI K, 1989, ARTIF INTELL, V38, P1, DOI 10.1016/0004-3702(89)90066-0
   KANG SB, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, V0, P88, DOI 10.1109/ICCV.1995.466802
   Kendall A, 2017, IEEE I CONF COMP VIS, V0, PP66, DOI 10.1109/ICCV.2017.17
   Koch T, 2019, LECT NOTES COMPUT SC, V11131, P331, DOI 10.1007/978-3-030-11015-4_25
   Laina I, 2016, INT CONF 3D VISION, V0, PP239, DOI 10.1109/3DV.2016.32
   Li J, 2019, COMPUT VIS IMAGE UND, V186, P25, DOI 10.1016/j.cviu.2019.06.002
   Li Qing, 2020, DEEP LEARNING BASED, V0, P0
   Liang ZF, 2018, PROC CVPR IEEE, V0, PP2811, DOI 10.1109/CVPR.2018.00297
   Lichao M., 2018, IEEE T GEOSCI REMOTE, V56, P6699
   Liu FY, 2015, PROC CVPR IEEE, V0, PP5162, DOI 10.1109/CVPR.2015.7299152
   Lyu Y, 2020, ISPRS J PHOTOGRAMM, V165, P108, DOI 10.1016/j.isprsjprs.2020.05.009
   Madhuanand L., 2020, ISPRS ANN PHOTOGRAMM, V0, P451
   Mahjourian R, 2018, PROC CVPR IEEE, V0, PP5667, DOI 10.1109/CVPR.2018.00594
   Mayer N, 2016, PROC CVPR IEEE, V0, PP4040, DOI 10.1109/CVPR.2016.438
   Mehta I, 2018, INT CONF 3D VISION, V0, PP314, DOI 10.1109/3DV.2018.00044
   Nex F, 2015, ISPRS ANN PHOTO REM, V2-3, P135, DOI 10.5194/isprsannals-II-3-W4-135-2015
   Nex F, 2014, APPL GEOMAT, V6, P1, DOI 10.1007/s12518-013-0120-x
   Poggi M, 2018, IEEE INT C INT ROBOT, V0, PP5848, DOI 10.1109/IROS.2018.8593814
   Remondino Fabio, 2013, 2013 DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE). FEDERATING THE 19TH INTI VSMM, V0, P47
   Repala V.K., 2018, PATTERN RECOGN, V0, P0
   Saxena A., 2005, P NIPS, V18, P1
   Spencer J., 2020, P IEEECVF C COMPUTER, V0, P14402
   Szeliski R., 2000, LECT NOTES COMPUTER, V1883, P0, DOI 10.1007/3-540-44480-7_1
   Tan FT, 2020, PROC CVPR IEEE, V0, PP647, DOI 10.1109/CVPR42600.2020.00073
   Tosi F., 2018, LECT NOTES COMPUT SC, V0, PP337, DOI 10.1007/978-3-030-11009-3_20
   Tosi F, 2019, PROC CVPR IEEE, V0, PP9791, DOI 10.1109/CVPR.2019.01003
   Vallet J, 2011, INT ARCH PHOTOGRAMM, V38-1, P253
   van den Heuvel FA, 1998, ISPRS J PHOTOGRAMM, V53, P354, DOI 10.1016/S0924-2716(98)00019-7
   Vijayanarasimhan Sudheendra, 2017, SFMNET LEARNING STRU, V0, P0
   Voumard J, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111732
   Wang CY, 2018, PROC CVPR IEEE, V0, PP2022, DOI 10.1109/CVPR.2018.00216
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zbontar J, 2015, PROC CVPR IEEE, V0, PP1592, DOI 10.1109/CVPR.2015.7298767
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhou K, 2020, COMPUT INTEL NEUROSC, V2020, P0, DOI 10.1155/2020/8562323
   Zhou TH, 2017, PROC CVPR IEEE, V0, PP6612, DOI 10.1109/CVPR.2017.700
NR 56
TC 10
Z9 10
U1 7
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUN 15
PY 2021
VL 176
IS 
BP 1
EP 14
DI 10.1016/j.isprsjprs.2021.03.024
EA APR 2021
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SJ4AV
UT WOS:000655474600001
DA 2023-04-26
ER

PT J
AU Pradhan, AMS
   Kim, YT
   Shrestha, S
   Huynh, TC
   Nguyen, BP
AF Pradhan, Ananta Man Singh
   Kim, Yun-Tae
   Shrestha, Suchita
   Thanh-Canh Huynh
   Ba-Phu Nguyen
TI Application of deep neural network to capture groundwater potential zone in mountainous terrain, Nepal Himalaya
SO ENVIRONMENTAL SCIENCE AND POLLUTION RESEARCH
LA English
DT Article
DE Deep neural network; Geographic Information System; Groundwater potential; Mountainous terrain
ID regional-scale; land-cover; gis; model; area; district; water; jackknife; depletion; recharge
AB This study aims to capture groundwater potential zones integrating deep neural network and groundwater influencing factors. The present work was carried out for Gopi khola watershed, mountainous terrain in Nepal Himalaya as the watershed mainly relies upon the groundwater assets; it is a need to explore groundwater potential for better management of the aquifer framework. Ten groundwater influencing factors were collected such as elevation, slope, curvature, topographic positioning index, topographic roughness index, drainage density, topographic wetness index, geology, lineament density, and land use thematic layers. Among those influencing factors, topographic roughness index was removed because of multicollinearity issue to reduce the dimension of the dataset. A spring inventory map of 145 spring locations was prepared using field survey method and an equal number of spring absence points were randomly generated. The 70% of spring and spring absence pixels were used as training dataset and remaining as test dataset. The final map was created based on predicted probabilities ranging from 0 to 1. The validation was done using the receiver operating characteristic curve, which shows that the area under the curve is 76.1% for the training dataset and 82.1% for the test dataset. The sensitivity analysis was performed using Jackknife test which shows that the lineament density is the most important factor. The experimental results demonstrated that deep neural network is highly capable to capture groundwater potential zone in mountainous terrain. The present study might be useful and preliminary work to exploit the groundwater. The consequences of the current study may be valuable to water administrators to settle on appropriate choices on the ideal utilization of groundwater assets for future arranging in the basic investigation zone.
C1 [Pradhan, Ananta Man Singh] Govt Nepal, Water Resource Res & Dev Ctr, Minist Energy Water Resources & Irrigat, Lalitpur 44700, Nepal.
   [Kim, Yun-Tae] Pukyong Natl Univ, Dept Ocean Engn, Geosyst Engn Lab, 599-1,Daeyeon3 Dong, Busan 48513, South Korea.
   [Shrestha, Suchita] Govt Nepal, Dept Mines & Geol, Minist Ind Commerce & Supplies, Kathmandu 44600, Nepal.
   [Thanh-Canh Huynh] Duy Tan Univ, Dept Civil Engn, Da Nang, Vietnam.
   [Thanh-Canh Huynh] Duy Tan Univ, Ctr Construct Mech & Mat, Inst Res & Dev, Da Nang 550000, Vietnam.
   [Ba-Phu Nguyen] Ind Univ Ho Chi Minh City, Dept Civil Engn, Ho Chi Minh City 700000, Vietnam.
C3 Pukyong National University; Duy Tan University; Duy Tan University; Industrial University of Ho Chi Minh City
RP Pradhan, AMS (corresponding author), Govt Nepal, Water Resource Res & Dev Ctr, Minist Energy Water Resources & Irrigat, Lalitpur 44700, Nepal.
EM anantageo@hotmail.com
FU Korea Agency for Infrastructure Technology Advancement (KAIA) - Ministry of Land, Infrastructure and Transport [19TSRD-B151228-01]
CR Achu AL, 2020, GROUNDWATER SUST DEV, V10, P0, DOI 10.1016/j.gsd.2020.100365
   ACWORTH RI, 1987, Q J ENG GEOL, V20, P265, DOI 10.1144/GSL.QJEG.1987.020.04.02
   Allair J, 2017, KERAS R INTERFACE KE, V0, P0
   Anand B, 2021, ENVIRON SCI POLLUT R, V28, P18437, DOI 10.1007/s11356-020-09019-1
   Anand B, 2020, ENVIRON DEV SUSTAIN, V22, P2779, DOI 10.1007/s10668-019-00318-3
   Aragon R, 2011, ECOHYDROLOGY, V4, P433, DOI 10.1002/eco.149
   Arya S, 2020, ENVIRON EARTH SCI, V79, P0, DOI 10.1007/s12665-020-8832-9
   Balamurugan G, 2017, J KING SAUD UNIV SCI, V29, P333, DOI 10.1016/j.jksus.2016.08.003
   Banks EW, 2011, J HYDROL, V404, P30, DOI 10.1016/j.jhydrol.2011.04.017
   Barik K.K., 2017, INT J ADV REMOTE SEN, V6, P2068, DOI 10.23953/CLOUD.IJARSG.33
   Bekker PA, 2015, J ECONOMETRICS, V185, P332, DOI 10.1016/j.jeconom.2014.08.012
   Bengio Y., 2015, BIOL PLAUSIBLE DEEP, V0, P0
   Benjmel K, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12020471
   BOBBA AG, 1992, J HYDROL, V131, P25, DOI 10.1016/0022-1694(92)90212-E
   Botzen WJW, 2013, MITIG ADAPT STRAT GL, V18, P229, DOI 10.1007/s11027-012-9359-5
   Burnham K.P., 2002, MODEL SELECTION MULT, V0, PP49, DOI 10.1007/B97636
   Burrough P., 2015, PRINCIPLES GEOGRAPHI, V0, P0
   Condon LE, 2015, WATER RESOUR RES, V51, P6602, DOI 10.1002/2014WR016774
   Das S, 2017, MODEL EARTH SYST ENV, V3, P1589, DOI 10.1007/s40808-017-0396-7
   Davis SN, 1966, HYDROGEOLOGY, V0, P0
   De Reu J, 2013, GEOMORPHOLOGY, V186, P39, DOI 10.1016/j.geomorph.2012.12.015
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, PI, DOI 10.1561/2000000039
   Dhital MR, 2015, LESSER HIMALAYA KOSH, V0, P163
   Dao DV, 2020, CATENA, V188, P0, DOI 10.1016/j.catena.2019.104451
   Draper N.R., 1998, WILEY SERIES PROBABI, V0, P0
   Ercanoglu M, 2004, ENG GEOL, V75, P229, DOI 10.1016/j.enggeo.2004.06.001
   Falah F, 2017, GEOCARTO INT, V32, P1069, DOI 10.1080/10106049.2016.1188166
   Ferozur RM, 2019, GROUNDWATER SUST DEV, V8, P205, DOI 10.1016/j.gsd.2018.11.006
   Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088
   Fienen M. N., 2016, INTEGRATED GROUNDWAT, V0, PP21, DOI 10.1007/978-3-319-23576-9_29
   Gintamo TT, 2015, AM SCI RES J ENG TEC, V0, P0
   Guisan A, 1999, PLANT ECOL, V143, P107, DOI 10.1023/A:1009841519580
   Aouragh MH, 2017, GEOMAT NAT HAZ RISK, V8, P194, DOI 10.1080/19475705.2016.1181676
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Jahan CS, 2019, SUST WAT RESOUR MAN, V5, P689, DOI 10.1007/s40899-018-0240-x
   Jenks G., 1967, INT YB CARTOGRAPHY, V7, P186
   Karunanidhi D, 2014, ARAB J GEOSCI, V7, P1791, DOI 10.1007/s12517-013-0881-x
   Kavzoglu T, 2014, LANDSLIDES, V11, P425, DOI 10.1007/s10346-013-0391-7
   Konikow LF, 2005, HYDROGEOL J, V13, P317, DOI 10.1007/s10040-004-0411-8
   Kuhlmeier PD, 1992, ASTM SPECIAL TECHNIC, V0, P183
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lerner DN, 2009, LAND USE POLICY, V26, PS265, DOI 10.1016/j.landusepol.2009.09.005
   Lilburne L, 2009, INT J GEOGR INF SCI, V23, P151, DOI 10.1080/13658810802094995
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   Mahmood A., 1996, CANADIAN J REMOTE SE, V22, P108, DOI 10.1080/07038992.1996.10874641
   Marblestone AH, 2016, FRONT COMPUT NEUROSC, V10, P0, DOI 10.3389/fncom.2016.00094
   Meijerink A.M.J., 2000, REMOTE SENSING HYDRO, V0, P305
   Menard S. W., 1995, APPL LOGISTIC REGRES, V0, P0
   MILLER RG, 1974, BIOMETRIKA, V61, P1
   Moghaddam DD, 2015, ARAB J GEOSCI, V8, P913, DOI 10.1007/s12517-013-1161-5
   Moghaddam DD, 2020, CATENA, V187, P0, DOI 10.1016/j.catena.2019.104421
   Molnar P, 2007, J GEOPHYS RES-EARTH, V112, P0, DOI 10.1029/2005JF000433
   MOORE ID, 1991, HYDROL PROCESS, V5, P3, DOI 10.1002/hyp.3360050103
   Moukana JA, 2008, COMPUT GEOSCI-UK, V34, P1527, DOI 10.1016/j.cageo.2007.11.005
   MURRAY C, 1982, HOLARCTIC ECOL, V5, P109
   Nag SK, 2005, PHOTONIRVACHAK-J IND, V33, P521
   Naghibi SA, 2016, ENVIRON MONIT ASSESS, V188, P0, DOI 10.1007/s10661-015-5049-6
   Naghibi SA, 2015, WATER RESOUR MANAG, V29, P5217, DOI 10.1007/s11269-015-1114-8
   Nampak H, 2014, J HYDROL, V513, P283, DOI 10.1016/j.jhydrol.2014.02.053
   OBrien RM, 2007, QUAL QUANT, V41, P673, DOI 10.1007/s11135-006-9018-6
   Oh HJ, 2011, J HYDROL, V399, P158, DOI 10.1016/j.jhydrol.2010.12.027
   Okello C, 2015, WATER-SUI, V7, P1264, DOI 10.3390/w7031264
   Ozdemir A, 2011, J HYDROL, V405, P123, DOI 10.1016/j.jhydrol.2011.05.015
   Palanisamy A, 2021, ENVIRON SCI POLLUT R, V28, P18423, DOI 10.1007/s11356-020-08518-5
   Pathak D, 2016, J NEPAL GEOL SOC, V50, P161, DOI 10.3126/jngs.v50i1.22878
   Pradhan AMS, 2019, B ENG GEOL ENVIRON, V78, P5745, DOI 10.1007/s10064-019-01533-y
   Pradhan AMS, 2018, GEOCARTO INT, V33, P810, DOI 10.1080/10106049.2017.1303089
   Rahmati O, 2016, CATENA, V137, P360, DOI 10.1016/j.catena.2015.10.010
   Razandi Y, 2015, EARTH SCI INFORM, V8, P867, DOI 10.1007/s12145-015-0220-8
   Riley SJ, 1999, INTERMT J SCI, VSci5, P23, DOI 10.1016/j.geomorph.2010.11.003
   Rizeei HM, 2019, J HYDROL, V579, P0, DOI 10.1016/j.jhydrol.2019.124172
   Rossi M, 2010, GEOMORPHOLOGY, V114, P129, DOI 10.1016/j.geomorph.2009.06.020
   Sander P, 2007, HYDROGEOL J, V15, P71, DOI 10.1007/s10040-006-0138-9
   Schwartz A, 1974, CALCULUS ANAL GEOMET, V0, P0
   Selvam S, 2015, ENVIRON EARTH SCI, V73, P3785, DOI 10.1007/s12665-014-3664-0
   Shrestha S, 2015, CARDIOVASCULAR GENETICS AND GENOMICS IN CLINICAL PRACTICE, V0, P3
   Singh LK, 2017, J CLEAN PROD, V142, P1436, DOI 10.1016/j.jclepro.2016.11.163
   Todd D.K., 2005, GROUNDWATER HYDROLOG, V0, P0
   Tundisi José Galizia, 2008, ESTUD. AV., V22, P7, DOI 10.1590/S0103-40142008000200002
   Wilson JP, 2000, TERRAIN ANAL PRINCIP, V0, P0
   Wirth SB, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12030821
   Yidana SM, 2020, APPL GEOCHEM, V115, P0, DOI 10.1016/j.apgeochem.2020.104533
   Yin HY, 2018, J HYDROL, V557, P434, DOI 10.1016/j.jhydrol.2017.12.043
   Zabihi M, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5424-9
   Zhang XF, 2014, AGR WATER MANAGE, V146, P270, DOI 10.1016/j.agwat.2014.08.017
   Zhang YK, 2006, J HYDROL, V319, P328, DOI 10.1016/j.jhydrol.2005.06.044
NR 86
TC 19
Z9 19
U1 1
U2 7
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0944-1344
EI 1614-7499
J9 ENVIRON SCI POLLUT R
JI Environ. Sci. Pollut. Res.
PD APR 15
PY 2021
VL 28
IS 15
BP 18501
EP 18517
DI 10.1007/s11356-020-10646-x
EA SEP 2020
PG 17
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA RI6VU
UT WOS:000565202500001
PM 32875448
DA 2023-04-26
ER

PT J
AU Al-Hameedi, WMM
   Chen, J
   Faichia, C
   Al-Shaibah, B
   Nath, B
   Abdulla-Al Kafy
   Hu, G
   Al-Aizari, A
AF Al-Hameedi, Wafaa Majeed Mutashar
   Chen, Jie
   Faichia, Cheechouyang
   Al-Shaibah, Bazel
   Nath, Biswajit
   Abdulla-Al Kafy
   Hu, Gao
   Al-Aizari, Ali
TI Remote Sensing-Based Urban Sprawl Modeling Using Multilayer Perceptron Neural Network Markov Chain in Baghdad, Iraq
SO REMOTE SENSING
LA English
DT Article
DE GIS; remote sensing; MLP neural network method; Markov chain model; land use/cover change; future urban simulation; Baghdad
ID land-use change; cover change; prediction; city; growth; environment; regression; gis
AB The global and regional land use/cover changes (LUCCs) are experiencing widespread changes, particularly in Baghdad City, the oldest city of Iraq, where it lacks ecological restoration and environmental management actions at present. To date, multiple land uses are experiencing urban construction-related land expansion, population increase, and socioeconomic development. Comprehensive evaluation and understanding of the effect of urban sprawl and its rapid LUCC are of great importance to managing land surface resources for sustainable development. The present research applied remote sensing data, such as Landsat-5 Thematic Mapper and Landsat-8 Operation Land Imager, on selected images between July and August from 1985 to 2020 with the use of multiple types of software to explore, classify, and analyze the historical and future LUCCs in Baghdad City. Three historical LUCC maps from 1985, 2000, and 2020 were created and analyzed. The result shows that urban construction land expands quickly, and agricultural land and natural vegetation have had a large loss of coverage during the last 35 years. The change analysis derived from previous land use was used as a change direction for future simulation, where natural and anthropogenic factors were selected as the drivers' variables in the process of multilayer perceptron neural network Markov chain model. The future land use/cover change (FLUCC) modeling results from 2030 to 2050 show that agriculture is the only land use type with a massive decreasing trend from 1985 to 2050 compared with other categories. The entire change in urban sprawl derived from historical and FLUCC in each period shows that urban construction land increases the fastest between 2020 and 2030. The rapid urbanization along with unplanned urban growth and rising population migration from rural to urban is the main driver of all transformation in land use. These findings facilitate sustainable ecological development in Baghdad City and theoretically support environmental decision making.
C1 [Al-Hameedi, Wafaa Majeed Mutashar; Chen, Jie; Hu, Gao] Cent South Univ, Sch Geosci & Infophys, Changsha 410083, Peoples R China.
   [Faichia, Cheechouyang; Al-Shaibah, Bazel; Al-Aizari, Ali] Northeast Normal Univ, Sch Environm, Inst Nat Disaster Res, Changchun 130024, Peoples R China.
   [Nath, Biswajit] Univ Chittagong, Dept Geog & Environm Studies, Chittagong 4331, Bangladesh.
   [Abdulla-Al Kafy] Rajshahi City Corp, Int Council Local Environm Initiat ICLEI South As, Rajshahi 6203, Bangladesh.
   [Abdulla-Al Kafy] Rajshahi Univ Engn & Technol RUET, Dept Urban & Reg Planning, Rajshahi 6204, Bangladesh.
C3 Central South University; Northeast Normal University - China; University of Chittagong; Rajshahi University of Engineering & Technology (RUET)
RP Chen, J (corresponding author), Cent South Univ, Sch Geosci & Infophys, Changsha 410083, Peoples R China.
EM wahua2014@csu.edu.cn; cj2011@csu.edu.cn; Cheny349@nenu.edu.cn; zee298@nenu.edu.cn; nath.gis79@cu.ac.bd; abdulla-al.kafy@localpathways.org; 195018002@csu.edu.cn; ruij253@nenu.edu.cn
FU Science and Technology Planning Project of Changsha [kh2005069]
CR Abbas Zahraa, 2020, IOP CONFERENCE SERIES: MATERIALS SCIENCE AND ENGINEERING, V745, P0, DOI 10.1088/1757-899X/745/1/012166
   Abdulkareem A.K., 2020, PLANT ARCH, V20, P1028
   Ahmed F., 2010, THESIS U KWAZULU NAT, V0, P0
   Ahmed SJ, 2014, SPRING GEOGR, V0, PP123, DOI 10.1007/978-94-007-6735-5_7
   Aitkenhead MJ, 2009, J ENVIRON MANAGE, V90, P236, DOI 10.1016/j.jenvman.2007.09.010
   Al-Ramahi FKM, 2020, IRAQI J AGRIC SCI, V51, P21
   Ali JM, 2017, SUSTAIN CITIES SOC, V29, P159, DOI 10.1016/j.scs.2016.12.010
   Almukhtar S., 2014, EFFECT URBAN CONFLIC, V0, P0
   Amin A., 2012, THESIS ALIGARH MUSLI, V0, P0
   Armin M, 2020, ARID ECOSYST, V10, P203, DOI 10.1134/S2079096120030129
   Arsanjani JJ, 2011, INT J IMAGE DATA FUS, V2, P329, DOI 10.1080/19479832.2011.605397
   BENGIO Y, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P1183, DOI 10.1109/ICNN.1993.298725
   Cao H, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9020137
   Chabuk A, 2019, ENVIRON SCI POLLUT R, V26, P35325, DOI 10.1007/s11356-019-05064-7
   Chauhan RP, 2020, PATHOGENS, V9, P0, DOI 10.3390/pathogens9050355
   Chen LP, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0200493
   Clarke KC., 2014, HDB REGIONAL SCI, V0, PP1217, DOI 10.1007/978-3-642-23430-9_63
   Cohen JE, 2005, SCI AM, V293, P48, DOI 10.1038/scientificamerican0905-48
   Congalton RG, 2001, INT J WILDLAND FIRE, V10, P321, DOI 10.1071/WF01031
   Dadhich Pran Nath, 2010, SELECTED TOPICS IN POWER SYSTEMS AND REMOTE SENSING. 10TH WSEAS/IASME INTERNATIONAL CONFERENCE ON ELECTRIC POWER SYSTEMS, V0, P0
   Dale VH, 1997, ECOL APPL, V7, P753, DOI 10.1890/1051-0761(1997)007[0753:TRBLUC]2.0.CO;2
   Dey NN., 2021, ENV CHALLENGES, V4, P100148, DOI 10.1016/j.envc.2021.100148
   Dixon B, 2008, INT J REMOTE SENS, V29, P1185, DOI 10.1080/01431160701294661
   Dongjie G, 2008, J GEOGR SCI, V18, P455, DOI 10.1007/s11442-008-0455-0
   Dzieszko P, 2014, QUAEST GEOGR, V33, P5, DOI 10.2478/quageo-2014-0004
   Faichia C, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12208410
   Fattah M.H., 2009, BRIEF HIST IRAQ, V0, P0
   Fazal S., 2013, SPRINGER BRIEFS GEOG, V0, P0
   Frank RJ, 2001, J INTELL ROBOT SYST, V31, P91, DOI 10.1023/A:1012074215150
   Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430
   Graham S., 2011, CITIES SIEGE NEW MIL, V0, P402
   Gumrah F, 2000, WATER AIR SOIL POLL, V119, P275, DOI 10.1023/A:1005165315197
   Gutierrez RS, 2008, INT J PROD ECON, V111, P409, DOI 10.1016/j.ijpe.2007.01.007
   Hadi Memarian, 2012, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V4, P542, DOI 10.4236/jgis.2012.46059
   Hamdy H.Q., 2020, INT J SCI RES, V9, P412
   Hoornweg D, 2017, ENVIRON URBAN, V29, P195, DOI 10.1177/0956247816663557
   Hsu LC, 2003, TECHNOL FORECAST SOC, V70, P563, DOI 10.1016/S0040-1625(02)00195-6
   Hua AK, 2017, J ENVIRON PUBLIC HEA, V2017, P0, DOI 10.1155/2017/7515130
   Hyandye C., 2015, AM J REMOTE SENS, V3, P6, DOI 10.11648/j.ajrs.20150301.12
   Jaeger JAG, 2010, ECOL INDIC, V10, P427, DOI 10.1016/j.ecolind.2009.07.010
   JONES LW, 1969, MIDDLE EAST J, V23, P209
   Kafy A.A., 2021, ENV CHALLENGES, V4, P0
   Kafy A.-A., 2021, BANGLADESH ENV CHALL, V4, P0, DOI 10.1016/j.envc.2021
   Khawaldah H. A., 2016, JOURNAL OF GEOGRAPHIC INFORMATION SYSTEM, V8, P412, DOI 10.4236/jgis.2016.83035
   Kotaridis I., 2018, CIV ENG ARCHIT, V6, P108, DOI 10.13189/cea.2018.060207
   Kumar S, 2014, GEOMAT NAT HAZ RISK, V5, P145, DOI 10.1080/19475705.2013.795502
   Lambin EF, 2003, ANNU REV ENV RESOUR, V28, P205, DOI 10.1146/annurev.energy.28.050302.105459
   Li P, 2019, RESPIRATION, V98, P239, DOI 10.1159/000500428
   Li X, 2017, ANN AM ASSOC GEOGR, V107, P1040, DOI 10.1080/24694452.2017.1303357
   Lin YP, 2011, INT J GEOGR INF SCI, V25, P65, DOI 10.1080/13658811003752332
   Long HL, 2007, LAND USE POLICY, V24, P141, DOI 10.1016/j.landusepol.2005.11.003
   Mallupattu PK, 2013, SCI WORLD J, V0, P0, DOI DOI 10.1155/2013/268623
   Mas J. F., 2004, INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION, V5, P249, DOI 10.1016/j.jag.2004.06.002
   Matlhodi B, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13132427
   Menezes J.M.P., 2006, P 9 BRAZ S NEUR NETW, V0, P0
   Mitrea CA, 2009, INT J ENG BUS MANAG, V1, P19
   Mohamedmeki Mohammed Zuhair, 2020, IOP CONFERENCE SERIES: MATERIALS SCIENCE AND ENGINEERING, V870, P0, DOI 10.1088/1757-899X/870/1/012101
   Omar NQ, 2014, J INDIAN SOC REMOTE, V42, P165, DOI 10.1007/s12524-013-0311-2
   Parse VA, 2016, J URBAN MANAG, V5, P43, DOI 10.1016/j.jum.2016.11.001
   Qassim ZH, 2020, AIP CONF PROC, V2307, P0, DOI 10.1063/5.0033128
   Qian YP, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11030933
   Rimal B, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040628
   Roy S., 2015, INT J SCI BASIC APPL, V24, P125
   Rwanga S. S., 2017, INTERNATIONAL JOURNAL OF GEOSCIENCES, V8, P611, DOI 10.4236/ijg.2017.84033
   Shamsi S. R. F., 2010, JOURNAL OF APPLIED SCIENCES AND ENVIRONMENTAL MANAGEMENT, V14, P81
   Shen L., 2020, J ENV INFORMATICS LE, V0, P0, DOI DOI 10.3808/JEIL.202000023
   Siebeneck LK, 2009, STUD CONFL TERROR, V32, P591, DOI 10.1080/10576100902961789
   Sirkeci I, 2005, INT MIGR, V43, P197, DOI 10.1111/j.1468-2435.2005.00338.x
   Sirkeci I., 2008, RETHINKING GLOBAL MI, V0, P161
   Somvanshi SS, 2020, ENVIRON DEV SUSTAIN, V22, P1073, DOI 10.1007/s10668-018-0234-8
   Wan E.A., 1994, FINITE IMPULSE RESPO, V0, P0
   Wang SW, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12093925
   Weng QH, 2002, J ENVIRON MANAGE, V64, P273, DOI 10.1006/jema.2001.0509
   Yang XJ, 2002, PHOTOGRAMM ENG REM S, V68, P725
   Zhou ML, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13152850
NR 77
TC 11
Z9 11
U1 2
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD OCT 15
PY 2021
VL 13
IS 20
BP 
EP 
DI 10.3390/rs13204034
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XI9VF
UT WOS:000726448700001
DA 2023-04-26
ER

PT J
AU Cota, G
   Sagan, V
   Maimaitijiang, M
   Freeman, K
AF Cota, Gizelle
   Sagan, Vasit
   Maimaitijiang, Maitiniyazi
   Freeman, Karen
TI Forest Conservation with Deep Learning: A Deeper Understanding of Human Geography around the Betampona Nature Reserve, Madagascar
SO REMOTE SENSING
LA English
DT Article
DE forest cover mapping; land cover mapping; FCNN; Betampona Nature Reserve (BNR); WorldView-3 SWIR; conservation efforts; Madagascar Flora and Fauna Group (MFG)
ID tropical rain-forest; remote-sensing data; land-cover; classification; degradation
AB Documenting the impacts of climate change and human activities on tropical rainforests is imperative for protecting tropical biodiversity and for better implementation of REDD+ and UN Sustainable Development Goals. Recent advances in very high-resolution satellite sensor systems (i.e., WorldView-3), computing power, and machine learning (ML) have provided improved mapping of fine-scale changes in the tropics. However, approaches so far focused on feature extraction or the extensive tuning of ML parameters, hindering the potential of ML in forest conservation mapping by not using textural information, which is found to be powerful for many applications. Additionally, the contribution of shortwave infrared (SWIR) bands in forest cover mapping is unknown. The objectives were to develop end-to-end mapping of the tropical forest using fully convolution neural networks (FCNNs) with WorldView-3 (WV-3) imagery and to evaluate human impact on the environment using the Betampona Nature Reserve (BNR) in Madagascar as the test site. FCNN (U-Net) using spatial/textural information was implemented and compared with feature-fed pixel-based methods including Support Vector Machine (SVM), Random Forest (RF), and Deep Neural Network (DNN). Results show that the FCNN model outperformed other models with an accuracy of 90.9%, while SVM, RF, and DNN provided accuracies of 88.6%, 84.8%, and 86.6%, respectively. When SWIR bands were excluded from the input data, FCNN provided superior performance over other methods with a 1.87% decrease in accuracy, while the accuracies of other models-SVM, RF, and DNN-decreased by 5.42%, 3.18%, and 8.55%, respectively. Spatial-temporal analysis showed a 0.7% increase in Evergreen Forest within the BNR and a 32% increase in tree cover within residential areas likely due to forest regeneration and conservation efforts. Other effects of conservation efforts are also discussed.
C1 [Cota, Gizelle; Sagan, Vasit; Maimaitijiang, Maitiniyazi] St Louis Univ, Geospatial Inst, St Louis, MO 63108 USA.
   [Cota, Gizelle; Sagan, Vasit; Maimaitijiang, Maitiniyazi] St Louis Univ, Dept Earth & Atmospher Sci, St Louis, MO 63108 USA.
   [Freeman, Karen] Madagascar Fauna & Flora Grp, Kalinka FK19 8NZ, Lochearnhead, Scotland.
C3 Saint Louis University; Saint Louis University
RP Sagan, V (corresponding author), St Louis Univ, Geospatial Inst, St Louis, MO 63108 USA.; Sagan, V (corresponding author), St Louis Univ, Dept Earth & Atmospher Sci, St Louis, MO 63108 USA.
EM gizelle.cota@slu.edu; vasit.sagan@slu.edu; mason.maimaitijiang@slu.edu; karen.freeman@savethelemur.org
FU Saint Louis University Geospatial Institute; NASA [80NSSC20M0100]; IUCN's SOS Lemurs grant [2017A-093]
CR [Anonymous], 2015, ICLR, V0, P0
   Armstrong AH, 2011, TROP CONSERV SCI, V4, P428, DOI 10.1177/194008291100400406
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DeFries R, 2010, BIOL CONSERV, V143, P2870, DOI 10.1016/j.biocon.2010.02.010
   Den Biggelaar C, 2016, AM J RURAL DEV, V4, P31
   Farris AR, 2020, J HUNGER ENVIRON NUT, V15, P388, DOI 10.1080/19320248.2019.1566110
   Fauvel M., 2006, P 2006 IEEE INT C AC, V0, PPII, DOI 10.1109/ICASSP.2006.1660467
   Ferreira MP, 2019, ISPRS J PHOTOGRAMM, V149, P119, DOI 10.1016/j.isprsjprs.2019.01.019
   Fu G, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050498
   Ghulam A, 2015, REMOTE SENS-BASEL, V7, P6257, DOI 10.3390/rs70506257
   Ghulam A, 2014, IEEE J-STARS, V7, P4960, DOI 10.1109/JSTARS.2014.2319314
   Ghulam A, 2014, ISPRS J PHOTOGRAMM, V88, P174, DOI 10.1016/j.isprsjprs.2013.12.007
   Giang TL, 2020, IEEE ACCESS, V8, P186257, DOI 10.1109/ACCESS.2020.3030112
   Gibson L, 2013, SCIENCE, V341, P1508, DOI 10.1126/science.1240495
   Golden Christopher D., 2014, MADAGASCAR CONSERVATION & DEVELOPMENT, V9, P83
   Goodman SM, 2005, ORYX, V39, P73, DOI 10.1017/S0030605305000128
   Hamdi ZM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171976
   Han ZM, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9080478
   Hartling S, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19061284
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Jensen J.R, 2005, INTRO DIGITAL IMAGE, V3rd, P0
   Ji SP, 2021, IEEE T GEOSCI REMOTE, V59, P3816, DOI 10.1109/TGRS.2020.3020804
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Kuester M., 2016, RADIOMETRIC USE WORL, V0, P0
   Kull Christian A., 2014, MADAGASCAR CONSERVATION & DEVELOPMENT, V9, P60
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee SH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203372
   Li M, 2014, EUR J REMOTE SENS, V47, P389, DOI 10.5721/EuJRS20144723
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
   Pacifici F, 2014, IEEE T GEOSCI REMOTE, V52, P6241, DOI 10.1109/TGRS.2013.2295819
   Pandey PC, 2021, GEOCARTO INT, V36, P957, DOI 10.1080/10106049.2019.1629647
   Ratovonamana R.Y., 2006, ECOLOGICAL STUDY EXO, V0, P0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosa GM, 2012, BIODIVERS CONSERV, V21, P1531, DOI 10.1007/s10531-012-0262-x
   Sidike P, 2019, REMOTE SENS ENVIRON, V221, P756, DOI 10.1016/j.rse.2018.11.031
   Styger E, 2007, AGR ECOSYST ENVIRON, V119, P257, DOI 10.1016/j.agee.2006.07.012
   Tsai YH, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060927
   Vieilledent G, 2018, BIOL CONSERV, V222, P189, DOI 10.1016/j.biocon.2018.04.008
   Wagner FH, 2019, REMOTE SENS ECOL CON, V5, P360, DOI 10.1002/rse2.111
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, P0, DOI 10.1016/j.rse.2020.111716
   Zhu Y, 2021, IEEE J-STARS, V14, P3251, DOI 10.1109/JSTARS.2021.3055784
NR 52
TC 2
Z9 2
U1 4
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2021
VL 13
IS 17
BP 
EP 
DI 10.3390/rs13173495
PG 29
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UO2OX
UT WOS:000694540300001
DA 2023-04-26
ER

PT J
AU Zhu, Y
   Geiss, C
   So, EM
   Jin, Y
AF Zhu, Yue
   Geiss, Christian
   So, Emily
   Jin, Ying
TI Multitemporal Relearning With Convolutional LSTM Models for Land Use Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Image segmentation; Feature extraction; Semantics; Training; Deep learning; Task analysis; Classification postprocessing (CPP); con; volutional neural networks (CNNs); deep learning (DL); multi; temporal land use classification; relearning
ID remote-sensing imagery; semantic segmentation; scene classification; satellite images; neural-network; extraction; villages
AB In this article, we present a novel hybrid framework, which integrates spatial-temporal semantic segmentation with postclassification relearning, for multitemporal land use and land cover (LULC) classification based on very high resolution (VHR) satellite imagery. To efficiently obtain optimal multitemporal LULC classification maps, the hybrid framework utilizes a spatial-temporal semantic segmentation model to harness temporal dependency for extracting high-level spatial-temporal features. In addition, the principle of postclassification relearning is adopted to efficiently optimize model output. Thereby, the initial outcome of a semantic segmentation model is provided to a subsequent model via an extended input space to guide the learning of discriminative feature representations in an end-to-end fashion. Last, object-based voting is coupled with postclassification relearning for coping with the high intraclass and low interclass variances. The framework was tested with two different postclassification relearning strategies (i.e., pixel-based relearning and object-based relearning) and three convolutional neural network models, i.e., UNet, a simple Convolutional LSTM, and a UNet Convolutional-LSTM. The experiments were conducted on two datasets with LULC labels that contain rich semantic information and variant building morphologic features (e.g., informal settlements). Each dataset contains four time steps from WorldView-2 and Quickbird imagery. The experimental results unambiguously underline that the proposed framework is efficient in terms of classifying complex LULC maps with multitemporal VHR images.
C1 [Zhu, Yue; So, Emily; Jin, Ying] Univ Cambridge, Dept Architecture, Cambridge CB2 1TN, England.
   [Geiss, Christian] German Aerosp Ctr DLR, German Remote Sensing Data Ctr DFD, D-82234 Wessling Oberpfaffenhofe, Germany.
C3 University of Cambridge; Helmholtz Association; German Aerospace Centre (DLR)
RP Zhu, Y (corresponding author), Univ Cambridge, Dept Architecture, Cambridge CB2 1TN, England.
EM yz591@cam.ac.uk; christian.geiss@dlr.de; ekms2@cam.ac.uk; yj242@cam.ac.uk
FU EPSRC Innovation and Knowledge Centre for Smart Infrastructure and Construction - Collaborative Programme Tranche 2 [EP/L010917/1]; EPSRC Managing Air Green Inner Cities (MAGIC) Grant [EP/N010221/1]; 'Urban spatial modelling and decision-support system' project of the Beijing Innovation Centre for Future Urban Design; EPSRC [EP/N010221/1, EP/N021614/1] Funding Source: UKRI
CR Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   [Anonymous], 2015, INT C MED IM COMP CO, V0, P0
   [Anonymous], 2016, D529816 ASTM, V0, P0, DOI DOI 10.1520/D5298-16
   Azad R, 2019, IEEE INT CONF COMP V, V0, PP406, DOI 10.1109/ICCVW.2019.00052
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Gallego A.-J., 2019, REMOTE SENS-BASEL, V11, P0
   Geiss C, 2019, ISPRS J PHOTOGRAMM, V151, P42, DOI 10.1016/j.isprsjprs.2019.03.001
   Geiss C, 2017, IEEE GEOSCI REMOTE S, V14, P2008, DOI 10.1109/LGRS.2017.2747222
   Geiss C, 2016, IEEE T GEOSCI REMOTE, V54, P5952, DOI 10.1109/TGRS.2016.2576978
   Geiss C, 2015, IEEE GEOSCI REMOTE S, V12, P2336, DOI 10.1109/LGRS.2015.2477436
   Han XP, 2018, ISPRS J PHOTOGRAMM, V138, P57, DOI 10.1016/j.isprsjprs.2018.02.009
   Hao P, 2013, URBAN STUD, V50, P3394, DOI 10.1177/0042098013484534
   Hosseinianfar H, 2020, CONSUM COMM NETWORK, V0, P0
   Huang X, 2014, IEEE T GEOSCI REMOTE, V52, P7140, DOI 10.1109/TGRS.2014.2308192
   International Diabetes Federation, 2019, IDF DIABETES ATLAS, V0, P0
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, V0, PP680, DOI 10.1109/CVPRW.2016.90
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lei G, 2020, REMOTE SENS-BASEL, V12, P0
   Li MM, 2016, ISPRS J PHOTOGRAMM, V122, P192, DOI 10.1016/j.isprsjprs.2016.10.007
   Liu SJ, 2020, ISPRS J PHOTOGRAMM, V164, P229, DOI 10.1016/j.isprsjprs.2020.04.008
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu Y, 2020, IEEE ELECTR DEVICE L, V8, P0
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Martinis S, 2011, IEEE T GEOSCI REMOTE, V49, P251, DOI 10.1109/TGRS.2010.2052816
   Milletari F, 2018, LECT NOTES COMPUT SC, V11073, P667, DOI 10.1007/978-3-030-00937-3_76
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Qi Z., 2019, REMOTE SENS-BASEL, V11, P0
   Russwurm M, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7040129
   Sharma A, 2018, NEURAL NETWORKS, V105, P346, DOI 10.1016/j.neunet.2018.05.019
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Shi Q, 2018, IEEE T GEOSCI REMOTE, V56, P3468, DOI 10.1109/TGRS.2018.2800107
   Taubenbock H, 1900, V13, V0, P5251
   Teimouri N., 2019, REMOTE SENS-BASEL, V11, P0
   van Oostrum M, 2018, J URBAN DES, V23, P732, DOI 10.1080/13574809.2018.1427498
   Vuolo F, 2018, INT J APPL EARTH OBS, V72, P122, DOI 10.1016/j.jag.2018.06.007
   Wurm M, 2019, ISPRS J PHOTOGRAMM, V150, P59, DOI 10.1016/j.isprsjprs.2019.02.006
   Yeung D.-Y., 2015, ADV NEUR IN, V0, P802
   Yu XR, 2017, GISCI REMOTE SENS, V54, P741, DOI 10.1080/15481603.2017.1323377
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang XY, 2020, ISPRS J PHOTOGRAMM, V161, P1, DOI 10.1016/j.isprsjprs.2020.01.005
   Zhang XY, 2017, ISPRS J PHOTOGRAMM, V132, P170, DOI 10.1016/j.isprsjprs.2017.09.007
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhou ZY, 2020, IEEE ICC, V0, P0
NR 49
TC 14
Z9 14
U1 7
U2 26
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 3251
EP 3265
DI 10.1109/JSTARS.2021.3055784
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA RI8WL
UT WOS:000637186500003
DA 2023-04-26
ER

PT J
AU Rosado, R
   Abreu, AJ
   Arencibia, JC
   Gonzalez, H
   Hernandez, Y
AF Rosado, Reynaldo
   Joan Abreu, Aldis
   Arencibia, Jose C.
   Gonzalez, Hector
   Hernandez, Yanio
TI Consumer Price Index Forecasting Based on Univariate Time Series and a Deep Neural Network
SO PROGRESS IN ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION
LA English
DT Proceedings Paper
DE Consumer Price Index; Time series forecasting; Long Short-Term Memory
AB The global Consumer Price Index (CPI) is a monthly record, which allows measuring the variation of the final consumer prices of a given set of goods and services of households living in a given geographic region, city or country. The present work addresses the problem of CPI forecasting using different Long Short-Term Memory (LSTM) neural network architectures according to state of the art in time series forecasting. Univariate time series data are mapped by a multivariate spatiotemporal representation using a set of Box-Jenkins functions and a time window. Next, a Convolutional Neural Network (CNN) with a specific droop out function combines the feature set to make a more discriminative representation space of the multivariate data. Finally, a LSTM exploits the temporality relationship among the data. The pipeline results, by combining a CNN with a LSTM, showed an improvement in forecasting CPI time series over Ecuador available dataset with respect to other LSTM-based architectures and models.
C1 [Rosado, Reynaldo; Joan Abreu, Aldis; Arencibia, Jose C.; Gonzalez, Hector; Hernandez, Yanio] Univ Ciencias Informat UCI, Havana, Cuba.
RP Gonzalez, H (corresponding author), Univ Ciencias Informat UCI, Havana, Cuba.
EM rrosado@uci.cu; ajabreu@uci.cu; jcarencibia@uci.cu; hglez@uci.cu; yhernandezh@uci.cu
FU FONCI through project: Plataforma para el analisis de grandes volumenes de datos y su aplicacion a sectores estrategicos
CR [Anonymous], 1976, HOLDEN DAY SERIES TI, V0, P0
   Chang O., 2020, INT J ADV SCI ENG IN, V10, P1078
   Chung J., 2014, PROC NIPS 2014 WORKS, V0, P0
   COLLINS S, 1991, J BUS ECON STAT, V9, P267, DOI 10.2307/1391291
   Davis R.A., 1987, TIME SERIES THEORY M, V0, P0
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Fauzan, 2018, 3 INT C COMP ENV AGR, V0, P1
   Garcia S, 2009, SOFT COMPUT, V13, P959, DOI 10.1007/s00500-008-0392-y
   GRANGER CWJ, 1976, J ROY STAT SOC B MET, V38, P189
   Lim B., 2020, ARXIV200413408, V0, P0
   Lindemann B., 2021, PROCEDIA CIRP, V99, P650
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mohamed, 2020, AM J THEOR APPL STAT, V9, P143, DOI 10.11648/J.AJTAS.20200904.18
   Qin XW, 2018, 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND BUSINESS ANALYTICS (ICDSBA 2018), V0, PP329, DOI 10.1109/ICDSBA.2018.00069
   Rohmah M.F., 2020, J PHYS C SERIES, V1456, P0
   Torres JF, 2021, BIG DATA, V9, P3, DOI 10.1089/big.2020.0159
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Zahara S, 2020, J PHYS C SERIES, V1456, P0
NR 18
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
J9 LECT NOTES COMPUT SC
PD JUN 15
PY 2021
VL 13055
IS 
BP 33
EP 42
DI 10.1007/978-3-030-89691-1_4
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Imaging Science & Photographic Technology
SC Computer Science; Imaging Science & Photographic Technology
GA BS5EA
UT WOS:000728363500004
DA 2023-04-26
ER

PT J
AU Dubrovskaya, SA
   Ryakhov, RV
AF Dubrovskaya, S. A.
   Ryakhov, R., V
TI Cartographic modeling of the Russian steppe-zone urban landscapes with the use of neural networks
SO THEORETICAL AND APPLIED ECOLOGY
LA Russian
DT Article
DE artificial neural networks; digital relief model; geomorphic indicators; urbogeosystem; natural-anthropogenic complex
AB Based on the method of automated classification of artificial neural networks, an urban-ecological landscape cartographic model of Volgograd was constructed, using geomorphometric data to identify spatially homogeneous sections of the urban-geographic system landscape structures. The neural network approach and data of ecological-functional zoning allow us to carry out the spatial differentiation of urban ecosystems and to obtain reliable information that is necessary to improve the ecological situation of urban space. As a result of the application of the Self-organizing map learning algorithm and the created digital model, a cartographic model of urban landscapes was compiled, which is a reflection of the geographic environment and the processes of development of technogenic impacts on the state of the natural-anthropogenic complex. In the classification by the method of artificial neural networks, based on vertical differentiation, the features of horizontal geomorphometric indicators information is included. For the first time, the integration of selected genetic types of relief with the modern functional purpose of the zones of the studied urban ecosystem was carried out. The accumulative relief type of Volgograd is identified by the neural network algorithm as a single continual polygon, characterized by a fairly uniform orientation of the slopes. The above-terrace complex is represented by the Khvalynsk abrasive and accumulative terraces, identified by a neural network by morphometric parameters. The water partite geoecological area is presented by gully slopes and near watershed slopes. To classify the slope type of terrain, maps of the exposures along the lines of local watersheds are applied.
C1 [Dubrovskaya, S. A.; Ryakhov, R., V] Russian Acad Sci, Inst Steppe, Ural Branch, 11 Pionerskaya St, Orenburg 460000, Russia.
C3 Russian Academy of Sciences
RP Dubrovskaya, SA (corresponding author), Russian Acad Sci, Inst Steppe, Ural Branch, 11 Pionerskaya St, Orenburg 460000, Russia.
EM skaverina@bk.ru
CR Adamovich TA, 2017, THEOR APPL ECOL, V0, P15
   [Anonymous], 1995, NEURAL NETWORKS PATT, V0, P0
   Anopin V.N., 2012, VESTNIK VOLG GASU SA, V0, P200
   Brylev V.A., 2013, IZVESTIYA VUZOV SEVE, V0, P62
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kulik K.N., 2014, IZVESTIYA NIZHNEVOLZ, V0, P27
   Likhacheva E.A., 2002, RELIEF HUMAN ENV ECO, V0, P0
   Melikhova E.V., 2011, THEORETICAL PROBLEMS, V0, P305
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   Shary PA, 2002, GEODERMA, V107, P1, DOI 10.1016/S0016-7061(01)00136-7
   Trubina LK, 2018, BULL TOMSK POLYTECH, V329, P43
   Yermolaev O.P., 2014, WORLD APPL SCI J, V30, P1648, DOI 10.5829/idosi.wasj.2014.30.11.14229
   Zipperer WC, 2000, ECOL APPL, V10, P685, DOI 10.2307/2641038
NR 13
TC 0
Z9 0
U1 0
U2 3
PU LLC PUBLISHING HOUSE, KAMERTON
PI MOSCOW
PA 9, STROMYNKA ST, MOSCOW, 107014, RUSSIA
SN 1995-4301
EI 2618-8406
J9 THEOR APPL ECOL
JI Theor. Appl. Ecol.
PD JUN 15
PY 2021
VL 0
IS 1
BP 53
EP 57
DI 10.25750/1995-4301-2021-1-053-057
PG 6
WC Ecology
SC Environmental Sciences & Ecology
GA RB6KP
UT WOS:000632219100006
DA 2023-04-26
ER

PT J
AU Dabija, A
   Kluczek, M
   Zagajewski, B
   Raczko, E
   Kycko, M
   Al-Sulttani, AH
   Tarda, A
   Pineda, L
   Corbera, J
AF Dabija, Anca
   Kluczek, Marcin
   Zagajewski, Bogdan
   Raczko, Edwin
   Kycko, Marlena
   Al-Sulttani, Ahmed H.
   Tarda, Anna
   Pineda, Lydia
   Corbera, Jordi
TI Comparison of Support Vector Machines and Random Forests for Corine Land Cover Mapping
SO REMOTE SENSING
LA English
DT Article
DE land cover mapping; Corine; Random Forest; Support Vector Machine; Braila; Catalonia; Warsaw
ID species classification; neural-networks; accuracy; area; sentinel-2; scale
AB Land cover information is essential in European Union spatial management, particularly that of invasive species, natural habitats, urbanization, and deforestation; therefore, the need for accurate and objective data and tools is critical. For this purpose, the European Union's flagship program, the Corine Land Cover (CLC), was created. Intensive works are currently being carried out to prepare a new version of CLC+ by 2024. The geographical, climatic, and economic diversity of the European Union raises the challenge to verify various test areas' methods and algorithms. Based on the Corine program's precise guidelines, Sentinel-2 and Landsat 8 satellite images were tested to assess classification accuracy and regional and spatial development in three varied areas of Catalonia, Poland, and Romania. The method is dependent on two machine learning algorithms, Random Forest (RF) and Support Vector Machine (SVM). The bias of classifications was reduced using an iterative of randomized training, test, and verification pixels. The ease of the implementation of the used algorithms makes reproducing the results possible and comparable. The results show that an SVM with a radial kernel is the best classifier, followed by RF. The high accuracy classes that can be updated and classes that should be redefined are specified. The methodology's potential can be used by developers of CLC+ products as a guideline for algorithms, sensors, and the possibilities and difficulties of classifying different CLC classes.
C1 [Dabija, Anca; Kluczek, Marcin; Zagajewski, Bogdan; Raczko, Edwin; Kycko, Marlena; Al-Sulttani, Ahmed H.] Univ Warsaw, Fac Geog & Reg Studies, Chair Geomat & Informat Syst, Dept Geoinformat Cartog & Remote Sensing, PL-00927 Warsaw, Poland.
   [Tarda, Anna; Pineda, Lydia; Corbera, Jordi] Cartog & Geol Inst Catalonia, Catalan Earth Observat Ctr, E-08038 Barcelona, Spain.
C3 University of Warsaw
RP Zagajewski, B (corresponding author), Univ Warsaw, Fac Geog & Reg Studies, Chair Geomat & Informat Syst, Dept Geoinformat Cartog & Remote Sensing, PL-00927 Warsaw, Poland.
EM anca.dabija@uw.edu.pl; m.kluczek@student.uw.edu.pl; bogdan@uw.edu.pl; edwin.raczko@uw.edu.pl; m.kluczek@student.uw.edu.pl; ahmedh.alsulttani@uokufa.edu.iq; anna.tarda@icgc.cat; lydia.pineda@icgc.cat; jordi.corbera@icgc.cat
FU European Union [734687]; Polish Ministry of Science and Higher Education (Ministerstwo Nauki i SzkolnictwaWyz. szego-MNiSW) [3934/H2020/2018/2, 379067/PnH/2017]
CR Abdi AM, 2020, GISCI REMOTE SENS, V57, P1, DOI 10.1080/15481603.2019.1650447
   Balzter H, 2015, REMOTE SENS-BASEL, V7, P14876, DOI 10.3390/rs71114876
   Bandoc G, 2015, J GEOGR SCI, V25, P1307, DOI 10.1007/s11442-015-1236-1
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bielecka E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11172017
   Biv R., 2020, RGDAL BINDINGS GEOSP, V0, P0
   Boccacci P, 2010, SCI HORTIC-AMSTERDAM, V124, P128, DOI 10.1016/j.scienta.2009.12.015
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   BUTTNER G, 2006, 72006 EEA, V0, P90
   Buttner G., 2017, 3436R0COPERNICUSEEA5, V0, P61
   Cao XH, 2020, INT J REMOTE SENS, V41, P4528, DOI 10.1080/01431161.2020.1723172
   Close O, 2018, LAND-BASEL, V7, P0, DOI 10.3390/land7040154
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Congalton RG, 2014, REMOTE SENS-BASEL, V6, P12070, DOI 10.3390/rs61212070
   Demirkan DC, 2020, J APPL REMOTE SENS, V14, P0, DOI 10.1117/1.JRS.14.026524
   Denize J, 2018, INT GEOSCI REMOTE SE, V0, P8271
   Di Sabatino A, 2013, ECOL INDIC, V32, P259, DOI 10.1016/j.ecolind.2013.03.034
   Diaz-Pacheco J, 2014, J LAND USE SCI, V9, P243, DOI 10.1080/1747423X.2012.761736
   Fernandez-Nogueira D, 2020, LAND-BASEL, V9, P0, DOI 10.3390/land9010005
   Foody GM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111630
   Forkuor G, 2018, GISCI REMOTE SENS, V55, P331, DOI 10.1080/15481603.2017.1370169
   Gallego FJ, 2011, INT J GEOGR INF SCI, V25, P2051, DOI 10.1080/13658816.2011.583653
   Garcia-Alvarez D, 2017, INT J APPL EARTH OBS, V63, P55, DOI 10.1016/j.jag.2017.07.001
   Gaujoux R., 2020, RNGTOOLS UTILITY FUN, V0, P0
   Ghamisi P, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2018.2890023
   Golenia M., 2015, POL, V47, P203, DOI 10.1515/pcr-2015-0018
   Gomez C, 2016, ISPRS J PHOTOGRAMM, V116, P55, DOI 10.1016/j.isprsjprs.2016.03.008
   Gounaridis D, 2016, J MAPS, V12, P1055, DOI 10.1080/17445647.2015.1123656
   Griffiths P, 2019, REMOTE SENS ENVIRON, V220, P135, DOI 10.1016/j.rse.2018.10.031
   Gudmann A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213580
   Guidici D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060629
   Hand D, 2018, STAT COMPUT, V28, P539, DOI 10.1007/s11222-017-9746-6
   Hansen MC, 2012, REMOTE SENS ENVIRON, V122, P66, DOI 10.1016/j.rse.2011.08.024
   Heinl M, 2009, INT J APPL EARTH OBS, V11, P423, DOI 10.1016/j.jag.2009.08.002
   Hijmans RJ, 2020, RASTER GEOGRAPHIC DA, V0, P0
   Holnicki P, 2017, ARCH ENVIRON PROT, V43, P48, DOI 10.1515/aep-2017-0005
   Immitzer M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030166
   Jaffrain, 2017, COPERNICUS LAND MONI, V0, P214
   Janitza S, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0201904
   Jansen LJM, 2002, AGR ECOSYST ENVIRON, V91, P89, DOI 10.1016/S0167-8809(01)00243-2
   Janssen S, 2008, ATMOS ENVIRON, V42, P4884, DOI 10.1016/j.atmosenv.2008.02.043
   Jensen JR, 2015, INTRO DIGITAL IMAGE, V0, P656
   Jozdani SE, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141713
   Karpatne A, 2016, IEEE GEOSC REM SEN M, V4, P8, DOI 10.1109/MGRS.2016.2528038
   Keil M., 2015, ISPRS INT ARCH PHOTO, V0, PP1093, DOI 10.5194/isprsarchives-XL-7-W3-1093-2015
   Krowczynska M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030408
   Leinenkugel P, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11192249
   Liu T, 2018, GISCI REMOTE SENS, V55, P243, DOI 10.1080/15481603.2018.1426091
   Marcinkowska-Ochtyra A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040570
   Mayer B, 2005, ATMOS CHEM PHYS, V5, P1855, DOI 10.5194/acp-5-1855-2005
   Mellor A, 2017, ISPRS J PHOTOGRAMM, V129, P151, DOI 10.1016/j.isprsjprs.2017.04.017
   Meyer D, 2019, E1071 MISC FUNCTIONS, V0, P0, DOI DOI 10.1016/j.cell.2020.01.011
   Muller K., 2020, DPLYR GRAMMAR DATA M, V0, P0
   Novillo CJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111717
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Pekkarinen A, 2009, ISPRS J PHOTOGRAMM, V64, P171, DOI 10.1016/j.isprsjprs.2008.09.004
   Noi PT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010018
   Phiri D, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142291
   Podawca K, 2019, MISC GEOGR, V23, P215, DOI 10.2478/mgrsd-2019-0019
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Raczko E, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071111
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Rovira J., 2019, OPEN ATMOSPHERIC SCI, V12, P14, DOI 10.2174/1874282301812010014
   Sabat-Tomala A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030516
   Sanchez-Espinosa A, 2019, J ENVIRON MANAGE, V247, P484, DOI 10.1016/j.jenvman.2019.06.084
   Schlapfer D., 2016, ATMOSPHERICTOPOGRAPH, V0, P263
   Sheykhmousa M, 2020, IEEE J-STARS, V13, P6308, DOI 10.1109/JSTARS.2020.3026724
   Stathopoulou M, 2004, INT J REMOTE SENS, V25, P2301, DOI 10.1080/01431160310001618725
   Stehman SV, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.018
   Topaloglu RH, 2016, INT ARCH PHOTOGRAMM, V41, P1055, DOI 10.5194/isprsarchives-XLI-B8-1055-2016
   Traczyk A., 2017, STUD OBSZ WIEJ, V47, P99, DOI 10.7163/SOW.47.6
   Thinh TV, 2019, SOLA, V15, P28, DOI 10.2151/sola.2019-006
   Ulmas P., 2020, 200302899 ARXIV, V0, P0
   Vermote E, 2016, REMOTE SENS ENVIRON, V185, P46, DOI 10.1016/j.rse.2016.04.008
   Vorovencii I, 2016, ENVIRON MONIT ASSESS, V188, P0, DOI 10.1007/s10661-016-5446-5
   Wallig M, 2020, FOREACH PROVIDES FOR, V0, P0
   Weinmann M, 2018, INT GEOSCI REMOTE SE, V0, P4946
   Weston S., 2019, DOPARALLEL FOR PAR A, V0, P0
   Zeferino LB, 2020, INT J APPL EARTH OBS, V91, P0, DOI 10.1016/j.jag.2020.102128
   Zoungrana BJB, 2015, REMOTE SENS-BASEL, V7, P12076, DOI 10.3390/rs70912076
NR 80
TC 26
Z9 26
U1 3
U2 19
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 15
PY 2021
VL 13
IS 4
BP 
EP 
DI 10.3390/rs13040777
PG 36
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QQ3UY
UT WOS:000624450400001
DA 2023-04-26
ER

PT J
AU Wongsaipun, S
   Theanjumpol, P
   Muenmanee, N
   Boonyakiat, D
   Funsueb, S
   Kittiwachana, S
AF Wongsaipun, Sakunna
   Theanjumpol, Parichat
   Muenmanee, Nadthawat
   Boonyakiat, Danai
   Funsueb, Sujitra
   Kittiwachana, Sila
TI Application of Artificial Neural Network for Tracing the Geographical Origins of Coffee Bean in Northern Areas of Thailand Using Near Infrared Spectroscopy
SO CHIANG MAI JOURNAL OF SCIENCE
LA English
DT Article
DE coffee; geographical origin tracing; near infrared (NIR) spectroscopy; artificial neural network (ANN); self-organizing map (SOM)
ID self-organizing maps; nir spectroscopy; robusta coffees; electronic nose; arabica; differentiation; prediction; parameters; tongue
AB The aim of this research study was to investigate the difference among coffee bean from different plantation areas in the northern of Thailand. Near infrared (NIR) spectra were recorded from Arabica coffee samples which were collected from Chiang Mai, Lampang and Mae Hong Son provinces in Thailand. In addition, color parameters and moisture content were analyzed. The data were exploratorily analyzed based on the uses of principal component analysis (PCA) and an artificial neural network (ANN) called self-organizing map (SOM). To identify the significant parameters of the spectroscopic data, a variable selection called self-organizing map discrimination index (SOMDI) was applied. As a result, SOM could overcome the PCA technique where the samples from the three different origins could be separated. Additionally, based on the SOMDI results, the coffee samples from Chiang Mai could be well discriminated using the NIR spectral regions of 880-1182, 1254-1326, 1896-2180 and 2260-2498 nm. This research demonstrated that using NIR spectroscopy coupled with the ANN algorithm allowed an efficient tracing method to differentiate the coffee bean samples in the northern of Thailand.
C1 [Wongsaipun, Sakunna; Funsueb, Sujitra; Kittiwachana, Sila] Chiang Mai Univ, Fac Sci, Dept Chem, Chiang Mai 50200, Thailand.
   [Wongsaipun, Sakunna; Theanjumpol, Parichat; Muenmanee, Nadthawat; Boonyakiat, Danai] Minist Higher Educ Sci Res & Innovat, Postharvest Technol Innovat Ctr, Bangkok 10400, Thailand.
   [Theanjumpol, Parichat; Muenmanee, Nadthawat] Chiang Mai Univ, Fac Agr, Postharvest Technol Res Ctr, Chiang Mai 50200, Thailand.
   [Boonyakiat, Danai] Chiang Mai Univ, Fac Agr, Dept Plant & Soil Sci, Chiang Mai 50200, Thailand.
   [Kittiwachana, Sila] Chiang Mai Univ, Fac Sci, Environm Sci Res Ctr ESRC, Chiang Mai 50200, Thailand.
C3 Chiang Mai University; Chiang Mai University; Chiang Mai University; Chiang Mai University
RP Kittiwachana, S (corresponding author), Chiang Mai Univ, Fac Sci, Dept Chem, Chiang Mai 50200, Thailand.; Kittiwachana, S (corresponding author), Chiang Mai Univ, Fac Sci, Environm Sci Res Ctr ESRC, Chiang Mai 50200, Thailand.
EM silacmu@gmail.com
FU Postharvest Technology Innovation Centre, Ministry of Higher Education, Science, Research and Innovation, Bangkok, Thailand; Chiang Mai University
CR Adnan A, 2017, FOODS, V6, P0, DOI 10.3390/foods6050038
   Arana VA, 2015, FOOD CHEM, V175, P500, DOI 10.1016/j.foodchem.2014.11.160
   Banbury C, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-47205-5
   Bertone E, 2016, FOOD CONTROL, V59, P683, DOI 10.1016/j.foodcont.2015.06.055
   Bicho NC, 2014, EMIR J FOOD AGR, V26, P9, DOI 10.9755/ejfa.v26i1.17190
   Buratti S, 2015, J SCI FOOD AGR, V95, P2192, DOI 10.1002/jsfa.6933
   Choi MY, 2010, FOOD CHEM, V121, P1260, DOI 10.1016/j.foodchem.2010.01.035
   Dong WJ, 2017, FOOD CHEM, V229, P743, DOI 10.1016/j.foodchem.2017.02.149
   Esteban-Diez I, 2007, TALANTA, V71, P221, DOI 10.1016/j.talanta.2006.03.052
   Funsueb S, 2016, CHEMOMETR INTELL LAB, V156, P203, DOI 10.1016/j.chemolab.2016.06.008
   Giraudo A, 2019, FOOD CONTROL, V99, P137, DOI 10.1016/j.foodcont.2018.12.033
   Kittiwachana S., 2015, ASIA PACIFIC J SCI T, V20, P1, DOI 10.14456/KKURJ.2015.1
   Kittiwachana S, 2013, TALANTA, V106, P229, DOI 10.1016/j.talanta.2012.12.005
   Kohonen T., 1991, P 1991 INT C ART NEU, V0, PP981, DOI 10.1016/B978-0-444-89178-5.50003-8.
   Krongchai C, 2020, CHIANG MAI J SCI, V47, P160
   Liu Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040450
   Lloyd GR, 2008, ANALYST, V133, P1046, DOI 10.1039/b715390b
   Lloyd GR, 2009, CHEMOMETR INTELL LAB, V98, P149, DOI 10.1016/j.chemolab.2009.06.002
   Martins PMM, 2020, FOOD RES INT, V129, P0, DOI 10.1016/j.foodres.2019.108872
   Marini F, 2009, ANAL CHIM ACTA, V635, P121, DOI 10.1016/j.aca.2009.01.009
   Marquetti I, 2016, COMPUT ELECTRON AGR, V121, P313, DOI 10.1016/j.compag.2015.12.018
   Mendes LC, 2001, FOOD QUAL PREFER, V12, P153, DOI 10.1016/S0950-3293(00)00042-2
   Okubo N, 2019, FOODS, V8, P0, DOI 10.3390/foods8020082
   Ribeiro JS, 2011, TALANTA, V83, P1352, DOI 10.1016/j.talanta.2010.11.001
   Wenz JJ, 2018, BBA-BIOMEMBRANES, V1860, P673, DOI 10.1016/j.bbamem.2017.12.007
   Wongravee K, 2010, ANAL CHEM, V82, P628, DOI 10.1021/ac9020566
   Worku M, 2019, FOOD CHEM, V290, P295, DOI 10.1016/j.foodchem.2019.03.135
NR 27
TC 5
Z9 5
U1 0
U2 7
PU CHIANG MAI UNIV, FAC SCIENCE
PI CHIANG MAI
PA 239 HUAY KAEW RD, T SUTHEP, CHIANG MAI, 50200, THAILAND
SN 0125-2526
EI 
J9 CHIANG MAI J SCI
JI Chiang Mai J. Sci.
PD JAN 15
PY 2021
VL 48
IS 1
BP 163
EP 175
DI 
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA PV5TX
UT WOS:000610051400013
DA 2023-04-26
ER

PT J
AU Zang, YF
   Meng, FC
   Lindenbergh, R
   Truong-Hong, L
   Li, BJ
AF Zang, Yufu
   Meng, Fancong
   Lindenbergh, Roderik
   Truong-Hong, Linh
   Li, Bijun
TI Deep Localization of Static Scans in Mobile Mapping Point Clouds
SO REMOTE SENSING
LA English
DT Article
DE point cloud localization; mobile laser scanning; terrestrial laser scanning; place recognition; pose refinement
ID terrestrial; registration; airborne
AB Mobile laser scanning (MLS) systems are often used to efficiently acquire reference data covering a large-scale scene. The terrestrial laser scanner (TLS) can easily collect high point density data of local scene. Localization of static TLS scans in mobile mapping point clouds can afford detailed geographic information for many specific tasks especially in autonomous driving and robotics. However, large-scale MLS reference data often have a huge amount of data and many similar scene data; significant differences may exist between MLS and TLS data. To overcome these challenges, this paper presents a novel deep neural network-based localization method in urban environment, divided by place recognition and pose refinement. Firstly, simple, reliable primitives, cylinder-like features were extracted to describe the global features of a local urban scene. Then, a probabilistic framework is applied to estimate a similarity between TLS and MLS data, under a stable decision-making strategy. Based on the results of a place recognition, we design a patch-based convolution neural network (CNN) (point-based CNN is used as kernel) for pose refinement. The input data unit is the batch consisting of several patches. One patch goes through three main blocks: feature extraction block (FEB), the patch correspondence search block and the pose estimation block. Finally, a global refinement was proposed to tune the predicted transformation parameters to realize localization. The research aim is to find the most similar scene of MLS reference data compared with the local TLS scan, and accurately estimate the transformation matrix between them. To evaluate the performance, comprehensive experiments were carried out. The experiments demonstrate that the proposed method has good performance in terms of efficiency, i.e., the runtime of processing a million points is 5 s, robustness, i.e., the success rate of place recognition is 100% in the experiments, accuracy, i.e., the mean rotation and translation error is (0.24 deg, 0.88 m) and (0.03 deg, 0.06 m) on TU Delft campus and Shanghai urban datasets, respectively, and outperformed some commonly used methods (e.g., iterative closest point (ICP), coherent point drift (CPD), random sample consensus (RANSAC)-based method).
C1 [Zang, Yufu] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
   [Zang, Yufu; Meng, Fancong; Lindenbergh, Roderik; Truong-Hong, Linh] Delft Univ Technol, Dept Geosci & Remote Sensing, Stevinweg 1, NL-2628 CN Delft, Netherlands.
   [Li, Bijun] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 Nanjing University of Information Science & Technology; Delft University of Technology; Wuhan University
RP Meng, FC (corresponding author), Delft Univ Technol, Dept Geosci & Remote Sensing, Stevinweg 1, NL-2628 CN Delft, Netherlands.
EM 3dmapzangyufu@nuist.edu.cn; Meng@student.tudelft.nl; R.C.Lindenbergh@tudelft.nl; L.Truong@tudelft.nl; lee@whu.edu.cn
FU National Science Foundation of China project [41701529]; OpenFund of State Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University [18S02]
CR Aissou B., 2020, PROC INT ARCHIV PHOT, V0, P191
   [Anonymous], 2008, REMOTE SENS SPATIAL, V0, P0
   Aoki Y, 2019, PROC CVPR IEEE, V0, PP7156, DOI 10.1109/CVPR.2019.00733
   Avidar D, 2017, IEEE I CONF COMP VIS, V0, PP891, DOI 10.1109/ICCV.2017.102
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cai ZP, 2019, ISPRS J PHOTOGRAMM, V147, P118, DOI 10.1016/j.isprsjprs.2018.11.016
   Che EZ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19040810
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Cheng L, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18051641
   Cheng L, 2013, REMOTE SENS-BASEL, V5, P6260, DOI 10.3390/rs5126260
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Dong JM, 2014, NEUROCOMPUTING, V140, P67, DOI 10.1016/j.neucom.2014.03.035
   Drawil NM, 2013, IEEE T INTELL TRANSP, V14, P262, DOI 10.1109/TITS.2012.2213815
   Elbaz G, 2017, PROC CVPR IEEE, V0, PP2472, DOI 10.1109/CVPR.2017.265
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hauglin M, 2014, INT J REMOTE SENS, V35, P3135, DOI 10.1080/01431161.2014.903440
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ji XG, 2021, MULTIMED TOOLS APPL, V80, P4553, DOI 10.1007/s11042-020-09910-6
   Kanai S., 2019, INT ARCH PHOTOGRAMM, V0, PP963, DOI 10.5194/isprs-archives-XLII-2-W13-963-2019
   Koguciuk D, 2017, FOUND COMPUT DECIS S, V42, P203, DOI 10.1515/fcds-2017-0010
   Koren M, 2017, INT J APPL EARTH OBS, V63, P122, DOI 10.1016/j.jag.2017.07.015
   Kurobe A, 2020, IEEE ROBOT AUTOM LET, V5, P3960, DOI 10.1109/LRA.2020.2970946
   Landsiedel C, 2017, INT J INTELL ROBOT, V1, P429, DOI 10.1007/s41315-017-0038-2
   Li XY, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20010237
   Liang FX, 2020, ISPRS J PHOTOGRAMM, V165, P120, DOI 10.1016/j.isprsjprs.2020.04.018
   Lu WX, 2019, IEEE I CONF COMP VIS, V0, PP12, DOI 10.1109/ICCV.2019.00010
   Makovetskii A, 2017, PROC SPIE, V10396, P0, DOI 10.1117/12.2273604
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nagy B., 2018, P EUROPEAN C COMPUTE, V0, P0
   Pais GD, 2020, PROC CVPR IEEE, V0, PP7191, DOI 10.1109/CVPR42600.2020.00722
   Poux F., 2020, INT ARCH PHOTOGRAMME, V43, P309, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2020-309-2020
   Qi C. R., 2017, ADV NEURAL INFORM PR, V0, P5099
   Sarode V, 2019, IEEE INT C COMP VIS, V0, P0
   Segal A., 2009, GENERALIZED ICP ROBO, V0, P435
   Sorkine-Hornung O, 2017, COMPUTING, V1, P1
   Uy MA, 2018, PROC CVPR IEEE, V0, PP4470, DOI 10.1109/CVPR.2018.00470
   Vivacqua R, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17102359
   Wong R., 2019, P IOP C SER MAT SCI, V705, P012004
   Wu HB, 2014, J APPL REMOTE SENS, V8, P0, DOI 10.1117/1.JRS.8.083587
   Yang BS, 2016, ISPRS J PHOTOGRAMM, V119, P373, DOI 10.1016/j.isprsjprs.2016.07.002
   Yang BS, 2015, ISPRS J PHOTOGRAMM, V109, P62, DOI 10.1016/j.isprsjprs.2015.08.006
   Yin H, 2018, IEEE INT VEH SYM, V0, P728
NR 42
TC 1
Z9 1
U1 1
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN 15
PY 2021
VL 13
IS 2
BP 
EP 
DI 10.3390/rs13020219
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PX7QX
UT WOS:000611550100001
DA 2023-04-26
ER

PT J
AU Liu, MX
   Liu, JH
   Atzberger, C
   Jiang, Y
   Ma, MF
   Wang, XM
AF Liu, Mingxing
   Liu, Jianhong
   Atzberger, Clement
   Jiang, Ya
   Ma, Minfei
   Wang, Xunmei
TI Zanthoxylum bungeanum Maxim mapping with multi-temporal Sentinel-2 images: The importance of different features and consistency of results
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Zanthoxylum bungeanum Maxim; Random forest classifier; Sentinel-2; Vegetation indices; Topographic variables; Importance analysis
ID support vector machines; random forest; time-series; neural-network; landsat 8; classification; cover; biomass; china; crops
AB Zanthoxylum bungeanum Maxim (ZBM) is an important woody species in large parts of Asia, which provides oils and medicinal materials. Timely and accurate mapping of its spatial distribution and planting area is of great significance to local economy and ecology. As a special tree species planted in the Grain for Green Program of China, Linxia Hui Autonomous Prefecture (Linxia) in Gansu Province of China has vigorously developed ZBM cultivation since the launch of the program. However, lacking the accurate ZBM planting information hinders the assessment of the benefits and losses of the program to local people. Therefore, this study investigated the potential of multi-temporal Sentinel-2 Multi-Spectral Instrument (MSI) to accurately map ZBM in the study area in 2019. We first investigated the classification accuracies of four alternative Random Forest (RF) classifications using either alone or in combination, spectral bands, vegetation indices (VIs), and topographical variables. The importance of the three categories of features was examined based on the mean decrease accuracy (MDA) metric. The classification results with the most important features were further assessed for their consistency by considering the voting rates of 800 trees based on testing samples. Results show that the sole use of the spectral bands (40 input features) already achieves a satisfactory classification accuracy of 95.43%. Adding extra VIs and topographical variables further improves the results, but only to a small extent. However, certain VIs and topographic variables are far more effective in classification compared with the original spectral bands, especially the Red Edge Normalized Difference Vegetation Index (NDVI705) and Normalized Difference Yellow Index (NDYI). The classification accuracy achieves nearly 95% when using only the top 15 most important features. The desirable periods for differencing of ZBM and other land cover types are fruit coloring and ripening periods. The final map shows that the ZBM planting in Linxia is mainly distributed along the Yellow River and around the Liujiaxia reservoir. The total mapped acreages of ZBM is 51,601 ha, covering 9.51% of the study area. 99% of ZBM tends to grow between 1500 and 2400 m altitude, and 67% of ZBM are planted in areas with slopes between 5 and 25.. Voting rates show that the percentages of classification results with strong and good consistency are generally over 70% for all land cover types, proving the derived land cover map's high credibility, including ZBM. Altogether, our results demonstrate the high potential of multi-temporal Sentinel-2 images in accurate mapping of ZBM, which can serve as a reference for other specialty crops or tree species.Y
C1 [Liu, Mingxing; Liu, Jianhong; Ma, Minfei] Northwest Univ, Shaanxi Key Lab Earth Surface Syst & Environm Car, Xian 710127, Peoples R China.
   [Liu, Mingxing; Liu, Jianhong; Jiang, Ya; Ma, Minfei; Wang, Xunmei] Northwest Univ, Coll Urban & Environm Sci, Xian 710127, Peoples R China.
   [Atzberger, Clement] Univ Nat Resources & Life Sci BOKU, Inst Geomat, Peter Jordan Str 82, A-1190 Vienna, Austria.
C3 Northwest University Xi'an; Northwest University Xi'an; University of Natural Resources & Life Sciences, Vienna
RP Liu, JH (corresponding author), Northwest Univ, Shaanxi Key Lab Earth Surface Syst & Environm Car, Xian 710127, Peoples R China.
EM mingxingliu@stumail.nwu.edu.cn; jhliu@nwu.edu.cn; clement.atzberger@boku.ac.at
FU National Natural Science Foundation of China [41401494]; Natural Science Foundation of Shaanxi Provincial Department of Education [14JK1745]
CR Ashourloo D, 2020, COMPUT ELECTRON AGR, V175, P0, DOI 10.1016/j.compag.2020.105583
   Ashourloo D, 2019, ISPRS J PHOTOGRAMM, V156, P63, DOI 10.1016/j.isprsjprs.2019.08.007
   Bazi Y, 2006, IEEE T GEOSCI REMOTE, V44, P3374, DOI 10.1109/TGRS.2006.880628
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Blackard JA, 1999, COMPUT ELECTRON AGR, V24, P131, DOI 10.1016/S0168-1699(99)00046-0
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Chen BQ, 2017, ISPRS J PHOTOGRAMM, V131, P104, DOI 10.1016/j.isprsjprs.2017.07.011
   Chen Y, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9142917
   Cho MA, 2006, REMOTE SENS ENVIRON, V101, P181, DOI 10.1016/j.rse.2005.12.011
   Chrysafis I, 2019, INT J APPL EARTH OBS, V77, P1, DOI 10.1016/j.jag.2018.12.004
   Clark ML, 2020, ISPRS J PHOTOGRAMM, V159, P26, DOI 10.1016/j.isprsjprs.2019.11.007
   Corbera E, 2011, ENVIRON SCI POLICY, V14, P89, DOI 10.1016/j.envsci.2010.11.002
   dAndrimont R, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2020.111660
   Dash JP, 2017, ISPRS J PHOTOGRAMM, V131, P1, DOI 10.1016/j.isprsjprs.2017.07.007
   Deng S, 2019, BIOMED PHARMACOTHER, V112, P0, DOI 10.1016/j.biopha.2019.108696
   Douik A, 2010, INT J COMPUT COMMUN, V5, P506, DOI 10.15837/ijccc.2010.4.2508
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Duriancik LF, 2008, J SOIL WATER CONSERV, V63, P185A, DOI 10.2489/jswc.63.6.185A
   Ebert AW, 2014, SUSTAINABILITY-BASEL, V6, P319, DOI 10.3390/su6010319
   Eva H, 2010, ISPRS J PHOTOGRAMM, V65, P191, DOI 10.1016/j.isprsjprs.2009.10.008
   Fang JY, 2001, SCIENCE, V292, P2320, DOI 10.1126/science.1058629
   Feng SJ, 2015, GENET RESOUR CROP EV, V62, P1193, DOI 10.1007/s10722-015-0222-x
   Ferreira MP, 2019, ISPRS J PHOTOGRAMM, V149, P119, DOI 10.1016/j.isprsjprs.2019.01.019
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   FOODY GM, 1992, PHOTOGRAMM ENG REM S, V58, P1335
   Gitelson AA, 2003, J PLANT PHYSIOL, V160, P271, DOI 10.1078/0176-1617-00887
   Goetz S, 2011, CARBON MANAG, V2, P231, DOI 10.4155/CMT.11.18
   Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hamrouni Y, 2021, ISPRS J PHOTOGRAMM, V171, P76, DOI 10.1016/j.isprsjprs.2020.10.018
   Hansen MC, 2013, SCIENCE, V342, P850, DOI 10.1126/science.1244693
   Hansen MC, 2008, REMOTE SENS ENVIRON, V112, P3784, DOI 10.1016/j.rse.2008.05.012
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Hunt ML, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111410
   Ifarraguerri A, 2004, IEEE GEOSCI REMOTE S, V1, P101, DOI 10.1109/LGRS.2003.822879
   Immitzer M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222599
   Immitzer M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030166
   Inglada J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050362
   Ingram JC, 2005, REMOTE SENS ENVIRON, V94, P491, DOI 10.1016/j.rse.2004.12.001
   Ji Y, 2019, FOOD SCI HUM WELL, V8, P115, DOI 10.1016/j.fshw.2019.03.008
   Lakshmanaprabu SK, 2019, INT J MACH LEARN CYB, V10, P2609, DOI 10.1007/s13042-018-00916-z
   Lambert MJ, 2018, REMOTE SENS ENVIRON, V216, P647, DOI 10.1016/j.rse.2018.06.036
   Le Toan T, 2011, REMOTE SENS ENVIRON, V115, P2850, DOI 10.1016/j.rse.2011.03.020
   Li CC, 2014, REMOTE SENS-BASEL, V6, P964, DOI 10.3390/rs6020964
   Li JK, 2015, FOOD CONTROL, V56, P9, DOI 10.1016/j.foodcont.2015.03.001
   Li LW, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111265
   Liang S., 2017, COMPREHENSIVE REMOTE, V0, P0
   Liu YA, 2019, ISPRS J PHOTOGRAMM, V151, P277, DOI 10.1016/j.isprsjprs.2019.03.016
   Liu YS, 2017, NATURE, V548, P275, DOI 10.1038/548275a
   Long HL, 2016, J RURAL STUD, V47, P392, DOI 10.1016/j.jrurstud.2016.03.011
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Maschler J, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081218
   Mayes S, 2012, J EXP BOT, V63, P1075, DOI 10.1093/jxb/err396
   Mellor A, 2013, REMOTE SENS-BASEL, V5, P2838, DOI 10.3390/rs5062838
   NELSON R, 1988, REMOTE SENS ENVIRON, V24, P247, DOI 10.1016/0034-4257(88)90028-4
   Ng WT, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010074
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Omer G, 2015, IEEE J-STARS, V8, P4825, DOI 10.1109/JSTARS.2015.2461136
   Onojeghuo AO, 2018, INT J REMOTE SENS, V39, P1042, DOI 10.1080/01431161.2017.1395969
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Peng C., 1999, TRANSFER-LONDON, V1, P0
   Phiri D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090967
   Potter C, 2012, REMOTE SENS ENVIRON, V121, P61, DOI 10.1016/j.rse.2012.01.019
   Qian C, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104182
   Raczko E, 2017, EUR J REMOTE SENS, V50, P144, DOI 10.1080/22797254.2017.1299557
   Ramoelo A, 2015, J APPL REMOTE SENS, V9, P0, DOI 10.1117/1.JRS.9.094096
   Reis BP, 2019, ECOL ENG, V127, P178, DOI 10.1016/j.ecoleng.2018.11.022
   Rocchini D, 2013, COMPUT GEOSCI-UK, V50, P128, DOI 10.1016/j.cageo.2012.05.022
   Romijn E, 2012, ENVIRON SCI POLICY, V19-20, P33, DOI 10.1016/j.envsci.2012.01.005
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Schultz B, 2015, REMOTE SENS-BASEL, V7, P14482, DOI 10.3390/rs71114482
   Sedano F, 2020, INT J APPL EARTH OBS, V92, P0, DOI 10.1016/j.jag.2020.102184
   Segarra J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142278
   Sesnie SE, 2010, INT J REMOTE SENS, V31, P2885, DOI 10.1080/01431160903140803
   Silveira EMO, 2019, INT J APPL EARTH OBS, V78, P175, DOI 10.1016/j.jag.2019.02.004
   Sulik JJ, 2016, REMOTE SENS ENVIRON, V184, P161, DOI 10.1016/j.rse.2016.06.016
   Sylvain JD, 2019, ISPRS J PHOTOGRAMM, V156, P14, DOI 10.1016/j.isprsjprs.2019.07.010
   Talema T, 2020, REMOTE SENS APPL, V18, P0, DOI 10.1016/j.rsase.2020.100290
   Tomppo E., 2002, UNASYLVA (ENGLISH ED.), V53, P16
   Tong XD, 2016, INT GEOSCI REMOTE SE, V0, PP3738, DOI 10.1109/IGARSS.2016.7729969
   Tscharntke T, 2012, BIOL CONSERV, V151, P53, DOI 10.1016/j.biocon.2012.01.068
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   van Leeuwen WJD, 2008, SENSORS-BASEL, V8, P2017, DOI 10.3390/s8032017
   Vuolo F, 2018, INT J APPL EARTH OBS, V72, P122, DOI 10.1016/j.jag.2018.06.007
   Waldner F, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111375
   Wang M, 2019, LAND USE POLICY, V88, P0, DOI 10.1016/j.landusepol.2019.104190
   Wang S, 2011, J LIQ CHROMATOGR R T, V34, P2640, DOI 10.1080/10826076.2011.593219
   Wardlow BD, 2007, REMOTE SENS ENVIRON, V108, P290, DOI 10.1016/j.rse.2006.11.021
   Wu FL, 2017, GLOBAL PLANET CHANGE, V158, P36, DOI 10.1016/j.gloplacha.2017.09.008
   Wu XT, 2019, SCI TOTAL ENVIRON, V678, P565, DOI 10.1016/j.scitotenv.2019.05.022
   Wulder MA, 2006, FOREST CHRON, V82, P187, DOI 10.5558/tfc82187-2
   Wulder MA, 2006, REMOTE SENS ENVIRON, V101, P150, DOI 10.1016/j.rse.2005.12.010
   Wyniawskyj NS, 2019, INT GEOSCI REMOTE SE, V0, PP6598, DOI 10.1109/IGARSS.2019.8899782
   Xiao XM, 2004, REMOTE SENS ENVIRON, V89, P519, DOI 10.1016/j.rse.2003.11.008
   Xiao XM, 2005, REMOTE SENS ENVIRON, V95, P480, DOI 10.1016/j.rse.2004.12.009
   Xu ZG, 2004, INT FOREST REV, V6, P317, DOI 10.1505/ifor.6.3.317.59976
   Ye Y, 2018, SHAANXI FOREST SCI T, V46, P74
   You NS, 2020, ISPRS J PHOTOGRAMM, V161, P109, DOI 10.1016/j.isprsjprs.2020.01.001
   Yuan C, 2015, CAN J FOREST RES, V45, P783, DOI 10.1139/cjfr-2014-0347
   Zeng MM, 2018, FOOD CHEM, V239, P111, DOI 10.1016/j.foodchem.2017.06.097
   Zhang MM, 2017, INT J MOL SCI, V18, P0, DOI 10.3390/ijms18102172
NR 104
TC 7
Z9 8
U1 5
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2021
VL 174
IS 
BP 68
EP 86
DI 10.1016/j.isprsjprs.2021.02.003
EA FEB 2021
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO4AQ
UT WOS:000640987800006
DA 2023-04-26
ER

PT J
AU Wong, PY
   Su, HJ
   Lee, HY
   Chen, YC
   Hsiao, YP
   Huang, JW
   Teo, TA
   Wu, CD
   Spengler, JD
   Klemes, JJ
AF Wong, Pei-Yi
   Su, Huey-Jen
   Lee, Hsiao-Yun
   Chen, Yu-Cheng
   Hsiao, Ya-Ping
   Huang, Jen-Wei
   Teo, Tee-Ann
   Wu, Chih-Da
   Spengler, John D.
   Klemes, Jiri Jaromir
TI Using land-use machine learning models to estimate daily NO2 concentration variations in Taiwan
SO JOURNAL OF CLEANER PRODUCTION
LA English
DT Article
DE NO < sub > 2 <; sub >; Land-use regression; Ordinary Kriging; Machine learning; Taiwan
ID use regression-model; nitrogen-dioxide concentrations; fine particulate matter; air-pollution exposure; neural-network; urban trees; pm2.5; incense; pollutants; resolution
AB It is likely that exposure surrogates from monitoring stations with various limitations are not sufficient for epidemiological studies covering large areas. Moreover, the spatiotemporal resolution of air pollution modelling approaches must be improved in order to achieve more accurate estimates. If not, the exposure assessments will not be applicable in future health risk assessments. To deal with this challenge, this study featured Land-Use Regression (LUR) models that use machine learning to assess the spatial-temporal variability of Nitrogen Dioxide (NO2). Daily average NO2 data was collected from 70 fixed air quality monitoring stations, belonging to the Taiwanese EPA, on the main island of Taiwan. Around 0.41 million observations from 2000 to 2016 were used for the analysis. Several datasets were employed to determine spatial predictor variables, including the EPA environmental resources dataset, the meteorological dataset, the land-use inventory, the landmark dataset, the digital road network map, the digital terrain model, MODIS Normalized Difference Vegetation Index database, and the power plant distribution dataset. Regarding analyses, conventional LUR and Hybrid Kriging-LUR were performed first to identify important predictor variables. A Deep Neural Network, Random Forest, and XGBoost algorithms were then used to fit the prediction model based on the variables selected by the LUR models. Lastly, data splitting, 10-fold cross validation, external data verification, and seasonal-based and county-based validation methods were applied to verify the robustness of the developed models. The results demonstrated that the proposed conventional LUR and Hybrid Kriging-LUR models captured 65% and 78%, respectively, of NO2 variation. When the XGBoost algorithm was further incorporated in LUR and hybrid-LUR, the explanatory power increased to 84% and 91%, respectively. The Hybrid Kriging-LUR with XGBoost algorithm outperformed all other integrated methods. This study demonstrates the value of combining Hybrid Kriging-LUR model and an XGBoost algorithm to estimate the spatial-temporal variability of NO2 exposure. For practical application, the associations of specific land-use/land cover types selected in the final model can be applied in land-use management and in planning emission reduction strategies.
C1 [Wong, Pei-Yi; Su, Huey-Jen] Natl Cheng Kung Univ, Dept Environm & Occupat Hlth, Tainan, Taiwan.
   [Lee, Hsiao-Yun] Natl Taipei Univ Nursing & Hlth Sci, Dept Leisure Ind & Hlth Promot, Taipei, Taiwan.
   [Chen, Yu-Cheng; Spengler, John D.] Natl Hlth Res Inst, Natl Inst Environm Hlth Sci, Miaoli, Taiwan.
   [Hsiao, Ya-Ping; Spengler, John D.] Natl Cheng Kung Univ, Dept Geomat, Tainan, Taiwan.
   [Huang, Jen-Wei] Natl Cheng Kung Univ, Dept Elect Engn, Tainan, Taiwan.
   [Teo, Tee-Ann] Natl Yang Ming Chiao Tung Univ, Dept Civil Engn, Hsinchu, Taiwan.
   [Klemes, Jiri Jaromir] Harvard TH Chan Sch Publ Hlth, Dept Environm Hlth, Boston, MA USA.
C3 National Cheng Kung University; National Taipei University of Nursing & Health Science (NTUNHS); National Health Research Institutes - Taiwan; National Cheng Kung University; National Cheng Kung University; National Yang Ming Chiao Tung University; Harvard University; Harvard T.H. Chan School of Public Health
RP Wu, CD (corresponding author), Natl Cheng Kung Univ, Dept Geomat, 1 Univ Rd, Tainan 701, Taiwan.
EM chidawu@mail.ncku.edu.tw
FU Ministry of Science and Technology, R.O. C. [MOST 108-2621-M-006-017-, MOST 108-2638-B-006-001-MY2]; National Health Research Institutes [NHRI-109A1-EMCO-02202312]
CR Achakulwisut P, 2019, LANCET PLANET HEALTH, V3, PE166, DOI 10.1016/S2542-5196(19)30046-4
   Adams MD, 2016, J ENVIRON MANAGE, V168, P133, DOI 10.1016/j.jenvman.2015.12.012
   Alexeeff SE, 2015, J EXPO SCI ENV EPID, V25, P138, DOI 10.1038/jes.2014.40
   Araki S, 2018, SCI TOTAL ENVIRON, V634, P1269, DOI 10.1016/j.scitotenv.2018.03.324
   Beelen R, 2013, ATMOS ENVIRON, V72, P10, DOI 10.1016/j.atmosenv.2013.02.037
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Briggs DJ, 1997, INT J GEOGR INF SCI, V11, P699, DOI 10.1080/136588197242158
   Brunekreef B, 2002, LANCET, V360, P1233, DOI 10.1016/S0140-6736(02)11274-8
   Chan TC, 2009, INT J HEALTH GEOGR, V8, P0, DOI 10.1186/1476-072X-8-26
   Chen J, 2019, ENVIRON INT, V130, P0, DOI 10.1016/j.envint.2019.104934
   Chen KS, 2004, J AIR WASTE MANAGE, V54, P36, DOI 10.1080/10473289.2004.10470880
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Chuang HC, 2013, J HAZARD MATER, V244, P142, DOI 10.1016/j.jhazmat.2012.11.034
   Di Q, 2020, ENVIRON SCI TECHNOL, V54, P1372, DOI 10.1021/acs.est.9b03358
   Eeftens M, 2012, ENVIRON SCI TECHNOL, V46, P11195, DOI 10.1021/es301948k
   Fantozzi F, 2015, URBAN CLIM, V12, P119, DOI 10.1016/j.uclim.2015.02.001
   Han H, 2016, INT CONF SOFTW ENG, V0, PP219, DOI 10.1109/ICSESS.2016.7883053
   Ierodiakonou D, 2016, J ALLERGY CLIN IMMUN, V137, P390, DOI 10.1016/j.jaci.2015.05.028
   Jerrett M, 2005, EPIDEMIOLOGY, V16, P727, DOI 10.1097/01.ede.0000181630.15826.7d
   Jiao C, 2020, ENVIRON POLLUT, V259, P0, DOI 10.1016/j.envpol.2019.113778
   Joharestani MZ, 2019, ATMOSPHERE-BASEL, V10, P0, DOI 10.3390/atmos10070373
   Jung CR, 2019, SCI TOTAL ENVIRON, V668, P342, DOI 10.1016/j.scitotenv.2019.03.018
   Kaminska JA, 2019, SCI TOTAL ENVIRON, V651, P475, DOI 10.1016/j.scitotenv.2018.09.196
   Kampa M, 2008, ENVIRON POLLUT, V151, P362, DOI 10.1016/j.envpol.2007.06.012
   Kenagy HS, 2016, AIR QUAL ATMOS HLTH, V9, P589, DOI 10.1007/s11869-015-0370-3
   Lee CS, 2018, ENVIRON SCI POLLUT R, V25, P22136, DOI 10.1007/s11356-018-2273-y
   Lee SC, 2004, ATMOS ENVIRON, V38, P941, DOI 10.1016/j.atmosenv.2003.11.002
   Lin Ta-Chang, 2008, CLIN MOL ALLERGY, V6, P3, DOI 10.1186/1476-7961-6-3
   Lui KH, 2016, ENVIRON POLLUT, V213, P524, DOI 10.1016/j.envpol.2016.02.053
   Lung SCC, 2003, J AIR WASTE MANAGE, V53, P130, DOI 10.1080/10473289.2003.10466140
   Michanowicz DR, 2016, TRANSPORT RES D-TR E, V43, P181, DOI 10.1016/j.trd.2015.12.007
   Moore DK, 2007, J ENVIRON MONITOR, V9, P246, DOI 10.1039/b615795e
   Motc, 2020, VEH STAT, V0, P0
   National Religion Information Network, 2020, OV REL AFF, V0, P0
   Qu Y, 2016, J ENVIRON SCI, V44, P13, DOI 10.1016/j.jes.2015.08.028
   Rao M, 2014, ENVIRON POLLUT, V194, P96, DOI 10.1016/j.envpol.2014.07.011
   Sbihi H, 2016, EUR RESPIR J, V47, P1062, DOI 10.1183/13993003.00746-2015
   Soh PW, 2018, IEEE ACCESS, V6, P38186, DOI 10.1109/ACCESS.2018.2849820
   Speiser JL, 2019, EXPERT SYST APPL, V134, P93, DOI 10.1016/j.eswa.2019.05.028
   Wong PY, 2021, ENVIRON MODELL SOFTW, V139, P0, DOI 10.1016/j.envsoft.2021.104996
   Wong PY, 2021, ENVIRON POLLUT, V277, P0, DOI 10.1016/j.envpol.2021.116846
   Wu CD, 2018, SCI TOTAL ENVIRON, V645, P1456, DOI 10.1016/j.scitotenv.2018.07.073
   Wu CD, 2017, ENVIRON POLLUT, V224, P148, DOI 10.1016/j.envpol.2017.01.074
   Wu SW, 2016, ENVIRON INT, V94, P76, DOI 10.1016/j.envint.2016.05.004
   Wu TJ, 2020, RESP MED, V172, P0, DOI 10.1016/j.rmed.2020.106133
   Xu H, 2019, SCI TOTAL ENVIRON, V655, P423, DOI 10.1016/j.scitotenv.2018.11.125
   Yin S, 2011, ENVIRON POLLUT, V159, P2155, DOI 10.1016/j.envpol.2011.03.009
   Young MT, 2016, ENVIRON SCI TECHNOL, V50, P3686, DOI 10.1021/acs.est.5b05099
   Yu KP, 2015, BUILD ENVIRON, V93, P258, DOI 10.1016/j.buildenv.2015.06.024
   Zhang ZY, 2018, ATMOS ENVIRON, V192, P48, DOI 10.1016/j.atmosenv.2018.08.046
   Zhou YL, 2019, J CLEAN PROD, V209, P134, DOI 10.1016/j.jclepro.2018.10.243
NR 51
TC 9
Z9 9
U1 9
U2 34
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0959-6526
EI 1879-1786
J9 J CLEAN PROD
JI J. Clean Prod.
PD OCT 1
PY 2021
VL 317
IS 
BP 
EP 
DI 10.1016/j.jclepro.2021.128411
EA JUL 2021
PG 9
WC Green & Sustainable Science & Technology; Engineering, Environmental; Environmental Sciences
SC Science & Technology - Other Topics; Engineering; Environmental Sciences & Ecology
GA XE1KL
UT WOS:000723154200006
DA 2023-04-26
ER

PT J
AU Jenny, B
   Heitzler, M
   Singh, D
   Farmakis-Serebryakova, M
   Liu, JC
   Hurni, L
AF Jenny, Bernhard
   Heitzler, Magnus
   Singh, Dilpreet
   Farmakis-Serebryakova, Marianna
   Liu, Jeffery Chieh
   Hurni, Lorenz
TI Cartographic Relief Shading with Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural networks; Lighting; Manuals; Rendering (computer graphics); Digital elevation models; Computational modeling; Visualization; Relief shading; shaded relief; hillshade; neural rendering; illustrative visualisation; image-to-image translation
ID representation; light; maps; quality; models; color; shape
AB Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.
C1 [Jenny, Bernhard; Singh, Dilpreet; Liu, Jeffery Chieh] Monash Univ, Melbourne, Vic, Australia.
   [Heitzler, Magnus; Farmakis-Serebryakova, Marianna; Hurni, Lorenz] Swiss Fed Inst Technol, Inst Cartog & Geoinformat, Zurich, Switzerland.
C3 Monash University; Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Jenny, B (corresponding author), Monash Univ, Melbourne, Vic, Australia.
EM bernie.jenny@monash.edu; hmagnus@ethz.ch; dilpreet.singh@monash.edu; mserebry@ethz.ch; jeffery.liu@monash.edu; lhurni@ethz.ch
FU National Geographic Society
CR Apple, 2020, COR ML INT MACH LEAR, V0, P0
   BATSON RM, 1975, J RES US GEOL SURV, V3, P401
   Bell S., 2019, N AM CARTOGRAPHIC SO, V0, P0
   Bi S, 2019, IEEE I CONF COMP VIS, V0, PP2730, DOI 10.1109/ICCV.2019.00282
   Biland J, 2017, CARTOGR GEOGR INF SC, V44, P358, DOI 10.1080/15230406.2016.1185647
   Brassel K., 1974, AM CARTOGRAPHER, V1, P15, DOI 10.1559/152304074784107818
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Collier P, 2003, CARTOGR J, V40, P17, DOI 10.1179/000870403235002033
   Coltekin A, 2019, INT J DIGIT EARTH, V12, P442, DOI 10.1080/17538947.2018.1447030
   Elgammal A, 2017, ARXIV170607068, V0, P0
   Farmakis-Serebryakova M, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040253
   Florinsky IV, 2019, T GIS, V23, P937, DOI 10.1111/tgis.12546
   Gatys LA, 2016, PROC CVPR IEEE, V0, PP2414, DOI 10.1109/CVPR.2016.265
   Geisthovel R, 2018, CARTOGR J, V55, P341, DOI 10.1080/00087041.2018.1551955
   Gerardin P, 2007, J VISION, V7, P0, DOI 10.1167/7.11.13
   Guilbert E., 2014, ABSTRACTING GEOGRAPH, V0, PP227, DOI 10.1007/978-3-319-00203-3_8
   Hammer M. Cavelti, 1997, FARBE LICHT SCHATTEN, V0, P0
   He K., 2015, PROC CVPR IEEE, V5, P6
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Heitzler M, 2020, T GIS, V24, P442, DOI 10.1111/tgis.12610
   HORN BKP, 1981, P IEEE, V69, P14, DOI 10.1109/PROC.1981.11918
   Iizuka S, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3072959.3073659
   Imhof E, 1982, CARTOGRAPHIC RELIEF, V0, P0
   Isola P, 2017, PROC CVPR IEEE, V0, PP5967, DOI 10.1109/CVPR.2017.632
   Jenny B., 2017, RELIEF CARTOGRAPHERS, V0, P0
   Jenny B., 2001, CARTOGRAPHICA INT J, V38, P67, DOI 10.3138/F722-0825-3142-HW05
   Jenny B, 2006, CARTOGR J, V43, P198, DOI 10.1179/000870406X158164
   Jenny B, 2021, CARTOGR GEOGR INF SC, V48, P21, DOI 10.1080/15230406.2020.1813052
   Jing YH, 2021, IEEE T CYBERNETICS, V51, P568, DOI 10.1109/TCYB.2019.2904768
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kennelly P. J., 2006, CARTOGR GEOGR INF SC, V33, P21, DOI 10.1559/152304006777323118
   Kennelly P. J., 2013, SKYLUM, V0, P0
   Kennelly PJ, 2021, CARTOGR GEOGR INF SC, V48, P63, DOI 10.1080/15230406.2020.1830856
   Kennelly PJ, 2014, INT J GEOGR INF SCI, V28, P383, DOI 10.1080/13658816.2013.848985
   Kennelly PJ, 2008, GEOMORPHOLOGY, V102, P567, DOI 10.1016/j.geomorph.2008.05.046
   King DB, 2015, ACS SYM SER, V1214, P1
   Lawonn K, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13322
   Lee CH, 2006, IEEE T VIS COMPUT GR, V12, P197, DOI 10.1109/TVCG.2006.30
   Leonowicz A.M., 2010, CARTOGRAPHICA, V45, P64, DOI 10.3138/CARTO.45.1.64
   Leonowicz A.M., 2010, CARTOGR PERSPECT, V67, P51, DOI 10.14714/CP67.114
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Mao XJ, 2016, ADV NEUR IN, V29, P0
   Mark R, 1992, 92422 US GEOL SURV U, V0, P0
   Marston BE, 2015, INT J GEOGR INF SCI, V29, P1144, DOI 10.1080/13658816.2015.1009911
   McManus IC, 2004, PERCEPTION, V33, P1421, DOI 10.1068/p5289
   Monmonier M, 2015, HIST CARTOGRAPHY CAR, V6, P343
   Nair V, 2010, ICML, V27, P807
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, V0, P0, DOI 10.1145/2901318.2901343
   Park T, 2019, PROC CVPR IEEE, V0, PP2332, DOI 10.1109/CVPR.2019.00244
   Patterson T, 2019, N AM CART SOC NACIS, V0, P0
   Patterson T., 2010, SHADED RELIEF ARCH, V0, P0
   Patterson T., 2016, 10 ICA MOUNT CART WO, V0, P1
   Pearson A. W., 2015, HIST CARTOGRAPHY CAR, V6, P1267
   Ritter F, 2006, IEEE T VIS COMPUT GR, V12, P877, DOI 10.1109/TVCG.2006.172
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusinkiewicz S, 2006, ACM T GRAPHIC, V25, P1199, DOI 10.1145/1141911.1142015
   Semmo A., 2017, P INT S NONPHOTOREAL, V0, P1
   Simonyan K, 2015, ARXIV, V0, P0
   Sloan P.-P. J., 2001, GRAPHICS INTERFACE, V0, PP143, DOI 10.20380/GI2001.17
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun J, 1998, NAT NEUROSCI, V1, P183, DOI 10.1038/630
   Swiss World Atlas, 2017, EDK SCHWEIZ K KANT E, V0, P0
   Tan WR, 2017, IEEE IMAGE PROC, V0, P3760
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Theroux J. P., 1981, COASTAL ZONE MANAGEM, V0, P0
   Tietjen C, 2005, IEEE EUR S VIS EUROV, V0, PP303, DOI 10.2312/VISSYM/EUROVIS05/303-310
   Toth T., 2011, CARTOGRAPHIC PERSPEC, V0, PP19, DOI 10.14714/CP67.111
   TUFTE E, 1990, ENVISIONING INFORM, V0, P0
   Vergne R, 2009, ACM T GRAPHIC, V28, P0, DOI 10.1145/1531326.1531331
   Veronesi F, 2015, COMPUT GEOSCI-UK, V74, P121, DOI 10.1016/j.cageo.2014.10.015
   Veronesi F, 2014, CARTOGR J, V51, P291, DOI 10.1179/1743277414Y.0000000100
   Viola I, 2018, IEEE T VIS COMPUT GR, V24, P2573, DOI 10.1109/TVCG.2017.2747545
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEIBEL R, 1992, CARTOGR GEOGR INFORM, V19, P133, DOI 10.1559/152304092783762317
   Yoeli P, 1967, CARTOGR J, V4, P82, DOI 10.1179/CAJ.1967.4.2.82
   YoUli, 1965, SURV MAPP, V25, P573
   Zhang DJ, 2020, IEEE ACCESS, V8, P64434, DOI 10.1109/ACCESS.2020.2984771
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 82
TC 11
Z9 12
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 15
PY 2021
VL 27
IS 2
BP 1225
EP 1235
DI 10.1109/TVCG.2020.3030456
PG 11
WC Computer Science, Software Engineering
SC Computer Science
GA WF5FO
UT WOS:000706330100105
PM 33048742
DA 2023-04-26
ER

PT J
AU Cheng, LX
   Wang, LZ
   Feng, RY
   Yan, JN
AF Cheng, Luxiao
   Wang, Lizhe
   Feng, Ruyi
   Yan, Jining
TI Remote Sensing and Social Sensing Data Fusion for Fine-Resolution Population Mapping With a Multimodel Neural Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Convolutional neural network (CNN); multimodel neural network; population mapping; population spatialization; remote sensing
ID points-of-interest; land-cover; china; interpolation; imagery
AB Mapping population distribution at fine spatial scales is significant and fundamental for resource utilization, assessment of city disaster, environmental regulation, and urbanization. Multisource data produced by remote and social sensing have been widely used to disaggregate census information to map population distributions at fine resolution. However, it is challenging to achieve accurate high-spatial-resolution population mapping by combining multisource data and considering geographic spatial heterogeneity. The existing approaches do not consider global and local spatial information simultaneously, resulting in low accuracy. This article proposes a multimodel fusion neural network for estimating fine-resolution population estimates from multisource data. Our approach takes into account the local spatial information and global information of each geographic unit. Specifically, a first-order space matrix of a geographic unit is used to characterize its local spatial information. We propose a multimodel neural network, which combines a convolutional neural network and a multilayer perceptron (MLP) model to estimate a fine-resolution population mapping. Using Shenzhen, China, as the experimental setting, a population distribution map was generated at a 100-m spatial resolution. The model was quantitatively validated by showing that it captured the relationship between the estimated population and the census population at the township level (R-2 = 0.77) more accurately than the WorldPop dataset (R-2 = 0.51) and the MLP-based model (R-2 = 0.63). Qualitatively, the proposed model can identify differences in population density in densely populated areas and some remote population clusters more accurately than the WorldPop population dataset.
C1 [Cheng, Luxiao; Wang, Lizhe; Feng, Ruyi; Yan, Jining] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.
   [Cheng, Luxiao; Wang, Lizhe; Feng, Ruyi; Yan, Jining] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
C3 China University of Geosciences; China University of Geosciences
RP Wang, LZ (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Wuhan 430074, Peoples R China.; Wang, LZ (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
EM Chenglx@cug.edu.cn; Lizhe.Wang@gmail.com; fengry@cug.edu.cn; yanjn@cug.edu.cn
FU National Natural Science Foundation of China [U1711266, 41925007]
CR [Anonymous], 2005, COMPUT ENVIRON URBAN, V0, P0, DOI DOI 10.1016/J.COMPENVURBSYS.2003.09.004
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Aubrecht C, 2013, NAT HAZARDS, V68, P147, DOI 10.1007/s11069-012-0389-9
   Bakillah M, 2014, INT J GEOGR INF SCI, V28, P1940, DOI 10.1080/13658816.2014.909045
   Balk DL, 2006, ADV PARASIT, V62, P119, DOI 10.1016/S0065-308X(05)62004-0
   Bhaduri B, 2007, GEOJOURNAL, V69, P103, DOI 10.1007/s10708-007-9105-9
   Biamonte J, 2017, NATURE, V549, P195, DOI 10.1038/nature23474
   Deville P, 2014, P NATL ACAD SCI USA, V111, P15888, DOI 10.1073/pnas.1408439111
   Dobson JE, 2000, PHOTOGRAMM ENG REM S, V66, P849
   DOXSEYWHITFIELD E, 2015, PAP APPL GEOGR, V0001, P0
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Eicher C., 2001, CARTOGRAPHY GEOGRAPH, V28, P125, DOI 10.1559/152304001782173727
   Fan RY, 2020, IEEE J-STARS, V13, P4973, DOI 10.1109/JSTARS.2020.3019410
   Fan W, 2019, IEEE J-STARS, V12, P4265, DOI 10.1109/JSTARS.2019.2911525
   Feng XB, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161910
   Gaughan AE, 2016, SCI DATA, V3, P0, DOI 10.1038/sdata.2016.5
   Ghamisi P, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2018.2890023
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   GOODCHILD MF, 1993, ENVIRON PLANN A, V25, P383, DOI 10.1068/a250383
   Han D, 2015, PROC CVPR IEEE, V0, PP5016, DOI 10.1109/CVPR.2015.7299136
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Huang Z, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12193254
   Hung CY, 2017, IEEE ENG MED BIO, V0, PP3110, DOI 10.1109/EMBC.2017.8037515
   Li JM, 2019, J CLEAN PROD, V210, P181, DOI 10.1016/j.jclepro.2018.10.293
   Lo CP, 2008, GISCI REMOTE SENS, V45, P131, DOI 10.2747/1548-1603.45.2.131
   Lu DS, 2008, REMOTE SENS ENVIRON, V112, P3668, DOI 10.1016/j.rse.2008.05.009
   Martino P, 2016, OPERATING PROCEDURE, V0, P0
   Mellander C, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0139779
   Nieves JJ, 2017, J R SOC INTERFACE, V14, P0, DOI 10.1098/rsif.2017.0401
   Park Y, 2020, ENVIRON POLLUT, V256, P0, DOI 10.1016/j.envpol.2019.113395
   Patel NN, 2015, INT J APPL EARTH OBS, V35, P199, DOI 10.1016/j.jag.2014.09.005
   Robinson C, 2017, GEOHUMANITIES17: PROCEEDINGS OF THE 1ST ACM SIGSPATIAL WORKSHOP ON GEOSPATIAL HUMANITIES, V0, PP47, DOI 10.1145/3149858.3149863
   Ru LX, 2021, IEEE T IMAGE PROCESS, V30, P1382, DOI 10.1109/TIP.2020.3039328
   Song JC, 2019, LANDSCAPE URBAN PLAN, V190, P0, DOI 10.1016/j.landurbplan.2019.05.011
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stevens FR, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0107042
   Sutton P, 2001, INT J REMOTE SENS, V22, P3061, DOI 10.1080/01431160010007015
   Tatem AJ, 2017, SCI DATA, V4, P0, DOI 10.1038/sdata.2017.4
   Tatem AJ, 2007, PLOS ONE, V2, P0, DOI 10.1371/journal.pone.0001298
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tobler W, 1997, INT J POPUL GEOGR, V3, P203
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   TOBLER WR, 1979, J AM STAT ASSOC, V74, P519, DOI 10.2307/2286968
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/7068349
   Wang LZ, 2016, SCI DATA, V3, P0, DOI 10.1038/sdata.2016.47
   Wang Q, 2020, PROC IEEE C COMPUT V, V0, P0
   Wellmann T, 2020, LANDSCAPE URBAN PLAN, V202, P0, DOI 10.1016/j.landurbplan.2020.103857
   Wright JK, 1936, GEOGR REV, V26, P103, DOI 10.2307/209467
   Xu M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040608
   Yao Y, 2017, INT J GEOGR INF SCI, V31, P1220, DOI 10.1080/13658816.2017.1290252
   Yao Y, 2017, INT J GEOGR INF SCI, V31, P825, DOI 10.1080/13658816.2016.1244608
   Ye TT, 2019, SCI TOTAL ENVIRON, V658, P936, DOI 10.1016/j.scitotenv.2018.12.276
   Yu BL, 2015, IEEE J-STARS, V8, P1217, DOI 10.1109/JSTARS.2015.2399416
   Zeng CQ, 2011, INT J REMOTE SENS, V32, P9599, DOI 10.1080/01431161.2011.569581
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhu X, 2014, T GIS, V18, P421, DOI 10.1111/tgis.12100
   Zhuo L, 2009, INT J REMOTE SENS, V30, P1003, DOI 10.1080/01431160802430693
NR 57
TC 13
Z9 13
U1 7
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 5973
EP 5987
DI 10.1109/JSTARS.2021.3086139
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TC8IR
UT WOS:000668882800003
DA 2023-04-26
ER

PT J
AU Campbell, SW
   Briggs, M
   Roy, SG
   Douglas, TA
   Saari, S
AF Campbell, Seth William
   Briggs, Martin
   Roy, Samuel G.
   Douglas, Thomas A.
   Saari, Stephanie
TI Ground-penetrating radar, electromagnetic induction, terrain, and vegetation observations coupled with machine learning to map permafrost distribution at Twelvemile Lake, Alaska
SO PERMAFROST AND PERIGLACIAL PROCESSES
LA English
DT Article
DE frequency&#8208; domain electromagnetic induction; ground&#8208; penetrating radar; machine learning; permafrost; terrain; vegetation
ID near-surface permafrost; active-layer thickness; yukon flats; discontinuous permafrost; interior alaska; carbon release; ice; climate; thaw; degradation
AB We collected ground-penetrating radar (GPR) and frequency-domain electromagnetic induction (FDEM) profiles in 2011 and 2012 to identify the extent of permafrost relative to surface biomass and solar insolation around Twelvemile Lake near Fort Yukon, Alaska. We compared a Landsat-derived biomass estimate and modeled solar insolation from a digital elevation model to the geophysical measurements. We show correspondence between vegetation type and biomass relative to permafrost extent and seasonal freeze-thaw. Thicker permafrost (>= 25 m) was covered by greater biomass, and seasonal thaw depths in these regions were minimal (1 m). Shallow (1-3 m depth) and thin (20-50 cm) newly forming permafrost or frozen layers from the previous winter occurred below northward oriented slopes with thin biomass cover. South-facing slopes exhibited permafrost when there was enough biomass to shield incoming solar energy. We developed an artificial neural network to predict permafrost extent across the broader region by mapping GPR-observed instances of permafrost to FDEM, biomass, and terrain observations with 90.2% accuracy. We identified a strong linear correlation (r = -0.77) between permafrost probability and seasonal thaw depth, indicating that our models may also be used to explore thaw patterns and variability in active layer thickness. This study highlights the combined influence of biomass and terrain on the presence of permafrost and the value of evaluating such parameters via remote sensing to predict permafrost spatial or temporal variability. Incorporating diverse geophysical datasets with in-situ validation into machine learning models demonstrates a useful approach to upscale estimated permafrost extent across large Arctic expanses.
C1 [Campbell, Seth William; Roy, Samuel G.] Univ Maine, Sch Earth & Climate Sci, Orono, ME 04469 USA.
   [Campbell, Seth William] Univ Maine, Climate Change Inst, Orono, ME USA.
   [Campbell, Seth William] US Army Cold Reg Res & Engn Lab, Hanover, NH USA.
   [Briggs, Martin] US Geol Survey, Earth Syst Proc Div, Hydrogeophys Branch, Storrs, CT USA.
   [Roy, Samuel G.] Univ Maine, Senator George J Mitchell Ctr Sustainabil Solut, Orono, ME USA.
   [Douglas, Thomas A.; Saari, Stephanie] US Army Cold Reg Res & Engn Lab, Ft Wainwright, AK USA.
C3 University of Maine System; University of Maine Orono; University of Maine System; University of Maine Orono; United States Department of Defense; United States Army; U.S. Army Corps of Engineers; U.S. Army Engineer Research & Development Center (ERDC); Cold Regions Research & Engineering Laboratory (CRREL); United States Department of the Interior; United States Geological Survey; University of Maine System; University of Maine Orono; United States Department of Defense; United States Army; U.S. Army Corps of Engineers; U.S. Army Engineer Research & Development Center (ERDC); Cold Regions Research & Engineering Laboratory (CRREL)
RP Campbell, SW (corresponding author), Univ Maine, Sch Earth & Climate Sci, Orono, ME 04469 USA.
EM scampb64@maine.edu
FU National Science Foundation; Strategic Environmental Research and Development Program
CR Anderson JE, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111363
   [Anonymous], 2002, CIRCUM ARCTIC MAP PE, V0, P0, DOI DOI 10.7265/SKBG-KF16
   ARCONE SA, 1995, J GLACIOL, V41, P68, DOI 10.3189/S0022143000017779
   Arcone SA, 1998, GEOPHYSICS, V63, P1573, DOI 10.1190/1.1444454
   ARCONE SA, 1984, COLD REG SCI TECHNOL, V9, P29, DOI 10.1016/0165-232X(84)90045-4
   Barnhart KR, 2014, J GEOPHYS RES-EARTH, V119, P1155, DOI 10.1002/2013JF002845
   Briggs MA, 2019, GROUNDWATER, V57, P737, DOI 10.1111/gwat.12866
   Briggs MA, 2017, PERMAFROST PERIGLAC, V28, P52, DOI 10.1002/ppp.1893
   Briggs MA, 2014, GEOPHYS RES LETT, V41, P1585, DOI 10.1002/2014GL059251
   Brown DRN, 2015, J GEOPHYS RES-BIOGEO, V120, P1619, DOI 10.1002/2015JG003033
   BROWN J, 1998, EOS T AGU, V79, P634
   Brown ME, 2016, IEEE GEOSC REM SEN M, V4, P24, DOI 10.1109/MGRS.2016.2560759
   Chasmer L, 2011, PERMAFROST PERIGLAC, V22, P199, DOI 10.1002/ppp.724
   Chen ZH, 2017, CAN J REMOTE SENS, V43, P513, DOI 10.1080/07038992.2017.1370367
   DeConto RM, 2012, NATURE, V484, P87, DOI 10.1038/nature10929
   Douglas B, 2014, PALGR STUD PAC HIST, V0, PP1, DOI 10.1057/9781137305893
   Douglas T., 2008, P 9 INT C PERMAFROST, V1, P373
   Douglas TA, 2016, GEOPHYSICS, V81, PWA71, DOI 10.1190/GEO2015-0149.1
   Fu P., 2000, P 4 INT C, V0, P0
   Fu PD, 2002, COMPUT ELECTRON AGR, V37, P25, DOI 10.1016/S0168-1699(02)00115-1
   Gangodagamage C, 2014, WATER RESOUR RES, V50, P6339, DOI 10.1002/2013WR014283
   Haltigin TW, 2012, PERMAFROST PERIGLAC, V23, P178, DOI 10.1002/ppp.1741
   HOEKSTRA P, 1978, GEOPHYSICS, V43, P782, DOI 10.1190/1.1440853
   Hrbacek F, 2020, CATENA, V190, P0, DOI 10.1016/j.catena.2020.104562
   Hugelius G, 2014, BIOGEOSCIENCES, V11, P6573, DOI 10.5194/bg-11-6573-2014
   Jepsen SM, 2013, GEOPHYS RES LETT, V40, P882, DOI 10.1002/grl.50187
   Jepsen SM, 2013, HYDROGEOL J, V21, P185, DOI 10.1007/s10040-012-0896-5
   Jepsen SM, 2012, USGS OPEN-FILE REP, V25, P2012
   Jepsen SM, 2016, HYDROL PROCESS, V30, P1782, DOI 10.1002/hyp.10756
   Ji L, 2012, INT J APPL EARTH OBS, V18, P451, DOI 10.1016/j.jag.2012.03.019
   Johansson M, 2013, ENVIRON RES LETT, V8, P0, DOI 10.1088/1748-9326/8/3/035025
   Jones BM, 2013, ENVIRON RES LETT, V8, P0, DOI 10.1088/1748-9326/8/4/045025
   Jorgenson MT, 2001, CLIMATIC CHANGE, V48, P551, DOI 10.1023/A:1005667424292
   Jorgenson T, 2008, MAP PERMAFROST CHARA, V0, P0
   Kohavi R., 1995, IJCAI-95. PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1137
   Kokelj SV, 2013, J GEOPHYS RES-EARTH, V118, P681, DOI 10.1002/jgrf.20063
   Lawson DE, 1998, CRREL REPORT, V0, P0
   Lawson DE, 1996, CRREL REPORT, V94, P31
   Leverington DW, 1997, PERMAFROST PERIGLAC, V8, P207, DOI 10.1002/(SICI)1099-1530(199732)8:2&lt;205::AID-PPP252&gt;3.0.CO;2-5
   Ling F, 2003, PERMAFROST PERIGLAC, V14, P141, DOI 10.1002/ppp.445
   Ling F, 2007, GLOBAL PLANET CHANGE, V57, P235, DOI 10.1016/j.gloplacha.2006.11.009
   Liston GE, 1998, J GLACIOL, V44, P498, DOI 10.3189/S0022143000002021
   Liu L, 2012, J GEOPHYS RES-EARTH, V117, P0, DOI 10.1029/2011JF002041
   Liu L, 2010, J GEOPHYS RES-EARTH, V115, P0, DOI 10.1029/2009JF001547
   Loranty MM, 2018, BIOGEOSCIENCES, V15, P5287, DOI 10.5194/bg-15-5287-2018
   Melvin AM, 2017, P NATL ACAD SCI USA, V114, PE122, DOI 10.1073/pnas.1611056113
   Minsley BJ, 2015, CRYOSPHERE, V9, P781, DOI 10.5194/tc-9-781-2015
   Minsley BJ, 2012, GEOPHYS RES LETT, V39, P0, DOI 10.1029/2011GL050079
   Mishra U, 2014, SOIL SCI SOC AM J, V78, P894, DOI 10.2136/sssaj2013.11.0484
   Moussavi MS, 2014, INT J REMOTE SENS, V35, P5263, DOI 10.1080/01431161.2014.939780
   Narine LL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111824
   Nelson F. E., 1998, J GEOPHYS RES ALL SE, V103, P28
   Nelson FE, 1997, ARCTIC ALPINE RES, V29, P367, DOI 10.2307/1551985
   Nguyen TN, 2009, PERMAFROST PERIGLAC, V20, P141, DOI 10.1002/ppp.637
   Nitze I, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9070640
   Novikova A, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091481
   Ong JB, 2010, HYDROGEOL J, V18, P1539, DOI 10.1007/s10040-010-0617-x
   Osterkamp TE, 1999, PERMAFROST PERIGLAC, V10, P17, DOI 10.1002/(SICI)1099-1530(199901/03)10:1&lt;17::AID-PPP303&gt;3.0.CO;2-4
   Panda SK, 2010, PERMAFROST PERIGLAC, V21, P271, DOI 10.1002/ppp.686
   Parsekian AD, 2013, GEOPHYS RES LETT, V40, P535, DOI 10.1002/grl.50137
   Pastick NJ, 2014, J GEOPHYS RES-BIOGEO, V119, P1244, DOI 10.1002/2013JG002594
   Pastick NJ, 2013, PERMAFROST PERIGLAC, V24, P184, DOI 10.1002/ppp.1775
   PEDDLE DR, 1993, REMOTE SENS ENVIRON, V44, P67, DOI 10.1016/0034-4257(93)90103-5
   PEDDLE DR, 1992, INT J REMOTE SENS, V13, P3375, DOI 10.1080/01431169208904126
   Perreault N, 2017, ARCT SCI, V3, P237, DOI 10.1139/as-2016-0047
   Ponti S, 2021, ECOL INDIC, V120, P0, DOI 10.1016/j.ecolind.2020.106889
   Rich PM, 1994, AM SOC PHOTOGRAMMETR, V0, P524
   Romanovsky VE, 2017, TERRESTRIAL PERMAFRO, V0, P0
   Schuur EAG, 2009, NATURE, V459, P556, DOI 10.1038/nature08031
   Sheets RA, 2009, USGEOLOGICAL SURVEY, V0, P0, DOI DOI 10.3133/OFR20091025
   Shiklomanov NI, 2013, GEOPHYS RES LETT, V40, P6356, DOI 10.1002/2013GL058295
   Shur YL, 2007, PERMAFROST PERIGLAC, V18, P7, DOI 10.1002/ppp.582
   Skurikhin AN, 2014, IEEE SW SYMP IMAG, V0, PP137, DOI 10.1109/SSIAI.2014.6806048
   Skurikhin AN, 2013, REMOTE SENS LETT, V4, P1077, DOI 10.1080/2150704X.2013.840404
   Smith GHS, 2006, DEPOSITIONAL MODELS, V0, P0, DOI DOI 10.1002/9781444304374.ch2
   Steedman AE, 2017, PERMAFROST PERIGLAC, V28, P66, DOI 10.1002/ppp.1880
   Tarnocai C, 2009, GLOBAL BIOGEOCHEM CY, V23, P0, DOI 10.1029/2008GB003327
   Ulrich M, 2011, GEOMORPHOLOGY, V134, P197, DOI 10.1016/j.geomorph.2011.07.002
   Ulrich M, 2014, PERMAFROST PERIGLAC, V25, P151, DOI 10.1002/ppp.1810
   USGS Earth Resources Observation and Science (EROS) Center, 2012, AB BIOM YUK FLATS EC, V0, P0
   Verpaelst M, 2017, ARCT SCI, V3, P301, DOI 10.1139/as-2016-0018
   Wainwright HM, 2015, J GEOPHYS RES-BIOGEO, V120, P788, DOI 10.1002/2014JG002799
   Walter KM, 2007, PHILOS T R SOC A, V365, P1657, DOI 10.1098/rsta.2007.2036
   Wellman TP, 2013, HYDROGEOL J, V21, P281, DOI 10.1007/s10040-012-0941-4
   Widhalm B, 2017, CRYOSPHERE, V11, P483, DOI 10.5194/tc-11-483-2017
   Wooldridge CL, 2005, J SEDIMENT RES, V75, P844, DOI 10.2110/jsr.2005.066
   Zhang T, 2008, POLAR GEOGR, V31, P47, DOI 10.1080/10889370802175895
   Zhang WX, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091487
NR 90
TC 3
Z9 3
U1 3
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1045-6740
EI 1099-1530
J9 PERMAFROST PERIGLAC
JI Permafrost Periglacial Process.
PD JUL 15
PY 2021
VL 32
IS 3
BP 407
EP 426
DI 10.1002/ppp.2100
EA FEB 2021
PG 20
WC Geography, Physical; Geology
SC Physical Geography; Geology
GA TU4PR
UT WOS:000614752800001
DA 2023-04-26
ER

PT J
AU Zheng, J
   Gao, ZR
   Ma, JS
   Shen, J
   Zhang, K
AF Zheng, Jing
   Gao, Ziren
   Ma, Jingsong
   Shen, Jie
   Zhang, Kang
TI Deep Graph Convolutional Networks for Accurate Automatic Road Network Selection
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE road network selection; graph convolutional networks (GCNs); deep architectures; cartographic generalization
ID neural-network
AB The selection of road networks is very important for cartographic generalization. Traditional artificial intelligence methods have improved selection efficiency but cannot fully extract the spatial features of road networks. However, current selection methods, which are based on the theory of graphs or strokes, have low automaticity and are highly subjective. Graph convolutional networks (GCNs) combine graph theory with neural networks; thus, they can not only extract spatial information but also realize automatic selection. Therefore, in this study, we adopted GCNs for automatic road network selection and transformed the process into one of node classification. In addition, to solve the problem of gradient vanishing in GCNs, we compared and analyzed the results of various GCNs (GraphSAGE and graph attention networks [GAT]) by selecting small-scale road networks under different deep architectures (JK-Nets, ResNet, and DenseNet). Our results indicate that GAT provides better selection of road networks than other models. Additionally, the three abovementioned deep architectures can effectively improve the selection effect of models; JK-Nets demonstrated more improvement with higher accuracy (88.12%) than other methods. Thus, our study shows that GCN is an appropriate tool for road network selection; its application in cartography must be further explored.
C1 [Zheng, Jing; Gao, Ziren; Ma, Jingsong; Zhang, Kang] Nanjing Univ, Dept Geog Informat Sci, Nanjing 210023, Peoples R China.
   [Ma, Jingsong; Shen, Jie] Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Peoples R China.
   [Shen, Jie] Nanjing Normal Univ, Inst Geog Sci, Nanjing 210046, Peoples R China.
   [Shen, Jie] Nanjing Normal Univ, Minist Educ, Key Lab Virtual Geog Environm, Nanjing 210046, Peoples R China.
C3 Nanjing University; Nanjing Normal University; Nanjing Normal University
RP Ma, JS (corresponding author), Nanjing Univ, Dept Geog Informat Sci, Nanjing 210023, Peoples R China.; Ma, JS (corresponding author), Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Peoples R China.
EM mg1927084@smail.nju.edu.cn; mg20270069@smail.nju.edu.cn; majs@nju.edu.cn; shenjie@njnu.edu.cn; mg1727079@smail.nju.edu.cn
FU National Natural Science Foundation of China
CR Ai T.H, 2021, ACTA GEOD CARTOGR SI, V50, P1
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Bahdanau D, 2016, ARXIV, V0, P0
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bruna J., 2013, INT C LEARNING REPRE, V0, P0
   Cai Y.X., 2008, J GEOMAT, V05, P24
   Cho K, 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/V1/D14-1179
   Defferrard M, 2016, NEURAL INFORM PROCES, V30, P3844
   [邓红艳 DENG Hongyan], 2006, 武汉大学学报. 信息科学版 GEOMATICS AND INFORMATION SCIENCE OF WUHAN UNIVERSITY., V31, P164
   Gori M, 2005, IEEE IJCNN, V0, P729
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Grover A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP855, DOI 10.1145/2939672.2939754
   Guo M., 2012, J GEOMAT SCI TECHNOL, V29, P308
   Hamaguchi T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P1802
   Hamilton WL, 2017, NIPS, V0, P0, DOI DOI 10.5555/3294771.3294869
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hongwei Wang, 2019, ACM TRANSACTIONS ON INFORMATION SYSTEMS, V37, P0, DOI 10.1145/3312738
   [胡云岗 HU Yungang], 2007, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V36, P351
   Huang GL, 2017, IEEE ICC, V0, P0
   Jepsen TS, 2022, IEEE T INTELL TRANSP, V23, P418, DOI 10.1109/TITS.2020.3011799
   Jiang B., 2004, T GIS, V8, P335, DOI https://doi.org/10.1111/j.1467-9671.2004.00186.x
   Kipf T. N., 2016, ARXIV, V0, P0
   Li GH, 2019, IEEE I CONF COMP VIS, V0, PP9266, DOI 10.1109/ICCV.2019.00936
   [李木梓 Li Muzi], 2012, 地球信息科学学报 JOURNAL OF GEO-INFORMATION SCIENCE, V14, P719
   Li Q., 2018, 32 AAAI C ART INT, V0, P0
   Liu K., 2017, RES INTELLIGENT SELE, V0, P0
   [刘凯 Liu Kai], 2016, 测绘科学技术学报 JOURNAL OF GEOMATICS SCIENCE AND TECHNOLOGY, V33, P325
   Liu P., 2019, GEOMAT WORLD, V26, P8
   Maas Andrew L., 2013, PROC 30 INT C MACH L, V0, P0
   Mackaness W. A., 1993, CARTOGR GEOGR INF SC, V20, P210, DOI 10.1559/152304093782637479
   Micheli A, 2009, IEEE T NEURAL NETWOR, V20, P498, DOI 10.1109/TNN.2008.2010350
   Quinlan J. R., 1986, MACHINE LEARNING, V1, P81, DOI 10.1023/A:1022643204877
   Richardson D., 1999, P ICA 19 INT CART C, V0, P14
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Thomson R, 2007, GEN GEOGRAPHIC INFOR, V0, P255
   Velickovic P., 2017, STAT-US, V0, P0
   Wang J.Y., 1985, J GEOMAT SCI TECHNOL, V1, P79
   [王米琪 Wang Miqi], 2020, 武汉大学学报. 信息科学版 GEOMATICS AND INFORMATION SCIENCE OF WUHAN UNIVERSITY, V45, P1960
   Wilder B, 2019, ADV NEUR IN, V32, P0
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu KYL, 2018, PR MACH LEARN RES, V80, P0
   [徐智邦 Xu Zhibang], 2018, 地球信息科学学报 JOURNAL OF GEO-INFORMATION SCIENCE, V20, P159
   [杨敏 Yang Min], 2013, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V42, P581
   Ying R, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP974, DOI 10.1145/3219819.3219890
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3634
   Yu F., 2015, 1511 ARXIV, V0, P0
   Yuan L.H., 2018, STUDY ENSEMBLE LEARN, V0, P0
   Zhang ZW, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2778, DOI 10.1145/3219819.3219969
NR 48
TC 2
Z9 4
U1 8
U2 26
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD NOV 15
PY 2021
VL 10
IS 11
BP 
EP 
DI 10.3390/ijgi10110768
PG 22
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA XL2KS
UT WOS:000727978700001
DA 2023-04-26
ER

PT J
AU Cheng, QM
   Xu, Y
   Fu, P
   Li, JL
   Wang, W
   Ren, YC
AF Cheng, Qimin
   Xu, Yuan
   Fu, Peng
   Li, Jinling
   Wang, Wei
   Ren, Yingchao
TI Scene Classification of Remotely Sensed Images via Densely Connected Convolutional Neural Networks and an Ensemble Classifier
SO PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING
LA English
DT Article
ID features; texture; representation; segmentation; diagnosis
AB Deep learning techniques, especially convolutional neural networks, have boosted performance in analyzing and understanding remotely sensed images to a great extent. However, existing scene-classification methods generally neglect local and spatial information that is vital to scene classification of remotely sensed images. In this study, a method of scene classification for remotely sensed images based on pretrained densely connected convolutional neural networks combined with an ensemble classifier is proposed to tackle the under utilization of local and spatial information for image classification. Specifically, we first exploit the pretrained DenseNet and fine-tuned it to release its potential in remote-sensing image feature representation. Second, a spatial-pyramid structure and an improved Fisher-vector coding strategy are leveraged to further strengthen representation capability and the robustness of the feature map captured from convolutional layers. Then we integrate an ensemble classifier in our network architecture considering that lower attention to feature descriptors. Extensive experiments are conducted, and the proposed method achieves superior performance on UC Merced, AID, and NWPU-RESISC45 data sets.
C1 [Cheng, Qimin; Xu, Yuan] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan, Peoples R China.
   [Fu, Peng] Univ Illinois, Dept Plant Biol, Urbana, IL 61801 USA.
   [Li, Jinling] Xunlei Ltd, Shenzhen, Peoples R China.
   [Wang, Wei; Ren, Yingchao] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
   [Wang, Wei; Ren, Yingchao] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing, Peoples R China.
C3 Huazhong University of Science & Technology; University of Illinois System; University of Illinois Urbana-Champaign; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Cheng, QM (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan, Peoples R China.
EM chengqm@hust.edu.cn
FU National Key R&D Program of China [2018YFB0505401]; National Natural Science Foundation of China [41771452]; Institute of Remote Sensing and Digital Earth [Y5SJ1500CX]
CR [Anonymous], 2015, ICLR, V0, P0
   [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   Aptoula E, 2014, IEEE T GEOSCI REMOTE, V52, P3023, DOI 10.1109/TGRS.2013.2268736
   Bhagavathy S, 2006, IEEE T GEOSCI REMOTE, V44, P3706, DOI 10.1109/TGRS.2006.881741
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Castelluccio M., 2015, LAND USE CLASSIFICAT, V0, P0
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chakraborty D, 2017, GEO-SPAT INF SCI, V20, P39, DOI 10.1080/10095020.2017.1307660
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2015, PROC CVPR IEEE, V0, PP1173, DOI 10.1109/CVPR.2015.7298721
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Chu SW, 2019, IEEE IMAGE PROC, V0, PP594, DOI 10.1109/ICIP.2019.8803789
   Csurka G., 2004, WORKSHOP STAT LEARNI, V1, P22, DOI 10.1234/12345678
   Dede MA, 2019, IEEE GEOSCI REMOTE S, V16, P732, DOI 10.1109/LGRS.2018.2880136
   Dezaki FT, 2019, IEEE T MED IMAGING, V38, P1821, DOI 10.1109/TMI.2018.2888807
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Editor J., 2018, DROP, V0, P0
   Editor J., 2010, IEEE COMP SOC C COMP, V0, P0
   Editor J., 2014, DROP, V0, P0
   Faraji M., 2015, ADV COMPUT SCI INT J, V4, P8
   Flores E, 2019, PATTERN RECOGN, V89, P32, DOI 10.1016/j.patcog.2018.12.019
   Gao B.-B., 2015, DEEP SPATIAL PYRAMID, V0, P0
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hao WL, 2019, PATTERN RECOGN, V92, P13, DOI 10.1016/j.patcog.2019.03.005
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He XW, 2019, NEUROCOMPUTING, V328, P48, DOI 10.1016/j.neucom.2018.02.106
   Heipke C, 2020, GEO-SPAT INF SCI, V23, P10, DOI 10.1080/10095020.2020.1718003
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Hu F, 2013, REMOTE SENS-BASEL, V5, P2275, DOI 10.3390/rs5052275
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang LH, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060483
   [霍丽君 Huo Lijun], 2017, 光学精密工程 OPTICS AND PRECISION ENGINEERING, V25, P198
   Jegou H, 2010, PROC CVPR IEEE, V0, PP3304, DOI 10.1109/CVPR.2010.5540039
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Khened M, 2019, MED IMAGE ANAL, V51, P21, DOI 10.1016/j.media.2018.10.004
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kusumaningrum R., 2014, J APPL REMOTE SENSIN, V8, P1
   Lazebnik S., 2006, PROC IEEE C COMPUT V, V2, P2169, DOI 10.1109/CVPR.2006.68
   Li G., 2018, IMAGE GRAPHICS TECHN, V875, P238
   Li HT, 2010, INT J REMOTE SENS, V31, P1453, DOI 10.1080/01431160903475266
   Li X, 2018, IEEE J-STARS, V11, P3680, DOI 10.1109/JSTARS.2018.2865187
   Lienou M, 2010, IEEE GEOSCI REMOTE S, V7, P28, DOI 10.1109/LGRS.2009.2023536
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Liu YF, 2018, IEEE T GEOSCI REMOTE, V56, P7109, DOI 10.1109/TGRS.2018.2848473
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2017, IEEE T GEOSCI REMOTE, V55, P5148, DOI 10.1109/TGRS.2017.2702596
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Mahendran A, 2015, PROC CVPR IEEE, V0, PP5188, DOI 10.1109/CVPR.2015.7299155
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Minetto R, 2019, IEEE T GEOSCI REMOTE, V57, P6530, DOI 10.1109/TGRS.2019.2906883
   Negrier R., 2014, P 12 INT WORKSH CONT, V0, PP1, DOI 10.1109/CBMI.2014.6849835
   Newsam S, 2004, APPL OPTICS, V43, P210, DOI 10.1364/AO.43.000210
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Paragios, 1900, V6314, V0, P0
   Penatti Otavio A. B., 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP44, DOI 10.1109/CVPRW.2015.7301382
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Risojevic V, 2011, IEEE INT SYMP SIGNAL, V0, P190
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Sermanet P., 2013, ARXIV PREPRINT ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1312.6229
   Sheng GF, 2012, INT J REMOTE SENS, V33, P2395, DOI 10.1080/01431161.2011.608740
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, V0, PP1701, DOI 10.1109/CVPR.2014.220
   Bui TD, 2019, BIOMED SIGNAL PROCES, V54, P0, DOI 10.1016/j.bspc.2019.101613
   Wan LH, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.016017
   Wang HF, 2019, NEUROCOMPUTING, V333, P145, DOI 10.1016/j.neucom.2018.12.018
   Wang J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030225
   Wang LF, 2018, IEEE IMAGE PROC, V0, PP3558, DOI 10.1109/ICIP.2018.8451027
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang Y, 2011, IEEE I CONF COMP VIS, V0, PP1465, DOI 10.1109/ICCV.2011.6126403
   Yosinski J., 2015, ARXIV150606579, V0, P0
   Yu H, 2018, GEO-SPAT INF SCI, V21, P33, DOI 10.1080/10095020.2017.1418263
   Yu W., 2014, DNN FLOW DNN FEATURE, V0, P0
   Zhang CJ, 2019, IEEE T GEOSCI REMOTE, V57, P9201, DOI 10.1109/TGRS.2019.2925615
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zhang K, 2019, IEEE IMAGE PROC, V0, PP410, DOI 10.1109/ICIP.2019.8802982
   Zhang RZ, 2018, IEEE T MED IMAGING, V37, P2149, DOI 10.1109/TMI.2018.2821244
   Zhang W, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050494
   Zhang ZC, 2018, IEEE T MED IMAGING, V37, P1407, DOI 10.1109/TMI.2018.2823338
   Zhao B, 2017, IEEE GEOSCI REMOTE S, V14, P1436, DOI 10.1109/LGRS.2017.2691013
   Zhao LJ, 2014, IEEE J-STARS, V7, P4620, DOI 10.1109/JSTARS.2014.2339842
   Zhao LJ, 2014, INT J REMOTE SENS, V35, P2296, DOI 10.1080/01431161.2014.890762
   Zheng XT, 2019, IEEE T GEOSCI REMOTE, V57, P4799, DOI 10.1109/TGRS.2019.2893115
   Zhong YF, 2015, J APPL REMOTE SENS, V9, P0, DOI 10.1117/1.JRS.9.095064
   Zhou FQ, 2018, NEUROCOMPUTING, V290, P34, DOI 10.1016/j.neucom.2018.02.027
NR 96
TC 3
Z9 3
U1 3
U2 20
PU AMER SOC PHOTOGRAMMETRY
PI BETHESDA
PA 5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA
SN 0099-1112
EI 2374-8079
J9 PHOTOGRAMM ENG REM S
JI Photogramm. Eng. Remote Sens.
PD APR 15
PY 2021
VL 87
IS 4
BP 295
EP 308
DI 10.14358/PERS.87.3.295
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QY7VX
UT WOS:000630246500008
DA 2023-04-26
ER

PT J
AU Hao, QB
   Pei, Y
   Zhou, R
   Sun, B
   Sun, J
   Li, ST
   Kang, XD
AF Hao, Qiaobo
   Pei, Yu
   Zhou, Rong
   Sun, Bin
   Sun, Jun
   Li, Shutao
   Kang, Xudong
TI Fusing Multiple Deep Models for In Vivo Human Brain Hyperspectral Image Classification to Identify Glioblastoma Tumor
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Deep learning; hyperspectral image (HSI) classification; identification of glioblastoma (GBM) tumor; intraoperative imaging; precision medicine
ID phasor analysis; components
AB Glioblastoma (GBM) tumor is the most common primary brain malignant tumor. The precise identification of GBM tumors is very important for diagnosis and treatment. Hyperspectral imaging is a fast, noncontact, accurate, and safe modern medical detection technology, which is expected to be a new tool of intraoperative diagnosis. In order to make full use of the spectral and spatial information of hyperspectral images (HSIs) to achieve accurate GBM tumor identification, a method based on the fusion of multiple deep models is proposed for in vivo human brain HSI classification. The proposed method includes the following major steps: 1) spectral phasor analysis and data oversampling; 2) 1-D deep neural network (1D-DNN)-based spectral HSI feature extraction and classification; 3) 2-D convolution neural network (2D-CNN)-based spectral-spatial HSI feature extraction and classification; 4) edge-preserving filtering-based classification result fusion and optimization; and 5) fully convolutional network (FCN)-based background segmentation. To verify the capabilities of the proposed method, experiments are performed on two real human brain hyperspectral datasets, including 36 in vivo HSIs captured from 16 different patients. The proposed method can achieve an overall accuracy of 96.69% for four-class classification and overall accuracy of 96.34% for GBM tumor identification. Experimental results demonstrate that the proposed method exhibits competitive classification performance and can generate satisfactory thematic maps of the location of the GBM tumor, which can provide the surgeon with guidance on successful and precise tumor resection.
C1 [Hao, Qiaobo; Pei, Yu; Sun, Bin; Li, Shutao; Kang, Xudong] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
   [Hao, Qiaobo; Pei, Yu; Sun, Bin; Li, Shutao; Kang, Xudong] Hunan Univ, Key Lab Visual Percept & Artificial Intelligence, Changsha 410082, Peoples R China.
   [Zhou, Rong; Sun, Jun] Fujitsu Res & Dev Ctr Co Ltd, Beijing 100022, Peoples R China.
C3 Hunan University; Hunan University; Fujitsu Ltd; Fujitsu Laboratories Ltd
RP Sun, B (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.; Sun, B (corresponding author), Hunan Univ, Key Lab Visual Percept & Artificial Intelligence, Changsha 410082, Peoples R China.
EM haoqiaobo@hnu.edu.cn; pedrodd@hnu.edu.cn; zhourong@fujitsu.com; sunbin611@hnu.edu.cn; sunjun@fujitsu.com; shutao_li@hnu.edu.cn; xudong_kang@163.com
FU National Natural Science Fund of China [61890962, 61801178, 61871179]; Science and Technology Talents Program of Hunan Association for Science and Technology [2017TJ-Q09]; Scientific Research Project of Hunan Education Department [19B105]
CR Andria G, 2009, IEEE T INSTRUM MEAS, V58, P3140, DOI 10.1109/TIM.2009.2016888
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P6712, DOI 10.1109/TGRS.2018.2841823
   Dong YF, 2021, IEEE T INSTRUM MEAS, V70, P0, DOI 10.1109/TIM.2021.3077967
   Erives H, 2009, IEEE T INSTRUM MEAS, V58, P631, DOI 10.1109/TIM.2009.2005557
   Fabelo H, 2019, IEEE ACCESS, V7, P39098, DOI 10.1109/ACCESS.2019.2904788
   Fabelo H, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19040920
   Fauvel M, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, V0, P238
   Fereidouni F, 2014, J BIOPHOTONICS, V7, P589, DOI 10.1002/jbio.201200244
   Fereidouni F, 2012, OPT EXPRESS, V20, P12729, DOI 10.1364/OE.20.012729
   Hamamci A, 2012, IEEE T MED IMAGING, V31, P790, DOI 10.1109/TMI.2011.2181857
   Hao QB, 2020, IEEE T GEOSCI REMOTE, V58, P4263, DOI 10.1109/TGRS.2019.2962014
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He NJ, 2019, IEEE T GEOSCI REMOTE, V57, P755, DOI 10.1109/TGRS.2018.2860464
   Islam A, 2013, IEEE T BIO-MED ENG, V60, P3204, DOI 10.1109/TBME.2013.2271383
   Kang XD, 2017, IEEE T GEOSCI REMOTE, V55, P7140, DOI 10.1109/TGRS.2017.2743102
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Kargel C, 2004, IEEE T INSTRUM MEAS, V53, P524, DOI 10.1109/TIM.2004.823296
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   Kong WW, 2019, IEEE T INSTRUM MEAS, V68, P938, DOI 10.1109/TIM.2018.2865046
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li R, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030582
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Manni F, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20236955
   Menze Bjoern H, 2015, IEEE TRANS MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Oppenlander ME, 2014, J NEUROSURG, V120, P846, DOI 10.3171/2013.12.JNS13184
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P740, DOI 10.1109/TGRS.2018.2860125
   Pike R, 2016, IEEE T BIO-MED ENG, V63, P653, DOI 10.1109/TBME.2015.2468578
   Prasad S, 2008, IEEE GEOSCI REMOTE S, V5, P625, DOI 10.1109/LGRS.2008.2001282
   Rasti B, 2020, IEEE GEOSC REM SEN M, V8, P60, DOI 10.1109/MGRS.2020.2979764
   Ravi D, 2017, IEEE T MED IMAGING, V36, P1845, DOI 10.1109/TMI.2017.2695523
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Wang JH, 2020, IEEE T CYBERNETICS, V50, P2971, DOI 10.1109/TCYB.2019.2891265
   Wei XL, 2019, IEEE T INSTRUM MEAS, V68, P4481, DOI 10.1109/TIM.2018.2887069
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Yuhui Yuan, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12351), V0, PP173, DOI 10.1007/978-3-030-58539-6_11
   Zhang YQ, 2021, IEEE T INSTRUM MEAS, V70, P0, DOI 10.1109/TIM.2020.3011777
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
NR 43
TC 11
Z9 11
U1 1
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PD JUN 15
PY 2021
VL 70
IS 
BP 
EP 
DI 10.1109/TIM.2021.3117634
PG 14
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Engineering; Instruments & Instrumentation
GA WG4JN
UT WOS:000706960500014
DA 2023-04-26
ER

PT J
AU Li, YY
   Huang, Q
   Pei, X
   Chen, YQ
   Jiao, LC
   Shang, RH
AF Li, Yangyang
   Huang, Qin
   Pei, Xuan
   Chen, Yanqiao
   Jiao, Licheng
   Shang, Ronghua
TI Cross-Layer Attention Network for Small Object Detection in Remote Sensing Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Object detection; Detectors; Remote sensing; Neural networks; Task analysis; Proposals; Attention mechanism; feature pyramid; object detection; remote sensing; small object
ID multiscale
AB In recent years, despite the tremendous progresses of object detection, small object detection has always been a challenge in the field of remote sensing. The main reason is that small objects cover few features that are easily lost during down-sampling. In this article, we propose a cross-layer attention network aiming to obtain stronger features of small objects for better detection. Specifically, we designed an up-sampling and down-sampling feature pyramid to obtain richer context information by bidirectionally fusing deep and shallow features, as well as skipping connections. Moreover, a cross-layer attention module is designed to obtain the nonlocal association of small objects in each layer, and further strengthen its representation ability through cross-layer integration and balance. Extensive experiments on the publicly available datasets (DIOR dataset and NWPUVHR-10 dataset) and the self-assembled datasets (SDOTA dataset and SDD dataset) show the excellent performance of our method compared with other detectors. Moreover, our method achieved 74.3% mAP on the public DIOR dataset without any tricks.
C1 [Li, Yangyang; Huang, Qin; Pei, Xuan; Jiao, Licheng; Shang, Ronghua] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Sch Artificial Intelligence,Minist Educ,Key Lab I, Xian 710071, Peoples R China.
   [Chen, Yanqiao] China Elect Technol Grp Corp, Res Inst 54, Shijiazhuang 050081, Hebei, Peoples R China.
C3 Xidian University; China Electronics Technology Group
RP Li, YY (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Sch Artificial Intelligence,Minist Educ,Key Lab I, Xian 710071, Peoples R China.
EM yyli@xidian.edu.cn; qinhuang@stu.xidian.edu.cn; 18804601171@163.com; chenyanqiao2016@163.com; lchjiao@mail.xidian.edu.cn; rhshang@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61772399, U1701267, 61773304, 61672405, 61772400]; Key Research and Development Program in Shaanxi Province of China [2019ZDLGY09-05]; Program for Cheung Kong Scholars and Innovative Research Team in University [IRT_15R53]; Technology Foundation for Selected Overseas Chinese Scholar in Shaanxi [2017021, 2018021]; National Key Research and Development Program of China [2017YFC08219]
CR [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   Cao Y, 2019, IEEE INT CONF COMP V, V0, PP1971, DOI 10.1109/ICCVW.2019.00246
   Chang SZ, 2020, IEEE T GEOSCI REMOTE, V58, P4033, DOI 10.1109/TGRS.2019.2960391
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cui LS, 2020, SCI CHINA INFORM SCI, V63, P0, DOI 10.1007/s11432-019-2723-1
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), V0, PP1796, DOI 10.1109/ICIT.2016.7475036
   Deng C., 2020, P ICLR, V0, P0
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Du B, 2019, IEEE J-STARS, V12, P3043, DOI 10.1109/JSTARS.2019.2917703
   Duan KW, 2019, IEEE I CONF COMP VIS, V0, PP6568, DOI 10.1109/ICCV.2019.00667
   Han JW, 2014, ISPRS J PHOTOGRAMM, V89, P37, DOI 10.1016/j.isprsjprs.2013.12.011
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang L., 2015, DENSEBOX UNIFYING LA, V0, P0
   Jiang YY, 2018, INT C PATT RECOG, V0, P3610
   Li CL, 2020, IEEE COMPUT SOC CONF, V0, PP737, DOI 10.1109/CVPRW50498.2020.00103
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li YY, 2020, IEEE ACCESS, V8, P63121, DOI 10.1109/ACCESS.2020.2984310
   Li YY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030389
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Li Z., 2017, FSSD FEATURE FUSION, V0, P0
   Lim J-S., 2019, ARXIV191206319, V0, P0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Mark Everingham, 2010, IJCV, V88, P303, DOI 10.1007/S11263-009-0275-4
   Newell A, 2017, ADV NEUR IN, V30, P0
   Pang JM, 2019, PROC CVPR IEEE, V0, PP821, DOI 10.1109/CVPR.2019.00091
   Pang JM, 2019, IEEE T GEOSCI REMOTE, V57, P5512, DOI 10.1109/TGRS.2019.2899955
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Rabbi J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091432
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8050813
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wang SL, 2018, PROC CVPR IEEE, V0, PP2589, DOI 10.1109/CVPR.2018.00274
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Yang F, 2019, IEEE I CONF COMP VIS, V0, PP8310, DOI 10.1109/ICCV.2019.00840
   Yang X, 2018, IEEE ACCESS, V6, P50839, DOI 10.1109/ACCESS.2018.2869884
   Yang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010132
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang H, 2019, PR MACH LEARN RES, V97, P0
NR 48
TC 20
Z9 20
U1 21
U2 69
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2148
EP 2161
DI 10.1109/JSTARS.2020.3046482
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QE6HN
UT WOS:000616306700002
DA 2023-04-26
ER

PT J
AU Nabil, A
AF Nabil, Aouadi
TI Combination of Hough Transform and Neural Network on recognizing mathematical symbols
SO 2021 8TH INTERNATIONAL CONFERENCE ON ICT & ACCESSIBILITY (ICTA)
LA English
DT Proceedings Paper
DE Perceptron Multilayer Network; Hough Transform; Mathematical Symbol Specialized Neural Network
ID recognition
AB Offline printed mathematical symbol recognition is a particularly difficult task. Recognizing mathematical symbols is one stage within the overall system for recognition of mathematical documents. We describe many experiments using MultiLayer Perceptron (MLP), Hough Transform (HT), k Nearest Neighbors (kNN) and structural Freeman chain code, to enhance symbol recognition of printed mathematics. First, we investigate the use of a MLP based method. Second, we compare the performance of a proposal neural structural method, named HT-MLPs, on symbols that initial MLP usually confuses. The inclusion of HT in MLP reduces symbol confusion rate by 21% and improves recognition rates from 72% to 93%. To improve the efficiency of the proposed method, we compare it to KNN then to Freeman code based methods, commonly used in pattern recognition. While analyzing results, we show that HT-MLP always gives a lower mean confusion and rejection and higher success rates than the others solutions.
C1 [Nabil, Aouadi] Latice Lab, Tunis, Tunisia.
RP Nabil, A (corresponding author), Latice Lab, Tunis, Tunisia.
EM nabil.aouadi@utic.rnu.tn
CR Alvaro F, 2013, P 2013 ACM S DOCUMEN, V0, P123
   Anderson R. H., 1967, PROC ACM S INTERACTI, V0, PP436, DOI 10.1145/2402536.2402585
   Ayeb Kawther Khazri, 2020, MEDITERRANEAN C PATT, V0, P0
   Ayeb Kawther Khazri, 2017, 1 INT WORKSHOP ARABI, V0, P0
   Bianchini Claudia, 2019, ARXIV, V0, P0
   Blostein D., 1996, HDB CHARACTER RECOGN, V0, PP557, DOI 10.1142/9789812830968_0021
   Garain U, 2004, INT C PATT RECOG, V0, PP384, DOI 10.1109/ICPR.2004.1334132
   Kacem A., 2001, JOUR IJDAR, V4, P97108
   KOSCHINSKI M, 1995, INT CONF ACOUST SPEE, V0, PP2439, DOI 10.1109/ICASSP.1995.479986
   Kosmala A., 1999, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION. ICDAR 99 (CAT. NO.PR00318), V0, PP107, DOI 10.1109/ICDAR.1999.791736
   Malon C, 2008, PATTERN RECOGN LETT, V29, P1326, DOI 10.1016/j.patrec.2008.02.005
   Nazemi A, 2019, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.1910.07395
   Topia E., 2003, PROC ICDAR, V0, P0
   Winkler H.J., 1995, P ICASSP, V4, P0
   Xuejun Z., 1997, PROC ICDAR, V0, P0
   Yang Michael, 2004, P 2004 INT S SYMBOLI, V0, P305
NR 16
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/ICTA54582.2021.9809779
PG 6
WC Computer Science, Cybernetics; Computer Science, Information Systems; Education, Special
SC Computer Science; Education & Educational Research
GA BT8IO
UT WOS:000853691200020
DA 2023-04-26
ER

PT J
AU Pacheco, JB
   do Amaral, HMC
AF Pacheco Junior, Joao Batista
   Costa do Amaral, Henrique Mariano
TI Performance Analysis in the Segmentation of urban paved roads in RGB satellite images using K-Means++ and SegNet: case study in Sao Luis-MA
SO INTELIGENCIA ARTIFICIAL-IBEROAMERICAL JOURNAL OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Geoprocessing; RGB image; image segmentation; K-Means++; Convolutional Neural Network
ID convolutional neural-networks
AB The design and manual insertion of new terrestrial roads into geographic databases is a frequent activity in geoprocessing and their demand usually occurs as the most up-to-date satellite imagery of the territory is acquired. Continually, new urban and rural occupations emerge, for which specific vector geometries need to be designed to characterize the cartographic inputs and accommodate the relevant associated data. Therefore, it is convenient to develop a computational tool that, with the help of artificial intelligence, automates what is possible in this respect, since manual editing depends on the limits of user agility, and does it in images that are usually easy and free to access. To test the feasibility of this proposal, a database of RGB images containing asphalted urban roads is presented to the K-Means++ algorithm and the SegNet Convolutional Neural Network, and the performance of each one was evaluated and compared for accuracy and IoU of road identification. Under the conditions of the experiment, K-Means++ achieved poor and unviable results for use in a real-life application involving asphalt road detection in RGB satellite images, with average accuracy ranging from 41.67% to 64.19% and average IoU of 12.30% to 16.16%, depending on the preprocessing strategy used. On the other hand, the SegNet Convolutional Neural Network proved to be appropriate for precision applications not sensitive to discontinuities, achieving an average accuracy of 87.12% and an average IoU of 71.93%.
C1 [Pacheco Junior, Joao Batista; Costa do Amaral, Henrique Mariano] Univ Estadual Maranhao, Sao Luis, Maranhao, Brazil.
C3 Universidade Estadual do Maranhao
RP Pacheco, JB (corresponding author), Univ Estadual Maranhao, Sao Luis, Maranhao, Brazil.
EM ioarmis.baptista@gmail.com; hmca13@gmail.com
CR [Anonymous], 2006, SISTEMA BRASILEIRO C, V0, P0
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, V0, P1027
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   BRAGA A. P., 2000, REDES NEURAIS ARTIFI, V0, P0
   Collobert R., 2008, P 25 INT C MACHINE L, V0, P0
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.32
   Doucette P, 2001, ISPRS J PHOTOGRAMM, V55, P347, DOI 10.1016/S0924-2716(01)00027-2
   Eickenberg M, 2017, NEUROIMAGE, V152, P184, DOI 10.1016/j.neuroimage.2016.10.001
   Ferreira J. L., 1900, V18, V0, P0
   GeoHack, 2019, GEOHACK SAO LUIS MAR, V0, P0
   Gonzalez R. C., 2018, DIGITAL IMAGE PROCES, V4th, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI 10.1016/j.conbuildmat.2017.09.110
   Guerin J., 2017, 4 INT C ART INT APPL, V0, P0
   Haykin S, 2001, NEURAL NETWORKS LEAR, V3rd, P0
   IBGE, 2011, EST MAR PED, V0, P0
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P1543
   LIPSCHUTZ S, 1965, SCHAUMS OUTLINE THEO, V0, P0
   Liu W.T.H, 2006, APLICACOES SENSORIAM, V0, P0
   Londe P. R., 2014, REV BRAS GEO MED SAU, V10, P264
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Ludwig Jr O., 2007, REDES NEURAIS, V0, P0
   MacQueen J.B., 1967, PROC 5 BERKELEY S MA, V0, P281
   Mathworks, 2019, SEMANTIC SEGMENTATIO, V0, P0
   Moraes Neto João M. de, 2002, REV. BRAS. ENG. AGRÍC. AMBIENT., V6, P180, DOI 10.1590/S1415-43662002000100032
   Nobrega R. A. d. A, 2007, DETECCAO MALHA VIARI, V0, P0
   Noh H, 2015, IEEE I CONF COMP VIS, V0, PP1520, DOI 10.1109/ICCV.2015.178
   Pacheco Junior J. B, 2019, USO REDES NEURAIS CO, V0, P0
   Patterson J., 2017, DEEP LEARNING PRACTI, V0, P0
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pinho C. M. D. d., 2008, INT ARCH PHOTOGRAM R, V38, P695
   Pinho C. M. D. d., 2005, ANAIS12S BRASILEIRO, V0, P4217
   Plotze R. d. O., 2004, 4 C BRAS COMP, V0, P59
   Ramachandran Prajit, 2017, ABS171005941 CORR, V0, P0
   Rollet R, 1998, INT J REMOTE SENS, V19, P3003, DOI 10.1080/014311698214398
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russel S., 2009, ARTIF INTELL, V3rd, P0
   Simoes A. d. S, 2000, SEGMENTACAO IMAGENS, V0, P0
   Skiena S, 2004, CALCULETED BETS, V0, P0
   Stona T, 2011, TESSELACAO PAVIMENTA, V0, P0
   Venturieri A, 1996, SEGMENTACAO IMAGENS, V0, P0
   Wei Zhang, 1992, PROCEEDINGS OF THE SPIE - THE INTERNATIONAL SOCIETY FOR OPTICAL ENGINEERING, V1709, P257, DOI 10.1117/12.140004
NR 44
TC 0
Z9 0
U1 0
U2 0
PU ASOC ESPANOLA INTELIGENCIA ARTIFICIAL
PI VALENCIA
PA FAC INFORMATICA, UNIV POLITECNICA VALENCIA, VALENCIA, SPAIN
SN 1137-3601
EI 1988-3064
J9 INTELIGENCIA ARTIFIC
JI Inteligencia Artif.
PD DEC 15
PY 2021
VL 24
IS 68
BP 89
EP 103
DI 10.4114/intartif.vol24iss68pp89-103
PG 15
WC Computer Science, Artificial Intelligence
SC Computer Science
GA ZV2IG
UT WOS:000770358700002
DA 2023-04-26
ER

PT J
AU Morone, P
   Yilan, G
   Imbert, E
AF Morone, Piergiuseppe
   Yilan, Gulsah
   Imbert, Enrica
TI Using fuzzy cognitive maps to identify better policy strategies to valorize organic waste flows: An Italian case study
SO JOURNAL OF CLEANER PRODUCTION
LA English
DT Article
DE Italy; Circular bioeconomy; Organic fraction of municipal solid waste; Policy scenarios; (OFMSW); Policy mixes; Organic fraction of municipal solid waste (OFMSW)
ID municipal solid-waste; circular bioeconomy; european-union; sustainability; management; food; biorefinery; transition; models; sector
AB In Europe, there is a vast amount of municipal waste available. The organic fraction of municipal solid waste (OFMSW) represents a particularly valuable part of this waste, due to its potential to be employed to produce a range of value-added products. While several studies have addressed the utilization of the OFMSW in the Italian context, an overall picture of how the circular bioeconomy (CBE) model is being implemented in Italy is lacking. Accordingly, the present study investigated the status quo of the Italian bioeconomy sector, focusing on the use of the OFMSW as feedstock. The research aimed at increasing our understanding of barriers to the effective adoption of the CBE and identifying effective policy strategies. Specifically, a fuzzy cognitive mapping technique using an artificial neural network model was used to assess the impact of both single policy measures and policy mixes on a sample of selected outcomes, including human health, the environment, profitability and biorefinery approach. The results clearly showed that excessive bureaucracy, linear logic and technology-based solutions ignoring the complex characteristics of waste planning activities were the most important variables influencing the implementation of the CBE in Italy. Moreover, the results suggested that a policy mix combining economic and financial support policies for sustainable activities alongside improvements to waste collection systems could generate the highest positive effect on all considered outcomes.
C1 [Morone, Piergiuseppe; Yilan, Gulsah; Imbert, Enrica] UniteUna Sapienza Univ Rome, Bioecon Transit Res Grp, I-00161 Rome, Italy.
   [Yilan, Gulsah] Marmara Univ, Dept Chem Engn, Goztepe Campus, TR-34722 Istanbul, Turkey.
C3 Marmara University
RP Morone, P (corresponding author), UniteUna Sapienza Univ Rome, Bioecon Transit Res Grp, I-00161 Rome, Italy.
EM piergiuseppe.morone@unitelma.it
FU German Federal Ministry for Education and Research (BMBF) [Forderkennzeichen 031B0781A]
CR Al-Khatib IA, 2010, J ENVIRON MANAGE, V91, P1131, DOI 10.1016/j.jenvman.2010.01.003
   [Anonymous], 2020, SERIE GENERALE, V177, P0
   Awasthi MK, 2019, RENEW SUST ENERG REV, V111, P115, DOI 10.1016/j.rser.2019.05.017
   Barampouti EM, 2019, RENEW SUST ENERG REV, V110, P298, DOI 10.1016/j.rser.2019.04.005
   Paes LAB, 2019, J CLEAN PROD, V239, P0, DOI 10.1016/j.jclepro.2019.118086
   Bovino C, 2014, RIFIUTI IMBALLAGGI M, V0, P393
   Brandao AS, 2021, J CLEAN PROD, V295, P0, DOI 10.1016/j.jclepro.2021.126407
   Carus M, 2018, IND BIOTECHNOL, V0, P0, DOI DOI 10.1089/IND.2018.29121.MCA
   Cucchiella F, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9112221
   DAdamo I, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su13041861
   DAdamo I, 2019, RESOURCES-BASEL, V8, P0, DOI 10.3390/resources8030151
   DAdamo I, 2019, WASTE MANAGE, V95, P102, DOI 10.1016/j.wasman.2019.06.005
   DAmato D, 2017, J CLEAN PROD, V168, P716, DOI 10.1016/j.jclepro.2017.09.053
   Demichelis F, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11154213
   Di Maria F, 2020, WASTE MANAGE, V103, P437, DOI 10.1016/j.wasman.2020.01.005
   Ding Y, 2021, J CLEAN PROD, V293, P0, DOI 10.1016/j.jclepro.2021.126144
   Edjabou ME, 2021, J CLEAN PROD, V295, P0, DOI 10.1016/j.jclepro.2021.126439
   Edjabou ME, 2015, WASTE MANAGE, V36, P12, DOI 10.1016/j.wasman.2014.11.009
   European Commission, 2020, CIRC EC STR ENV, V0, P0
   Eurostat, 2020, 1 POP EST, V0, P0
   Eurostat, 2021, MUN WAST STAT, V0, P0
   Falcone PM, 2020, LAND USE POLICY, V96, P0, DOI 10.1016/j.landusepol.2020.104680
   Falcone PM, 2017, ENERGY RES SOC SCI, V33, P105, DOI 10.1016/j.erss.2017.09.007
   Fatimah YA, 2020, J CLEAN PROD, V269, P0, DOI 10.1016/j.jclepro.2020.122263
   Fava F, 2015, NEW BIOTECHNOL, V32, P100, DOI 10.1016/j.nbt.2013.11.003
   Ferrari AM, 2021, J CLEAN PROD, V286, P0, DOI 10.1016/j.jclepro.2020.125314
   Ghisellini P, 2020, J CLEAN PROD, V243, P0, DOI 10.1016/j.jclepro.2019.118360
   Huertas-Valdivia I, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12156211
   ISPRA (Istituto Superiore per la Protezione e la Ricerca Ambientale), 2020, 9788844810306 ISBN I, V0, P0
   Kirchherr J, 2018, ECOL ECON, V150, P264, DOI 10.1016/j.ecolecon.2018.04.028
   Kurniawan TA, 2021, ENVIRON POLLUT, V277, P0, DOI 10.1016/j.envpol.2021.116741
   Ladu L, 2020, FOREST POLICY ECON, V110, P0, DOI 10.1016/j.forpol.2019.05.023
   Li N, 2018, RESOUR CONSERV RECY, V130, P109, DOI 10.1016/j.resconrec.2017.11.008
   Lopolito A, 2020, METHODSX, V7, P0, DOI 10.1016/j.mex.2020.100877
   Lytras G, 2021, WASTE BIOMASS VALORI, V12, P1677, DOI 10.1007/s12649-020-01108-z
   Fernandez-Gonzalez JM, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12114798
   Marino A, 2020, SCI TOTAL ENVIRON, V729, P0, DOI 10.1016/j.scitotenv.2020.138142
   Marrucci L, 2020, WASTE MANAGE, V105, P594, DOI 10.1016/j.wasman.2020.03.002
   Martinkus N, 2019, BIOMASS BIOENERG, V128, P0, DOI 10.1016/j.biombioe.2019.105330
   Moretto G, 2020, WATER RES, V170, P0, DOI 10.1016/j.watres.2019.115371
   Morone P, 2020, CURR OPIN GREEN SUST, V23, P55, DOI 10.1016/j.cogsc.2020.02.006
   Morone P, 2019, J CLEAN PROD, V208, P563, DOI 10.1016/j.jclepro.2018.10.075
   Ozesmi U, 2004, ECOL MODEL, V176, P43, DOI 10.1016/j.ecolmodel.2003.10.027
   Priyadarshini P, 2020, BIORESOURCE TECHNOL, V304, P0, DOI 10.1016/j.biortech.2020.123018
   Romano G, 2020, WASTE MANAGE, V118, P573, DOI 10.1016/j.wasman.2020.08.057
   S Venkata Mohan, 2018, N BIOTECHNOL, V40, P60, DOI 10.1016/j.nbt.2017.06.006
   Salmenpera H, 2021, J CLEAN PROD, V280, P0, DOI 10.1016/j.jclepro.2020.124339
   San Paolo Intesa, 2020, BIOECONOMIA EUROPA 6, V0, P0
   Sanz-Hernandez A, 2019, J CLEAN PROD, V224, P107, DOI 10.1016/j.jclepro.2019.03.168
   Sisto R, 2017, J CLEAN PROD, V168, P302, DOI 10.1016/j.jclepro.2017.08.186
   Stegmann P., 2020, RESOURCES CONSERVATI, V6, P0, DOI 10.1016/j.rcrx.2019.100029
   Thurer M, 2018, J CLEAN PROD, V181, P608, DOI 10.1016/j.jclepro.2017.12.130
   Tomic T, 2020, J ENVIRON MANAGE, V267, P0, DOI 10.1016/j.jenvman.2020.110564
   Tsai FM, 2020, J CLEAN PROD, V275, P0, DOI 10.1016/j.jclepro.2020.124132
   Tseng ML, 2020, RESOUR CONSERV RECY, V154, P0, DOI 10.1016/j.resconrec.2019.104601
   Ubando AT, 2020, BIORESOURCE TECHNOL, V299, P0, DOI 10.1016/j.biortech.2019.122585
   Vanhamaki S, 2020, RESOUR CONSERV RECY, V156, P0, DOI 10.1016/j.resconrec.2020.104716
NR 58
TC 13
Z9 13
U1 5
U2 10
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0959-6526
EI 1879-1786
J9 J CLEAN PROD
JI J. Clean Prod.
PD OCT 15
PY 2021
VL 319
IS 
BP 
EP 
DI 10.1016/j.jclepro.2021.128722
EA AUG 2021
PG 12
WC Green & Sustainable Science & Technology; Engineering, Environmental; Environmental Sciences
SC Science & Technology - Other Topics; Engineering; Environmental Sciences & Ecology
GA XM2BK
UT WOS:000728638800005
DA 2023-04-26
ER

PT J
AU Shahvi, S
   Mellander, PE
   Jordan, P
   Fenton, O
AF Shahvi, S.
   Mellander, P-E
   Jordan, P.
   Fenton, O.
TI A Fuzzy Cognitive Map method for integrated and participatory water governance and indicators affecting drinking water supplies
SO SCIENCE OF THE TOTAL ENVIRONMENT
LA English
DT Article
DE Agriculture; Water governance; Water quality; Fuzzy Cognitive Map; Policy
ID decision-making; stakeholder analysis; farmers; systems; contamination; scenarios; knowledge; policy; risk
AB Drinking water governance is challenging with different perceptions and priorities among stakeholders in different countries. To make provision for drinking water protection in agricultural areas, governance systems need to be mapped for bottlenecks to be identified and solutions highlighted. To address this a system thinking approach was used in an explanatory network analysis of Fuzzy Cognitive Maps (FCM) that were created during face to face interviews with stakeholder representative groups (individuals, policy developers, researchers, and regulators). Two exercises were designed and facilitated to obtain stakeholder maps on A) the water governance framework from stakeholders' own perspective with a ranking of actors in terms of their perceived importance and B) a list of importance factors and how these were connected for the provision of good drinking water quality supplies in agricultural areas. Causal relationships were subsequently drawn around each subject allowing mapping. A graph theory Hierarchy Index (h) approach examined if stakeholder groups preferred top down hierarchical governance or a more inclusive democratic governance approach. Finally, an auto-associative neural network method was deployed on group maps for examination during steady-state conditions for three scenarios to be explored i.e. changing "Farmers knowledge", "best management practice (BMP) uptake" and "Farmers behaviour and belief" to the highest level of influence and seeing how the system reacted. Results of Exercise A showed that all stakeholder representative groups had a different perception of the water governance framework. Most stakeholder groups had a democratic point of view regarding water governance structures and the ranking and importance of the actors within the framework. Results of Exercise B demonstrated that most of the groups have similar opinions regarding the highest ranked factors affecting drinking water quality and the possible environmental ecological policy options. In this second exercise, only one representative group showed a democratic outlook whereas all others had a hierarchal outlook. Scenario testing of policy options enabled bottlenecks and possible solutions to be identified. By boosting "Farmers behaviour and belief" to the highest possible level, resulted in a large increase in other factors - a scenario where farmers could benefit from the outcome. This would be achieved by enhancing farmers' willingness and intention to participate and implement BMPs. Better results would be achieved if farmers believed in the method and could benefit from the outcome. Also keeping "Farmers knowledge" at the highest point had a positive influence on the other factors. This can be achieved by enhancing farmers training and knowledge transfer by local and national actors. This method is widely applicable and should be considered for more integrated and participatory approaches to drinking water governance. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Shahvi, S.; Mellander, P-E; Fenton, O.] TEAGASC, Environm Res Ctr, Johnstown Castle, Co Wexford, Ireland.
   [Jordan, P.] Ulster Univ, Sch Geog & Environm Sci, Coleraine, Londonderry, North Ireland.
C3 Teagasc; Ulster University
RP Fenton, O (corresponding author), TEAGASC, Johnstown Castle Y35 Y52, Co Wexford, Ireland.
EM owen.fenton@teagasc.ie
FU European Union Horizon 2020 - Research and innovation Framework programme [727450]
CR Akhmouch A, 2016, WATER-SUI, V8, P0, DOI 10.3390/w8050204
   [Anonymous], 1976, STRUCTURE DECISION C, V0, P0
   Arnold RD, 2015, PROCEDIA COMPUT SCI, V44, P669, DOI 10.1016/j.procs.2015.03.050
   Ashekuzzaman SM, 2018, FRONT SUSTAIN FOOD S, V2, P0, DOI 10.3389/fsufs.2018.00034
   Bakker K, 2011, INT J WATER RESOUR D, V27, P275, DOI 10.1080/07900627.2011.564969
   Bastian M., 2009, INT AAAI C WEBLOGS S, V0, P0
   Berkes F, 2004, CONSERV BIOL, V18, P621, DOI 10.1111/j.1523-1739.2004.00077.x
   Besner MC, 2011, WATER RES, V45, P961, DOI 10.1016/j.watres.2010.10.035
   Blackstock KL, 2010, SCI TOTAL ENVIRON, V408, P5631, DOI 10.1016/j.scitotenv.2009.04.029
   Borisova T, 2012, J AM WATER RESOUR AS, V48, P277, DOI 10.1111/j.1752-1688.2011.00615.x
   Bruns A, 2012, INFORM COMMUN SOC, V15, P1323, DOI 10.1080/1369118X.2011.635214
   Cascetta E, 2015, TRANSPORT POLICY, V38, P27, DOI 10.1016/j.tranpol.2014.11.005
   CASIANOFLORES C, 2016, WATER, V8, P0, DOI 10.HTTPS://D0I.0RG/10.3390/W8050210
   Chopin P, 2019, RENEW ENERG, V131, P128, DOI 10.1016/j.renene.2018.06.031
   Cumming GS, 2005, ECOSYSTEMS, V8, P143, DOI 10.1007/s10021-004-0075-1
   Dadaser F., 2002, EPMR2002 ENV PROBLEM, V0, P0
   Dadaser F., 2001, P 4 NAT ENV ENG C ME, V0, P25
   Daly ER, 2010, EPIDEMIOL INFECT, V138, P491, DOI 10.1017/S0950268809990744
   Darke P., 1996, REQUIREMENTS ENGINEERING, V1, P88, DOI 10.1007/BF01235904
   Eliasson J, 2015, NATURE, V517, P6, DOI 10.1038/517006a
   Fenton O, 2017, AGR ECOSYST ENVIRON, V239, P246, DOI 10.1016/j.agee.2017.01.014
   Foster N, 2016, WATER-SUI, V8, P0, DOI 10.3390/w8110540
   Gray S, 2012, ECOL MODEL, V229, P88, DOI 10.1016/j.ecolmodel.2011.09.011
   GREGORY R, 1994, MANAGE SCI, V40, P1035, DOI 10.1287/mnsc.40.8.1035
   Groumpus G., 2017, INT J ROBOT AUTOM, V1, P0, DOI 10.19080/RAEJ.2017.01.555563
   Gundry S.W., 2006, J WATER PRACTICE TEC, V1, P2, DOI 10.2166/WPT.2006032
   Harary F., 1965, STRUCTURAL MODELS IN, V0, P0
   Harisha RS, 2010, DESALINATION, V252, P75, DOI 10.1016/j.desal.2009.10.022
   Heymann S., 2013, 17 INT C INF VIS LON, V0, P0, DOI DOI 10.1109/IV.2013.39.
   Hjortso CN, 2004, EUR J OPER RES, V152, P667, DOI 10.1016/S0377-2217(03)00065-1
   Hyland JJ, 2018, LAND USE POLICY, V78, P562, DOI 10.1016/j.landusepol.2018.07.006
   Hyland JJ, 2018, AGR SYST, V162, P97, DOI 10.1016/j.agsy.2018.01.023
   Jacomy M, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0098679
   Jaramillo Marcela, 2019, CURRENT OPINION IN ENVIRONMENTAL SCIENCE & HEALTH, V7, P45, DOI 10.1016/j.coesh.2018.10.003
   Jetter AJ, 2014, FUTURES, V61, P45, DOI 10.1016/j.futures.2014.05.002
   Jimenez A, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12030827
   Juntunen JK, 2019, J PROD INNOVAT MANAG, V36, P331, DOI 10.1111/jpim.12481
   Kafetzis A., 2010, USING FUZZY COGNITIV, V0, P2
   Khan K, 2018, J ENVIRON SCI-CHINA, V72, P1, DOI 10.1016/j.jes.2017.12.008
   Kirchhoff Christine J., 2016, WATER RESOURCES RESEARCH, V52, P2951, DOI 10.1002/2015WR018431
   Kok K, 2009, GLOBAL ENVIRON CHANG, V19, P122, DOI 10.1016/j.gloenvcha.2008.08.003
   Kontogianni AD, 2012, APPL SOFT COMPUT, V12, P3725, DOI 10.1016/j.asoc.2012.05.003
   Kosko B., 1987, IEEE FIRST INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, V0, P261
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kubanza NS, 2018, LOCAL ENVIRON, V23, P220, DOI 10.1080/13549839.2017.1399996
   Lai WWP, 2018, WATER AIR SOIL POLL, V229, P0, DOI 10.1007/s11270-018-3901-3
   LOU Y, 2014, SCI TOTAL ENVIRON, V473, P619, DOI 10.1016/J.SCIT0TENV.2013.12.065
   Lynam T, 2007, ECOL SOC, V12, P0
   Lyon W., 2010, DISC WAT GOV 5 WORLD, V0, P0, DOI DOI 10.1109/IV.2013.39
   Machado KC, 2016, SCI TOTAL ENVIRON, V572, P138, DOI 10.1016/j.scitotenv.2016.07.210
   Martin EG, 2020, SCI TOTAL ENVIRON, V738, P0, DOI 10.1016/j.scitotenv.2020.139693
   McGrory ER, 2017, SCI TOTAL ENVIRON, V579, P1863, DOI 10.1016/j.scitotenv.2016.11.171
   Micha E, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12072578
   MILLER KA, 2011, ENV ENERGY LAW POLIC, V5, P395
   Morton P.A., 2019, WILEY WIRES WATER, V0, P1
   Naidu R, 2016, CHEMOSPHERE, V154, P350, DOI 10.1016/j.chemosphere.2016.03.068
   Nelson R, 2008, ENVIRON SCI POLICY, V11, P588, DOI 10.1016/j.envsci.2008.06.005
   Okumah M, 2020, J ENVIRON PLANN MAN, V63, P1375, DOI 10.1080/09640568.2019.1663724
   Ozesmi U, 2004, ECOL MODEL, V176, P43, DOI 10.1016/j.ecolmodel.2003.10.027
   Ozesmi U, 2003, ENVIRON MANAGE, V31, P518, DOI 10.1007/s00267-002-2841-1
   Ozesmi U., 1999, 1999 WORLD C NAT RES, V0, P0
   Panikkar B, 2019, ENVIRON HEALTH-GLOB, V18, P0, DOI 10.1186/s12940-019-0513-3
   Papageorgiou E, 2011, INTERNATIONAL PERSPECTIVES ON GLOBAL ENVIRONMENTAL CHANGE, V0, P427
   Puccia C.J., 1983, DEVELOPMENTS IN ENVIRONMENTAL MODELLING, V5, P719
   Dahik CQ, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10061707
   Radomski PJ, 1996, FISHERIES, V21, P14, DOI 10.1577/1548-8446(1996)021<0014:DMAMIF>2.0.CO;2
   Reimann S, 1998, NEURAL NETWORKS, V11, P611, DOI 10.1016/S0893-6080(98)00001-X
   Rufener S, 2010, J HEALTH POPUL NUTR, V28, P34, DOI 10.3329/jhpn.v28i1.4521
   Sandell K., 1996, APPROACHING NATURE FROM LOCAL COMMUNITIES: SECURITY PERCEIVED AND ACHIEVED., V0, P163
   Schmoll O., 2006, PROTECTING GROUNDWAT, V0, P0
   Schutz KE, 2019, APPL ANIM BEHAV SCI, V217, P16, DOI 10.1016/j.applanim.2019.05.005
   Suprun E, 2018, SYSTEMS, V6, P0, DOI 10.3390/systems6030033
   Ulrich W, 2010, SYSTEMS APPROACHES TO MANAGING CHANGE: A PRACTICAL GUIDE, V0, PP243, DOI 10.1007/978-1-84882-809-4_6
   Voinov A, 2016, ENVIRON MODELL SOFTW, V77, P196, DOI 10.1016/j.envsoft.2015.11.016
   Voinov A, 2010, ENVIRON MODELL SOFTW, V25, P1268, DOI 10.1016/j.envsoft.2010.03.007
   Wiek A, 2012, WATER RESOUR MANAG, V26, P3153, DOI 10.1007/s11269-012-0065-6
   Yalcin N., 2001, THESIS, V0, P0
NR 78
TC 11
Z9 11
U1 3
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0048-9697
EI 1879-1026
J9 SCI TOTAL ENVIRON
JI Sci. Total Environ.
PD JAN 1
PY 2021
VL 750
IS 
BP 
EP 
DI 10.1016/j.scitotenv.2020.142193
PG 14
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA OM0BS
UT WOS:000585694600118
PM 33182184
DA 2023-04-26
ER

PT J
AU Zhao, ZY
   Yang, Q
   Ding, XG
   Xing, ZS
AF Zhao, Zhengyong
   Yang, Qi
   Ding, Xiaogang
   Xing, Zisheng
TI Model Prediction of the Soil Moisture Regime and Soil Nutrient Regime Based on DEM-Derived Topo-Hydrologic Variables for Mapping Ecosites
SO LAND
LA English
DT Article
DE soil moisture regime; ecosite; edatopic grid; artificial neural network
ID artificial neural-network; texture distributions; nova-scotia; forest; classification; vegetation; province; canada; maps; area
AB Ecosites are required for stand-level forest management and can be determined within a two-dimensional edatopic grid with soil nutrient regimes (SNRs) and soil moisture regimes (SMRs) as coordinates. A new modeling method is introduced in this study to map high-resolution SNR and SMR and then to design ecosites in Nova Scotia, Canada. Using coarse-resolution soil maps and nine topo-hydrologic variables derived from high-resolution digital elevation model (DEM) data as model inputs, 511 artificial neural network (ANN) models were developed by a 10-fold cross-validation with 1507 field samples to estimate 10 m resolution SNR and SMR maps. The results showed that the optimal models for mapping SNR and SMR engaged eight and seven topo-hydrologic variables, together with three coarse-resolution soil maps, as model inputs, respectively; 82% of model-estimated SNRs were identical to field assessments, while this value was 61% for SMRs, and the produced ecosite maps had 67-68% correctness. According to the error matrix, the predicted SNR and SMR maps greatly alleviated poor prediction in the areas of extreme nutrient or moisture conditions (e.g., very poor or very rich, wet, or very dry). Thus, the new method for modeling high-resolution SNR and SMR could be used to produce ecosite maps in sites where accessibility is hard.
C1 [Zhao, Zhengyong; Yang, Qi] Guangxi Univ, Coll Forestry, Guangxi Key Lab Forest Ecol & Conservat, Nanning 530004, Peoples R China.
   [Zhao, Zhengyong] Univ British Columbia, Fac Forestry, Vancouver, BC V6T 1Z4, Canada.
   [Ding, Xiaogang] Guangdong Acad Forestry, Guangzhou 510520, Peoples R China.
   [Xing, Zisheng] Brandon Res & Dev Ctr, Portage, MB R1N 3V6, Canada.
C3 Guangxi University; University of British Columbia
RP Ding, XG (corresponding author), Guangdong Acad Forestry, Guangzhou 510520, Peoples R China.
EM u1v54@unb.ca; qi66yang@yahoo.ca; 27267152@sinogaf.cn; zisheng.xing@canada.ca
FU Guangxi Natural Science Foundation of China [2018GXNSFAA050135, 2018GXNSFBA138035]; Guangdong Forestry Science and Technology Plan of China [2019-07]
CR Akumu CE, 2019, GEODERMA, V351, P25, DOI 10.1016/j.geoderma.2019.05.014
   Arp P.A., 2005, SOILS PLANT GROWTH F, V0, P21
   Beucher A, 2019, GEODERMA, V352, P351, DOI 10.1016/j.geoderma.2017.11.004
   Brady N.C., 2008, NATURE PROPERTIES SO, V14th, P134
   Bulut B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161875
   Ding XG, 2020, COMPUT ELECTRON AGR, V169, P0, DOI 10.1016/j.compag.2020.105217
   Emadi M, 2016, ARCH AGRON SOIL SCI, V62, P502, DOI 10.1080/03650340.2015.1065607
   Hateffard F, 2019, J MT SCI-ENGL, V16, P1833, DOI 10.1007/s11629-019-5409-8
   Keys K., 2007, FIELD MANUAL FOREST, V0, P112
   Keys K., 2011, 20112 FOR NOV SCOT D, V0, P15
   Li Q, 2018, HYDROL EARTH SYST SC, V22, P1947, DOI 10.5194/hess-22-1947-2018
   Li ZY, 1998, J INFRARED MILLIM W, V17, P153
   Lopez C., 1999, P INT JOINT C NEUR N, V0, P1185
   MacMillan RA, 2007, GEODERMA, V140, P353, DOI 10.1016/j.geoderma.2007.04.027
   McLaughlan M.S., 2010, FIELD GUIDE ECOSITES, V0, P34
   Montigny MK, 2005, BIOL CONSERV, V125, P237, DOI 10.1016/j.biocon.2005.03.028
   Neily P., 2003, 20032 DNR NOV SCOT D, V0, P1
   New Brunswick Department of Natural Resources (NBDNR), 2007, OUR LANDSCAPE HERITA, V0, P10
   Pyo J, 2020, SCI TOTAL ENVIRON, V741, P0, DOI 10.1016/j.scitotenv.2020.140162
   Sigillito V.G., 1990, NEURAL NETWORK PC TO, V0, P96
   SIMS RA, 1992, FOREST CHRON, V68, P64, DOI 10.5558/tfc68064-1
   Taylor K.C., 2000, FIELD GUIDE FOREST E, V2nd, P68
   Wang GG, 2000, FOREST ECOL MANAG, V129, P93, DOI 10.1016/S0378-1127(99)00142-5
   Yang Q, 2017, SCI REP-UK, V7, P0, DOI 10.1038/s41598-017-11381-z
   Zhao Z., 2018, ADV APPL ARTIFICIAL, V0, P51
   Zhao ZY, 2020, COMPUT ELECTRON AGR, V169, P0, DOI 10.1016/j.compag.2019.105172
   Zhao ZY, 2013, CAN J SOIL SCI, V93, P329, DOI 10.4141/cjss2012-079
   Zhao ZY, 2013, CAN J SOIL SCI, V93, P193, DOI 10.4141/CJSS2012-016
   Zhao ZY, 2013, CAN J SOIL SCI, V93, P73, DOI 10.4141/cjss2011-095
   Zhao ZY, 2010, CAN J SOIL SCI, V90, P75, DOI 10.4141/CJSS08057
   Zhao ZY, 2009, COMPUT ELECTRON AGR, V65, P36, DOI 10.1016/j.compag.2008.07.008
NR 32
TC 0
Z9 0
U1 3
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2073-445X
J9 LAND-BASEL
JI Land
PD MAY 15
PY 2021
VL 10
IS 5
BP 
EP 
DI 10.3390/land10050449
PG 12
WC Environmental Studies
SC Environmental Sciences & Ecology
GA SH5AB
UT WOS:000654146900001
DA 2023-04-26
ER

PT J
AU Aslam, B
   Maqsoom, A
   Khalid, N
   Ullah, F
   Sepasgozar, S
AF Aslam, Bilal
   Maqsoom, Ahsen
   Khalid, Nauman
   Ullah, Fahim
   Sepasgozar, Samad
TI Urban Overheating Assessment through Prediction of Surface Temperatures: A Case Study of Karachi, Pakistan
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE urban overheating; land surface temperature; China Pakistan Economic Corridor; Karachi city; long short-term memory; artificial neural network; urban heat island
ID heat-island; land-surface; neural-network; impervious surface; multisensor data; satellite data; indicators; ecology; pattern; impact
AB Global climate has been radically affected by the urbanization process in recent years. Karachi, Pakistan's economic hub, is also showing signs of swift urbanization. Owing to the construction of infrastructure projects under the China-Pakistan Economic Corridor (CPEC) and associated urbanization, Karachi's climate has been significantly affected. The associated replacement of natural surfaces by anthropogenic materials results in urban overheating and increased local temperatures leading to serious health issues and higher air pollution. Thus, these temperature changes and urban overheating effects must be addressed to minimize their impact on the city's population. For analyzing the urban overheating of Karachi city, LST (land surface temperature) is assessed in the current study, where data of the past 20 years (2000-2020) is used. For this purpose, remote sensing data from the Advanced Spaceborne Thermal Emission and Reflection Radiometer Global Digital Elevation Model (ASTER GDEM) and Moderate-Resolution Imaging Spectroradiometer (MODIS) sensors were utilized. The long short-term memory (LSTM) model was utilized where the road density (RD), elevation, and enhanced vegetation index (EVI) are used as input parameters. Upon comparing estimated and measured LST, the values of mean absolute error (MAE), mean square error (MSE), and mean absolute percentage error (MAPE) are 0.27 K, 0.237, and 0.15% for January, and 0.29 K, 0.261, and 0.13% for May, respectively. The low MAE, MSE, and MAPE values show a higher correlation between the predicted and observed LST values. Moreover, results show that more than 90% of the pixel data falls in the least possible error range of -1 K to +1 K. The MAE, MSE and MAPE values for Support Vector Regression (SVR) are 0.52 K, 0.453 and 0.18% and 0.76 K, 0.873, and 0.26%. The current model outperforms previous studies, shows a higher accuracy, and depicts greater reliability to predict the actual scenario. In the future, based on the accurate LST results from this model, city planners can propose mitigation strategies to reduce the harmful effects of urban overheating and associated Urban Heat Island effects (UHI).
C1 [Aslam, Bilal] Quaid I Azam Univ, Dept Earth Sci, Islamabad 45320, Pakistan.
   [Maqsoom, Ahsen; Khalid, Nauman] COMSATS Univ Islamabad, Dept Civil Engn, Wah Cantt 47040, Pakistan.
   [Ullah, Fahim] Univ Southern Queensland, Sch Civil Engn & Surveying, Ipswich, Qld 4300, Australia.
   [Sepasgozar, Samad] Univ New South Wales, Sch Built Environm, Sydney, NSW 2052, Australia.
C3 Quaid I Azam University; COMSATS University Islamabad (CUI); University of Southern Queensland; University of New South Wales Sydney
RP Ullah, F (corresponding author), Univ Southern Queensland, Sch Civil Engn & Surveying, Ipswich, Qld 4300, Australia.
EM 31520@student.riphah.edu.pk; ahsen.maqsoom@ciitwah.edu.pk; fa17-cve-048@cuiwah.edu.pk; fahim.ullah@usq.edu.au; sepas@unsw.edu.au
CR Abdulla-Al Kafy, 2021, SUSTAIN CITIES SOC, V64, P0, DOI 10.1016/j.scs.2020.102542
   Akbari H., 2005, ENERGY SAVING POTENT, V0, P0
   Alam K, 2011, ATMOS RES, V101, P773, DOI 10.1016/j.atmosres.2011.05.007
   Arshad A, 2020, INT J DISAST RISK RE, V46, P0, DOI 10.1016/j.ijdrr.2019.101468
   Ashtiani A, 2014, ENERG BUILDINGS, V76, P597, DOI 10.1016/j.enbuild.2014.03.018
   Aslam B, 2020, ARAB J GEOSCI, V13, P0, DOI 10.1007/s12517-020-05916-4
   Atif S, 2021, NAT HAZARDS, V108, P2357, DOI 10.1007/s11069-021-04783-w
   Battista G, 2019, SOL ENERGY, V180, P608, DOI 10.1016/j.solener.2019.01.074
   Bhattacharya BK, 2010, J HYDROL, V387, P65, DOI 10.1016/j.jhydrol.2010.03.030
   Cao J, 2021, LANDSCAPE URBAN PLAN, V215, P0, DOI 10.1016/j.landurbplan.2021.104210
   Cheval S, 2009, THEOR APPL CLIMATOL, V96, P145, DOI 10.1007/s00704-008-0019-3
   Dissanayake D, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11082257
   Dousset B, 2003, ISPRS J PHOTOGRAMM, V58, P43, DOI 10.1016/S0924-2716(03)00016-9
   Estoque RC, 2017, ISPRS J PHOTOGRAMM, V133, P18, DOI 10.1016/j.isprsjprs.2017.09.008
   Estoque RC, 2017, SCI TOTAL ENVIRON, V577, P349, DOI 10.1016/j.scitotenv.2016.10.195
   de Macedo MMG, 2020, IEEE J-STARS, V13, P1134, DOI 10.1109/JSTARS.2020.2973602
   Ge X, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9100593
   Ghumman U, 2016, PREHOSP DISASTER MED, V31, P263, DOI 10.1017/S1049023X16000273
   Goward SN, 2002, REMOTE SENS ENVIRON, V79, P225, DOI 10.1016/S0034-4257(01)00275-9
   Gray K.A., 2000, URBAN HEAT ISLAND PH, V0, P0
   Grimm NB, 2008, SCIENCE, V319, P756, DOI 10.1126/science.1150195
   Gui X, 2019, ENVIRON SCI POLLUT R, V26, P30808, DOI 10.1007/s11356-019-06273-w
   Hanif U., 2017, PAK J METEOROL, V13, P87
   Hart M, 2009, THEOR APPL CLIMATOL, V95, P397, DOI 10.1007/s00704-008-0017-5
   Huete A., 1999, MODIS VEGETATION IND, V1200, P0
   Hung T, 2006, INT J APPL EARTH OBS, V8, P34, DOI 10.1016/j.jag.2005.05.003
   Jiang ZY, 2006, GEO-SPAT INF SCI, V9, P293, DOI 10.1007/BF02826743
   Jing R, 2020, INT J REMOTE SENS, V41, P6209, DOI 10.1080/01431161.2020.1734253
   Jusuf SK, 2007, HABITAT INT, V31, P232, DOI 10.1016/j.habitatint.2007.02.006
   Khandelwal S, 1900, P177, V0, P0
   Khandelwal S, 2018, EGYPT J REMOTE SENS, V21, P87, DOI 10.1016/j.ejrs.2017.01.005
   Lakshmi V, 2011, HYDROL RES, V42, P95, DOI 10.2166/nh.2011.071
   Landsberg H., 1981, URBAN CLIM, V0, P0
   Li XM, 2020, J COASTAL RES, V0, PP21, DOI 10.2112/SI102-003.1
   Liang BQ, 2008, J URBAN PLAN DEV, V134, P129, DOI 10.1061/(ASCE)0733-9488(2008)134:3(129)
   Lin PY, 2017, LANDSCAPE URBAN PLAN, V168, P48, DOI 10.1016/j.landurbplan.2017.09.024
   Liu W, 2007, THEOR APPL CLIMATOL, V87, P213, DOI 10.1007/s00704-005-0192-6
   Ma XL, 2015, TRANSPORT RES C-EMER, V54, P187, DOI 10.1016/j.trc.2015.03.014
   Mathew A, 2019, SOL ENERGY, V186, P404, DOI 10.1016/j.solener.2019.04.001
   Mathew A, 2018, SUSTAIN CITIES SOC, V40, P484, DOI 10.1016/j.scs.2018.04.018
   Mathew A, 2018, ENERG BUILDINGS, V159, P271, DOI 10.1016/j.enbuild.2017.10.062
   Mathew A, 2016, ENERG BUILDINGS, V128, P605, DOI 10.1016/j.enbuild.2016.07.004
   Memon RA, 2009, ATMOS RES, V94, P491, DOI 10.1016/j.atmosres.2009.07.006
   Mirzaei PA, 2010, BUILD ENVIRON, V45, P1582, DOI 10.1016/j.buildenv.2010.01.001
   Monteiro FF, 2021, URBAN CLIM, V35, P0, DOI 10.1016/j.uclim.2020.100726
   Munawar HS, 2021, FIRE-BASEL, V4, P0, DOI 10.3390/fire4030040
   Munawar HS, 2021, SUSTAINABILITY-BASEL, V13, P0, DOI 10.3390/su13147547
   Myint SW, 2010, GISCI REMOTE SENS, V47, P301, DOI 10.2747/1548-1603.47.3.301
   Nasim W, 2018, ATMOS RES, V205, P118, DOI 10.1016/j.atmosres.2018.01.009
   Nurwanda A, 2020, SUSTAIN CITIES SOC, V52, P0, DOI 10.1016/j.scs.2019.101772
   Parida BR, 2008, INT J REMOTE SENS, V29, P4219, DOI 10.1080/01431160701871096
   Priyankara P, 2019, CLIMATE, V7, P0, DOI 10.3390/cli7090110
   Pu RL, 2006, REMOTE SENS ENVIRON, V104, P211, DOI 10.1016/j.rse.2005.09.022
   Qadir Z, 2021, COMPUT COMMUN, V168, P114, DOI 10.1016/j.comcom.2021.01.003
   Ranagalage M, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9070461
   Ranagalage M, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7090341
   Raza D, 2019, J GEOGR NAT DISAST, V9, P1000237
   Salim A, 2015, INT J OCCUP ENV MED, V6, P249, DOI 10.15171/ijoem.2015.678
   Santarnouris M, 2015, ENERG BUILDINGS, V98, P125, DOI 10.1016/j.enbuild.2014.08.050
   Sarif MO, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9120726
   Sarrat C, 2006, ATMOS ENVIRON, V40, P1743, DOI 10.1016/j.atmosenv.2005.11.037
   Simwanda M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141645
   Streutker DR, 2002, INT J REMOTE SENS, V23, P2595, DOI 10.1080/01431160110115023
   Taha H, 1997, ENERG BUILDINGS, V25, P99, DOI 10.1016/S0378-7788(96)00999-1
   Tan Z, 2016, ENERG BUILDINGS, V114, P265, DOI 10.1016/j.enbuild.2015.06.031
   Teferi E, 2017, CLIM CHANG MANAG, V0, PP539, DOI 10.1007/978-3-319-49520-0_33
   Tiangco M, 2008, INT J REMOTE SENS, V29, P2799, DOI 10.1080/01431160701408360
   Ullah F, 2021, TECHNOL FORECAST SOC, V167, P0, DOI 10.1016/j.techfore.2021.120743
   Ullah F, 2021, INT J INTELL SYST, V36, P3429, DOI 10.1002/int.22422
   Voogt JA, 2003, REMOTE SENS ENVIRON, V86, P370, DOI 10.1016/S0034-4257(03)00079-8
   Wang Y., 2020, IEEE T SYST MAN CY-S, V0, PP1, DOI 10.1109/TSMC.2020.3020562
   Wang ZQ, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10030193
   Weng QH, 2004, REMOTE SENS ENVIRON, V89, P467, DOI 10.1016/j.rse.2003.11.005
   Wong MS, 2010, BUILD ENVIRON, V45, P1880, DOI 10.1016/j.buildenv.2010.02.019
   Xiao RB, 2007, J ENVIRON SCI-CHINA, V19, P250, DOI 10.1016/S1001-0742(07)60041-2
   Yang S, 1989, J S CHINA NORM U, V1, P41
   Yang YB, 2019, FORESTS, V10, P0, DOI 10.3390/f10010058
   Yuan F, 2007, REMOTE SENS ENVIRON, V106, P375, DOI 10.1016/j.rse.2006.09.003
   Zhang KX, 2010, ENVIRON MONIT ASSESS, V169, P101, DOI 10.1007/s10661-009-1154-8
   Zhang X, 2009, INT J REMOTE SENS, V30, P2105, DOI 10.1080/01431160802549252
NR 81
TC 18
Z9 18
U1 10
U2 31
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD AUG 15
PY 2021
VL 10
IS 8
BP 
EP 
DI 10.3390/ijgi10080539
PG 21
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA UG3TX
UT WOS:000689180300001
DA 2023-04-26
ER

PT J
AU Albu, AB
   Nagy, G
AF Albu, Alexandra Branzan
   Nagy, George
TI Imaging Reality and Abstraction an Exploration of Natural and Symbolic Patterns
SO VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 4: VISAPP
LA English
DT Proceedings Paper
DE Physical Scenes; Symbols; Perception; Cognition
AB Understanding visual symbols is a strictly human skill, as opposed to comprehending natural scenes-which is an essential survival skill, common to many species. As an illustration of the natural vs. symbolic dichotomy, selective features are computed for differentiating a satellite photograph from a map of the same geographical region. Images of physical scenes /objects are currently captured in all parts of the electromagnetic spectrum. Symbols, whether produced by man or machine, are almost always imaged in the visible range. Although natural and symbolic images differ in many ways, there is no universal set of differentiating characteristics. With respect to the traditional branches of pattern recognition, it is tempting to suggest that statistical, neural network and genetic/evolutionary pattern recognition methods are eminently suitable for images of scenes and simple symbols, whereas structural and syntactic approaches are best for more complex, composite graphical symbols.
C1 [Albu, Alexandra Branzan] Univ Victoria, Elect & Comp Engn, Victoria, BC, Canada.
   [Nagy, George] Rensselaer Polytech Inst, Elect Comp & Syst Engn, Troy, NY USA.
C3 University of Victoria; Rensselaer Polytechnic Institute
RP Albu, AB (corresponding author), Univ Victoria, Elect & Comp Engn, Victoria, BC, Canada.
CR Al-Muhammed M.M.J., 2018, INT J INFORM TECHNOL, V8, P2598
   ALVAREZ LW, 1970, SCIENCE, V167, P832, DOI 10.1126/science.167.3919.832
   Ammonius S.M., 1991, ARISTOTLE CATEGORIES, V0, P0
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   [Anonymous], 2006, MACH LEARN, V0, P0
   Battaglia P. W, 2018, ARXIV180601261V3, V0, P0
   Bellman R. E., 1961, ADAPTIVE CONTROL PRO, V0, P0, DOI DOI 10.1515/9781400874668
   Bunke H, 2012, PATTERN RECOGN LETT, V33, P811, DOI 10.1016/j.patrec.2011.04.017
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Del Viva M., 2013, PLOS ONE, V8, P7
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   FU KS, 1982, SYNTACTIC PATTERN RE, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Hjort N. L., 1995, PATTERN RECOGN, V1st, P0
   Landis EN, 2007, MATER STRUCT, V40, P357, DOI 10.1617/s11527-006-9145-5
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Linkeos Technology Ltd, 2020, COSM RAY MUOGR, V0, P0
   Llados J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS
   Mattson MP, 2014, FRONT NEUROSCI-SWITZ, V8, P0, DOI 10.3389/fnins.2014.00265
   Mulligan J, 2009, MATH EDUC RES J, V21, P33, DOI 10.1007/BF03217544
   Nagy G, 2016, PATTERN RECOGN LETT, V79, P106, DOI 10.1016/j.patrec.2015.11.024
   Nayef N, 2019, ARXIV190700945CSCV I, V0, P0
   OGorman L, 1988, P IEEE INT C AC SPEE, V0, P0
   Redmond E, 2020, PLACES CIVIL WAR HIS, V0, P0
   Renton G., 2009, P INT C DOC AN REC W, V1, P62
   Rezvanifar Alireza, 2019, IPSJ TRANSACTIONS ON COMPUTER VISION AND APPLICATIONS, V11, P0, DOI 10.1186/s41074-019-0055-1
   Rosten E, 2005, IEEE I CONF COMP VIS, V0, P1508
   Searls D.B., 1982, STRUCTURED DOCUMENT, V0, P0
   Stokes D., 2014, DOMINANCE VISUAL, V0, P0
   Warren E., 2005, P 29 TH C INT GROUP, V4, P305
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 415
EP 422
DI 10.5220/0010295704150422
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology
SC Computer Science; Imaging Science & Photographic Technology
GA BR7NM
UT WOS:000668577400044
DA 2023-04-26
ER

PT J
AU Jiang, X
   Liang, SJ
   He, XY
   Ziegler, AD
   Lin, PR
   Pan, M
   Wang, DS
   Zou, JY
   Hao, DL
   Mao, GQ
   Zeng, YL
   Yin, J
   Feng, L
   Miao, CY
   Wood, EF
   Zeng, ZZ
AF Jiang, Xin
   Liang, Shijing
   He, Xinyue
   Ziegler, Alan D.
   Lin, Peirong
   Pan, Ming
   Wang, Dashan
   Zou, Junyu
   Hao, Dalei
   Mao, Ganquan
   Zeng, Yelu
   Yin, Jie
   Feng, Lian
   Miao, Chiyuan
   Wood, Eric F.
   Zeng, Zhenzhong
TI Rapid and large-scale mapping of flood inundation via integrating spaceborne synthetic aperture radar imagery with unsupervised deep learning
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Flood inundation; Sentinel-1; Unsupervised machine learning; Google Earth Engine; Disaster assessment
ID multitemporal sar data; sentinel-1; segmentation; modis; classification; wetland; extraction; vegetation; expansion; dynamics
AB Synthetic aperture radar (SAR) has great potential for timely monitoring of flood information as it penetrates the clouds during flood events. Moreover, the proliferation of SAR satellites with high spatial and temporal resolution provides a tremendous opportunity to understand the flood risk and its quick response. However, traditional algorithms to extract flood inundation using SAR often require manual parameter tuning or data annotation, which presents a challenge for the rapid automated mapping of large and complex flooded scenarios. To address this issue, we proposed a segmentation algorithm for automatic flood mapping in near-real-time over vast areas and for all-weather conditions by integrating Sentinel-1 SAR imagery with an unsupervised machine learning approach named Felz-CNN. The algorithm consists of three phases: (i) super-pixel generation; (ii) convolutional neural network-based featurization; (iii) super-pixel aggregation. We evaluated the Felz-CNN algorithm by mapping flood inundation during the Yangtze River flood in 2020, covering a total study area of 1,140,300 km(2). When validated on fine-resolution Planet satellite imagery, the algorithm accurately identified flood extent with producer and user accuracy of 93% and 94%, respectively. The results are indicative of the usefulness of our unsupervised approach for the application of flood mapping. Meanwhile, we overlapped the post-disaster inundation map with a 10-m resolution global land cover map (FROM-GLC10) to assess the damages to different land cover types. Of these types, cropland and residential settlements were most severely affected, with inundation areas of 9,430.36 km(2) and 1,397.50 km(2), respectively, results that are in agreement with statistics from relevant agencies. Compared with traditional supervised classification algorithms that require time-consuming data annotation, our unsupervised algorithm can be deployed directly to high-performance computing platforms such as Google Earth Engine and PIE-Engine to generate a large-spatial map of flood-affected areas within minutes, without time-consuming data downloading and processing. Importantly, this efficiency enables the fast and effective monitoring of flood conditions to aid in disaster governance and mitigation globally.
C1 [Jiang, Xin; Liang, Shijing; He, Xinyue; Wang, Dashan; Zou, Junyu; Mao, Ganquan; Feng, Lian; Zeng, Zhenzhong] Southern Univ Sci & Technol, Sch Environm Sci & Engn, Shenzhen 518055, Peoples R China.
   [Ziegler, Alan D.] Mae Jo Univ, Fac Fisheries Technol & Aquat Resources, Chiang Mai, Thailand.
   [Lin, Peirong; Pan, Ming; Wood, Eric F.] Princeton Univ, Dept Civil & Environm Engn, Princeton, NJ 08544 USA.
   [Lin, Peirong] Peking Univ, Inst Remote Sensing & GIS, Beijing 100871, Peoples R China.
   [Hao, Dalei; Zeng, Yelu] Pacific Northwest Natl Lab, Joint Global Change Res Inst, College Pk, MD USA.
   [Yin, Jie] East China Normal Univ, Minist Educ, Key Lab Geog Informat Sci, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China.
   [Miao, Chiyuan] Beijing Normal Univ, Fac Geog Sci, State Key Lab Earth Surface Proc & Resource Ecol, Beijing 100875, Peoples R China.
C3 Southern University of Science & Technology; Maejo University; Princeton University; Peking University; United States Department of Energy (DOE); Pacific Northwest National Laboratory; East China Normal University; Beijing Normal University
RP Zeng, ZZ (corresponding author), Southern Univ Sci & Technol, Sch Environm Sci & Engn, Shenzhen 518055, Peoples R China.; Zeng, ZZ (corresponding author), Southern Univ Sci & Technol, Coll Engn, North 808, Shenzhen 518055, Peoples R China.
EM zengzz@sustech.edu.cn
FU National Natural Science Foundation of China [42071022]; Southern University of Science and Technology [29/Y01296122]
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akbarizadeh G, 2012, IEEE T GEOSCI REMOTE, V50, P4358, DOI 10.1109/TGRS.2012.2194787
   Amitrano D, 2018, IEEE T GEOSCI REMOTE, V56, P3290, DOI 10.1109/TGRS.2018.2797536
   Atkinson P.M, 1900, V173, V0, P79
   Beaton A, 2019, REMOTE SENS ENVIRON, V224, P352, DOI 10.1016/j.rse.2019.02.011
   Benoudjit A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070779
   Benz UC, 1999, IEEE T GEOSCI REMOTE, V37, P1023, DOI 10.1109/36.752221
   Boni G, 2016, IEEE J-STARS, V9, P2794, DOI 10.1109/JSTARS.2016.2514402
   Chen B, 2018, ISPRS J PHOTOGRAMM, V139, P75, DOI 10.1016/j.isprsjprs.2018.02.021
   Chini M, 2017, IEEE T GEOSCI REMOTE, V55, P6975, DOI 10.1109/TGRS.2017.2737664
   Cian F, 2019, GEOSCIENCES, V9, P0, DOI 10.3390/geosciences9030124
   Clausi DA, 2004, IEEE T GEOSCI REMOTE, V42, P215, DOI 10.1109/TGRS.2003.817218
   CLEMENT MA, 2018, J FLOOD RISK MANAG, V11, P152, DOI 10.1111/JFR3.12303
   Clementson LA, 2021, FRONT MAR SCI, V8, P0, DOI 10.3389/fmars.2021.580516
   DeVries B, 2020, REMOTE SENS ENVIRON, V240, P0, DOI 10.1016/j.rse.2020.111664
   Dong JH, 2019, IEEE I CONF COMP VIS, V0, PP10711, DOI 10.1109/ICCV.2019.01081
   El Zaart A, 2002, PATTERN RECOGN, V35, P713, DOI 10.1016/S0031-3203(01)00070-X
   Ettritch G, 2018, REMOTE SENS ENVIRON, V217, P506, DOI 10.1016/j.rse.2018.08.029
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Filipponi F., 2019, PROCEEDINGS, V18, P11, DOI 10.3390/ECRS-3-06201
   Flores A., 2019, SYNTHETIC APERTURE R, V0, P0, DOI DOI 10.25966/nr2c-s697
   Fu BL, 2017, ECOL INDIC, V73, P105, DOI 10.1016/j.ecolind.2016.09.029
   Galford GL, 2008, REMOTE SENS ENVIRON, V112, P576, DOI 10.1016/j.rse.2007.05.017
   Gamba P, 2006, IEEE T GEOSCI REMOTE, V44, P2820, DOI 10.1109/TGRS.2006.879498
   Giustarini L, 2011, HYDROL EARTH SYST SC, V15, P2349, DOI 10.5194/hess-15-2349-2011
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Glorot X., 2010, P 13 INT C ART INT S, V0, P249
   Gong P, 2019, SCI BULL, V64, P370, DOI 10.1016/j.scib.2019.03.002
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Henry JB, 2006, INT J REMOTE SENS, V27, P1921, DOI 10.1080/01431160500486724
   Hosseini FS, 2020, SCI TOTAL ENVIRON, V711, P0, DOI 10.1016/j.scitotenv.2019.135161
   Huang C, 2018, REV GEOPHYS, V56, P333, DOI 10.1029/2018RG000598
   Kalyanapu AJ, 2012, J FLOOD RISK MANAG, V5, P37, DOI 10.1111/j.1753-318X.2011.01123.x
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P1543
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LEE JS, 1989, IEEE T GEOSCI REMOTE, V27, P674, DOI 10.1109/36.35954
   Li Y, 2019, ISPRS J PHOTOGRAMM, V152, P178, DOI 10.1016/j.isprsjprs.2019.04.014
   Liang JY, 2020, ISPRS J PHOTOGRAMM, V159, P53, DOI 10.1016/j.isprsjprs.2019.10.017
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu X, 2020, NAT NANOTECHNOL, V15, P307, DOI 10.1038/s41565-020-0641-5
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Luppino LT, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3056196
   Mallakpour I, 2015, NAT CLIM CHANGE, V5, P250, DOI 10.1038/NCLIMATE2516
   Martinis S, 2009, NAT HAZARD EARTH SYS, V9, P303, DOI 10.5194/nhess-9-303-2009
   Martinis S, 2013, REMOTE SENS-BASEL, V5, P5598, DOI 10.3390/rs5115598
   Martinis S, 2011, IEEE T GEOSCI REMOTE, V49, P251, DOI 10.1109/TGRS.2010.2052816
   Mason DC, 2012, IEEE T GEOSCI REMOTE, V50, P3041, DOI 10.1109/TGRS.2011.2178030
   Nemni E, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162532
   Neubert P, 2014, INT C PATT RECOG, V0, PP996, DOI 10.1109/ICPR.2014.181
   Okada G, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13071401
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pfister, 2006, 30 ISPRS C COMM 7, V0, P217
   Plank S, 2017, INT J REMOTE SENS, V38, P3831, DOI 10.1080/01431161.2017.1306143
   Rahman AS, 2020, J HYDROL, V581, P0, DOI 10.1016/j.jhydrol.2019.124372
   Reichstein M, 2021, NATURE, V592, P347, DOI 10.1038/d41586-021-00927-x
   Renschler CS, 2017, INT J APPL EARTH OBS, V62, P157, DOI 10.1016/j.jag.2017.06.002
   Robson BA, 2015, REMOTE SENS ENVIRON, V170, P372, DOI 10.1016/j.rse.2015.10.001
   Schlaffer S, 2015, INT J APPL EARTH OBS, V38, P15, DOI 10.1016/j.jag.2014.12.001
   Shen XY, 2019, REMOTE SENS ENVIRON, V221, P302, DOI 10.1016/j.rse.2018.11.008
   Singha M, 2020, ISPRS J PHOTOGRAMM, V166, P278, DOI 10.1016/j.isprsjprs.2020.06.011
   Sivanpillai R, 2021, FRONT EARTH SCI-PRC, V15, P1, DOI 10.1007/s11707-020-0818-0
   Souissi D, 2020, GEOCARTO INT, V35, P991, DOI 10.1080/10106049.2019.1566405
   Tan QL, 2004, INT GEOSCI REMOTE SE, V0, P4885
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   Tsyganskaya V, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081286
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wagenaar D, 2017, NAT HAZARD EARTH SYS, V17, P1683, DOI 10.5194/nhess-17-1683-2017
   Wang H, 2008, INT J REMOTE SENS, V29, P1649, DOI 10.1080/01431160701395211
   Wang LX, 2018, ISPRS J PHOTOGRAMM, V141, P10, DOI 10.1016/j.isprsjprs.2018.03.026
   Ward PJ, 2015, NAT CLIM CHANGE, V5, P712, DOI 10.1038/nclimate2742
   Waske B, 2008, IEEE T GEOSCI REMOTE, V46, P1457, DOI 10.1109/TGRS.2008.916089
   Wu QS, 2019, REMOTE SENS ENVIRON, V228, P1, DOI 10.1016/j.rse.2019.04.015
   Xie JY, 2016, PR MACH LEARN RES, V48, P0
   Xiong J, 2017, ISPRS J PHOTOGRAMM, V126, P225, DOI 10.1016/j.isprsjprs.2017.01.019
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Zeng ZZ, 2018, NAT GEOSCI, V11, P556, DOI 10.1038/s41561-018-0166-9
   Zhang ZQ, 2019, IEEE J-STARS, V12, P3784, DOI 10.1109/JSTARS.2019.2936406
   Zhao J, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111605
   Zhao J, 2021, REMOTE SENS ENVIRON, V256, P0, DOI 10.1016/j.rse.2021.112338
NR 81
TC 19
Z9 19
U1 23
U2 94
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG 15
PY 2021
VL 178
IS 
BP 36
EP 50
DI 10.1016/j.isprsjprs.2021.05.019
EA JUN 2021
PG 15
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TE4AS
UT WOS:000669954900003
DA 2023-04-26
ER

PT J
AU Bickel, VT
   Mandrake, L
   Doran, G
AF Bickel, Valentin T.
   Mandrake, Lukas
   Doran, Gary
TI Analyzing multi-domain learning for enhanced rockfall mapping in known and unknown planetary domains
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Rockfall; Transfer learning; Domain adaptation; Moon; Mars; Ceres
AB Rockfalls are small-scale mass wasting events that have been observed across the solar system. They provide valuable information about the endo- and exogenic activity of their host body, but are difficult to identify and map in satellite imagery, especially on global scales and in big data sets. Past work implemented convolutional neural networks to automate rockfall mapping on the Moon and Mars with the caveat of (1) achieving sub-optimal performance and (2) requiring substantial manual image labeling efforts. Mixing annotated image data from the Moon and Mars while keeping the total number of labels constant, we show that including a small number (10%) of rockfall labels from a foreign domain (e.g. Moon) during detector training can increase performance in the home domain (e.g. Mars) by up to 6% Average Precision (AP) in comparison to a purely home domain-trained detector. We additionally show that using a large number of foreign domain training examples (90%) in combination with a small number (10%) of home domain labels can be as powerful or more powerful as exclusively (100%) using home labels in the home domain. We further observe that rockfall detectors trained on multiple domains outperform single-domain trained detectors in completely unknown domains by up to 16% AP, using image data from Ceres and comet 67P. We conduct an experiment varying only image resolution on a single planetary body (Mars) to test whether the improvement was due to training on differing resolutions specifically and show that none of the improvement can be explained by this effect alone. This means that the benefits of multi-domain training mostly draw from either variations in lighting condition, differing physical appearance/backgrounds around the target of interest for generalization purposes, or both. Our findings have important applications such as machine learning-enabled science discovery in legacy and new planetary datasets.
C1 [Bickel, Valentin T.] MPI Solar Syst Res, Justus Von Liebig Weg 3, D-37077 Gottingen, Lower Saxony, Germany.
   [Bickel, Valentin T.; Mandrake, Lukas; Doran, Gary] NASA, Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.
C3 National Aeronautics & Space Administration (NASA); NASA Jet Propulsion Laboratory (JPL)
RP Bickel, VT (corresponding author), MPI Solar Syst Res, Justus Von Liebig Weg 3, D-37077 Gottingen, Lower Saxony, Germany.; Bickel, VT (corresponding author), NASA, Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.
EM bickel@mps.mpg.de
FU IFI programme of the German Academic Exchange Service (DAAD)
CR Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Benedix GK, 2020, EARTH SPACE SCI, V7, P0, DOI 10.1029/2019EA001005
   Bickel V., 2018, IEEE T GEOSCI ELECT, V57, P0
   Bickel V., 2021, FRONT REMOTE SENS, V0, P0
   Bickel VT, 2020, ICARUS, V348, P0, DOI 10.1016/j.icarus.2020.113850
   Bickel VT, 2019, J GEOPHYS RES-PLANET, V124, P1296, DOI 10.1029/2018JE005876
   Bickel VT, 2020, IEEE J-STARS, V13, P2831, DOI 10.1109/JSTARS.2020.2991588
   Bickel VT, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-16653-3
   Bilen H., 2017, ARXIV170107275, V0, P0
   Douillard A., 2018, OBJECT DETECTION DEE, V0, P0
   Duarte KD, 2019, J GEOPHYS RES-PLANET, V124, P3329, DOI 10.1029/2018JE005673
   Dundas CM, 2017, NAT GEOSCI, V10, P903, DOI 10.1038/s41561-017-0012-5
   Hovland H., 1973, MOON PLANETS, V6, P0
   Jackson P. T., 2018, STYLE AUGMENTATION D, V0, P83
   Jaeger PF, 2018, MACHINE LEARNING HLT, V0, P0
   Jung H, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0203355
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lucchetti A, 2019, GEOPHYS RES LETT, V46, P14336, DOI 10.1029/2019GL085132
   MALIN MC, 1992, J GEOPHYS RES-PLANET, V97, P16337, DOI 10.1029/92JE01343
   Malisiewicz T., 2011, BLAZING FAST NMS, V0, P0
   McEwen AS, 2007, J GEOPHYS RES-PLANET, V112, P0, DOI 10.1029/2005JE002605
   Nagle-McNaughton T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213607
   Needham DH, 2017, EARTH PLANET SC LETT, V478, P175, DOI 10.1016/j.epsl.2017.09.002
   Otto KA, 2013, J GEOPHYS RES-PLANET, V118, P2279, DOI 10.1002/2013JE004333
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Prakash N., 2021, SCI REP-UK, V0, P0
   Raymond CA, 2020, NAT ASTRON, V4, P741, DOI 10.1038/s41550-020-1168-2
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Robinson MS, 2010, SPACE SCI REV, V150, P81, DOI 10.1007/s11214-010-9634-2
   Russell P, 2008, GEOPHYS RES LETT, V35, P0, DOI 10.1029/2008GL035790
   Sargeant HM, 2020, J GEOPHYS RES-PLANET, V125, P0, DOI 10.1029/2019JE006157
   Sierks H, 2011, SPACE SCI REV, V163, P263, DOI 10.1007/s11214-011-9745-4
   Singh K. R., 2019, ESRI OBJECT DETECTIO, V0, P0
   Tesson PA, 2020, ICARUS, V342, P0, DOI 10.1016/j.icarus.2019.113503
   Hoang TM, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19020281
   Tranheden W., 2020, DACS DOMAIN ADAPTATI, V0, P0
   Tubiana C, 2015, ASTRON ASTROPHYS, V583, P0, DOI 10.1051/0004-6361/201525985
   Wang XD, 2019, PROC CVPR IEEE, V0, PP7281, DOI 10.1109/CVPR.2019.00746
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111309
   Wright J, 2020, EARTH PLANET SC LETT, V549, P0, DOI 10.1016/j.epsl.2020.116519
   Xiao ZY, 2013, EARTH PLANET SC LETT, V376, P1, DOI 10.1016/j.epsl.2013.06.015
NR 43
TC 1
Z9 1
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD DEC 15
PY 2021
VL 182
IS 
BP 1
EP 13
DI 10.1016/j.isprsjprs.2021.09.018
EA OCT 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA WK6CD
UT WOS:000709811500001
DA 2023-04-26
ER

PT J
AU Sangani, DJ
   Thakker, RA
   Panchal, SD
   Gogineni, R
AF Sangani, Dhara J.
   Thakker, Rajesh A.
   Panchal, S. D.
   Gogineni, Rajesh
TI Pansharpening of Satellite Images with Convolutional Sparse Coding and Adaptive PCNN-Based Approach
SO JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING
LA English
DT Article
DE Pansharpening; Non-subsampled shearlet transform; Convolutional sparse coding; Adaptive pulse couple neural network; High-resolution multispectral image
ID pan-sharpening method; contourlet transform; variational approach; fusion algorithm; model; representation
AB In remote sensing, Pansharpening process has great significance in many practical applications like map updating, hazard monitoring, target recognition and object classification. Satellite sensors capturing panchromatic and multispectral images with complementary characteristics due to tradeoff between IFOV (instantaneous field of view) and SNR (signal-to-noise ratio). Pansharpening is a process of combining PAN (panchromatic) image of high spatial resolution with MS (multispectral) image of high spectral resolution to get image of high spectral and spatial resolution. In Pansharpening, balancing between extraction of information and injection of information is crucial point; misbalancing can cause intensity distortion. Proposed method is a combination of CSC (convolution sparse coding) and adaptive PCNN (pulse coupled neural network) approach. NSST (non-sub-sampled shearlet transform) is used for band separation of PAN and MS image. CSC is used for fusing low pass sub-bands, and adaptive PCNN method is employed for fusing high pass sub-bands. Five datasets with different geographical areas like mountain, urban and vegetation area are used for experiment purpose. Visual results and quantitative index analysis reflect the superiority of proposed method in preserving spectral details in pansharpened image.
C1 [Sangani, Dhara J.] Vishwakarma Govt Engn Coll Chandkheda, Elect & Commun Dept, Gandhi Sagar 382424, Gujarat, India.
   [Thakker, Rajesh A.] Govt Engn Coll, Dept ECE, Rajkot, Gujarat, India.
   [Panchal, S. D.] Gujarat Technol Univ, Comp Engn, Ahmadabad, Gujarat, India.
   [Gogineni, Rajesh] Dhanekula Inst Engn & Technol, Dept Elect & Commun Engn, Vijayawada 521139, India.
C3 Gujarat Technological University
RP Sangani, DJ (corresponding author), Vishwakarma Govt Engn Coll Chandkheda, Elect & Commun Dept, Gandhi Sagar 382424, Gujarat, India.
EM dsangani1987@gmail.com
CR Aiazzi B, 2006, PHOTOGRAMM ENG REM S, V72, P591, DOI 10.14358/PERS.72.5.591
   Amro I, 2011, EURASIP J ADV SIG PR, V0, P0, DOI DOI 10.1186/1687-6180-2011-79
   Ballester C, 2006, INT J COMPUT VISION, V69, P43, DOI 10.1007/s11263-006-6852-x
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   Chen CQ, 2018, REMOTE SENS LETT, V9, P170, DOI 10.1080/2150704X.2017.1410292
   Chen FR, 2012, PROCEDIA ENGINEER, V29, P2938, DOI 10.1016/j.proeng.2012.01.418
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Chu H, 2008, IEEE GEOSCI REMOTE S, V5, P653, DOI 10.1109/LGRS.2008.2002034
   Deng LJ, 2017, IEEE IMAGE PROC, V0, P535
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Duran J, 2017, ISPRS J PHOTOGRAMM, V125, P78, DOI 10.1016/j.isprsjprs.2016.12.013
   Fang FM, 2013, IEEE T IMAGE PROCESS, V22, P2822, DOI 10.1109/TIP.2013.2258355
   Fei RR, 2019, IEEE GEOSCI REMOTE S, V16, P1595, DOI 10.1109/LGRS.2019.2904526
   Fu XY, 2019, PROC CVPR IEEE, V0, PP10257, DOI 10.1109/CVPR.2019.01051
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Garzelli A, 2008, IEEE T GEOSCI REMOTE, V46, P228, DOI 10.1109/TGRS.2007.907604
   Ghahremani M, 2015, IEEE GEOSCI REMOTE S, V12, P502, DOI 10.1109/LGRS.2014.2347955
   Gogineni R, 2019, IEEE J-STARS, V12, P4024, DOI 10.1109/JSTARS.2019.2945815
   Gogineni R, 2018, ISPRS J PHOTOGRAMM, V146, P360, DOI 10.1016/j.isprsjprs.2018.10.009
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Jiang YY, 2015, IEEE I CONF COMP VIS, V0, PP540, DOI 10.1109/ICCV.2015.69
   Joshi MV, 2006, IEEE T GEOSCI REMOTE, V44, P2549, DOI 10.1109/TGRS.2006.873340
   Laben C. A., 2000, US PATENT, V0, Patent No. 6011875
   Li ST, 2011, IEEE T GEOSCI REMOTE, V49, P738, DOI 10.1109/TGRS.2010.2067219
   Lolli S, 2017, IEEE GEOSCI REMOTE S, V14, P2255, DOI 10.1109/LGRS.2017.2761021
   Masi G, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070594
   Moller M, 2012, SIAM J IMAGING SCI, V5, P150, DOI 10.1137/100810356
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Nunez J, 1999, IEEE T GEOSCI REMOTE, V37, P1204, DOI 10.1109/36.763274
   Ophir B, 2011, IEEE J-STSP, V5, P1014, DOI 10.1109/JSTSP.2011.2155032
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   Palsson F, 2014, IEEE GEOSCI REMOTE S, V11, P318, DOI 10.1109/LGRS.2013.2257669
   Panchal S, 2017, J INDIAN SOC REMOTE, V45, P385, DOI 10.1007/s12524-016-0608-z
   Rahmani S, 2010, IEEE GEOSCI REMOTE S, V7, P746, DOI 10.1109/LGRS.2010.2046715
   Sahu A, 2015, 2014 INTERNATIONAL CONFERENCE ON MEDICAL IMAGING, V0, P448
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Vicinanza MR, 2015, IEEE GEOSCI REMOTE S, V12, P180, DOI 10.1109/LGRS.2014.2331291
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wang XH, 2019, IEEE ACCESS, V7, P52508, DOI 10.1109/ACCESS.2019.2910656
   YIN H, 2015, SIGNAL PROCESS, V0, P0
   Zhu XX, 2016, IEEE T GEOSCI REMOTE, V54, P2664, DOI 10.1109/TGRS.2015.2504261
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 43
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0255-660X
EI 0974-3006
J9 J INDIAN SOC REMOTE
JI J. Indian Soc. Remote Sens.
PD DEC 15
PY 2021
VL 49
IS 12
BP 2989
EP 3004
DI 10.1007/s12524-021-01440-4
EA OCT 2021
PG 16
WC Environmental Sciences; Remote Sensing
SC Environmental Sciences & Ecology; Remote Sensing
GA XC3JP
UT WOS:000710066100001
DA 2023-04-26
ER

PT J
AU Lin, YP
   Vosselman, G
   Cao, YP
   Yang, MY
AF Lin, Yaping
   Vosselman, George
   Cao, Yanpeng
   Yang, Michael Ying
TI Local and global encoder network for semantic segmentation of Airborne laser scanning point clouds
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Point clouds; Semantic segmentation; Global context; Attention models
ID convolutional neural-network; lidar; classification
AB Interpretation of Airborne Laser Scanning (ALS) point clouds is a critical procedure for producing various geo-information products like 3D city models, digital terrain models and land use maps. In this paper, we present a local and global encoder network (LGENet) for semantic segmentation of ALS point clouds. Adapting the KPConv network, we first extract features by both 2D and 3D point convolutions to allow the network to learn more representative local geometry. Then global encoders are used in the network to exploit contextual information at the object and point level. We design a segment-based Edge Conditioned Convolution to encode the global context between segments. We apply a spatial-channel attention module at the end of the network, which not only captures the global interdependencies between points but also models interactions between channels. We evaluate our method on two ALS datasets namely, the ISPRS benchmark dataset and DCF2019 dataset. For the ISPRS benchmark dataset, our model achieves state-of-the-art results with an overall accuracy of 0.845 and an average F1 score of 0.737. With regards to the DFC2019 dataset, our proposed network achieves an overall accuracy of 0.984 and an average F1 score of 0.834.
C1 [Lin, Yaping; Vosselman, George; Yang, Michael Ying] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
   [Cao, Yanpeng] Zhejiang Univ, Sch Mech Engn, State Key Lab Fluid Power & Mechatron Syst, Hangzhou, Peoples R China.
C3 University of Twente; Zhejiang University
RP Yang, MY (corresponding author), Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
EM ylin@utwente.nl; george.vosselman@utwente.nl; caoyp@zju.edu.cn; michael.yang@utwente.nl
CR [Anonymous], 1900, DOI 10.5194/ISPRSANNALS-II- 5-W2- 313-2013 DOI 10.5194/ISPRSANNALS-II-5-W2-313-2013, V0, P0
   Arief HA, 2019, ISPRS J PHOTOGRAMM, V155, P90, DOI 10.1016/j.isprsjprs.2019.07.002
   Armeni I, 2016, PROC CVPR IEEE, V0, PP1534, DOI 10.1109/CVPR.2016.170
   Bosch M, 2019, IEEE WINT CONF APPL, V0, PP1524, DOI 10.1109/WACV.2019.00167
   Boulch A., 2020, P AS C COMP VIS, V0, P0
   Boulch A, 2020, COMPUT GRAPH-UK, V88, P24, DOI 10.1016/j.cag.2020.02.005
   Boulch A, 2018, COMPUT GRAPH-UK, V71, P189, DOI 10.1016/j.cag.2017.11.010
   Chehata N., 2009, INT ARCH PHOTOGRAMM, V0, P0
   Chen ZY, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17010150
   Cooper HM, 2013, CLIMATIC CHANGE, V116, P547, DOI 10.1007/s10584-012-0510-9
   Dai A, 2017, PROC CVPR IEEE, V0, PP2432, DOI 10.1109/CVPR.2017.261
   Feng MT, 2020, PATTERN RECOGN, V107, P0, DOI 10.1016/j.patcog.2020.107446
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Groh F, 2019, LECT NOTES COMPUT SC, V11361, P105, DOI 10.1007/978-3-030-20887-5_7
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Hu Q., 2020, P IEEECVF C COMPUTER, V0, PP11108, DOI 10.48550/ARXIV.1911.11236
   Hu XY, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8090730
   Huang R, 2020, ISPRS J PHOTOGRAMM, V163, P62, DOI 10.1016/j.isprsjprs.2020.02.020
   Jiang M., 2018, POINTSIFT SIFT NETWO, V0, P0
   Kalogerakis E, 2017, PROC CVPR IEEE, V0, PP6630, DOI 10.1109/CVPR.2017.702
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Landrieu L, 2018, PROC CVPR IEEE, V0, PP4558, DOI 10.1109/CVPR.2018.00479
   Landrieu L, 2017, SIAM J IMAGING SCI, V10, P1724, DOI 10.1137/17M1113436
   Lemmen C, 2015, LAND USE POLICY, V49, P535, DOI 10.1016/j.landusepol.2015.01.014
   Li WZ, 2020, ISPRS J PHOTOGRAMM, V164, P26, DOI 10.1016/j.isprsjprs.2020.03.016
   Li X, 2020, ISPRS J PHOTOGRAMM, V166, P128, DOI 10.1016/j.isprsjprs.2020.05.023
   Li YY, 2018, ADV NEUR IN, V31, P0
   Lin CH, 2014, ISPRS J PHOTOGRAMM, V94, P70, DOI 10.1016/j.isprsjprs.2014.04.016
   Lin Y., 2018, ISPRS TC 2 MID TERM, V0, P0
   Lin YP, 2020, ISPRS J PHOTOGRAMM, V169, P73, DOI 10.1016/j.isprsjprs.2020.09.003
   Lodha SK, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, P0
   Lodha SK, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, V0, P435
   Mao JG, 2019, IEEE I CONF COMP VIS, V0, PP1578, DOI 10.1109/ICCV.2019.00166
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Meng XL, 2012, PHOTOGRAMM ENG REM S, V78, P35, DOI 10.14358/PERS.78.1.35
   Murgante B, 2009, STUD COMPUT INTELL, V176, P1, DOI 10.1007/978-3-540-89930-3
   Murtha T., 2018, J DIGIT LANDS ARCHI, V3, P249
   Niemeyer J, 2016, INT ARCH PHOTOGRAMM, V41, P655, DOI 10.5194/isprsarchives-XLI-B3-655-2016
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Qi C.R., 2017, ADV NEUR IN, V0, P5099
   Qi CR, 2017, PROC CVPR IEEE, V0, PP77, DOI 10.1109/CVPR.2017.16
   Pham QH, 2019, PROC CVPR IEEE, V0, PP8819, DOI 10.1109/CVPR.2019.00903
   Shen YL, 2010, 2010 18TH INTERNATIONAL CONFERENCE ON GEOINFORMATICS, V0, P0, DOI DOI 10.1109/GEOINFORMATICS.2010.5567852
   Simonovsky M, 2017, PROC CVPR IEEE, V0, PP29, DOI 10.1109/CVPR.2017.11
   Sorgel U, 2019, ISPRS ANN PHOTOGRAMM, V0, PP77, DOI 10.5194/ISPRS-ANNALS-IV-2-W5-77-2019
   Tchapmi LP, 2017, INT CONF 3D VISION, V0, PP537, DOI 10.1109/3DV.2017.00067
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Varney N., 2020, PYRAMID POINT MULTIL, V0, P0
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Vosselman G., 2010, AIRBORNE TERRESTRIAL, V0, P0
   Vosselman G, 2017, ISPRS J PHOTOGRAMM, V128, P354, DOI 10.1016/j.isprsjprs.2017.03.010
   Wallace L, 2012, REMOTE SENS-BASEL, V4, P1519, DOI 10.3390/rs4061519
   Wang R.E., 2020, ARXIV PREPRINT ARXIV, V0, P0
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Weinmann M., 2014, ISPRS ANN PHOTOGRAMM, VII-3, P181, DOI 10.5194/ISPRSANNALS-II-3-181-2014
   Wen CC, 2021, ISPRS J PHOTOGRAMM, V173, P181, DOI 10.1016/j.isprsjprs.2021.01.007
   Wen CC, 2020, ISPRS J PHOTOGRAMM, V162, P50, DOI 10.1016/j.isprsjprs.2020.02.004
   Winiwarter L, 2019, PFG-J PHOTOGRAMM REM, V87, P75, DOI 10.1007/s41064-019-00073-0
   Wu WX, 2019, PROC CVPR IEEE, V0, PP9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, V0, PP1912, DOI 10.1109/CVPR.2015.7298801
   Xiong XH, 2011, IEEE INT CONF ROBOT, V0, PP2609, DOI 10.1109/ICRA.2011.5980125
   Xu S, 2014, ISPRS J PHOTOGRAMM, V88, P1, DOI 10.1016/j.isprsjprs.2013.11.008
   Xu Y, 2018, ADV SOC SCI EDUC HUM, V284, P87
   Yang ZS, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18103347
   Yang ZS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090936
   Yousefhussien M, 2018, ISPRS J PHOTOGRAMM, V143, P191, DOI 10.1016/j.isprsjprs.2018.03.018
   Zhao RB, 2018, INT J GEOGR INF SCI, V32, P960, DOI 10.1080/13658816.2018.1431840
   Zheng S, 2015, IEEE I CONF COMP VIS, V0, PP1529, DOI 10.1109/ICCV.2015.179
NR 69
TC 9
Z9 9
U1 9
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUN 15
PY 2021
VL 176
IS 
BP 151
EP 168
DI 10.1016/j.isprsjprs.2021.04.016
EA APR 2021
PG 18
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SJ4AV
UT WOS:000655474600012
DA 2023-04-26
ER

PT J
AU Li, W
   He, CY
   Hu, AD
   Zhao, DS
   Shen, Y
   Zhang, KF
AF Li, Wang
   He, Changyong
   Hu, Andong
   Zhao, Dongsheng
   Shen, Yi
   Zhang, Kefei
TI A new method for improving the performance of an ionospheric model developed by multi-instrument measurements based on artificial neural network
SO ADVANCES IN SPACE RESEARCH
LA English
DT Article
DE Artificial neural network; Ionospheric model; Data correction; COSMIC; Ionosonde
ID gnss-radio occultation; electron-density; plasma bubbles; ionosonde; tec; values
AB There are remarkable ionospheric discrepancies between space-borne (COSMIC) measurements and ground-based (ionosonde) observations, the discrepancies could decrease the accuracies of the ionospheric model developed by multi-source data seriously. To reduce the discrepancies between two observational systems, the peak frequency (foF2) and peak height (hmF2) derived from the COSMIC and ionosonde data are used to develop the ionospheric models by an artificial neural network (ANN) method, respectively. The averaged root-mean-square errors (RMSEs) of COSPF (COSMIC peak frequency model), COSPH (COSMIC peak height model), IONOPF (Ionosonde peak frequency model) and IONOPH (Ionosonde peak height model) are 0.58 MHz, 19.59 km, 0.92 MHz and 23.40 km, respectively. The results indicate that the discrepancies between these models are dependent on universal time, geographic latitude and seasons. The peak frequencies measured by COSMIC are generally larger than ionosonde's observations in the nighttime or middle-latitudes with the amplitude of lower than 25%, while the averaged peak height derived from COSMIC is smaller than ionosonde's data in the polar regions. The differences between ANN-based maps and references show that the discrepancies between two ionospheric detecting techniques are proportional to the intensity of solar radiation. Besides, a new method based on the ANN technique is proposed to reduce the discrepancies for improving ionospheric models developed by multiple measurements, the results indicate that the RMSEs of ANN models optimized by the method are 14-25% lower than the models without the application of the method. Furthermore, the ionospheric model built by the multiple measurements with the application of the method is more powerful in capturing the ionospheric dynamic physics features, such as equatorial ionization, Weddell Sea, mid-latitude summer nighttime and winter anomalies. In conclusion, the new method is significant in improving the accuracy and physical characteristics of an ionospheric model based on multi-source observations. (C) 2020 COSPAR. Published by Elsevier Ltd. All rights reserved.
C1 [Li, Wang; Zhao, Dongsheng; Zhang, Kefei] China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
   [Li, Wang; He, Changyong; Hu, Andong; Zhang, Kefei] RMIT Univ, SPACE Res Ctr, Sch Sci, Melbourne, Vic 3001, Australia.
   [He, Changyong] ENSG, IGN, Cite Descartes, F-77455 Champs Sur Marne, Marne La Vallee, France.
   [Hu, Andong] Ctr Wiskunde & Informat CWI, Multiscale Grp, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.
   [Shen, Yi] Xinyang Normal Univ, Key Lab Synergist Prevent Water & Soil Environm P, Xinyang 464000, Peoples R China.
C3 China University of Mining & Technology; Royal Melbourne Institute of Technology (RMIT); Universite Gustave-Eiffel; Xinyang Normal University
RP Zhang, KF (corresponding author), China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
EM profkzhang@cumt.edu.cn
FU National Natural Science Foundations of China [41730109, 41870404]; Key Laboratory for Synergistic Prevention of Water and Soil Environmental Pollution [KLSPWSEP-A06]; China Postdoctoral Science Foundation [2020M671645]; Fundamental Research Funds for the Central Universities [2020QN31]; Priority Academic Program Development of Jiangsu Higher Education Institutions (Surveying and Mapping); Jiangsu Dual Creative Talents Project; Jiangsu Dual Creative Teams Programme Project; Xuzhou Key Project [KC19111]
CR APPLETON EV, 1946, NATURE, V157, P691, DOI 10.1038/157691a0
   Balan N, 2018, J ATMOS SOL-TERR PHY, V171, P3, DOI 10.1016/j.jastp.2017.06.020
   BALAN N, 1995, J GEOPHYS RES-SPACE, V100, P21421, DOI 10.1029/95JA01555
   Bauer P, 2014, MON WEATHER REV, V142, P555, DOI 10.1175/MWR-D-13-00130.1
   Bilitza D, 2006, RADIO SCI, V41, P0, DOI 10.1029/2005RS003370
   Brum CGM, 2011, J GEOPHYS RES-SPACE, V116, P0, DOI 10.1029/2010JA015727
   Burns AG, 2015, J GEOPHYS RES-SPACE, V120, P5890, DOI 10.1002/2015JA021220
   Chu YH, 2010, ADV SPACE RES, V46, P431, DOI 10.1016/j.asr.2009.10.014
   Ely CV, 2012, ADV SPACE RES, V49, P1553, DOI 10.1016/j.asr.2011.12.029
   FRANK LA, 1971, J GEOPHYS RES, V76, P3612, DOI 10.1029/JA076i016p03612
   Gowtam VS, 2019, J GEOPHYS RES-SPACE, V124, P4639, DOI 10.1029/2019JA026540
   Gowtam VS, 2017, J GEOPHYS RES-SPACE, V122, P11743, DOI 10.1002/2017JA024795
   Gowtam VS, 2017, ADV SPACE RES, V60, P1585, DOI 10.1016/j.asr.2017.03.017
   Gowtam VS, 2017, J GEOPHYS RES-SPACE, V122, P8816, DOI 10.1002/2017JA024170
   Gulyaeva TL, 2011, ADV SPACE RES, V47, P913, DOI 10.1016/j.asr.2010.10.025
   Guo J., 1999, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0133378
   Guo J., 2019, J GEODYN, V0, PP1241, DOI 10.1016/j.jog.2019.01.005.
   He MS, 2009, J GEOPHYS RES-SPACE, V114, P0, DOI 10.1029/2009JA014175
   Hu LH, 2014, ADV SPACE RES, V54, P929, DOI 10.1016/j.asr.2014.05.012
   Klimenko MV, 2015, ADV SPACE RES, V56, P1951, DOI 10.1016/j.asr.2015.07.019
   Krankowski A, 2011, J GEODESY, V85, P949, DOI 10.1007/s00190-011-0481-z
   Lee WK, 2011, J GEOPHYS RES-SPACE, V116, P0, DOI 10.1029/2010JA015815
   Lei JH, 2007, J GEOPHYS RES-SPACE, V112, P0, DOI 10.1029/2006JA012240
   LI W, 2020, REMOTE SENS, V12, P0, DOI 10.3390/RS12050866.
   Li W, 2018, J GEOPHYS RES-SPACE, V123, P8865, DOI 10.1029/2018JA025700
   Li W, 2018, GPS SOLUT, V22, P0, DOI 10.1007/s10291-018-0722-1
   Li W, 2018, ADV SPACE RES, V61, P1206, DOI 10.1016/j.asr.2017.12.013
   Li W, 2017, J ATMOS SOL-TERR PHY, V161, P43, DOI 10.1016/j.jastp.2017.06.012
   Li ZS, 2015, J GEODESY, V89, P331, DOI 10.1007/s00190-014-0778-9
   Lin C.-H., 2009, J GEOPHYS RES SPACE, V114, P0, DOI 10.1029/2008JA013455
   Lin C.-H., 2010, J GEOPHYS RES SPACE, V115, P0, DOI 10.1029/2009JA014084.
   MCCLURE JP, 1977, J GEOPHYS RES-SPACE, V82, P2650, DOI 10.1029/JA082i019p02650
   McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570
   McNamara LF, 2015, ADV SPACE RES, V55, P163, DOI 10.1016/j.asr.2014.07.015
   Muller-Wodarg ICF, 2012, ICARUS, V221, P481, DOI 10.1016/j.icarus.2012.08.034
   Okoh D, 2019, J GEOPHYS RES-SPACE, V124, P10512, DOI 10.1029/2019JA027065
   Potula BS, 2011, J GEOPHYS RES-SPACE, V116, P0, DOI 10.1029/2010JA015814
   Ram ST, 2016, GPS SOLUT, V20, P825, DOI 10.1007/s10291-015-0491-z
   Rishbeth H, 2000, ANN GEOPHYS-ATM HYDR, V18, P945, DOI 10.1007/s00585-000-0945-6
   Shagimuratov II, 2012, EARTH PLANETS SPACE, V64, P521, DOI 10.5047/eps.2011.10.015
   Smith J, 2017, J GEOPHYS RES-SPACE, V122, P5743, DOI 10.1002/2017JA024128
   Song R, 2018, ADV SPACE RES, V62, P745, DOI 10.1016/j.asr.2018.03.043
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Steane AM, 1996, PHYS REV LETT, V77, P793, DOI 10.1103/PhysRevLett.77.793
   Sun L., 2014, CHIN J GEOPHYS, V0, P0
   Themens DR, 2017, J GEOPHYS RES-SPACE, V122, P9015, DOI 10.1002/2017JA024398
   TORR MR, 1973, J ATMOS TERR PHYS, V35, P2237, DOI 10.1016/0021-9169(73)90140-2
   Tulasi Ram S., 2018, JOURNAL OF GEOPHYSICAL RESEARCH: SPACE PHYSICS, V123, P5807, DOI 10.1029/2018JA025559
   Widrow B., 1960, 1960 IRE WESCON CONV, V4, P126
   Yasyukevich YV, 2018, J SPACE WEATHER SPAC, V8, P0, DOI 10.1051/swsc/2018036
   Yue XA, 2015, J ATMOS SOL-TERR PHY, V129, P30, DOI 10.1016/j.jastp.2015.04.004
   Yue XN, 2014, SPACE WEATHER, V12, P616, DOI 10.1002/2014SW001133
   Zhang ML, 2014, ADV SPACE RES, V53, P395, DOI 10.1016/j.asr.2013.11.053
NR 53
TC 5
Z9 5
U1 0
U2 6
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0273-1177
EI 1879-1948
J9 ADV SPACE RES
JI Adv. Space Res.
PD JAN 1
PY 2021
VL 67
IS 1
BP 20
EP 34
DI 10.1016/j.asr.2020.07.032
PG 15
WC Engineering, Aerospace; Astronomy & Astrophysics; Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences
SC Engineering; Astronomy & Astrophysics; Geology; Meteorology & Atmospheric Sciences
GA PI1OC
UT WOS:000600867300004
DA 2023-04-26
ER

PT J
AU Foroughi, F
   Chen, ZH
   Wang, JK
AF Foroughi, Farzin
   Chen, Zonghai
   Wang, Jikai
TI A CNN-Based System for Mobile Robot Navigation in Indoor Environments via Visual Localization with a Small Dataset
SO WORLD ELECTRIC VEHICLE JOURNAL
LA English
DT Article
DE mobile robot; mobile robot localization; convolutional neural network; cross-entropy loss function
AB Deep learning has made great advances in the field of image processing, which allows automotive devices to be more widely used in humans' daily lives than ever before. Nowadays, the mobile robot navigation system is among the hottest topics that researchers are trying to develop by adopting deep learning methods. In this paper, we present a system that allows the mobile robot to localize and navigate autonomously in the accessible areas of an indoor environment. The proposed system exploits the Convolutional Neural Network (CNN) model's advantage to extract data feature maps for image classification and visual localization, which attempts to precisely determine the location region of the mobile robot focusing on the topological maps of the real environment. The system attempts to precisely determine the location region of the mobile robot by integrating the CNN model and topological map of the robot workspace. A dataset with small numbers of images is acquired from the MYNT EYE camera. Furthermore, we introduce a new loss function to tackle the bounded generalization capability of the CNN model in small datasets. The proposed loss function not only considers the probability of the input data when it is allocated to its true class but also considers the probability of allocating the input data to other classes rather than its actual class. We investigate the capability of the proposed system by evaluating the empirical studies based on provided datasets. The results illustrate that the proposed system outperforms other state-of-the-art techniques in terms of accuracy and generalization capability.
C1 [Foroughi, Farzin; Chen, Zonghai; Wang, Jikai] Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China.
RP Wang, JK (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China.
EM foroughi@mail.ustc.edu.cn; chenzh@ustc.edu.cn; wangjk@ustc.edu.cm
FU National Natural Science Foundation of China [62103393, 91848111]; Chinese Academy of Science-The World Academy of Sciences (CAS-TWAS)
CR Agarap A F, 2018, ARXIV, V0, P0
   Ba J. L., 2016, ARXIV, V0, P0, DOI DOI 10.48550/ARXIV.1607.06450
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Dourado CMJM, 2019, FUTURE GENER COMP SY, V100, P859, DOI 10.1016/j.future.2019.05.074
   Elbasiony R, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), V0, PP225, DOI 10.1109/ICMLA.2014.42
   Ferris B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2480
   Foroughi F., 2019, P 2019 INT C IND ENG, V0, P1
   Foroughi F., 2015, INT J COMPUT APPL, V116, P1
   Howard AG, 2017, ARXIV, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Guang XX, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18092952
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kendall A, 2015, IEEE I CONF COMP VIS, V0, PP2938, DOI 10.1109/ICCV.2015.336
   Kim H, 2015, SENSORS-BASEL, V15, P21636, DOI 10.3390/s150921636
   Konrad T, 2018, ANNU REV CONTROL, V46, P181, DOI 10.1016/j.arcontrol.2018.09.002
   Krizhevsky A., 2012, P ADV NEUR INF PROC, V25, P1097
   Kukacka J., 2017, ARXIV, V0, P0
   Lin SQ, 2021, IEEE ROBOT AUTOM LET, V6, P7041, DOI 10.1109/LRA.2021.3097242
   Morales Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON INTEGRATION TECHNOLOGY, V0, P519, DOI 10.1109/ICITECHNOLOGY.2007.4290370
   Onyekpe U, 2021, APPL SCI-BASEL, V11, P0, DOI 10.3390/app11031270
   Radwan N, 2018, IEEE ROBOT AUTOM LET, V3, P4407, DOI 10.1109/LRA.2018.2869640
   Raghavan AN, 2010, IEEE INT CONF ROBOT, V0, PP4391, DOI 10.1109/ROBOT.2010.5509232
   Ran T, 2021, ISA T, V109, P389, DOI 10.1016/j.isatra.2020.10.023
   Ren MY, 2017, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.1611.04520
   Rodrigues M. L., 2012, 2012 BRAZILIAN ROBOTICS SYMPOSIUM AND LATIN AMERICAN ROBOTICS SYMPOSIUM (SBR-LARS 2012), V0, PP79, DOI 10.1109/SBR-LARS.2012.20
   Saravanan M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, V0, P0
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662
   Sibai F.N., 2012, P 2012 INT C COMPUTE, V0, P1
   Simonyan K, 2015, ARXIV, V0, P0
   Song ZL, 2011, COMM COM INF SC, V164, P198
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wu H, 2018, ARTIF LIFE ROBOT, V23, P373, DOI 10.1007/s10015-018-0449-7
   Yang J, 2018, ALGORITHMS, V11, P0, DOI 10.3390/a11030028
NR 33
TC 4
Z9 4
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2032-6653
EI 
J9 WORLD ELECTR VEHIC J
JI World Electr. Vehicle J.
PD SEP 15
PY 2021
VL 12
IS 3
BP 
EP 
DI 10.3390/wevj12030134
PG 22
WC Engineering, Electrical & Electronic; Transportation Science & Technology
SC Engineering; Transportation
GA VM0QH
UT WOS:000937526300046
DA 2023-04-26
ER

PT J
AU Li, ZN
   Sun, HY
   Gao, YL
   Wang, J
AF Li, Zhenni
   Sun, Haoyi
   Gao, Yuliang
   Wang, Jiao
TI A Residual Network and FPGA Based Real-Time Depth Map Enhancement System
SO ENTROPY
LA English
DT Article
DE depth map enhancement; residual network; FPGA; ToF
AB Depth maps obtained through sensors are often unsatisfactory because of their low-resolution and noise interference. In this paper, we propose a real-time depth map enhancement system based on a residual network which uses dual channels to process depth maps and intensity maps respectively and cancels the preprocessing process, and the algorithm proposed can achieve real-time processing speed at more than 30 fps. Furthermore, the FPGA design and implementation for depth sensing is also introduced. In this FPGA design, intensity image and depth image are captured by the dual-camera synchronous acquisition system as the input of neural network. Experiments on various depth map restoration shows our algorithms has better performance than existing LRMC, DE-CNN and DDTF algorithms on standard datasets and has a better depth map super-resolution, and our FPGA completed the test of the system to ensure that the data throughput of the USB 3.0 interface of the acquisition system is stable at 226 Mbps, and support dual-camera to work at full speed, that is, 54 fps@ (1280 x 960 + 328 x 248 x 3).
C1 [Li, Zhenni; Sun, Haoyi; Wang, Jiao] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Gao, Yuliang] Nankai Univ, Coll Artificial Intelligence, Tianjin 300071, Peoples R China.
C3 Northeastern University - China; Nankai University
RP Wang, J (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
EM lizhenni@ise.neu.edu.cn; haoyisun@outlook.com; gaoyuliang@mail.nankai.edu.cn; wangjiao@ise.neu.edu.cn
FU Fundamental Research Funds for the Central Universities [2020GFYD011, 2020 GFZD008]
CR Ahmad A, 2019, DES AUT TEST EUROPE, V0, PP1106, DOI 10.23919/DATE.2019.8715272
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cao YZH, 2017, IEEE T IMAGE PROCESS, V26, P836, DOI 10.1109/TIP.2016.2621673
   Chen BL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P1473
   Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755
   Cypress, 2018, DES EZ U SB FX3 SLAV, V0, P0
   Dong HW, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON CYBERNETICS, V0, P184, DOI 10.1109/CRC.2017.43
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He L, 2018, IEEE T IMAGE PROCESS, V27, P4676, DOI 10.1109/TIP.2018.2832296
   Hou Y., 1900, P213, V0, P0, DOI DOI 10.1109/ICCRE.2017.7935072
   Huanshihong Deng, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS, V0, P174, DOI 10.1109/ICTA50426.2020.9332014
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Korinevskaya A, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), V0, PP117, DOI 10.1109/ISMAR-Adjunct.2018.00047
   Kumari S., 2019, P 2019 IEEE INT C IM, V0, P0
   Lee Y, 2019, INT C CONTR AUTOMAT, V0, PP1622, DOI 10.23919/ICCAS47443.2019.8971538
   Li B., 2017, ARXIV2017170500534, V0, P0
   Li LH, 2015, IEEE IMAGE PROC, V0, PP556, DOI 10.1109/ICIP.2015.7350860
   Li WJ, 2018, INT SYM COMPUT INTEL, V0, PP111, DOI 10.1109/ISCID.2018.10126
   Li Z., 2020, ARXIV2020201102910, V0, P0
   Lu S, 2014, PROC CVPR IEEE, V0, PP3390, DOI 10.1109/CVPR.2014.433
   Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6
   Manabe T, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), V0, P299
   Mandal S, 2017, IEEE T IMAGE PROCESS, V26, P119, DOI 10.1109/TIP.2016.2621410
   Ni M, 2017, IEEE ACCESS, V5, P26666, DOI 10.1109/ACCESS.2017.2773141
   Pfeifer M, 2019, ANN IEEE SYM FIELD P, V0, PP118, DOI 10.1109/FCCM.2019.00026
   Prashant GP, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), V0, P185
   Qian TT, 2018, 2018 3RD IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS AND MICROSYSTEMS (ICICM), V0, PP362, DOI 10.1109/ICAM.2018.8596436
   Raghunandan A, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), V0, P563
   Schlemper J, 2018, IEEE T MED IMAGING, V37, P491, DOI 10.1109/TMI.2017.2760978
   Shandilya R., 2017, P INT C TRENDS EL IN, V0, PP1010, DOI 10.1109/ICOEI.2017.8300860
   Siddiqui S.A., 2020, ARXIV2020201209667, V0, P0
   Simonyan K, 2015, ARXIV, V0, P0
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Wang J, 2015, J OPER RES SOC CHINA, V3, P99, DOI 10.1007/s40305-015-0074-2
   Xilinx, 2017, FIFO GEN LOGICORE IP, V0, P0
   Xilinx, 2016, AXI IIC BUS INTERFAC, V0, P0
   Xilinx, 2019, ULTRASCALE ARCHITECT, V0, P0
   Xu D, 2018, IEEE IMAGE PROC, V0, PP2187, DOI 10.1109/ICIP.2018.8451042
   Yang S, 2018, IEEE T CYBERNETICS, V48, P399, DOI 10.1109/TCYB.2016.2638856
   Yuhua Jiang, 2020, 2020 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE, V0, P14, DOI 10.1109/ISPDS51347.2020.00011
   Zhang X, 2016, INT CONF ACOUST SPEE, V0, PP2499, DOI 10.1109/ICASSP.2016.7472127
   Zhou WT, 2017, INT CONF ACOUST SPEE, V0, PP1457, DOI 10.1109/ICASSP.2017.7952398
   Zuo YF, 2021, IEEE T MULTIMEDIA, V23, P772, DOI 10.1109/TMM.2020.2987706
NR 45
TC 0
Z9 0
U1 4
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD MAY 15
PY 2021
VL 23
IS 5
BP 
EP 
DI 10.3390/e23050546
PG 23
WC Physics, Multidisciplinary
SC Physics
GA SH1CK
UT WOS:000653873600001
PM 33924967
DA 2023-04-26
ER

PT J
AU Zitzlsberger, G
   Podhoranyi, M
   Svaton, V
   Lazecky, M
   Martinovic, J
AF Zitzlsberger, Georg
   Podhoranyi, Michal
   Svaton, Vaclav
   Lazecky, Milan
   Martinovic, Jan
TI Neural Network-Based Urban Change Monitoring with Deep-Temporal Multispectral and SAR Remote Sensing Data
SO REMOTE SENSING
LA English
DT Article
DE urban change detection; continuous urban monitoring; neural network; SAR; optical multispectral; deep-temporal; ERS-1; ERS-2; Landsat 5 TM; Sentinel 1; Sentinel 2
ID built-up index; impervious surface; extraction; land; classification; framework; space; pixel; area
AB Remote-sensing-driven urban change detection has been studied in many ways for decades for a wide field of applications, such as understanding socio-economic impacts, identifying new settlements, or analyzing trends of urban sprawl. Such kinds of analyses are usually carried out manually by selecting high-quality samples that binds them to small-scale scenarios, either temporarily limited or with low spatial or temporal resolution. We propose a fully automated method that uses a large amount of available remote sensing observations for a selected period without the need to manually select samples. This enables continuous urban monitoring in a fully automated process. Furthermore, we combine multispectral optical and synthetic aperture radar (SAR) data from two eras as two mission pairs with synthetic labeling to train a neural network for detecting urban changes and activities. As pairs, we consider European Remote Sensing (ERS-1/2) and Landsat 5 Thematic Mapper (TM) for 1991-2011 and Sentinel 1 and 2 for 2017-2021. For every era, we use three different urban sites-Limassol, Rotterdam, and Liege-with at least 500 km(2) each, and deep observation time series with hundreds and up to over a thousand of samples. These sites were selected to represent different challenges in training a common neural network due to atmospheric effects, different geographies, and observation coverage. We train one model for each of the two eras using synthetic but noisy labels, which are created automatically by combining state-of-the-art methods, without the availability of existing ground truth data. To combine the benefit of both remote sensing types, the network models are ensembles of optical- and SAR-specialized sub-networks. We study the sensitivity of urban and impervious changes and the contribution of optical and SAR data to the overall solution. Our implementation and trained models are available publicly to enable others to utilize fully automated continuous urban monitoring.
C1 [Zitzlsberger, Georg; Podhoranyi, Michal; Svaton, Vaclav; Lazecky, Milan; Martinovic, Jan] VSB Tech Univ Ostrava, IT4Innovat, Ostrava 70800, Czech Republic.
   [Lazecky, Milan] Univ Leeds, Sch Earth & Environm, Leeds LS2 9JT, W Yorkshire, England.
C3 Technical University of Ostrava; University of Leeds
RP Zitzlsberger, G (corresponding author), VSB Tech Univ Ostrava, IT4Innovat, Ostrava 70800, Czech Republic.
EM georg.zitzlsberger@vsb.cz
FU ESA via the Blockchain ENabled DEep Learning for Space Data (BLENDED) project [4000129481/19/I-IT4I]; Ministry of Education, Youth and Sports from the National Programme of Sustainability (NPS II) project "IT4Innovations excellence in science" [LQ1602]; Ministry of Education, Youth and Sports of the Czech Republic [90140, OPEN-21-31]
CR [Anonymous], 2018, CORR, V0, P0
   Ansari RA, 2020, REMOTE SENS APPL, V20, P0, DOI 10.1016/j.rsase.2020.100418
   Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Benedetti A, 2018, INT GEOSCI REMOTE SE, V0, P1962
   Canty MJ, 2008, REMOTE SENS ENVIRON, V112, P1025, DOI 10.1016/j.rse.2007.07.013
   Chen J., 2016, P WORKSH TRACK INT C, V0, P0
   Chen JY, 2020, EUR J REMOTE SENS, V53, P274, DOI 10.1080/22797254.2020.1820383
   Chen JY, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.016502
   Chen THK, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112096
   Conradsen K, 2016, IEEE T GEOSCI REMOTE, V54, P3007, DOI 10.1109/TGRS.2015.2510160
   Daudt RC, 2018, IEEE IMAGE PROC, V0, PP4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, V0, P2115
   Demir I, 2018, IEEE COMPUT SOC CONF, V0, PP172, DOI 10.1109/CVPRW.2018.00031
   Deng CB, 2020, REMOTE SENS ENVIRON, V238, P0, DOI 10.1016/j.rse.2018.10.011
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Esch T, 2020, INT J DIGIT EARTH, V13, P136, DOI 10.1080/17538947.2018.1548655
   Esch T, 2017, ISPRS J PHOTOGRAMM, V134, P30, DOI 10.1016/j.isprsjprs.2017.10.012
   Estoque RC, 2015, ECOL INDIC, V56, P205, DOI 10.1016/j.ecolind.2015.03.037
   Faridatul MI, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7120453
   Fisher P, 1997, INT J REMOTE SENS, V18, P679, DOI 10.1080/014311697219015
   Gal Yarin, 2016, ADV NEURAL INFORM PR, V2016, P1019
   Glorot X., 2011, P 14 INT C ART INT S, V0, P315
   Gomez-Chova L, 2006, PATTERN RECOGN LETT, V27, P234, DOI 10.1016/j.patrec.2005.08.004
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Guha S, 2021, QUATERN INT, V575, P249, DOI 10.1016/j.quaint.2020.06.041
   Huang B., 2018, ARXIV180512219, V0, P0
   Huang B., 2019, ARXIV180512219, V0, P0
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Jafari M, 2016, EUR J REMOTE SENS, V49, P513, DOI 10.5721/EuJRS20164927
   Jiang M, 2020, ISPRS J PHOTOGRAMM, V169, P93, DOI 10.1016/j.isprsjprs.2020.08.023
   Jing CB, 2021, REMOTE SENS ENVIRON, V255, P0, DOI 10.1016/j.rse.2021.112293
   Ju C, 2018, J APPL STAT, V45, P2800, DOI 10.1080/02664763.2018.1441383
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   King MD, 2013, IEEE T GEOSCI REMOTE, V51, P3826, DOI 10.1109/TGRS.2012.2227333
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kundu K, 2020, J INDIAN SOC REMOTE, V48, P1535, DOI 10.1007/s12524-020-01177-6
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lehner A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020173
   Lu DS, 2011, ISPRS J PHOTOGRAMM, V66, P298, DOI 10.1016/j.isprsjprs.2010.10.010
   Ma J, 2021, MED IMAGE ANAL, V71, P0, DOI 10.1016/j.media.2021.102035
   Manzoni M, 2021, REMOTE SENS ENVIRON, V253, P0, DOI 10.1016/j.rse.2020.112152
   Marconcini M, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-00580-5
   Mitra D, 2018, APPL GEOGR, V97, P109, DOI 10.1016/j.apgeog.2018.04.012
   Moreira A, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2248301
   Muro J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100795
   Nguyen L., 2019, J AMBIENT INTELL HUM, V0, PP1, DOI 10.1007/S12652-019-01276-4
   Nguyen T., 2020, P INT C LEARN REPR I, V0, P0
   Nielsen AA, 2017, INT GEOSCI REMOTE SE, V0, PP3901, DOI 10.1109/IGARSS.2017.8127854
   Pandey D, 2020, ADV SPACE RES, V66, P1829, DOI 10.1016/j.asr.2020.06.038
   Patra S, 2007, LECT NOTES COMPUT SC, V4815, P161
   Qin YW, 2017, ISPRS J PHOTOGRAMM, V124, P89, DOI 10.1016/j.isprsjprs.2016.12.011
   Reina GA, 2020, FRONT NEUROSCI-SWITZ, V14, P0, DOI 10.3389/fnins.2020.00065
   Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001
   Roy M, 2014, IEEE GEOSCI REMOTE S, V11, P49, DOI 10.1109/LGRS.2013.2245855
   Shahroudnejad A., 2021, ARXIV2021210201792, V0, P0
   Shi X., 2015, ADV NEURAL INFORM PR, V28, P802, DOI 10.5555/2969239.2969329
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sinha S, 2020, ADV SPACE RES, V66, P1372, DOI 10.1016/j.asr.2020.05.040
   Song H., 2020, ARXIV200708199, V0, P0
   Susaki J, 2014, REMOTE SENS ENVIRON, V155, P334, DOI 10.1016/j.rse.2014.09.006
   Valentin B, 2021, P 2021 C BIG DATA SP, V0, PP97, DOI 10.2760/125905.
   Wania A, 2014, APPL GEOGR, V46, P35, DOI 10.1016/j.apgeog.2013.10.005
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Xu HQ, 2010, PHOTOGRAMM ENG REM S, V76, P557, DOI 10.14358/PERS.76.5.557
   Yoo C, 2019, ISPRS J PHOTOGRAMM, V157, P155, DOI 10.1016/j.isprsjprs.2019.09.009
   You YN, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152460
   Zhang HS, 2016, LANDSCAPE URBAN PLAN, V151, P55, DOI 10.1016/j.landurbplan.2016.03.009
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhang SH, 2018, IEEE ACCESS, V6, P41224, DOI 10.1109/ACCESS.2018.2857405
   Zhong JL, 2020, J CLEAN PROD, V259, P0, DOI 10.1016/j.jclepro.2020.120754
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zinkevich M., 2010, NEURAL INFORM PROCES, V0, P0
NR 75
TC 5
Z9 5
U1 7
U2 31
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG 15
PY 2021
VL 13
IS 15
BP 
EP 
DI 10.3390/rs13153000
PG 31
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TW3JO
UT WOS:000682301100001
DA 2023-04-26
ER

PT J
AU Ma, XJ
   Ji, KF
   Xiong, BL
   Zhang, LB
   Feng, SJ
   Kuang, GY
AF Ma, Xiaojie
   Ji, Kefeng
   Xiong, Boli
   Zhang, Linbin
   Feng, Sijia
   Kuang, Gangyao
TI Light-YOLOv4: An Edge-Device Oriented Target Detection Method for Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Object detection; Image edge detection; Training; Remote sensing; Detectors; Feature extraction; Quantization (signal); Edge device; model compression; NVIDIA Jetson TX2; remote sensing; target detection; YOLOv4
ID model compression; vehicle detection; neural-network; deep
AB Most deep-learning-based target detection methods have high computational complexity and memory consumption, and they are difficult to deploy on edge devices with limited computing resources and memory. To tackle this problem, this article proposes to learn a lightweight detector named Light-YOLOv4, and it is obtained from YOLOv4 through model compression. To this end, first, we perform sparsity training by applying L1 regularization to the channel scaling factors, so the less important channels and layers can be found. Second, channel pruning and layer pruning are enforced on the network to prune the less important parts, which could significantly reduce network's width and depth. Third, the pruned model is retrained with a knowledge distillation method to improve the detection accuracy. Fourth, the model is quantized from FP32 to FP16, and it could further accelerate the model with almost no loss of detection accuracy. Finally, to evaluate Light-YOLOv4's performance on edge devices, Light-YOLOv4 is deployed on NVIDIA Jetson TX2. Experiments on the SAR ship detection dataset (SSDD) demonstrate that the model size, parameter size, and FLOPs of Light-YOLOv4 have been reduced by 98.63%, 98.66%, and 91.30% compared with YOLOv4, and the detection speed has been increased to 4.2x. While the detection accuracy of Light-YOLOv4 is only slightly reduced, for example, the mAP has only reduced by 0.013. Besides, experiments on the Gaofen Airplane dataset also prove the feasibility of Light-YOLOv4. Moreover, compared with other state-of-the-art methods, such as SSD and FPN, Light-YOLOv4 is more suitable for edge devices.
C1 [Ma, Xiaojie; Ji, Kefeng; Xiong, Boli; Zhang, Linbin; Feng, Sijia; Kuang, Gangyao] Natl Univ Def Technol, Coll Elect Sci, State Key Lab Complex Electromagnet Environm Effe, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China
RP Ji, KF (corresponding author), Natl Univ Def Technol, Coll Elect Sci, State Key Lab Complex Electromagnet Environm Effe, Changsha 410073, Peoples R China.
EM mxj286@foxmail.com; jikefeng@nudt.edu.cn; bolixiong@qq.com; zlbnudt@163.com; fengsijia12@nudt.edu.cn; kuangyeats@hotmail.com
FU National Natural Science Foundation of China [62001480]
CR Amani M, 2020, IEEE J-STARS, V13, P5326, DOI 10.1109/JSTARS.2020.3021052
   An QZ, 2019, IEEE T GEOSCI REMOTE, V57, P8333, DOI 10.1109/TGRS.2019.2920534
   [Anonymous], 2020, 2020 GAOFEN CHALLENG, V0, P0
   Bouguettaya A, 2022, IEEE T NEUR NET LEAR, V33, P6047, DOI 10.1109/TNNLS.2021.3080276
   Chen HY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101618
   Chen WY, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3074415
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Cui ZY, 2021, IEEE T GEOSCI REMOTE, V59, P379, DOI 10.1109/TGRS.2020.2997200
   Cui ZY, 2019, IEEE T GEOSCI REMOTE, V57, P8983, DOI 10.1109/TGRS.2019.2923988
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Dong RC, 2019, IEEE T GEOSCI REMOTE, V57, P8534, DOI 10.1109/TGRS.2019.2921396
   Du SJ, 2021, IEEE ACCESS, V9, P25671, DOI 10.1109/ACCESS.2021.3057723
   Gao Han, 2021, JOURNAL OF SOFTWARE, V32, P68, DOI 10.13328/j.cnki.jos.006096
   Gao Z, 2019, IEEE J-STARS, V12, P3552, DOI 10.1109/JSTARS.2019.2933501
   Guo JY, 2021, IEEE T CIRC SYST VID, V31, P1114, DOI 10.1109/TCSVT.2020.2996231
   Hinton G., 2015, ARXIV PREPRINT ARXIV, V0, P0
   Jeong E, 2022, IEEE EMBED SYST LETT, V14, P15, DOI 10.1109/LES.2021.3087707
   Khayrov E. M., 2019, P 21 INT C NEUR, V0, P230
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Li Jianwei, 2018, SYSTEMS ENGINEERING AND ELECTRONICS, V40, P1953, DOI 10.3969/j.issn.1001-506X.2018.09.09
   Li QP, 2019, IEEE T GEOSCI REMOTE, V57, P5028, DOI 10.1109/TGRS.2019.2895362
   Li YD, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3038901
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE I CONF COMP VIS, V0, PP2755, DOI 10.1109/ICCV.2017.298
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Minaeian S, 2018, IEEE T INTELL TRANSP, V19, P497, DOI 10.1109/TITS.2017.2782790
   Nascimento JMP, 2020, IEEE J-STARS, V13, P3701, DOI 10.1109/JSTARS.2020.2996679
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), V0, PP165, DOI 10.1109/ZINC50678.2020.9161446
   Redmon J, 2018, ABS180402767 CORR, V0, P0, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Romero A., 2014, ARXIV14126550, V0, P0
   [孙显 Sun Xian], 2020, 中国图象图形学报 JOURNAL OF IMAGE AND GRAPHICS, V25, P1719
   Sun ZZ, 2021, IEEE J-STARS, V14, P7799, DOI 10.1109/JSTARS.2021.3099483
   TensorRT NVIDIA, 2019, NVID DEEP LEARN SDK, V0, P0
   Verma G, 2021, 2021 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), V0, PP858, DOI 10.1109/IPDPSW52791.2021.00128
   Wang CY, 2020, IEEE COMPUT SOC CONF, V0, PP1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang H, 2019, IEEE INTEL TRANSP SY, V11, P82, DOI 10.1109/MITS.2019.2903518
   Wang XY, 2020, INT GEOSCI REMOTE SE, V0, PP1244, DOI 10.1109/IGARSS39084.2020.9324162
   Wu JX, 2016, PROC CVPR IEEE, V0, PP4820, DOI 10.1109/CVPR.2016.521
   Xiao D, 2019, IEEE ACCESS, V7, P123757, DOI 10.1109/ACCESS.2019.2928603
   Xu YH, 2020, IEEE T MULTIMEDIA, V22, P1874, DOI 10.1109/TMM.2019.2949857
   Yao Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070762
   Zalpour M, 2020, INT J REMOTE SENS, V41, P2239, DOI 10.1080/01431161.2019.1685720
   Zhang F, 2020, REMOTE SENS LETT, V11, P485, DOI 10.1080/2150704X.2020.1730472
   Zhang PY, 2019, IEEE INT CONF COMP V, V0, PP37, DOI 10.1109/ICCVW.2019.00011
   Zhao Y, 2020, IEEE J-STARS, V13, P2738, DOI 10.1109/JSTARS.2020.2997081
   Zhao Y, 2020, IEEE T COGN COMMUN, V6, P1146, DOI 10.1109/TCCN.2020.2999479
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou M, 2020, IEEE GEOSCI REMOTE S, V17, P381, DOI 10.1109/LGRS.2019.2924822
   Zhu XX, 2021, IEEE GEOSC REM SEN M, V9, P143, DOI 10.1109/MGRS.2020.3046356
NR 56
TC 12
Z9 12
U1 18
U2 76
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10808
EP 10820
DI 10.1109/JSTARS.2021.3120009
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WR7ZC
UT WOS:000714714100003
DA 2023-04-26
ER

PT J
AU Kim, HG
   Hong, S
   Chon, TS
   Joo, GJ
AF Kim, Hyo Gyeom
   Hong, Sungwon
   Chon, Tae-Soo
   Joo, Gea-Jae
TI Spatial patterning of chlorophyll a and water-quality measurements for determining environmental thresholds for local eutrophication in the Nakdong River basin
SO ENVIRONMENTAL POLLUTION
LA English
DT Article
DE Geo-SOM; Linear mixed model; Biological threshold; Phosphorus; Regional variation; Random effect
ID phosphorus relationships; nutrient relationships; land-use; nitrogen; lake; model; classification; downstream; cluster; blooms
AB Management of water-quality in a river ecosystem needs to be focused on susceptible regions to eutrophication based on proper measurements. The stress response relationships between nutrients and primary productivity of phytoplankton allow the derivation of ecologically acceptable thresholds of stressors under field conditions. However, spatio-temporal variations in heterogeneous environmental conditions have hindered the development of locally applicable criteria. To address these issues, we utilized a combination of a geographically specialized artificial neural network (Geo-SOM, geo-self-organizing map) and linear mixed-effect models (LMMs). The model was applied to a 24-month dataset of 54 stations that spanned a wide spatial gradient in the Nakdong River basin. The Geo-SOM classified 1286 observations in the basin into 13 clusters that were regionally and seasonally distinct. Inclusion of the random effects of Geo-SOM clustering improved the performance of each LMM, which suggests that there were significant spatio-temporal variations in the Chla-stressor relationships. These variations arise owing to differences in background seasonality and the effects of local pollutant variables and land-use patterns. Among the 16 environmental variables, the major stressors for Chla were total phosphate (TP) as a nutrient and biological oxygen demand (BOD) as a non-nutrient according to the results of both Geo-SOM and LMM analyses. Based on LMMs with the random effect of the Geo-SOM clusters on the intercept and the slope, we can propose recommended thresholds for TP (18.5 mu g L-1) and BOD (1.6 mg L-1) in the Nakdong River. The combined method of LMM and Geo-SOM will be useful in guiding appropriate local water-quality-management strategies and in the global development of large-scale nutrient criteria. (C) 2020 Published by Elsevier Ltd.
C1 [Kim, Hyo Gyeom; Hong, Sungwon; Chon, Tae-Soo; Joo, Gea-Jae] Pusan Natl Univ, Dept Biol Sci, Busan 46241, South Korea.
   [Hong, Sungwon] Kangwon Natl Univ, Grad Sch, Dept Forest Environm Syst, Chunchon 24341, South Korea.
   [Chon, Tae-Soo] Ecol & Future Res Assoc, Busan 46228, South Korea.
C3 Pusan National University; Kangwon National University
RP Joo, GJ (corresponding author), Pusan Natl Univ, Dept Biol Sci, Busan 46241, South Korea.
EM gjjoo@pusan.ac.kr
FU NRF (National Research Foundation of Korea) [NRF-2016R1D1A1B01009492]; National Research Foundation of Korea [4199990314285] Funding Source: Korea Institute of Science & Technology Information (KISTI), National Science & Technology Information Service (NTIS)
CR [Anonymous], 2018, LANG ENV STAT COMP, V0, P0
   *ANZECC, 2000, AUSTR NZ GUID FRESH, V0, P0
   Astel A, 2007, WATER RES, V41, P4566, DOI 10.1016/j.watres.2007.06.030
   Bacao F, 2004, LECT NOTES COMPUT SC, V3234, P22
   Bowling LC, 2013, HARMFUL ALGAE, V30, P27, DOI 10.1016/j.hal.2013.08.002
   Burnham K.P., 2002, MODEL SELECTION MULT, V2, P0
   Camargo JA, 2005, WATER RES, V39, P3376, DOI 10.1016/j.watres.2005.05.048
   Cardigos P, 2009, ASSER INT SPORT LAW, V0, PP451, DOI 10.1007/978-90-6704-487-5_28
   Chambers PA, 2012, J ENVIRON QUAL, V41, P7, DOI 10.2134/jeq2010.0273
   Chon TS, 2011, ECOL INFORM, V6, P50, DOI 10.1016/j.ecoinf.2010.11.002
   Clement F, 2017, ECOL INDIC, V72, P627, DOI 10.1016/j.ecolind.2016.09.001
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dodds W.K., 2009, EUTROPHICATION US FR, V0, P0
   Dodds WK, 2016, INLAND WATERS, V6, P155, DOI 10.5268/IW-6.2.909
   Dodds WK, 1998, WATER RES, V32, P1455, DOI 10.1016/S0043-1354(97)00370-9
   Dodds WK, 2002, CAN J FISH AQUAT SCI, V59, P865, DOI 10.1139/F02-063
   Ensign SH, 2001, WATER RES, V35, P3381, DOI 10.1016/S0043-1354(01)00060-4
   Filstrup CT, 2014, LIMNOL OCEANOGR, V59, P1691, DOI 10.4319/lo.2014.59.5.1691
   Haggard BE, 2013, J ENVIRON QUAL, V42, P437, DOI 10.2134/jeq2012.0181
   Hong S, 2020, ECOL INDIC, V109, P0, DOI 10.1016/j.ecolind.2019.105844
   Juha Vesanto, 1999, P MATLAB DSP C ESP F, V0, P16
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Kim HG, 2019, ECOL MODEL, V398, P67, DOI 10.1016/j.ecolmodel.2019.02.003
   Kim M, 2011, ASIAN J TECHNOL INNO, V19, P67, DOI 10.1080/19761597.2011.578426
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Liang XQ, 2014, ENVIRON POLLUT, V192, P251, DOI 10.1016/j.envpol.2014.04.007
   Liu J, 2018, LANDSCAPE URBAN PLAN, V176, P51, DOI 10.1016/j.landurbplan.2018.04.006
   Liu WZ, 2012, HYDROL PROCESS, V26, P570, DOI 10.1002/hyp.8157
   Lohman K, 1999, CAN J FISH AQUAT SCI, V56, P124, DOI 10.1139/cjfas-56-1-124
   Milosevic D, 2016, ECOL INDIC, V61, P777, DOI 10.1016/j.ecolind.2015.10.029
   OHare MT, 2018, FRONT PLANT SCI, V9, P0, DOI 10.3389/fpls.2018.00451
   Paerl HW, 2008, SCIENCE, V320, P57, DOI 10.1126/science.1155398
   Phillips G, 2008, AQUAT ECOL, V42, P213, DOI 10.1007/s10452-008-9180-0
   RECKHOW KH, 1993, ECOL MODEL, V70, P35, DOI 10.1016/0304-3800(93)90071-Y
   Royer TV, 2008, J ENVIRON QUAL, V37, P437, DOI 10.2134/jeq2007.0344
   Son Heejong, 2013, JOURNAL OF KOREAN SOCIETY OF ENVIRONMENTAL ENGINEERS 대한환경공학회지, V35, P430
   Soranno PA, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0135454
   Sun RH, 2013, J AM WATER RESOUR AS, V49, P741, DOI 10.1111/jawr.12033
   Taranu ZE, 2008, ECOSYSTEMS, V11, P715, DOI 10.1007/s10021-008-9153-0
   Ultsch A., 2005, P EUR S ART NEUR NET, V0, P1
   *USEPA, 2006, EPA641B06002 OFF WAT, V0, P0
   Vanormelingen P, 2008, FRESHWATER BIOL, V53, P2170, DOI 10.1111/j.1365-2427.2008.02040.x
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   Vyverman W, 2007, ECOLOGY, V88, P1924, DOI 10.1890/06-1564.1
   Wagenmakers EJ, 2004, PSYCHON B REV, V11, P192, DOI 10.3758/BF03206482
   Wagner T, 2011, FRESHWATER BIOL, V56, P1811, DOI 10.1111/j.1365-2427.2011.02621.x
   Yu Q, 2015, WATER-SUI, V7, P2184, DOI 10.3390/w7052184
   Zuur Alain F., 2009, P1, V0, P0
NR 49
TC 15
Z9 16
U1 2
U2 23
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0269-7491
EI 1873-6424
J9 ENVIRON POLLUT
JI Environ. Pollut.
PD JAN 1
PY 2021
VL 268
IS 
BP 
EP 
DI 10.1016/j.envpol.2020.115701
PG 11
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA PH6XN
UT WOS:000600553000107
PM 33045591
DA 2023-04-26
ER

PT J
AU Adrian, J
   Sagan, V
   Maimaitijiang, M
AF Adrian, Jarrett
   Sagan, Vasit
   Maimaitijiang, Maitiniyazi
TI Sentinel SAR-optical fusion for crop type mapping using deep learning and Google Earth Engine
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE 3D U-Net; Denoising neural networks; Sentinel-1; Sentinel-2; Data fusion
ID instance segmentation; land-cover; classification; rapeseed; network
AB Accurate crop type mapping provides numerous benefits for a deeper understanding of food systems and yield prediction. Ever-increasing big data, easy access to high-resolution imagery, and cloud-based analytics platforms like Google Earth Engine have drastically improved the ability for scientists to advance data-driven agriculture with improved algorithms for crop type mapping using remote sensing, computer vision, and machine learning. Crop type mapping techniques mainly relied on standalone SAR and optical imagery, few studies investigated the potential of SAR-optical data fusion, coupled with virtual constellation, and 3-dimensional (3D) deep learning networks. To this extent, we use a deep learning approach that utilizes the denoised backscatter and texture information from multi-temporal Sentinel-1 SAR data and the spectral information from multi-temporal optical Sentinel-2 data for mapping ten different crop types, as well as water, soil and urban area. Multi-temporal Sentinel-1 data was fused with multi-temporal optical Sentinel-2 data in an effort to improve classification accuracies for crop types. We compared the results of the 3D U-Net to the state-of-the-art deep learning networks, including SegNet and 2D U-Net, as well as commonly used machine learning method such as Random Forest. The results showed (1) fusing multi-temporal SAR and optical data yields higher training overall accuracies (OA) (3D U-Net 0.992, 2D U-Net 0.943, SegNet 0.871) and testing OA (3D U-Net 0.941, 2D U-Net 0.847, SegNet 0.643) for crop type mapping compared to standalone multi-temporal SAR or optical data (2) optical data fused with denoised SAR data via a denoising convolution neural network (OA 0.912) performed better for crop type mapping compared to optical data fused with boxcar (OA 0.880), Lee (OA 0.881), and median (OA 0.887) filtered SAR data and (3) 3D convolutional neural networks perform better than 2D convolutional neural networks for crop type mapping (SAR OA 0.912, optical OA 0.937, fused OA 0.992).
C1 [Adrian, Jarrett; Sagan, Vasit; Maimaitijiang, Maitiniyazi] St Louis Univ, Geospatial Inst, 3694 West Pine Mall, St Louis, MO 63108 USA.
   [Adrian, Jarrett; Sagan, Vasit; Maimaitijiang, Maitiniyazi] St Louis Univ, Dept Earth & Atmospher Sci, 3642 Lindell Blvd, St Louis, MO 63108 USA.
C3 Saint Louis University; Saint Louis University
RP Sagan, V (corresponding author), St Louis Univ, Geospatial Inst, 3694 West Pine Mall, St Louis, MO 63108 USA.
EM vasit.sagan@slu.edu
FU National Science Foundation [IIA-1355406, IIA-1430427]; National Aeronautics and Space Administration [NNX15AK03H]
CR [Anonymous], 2001, 18 INT C MACHINE LEA, V0, P0
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Belgiu M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070818
   Bertoldi G, 2014, J HYDROL, V516, P245, DOI 10.1016/j.jhydrol.2014.02.018
   Blaes X, 2005, REMOTE SENS ENVIRON, V96, P352, DOI 10.1016/j.rse.2005.03.010
   Braun A, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040359
   Buckley C, 2013, ENVIRON SCI POLICY, V25, P118, DOI 10.1016/j.envsci.2012.10.002
   Chen K, 2019, PROC CVPR IEEE, V0, PP4969, DOI 10.1109/CVPR.2019.00511
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cowton J, 2019, IEEE ACCESS, V7, P108049, DOI 10.1109/ACCESS.2019.2933060
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Tran D, 2015, IEEE I CONF COMP VIS, V0, PP4489, DOI 10.1109/ICCV.2015.510
   Du ZR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070888
   Dwivedi S, 2019, COMPUT VIS IMAGE PRO, V0, P1
   Everitt BS, 2010, CAMBRIDGE DICT STAT, V0, P0, DOI DOI 10.1017/CBO9780511779633
   Forkuor G, 2014, REMOTE SENS-BASEL, V6, P6472, DOI 10.3390/rs6076472
   Fritz S, 2019, AGR SYST, V168, P258, DOI 10.1016/j.agsy.2018.05.010
   Fung A. K., 1994, MICROWAVE SCATTERING, V0, P0
   Gao H, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18093139
   Ghosh A, 2018, IEEE COMPUT SOC CONF, V0, PP252, DOI 10.1109/CVPRW.2018.00047
   Guo YQ, 2019, ISPRS J PHOTOGRAMM, V155, P187, DOI 10.1016/j.isprsjprs.2019.07.008
   Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481
   Hamwood J, 2018, BIOMED OPT EXPRESS, V9, P3049, DOI 10.1364/BOE.9.003049
   Huang XD, 2017, REMOTE SENS ENVIRON, V193, P11, DOI 10.1016/j.rse.2017.02.014
   ?i?ek O., 2016, INT C MED IM COMP CO, V0, PP424, DOI 10.1007/978-3-319-46723-8_49
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Jifara W, 2019, J SUPERCOMPUT, V75, P704, DOI 10.1007/s11227-017-2080-0
   Johnson DM, 2010, PHOTOGRAMM ENG REM S, V76, P1201
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lef`evre, 2016, AS C COMP VIS, V0, P1
   Li JJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10122036
   Li Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010067
   Liu YJ, 2019, IEEE T SYST MAN CY-S, V49, P2318, DOI 10.1109/TSMC.2018.2815560
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lussem U, 2016, INT ARCH PHOTOGRAMM, V41, P959, DOI 10.5194/isprsarchives-XLI-B8-959-2016
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071119
   Maimaitijiang M, 2017, ISPRS J PHOTOGRAMM, V134, P43, DOI 10.1016/j.isprsjprs.2017.10.011
   Mao X.J, 2016, NEURAL INF PROCESS S, V0, P1
   McNairn H, 2014, INT J APPL EARTH OBS, V28, P252, DOI 10.1016/j.jag.2013.12.015
   McNairn H, 2009, ISPRS J PHOTOGRAMM, V64, P434, DOI 10.1016/j.isprsjprs.2008.07.006
   Mercier A, 2020, ISPRS J PHOTOGRAMM, V163, P231, DOI 10.1016/j.isprsjprs.2020.03.009
   Mirsoleimani HR, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19143209
   Mirzaee S, 2014, INT ARCH PHOTOGRAMM, V40, P191, DOI 10.5194/isprsarchives-XL-2-W3-191-2014
   Moran MS, 1997, REMOTE SENS ENVIRON, V61, P319, DOI 10.1016/S0034-4257(97)00045-X
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Ndikumana E, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081217
   NOAA, 2020, CLIM COULMB MISS, V0, P0
   Orynbaikyzy A, 2019, INT J REMOTE SENS, V40, P6553, DOI 10.1080/01431161.2019.1569791
   Paloscia S, 2012, EUR J REMOTE SENS, V45, P99, DOI 10.5721/EuJRS20124510
   Pohl C, 2015, INT J IMAGE DATA FUS, V6, P3, DOI 10.1080/19479832.2014.998727
   Potlapally A, 2019, 2019 INT C CONT COMP, V0, P0
   Qazi WA, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.026038
   Qi Z, 2018, SENSORS-BASEL, V0, P4
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Rubel F, 2017, METEOROL Z, V26, P115, DOI 10.1127/metz/2016/0816
   Schmitt M, 2018, ISPRS ANN PHOTOGRAM, V0, P1
   Sidike P, 2019, REMOTE SENS ENVIRON, V221, P756, DOI 10.1016/j.rse.2018.11.031
   Sijbers J, 1996, MAGN RESON IMAGING, V14, P1157, DOI 10.1016/S0730-725X(96)00219-6
   Sonobe R, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101148
   Su H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060989
   Su H, 2019, INT GEOSCI REMOTE SE, V0, PP1454, DOI 10.1109/IGARSS.2019.8898573
   Suarez-Paniagua V, 2018, BMC BIOINFORMATICS, V19, P0, DOI 10.1186/s12859-018-2195-1
   Sukawattanavijit C, 2017, IEEE GEOSCI REMOTE S, V14, P284, DOI 10.1109/LGRS.2016.2628406
   Tin Kam Ho, 1995, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, V0, PP278, DOI 10.1109/ICDAR.1995.598994
   Torbick N, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071058
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   USDA, 2019, PUBL SOIL SURV MISS, V0, P0
   Van Tricht K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101642
   Veloso A, 2017, REMOTE SENS ENVIRON, V199, P415, DOI 10.1016/j.rse.2017.07.015
   Vescovi FD, 1999, ENVIRON MONIT ASSESS, V58, P133, DOI 10.1023/A:1006047906601
   Vreugdenhil M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091396
   Waldhoff G, 2017, INT J APPL EARTH OBS, V61, P55, DOI 10.1016/j.jag.2017.04.009
   Wang C, 2019, ENTROPY-SWITZ, V21, P0, DOI 10.3390/e21020168
   Wang DQ, 2013, J INF SCI ENG, V29, P209
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Warth G, 2019, EUR J REMOTE SENS, V52, P322, DOI 10.1080/22797254.2019.1604083
   Wei S, 2019, SAR BIG DATA ERA, V2019, P1
   Wei SS, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010068
   Xu ZW, 2018, ISPRS J PHOTOGRAMM, V144, P423, DOI 10.1016/j.isprsjprs.2018.08.005
   Yekeen ST, 2020, ISPRS J PHOTOGRAMM, V167, P190, DOI 10.1016/j.isprsjprs.2020.07.011
   Zhang JH, 2020, MULTIMED TOOLS APPL, V79, P2427, DOI 10.1007/s11042-019-08302-9
   Zhao A, 2016, COMPUT SCI, V0, P1
   Zhou W, 2018, J SPECTROSC, V2018, P0, DOI 10.1155/2018/3918954
NR 89
TC 51
Z9 51
U1 63
U2 190
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY 15
PY 2021
VL 175
IS 
BP 215
EP 235
DI 10.1016/j.isprsjprs.2021.02.018
EA MAR 2021
PG 21
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT8HA
UT WOS:000644695700016
DA 2023-04-26
ER

PT J
AU Chung, S
   Abbott, LF
AF Chung, SueYeon
   Abbott, L. F.
TI Neural population geometry: An approach for understanding biological and artificial neural networks
SO CURRENT OPINION IN NEUROBIOLOGY
LA English
DT Article
ID dimensionality; information; systems; models; space
AB Advances in experimental neuroscience have transformed our ability to explore the structure and function of neural circuits. At the same time, advances in machine learning have unleashed the remarkable computational power of artificial neural networks (ANNs). While these two fields have different tools and applications, they present a similar challenge: namely, understanding how information is embedded and processed through high-dimensional representations to solve complex tasks. One approach to addressing this challenge is to utilize mathematical and computational tools to analyze the geometry of these high-dimensional representations, i.e., neural population geometry. We review examples of geometrical approaches providing insight into the function of biological and artificial neural networks: representation untangling in perception, a geometric theory of classification capacity, disentanglement, and abstraction in cognitive systems, topological representations underlying cognitive maps, dynamic untangling in motor systems, and a dynamical approach to cognition. Together, these findings illustrate an exciting trend at the intersection of machine learning, neuroscience, and geometry, in which neural population geometry provides a useful population-level mechanistic descriptor underlying task implementation. Importantly, geometric descriptions are applicable across sensory modalities, brain regions, network architectures, and timescales. Thus, neural population geometry has the potential to unify our understanding of structure and function in biological and artificial neural networks, bridging the gap between single neurons, population activities, and behavior.
C1 [Chung, SueYeon; Abbott, L. F.] Columbia Univ, Ctr Theoret Neurosci, New York, NY 10027 USA.
C3 Columbia University
RP Chung, S (corresponding author), Columbia Univ, Ctr Theoret Neurosci, New York, NY 10027 USA.
EM sueyeon.chung@columbia.edu
FU NSF NeuroNex Award [DBI-1707398]; Gatsby Charitable Foundation [GAT3708]; Simons Collaboration for the Global Brain
CR AMARI SI, 1977, BIOL CYBERN, V26, P175, DOI 10.1007/BF00365229
   Balasubramanian M, 2002, SCIENCE, V295, P0
   Barrett DGT, 2019, CURR OPIN NEUROBIOL, V55, P55, DOI 10.1016/j.conb.2019.01.007
   Bernardi S, 2020, CELL, V183, P954, DOI 10.1016/j.cell.2020.09.031
   Borg I., 2005, MODERN MULTIDIMENSIO, V0, P0
   Brunel N, 1998, NEURAL COMPUT, V10, P1731, DOI 10.1162/089976698300017115
   Chaudhuri R, 2019, NAT NEUROSCI, V22, P1512, DOI 10.1038/s41593-019-0460-x
   Chung S, 2020, COMPUTATIONAL SYSTEM, V0, P0
   Chung S, 2018, PHYS REV X, V8, P0, DOI 10.1103/PhysRevX.8.031003
   Chung S, 2016, PHYS REV E, V93, P0, DOI 10.1103/PhysRevE.93.060301
   Cohen U, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-020-14578-5
   COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137
   Dabaghian Y, 2014, ELIFE, V3, P0, DOI 10.7554/eLife.03476
   DiCarlo JJ, 2007, TRENDS COGN SCI, V11, P333, DOI 10.1016/j.tics.2007.06.010
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Ehrlich DB, 1900, V2021, V0, P0, DOI DOI 10.1101/2021.02.01.429156
   Eichenbaum H, 2018, NEUROSCI LETT, V680, P88, DOI 10.1016/j.neulet.2017.04.006
   Froudarakis Emmanouil, 2020, OBJECT MANIFOLD GEOM, V0, P0, DOI DOI 10.1101/2020.08.20.258798
   Gallego JA, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-06560-z
   Gallego JA, 2017, NEURON, V94, P978, DOI 10.1016/j.neuron.2017.05.025
   GARDNER E, 1988, J PHYS A-MATH GEN, V21, P257, DOI 10.1088/0305-4470/21/1/030
   Gigante S., 2019, ADV NEUR IN, V0, P1840
   Giusti C, 2015, P NATL ACAD SCI USA, V112, P13455, DOI 10.1073/pnas.1506407112
   Henaff OJ, 2019, NAT NEUROSCI, V22, P984, DOI 10.1038/s41593-019-0377-4
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Jazayeri M, 2021, CURR OPIN NEUROBIOL, V70, P113, DOI 10.1016/j.conb.2021.08.002
   Jazayeri M, 2017, NEURON, V93, P1003, DOI 10.1016/j.neuron.2017.02.019
   Jun JJ, 2017, NATURE, V551, P232, DOI 10.1038/nature24636
   Kell AJE, 2018, NEURON, V98, P630, DOI 10.1016/j.neuron.2018.03.044
   Khaligh-Razavi SM, 2014, PLOS COMPUT BIOL, V10, P0, DOI 10.1371/journal.pcbi.1003915
   Kobak D, 2019, ELIFE, V8, P0, DOI 10.7554/eLife.44526
   KOPELL N, 1986, COMMUN PUR APPL MATH, V39, P623, DOI 10.1002/cpa.3160390504
   Kriegeskorte N, 2015, ANNU REV VIS SCI, V1, P417, DOI 10.1146/annurev-vision-082114-035447
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Le QV, 2013, INT CONF ACOUST SPEE, V0, PP8595, DOI 10.1109/ICASSP.2013.6639343
   Low RJ, 2018, PROBING VARIABILITY, V0, P0, DOI DOI 10.1101/418939
   Mamou Jonathan, 2020, P 37 INT C MACH LEAR, V0, P6713
   Mante V, 2013, NATURE, V503, P78, DOI 10.1038/nature12742
   McInnes Leland, 2020, ARXIV, V0, P0, DOI DOI 10.48550/arXiv:1802.03426
   Nieh EH, 2021, NATURE, V595, P80, DOI 10.1038/s41586-021-03652-7
   Okazawa G, 2021, CELL, V184, P3748, DOI 10.1016/j.cell.2021.05.022
   Ramon y cajal s, 1995, HISTOLOGY NERVOUS SY, V0, P0
   Rigotti M, 2013, NATURE, V497, P585, DOI 10.1038/nature12160
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rumelhart D. E., 1988, PARALLEL DISTRIBUTED, V0, P0
   Russo AA, 2020, NEURON, V107, P745, DOI 10.1016/j.neuron.2020.05.020
   Russo AA, 2018, NEURON, V97, P953, DOI 10.1016/j.neuron.2018.01.004
   Sadtler PT, 2014, NATURE, V512, P423, DOI 10.1038/nature13665
   Saxe A, 2021, NAT REV NEUROSCI, V22, P55, DOI 10.1038/s41583-020-00395-8
   Saxena S, 2019, CURR OPIN NEUROBIOL, V55, P103, DOI 10.1016/j.conb.2019.02.002
   Schrimpf M., 2020, BIORXIV, V2020, P0, DOI 10.1101/ 2020.06.26.174482
   Seung HS, 1996, P NATL ACAD SCI USA, V93, P13339, DOI 10.1073/pnas.93.23.13339
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   SEUNG HS, 1993, P NATL ACAD SCI USA, V90, P10749, DOI 10.1073/pnas.90.22.10749
   Shenoy KV, 2013, ANNU REV NEUROSCI, V36, P337, DOI 10.1146/annurev-neuro-062111-150509
   Sherrington CS, 1906, J PHYSIOL-LONDON, V34, P1
   Sohn H, 2019, NEURON, V103, P934, DOI 10.1016/j.neuron.2019.06.012
   Stephenson C, 2019, ADV NEUR IN, V32, P0
   Stringer C, 2019, NATURE, V571, P361, DOI 10.1038/s41586-019-1346-5
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111
   Yuste R, 2015, NAT REV NEUROSCI, V16, P487, DOI 10.1038/nrn3962
NR 62
TC 19
Z9 19
U1 5
U2 16
PU CURRENT BIOLOGY LTD
PI LONDON
PA 84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND
SN 0959-4388
EI 1873-6882
J9 CURR OPIN NEUROBIOL
JI Curr. Opin. Neurobiol.
PD OCT 15
PY 2021
VL 70
IS 
BP 137
EP 144
DI 10.1016/j.conb.2021.10.010
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA YE1YT
UT WOS:000740926400016
PM 34801787
DA 2023-04-26
ER

PT J
AU Wittich, D
   Rottensteiner, F
AF Wittich, D.
   Rottensteiner, F.
TI Appearance based deep domain adaptation for the classification of aerial images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Domain Adaptation; Pixel-wise Classification; Deep Learning; Aerial Images; Remote Sensing; Appearance Adaptation
ID semantic segmentation
AB This paper addresses appearance based domain adaptation for the pixel-wise classification of remotely sensed data using deep neural networks (DNN) as a strategy to reduce the requirements of DNN with respect to the availability of training data. We focus on the setting in which labelled data are only available in a source domain D S, but not in a target domain D T, known as unsupervised domain adaptation in Computer Vision. Our method is based on adversarial training of an appearance adaptation network (AAN) that transforms images from D S such that they look like images from D T. Together with the original label maps from D S, the transformed images are used to adapt a DNN to D T. The AAN has to change the appearance of objects of a certain class such that they resemble objects of the same class in D T. Many approaches try to achieve this goal by incorporating cycle consistency in the adaptation process, but such approaches tend to hallucinate structures that occur frequently in one of the domains. In contrast, we propose a joint training strategy of the AAN and the classifier, which constrains the AAN to transform the images such that they are correctly classified. To further improve the adaptation performance, we propose a new regularization loss for the discriminator network used in adversarial training. We also address the problem of finding the optimal values of the trained network parameters, proposing a new unsupervised entropy based parameter selection criterion, which compensates for the fact that there is no validation set in D T that could be monitored. As a minor contribution, we present a new weighting strategy for the cross-entropy loss, addressing the problem of imbalanced class distributions. Our method is evaluated in 42 adaptation scenarios using datasets from 7 cities, all consisting of high-resolution digital orthophotos and height data. It achieves a positive transfer in all cases, and on average it improves the performance in the target domain by 4.3% in overall accuracy. In adaptation scenarios between the Vaihingen and Potsdam datasets from the ISPRS semantic labelling benchmark our method outperforms those from recent publications by 10 20% with respect to the mean intersection over union.
C1 [Wittich, D.; Rottensteiner, F.] Leibniz Univ Hannover, Inst Photogrammetry & GeoInformat, Hannover, Germany.
C3 Leibniz University Hannover
RP Wittich, D (corresponding author), Leibniz Univ Hannover, Inst Photogrammetry & GeoInformat, Hannover, Germany.
EM wittich@ipi.uni-hannover.de; rottensteiner@ipi.uni-hannover.de
CR Benaim S., 2018, EUR C COMP VIS ECCV, V0, P218
   Benjdira B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111369
   Chang WL, 2019, PROC CVPR IEEE, V0, PP1900, DOI 10.1109/CVPR.2019.00200
   Chen YC, 2019, PROC CVPR IEEE, V0, PP1791, DOI 10.1109/CVPR.2019.00189
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   Cohen JP, 2018, LECT NOTES COMPUT SC, V11070, P529, DOI 10.1007/978-3-030-00928-1_60
   Cramer M, 2010, PHOTOGRAMM FERNERKUN, V0, PP73, DOI 10.1127/1432-8364/2010/0041
   Demir B., 2016, SOC PHOTOOPTICAL INS, V10004, P0
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Ganin Y, 2016, J MACH LEARN RES, V17, P0
   Gatys LA, 2016, PROC CVPR IEEE, V0, PP2414, DOI 10.1109/CVPR.2016.265
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gritzner D., 2020, ISPRS ANN PHOTOGRAMM, V0, P483
   Hadsell R, 2006, IEEE C COMP VIS PATT, V2, P1735, DOI 10.1109/CVPR.2006.100
   Haeusser P, 2017, IEEE I CONF COMP VIS, V0, PP2784, DOI 10.1109/ICCV.2017.301
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Hoffman J, 2018, PR MACH LEARN RES, V80, P0
   Huang HS, 2018, LECT NOTES COMPUT SC, V11220, P611, DOI 10.1007/978-3-030-01270-0_36
   Isola P, 2017, PROC CVPR IEEE, V0, PP5967, DOI 10.1109/CVPR.2017.632
   Ji SP, 2021, IEEE T GEOSCI REMOTE, V59, P3816, DOI 10.1109/TGRS.2020.3020804
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li X, 2020, INT J REMOTE SENS, V41, P7327, DOI 10.1080/01431161.2020.1757782
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu MY, 2017, ADV NEUR IN, V30, P0
   Liu W, 2020, IEEE GEOSCI REMOTE S, V17, P1978, DOI 10.1109/LGRS.2019.2956490
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Marmanis D, 2016, ISPRS ANN PHOTO REM, V3, P473, DOI 10.5194/isprsannals-III-3-473-2016
   Miyato T., 2018, P INT C LEARNING REP, V0, P1
   Murez Z, 2018, PROC CVPR IEEE, V0, PP4500, DOI 10.1109/CVPR.2018.00473
   Musto L, 2020, SEMANTICALLY ADAPTIV, V0, P0
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   Ren YY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213547
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F, 2015, PROC CVPR IEEE, V0, PP815, DOI 10.1109/CVPR.2015.7298682
   Sorensen T., 1948, BIOL SKAR, V5, P1
   Soto P., 2020, INT ARCH PHOTOGRAMM, V43, P1635
   Tasar Onur, 2020, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V58, P7178, DOI 10.1109/TGRS.2020.2980417
   Tasar O, 2020, INT GEOSCI REMOTE SE, V0, PP1837, DOI 10.1109/IGARSS39084.2020.9323711
   Vu TH, 2019, PROC CVPR IEEE, V0, PP2512, DOI 10.1109/CVPR.2019.00262
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   Tzeng E, 2017, PROC CVPR IEEE, V0, PP2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wegner J. -D., 2017, ISPRS 2D SEMANTIC LA, V0, P0
   Wittich D, 2019, ISPRS ANN PHOTOGRAMM, VIV 2 W7, P197
   Wittich D., 2020, ISPRS ANN PHOTOGRAMM, V2, P591, DOI 10.5194/ISPRS-ANNALS-V-2-2020-591-2020
   Yang C., 1900, VV-3, V0, PV339
   Yang C., 2019, INT ARCH PHOTOGRAMME, V0, PP139, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W13-139-2019
   Yang Y., 1900, P9011, V0, P0
   Yang YC, 2020, PROC CVPR IEEE, V0, PP4084, DOI 10.1109/CVPR42600.2020.00414
   Zhang G, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8120582
   Zhang Y, 2017, IEEE I CONF COMP VIS, V0, PP2039, DOI 10.1109/ICCV.2017.223
   Zhang YH, 2018, PROC CVPR IEEE, V0, PP6810, DOI 10.1109/CVPR.2018.00712
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_
NR 60
TC 18
Z9 18
U1 5
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD OCT 15
PY 2021
VL 180
IS 
BP 82
EP 102
DI 10.1016/j.isprsjprs.2021.08.004
EA AUG 2021
PG 21
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA US0ZU
UT WOS:000697167200006
DA 2023-04-26
ER

PT J
AU Huang, JF
   Zhang, XC
   Sun, Y
   Xin, QCA
AF Huang, Jianfeng
   Zhang, Xinchang
   Sun, Ying
   Xin, Qinchuan
TI Attention-Guided Label Refinement Network for Semantic Segmentation of Very High Resolution Aerial Orthoimages
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Semantics; Labeling; Feature extraction; Image segmentation; Remote sensing; Decoding; Sun; Attention mechanism; convolutional neural networks (CNNs); deep learning; semantic segmentation; urban object extraction; very high spatial resolution images
ID convolutional neural-network; remote-sensing imagery; land-cover; classification; extraction
AB The recent applications of fully convolutional networks (FCNs) have shown to improve the semantic segmentation of very high resolution (VHR) remote-sensing images because of the excellent feature representation and end-to-end pixel labeling capabilities. While many FCN-based methods concatenate features from multilevel encoding stages to refine the coarse labeling results, the semantic gap between features of different levels and the selection of representative features are often overlooked, leading to the generation of redundant information and unexpected classification results. In this article, we propose an attention-guided label refinement network (ALRNet) for improved semantic labeling of VHR images. ALRNet follows the paradigm of the encoder-decoder architecture, which progressively refines the coarse labeling maps of different scales by using the channelwise attention mechanism. A novel attention-guided feature fusion module based on the squeeze-and-excitation module is designed to fuse higher level and lower level features. In this way, the semantic gaps among features of different levels are declined, and the category discrimination of each pixel in the lower level features is strengthened, which is helpful for subsequent label refinement. ALRNet is tested on three public datasets, including two ISRPS 2-D labeling datasets and the Wuhan University aerial building dataset. Results demonstrated that ALRNet had shown promising segmentation performance in comparison with state-of-the-art deep learning networks. The source code of ALRNet is made publicly available for further studies.
C1 [Huang, Jianfeng] Sun Yat Sen Univ, Sch Atmospher Sci, Southern Marine Sci & Engn Guangdong Lab Zhuhai, Zhuhai 519082, Peoples R China.
   [Huang, Jianfeng] Sun Yat Sen Univ, Guangdong Prov Key Lab Climate Change & Nat Disas, Sch Atmospher Sci, Guangzhou 510275, Peoples R China.
   [Zhang, Xinchang] Guangzhou Univ, Sch Geog & Remote Sensing, Guangzhou 510006, Peoples R China.
   [Zhang, Xinchang] Henan Univ, Coll Environm & Planning, Kaifeng 475004, Peoples R China.
   [Sun, Ying; Xin, Qinchuan] Sun Yat Sen Univ, Guangdong Key Lab Urbanizat & Geosimulat, Guangzhou 510275, Peoples R China.
   [Sun, Ying; Xin, Qinchuan] Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
C3 Southern Marine Science & Engineering Guangdong Laboratory; Southern Marine Science & Engineering Guangdong Laboratory (Zhuhai); Sun Yat Sen University; Sun Yat Sen University; Guangzhou University; Henan University; Sun Yat Sen University; Sun Yat Sen University
RP Sun, Y (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Urbanizat & Geosimulat, Guangzhou 510275, Peoples R China.; Sun, Y (corresponding author), Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
EM huangjf9@mail3.sysu.edu.cn; eeszxc@mail.sysu.edu.cn; sunying23@mail.sysu.edu.cn; xinqinchuan@gmail.com
FU National Key Research and Development Program of China [2017YFA0604300, 2017YFA0604400, 2018YFB2100702, 42071441, 41801351, 41875122]; Guangdong Basic and Applied Basic Research Foundation [2020A1515110441]; InnovationGroup Project of Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai) [311020008]
CR Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bischke B, 2019, IEEE IMAGE PROC, V0, PP1480, DOI 10.1109/ICIP.2019.8803050
   Bruzzone L, 2014, REMOTE SENS DIGIT IM, V18, P127, DOI 10.1007/978-94-007-7969-3_9
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, V0, PP3640, DOI 10.1109/CVPR.2016.396
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Fu J, 2019, PROC CVPR IEEE, V0, PP3141, DOI 10.1109/CVPR.2019.00326
   Gerke M., 2014, USE STAIR VISION LIB, V0, P0, DOI DOI 10.13140/2.1.5015.9683
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Islam M. A., 2017, ARXIV170300551, V0, P0
   Islam MA, 2017, PROC CVPR IEEE, V0, PP4877, DOI 10.1109/CVPR.2017.518
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Li H., 2018, LECT NOTES COMPUT SC, V0, P285
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu PH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070830
   Liu YC, 2018, ISPRS J PHOTOGRAMM, V145, P78, DOI 10.1016/j.isprsjprs.2017.12.007
   Luo HF, 2019, IEEE J-STARS, V12, P3492, DOI 10.1109/JSTARS.2019.2930724
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P7092, DOI 10.1109/TGRS.2017.2740362
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Nogueira K, 2019, IEEE T GEOSCI REMOTE, V57, P7503, DOI 10.1109/TGRS.2019.2913861
   Oktay O, 2018, ARXIV180403999, V0, P0
   Paisitkriangkrai S, 2016, IEEE J-STARS, V9, P2868, DOI 10.1109/JSTARS.2016.2582921
   Pan XR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11080917
   Panboonyuen T, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010083
   Piramanayagam S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091429
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sherrah J., 2016, ABS160602585 CORR, V0, P0
   Simonyan K, 2015, ARXIV, V0, P0
   Sun Y, 2018, ISPRS J PHOTOGRAMM, V143, P3, DOI 10.1016/j.isprsjprs.2018.06.005
   Toth C, 2016, ISPRS J PHOTOGRAMM, V115, P22, DOI 10.1016/j.isprsjprs.2015.10.004
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050446
   Wang XL, 2018, PROC CVPR IEEE, V0, PP7794, DOI 10.1109/CVPR.2018.00813
   Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z
   Xu RD, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101602
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yang H, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111768
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhang H, 2018, PROC CVPR IEEE, V0, PP7151, DOI 10.1109/CVPR.2018.00747
   Zhao WZ, 2017, ISPRS J PHOTOGRAMM, V132, P48, DOI 10.1016/j.isprsjprs.2017.08.011
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 61
TC 8
Z9 9
U1 4
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4490
EP 4503
DI 10.1109/JSTARS.2021.3073935
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SC1VT
UT WOS:000650468700005
DA 2023-04-26
ER

PT J
AU Vassanyi, G
   Gede, M
AF Vassanyi, Gergely
   Gede, Matyas
TI Automatic vectorization of point symbols on archive maps using deep convolutional neural network
SO 30TH INTERNATIONAL CARTOGRAPHIC CONFERENCE (ICC 2021), VOL 4
LA English
DT Proceedings Paper
DE MRCNN; vectorization; map symbols; Python
AB Archive topographical maps are a key source of geographical information from past ages, which can be valuable for several science fields. Since manual digitization is usually slow and takes much human resource, automatic methods are preferred, such as deep learning algorithms. Although automatic vectorization is a common problem, there have been few approaches regarding point symbols. In this paper, a point symbol vectorization method is proposed, which was tested on Third Military Survey map sheets using a Mask Regional Convolutional Neural Network (MRCNN). The MRCNN implementation uses the ResNet101 network improved with the Feature Pyramid Network architecture and is developed in a Google Colab environment. The pretrained network was trained on four point symbol categories simultaneously. Results show 90% accuracy, while 94% of symbols detected for some categories on the complete test sheet.
C1 [Vassanyi, Gergely; Gede, Matyas] Eotvos Lorand Univ Budapest, Dept Cartog & Geoinformat, Budapest, Hungary.
C3 Eotvos Lorand University
RP Vassanyi, G (corresponding author), Eotvos Lorand Univ Budapest, Dept Cartog & Geoinformat, Budapest, Hungary.
EM vassanyigergely@gmail.com; saman@map.elte.hu
FU Hungarian Government; European Social Fund;  [EFOP-3.6.3-VEKOP-16-2017-00001]
CR Abdulla W., 2017, GITHUB REPOSITORY, V0, P0
   Gede Matyas, 2020, INT WORKSHOP AUTOMAT, V0, P0, DOI DOI 10.21862/avhm2020.04
   Groom G.B., 2020, P 2020 INT WORKSH AU, V0, PP89, DOI 10.21862/AVHM2020.11
   He K., 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Iosifescu Ionut, 2016, E PERIMETRON, V11, P0
   Jiao Chenjing, 2020, INT WORKSHOP AUTOMAT, V0, P0, DOI DOI 10.21862/avhm2020.03
   Laumer Daniel, 2020, INT WORKSHOP AUTOMAT, V0, P0, DOI DOI 10.21862/avhm2020.07
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Nelson Mark J., 2020, ITICSE 20: PROCEEDINGS OF THE 2020 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, V0, PP533, DOI 10.1145/3341525.3393997
   Quan YN, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18103403
   Saeedimoghaddam M, 2020, INT J GEOGR INF SCI, V34, P947, DOI 10.1080/13658816.2019.1696968
   Skalski P., 2019, MAKE SENSE, V0, P0
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
NR 15
TC 0
Z9 0
U1 2
U2 2
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.5194/ica-proc-4-109-2021
PG 5
WC Geography; Geography, Physical
SC Geography; Physical Geography
GA BT8VN
UT WOS:000855572500107
DA 2023-04-26
ER

PT J
AU Yan, YL
   Ryu, Y
AF Yan, Yulin
   Ryu, Youngryel
TI Exploring Google Street View with deep learning for crop type mapping
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Crop type mapping; Deep learning; Google Earth Engine; Google Street View; Ground referencing
ID urban land-use; training data; sample-size; ndvi data; classification; information; imagery
AB Ground reference data are an essential prerequisite for supervised crop mapping. The lack of a low-cost and efficient ground referencing method results in pervasively limited reference data and hinders crop classification. In this study, we apply a convolutional neural network (CNN) model to explore the efficacy of automatic ground truthing via Google Street View (GSV) images in two distinct farming regions: Illinois and the Central Valley in California. We demonstrate the feasibility and reliability of our new ground referencing technique by performing pixel-based crop mapping at the state level using the cloud-based Google Earth Engine platform. The mapping results are evaluated using the United States Department of Agriculture (USDA) crop data layer (CDL) products. From similar to 130,000 GSV images, the CNN model identified similar to 9,400 target crop images. These images are well classified into crop types, including alfalfa, almond, corn, cotton, grape, rice, soybean, and pistachio. The overall GSV image classification accuracy is 92% for the Central Valley and 97% for Illinois. Subsequently, we shifted the image geographical coordinates 2-3 times in a certain direction to produce 31,829 crop reference points: 17,358 in Illinois, and 14,471 in the Central Valley. Evaluation of the mapping results with CDL products revealed satisfactory coherence. GSV-derived mapping results capture the general pattern of crop type distributions for 2011-2019. The overall agreement between CDL products and our mapping results is indicated by R-2 values of 0.44-0.99 for the Central Valley and 0.81-0.98 for Illinois. To show the applicational value of the proposed method in other countries, we further mapped rice paddy (2014-2018) in South Korea which yielded fairly well outcomes (R-2 = 0.91). These results indicate that GSV images used with a deep learning model offer an efficient and cost-effective alternative method for ground referencing, in many regions of the world.
C1 [Yan, Yulin; Ryu, Youngryel] Seoul Natl Univ, Interdisciplinary Program Agr & Forest Meteorol, Seoul, South Korea.
   [Ryu, Youngryel] Seoul Natl Univ, Dept Landscape Architecture & Rural Syst Engn, Seoul 151921, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Ryu, Y (corresponding author), Seoul Natl Univ, Dept Landscape Architecture & Rural Syst Engn, Seoul 151921, South Korea.
EM yryu@snu.ac.kr
FU "Cooperative Research Program for Agriculture Science & Technology Development", Rural Development Administration, Republic of Korea [PJ01475502]; China Scholarship Council; SNU Global Scholarship
CR [Anonymous], 2011, INTRO REMOTE SENSING, V0, P0
   Arvor D, 2011, INT J REMOTE SENS, V32, P7847, DOI 10.1080/01431161.2010.531783
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Cai YP, 2018, REMOTE SENS ENVIRON, V210, P35, DOI 10.1016/j.rse.2018.02.045
   Ciresan D. C, 2011, 22 INT JOINT C ART I, V0, P0
   Dodge S, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX), V0, P0
   Dong JW, 2016, REMOTE SENS ENVIRON, V185, P142, DOI 10.1016/j.rse.2016.02.016
   Foerster S, 2012, COMPUT ELECTRON AGR, V89, P30, DOI 10.1016/j.compag.2012.07.015
   Foga S, 2017, REMOTE SENS ENVIRON, V194, P379, DOI 10.1016/j.rse.2017.03.026
   Foody GM, 2016, ISPRS INT J GEO-INF, V5, P0, DOI 10.3390/ijgi5110199
   Foody GM, 2004, REMOTE SENS ENVIRON, V93, P107, DOI 10.1016/j.rse.2004.06.017
   Fowler J, 2020, INT J APPL EARTH OBS, V91, P0, DOI 10.1016/j.jag.2020.102114
   Frias-Martinez V, 2014, ENG APPL ARTIF INTEL, V35, P237, DOI 10.1016/j.engappai.2014.06.019
   Friedl MA, 2010, REMOTE SENS ENVIRON, V114, P168, DOI 10.1016/j.rse.2009.08.016
   Fritz S, 2019, COPERNICUS GLOBAL LA, V0, P0
   Fritz S, 2015, GLOBAL CHANGE BIOL, V21, P1980, DOI 10.1111/gcb.12838
   Fritz S, 2009, REMOTE SENS-BASEL, V1, P345, DOI 10.3390/rs1030345
   Gebru T, 2017, P NATL ACAD SCI USA, V114, P13108, DOI 10.1073/pnas.1700035114
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Graesser J, 2017, REMOTE SENS ENVIRON, V201, P165, DOI 10.1016/j.rse.2017.08.027
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Heydari SS, 2018, REMOTE SENS ENVIRON, V204, P648, DOI 10.1016/j.rse.2017.09.035
   Howard DM, 2014, PHOTOGRAMM ENG REM S, V80, P537, DOI 10.14358/PERS.80.6.537-549
   Kavzoglu T, 2009, ENVIRON MODELL SOFTW, V24, P850, DOI 10.1016/j.envsoft.2008.11.012
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   King L, 2017, REMOTE SENS ENVIRON, V195, P13, DOI 10.1016/j.rse.2017.03.047
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kun J., 2013, J APPL REMOTE SENS, V7, P1
   Li XJ, 2017, GISCI REMOTE SENS, V54, P819, DOI 10.1080/15481603.2017.1338389
   Liang Y, 2017, ICCAD-IEEE ACM INT, V0, P9
   Lillesand T., 2015, REMOTE SENSING IMAGE, V0, P0
   Liu XP, 2017, INT J GEOGR INF SCI, V31, P1675, DOI 10.1080/13658816.2017.1324976
   Long Y, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0171110
   Luo JQ, 2020, J COASTAL RES, V0, PP12, DOI 10.2112/JCR-SI108-003.1
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Massey R, 2017, REMOTE SENS ENVIRON, V198, P490, DOI 10.1016/j.rse.2017.06.033
   Munoz J.E.V., 2020, IEEE GEOSCI REMOTE S, V0, P0
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Phalke AR, 2018, REMOTE SENS ENVIRON, V219, P180, DOI 10.1016/j.rse.2018.09.025
   Rakower L.H., 2011, J INT L, V0, P317
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Ringland J, 2019, COMPUT ELECTRON AGR, V158, P36, DOI 10.1016/j.compag.2019.01.014
   Skakun S, 2017, REMOTE SENS ENVIRON, V195, P244, DOI 10.1016/j.rse.2017.04.026
   Srivastava S, 2020, INT J GEOGR INF SCI, V34, P1117, DOI 10.1080/13658816.2018.1542698
   Srivastava S, 2019, REMOTE SENS ENVIRON, V228, P129, DOI 10.1016/j.rse.2019.04.014
   Torbick N., 2018, REMOTE SENS, V10, P0
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Van Niel TG, 2005, REMOTE SENS ENVIRON, V98, P468, DOI 10.1016/j.rse.2005.08.011
   Waldner F, 2019, INT J APPL EARTH OBS, V80, P82, DOI 10.1016/j.jag.2019.01.002
   Wang S, 2020, SCI DATA, V7, P0, DOI 10.1038/s41597-020-00646-4
   Wang S, 2019, REMOTE SENS ENVIRON, V222, P303, DOI 10.1016/j.rse.2018.12.026
   Wardlow BD, 2008, REMOTE SENS ENVIRON, V112, P1096, DOI 10.1016/j.rse.2007.07.019
   Wardlow BD, 2007, REMOTE SENS ENVIRON, V108, P290, DOI 10.1016/j.rse.2006.11.021
   Wood SA, 2013, SCI REP-UK, V3, P0, DOI 10.1038/srep02976
   Xiao X., 2011, EOS T AM GEOPHYS UN, V92, P453, DOI 10.1029/2011EO490002
   You LZ, 2014, AGR SYST, V127, P53, DOI 10.1016/j.agsy.2014.01.002
   Zhang F, 2019, ISPRS J PHOTOGRAMM, V153, P48, DOI 10.1016/j.isprsjprs.2019.04.017
   Zhang WX, 2017, COMPUT ENVIRON URBAN, V64, P215, DOI 10.1016/j.compenvurbsys.2017.03.001
   Zhong LH, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111411
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhong LH, 2016, ISPRS J PHOTOGRAMM, V119, P151, DOI 10.1016/j.isprsjprs.2016.05.014
NR 62
TC 24
Z9 25
U1 11
U2 62
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN 15
PY 2021
VL 171
IS 
BP 278
EP 296
DI 10.1016/j.isprsjprs.2020.11.022
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PN3UD
UT WOS:000604406500019
DA 2023-04-26
ER

PT J
AU Dasenbrock, J
   Pluta, A
   Zech, M
   Medjroubi, W
AF Dasenbrock, Jan
   Pluta, Adam
   Zech, Matthias
   Medjroubi, Wided
TI Detecting Pipeline Pathways in Landsat 5 Satellite Images with Deep Learning
SO ENERGIES
LA English
DT Article
DE pipeline detection; CNN; Landsat 5; U-Net; gas transport network
ID power-to-gas
AB Energy system modeling is essential in analyzing present and future system configurations motivated by the energy transition. Energy models need various input data sets at different scales, including detailed information about energy generation and transport infrastructure. However, accessing such data sets is not straightforward and often restricted, especially for energy infrastructure data. We present a detection model for the automatic recognition of pipeline pathways using a Convolutional Neural Network (CNN) to address this lack of energy infrastructure data sets. The model was trained with historical low-resolution satellite images of the construction phase of British gas transport pipelines, made with the Landsat 5 Thematic Mapper instrument. The satellite images have been automatically labeled with the help of high-resolution pipeline route data provided by the respective Transmission System Operator (TSO). We have used data augmentation on the training data and trained our model with four different initial learning rates. The models trained with the different learning rates have been validated with 5-fold cross-validation using the Intersection over Union (IoU) metric. We show that our model can reliably identify pipeline pathways despite the comparably low resolution of the used satellite images. Further, we have successfully tested the model's capability in other geographic regions by deploying satellite images of the NEL pipeline in Northern Germany.
C1 [Dasenbrock, Jan; Pluta, Adam; Zech, Matthias; Medjroubi, Wided] DLR Inst Networked Energy Syst, D-26129 Oldenburg, Germany.
RP Dasenbrock, J (corresponding author), DLR Inst Networked Energy Syst, D-26129 Oldenburg, Germany.
EM jan.dasenbrock@dlr.de; adam.pluta@dlr.de; matthias.zech@dlr.de; wided.medjroubi@dlr.de
FU DLR Institute for Networked Energy Systems project "SciGRID_gas" by the German Federal Ministry for Economic Affairs and Energy (BMWi) [03ET4063]
CR [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   [Anonymous], 2006, MACH LEARN, V0, P0
   Bai YB, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101626
   Brown T, 2018, ENERGY, V160, P720, DOI 10.1016/j.energy.2018.06.222
   Ching T, 2018, J R SOC INTERFACE, V15, P0, DOI 10.1098/rsif.2017.0387
   Cicek Ozgun, 2016, MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2016. 19TH INTERNATIONAL CONFERENCE. PROCEEDINGS: LNCS 9901, V0, PP424, DOI 10.1007/978-3-319-46723-8_49
   Clegg S, 2016, IET GENER TRANSM DIS, V10, P566, DOI 10.1049/iet-gtd.2015.0439
   Clegg S, 2015, IEEE T SUSTAIN ENERG, V6, P1234, DOI 10.1109/TSTE.2015.2424885
   Dasenbrock J., 2020, THESIS U OLDENBURG O, V0, P0
   Frajberg D, 2017, LECT NOTES COMPUT SC, V10614, P12, DOI 10.1007/978-3-319-68612-7_2
   Geron A., 2019, HANDS ON MACHINE LEA, V0, P0
   Goceri E, 2019, INT CONF IMAG PROC, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Islam M, 2020, LECT NOTES COMPUT SC, V11992, P262, DOI 10.1007/978-3-030-46640-4_25
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), V0, P115
   Kennedy J.L., 1984, OIL GAS PIPELINE FUN, V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Knopp L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152422
   Kunz F., 2017, ELECT HEAT GAS SECTO, V0, P0
   Tran LA, 2019, INT CONF SYST SCI EN, V0, PP62, DOI 10.1109/ICSSE.2019.8823532
   Matke C, 2017, TRENDS MATH, V0, PP177, DOI 10.1007/978-3-319-51795-7_11
   Medjroubi W, 2017, ENERGY REP, V3, P14, DOI 10.1016/j.egyr.2016.12.001
   Mnih V., 2013, MACHINE LEARNING AER, V0, P0
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, V0, P27
   Pluta A., 2020, J OPEN RES STW, V8, P19, DOI 10.5334/JORS.317
   Qadrdan M, 2015, INT J HYDROGEN ENERG, V40, P5763, DOI 10.1016/j.ijhydene.2015.03.004
   Ronneberger O., 2015, INT C MED IM COMP CO, V0, PP234, DOI 10.1007/978-3-319-24574-4_28
   Sayler K., 2020, LANDSAT 4 7 COLLECTI, V0, P0
   Schmidt M, 2017, DATA, V2, P0, DOI 10.3390/data2040040
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Ulku I., 2019, ARXIV191210230, V0, P0
   University of Freiburg, 2015, U NET CT, V0, P0
   van der Werff H, 2008, SENSORS-BASEL, V8, P3733, DOI 10.3390/s8063733
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/7068349
   Wei Y, 2019, INT GEOSCI REMOTE SE, V0, PP3923, DOI 10.1109/IGARSS.2019.8898565
   Wurm M, 2021, ISPRS INT J GEO-INF, V10, P0, DOI 10.3390/ijgi10010023
   Yuan XF, 2021, IEEE T IND ELECTRON, V68, P4404, DOI 10.1109/TIE.2020.2984443
   Yuan XF, 2021, IEEE T NEUR NET LEAR, V32, P3296, DOI 10.1109/TNNLS.2019.2951708
   Zakharov I., 2016, P 11 PIP TECHN C BER, V0, P0
   Zech M, 2020, IEEE PHOT SPEC CONF, V0, P767
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
NR 48
TC 1
Z9 1
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1996-1073
J9 ENERGIES
JI Energies
PD SEP 15
PY 2021
VL 14
IS 18
BP 
EP 
DI 10.3390/en14185642
PG 13
WC Energy & Fuels
SC Energy & Fuels
GA UV2FQ
UT WOS:000699301700001
DA 2023-04-26
ER

PT J
AU Al-Najjar, HAH
   Pradhan, B
AF Al-Najjar, Husam A. H.
   Pradhan, Biswajeet
TI Spatial landslide susceptibility assessment using machine learning techniques assisted by additional data created with generative adversarial networks
SO GEOSCIENCE FRONTIERS
LA English
DT Article
DE Landslide susceptibility; Inventory; Machine learning; Generative adversarial network; Convolutional neural network; Geographic information system
ID artificial neural-network; support vector machine; logistic-regression; frequency ratio; decision-tree; models; shallow; mountains; prediction; selection
AB In recent years, landslide susceptibility mapping has substantially improved with advances in machine learning. However, there are still challenges remain in landslide mapping due to the availability of limited inventory data. In this paper, a novel method that improves the performance of machine learning techniques is presented. The proposed method creates synthetic inventory data using Generative Adversarial Networks (GANs) for improving the prediction of landslides. In this research, landslide inventory data of 156 landslide locations were identified in Cameron Highlands, Malaysia, taken from previous projects the authors worked on. Elevation, slope, aspect, plan curvature, profile curvature, total curvature, lithology, land use and land cover (LULC), distance to the road, distance to the river, stream power index (SPI), sediment transport index (STI), terrain roughness index (TRI), topographic wetness index (TWI) and vegetation density are geo-environmental factors considered in this study based on suggestions from previous works on Cameron Highlands. To show the capability of GANs in improving landslide prediction models, this study tests the proposed GAN model with benchmark models namely Artificial Neural Network (ANN), Support Vector Machine (SVM), Decision Trees (DT), Random Forest (RF) and Bagging ensemble models with ANN and SVM models. These models were validated using the area under the receiver operating characteristic curve (AUROC). The DT, RF, SVM, ANN and Bagging ensemble could achieve the AUROC values of (0.90, 0.94, 0.86, 0.69 and 0.82) for the training; and the AUROC of (0.76, 0.81, 0.85, 0.72 and 0.75) for the test, subsequently. When using additional samples, the same models achieved the AUROC values of (0.92, 0.94, 0.88, 0.75 and 0.84) for the training and (0.78, 0.82, 0.82, 0.78 and 0.80) for the test, respectively. Using the additional samples improved the test accuracy of all the models except SVM. As a result, in data-scarce environments, this research showed that utilizing GANs to generate supplementary samples is promising because it can improve the predictive capability of common landslide prediction models.
C1 [Al-Najjar, Husam A. H.; Pradhan, Biswajeet] Univ Technol Sydney, Fac Engn & IT, Ctr Adv Modelling & Geospatial Informat Syst CAMG, Sydney, NSW 2007, Australia.
   [Pradhan, Biswajeet] Sejong Univ, Dept Energy & Mineral Resources Engn, 209 Neungdong Ro, Seoul 05006, South Korea.
   [Pradhan, Biswajeet] King Abdulaziz Univ, Ctr Excellence Climate Change Res, POB 80234, Jeddah 21589, Saudi Arabia.
   [Pradhan, Biswajeet] Univ Kebangsaan Malaysia, Earth Observat Ctr, Inst Climate Change, Bangi 43600, Selangor, Malaysia.
C3 University of Technology Sydney; Sejong University; King Abdulaziz University; Universiti Kebangsaan Malaysia
RP Pradhan, B (corresponding author), Univ Technol Sydney, Fac Engn & IT, Ctr Adv Modelling & Geospatial Informat Syst CAMG, Sydney, NSW 2007, Australia.
EM Husam.al-najjar@student.uts.edu.au; biswajeet24@gmail.com
FU Centre for Advanced Modeling and Geospatial Information Systems (CAMGIS), Faculty of Engineering and Information Technology, the University of Technology Sydney, Australia
CR Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   Akbar A.Q., 2018, LOWLAND TECHNOL INT, V20, P401
   Aktas H, 2019, COMPUT GEOSCI-UK, V133, P0, DOI 10.1016/j.cageo.2019.104329
   Al-Najjar HAH, 2019, PROC SPIE, V11156, P0, DOI 10.1117/12.2532687
   Ashournejad Q, 2019, ARAB J GEOSCI, V12, P0, DOI 10.1007/s12517-019-4236-0
   Ayalew L, 2005, GEOMORPHOLOGY, V65, P15, DOI 10.1016/j.geomorph.2004.06.010
   Bragagnolo L, 2020, CATENA, V184, P0, DOI 10.1016/j.catena.2019.104240
   Braun A, 2019, IAEG AEG ANN M P SPR, V0, PP207, DOI 10.1007/978-3-319-93124-1_25
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Can A, 2019, B ENG GEOL ENVIRON, V78, P89, DOI 10.1007/s10064-017-1034-3
   Canoglu MC, 2019, B ENG GEOL ENVIRON, V78, P3159, DOI 10.1007/s10064-018-1337-z
   Ciurleo M, 2017, ENG GEOL, V223, P71, DOI 10.1016/j.enggeo.2017.04.023
   Conoscenti C, 2016, GEOMORPHOLOGY, V261, P222, DOI 10.1016/j.geomorph.2016.03.006
   Dou J, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0133262
   Du J, 2020, ENG GEOL, V270, P0, DOI 10.1016/j.enggeo.2020.105572
   Fanos AM, 2019, EARTH SYST ENVIRON, V3, P491, DOI 10.1007/s41748-019-00114-z
   Feizizadeh B, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-2918-z
   Formetta G, 2014, PROCED EARTH PLAN SC, V9, P74, DOI 10.1016/j.proeps.2014.06.006
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Glade T., 2012, LANDSLIDE HAZARD RIS, V0, P0, DOI DOI 10.1002/9780470012659
   Goetz JN, 2015, COMPUT GEOSCI-UK, V81, P1, DOI 10.1016/j.cageo.2015.04.007
   Goetz JN, 2011, GEOMORPHOLOGY, V129, P376, DOI 10.1016/j.geomorph.2011.03.001
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Hong HY, 2019, CATENA, V176, P45, DOI 10.1016/j.catena.2018.12.035
   Huang Y, 2018, CATENA, V165, P520, DOI 10.1016/j.catena.2018.03.003
   Hussin HY, 2016, GEOMORPHOLOGY, V253, P508, DOI 10.1016/j.geomorph.2015.10.030
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Kadavi PR, 2019, ENVIRON EARTH SCI, V78, P0, DOI 10.1007/s12665-019-8119-1
   Kadavi PR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081252
   Kalantar B, 2018, GEOMAT NAT HAZ RISK, V9, P49, DOI 10.1080/19475705.2017.1407368
   Kamp U, 2008, GEOMORPHOLOGY, V101, P631, DOI 10.1016/j.geomorph.2008.03.003
   Kavzoglu T, 2019, ADV NAT TECH HAZ RES, V50, P283, DOI 10.1007/978-3-319-77377-3_13
   Kavzoglu T, 2015, ENG GEOL, V192, P101, DOI 10.1016/j.enggeo.2015.04.004
   Kawabata D, 2009, GEOMORPHOLOGY, V113, P97, DOI 10.1016/j.geomorph.2009.06.006
   Kornejady A, 2018, GEOCARTO INT, V33, P1155, DOI 10.1080/10106049.2017.1334832
   Kornejady A, 2017, CATENA, V152, P144, DOI 10.1016/j.catena.2017.01.010
   Lai JS, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8090397
   Lee JH, 2018, GEOMORPHOLOGY, V303, P284, DOI 10.1016/j.geomorph.2017.12.007
   Lee ML, 2014, NAT HAZARDS, V70, P353, DOI 10.1007/s11069-013-0814-8
   Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X
   Lee S, 2006, ENVIRON GEOL, V50, P847, DOI 10.1007/s00254-006-0256-7
   Mandal S, 2019, ENVIRON SCI ENG, V0, PP185, DOI 10.1007/978-3-030-10495-5_9
   Matori A.N., 2012, INT C MON SIM PREV R, V73, P207, DOI 10.2495/DEB120181
   Mezaal MR, 2018, CATENA, V167, P147, DOI 10.1016/j.catena.2018.04.038
   Ozdemir A, 2013, J ASIAN EARTH SCI, V64, P180, DOI 10.1016/j.jseaes.2012.12.014
   Park JY, 2019, ENG GEOL, V260, P0, DOI 10.1016/j.enggeo.2019.105193
   Polikar R, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, V0, PP1, DOI 10.1007/978-1-4419-9326-7_1
   Pradhan B, 2013, COMPUT GEOSCI-UK, V51, P350, DOI 10.1016/j.cageo.2012.08.023
   Pradhan B, 2010, LANDSLIDES, V7, P13, DOI 10.1007/s10346-009-0183-2
   Romer C, 2016, ENG GEOL, V201, P29, DOI 10.1016/j.enggeo.2015.12.013
   Rotigliano E, 2012, NAT HAZARDS, V61, P143, DOI 10.1007/s11069-011-9846-0
   Saito H, 2009, GEOMORPHOLOGY, V109, P108, DOI 10.1016/j.geomorph.2009.02.026
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   Sameen MI, 2020, CATENA, V187, P0, DOI 10.1016/j.catena.2019.104358
   Samia J, 2018, LANDSLIDES, V15, P2129, DOI 10.1007/s10346-018-1024-y
   Soma AS, 2019, J MT SCI-ENGL, V16, P383, DOI 10.1007/s11629-018-4884-7
   Steger S, 2017, LANDSLIDES, V14, P1767, DOI 10.1007/s10346-017-0820-0
   Steger S., 2018, EGU GEN ASS C, V0, P8551
   Suzen ML, 2004, ENVIRON GEOL, V45, P665, DOI 10.1007/s00254-003-0917-8
   Tsangaratos P, 2016, CATENA, V145, P164, DOI 10.1016/j.catena.2016.06.004
   Vapnik V N., 1995, NATURE STAT LEARNING, V0, P119
   Wang HJ, 2019, ENG GEOL, V251, P71, DOI 10.1016/j.enggeo.2019.02.004
   Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849
   Xiao T, 2019, ACTA GEOCHIM, V38, P654, DOI 10.1007/s11631-019-00341-1
   Yan F, 2019, GEOMORPHOLOGY, V327, P170, DOI 10.1016/j.geomorph.2018.10.024
   Yeon YK, 2010, ENG GEOL, V116, P274, DOI 10.1016/j.enggeo.2010.09.009
   Yilmaz I., 2019, NATURAL HAZARDS GIS, V48, P0, DOI 10.1007/978-3-319-73383-8_9.
   Yilmaz I, 2009, COMPUT GEOSCI-UK, V35, P1125, DOI 10.1016/j.cageo.2008.08.007
   Zezere JL, 2017, SCI TOTAL ENVIRON, V589, P250, DOI 10.1016/j.scitotenv.2017.02.188
   Zhang TY, 2019, J MT SCI-ENGL, V16, P1275, DOI 10.1007/s11629-018-5337-z
   Zhu AX, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104188
NR 72
TC 49
Z9 51
U1 38
U2 124
PU CHINA UNIV GEOSCIENCES, BEIJING
PI HAIDIAN DISTRICT
PA 29 XUEYUAN RD, HAIDIAN DISTRICT, 100083, PEOPLES R CHINA
SN 1674-9871
EI 
J9 GEOSCI FRONT
JI Geosci. Front.
PD MAR 15
PY 2021
VL 12
IS 2
BP 625
EP 637
DI 10.1016/j.gsf.2020.09.002
PG 13
WC Geosciences, Multidisciplinary
SC Geology
GA PY3MA
UT WOS:000611950300009
DA 2023-04-26
ER

PT J
AU Yin, ZX
   Li, XD
   Ge, Y
   Shang, C
   Li, XY
   Du, Y
   Ling, F
AF Yin, Zhixiang
   Li, Xiaodong
   Ge, Yong
   Shang, Cheng
   Li, Xinyan
   Du, Yun
   Ling, Feng
TI Estimating subpixel turbulent heat flux over leads from MODIS thermal infrared imagery with deep learning
SO CRYOSPHERE
LA English
DT Article
ID sea-ice leads; stray light correction; surface-temperature; superresolution; algorithm; validation
AB The turbulent heat flux (THF) over leads is an important parameter for climate change monitoring in the Arctic region. THF over leads is often calculated from satellite-derived ice surface temperature (IST) products, in which mixed pixels containing both ice and open water along lead boundaries reduce the accuracy of calculated THF. To address this problem, this paper proposes a deep residual convolutional neural network (CNN)-based framework to estimate THF over leads at the subpixel scale (DeepSTHF) based on remotely sensed images The proposed DeepSTHF provides an IST image and the corresponding lead map with a finer spatial resolution than the input IST image so that the subpixel-scale THF can be estimated from them. The proposed approach is verified using simulated and real Moderate Resolution Imaging Spectroradiometer images and compared with the conventional cubic interpolation and pixelbased methods. The results demonstrate that the proposed CNN-based method can effectively estimate subpixel-scale information from the coarse data and performs well in producing fine-spatial-resolution IST images and lead maps, thereby providing more accurate and reliable THF over leads.
C1 [Yin, Zhixiang; Li, Xiaodong; Shang, Cheng; Li, Xinyan; Du, Yun; Ling, Feng] Chinese Acad Sci, Innovat Acad Precis Measurement Sci & Technol, Key Lab Environm & Disaster Monitoring & Evaluat, Wuhan 430077, Peoples R China.
   [Yin, Zhixiang; Shang, Cheng; Li, Xinyan] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Yin, Zhixiang] Anhui Univ, Anhui Prov Key Lab Wetland Ecosyst Protect & Rest, Hefei 230601, Peoples R China.
   [Ge, Yong] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Anhui University; Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS
RP Ling, F (corresponding author), Chinese Acad Sci, Innovat Acad Precis Measurement Sci & Technol, Key Lab Environm & Disaster Monitoring & Evaluat, Wuhan 430077, Peoples R China.
EM lingf@whigg.ac.cn
FU Natural Science Foundation of Hubei Province for Innovation Groups [2019CFA019]; National Science Fund for Distinguished Young Scholars [41725006]; National Natural Science Foundation of China [62071457, 61671425]
CR Atkinson PM, 2013, INT J APPL EARTH OBS, V22, P106, DOI 10.1016/j.jag.2012.04.012
   Aulicino G, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10030366
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barber DG, 2014, J GEOPHYS RES-ATMOS, V119, P11593, DOI 10.1002/2014JD021736
   Brodeau L, 2017, J PHYS OCEANOGR, V47, P5, DOI 10.1175/JPO-D-16-0169.1
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Du C, 2015, REMOTE SENS-BASEL, V7, P647, DOI 10.3390/rs70100647
   EBERT EE, 1993, J GEOPHYS RES-OCEANS, V98, P10085, DOI 10.1029/93JC00656
   EPPLER DT, 1992, REMOTE SENS ENVIRON, V40, P197, DOI 10.1016/0034-4257(92)90003-3
   Eythorsson D, 2019, INT J APPL EARTH OBS, V80, P71, DOI 10.1016/j.jag.2019.04.003
   Fan P, 2020, REMOTE SENS ENVIRON, V248, P0, DOI 10.1016/j.rse.2020.111975
   Fett RW, 1997, J GEOPHYS RES-ATMOS, V102, P13657, DOI 10.1029/97JD00340
   Foody GM, 2007, PHOTOGRAMM ENG REM S, V73, P923, DOI 10.14358/PERS.73.8.923
   Foody GM, 2005, INT J REMOTE SENS, V26, P5381, DOI 10.1080/01431160500213292
   Ge Y, 2019, EARTH-SCI REV, V197, P0, DOI 10.1016/j.earscirev.2019.102897
   Ge Y, 2009, IEEE T GEOSCI REMOTE, V47, P2155, DOI 10.1109/TGRS.2008.2010863
   Gerace A, 2017, REMOTE SENS ENVIRON, V191, P246, DOI 10.1016/j.rse.2017.01.029
   Glasner D, 2009, IEEE I CONF COMP VIS, V0, PP349, DOI 10.1109/ICCV.2009.5459271
   Goosse H, 2001, DESCRIPTION CLIO MOD, V0, P0
   Jia YX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151815
   KEY J, 1994, ARCTIC, V47, P280
   Key JR, 1997, REMOTE SENS ENVIRON, V61, P302, DOI 10.1016/S0034-4257(97)89497-7
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Lanaras C, 2018, ISPRS J PHOTOGRAMM, V146, P305, DOI 10.1016/j.isprsjprs.2018.09.018
   Leach R, 2014, SURF TOPOGR-METROL, V2, P0, DOI 10.1088/2051-672X/2/2/023001
   Ledig C, 2017, PROC CVPR IEEE, V0, PP105, DOI 10.1109/CVPR.2017.19
   Lewis BJ, 2019, J GEOPHYS RES-OCEANS, V124, P3411, DOI 10.1029/2018JC014898
   Li XD, 2014, IEEE T GEOSCI REMOTE, V52, P2810, DOI 10.1109/TGRS.2013.2266345
   LINDSAY RW, 1995, J GEOPHYS RES-OCEANS, V100, P4533, DOI 10.1029/94JC02393
   Ling F, 1900, P2021, V0, P0, DOI DOI 10.5281/zenodo.5006637
   Ling F, 2019, WATER RESOUR RES, V55, P5631, DOI 10.1029/2018WR024136
   Ling F, 2019, REMOTE SENS LETT, V10, P598, DOI 10.1080/2150704X.2019.1587196
   Ling F, 2010, INT J REMOTE SENS, V31, P5023, DOI 10.1080/01431160903252350
   Lupkes C, 2008, GEOPHYS RES LETT, V35, P0, DOI 10.1029/2007GL032461
   Marcq S, 2012, CRYOSPHERE, V6, P143, DOI 10.5194/tc-6-143-2012
   Masters D., 2018, ARXIV180407612, V0, P0, DOI DOI 10.48550/ARXIV.1804.07612
   MAYKUT GA, 1978, J GEOPHYS RES-OCEANS, V83, P3646, DOI 10.1029/JC083iC07p03646
   Meng Y, 1900, V14, V0, PP887, DOI 10.1109/JSTARS.2020.3042242
   Montanaro M, 2015, APPL OPTICS, V54, P3963, DOI 10.1364/AO.54.003963
   Noh H, 2015, IEEE I CONF COMP VIS, V0, PP1520, DOI 10.1109/ICCV.2015.178
   Qu M, 2021, REMOTE SENS ENVIRON, V256, P0, DOI 10.1016/j.rse.2021.112342
   Qu M, 2019, CRYOSPHERE, V13, P1565, DOI 10.5194/tc-13-1565-2019
   Reddi S.J., 2019, ARXIV PREPRINT ARXIV, V0, P0
   Renfrew IA, 2002, J PHYS OCEANOGR, V32, P383, DOI 10.1175/1520-0485(2002)032<0383:ACOSLA>2.0.CO;2
   Rohrs J, 2012, CRYOSPHERE, V6, P343, DOI 10.5194/tc-6-343-2012
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   TENNEKES H, 1973, J ATMOS SCI, V30, P234, DOI 10.1175/1520-0469(1973)030<0234:TLWP>2.0.CO;2
   Tschudi MA, 2002, J GEOPHYS RES-OCEANS, V107, P0, DOI 10.1029/2000JC000541
   Van Doninck J, 2011, INT J APPL EARTH OBS, V13, P934, DOI 10.1016/j.jag.2011.07.003
   Wang QM, 2014, ISPRS J PHOTOGRAMM, V92, P1, DOI 10.1016/j.isprsjprs.2014.02.012
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Willmes S, 2015, ANN GLACIOL, V56, P29, DOI 10.3189/2015AoG69A615
   Zhang K, 2018, PROC CVPR IEEE, V0, PP3262, DOI 10.1109/CVPR.2018.00344
   Zhang YY, 2018, CRYOSPHERE, V12, P3747, DOI 10.5194/tc-12-3747-2018
   Zhong YF, 2013, PATTERN RECOGN, V46, P2902, DOI 10.1016/j.patcog.2013.04.009
NR 56
TC 1
Z9 1
U1 3
U2 7
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1994-0416
EI 1994-0424
J9 CRYOSPHERE
JI Cryosphere
PD JUN 24
PY 2021
VL 15
IS 6
BP 2835
EP 2856
DI 10.5194/tc-15-2835-2021
PG 22
WC Geography, Physical; Geosciences, Multidisciplinary
SC Physical Geography; Geology
GA TB4YI
UT WOS:000667954200001
DA 2023-04-26
ER

PT J
AU Priya, T
   Pandey, AC
AF Priya, Tannu
   Pandey, Arvind Chandra
TI Geoinformatics-based assessment of land deformation and damage zonation for Gorkha earthquake, 2015, using SAR interferometry and ANN approach
SO SN APPLIED SCIENCES
LA English
DT Article
DE Earthquake; Synthetic aperture radar; InSAR; ANN; Damage assessment; Surface deformation; Satellite images; GIS
AB The Gorkha earthquake 2015 was one of the largest disastrous events that occurred in the main Himalayan thrust (MHT) region with epicenter at Gorkha region and magnitude of 7.8 which caused severe causality to life as well as property. The spatial statistics on vertical displacement and extent of damage zone is still too scarce to provide strong evidences of its hazard potential. In the present study, quantitative assessment on surface deformation has been carried out to compare land displacement of two different regions of Nepal (the Central Nepal and the Eastern Nepal), which are located at different distances from the epicenter, using InSAR technique on post- and pre-earthquake images from Sentinel 1A SLC product. The Central Nepal experiences an upliftment of 1.1 m and land subsidence of - 0.61 m, whereas for the Eastern Nepal the estimated upliftment and subsidence were 1.0 m and - 0.33 m, respectively. Further a regional earthquake-prone zone map was generated using the historical earthquake epicenter data and geographic information system (GIS) to understand the major vulnerability zones in the area. A total of 564 earthquake events were reported by USGS in Nepal region during 2000-2019, of which 476 (84.39%) were of magnitude greater than 4 on Richter scale and 376 events (66%) occurred at depth greater than 15 km. The damage assessment was done using machine learning (artificial neural network) back-propagation model in which the satellite imagery retrieved from the optical satellite Landsat 8 OLI sensor and digital elevation model was used to map slope, aspect, relief, drainage and lineament to be used as input layers to generate damage proxy map. The result obtained from ANN illustrated that despite being located comparatively at more distance from epicenter, the Eastern Nepal exhibited more damage-prone area (587 sq. km) in comparison with Central Nepal with 457sq. km damage prone in similar zone. Central Nepal evidences more damage-prone areas over compact build-up in contrast to Eastern Nepal, making greater risk potential in urban areas of Central Nepal during earthquake activity.
C1 [Priya, Tannu; Pandey, Arvind Chandra] Cent Univ Jharkhand, Sch Nat Resource Management, Dept Geoinformat, Ranchi 834005, Bihar, India.
C3 Central University of Jharkhand
RP Pandey, AC (corresponding author), Cent Univ Jharkhand, Sch Nat Resource Management, Dept Geoinformat, Ranchi 834005, Bihar, India.
EM arvindchandrap@yahoo.com
CR Adhikari RK, 2020, B EARTHQ ENG, V18, P3863, DOI 10.1007/s10518-020-00834-y
   Bhattacharya A, 2012, NAT HAZARDS, V64, P1105, DOI 10.1007/s11069-012-0292-4
   Cassidy J. F., 2013, ENCY NATURAL HAZARDS, V0, PP208, DOI 10.1007/978-1-4020-4399-4_104
   Chandrasekhar DV, 2009, EARTH PLANET SC LETT, V280, P229, DOI 10.1016/j.epsl.2009.01.039
   Chatterjee RS, 2006, REMOTE SENS ENVIRON, V102, P176, DOI 10.1016/j.rse.2006.02.006
   Cooner AJ, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100868
   Fagereng A, 2019, PROBLEMS SOLUTIONS S, V0, PP57, DOI 10.1016/B978-0-12-814048-2.00004-1
   Fattahil H, 2015, J GEOPHYS RES-SOL EA, V120, P8758, DOI 10.1002/2015JB012419
   Furuya M., 2011, ENCY SOLID EARTH GEO, V0, PP1041, DOI 10.1007/978-90-481-8702-7_97
   George UA, 2019, SN APPL SCI, V1, P0, DOI 10.1007/s42452-019-1504-2
   Khare SS, 2013, IOSR J MECH CIV ENG, V6, P16, DOI 10.9790/1684-0611621
   Kumar A., 2017, J URBAN ENV ENG, V11, P133
   MASSONNET D, 1993, NATURE, V364, P138, DOI 10.1038/364138a0
   Miyake H, 2017, EARTH PLANETS SPACE, V69, P0, DOI 10.1186/s40623-016-0597-8
   Narayanakumar S., 2016, CIRCUITS SYST, V7, P3456, DOI 10.4236/cs.2016.711294
   Pepe A, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7121264
   Rastogi BK., 2012, NAT HAZARDS, V62, P1347, DOI 10.1007/s11069-012-0110-z
   Rijal N, 2019, SSRN ELECT J, V0, P0, DOI DOI 10.2139/ssrn.3373800
   Sapkota SN, 2016, EARTH PLANETS SPACE, V68, P0, DOI 10.1186/s40623-016-0416-2
   Saraf AK, 2012, INT J REMOTE SENS, V33, P1296, DOI 10.1080/01431161.2010.549855
   Satyabala SP, 2006, GEOPHYS RES LETT, V33, P0, DOI 10.1029/2006GL027422
   Sreejith K. M., 2016, PROCEEDINGS OF THE INDIAN NATIONAL SCIENCE ACADEMY, V82, P737, DOI 10.16943/ptinsa/2016/48481
   Swathi S., 2020, NEPAL EARTHQUAKE 201, V0, P0
   Yun SH, 2015, SEISMOL RES LETT, V86, P1549, DOI 10.1785/0220150152
   Zeng QM, 2007, INT GEOSCI REMOTE SE, V0, PP2086, DOI 10.1109/IGARSS.2007.4423244
   Zia M, 2014, NAT HAZARDS, V71, P1379, DOI 10.1007/s11069-013-0947-9
NR 26
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2523-3963
EI 2523-3971
J9 SN APPL SCI
JI SN Appl. Sci.
PD MAY 15
PY 2021
VL 3
IS 5
BP 
EP 
DI 10.1007/s42452-021-04574-9
PG 16
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA RQ5NR
UT WOS:000642466100003
DA 2023-04-26
ER

PT J
AU Kim, H
   Yoo, HJ
   Lee, JL
AF Kim, Hyoseob
   Yoo, Ho Jun
   Lee, Jung Lyul
TI Nonlinear Kernel Convolutional Neural Network to Find Median Sand Particle Size
SO JOURNAL OF COASTAL RESEARCH
LA English
DT Article
DE Mean sand particle size; CNN; SNN; image recognition; sediment particle
AB Convolutional Neural Network (CNN) has successfully been used in various areas. We focus on predicting various sand particle sizes by applying convolutional neural network with a nonlinear kernel. The nonlinear kernel involves a bias and negative square of subtraction between input image pixel numbers and the kernel coefficients and summation. The convolution layer conform new feature map in Convolutional Neural Network. While using batch gradient descent method to train relevant coefficients and biases, the gradient of the square of subtraction term appears in the whole gradient over each kernel coefficient. The network was examined on regular-sized sands, i.e. 2000, 1000, 500, 250, 125 and 63 micrometer. The network was trained by using various images for each size. It was validated against new images and the absolute error was less than 30 micrometer, respectively, which is satisfactory. The network was applied by using 3 images of sands with size distribution. The results show good validation and satisfactory predictions. In the course of study, several numbers of kernels, kernel sizes, pooling sizes were tried and the optimum architecture for this work was chosen. It is expected that the present network will reduce time and effort in obtaining median sand size in many field projects. The size distribution of sand particles could also be obtained with the present network in the near future.
C1 [Kim, Hyoseob] Kookmin Univ, Dept Civil & Environm Engn, Seoul, South Korea.
   [Yoo, Ho Jun] Geosyst Res Corp, Dept Res Inst, Gunpo, South Korea.
   [Lee, Jung Lyul] Sungkyunkwan Univ, Grad Sch Water Resources, Suwon, South Korea.
C3 Kookmin University; Sungkyunkwan University (SKKU)
RP Yoo, HJ (corresponding author), Geosyst Res Corp, Dept Res Inst, Gunpo, South Korea.
EM yoohj@geosr.com
FU Ministry of Oceans and Fisheries, Korea
CR Bordeleau F.E., 2019, P 27 EUR C INF SYST, V0, P1
   Dahl M, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0167493
   Folk R.L., 1957, J SEDIMENT PETROL, V27, P3, DOI 10.1306/74d70646-2b21-11d7-8648000102c1865
   Fu B, 2019, MULTIMED TOOLS APPL, V78, P30707, DOI 10.1007/s11042-018-6521-4
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Joensuu M, 2018, LIMNOL OCEANOGR, V63, P173, DOI 10.1002/lno.10622
   Lee M, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10103501
   Machairas N, 2020, GEOTECH SP, V0, P612
   Maitre J, 2019, COMPUT GEOSCI-UK, V130, P84, DOI 10.1016/j.cageo.2019.05.009
   Yoo H, 2020, MATH MODEL ENG, V6, P147, DOI 10.21595/mme.2020.21552
NR 10
TC 0
Z9 0
U1 0
U2 0
PU COASTAL EDUCATION & RESEARCH FOUNDATION
PI COCONUT CREEK
PA 5130 NW 54TH STREET, COCONUT CREEK, FL 33073 USA
SN 0749-0208
EI 1551-5036
J9 J COASTAL RES
JI J. Coast. Res.
PD FAL 15
PY 2021
VL 0
IS 
BP 1
EP 5
DI 10.2112/JCR-SI114-001.1
PG 5
WC Environmental Sciences; Geography, Physical; Geosciences, Multidisciplinary
SC Environmental Sciences & Ecology; Physical Geography; Geology
GA XE8YJ
UT WOS:000723668500001
DA 2023-04-26
ER

PT J
AU McNellie, MJ
   Oliver, I
   Ferrier, S
   Newell, G
   Manion, G
   Griffioen, P
   White, M
   Koen, T
   Somerville, M
   Gibbons, P
AF McNellie, Megan J.
   Oliver, Ian
   Ferrier, Simon
   Newell, Graeme
   Manion, Glenn
   Griffioen, Peter
   White, Matt
   Koen, Terry
   Somerville, Michael
   Gibbons, Philip
TI Extending vegetation site data and ensemble models to predict patterns of foliage cover and species richness for plant functional groups
SO LANDSCAPE ECOLOGY
LA English
DT Article
DE Growth form; Residual error; Ensemble; Neural network; Predictive modelling; Site-based floristic records; Spatially-explicit vegetation models; Vegetation richness; Vegetation cover
ID new-south-wales; biodiversity; conservation; forest; fragmentation; distributions; information; assessments; management; databases
AB Context Ensembles of artificial neural network models can be trained to predict the continuous characteristics of vegetation such as the foliage cover and species richness of different plant functional groups. Objectives Our first objective was to synthesise existing site-based observations of native plant species to quantify summed percentage foliage cover and species richness within four functional groups and in totality. Secondly, we generated spatially-explicit, continuous, landscape-scale models of these functional groups, accompanied by maps of the model residuals to show uncertainty. Methods Using a case study from New South Wales, Australia, we aggregated floristic observations from 6806 sites into four common plant growth forms (trees, shrubs, grasses and forbs) representing four different functional groups. We coupled these response data with spatially-complete surfaces describing environmental predictors and predictors that reflect landscape-scale disturbance. We predicted the distribution of foliage cover and species richness of these four plant functional groups over 1.5 million hectares. Importantly, we display spatially explicit model residuals so that end-users have a tangible and transparent means of assessing model uncertainty. Results Models of richness generally performed well (R-2 0.43-0.63), whereas models of cover were more variable (R-2 0.12-0.69). RMSD ranged from 1.42 (tree richness) to 29.86 (total native cover). MAE ranged from 1.0 (tree richness) to 20.73 (total native foliage cover). Conclusions Continuous maps of vegetation attributes can add considerable value to existing maps and models of discrete vegetation classes and provide ecologically informative data to support better decisions across multiple spatial scales.
C1 [McNellie, Megan J.] Dept Planning Ind & Environm, POB 5336, Wagga Wagga, NSW 2650, Australia.
   [McNellie, Megan J.; Gibbons, Philip] Australian Natl Univ, Fenner Sch Environm & Soc, Frank Fenner Bldg,Linnaeus Way, Acton, ACT 2601, Australia.
   [Oliver, Ian] Dept Planning Ind & Environm, Gosford, NSW 2250, Australia.
   [Ferrier, Simon] CSIRO Land & Water, POB 1700, Canberra, ACT 2601, Australia.
   [Newell, Graeme; Griffioen, Peter; White, Matt] Arthur Rylah Inst Environm Res, Dept Environm Land Water & Planning, 123 Brown St, Heidelberg, Vic 3084, Australia.
   [Manion, Glenn; Somerville, Michael] Dept Planning Ind & Environm, Armidale, NSW 2351, Australia.
   [Koen, Terry] Dept Planning Ind & Environm, Cowra, NSW 2794, Australia.
C3 Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Arthur Rylah Institute for Environmental Research (ARI)
RP McNellie, MJ (corresponding author), Dept Planning Ind & Environm, POB 5336, Wagga Wagga, NSW 2650, Australia.
EM megan.mcnellie@environment.nsw.gov.au; ian.oliver2@environment.nsw.gov.au; simon.ferrier@csiro.au; graeme.newell@delwp.vic.gov.au; manionglenn@bigpond.com; peter.griffioen@delwp.vic.gov.au; matt.white@delwp.vic.gov.au; sandtkoen@bigpond.com; msomerv2@gmail.com; philip.gibbons@anu.edu.au
CR [Anonymous], 2009, MAPPING SPECIES DIST, V0, P0
   [Anonymous], 2013, EL STAT TXB, V0, P0
   [Anonymous], 2004, OCEAN SHORES DESERT, V0, P0
   [Anonymous], 1995, NEURAL NETWORKS PATT, V0, P0
   Anselin L, 2010, ADV SPAT SCI, V0, PP1, DOI 10.1007/978-3-642-01976-0
   Araujo MB, 2007, TRENDS ECOL EVOL, V22, P42, DOI 10.1016/j.tree.2006.09.010
   Ashcroft MB, 2017, GLOBAL CHANGE BIOL, V23, P2929, DOI 10.1111/gcb.13628
   Austin MP, 2002, ECOL MODEL, V157, P101, DOI 10.1016/S0304-3800(02)00205-3
   AUSTIN MP, 1989, VEGETATIO, V83, P35, DOI 10.1007/BF00031679
   Austin MP, 1998, ANN MO BOT GARD, V85, P2, DOI 10.2307/2991991
   Banks-Leite C, 2020, ONE EARTH, V3, P672, DOI 10.1016/j.oneear.2020.11.016
   BOX EO, 1981, VEGETATIO, V45, P127, DOI 10.1007/BF00119222
   BROWN JH, 1995, ECOLOGY, V76, P2028, DOI 10.2307/1941678
   Bruelheide H, 2019, J VEG SCI, V30, P161, DOI 10.1111/jvs.12710
   CAIN SA, 1950, BOT REV, V16, P1, DOI 10.1007/BF02879783
   Cavender-Bares J., 2020, REMOTE SENSING PLANT, V0, P0, DOI DOI 10.1007/978-3-030-33157-3
   Chicco D, 2017, BIODATA MIN, V10, P0, DOI 10.1186/s13040-017-0155-3
   Chytry M, 2011, APPL VEG SCI, V14, P435, DOI 10.1111/j.1654-109X.2011.01154.x
   Cook CN, 2010, J APPL ECOL, V47, P650, DOI 10.1111/j.1365-2664.2010.01803.x
   Dale MB., 1989, ADV VEGETATION SCI, V0, P0, DOI DOI 10.1007/978-94-009-2432-1
   De Caceres M, 2012, J VEG SCI, V23, P387, DOI 10.1111/j.1654-1103.2011.01354.x
   DEFRIES RS, 1995, J GEOPHYS RES-ATMOS, V100, P20867, DOI 10.1029/95JD01536
   Dengler J, 2011, J VEG SCI, V22, P582, DOI 10.1111/j.1654-1103.2011.01265.x
   Dormann CF, 2007, GLOBAL ECOL BIOGEOGR, V16, P774, DOI 10.1111/j.1466-8238.2007.00344.x
   Drielsma Michael, 2006, ECOLOGICAL MANAGEMENT & RESTORATION, V7, PS45, DOI 10.1111/j.1442-8903.2006.00291.x
   Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x
   Engemann K, 2016, ECOLOGY, V97, P3243, DOI 10.1002/ecy.1569
   Evans JS, 2009, LANDSCAPE ECOL, V24, P673, DOI 10.1007/s10980-009-9341-0
   Evans MC, 2011, BIOSCIENCE, V61, P281, DOI 10.1525/bio.2011.61.4.8
   Ferrier S, 2006, J APPL ECOL, V43, P393, DOI 10.1111/j.1365-2664.2006.01149.x
   Ferrier S, 2010, DIVERS DISTRIB, V16, P386, DOI 10.1111/j.1472-4642.2010.00657.x
   Fick SE, 2017, INT J CLIMATOL, V37, P4302, DOI 10.1002/joc.5086
   Fielding AH., 1999, GENERIC, V0, P0
   Fischer J, 2007, GLOBAL ECOL BIOGEOGR, V16, P265, DOI 10.1111/j.1466-8238.2007.00287.x
   Fleishman E, 2006, ECOL INDIC, V6, P543, DOI 10.1016/j.ecolind.2005.07.005
   Franklin J, 2017, GLOBAL ECOL BIOGEOGR, V26, P6, DOI 10.1111/geb.12501
   Gardner TA, 2009, ECOL LETT, V12, P561, DOI 10.1111/j.1461-0248.2009.01294.x
   Gilliam FS, 2007, BIOSCIENCE, V57, P845, DOI 10.1641/B571007
   GRIME JP, 1977, AM NAT, V111, P1169, DOI 10.1086/283244
   Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9
   Harden GJ., 1990, FLORA NEW S WALES, V0, P0
   Hearn SM, 2011, J ENVIRON MANAGE, V92, P1174, DOI 10.1016/j.jenvman.2010.11.021
   Heikkinen RK, 2012, ECOGRAPHY, V35, P276, DOI 10.1111/j.1600-0587.2011.06999.x
   Hengl T, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0169748
   Hooper DU, 2005, ECOL MONOGR, V75, P3, DOI 10.1890/04-0922
   Houborg R, 2015, INT J APPL EARTH OBS, V43, P1, DOI 10.1016/j.jag.2015.06.001
   Inskeep, 2011, 1 2 SRTM DERIVED DIG, V0, P0
   Johnson DP, 2020, AUSTRAL ECOL, V45, P366, DOI 10.1111/aec.12866
   Kattge J, 2020, GLOBAL CHANGE BIOL, V26, P119, DOI 10.1111/gcb.14904
   Keitt TH, 2002, ECOGRAPHY, V25, P616, DOI 10.1034/j.1600-0587.2002.250509.x
   Kelemen A, 2013, J VEG SCI, V24, P1195, DOI 10.1111/jvs.12027
   Kissling WD, 2018, BIOL REV, V93, P600, DOI 10.1111/brv.12359
   Lake PS, 2000, J N AM BENTHOL SOC, V19, P573, DOI 10.2307/1468118
   Leitao PJ, 2019, FRONT ECOL EVOL, V7, P0, DOI 10.3389/fevo.2019.00009
   Lesslie R, 2006, J LAND USE SCI, V1, P45, DOI 10.1080/17474230600605244
   LEVIN SA, 1992, ECOLOGY, V73, P1943, DOI 10.2307/1941447
   Lindenmayer DB, 2018, AUSTRAL ECOL, V43, P798, DOI 10.1111/aec.12622
   Lucas RM, 2006, REMOTE SENS ENVIRON, V100, P388, DOI 10.1016/j.rse.2005.09.020
   Lunt ID, 2007, AUST J BOT, V55, P401, DOI 10.1071/BT06178
   Margules CR, 2000, NATURE, V405, P243, DOI 10.1038/35012251
   Maxwell S, 2016, NATURE, V536, P143, DOI 10.1038/536143a
   McElhinny C., 2006, PACIFIC CONSERVATION BIOLOGY, V12, P89
   McElhinny C, 2005, FOREST ECOL MANAG, V218, P1, DOI 10.1016/j.foreco.2005.08.034
   McNellie MJ, 2019, APPL VEG SCI, V22, P361, DOI 10.1111/avsc.12437
   McNellie MJ, 2015, ECOL INFORM, V30, P230, DOI 10.1016/j.ecoinf.2015.05.012
   Miller J, 2005, PROF GEOGR, V57, P169, DOI 10.1111/j.0033-0124.2005.00470.x
   Morrison LW, 2016, J PLANT ECOL, V9, P367, DOI 10.1093/jpe/rtv077
   Newbold T, 2016, SCIENCE, V353, P288, DOI 10.1126/science.aaf2201
   NOSS RF, 1990, CONSERV BIOL, V4, P355, DOI 10.1111/j.1523-1739.1990.tb00309.x
   NSW Office of Environment and Heritage, 2017, NSW STAT VEG TYP MAP, V0, P0
   OBrien RM, 2007, QUAL QUANT, V41, P673, DOI 10.1007/s11135-006-9018-6
   Olff H, 1998, TRENDS ECOL EVOL, V13, P261, DOI 10.1016/S0169-5347(98)01364-0
   Oliver I, 2021, ECOL INDIC, V124, P0, DOI 10.1016/j.ecolind.2021.107341
   Oliver I, 2019, AUSTRALAS J ENV MAN, V26, P124, DOI 10.1080/14486563.2019.1595186
   Opitz D., 1999, J ARTIF INTELL RES, V11, P0, DOI 10.1613/JAIR.614
   Paramasivam CR., 2019, GIS GEOSTATISTICAL T, V0, PP23, DOI 10.1016/B978-0-12-815413-7.00003-1
   Patterson, 1998, INT CLASSIFICATION E, V0, P0
   Pausas JG, 2001, J VEG SCI, V12, P153, DOI 10.2307/3236601
   Pausas JG, 2019, J ECOL, V107, P1031, DOI 10.1111/1365-2745.13109
   Peet RK, 2013, VEGBANK VEGETATION P, V0, P0
   Pressey RL, 2000, BIOL CONSERV, V96, P55, DOI 10.1016/S0006-3207(00)00050-1
   Pressey RL, 2007, TRENDS ECOL EVOL, V22, P583, DOI 10.1016/j.tree.2007.10.001
   Quinn TP, 2021, METHODS ECOL EVOL, V12, P127, DOI 10.1111/2041-210X.13495
   Rowe N, 2005, NEW PHYTOL, V166, P61, DOI 10.1111/j.1469-8137.2004.01309.x
   Sajid A. H., 2013, CANADIAN BIOSYSTEMS ENGINEERING, V55, P0, DOI 10.7451/CBE.2013.55.1.1
   SAUNDERS DA, 1991, CONSERV BIOL, V5, P18, DOI 10.1111/j.1523-1739.1991.tb00384.x
   Scarth P, 2010, P 15 AUSTR REM SENS, V13, P0
   Schaminee JHJ, 2011, PLANT BIOSYST, V145, P85, DOI 10.1080/11263504.2011.602744
   Schrodt F., 2020, REMOTE SENSING PLANT, V0, PP449, DOI 10.1007/978-3-030-33157-3_17
   Shmueli G, 2010, STAT SCI, V25, P289, DOI 10.1214/10-STS330
   Smith WG, 1913, J ECOL, V1, P16, DOI 10.2307/2255456
   Speed JDM, 2017, BIOL CONSERV, V205, P77, DOI 10.1016/j.biocon.2016.11.030
   Svenning JC, 2013, AM J BOT, V100, P1266, DOI 10.3732/ajb.1200469
   Taylor C, 2020, AUSTRAL ECOL, V45, P340, DOI 10.1111/aec.12863
   Townsend, 2020, REMOTE SENSING PLANT, V0, PP309, DOI 10.1007/978-3-030-33157-3_13
   Townsend PA., 2020, REMOTE SENSING PLANT, V0, PP503, DOI 10.1007/978-3-030-33157-3_19
   Turner MG, 2005, ECOLOGY, V86, P1967, DOI 10.1890/04-0890
   Ustin SL, 2010, NEW PHYTOL, V186, P795, DOI 10.1111/j.1469-8137.2010.03284.x
   Warming E., 1909, OECOLOGY PLANTS, V0, P0
   Williams KJ, 2012, INT J GEOGR INF SCI, V26, P2009, DOI 10.1080/13658816.2012.698015
   Wintle BA, 2005, AUSTRAL ECOL, V30, P719, DOI 10.1111/j.1442-9993.2005.01514.x
   Wiser SK, 2011, APPL VEG SCI, V14, P506, DOI 10.1111/j.1654-109X.2011.01146.x
   Xu TB, 2013, ENVIRON MODELL SOFTW, V40, P267, DOI 10.1016/j.envsoft.2012.10.003
NR 103
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-2973
EI 1572-9761
J9 LANDSCAPE ECOL
JI Landsc. Ecol.
PD MAY 15
PY 2021
VL 36
IS 5
BP 1391
EP 1407
DI 10.1007/s10980-021-01221-x
EA MAR 2021
PG 17
WC Ecology; Geography, Physical; Geosciences, Multidisciplinary
SC Environmental Sciences & Ecology; Physical Geography; Geology
GA RP7BS
UT WOS:000625721500002
DA 2023-04-26
ER

PT J
AU Zang, Q
   Diao, WH
   Chen, KQ
   Liu, L
   Yan, ML
   Sun, X
AF Zang, Qian
   Diao, Wenhui
   Chen, Kaiqiang
   Liu, Ling
   Yan, Menglong
   Sun, Xian
TI CBF-Net: An Adaptive Context Balancing and Feature Filtering Network for Point Cloud Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Balanced context encoding (BCE); filtered feature aggregation; point cloud classification
ID form lidar data; neural-network
AB Point cloud classification is regarded as a critical task in remote sensing data interpretation, which is widely used in many fields. Recently, many proposed methods tend to develop an end-to-end network to directly operate on the raw point cloud, which has shown great power. However, most of these methods abstract local features by equally considering the neighboring points. The features learned may neglect to distinguish contributions of different points especially the edge points and outliers, leading to a coarse classification result especially for boundaries. Moreover, the extracted features are high redundant and intercorrelated with similar categories, posing difficulty in identifying classes sharing similar characteristics especially in complex scenes. Therefore, we propose an adaptive context balancing and feature filtering network (CBF-Net) to tackle the aforementioned problems. First, we introduce a balanced context encoding module to balance semantically the features of neighboring points, which can help the model learn more from the edge points and, therefore, contribute to a finer classification. Then, considering that the interference for similar classes probably causes confusion among them, a filtered feature aggregating module is proposed to filter the extracted features by mapping them into a cleaner subspace with a lower rank. We have conducted thorough experiments on the International Society for Photogrammetry and Remote Sensing 3-D labeling dataset. Experimental results show that our CBF-Net can obtain high accuracy and achieve state-of-the-art level in the categories of Powerline, Car, and Facade. In addition, we also conduct experiments on the RueMonge2014 dataset, which further reveals the strong ability of our model.
C1 [Zang, Qian; Diao, Wenhui; Chen, Kaiqiang; Yan, Menglong; Sun, Xian] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100190, Peoples R China.
   [Zang, Qian; Diao, Wenhui; Chen, Kaiqiang; Yan, Menglong; Sun, Xian] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Network Informat Syst Technol, Beijing 100190, Peoples R China.
   [Zang, Qian; Sun, Xian] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
   [Zang, Qian; Sun, Xian] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 100190, Peoples R China.
   [Liu, Ling] China Commun Informat Technol Grp Co Ltd, Beijing 100089, Peoples R China.
   [Liu, Ling] Tsinghua Univ, Sch Civil Engn, Beijing 100084, Peoples R China.
   [Yan, Menglong] Jigang Def Technol Co Ltd, Jinan 250132, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Tsinghua University
RP Diao, WH (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100190, Peoples R China.; Diao, WH (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Network Informat Syst Technol, Beijing 100190, Peoples R China.
EM zangqian19@mails.ucas.ac.cn; diaowh@aircas.ac.cn; chenkaigiang14@mails.ucas.ac.cn; liuling@ccccltd.cn; yanml@aircas.ac.cn; sunxian@mail.ie.ac.cn
FU National Science Foundation of China [61725105]
CR Babiloni Francesca, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP13942, DOI 10.1109/CVPR42600.2020.01396
   Biswas J, 2012, IEEE INT CONF ROBOT, V0, PP1697, DOI 10.1109/icra.2012.6224766
   Chan JCW, 2008, REMOTE SENS ENVIRON, V112, P2999, DOI 10.1016/j.rse.2008.02.011
   Charaniya Amin P., 2004, 2004 C COMP VIS PATT, V0, PP25, DOI 10.1109/CVPR.2004.446
   Chehata N., 2009, LASERSCANNING, V0, P0
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3081421
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Graham B, 2018, PROC CVPR IEEE, V0, PP9224, DOI 10.1109/CVPR.2018.00961
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   Guo B, 2015, ISPRS J PHOTOGRAMM, V100, P71, DOI 10.1016/j.isprsjprs.2014.04.015
   Huang J, 2016, INT C PATT RECOG, V0, PP2670, DOI 10.1109/ICPR.2016.7900038
   Jiang Mingyang, 2018, ABS180700652 CORR, V0, P0
   Kalman D., 1996, COLL MATH J, V27, P2, DOI 10.1080/07468342.1996.11973744
   LeCun Y., 2016, C TRACK P 4 INT C LE, V0, P0
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li X, 2020, ISPRS J PHOTOGRAMM, V166, P128, DOI 10.1016/j.isprsjprs.2020.05.023
   Lin CH, 2014, ISPRS J PHOTOGRAMM, V94, P70, DOI 10.1016/j.isprsjprs.2014.04.016
   Lodha SK, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, P0
   Mallet C, 2011, ISPRS J PHOTOGRAMM, V66, PS71, DOI 10.1016/j.isprsjprs.2011.09.008
   Niemeyer J, 2016, INT ARCH PHOTOGRAMM, V41, P655, DOI 10.5194/isprsarchives-XLI-B3-655-2016
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Niu RG, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3065112
   Pridmore, 2014, BRIT VIS C, V0, P0
   Qi C. R., 2017, ADV NEURAL INFORM PR, V0, P5099
   Reitberger J, 2008, INT J REMOTE SENS, V29, P1407, DOI 10.1080/01431160701736448
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Riemenschneider H, 2014, LECT NOTES COMPUT SC, V8693, P516, DOI 10.1007/978-3-319-10602-1_34
   Secord J, 2007, IEEE GEOSCI REMOTE S, V4, P196, DOI 10.1109/LGRS.2006.888107
   Sorgel U, 2019, ISPRS ANN PHOTOGRAMM, V0, PP77, DOI 10.5194/ISPRS-ANNALS-IV-2-W5-77-2019
   Stilla U., 2010, P INT SOC PHOT REM S, V0, P0
   Su H, 2015, IEEE I CONF COMP VIS, V0, PP945, DOI 10.1109/ICCV.2015.114
   Tariyal S, 2016, IEEE ACCESS, V4, P10096, DOI 10.1109/ACCESS.2016.2611583
   Thoennessen U., 2007, INTERNATIONAL ARCHIV, V36, P0
   Wagner W, 2008, INT J REMOTE SENS, V29, P1433, DOI 10.1080/01431160701736398
   Wang PS, 2017, ACM T GRAPHIC, V36, P0, DOI 10.1145/3072959.3073608
   Wang Z, 2018, IEEE T GEOSCI REMOTE, V56, P4594, DOI 10.1109/TGRS.2018.2829625
   Weinberger K. Q., 2013, ADV NEUR INF P SYST, V0, P0
   Weinmann M, 2015, ISPRS ANN PHOTO REM, V2-3, P271, DOI 10.5194/isprsannals-II-3-W4-271-2015
   Wen CC, 2020, ISPRS J PHOTOGRAMM, V162, P50, DOI 10.1016/j.isprsjprs.2020.02.004
   Winiwarter L, 2019, PFG-J PHOTOGRAMM REM, V87, P75, DOI 10.1007/s41064-019-00073-0
   Xu S, 2014, ISPRS J PHOTOGRAMM, V88, P1, DOI 10.1016/j.isprsjprs.2013.11.008
   Xu YS, 2020, IEEE J-STARS, V13, P72, DOI 10.1109/JSTARS.2019.2951293
   Yan WY, 2015, REMOTE SENS ENVIRON, V158, P295, DOI 10.1016/j.rse.2014.11.001
   Yang ZS, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18103347
   Yang ZS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090936
   Yousefhussien M, 2018, ISPRS J PHOTOGRAMM, V143, P191, DOI 10.1016/j.isprsjprs.2018.03.018
   Zhao RB, 2018, INT J GEOGR INF SCI, V32, P960, DOI 10.1080/13658816.2018.1431840
NR 48
TC 0
Z9 0
U1 3
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 8703
EP 8717
DI 10.1109/JSTARS.2021.3106376
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UO4XN
UT WOS:000694698900016
DA 2023-04-26
ER

PT J
AU Liu, DY
   Jia, K
   Xia, M
   Wei, XQ
   Yao, YJ
   Zhang, XT
   Tao, GF
AF Liu, Duanyang
   Jia, Kun
   Xia, Mu
   Wei, Xiangqin
   Yao, Yunjun
   Zhang, Xiaotong
   Tao, Guofeng
TI Fractional Vegetation Cover Estimation Algorithm Based on Recurrent Neural Network for MODIS 250 m Reflectance Data
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Vegetation mapping; Estimation; Reflectivity; MODIS; Glass; Land surface; Spatial resolution; Artificial intelligence; multivariate adaptive regression splines; neural networks; subpixel vegetation cover mapping
ID time-series; surface; model; fcover; fapar; lai; information; derivation; principles; variables
AB Fractional vegetation cover (FVC) is a critical land surface parameter, and several large-scale FVC products have been generated based on remote sensing data. Among these existing products, the global land surface satellite (GLASS) FVC product, derived from moderate resolution imaging spectroradiometer (MODIS) 500 m reflectance data (MOD09A1), has achieved complete spatial-temporal continuity and satisfying accuracy. To further improve the spatial resolution of GLASS FVC product, this study developed a novel FVC estimation algorithm for MODIS 250 m reflectance data based on a recurrent neural network with the long short-term memory unit (RNN-LSTM). The RNN-LSTM was established using sequence training samples derived from the MODIS 250 m reflectance and GLASS FVC products, which were conducted over three vegetation types in mid-West China. Additionally, two machine learning methods, including the back propagation neural network (BPNN) and multivariate adaptive regression splines (MARS), were used to compare with the proposed method. The evaluation results showed that RNN-LSTM derived FVC had reliable spatial-temporal continuity and good consistency with the GLASS FVC product. Furthermore, the smooth temporal profiles of the RNN-LSTM FVC estimation indicated that the proposed method was capable of capturing the temporal characteristics of vegetation growth and reducing the uncertainties from the atmosphere and radiation. Finally, an independent validation case in the Heihe area indicated that the RNN-LSTM algorithm achieved the best accuracy (R-2 = 0.8081, rmse = 0.0951) compared with the BPNN (R-2 = 0.7320, rmse = 0.1127) and MARS (R-2 = 0.7361, rmse = 0.1117). This study provides a new approach by showing the potential of the RNN-LSTM method for land surface parameter estimation and related research.
C1 [Liu, Duanyang; Jia, Kun; Xia, Mu; Yao, Yunjun; Zhang, Xiaotong; Tao, Guofeng] Beijing Normal Univ, State Key Lab Remote Sensing Sci, Beijing 100875, Peoples R China.
   [Liu, Duanyang; Jia, Kun; Xia, Mu; Yao, Yunjun; Zhang, Xiaotong; Tao, Guofeng] Beijing Normal Univ, Fac Geog Sci, Beijing Engn Res Ctr Global Land Remote Sensing P, Beijing 100875, Peoples R China.
   [Wei, Xiangqin] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100101, Peoples R China.
C3 Beijing Normal University; Beijing Normal University; Chinese Academy of Sciences
RP Jia, K (corresponding author), Beijing Normal Univ, State Key Lab Remote Sensing Sci, Beijing 100875, Peoples R China.; Jia, K (corresponding author), Beijing Normal Univ, Fac Geog Sci, Beijing Engn Res Ctr Global Land Remote Sensing P, Beijing 100875, Peoples R China.
EM duanyangliu0505@mail.bnu.edu.cn; jiakun@bnu.edu.cn; xiamu@mail.bnu.edu.cn; weixq@aircas.ac.cn; boyyunjun@bnu.edu.cn; xtngzhang@bnu.edu.cn; 201921051079@mail.bnu.edu.cn
FU National Key Research and Development Program of China [2016YFA0600103, 2020YFE0200700, 2019YFE0127300]; Tang Scholar of Beijing Normal University
CR ADAMS JB, 1986, J GEOPHYS RES-SOLID, V91, P8098, DOI 10.1029/JB091iB08p08098
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   [Anonymous], 1997, NEURAL COMPUT, V0, P0
   Arneth A, 2015, NATURE, V524, P44, DOI 10.1038/524044a
   Ayhan B, 2020, PROC SPIE, V11398, P0, DOI 10.1117/12.2557833
   Bacour C, 2006, REMOTE SENS ENVIRON, V105, P313, DOI 10.1016/j.rse.2006.07.014
   Baret F, 2013, REMOTE SENS ENVIRON, V137, P299, DOI 10.1016/j.rse.2012.12.027
   Baret F., 2006, ALGORITHM THEORETICA, V0, P0
   Baret F, 2007, REMOTE SENS ENVIRON, V110, P275, DOI 10.1016/j.rse.2007.02.018
   Barlage M, 2004, J HYDROMETEOROL, V5, P823, DOI 10.1175/1525-7541(2004)005<0823:TEOOFV>2.0.CO;2
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bian JH, 2017, REMOTE SENS ENVIRON, V197, P98, DOI 10.1016/j.rse.2017.05.031
   Bo Y., 2011, REMOTE SENS TECHNOL, V19, P443
   Camacho F., 2016, P EGU GEN ASS C, V0, PEPSC2016
   Camacho F, 2013, REMOTE SENS ENVIRON, V137, P310, DOI 10.1016/j.rse.2013.02.030
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2004, REMOTE SENS ENVIRON, V91, P332, DOI 10.1016/j.rse.2004.03.014
   Chen J., 2017, ACTA OECOL, V24, P1
   Czyzowska-Wisniewski EH, 2015, REMOTE SENS ENVIRON, V156, P403, DOI 10.1016/j.rse.2014.09.026
   Dobreva ID, 2011, REMOTE SENS ENVIRON, V115, P3355, DOI 10.1016/j.rse.2011.07.018
   Donohue RJ, 2010, J HYDROL, V390, P23, DOI 10.1016/j.jhydrol.2010.06.025
   Ferro CJS, 2002, PHOTOGRAMM ENG REM S, V68, P51
   Friedl MA, 2010, REMOTE SENS ENVIRON, V114, P168, DOI 10.1016/j.rse.2009.08.016
   FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963
   Fu XG, 2015, IEEE T NEUR NET LEAR, V26, P1900, DOI 10.1109/TNNLS.2014.2361267
   Gao L, 2020, ISPRS J PHOTOGRAMM, V159, P364, DOI 10.1016/j.isprsjprs.2019.11.018
   Garcia-Haro FJ, 2005, INT J REMOTE SENS, V26, P2135, DOI 10.1080/01431160512331337817
   Grings F, 2020, IEEE T GEOSCI REMOTE, V58, P1303, DOI 10.1109/TGRS.2019.2945719
   Gutman G, 1998, INT J REMOTE SENS, V19, P1533, DOI 10.1080/014311698215333
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA, V0, P0, DOI DOI 10.1109/9780470544037.CH14
   Jekabsons G., 2011, ARESLAB ADAPTIVE REG, V0, P0
   Jekabsons G, 2016, ARESLAB ADAPTIVE REG, V0, P0
   Jia K, 2015, IEEE T GEOSCI REMOTE, V53, P4787, DOI 10.1109/TGRS.2015.2409563
   Jia K, 2014, REMOTE SENS LETT, V5, P148, DOI 10.1080/2150704X.2014.889862
   Jia K, 2011, INT J REMOTE SENS, V32, P9307, DOI 10.1080/01431161.2011.554454
   Jiang MC, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030271
   Jiapaer G, 2011, AGR FOREST METEOROL, V151, P1698, DOI 10.1016/j.agrformet.2011.07.004
   Jimenez-Munoz JC, 2009, SENSORS-BASEL, V9, P768, DOI 10.3390/s90200768
   Kuter S, 2021, REMOTE SENS ENVIRON, V255, P0, DOI 10.1016/j.rse.2021.112294
   Kuter S, 2018, REMOTE SENS ENVIRON, V205, P236, DOI 10.1016/j.rse.2017.11.021
   Kwan C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122000
   Kwan C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091392
   Kwan C, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040520
   Kwan C, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18041051
   Li YS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12234003
   Liu DY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212524
   Liu DY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101648
   Liu YK, 2012, J VEG SCI, V23, P406, DOI 10.1111/j.1654-1103.2011.01373.x
   Lyu D, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182942
   Ma JH, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091388
   Melia J., 2009, P 29 EARSEL S CHIN G, V0, P1
   Mou LC, 2018, INT GEOSCI REMOTE SE, V0, P4363
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Mu XH, 2018, REMOTE SENS ENVIRON, V216, P44, DOI 10.1016/j.rse.2018.06.022
   Mu XH, 2015, IEEE J-STARS, V8, P439, DOI 10.1109/JSTARS.2014.2342257
   Olson DM, 2001, BIOSCIENCE, V51, P933, DOI 10.1641/0006-3568(2001)051[0933:TEOTWA]2.0.CO;2
   Rodriguez P, 1999, CONNECT SCI, V11, P5, DOI 10.1080/095400999116340
   Roujean JL, 2002, J GEOPHYS RES-ATMOS, V107, P0, DOI 10.1029/2001JD000751
   ROUJEAN JL, 1992, J GEOPHYS RES-ATMOS, V97, P20455, DOI 10.1029/92JD01411
   Schafer RW, 2011, IEEE SIGNAL PROC MAG, V28, P111, DOI 10.1109/MSP.2011.941097
   Srivastava S, 2018, SOL ENERGY, V162, P232, DOI 10.1016/j.solener.2018.01.005
   Sugiyarto AW, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA SCIENCES (AIDAS2019), V0, PP53, DOI 10.1109/AiDAS47888.2019.8970735
   Sulla-Menashe D., 2018, USER GUIDE COLLECTIO, V0, P1
   Tang HR, 2013, INT J DIGIT EARTH, V6, P157, DOI 10.1080/17538947.2013.833313
   Tu YX, 2020, IEEE GEOSCI REMOTE S, V17, P1672, DOI 10.1109/LGRS.2019.2954291
   Tu YX, 2020, INT J DIGIT EARTH, V13, P487, DOI 10.1080/17538947.2018.1531438
   Verger A., 2013, P MULTITEMP 2013 7 I, V0, P1
   Verger A., 1900, P277, V0, P0
   Wang XX, 2016, IEEE T GEOSCI REMOTE, V54, P7442, DOI 10.1109/TGRS.2016.2604007
   Weiss M, 2000, AGRONOMIE, V20, P3, DOI 10.1051/agro:2000105
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wu H, 2009, SENSORS-BASEL, V9, P1768, DOI 10.3390/s90301768
   Xiao JF, 2005, REMOTE SENS ENVIRON, V98, P237, DOI 10.1016/j.rse.2005.07.011
   Xue J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030324
   Yan J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010037
   Yang LQ, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8080682
   Zeng XB, 2000, J APPL METEOROL, V39, P826, DOI 10.1175/1520-0450(2000)039<0826:DAEOGK>2.0.CO;2
   Zeng XB, 2002, J CLIMATE, V15, P1832, DOI 10.1175/1520-0442(2002)015&lt;1832:COTCLM&gt;2.0.CO;2
   Zhan XC, 2019, IEEE T GEOSCI REMOTE, V57, P9344, DOI 10.1109/TGRS.2019.2926392
   Zhang XF, 2013, INT J APPL EARTH OBS, V21, P506, DOI 10.1016/j.jag.2012.07.003
   Zhang YT, 2020, IEEE INT CON MULTI, V0, P0
   Zhou F, 2019, NEUROCOMPUTING, V328, P39, DOI 10.1016/j.neucom.2018.02.105
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 85
TC 2
Z9 2
U1 18
U2 40
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 6532
EP 6543
DI 10.1109/JSTARS.2021.3075624
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TJ4GO
UT WOS:000673442300013
DA 2023-04-26
ER

PT J
AU Lumnitz, S
   Devisscher, T
   Mayaud, JR
   Radic, V
   Coops, NC
   Griess, VC
AF Lumnitz, Stefanie
   Devisscher, Tahia
   Mayaud, Jerome R.
   Radic, Valentina
   Coops, Nicholas C.
   Griess, Verena C.
TI Mapping trees along urban street networks with deep learning and street-level imagery
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Deep learning; Instance segmentation; Monocular depth estimation; Street-level images; Urban forest management
ID view; health; point
AB Planning and managing urban forests for livable cities remains a challenge worldwide owing to sparse information on the spatial distribution, structure and composition of urban trees and forests. National and municipal sources of tree inventory remain limited due to a lack of detailed, consistent and frequent inventory assessments. Despite advancements in research on the automation of urban tree mapping using Light Detection and Ranging (LiDAR) or high-resolution satellite imagery, in practice most municipalities still perform labor-intensive field surveys to collect and update tree inventories. We present a robust, affordable and rapid method for creating tree inventories in any urban region where sufficient street-level imagery is readily available. Our approach is novel in that we use a Mask Regional Convolutional Neural Network (Mask R-CNN) to detect and locate separate tree instances from street-level imagery, thereby successfully creating shape masks around unique fuzzy urban objects like trees. The novelty of this method is enhanced by using monocular depth estimation and triangulation to estimate precise tree location, relying only on photographs and images taken from the street. Experiments across four cities show that our method is transferable to different image sources (Google Street View, Mapillary) and urban ecosystems. We successfully detect >70% of all public and private trees recorded in a ground-truth campaign across Metro Vancouver. The accuracy of geolocation is also promising. We automatically locate public and private trees with a mean error in the absolute position ranging from 4 to 6 m, which is comparable to ground-truth measurements in conventional manual urban tree inventory campaigns.
C1 [Lumnitz, Stefanie; Devisscher, Tahia; Coops, Nicholas C.] Univ British Columbia, Dept Forest Resources Management, Vancouver, BC, Canada.
   [Lumnitz, Stefanie] European Space Agcy, ESRIN, Frascati, Italy.
   [Mayaud, Jerome R.] Spare Labs Inc, Vancouver, BC, Canada.
   [Radic, Valentina] Univ British Columbia, Dept Earth Ocean Atmospher Sci, Vancouver, BC, Canada.
   [Griess, Verena C.] ETH, Dept Environm Syst Sci, Inst Terr Ecosyst, Zurich, Switzerland.
C3 University of British Columbia; European Space Agency; University of British Columbia; Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Lumnitz, S (corresponding author), Univ British Columbia, Dept Forest Resources Management, Vancouver, BC, Canada.
EM Stefanie.Lumnitz@gmail.com
FU University of British Columbia; Genome Canada; Genome British Columbia; Genome Quebec under the research project Biosurveillance of Alien Forest Enemies (bioSAFE) as part of the 2015 Large-Scale Applied Research Project competition in Natural Resources and the Environment: Sector Challenges - Genomic Solutions [10106]; Banting Postdoctoral Fellowship program [201709BPF-393653-294704]; Social Sciences and Humanities Research Council (SSHRC) of Canada
CR Abdulla W., 2017, GITHUB REPOSITORY, V0, P0
   Agarwal S, 2010, COMPUTER, V43, P40, DOI 10.1109/MC.2010.175
   Alberti M, 2003, BIOSCIENCE, V53, P1169, DOI 10.1641/0006-3568(2003)053[1169:IHIEOA]2.0.CO;2
   Alberti M., 2008, ADV URBAN ECOLOGY IN, V0, P0
   Alonzo M, 2014, REMOTE SENS ENVIRON, V148, P70, DOI 10.1016/j.rse.2014.03.018
   [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   Aval J, 2018, ISPRS J PHOTOGRAMM, V146, P197, DOI 10.1016/j.isprsjprs.2018.09.016
   Berland A, 2017, URBAN FOR URBAN GREE, V21, P11, DOI 10.1016/j.ufug.2016.11.006
   Bolei Z., 2017, COCO PLACES 2017 CHA, V0, P0
   Branson S, 2018, ISPRS J PHOTOGRAMM, V135, P13, DOI 10.1016/j.isprsjprs.2017.11.008
   Caesar H., 2016, ARXIV161203716, V0, P0
   Cai B.Y., 2018, TREEPEDIA 2 0 APPL D, V0, P0
   Cheng L, 2018, ISPRS J PHOTOGRAMM, V141, P72, DOI 10.1016/j.isprsjprs.2018.04.006
   Chollet F., 2017, DEEP LEARNING PYTHON, V0, P0
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Davis J, 2006, PROC 23 INT C MACH L, V0, PP233, DOI 10.1145/1143844.1143874
   Duarte F., 2017, HUM DIG REAL DES MOD, V0, PP59, DOI 10.1007/978-981-10-6611-5_6
   Falco G, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17020255
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C., 2016, ARXIV160903677, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jang KM, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9100586
   Kang YH, 2020, ANN GIS, V26, P261, DOI 10.1080/19475683.2020.1791954
   Ke YH, 2011, INT J REMOTE SENS, V32, P4725, DOI 10.1080/01431161.2010.494184
   Kelly M, 2007, COMPUT ENVIRON URBAN, V31, P689, DOI 10.1016/j.compenvurbsys.2006.10.002
   Kisantal M., 2019, ARXIV190207296, V0, P0
   Krylov VA, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050661
   Laumer D, 2020, ISPRS J PHOTOGRAMM, V162, P125, DOI 10.1016/j.isprsjprs.2020.02.001
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lefevre S, 2017, P IEEE, V105, P1884, DOI 10.1109/JPROC.2017.2684300
   Li SN, 2016, ISPRS J PHOTOGRAMM, V115, P119, DOI 10.1016/j.isprsjprs.2015.10.012
   Li XJ, 2017, LECT NOTES GEOINF CA, V0, PP341, DOI 10.1007/978-3-319-57336-6_24
   Li XJ, 2018, LANDSCAPE URBAN PLAN, V169, P81, DOI 10.1016/j.landurbplan.2017.08.011
   Li XJ, 2015, URBAN FOR URBAN GREE, V14, P675, DOI 10.1016/j.ufug.2015.06.006
   Li X, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101144
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Michels J., 2005, P 22 INT C MACHINE L, V0, PP593, DOI 10.1145/1102351.1102426
   Nielsen P, 2014, LECT N PROD ENG, V0, PP17, DOI 10.1007/978-3-319-04271-8_2
   Nitoslawski SA, 2016, FORESTS, V7, P0, DOI 10.3390/f7060119
   Nowak DJ, 2014, ENVIRON POLLUT, V193, P119, DOI 10.1016/j.envpol.2014.05.028
   Padayachee AL, 2017, BIOL INVASIONS, V19, P3557, DOI 10.1007/s10530-017-1596-9
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Plowright AA, 2017, REMOTE SENS ENVIRON, V194, P391, DOI 10.1016/j.rse.2017.03.045
   Plowright AA, 2016, URBAN FOR URBAN GREE, V19, P140, DOI 10.1016/j.ufug.2016.06.026
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seiferling I, 2017, LANDSCAPE URBAN PLAN, V165, P93, DOI 10.1016/j.landurbplan.2017.05.010
   Small C, 2001, INT J REMOTE SENS, V22, P1305, DOI 10.1080/01431160151144369
   Steele F., 2016, TECH REP, V0, P0
   Stewart I., 2010, URBAN CLIM, V0, P7
   Stubbings P, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121395
   Tippetts B, 2016, J REAL-TIME IMAGE PR, V11, P5, DOI 10.1007/s11554-012-0313-2
   van den Bosch M, 2017, ENVIRON RES, V158, P373, DOI 10.1016/j.envres.2017.05.040
   Wegner JD, 2016, PROC CVPR IEEE, V0, PP6014, DOI 10.1109/CVPR.2016.647
   Yin DM, 2016, INT J REMOTE SENS, V37, P4521, DOI 10.1080/01431161.2016.1214302
   Zhang X, 2018, ISPRS J PHOTOGRAMM, V140, P77, DOI 10.1016/j.isprsjprs.2017.07.009
   Zhen Z, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8040333
NR 59
TC 31
Z9 31
U1 25
U2 68
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY 15
PY 2021
VL 175
IS 
BP 144
EP 157
DI 10.1016/j.isprsjprs.2021.01.016
EA MAR 2021
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT8HA
UT WOS:000644695700011
DA 2023-04-26
ER

PT J
AU Kuo, CL
   Tsai, MH
AF Kuo, Chiao-Ling
   Tsai, Ming-Hua
TI Road Characteristics Detection Based on Joint Convolutional Neural Networks with Adaptive Squares
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE road characteristics detection; roadmap tiles; deep learning; CNN; adaptive squares; combination rules
ID intersection detection; automatic extraction; gps traces; land-cover; images; classification; features; quality; safety; maps
AB The importance of road characteristics has been highlighted, as road characteristics are fundamental structures established to support many transportation-relevant services. However, there is still huge room for improvement in terms of types and performance of road characteristics detection. With the advantage of geographically tiled maps with high update rates, remarkable accessibility, and increasing availability, this paper proposes a novel simple deep-learning-based approach, namely joint convolutional neural networks (CNNs) adopting adaptive squares with combination rules to detect road characteristics from roadmap tiles. The proposed joint CNNs are responsible for the foreground and background image classification and various types of road characteristics classification from previous foreground images, raising detection accuracy. The adaptive squares with combination rules help efficiently focus road characteristics, augmenting the ability to detect them and provide optimal detection results. Five types of road characteristics-crossroads, T-junctions, Y-junctions, corners, and curves-are exploited, and experimental results demonstrate successful outcomes with outstanding performance in reality. The information of exploited road characteristics with location and type is, thus, converted from human-readable to machine-readable, the results will benefit many applications like feature point reminders, road condition reports, or alert detection for users, drivers, and even autonomous vehicles. We believe this approach will also enable a new path for object detection and geospatial information extraction from valuable map tiles.
C1 [Kuo, Chiao-Ling; Tsai, Ming-Hua] Acad Sinica, Res Ctr Humanities & Social Sci, Taipei 11529, Taiwan.
   [Kuo, Chiao-Ling] Natl Taiwan Univ, Dept Geog, Taipei 10617, Taiwan.
C3 Academia Sinica - Taiwan; National Taiwan University
RP Kuo, CL (corresponding author), Acad Sinica, Res Ctr Humanities & Social Sci, Taipei 11529, Taiwan.; Kuo, CL (corresponding author), Natl Taiwan Univ, Dept Geog, Taipei 10617, Taiwan.
EM kuo@chiaoling.com; caps9129@gmail.com
FU Ministry of Science and Technology, Taiwan (R.O.C.) [MOST 108-2621-M-001-001-]
CR Bakhtiari HRR, 2017, EGYPT J REMOTE SENS, V20, P117, DOI 10.1016/j.ejrs.2017.03.001
   Bastani F., 2018, P IEEE C COMP VIS PA, V0, P0
   Behrendt K., 2017, P 2017 IEEE INT C RO, V0, P0
   Bhatt D., 2017, P 2017 IEEE RSJ INT, V0, P0
   Chen BQ, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9030181
   Chen C., 2016, P 2016 IEEE INT VEH, V0, P0
   Chiang Y.Y., 2005, P 13 ANN ACM INT WOR, V0, P0
   Chiang YY, 2009, GEOINFORMATICA, V13, P121, DOI 10.1007/s10707-008-0046-3
   Ewing R, 2016, URBAN STUD, V53, P247, DOI 10.1177/0042098014562331
   Farahani RZ, 2013, EUR J OPER RES, V229, P281, DOI 10.1016/j.ejor.2013.01.001
   Hosang J, 2017, PROC CVPR IEEE, V0, PP6469, DOI 10.1109/CVPR.2017.685
   Hu J, 2007, IEEE T GEOSCI REMOTE, V45, P4144, DOI 10.1109/TGRS.2007.906107
   Iagnemma K., 2018, U.S. PATENT, V0, Patent No. [US10126136B2, 10126136]
   Jacobs KT, 2020, T GIS, V24, P1280, DOI 10.1111/tgis.12680
   Jung JY, 2018, ELECTRONICS-SWITZ, V7, P0, DOI 10.3390/electronics7110276
   Kastanakis B, 2016, MAPBOX COOKBOOK, V0, P0
   Keller S, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9110638
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Li J, 2022, IEEE T IND ELECTRON, V69, P2708, DOI 10.1109/TIE.2021.3070508
   Li L, 2017, ISPRS INT GEO-INF, V6, P0, DOI 10.3390/ijgi6120403
   Liu J, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6100314
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Marshall WE, 2011, ACCIDENT ANAL PREV, V43, P769, DOI 10.1016/j.aap.2010.10.024
   Martinelli L., 2015, VECTOR TILES OPENSTR, V0, P0
   Maso J., 2010, IMPLEMENT STANDARD V, V1, P114
   Mokhtarzade M, 2007, INT J APPL EARTH OBS, V9, P32, DOI 10.1016/j.jag.2006.05.001
   Montella A, 2020, ACCIDENT ANAL PREV, V141, P0, DOI 10.1016/j.aap.2020.105523
   Mooney P., 2017, MAPPING CITIZEN SENS, V0, PP37, DOI 10.5334/BBF.C
   Mundhenk T.N., 2016, EUR C COMP VIS BERL, V0, P0
   Munoz-Organero M, 2018, COMPUT ENVIRON URBAN, V68, P1, DOI 10.1016/j.compenvurbsys.2017.09.005
   Nasiri A, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7070253
   Novack T, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113794
   Pathak A.R., 2018, PROCEDIA COMPUTER SC, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Pourabdollah A, 2013, ISPRS INT GEO-INF, V2, P704, DOI 10.3390/ijgi2030704
   Qiu J, 2016, PHOTOGRAMM ENG REM S, V82, P593, DOI 10.14358/PERS.82.8.593
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruiz JJ, 2011, SURV REV, V43, P212, DOI 10.1179/003962611X12894696205109
   Saeedimoghaddam M, 2020, INT J GEOGR INF SCI, V34, P947, DOI 10.1080/13658816.2019.1696968
   Sehra SS, 2017, FUTURE INTERNET, V9, P0, DOI 10.3390/fi9020015
   Shi N.X., 2010, U.S. PATENT, V0, Patent No. [US7734412B2, 7734412]
   Simonyan K, 2015, ARXIV, V0, P0
   Soilan M, 2018, INT J APPL EARTH OBS, V64, P226, DOI 10.1016/j.jag.2017.09.010
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Wang J, 2017, COMPUT ENVIRON URBAN, V64, P19, DOI 10.1016/j.compenvurbsys.2016.12.006
   Wang XS, 2013, ACCIDENT ANAL PREV, V56, P22, DOI 10.1016/j.aap.2013.02.026
   Wang ZY, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18072100
   Wu SB, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8110478
   Xie K, 2014, ANAL METHODS ACCID R, V2, P39, DOI 10.1016/j.amar.2014.06.001
   Xie XZ, 2017, ISPRS INT GEO-INF, V6, P0, DOI 10.3390/ijgi6100311
   Xie XZ, 2015, ISPRS INT J GEO-INF, V4, P2446, DOI 10.3390/ijgi4042446
   Yang C, 2020, INT J GEOGR INF SCI, V34, P996, DOI 10.1080/13658816.2019.1700510
   Yang X, 2018, TRANSPORT RES C-EMER, V89, P168, DOI 10.1016/j.trc.2018.02.007
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zourlidou S., 2019, P 22 AGILE C GEOGR I, V0, P0
NR 55
TC 6
Z9 6
U1 2
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD JUN 15
PY 2021
VL 10
IS 6
BP 
EP 
DI 10.3390/ijgi10060377
PG 20
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA SZ4LD
UT WOS:000666537700001
DA 2023-04-26
ER

PT J
AU Kajla, NI
   Missen, MMS
   Luqman, MM
   Coustaty, M
AF Kajla, Nadeem Iqbal
   Missen, Malik Muhammad Saad
   Luqman, Muhammad Muzzamil
   Coustaty, Mickael
TI Graph Neural Networks Using Local Descriptions in Attributed Graphs: An Application to Symbol Recognition and Hand Written Character Recognition
SO IEEE ACCESS
LA English
DT Article
DE Text analysis; Graph neural networks; Mathematical model; Numerical models; Message passing; Computer architecture; Measurement; Graph Neural Networks (GNN); attributed graphs; graph matching; local descriptions; graph similarity; graph learning; graph classification; document image analysis (DIA); pattern recognition (PR)
ID edit distance
AB Graph-based methods have been widely used by the document image analysis and recognition community, as the different objects and the content in document images is best represented by this powerful structural representation. Designing of novel computation tools for processing these graph-based structural representations has always remained a hot topic of research. Recently, Graph Neural Network (GNN) have been used for solving different problems in the domain of document image analysis and recognition. In this article we take forward the state of the art by presenting a new approach to gather the symbolic and numeric information from the nodes and edges of a graph. We use this information to learn a Graph Neural Network (GNN). The experimentation on the recognition of handwritten letters and graphical symbols shows that the proposed approach is an interesting contribution to the growing set of GNN-based methods for document image analysis and recognition.
C1 [Kajla, Nadeem Iqbal; Missen, Malik Muhammad Saad] Islamia Univ Bahawalpur, Dept IT, Bahawalpur 63100, Pakistan.
   [Luqman, Muhammad Muzzamil; Coustaty, Mickael] La Rochelle Univ, Lab Informat Image & Interact L3i, F-17000 La Rochelle, France.
C3 Islamia University of Bahawalpur
RP Missen, MMS (corresponding author), Islamia Univ Bahawalpur, Dept IT, Bahawalpur 63100, Pakistan.; Coustaty, M (corresponding author), La Rochelle Univ, Lab Informat Image & Interact L3i, F-17000 La Rochelle, France.
EM saad.missen@iub.edu.pk; mickael.coustaty@univ-lr.fr
FU European Regional Development Fund Program: Interreg Atlantic Area Program; LabCom IDEAS [ANR-18-LCV3-0008]
CR Abu-Aisheh Z, 2017, PATTERN RECOGN LETT, V100, P96, DOI 10.1016/j.patrec.2017.10.007
   Battaglia P., 2016, NIPS, V0, P4502
   Bianchi FM, 2014, SOFT COMPUT, V18, P393, DOI 10.1007/s00500-013-1065-z
   Borzeshi EZ, 2013, PATTERN RECOGN, V46, P1648, DOI 10.1016/j.patcog.2012.11.020
   Bromley J., 1993, INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, V7, P669, DOI 10.1142/S0218001493000339
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruna J., 2013, PROC 2 INT C LEARN R, V0, P0
   Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3
   Bunke H, 2011, PATTERN RECOGN, V44, P1057, DOI 10.1016/j.patcog.2010.11.015
   Cho K., 2014, 8 WORKSHOP SYNTAX SE, V0, Pabs/1409.1259
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Defferrard M, 2016, NEURAL INFORM PROCES, V30, P3844
   Dutta A., 2017, ARXIV170200156, V0, P0
   Dutta A, 2017, PROC INT CONF DOC, V0, PP33, DOI 10.1109/ICDAR.2017.15
   Fankhauser S, 2011, LECT NOTES COMPUT SC, V6658, P102, DOI 10.1007/978-3-642-20844-7_11
   Fischer A, 2015, PATTERN RECOGN, V48, P331, DOI 10.1016/j.patcog.2014.07.015
   Foggia P, 2014, INT J PATTERN RECOGN, V28, P0, DOI 10.1142/S0218001414500013
   Gilmer J, 2017, PR MACH LEARN RES, V70, P0
   Jain BJ, 2011, LECT NOTES COMPUT SC, V6658, P62, DOI 10.1007/978-3-642-20844-7_7
   Jain BJ, 2010, LECT NOTES COMPUT SC, V6218, P109, DOI 10.1007/978-3-642-14980-1_10
   Jouili S, 2009, LECT NOTES COMPUT SC, V5807, P89
   Kuhn HW., 1955, NAV RES LOG, V2, P83, DOI 10.1002/NAV.3800020109
   Li Y, 2015, ARXIV, V0, P0
   Luqman MM, 2013, PATTERN RECOGN, V46, P551, DOI 10.1016/j.patcog.2012.07.029
   Monti F, 2017, PROC CVPR IEEE, V0, PP5425, DOI 10.1109/CVPR.2017.576
   Riba P, 2018, INT C PATT RECOG, V0, PP2239, DOI 10.1109/ICPR.2018.8545310
   Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004
   Riesen K, 2009, ENG APPL ARTIF INTEL, V22, P48, DOI 10.1016/j.engappai.2008.04.006
   Riesen K, 2008, LECT NOTES COMPUT SC, V5342, P287
   Schutt KT, 2017, NAT COMMUN, V8, P0, DOI 10.1038/ncomms13890
   Sidere Nicolas, 2009, 2009 10TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR), V0, PP681, DOI 10.1109/ICDAR.2009.218
   Sidere N., 2009, P IAPR WORKSH GRAPH P IAPR WORKSH GRAPH, V0, P44
   Wu Y, 2016, ARXIV, V0, P0
NR 33
TC 5
Z9 5
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2021
VL 9
IS 
BP 99103
EP 99111
DI 10.1109/ACCESS.2021.3096845
PG 9
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA TL9QU
UT WOS:000675188400001
DA 2023-04-26
ER

PT J
AU Zang, N
   Cao, Y
   Wang, YB
   Huang, B
   Zhang, LQ
   Mathiopoulos, PT
AF Zang, Ning
   Cao, Yun
   Wang, Yuebin
   Huang, Bo
   Zhang, Liqiang
   Mathiopoulos, P. Takis
TI Land-Use Mapping for High-Spatial Resolution Remote Sensing Image Via Deep Learning: A Review
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Review
DE Semantics; Meters; Buildings; Satellites; Remote sensing; Image segmentation; Spatial resolution; Deep learning (DL); high-spatial resolution remote sensing images (HSR-RSIs); land-use mapping (LUM); semantic segmentation
ID convolutional neural-network; semantic segmentation; supervised classification; domain adaptation; aerial imagery; sensed images; representations; extraction; buildings; cnn
AB Land-use mapping (LUM) using high-spatial resolution remote sensing images (HSR-RSIs) is a challenging and crucial technology. However, due to the characteristics of HSR-RSIs, such as different image acquisition conditions and massive, detailed information, and performing LUM faces unique scientific challenges. With the emergence of new deep learning (DL) algorithms in recent years, methods to LUM with DL have achieved huge breakthroughs, which offer novel opportunities for the development of LUM for HSR-RSIs. This article aims to provide a thorough review of recent achievements in this field. Existing high spatial resolution datasets in the research of semantic segmentation and single-object segmentation are presented first. Next, we introduce several basic DL approaches that are frequently adopted for LUM. After reviewing DL-based LUM methods comprehensively, which highlights the contributions of researchers in the field of LUM for HSR-RSIs, we summarize these DL-based approaches based on two LUM criteria. Individually, the first one has supervised learning, semisupervised learning, or unsupervised learning, while another one is pixel-based or object-based. We then briefly review the fundamentals and the developments of the development of semantic segmentation and single-object segmentation. At last, quantitative results that experiment on the dataset of ISPRS Vaihingen and ISPRS Potsdam are given for several representative models such as fully convolutional network (FCN) and U-Net, following up with a comparison and discussion of the results.
C1 [Zang, Ning; Cao, Yun; Wang, Yuebin] China Univ Geosci, Sch Land Sci & Technol, Beijing 100083, Peoples R China.
   [Huang, Bo] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Zhang, Liqiang] Beijing Normal Univ, Fac Geog Sci, Beijing 100875, Peoples R China.
   [Mathiopoulos, P. Takis] Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece.
C3 China University of Geosciences; Chinese University of Hong Kong; Beijing Normal University; National & Kapodistrian University of Athens
RP Wang, YB (corresponding author), China Univ Geosci, Sch Land Sci & Technol, Beijing 100083, Peoples R China.
EM zangning97@163.com; cy12160019@163.com; xxgcdxwyb@163.com; bohuang@cuhk.edu.hk; zhanglq@bnu.edu.cn; mathio@hol.gr
FU National Natural Science Foundation of China [41801241]; Fundamental Research Funds for the Central Universities [292018029, 375201906]; Key Research, and Development Projects of Shanxi Province [201903D121142]; Open Fund of the State Key Laboratory of Remote Sensing Science [OFSLRSS201923]; Guizhou Science, and Technology Plan Project [Qiankehezhicheng [2020] 4Y022]
CR Aggarwal N., 2016, INT J ENG TRENDS TEC, V38, P5, DOI 10.14445/22315381/IJETT-V38P202
   Alvarez JM, 2012, LECT NOTES COMPUT SC, V7578, P376, DOI 10.1007/978-3-642-33786-4_28
   Amit SNKB, 2017, FRONT ARTIF INTEL AP, V292, P249, DOI 10.3233/978-1-61499-720-7-249
   Aoki E. Y, 2015, IMAGE PROCESS MACH V, V9405, P0
   Ardila JP, 2011, ISPRS J PHOTOGRAMM, V66, P762, DOI 10.1016/j.isprsjprs.2011.08.002
   ASLI OO, 2015, OPEN REMOTE SENS J, V7, P5611
   Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Audebert N, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040368
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Audebert N, 2016, INT GEOSCI REMOTE SE, V0, PP5091, DOI 10.1109/IGARSS.2016.7730327
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banerjee B, 2015, J INDIAN SOC REMOTE, V43, P719, DOI 10.1007/s12524-014-0370-z
   Belward AS, 2015, ISPRS J PHOTOGRAMM, V103, P115, DOI 10.1016/j.isprsjprs.2014.03.009
   Bian C, 2020, MED IMAGE ANAL, V64, P0, DOI 10.1016/j.media.2020.101732
   Bittner K, 2018, IEEE J-STARS, V11, P2615, DOI 10.1109/JSTARS.2018.2849363
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P2587, DOI 10.1109/TGRS.2006.875360
   Bulo SR, 2018, PROC CVPR IEEE, V0, PP5639, DOI 10.1109/CVPR.2018.00591
   Buslaev A, 2018, IEEE COMPUT SOC CONF, V0, PP197, DOI 10.1109/CVPRW.2018.00035
   Camps-Valls G, 2007, IEEE T GEOSCI REMOTE, V45, P3044, DOI 10.1109/TGRS.2007.895416
   Cao R, 2020, INT J REMOTE SENS, V41, P740, DOI 10.1080/2150704X.2019.1647368
   Censi AM, 2021, IEEE ACCESS, V9, P23070, DOI 10.1109/ACCESS.2021.3055554
   Che J, 1900, V13, V0, P2021
   Chen J., 2020, ADV NEURAL NETWORKS, V0, P0
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, PP801, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, V0, PP1, DOI 10.1109/NANOARCH.2017.8053709
   Chen Q, 2019, ISPRS J PHOTOGRAMM, V147, P42, DOI 10.1016/j.isprsjprs.2018.11.011
   Chen YH, 2018, PROC CVPR IEEE, V0, PP7892, DOI 10.1109/CVPR.2018.00823
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng DC, 2017, IEEE J-STARS, V10, P5769, DOI 10.1109/JSTARS.2017.2747599
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Davydow A, 2018, IEEE COMPUT SOC CONF, V0, PP280, DOI 10.1109/CVPRW.2018.00053
   Demir I, 2018, IEEE COMPUT SOC CONF, V0, PP172, DOI 10.1109/CVPRW.2018.00031
   Diba A, 2017, PROC CVPR IEEE, V0, PP5131, DOI 10.1109/CVPR.2017.545
   Ding AZ, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, V0, P0
   Ding HH, 2019, IEEE I CONF COMP VIS, V0, PP6818, DOI 10.1109/ICCV.2019.00692
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Du SJ, 2021, INT J DIGIT EARTH, V14, P357, DOI 10.1080/17538947.2020.1831087
   Fang B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020159
   Fetaya N, 2015, P BRIT MACH VIS C, V0, P0
   Fidler S., 2020, P IEEE CVF INT C COM, V0, P5229
   Fu G, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050498
   Fu TY, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.025010
   Gomez-Chova L, 2008, IEEE GEOSCI REMOTE S, V5, P336, DOI 10.1109/LGRS.2008.916070
   Gong JQ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071557
   Guangrui Li, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12359), V0, PP440, DOI 10.1007/978-3-030-58568-6_26
   Guo R, 2018, ISPRS INT J GEO-INF, V7, P0, DOI 10.3390/ijgi7030110
   HARIHARAN B, 2015, PROC CVPR IEEE, V0, PP447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Henry C, 2018, IEEE GEOSCI REMOTE S, V15, P1867, DOI 10.1109/LGRS.2018.2864342
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Howard A. G., 2017, MOBILENETS EFFICIENT, V0, P0
   Hu F, 2016, INT CONF SIGN PROCES, V0, PP192, DOI 10.1109/ICSP.2016.7877822
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2015, IEEE T GEOSCI REMOTE, V53, P3639, DOI 10.1109/TGRS.2014.2380779
   Huang X, 2014, ISPRS J PHOTOGRAMM, V90, P36, DOI 10.1016/j.isprsjprs.2014.01.008
   Huang X, 2012, IEEE J-STARS, V5, P161, DOI 10.1109/JSTARS.2011.2168195
   Ibrahim M. S., 2020, P IEEE CVF C COMP VI, V0, PP12712, DOI 10.1109/CVPR42600.2020.01273
   Jegou S, 2017, IEEE COMPUT SOC CONF, V0, PP1175, DOI 10.1109/CVPRW.2017.156
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang XJ, 2013, 2013 SIXTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), V0, PP256, DOI 10.1109/ICACI.2013.6748512
   JIANWEN M, 2005, INT J APPL EARTH OBS, V7, P183
   Jinyu Yang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12372), V0, PP480, DOI 10.1007/978-3-030-58583-9_29
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Kampffmeyer M, 2018, IEEE J-STARS, V11, P1758, DOI 10.1109/JSTARS.2018.2834961
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, V0, PP680, DOI 10.1109/CVPRW.2016.90
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kiyasu S., 2011, SICE 2011 - 50TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN, V0, P2402
   Kiyasu Senya, 2009, 2009 ICROS-SICE INTERNATIONAL JOINT CONFERENCE. ICCAS-SICE 2009, V0, P4874
   Kreso I, 2017, IEEE INT CONF COMP V, V0, PP238, DOI 10.1109/ICCVW.2017.37
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Laddha A, 2016, IEEE INT VEH SYM, V0, PP118, DOI 10.1109/IVS.2016.7535374
   Laine S., 2016, ARXIV161002242, V0, P0
   Lan M, 2020, INFORM SCIENCES, V535, P156, DOI 10.1016/j.ins.2020.05.062
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee H., 2009, P 26 ANN INT C MACHI, V0, PP609, DOI 10.1145/1553374.1553453
   Li HZ, 2021, IEEE SYST J, V15, P3189, DOI 10.1109/TSMC.2019.2963398
   Li MC, 2016, INT J APPL EARTH OBS, V49, P87, DOI 10.1016/j.jag.2016.01.011
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li WJ, 2016, INT J REMOTE SENS, V37, P5632, DOI 10.1080/01431161.2016.1246775
   Li X, 2019, PROC CVPR IEEE, V0, PP510, DOI 10.1109/CVPR.2019.00060
   Li X, 2017, IEEE J-STARS, V10, P2022, DOI 10.1109/JSTARS.2016.2646138
   Li YS, 2016, IEEE GEOSCI REMOTE S, V13, P157, DOI 10.1109/LGRS.2015.2503142
   Li YH, 2018, PROC CVPR IEEE, V0, PP1091, DOI 10.1109/CVPR.2018.00120
   Lian Q, 2019, IEEE I CONF COMP VIS, V0, PP6757, DOI 10.1109/ICCV.2019.00686
   Liu QH, 2020, IEEE T GEOSCI REMOTE, V58, P6309, DOI 10.1109/TGRS.2020.2976658
   Liu W, 2020, IEEE T GEOSCI REMOTE, V58, P4279, DOI 10.1109/TGRS.2019.2962039
   Liu YS, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.016501
   Liu Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060522
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Lu QK, 2017, REMOTE SENS LETT, V8, P1210, DOI 10.1080/2150704X.2017.1375610
   Lv Q, 2014, INT GEOSCI REMOTE SE, V0, P0, DOI DOI 10.1109/IGARSS.2014.6947537
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Ma L, 2019, IEEE T GEOSCI REMOTE, V57, P2305, DOI 10.1109/TGRS.2018.2872850
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Matasci G, 2015, IEEE T GEOSCI REMOTE, V53, P3550, DOI 10.1109/TGRS.2014.2377785
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mnih V., 2013, MACHINE LEARNING AER, V0, P0
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P7557, DOI 10.1109/TGRS.2020.2979552
   Muller X., 2011, PROC 28 INT C MACH L, V0, P833
   Nogueira K, 2016, INT C PATT RECOG, V0, PP3566, DOI 10.1109/ICPR.2016.7900187
   Noh H, 2015, IEEE I CONF COMP VIS, V0, PP1520, DOI 10.1109/ICCV.2015.178
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Onim M., 2020, P 2 INT C ADV INF CO, V0, P0
   Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642
   Paisitkriangkrai Sakrapee, 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP36, DOI 10.1109/CVPRW.2015.7301381
   Paisitkriangkrai S, 2016, IEEE J-STARS, V9, P2868, DOI 10.1109/JSTARS.2016.2582921
   Pan XR, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113774
   Pandey Prashant, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12351), V0, PP413, DOI 10.1007/978-3-030-58539-6_25
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Paul S., 2020, ECCV, V0, P571
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Persello C, 2014, IEEE T GEOSCI REMOTE, V52, P6937, DOI 10.1109/TGRS.2014.2305805
   Persello C, 2012, IEEE T GEOSCI REMOTE, V50, P4468, DOI 10.1109/TGRS.2012.2192740
   QI L, 2015, J SENSORS, V2015, P1
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), V0, PP1, DOI 10.1109/ICPHM.2017.7998297
   Qin YC, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19051164
   Rahman M. A, 2020, ARXIV200810736, V0, P0
   Razavian A- S., 2014, P IEEE C COMP VIS PA, V1403, P6382, DOI 10.1109/cvprw.2014.131
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Romero A, 2015, IEEE T PATTERN ANAL, V37, P1716, DOI 10.1109/TPAMI.2014.2366129
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rottensteiner F., 2014, ISPRS SEMANTIC LABEL, V1, P4, DOI 10.13140/2.1.3570.9445
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SAEID N, 2018, IEEE T GEOSCI ELECT, V56, P1425
   Samy M, 2018, IEEE COMPUT SOC CONF, V0, PP267, DOI 10.1109/CVPRW.2018.00050
   Seferbekov S, 2018, IEEE COMPUT SOC CONF, V0, PP272, DOI 10.1109/CVPRW.2018.00051
   Sener Ozan, 2016, ADV NEURAL INFORM PR, V29, P2110
   Sherrah J., 2016, ARXIV160602585, V0, P0
   Shi H, 2015, IEEE GEOSCI REMOTE S, V12, P1948, DOI 10.1109/LGRS.2015.2439696
   Shi YL, 2020, ISPRS J PHOTOGRAMM, V159, P184, DOI 10.1016/j.isprsjprs.2019.11.004
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Simonyan K., 2015, 3 INT C LEARN REPR I, V0, P1
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Souly N, 2017, IEEE I CONF COMP VIS, V0, PP5689, DOI 10.1109/ICCV.2017.606
   Srivastava PK, 2012, ADV SPACE RES, V50, P1250, DOI 10.1016/j.asr.2012.06.032
   Sun J, 1900, V14, V0, P2327
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   Sun X, 2020, IEEE J-STARS, V13, P5398, DOI 10.1109/JSTARS.2020.3021098
   Sun XF, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.042617
   Sun Y., 2019, UNSUPERVISED DOMAIN, V0, P2
   Szegedy, 2014, INTRIGUING PROPERTIE, V0, P0, DOI DOI 10.1109/CVPR.2015.7298594
   Tan YH, 2019, PHOTOGRAMM ENG REM S, V85, P737, DOI 10.14358/PERS.85.10.737
   Tang H, 2020, P IEEE CVF INT C COM, V0, P992
   Tao YT, 2017, IEEE T GEOSCI REMOTE, V55, P6805, DOI 10.1109/TGRS.2017.2734697
   Tian C., 2019, COMPUTER VISION PATT, V0, P192
   Tong X.-Y., 2018, ARXIV180705713, V0, P0
   Tong XY, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111322
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   Tzeng E, 2017, PROC CVPR IEEE, V0, PP2962, DOI 10.1109/CVPR.2017.316
   Vincent P, 2008, P 25 INT C MACH LEAR, V0, PP1096, DOI 10.1145/1390156.1390294
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Volpi M, 2015, IEEE COMPUT SOC CONF, V0, P0, DOI DOI 10.1109/CVPRW.2015.7301377
   Voltersen M, 2014, REMOTE SENS ENVIRON, V154, P192, DOI 10.1016/j.rse.2014.08.024
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, P0, DOI 10.1155/2018/7068349
   Wang HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050446
   Wei YC, 2018, PROC CVPR IEEE, V0, PP7268, DOI 10.1109/CVPR.2018.00759
   WEIXING W, 2016, J TRAFFIC TRANSP ENG, V3, P271
   Xiaoyong H., 2016, ACTA OPT SINICA, V36, P0
   Xie J., 2020, J PHYS C SOLID STATE, V1607, P0
   Xu YH, 2019, IEEE J-STARS, V12, P1709, DOI 10.1109/JSTARS.2019.2911113
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010144
   Yang X, 2019, INT GEOSCI REMOTE SE, V0, PP5913, DOI 10.1109/IGARSS.2019.8898705
   Yao C., 2017, INT ARCH PHOTOGRAMM, V2, P989, DOI 10.5194/isprs-archives-XLII-2-W7-989-2017
   Yao XD, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19122792
   Yokoya N, 2018, IEEE J-STARS, V11, P1363, DOI 10.1109/JSTARS.2018.2799698
   Yuan M, 2019, INT J REMOTE SENS, V40, P8359, DOI 10.1080/01431161.2019.1608393
   Zeng Y, 2019, IEEE I CONF COMP VIS, V0, PP7222, DOI 10.1109/ICCV.2019.00732
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang C, 2018, ISPRS J PHOTOGRAMM, V140, P133, DOI 10.1016/j.isprsjprs.2017.07.014
   Zhang CH, 2012, PRECIS AGRIC, V13, P693, DOI 10.1007/s11119-012-9274-5
   Zhang L., 2020, P IEEE CVF INT C COM, V0, P8838
   Zhang LF, 2019, INFORM SCIENCES, V485, P154, DOI 10.1016/j.ins.2019.02.008
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang L, 2019, IEEE I CONF COMP VIS, V0, PP5581, DOI 10.1109/ICCV.2019.00568
   Zhang M, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050500
   Zhang XD, 2017, IEEE J-STARS, V10, P3373, DOI 10.1109/JSTARS.2017.2672736
   Zhao B, 2017, IEEE GEOSCI REMOTE S, V14, P1436, DOI 10.1109/LGRS.2017.2691013
   Zhao B, 2016, ISPRS J PHOTOGRAMM, V116, P73, DOI 10.1016/j.isprsjprs.2016.03.004
   Zhao WQ, 2019, IEEE T SYST MAN CY-S, V49, P1254, DOI 10.1109/TSMC.2017.2724440
   Zhao WZ, 2017, ISPRS J PHOTOGRAMM, V132, P48, DOI 10.1016/j.isprsjprs.2017.08.011
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
   Zhaohong D, 2016, PLOS ONE, V11, P0
   Zhonghao Wang, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP12632, DOI 10.1109/CVPR42600.2020.01265
   Zhu QQ, 2016, IEEE GEOSCI REMOTE S, V13, P747, DOI 10.1109/LGRS.2015.2513443
   Zhu X. X., 2018, RIFCN RECURRENT NETW, V0, P0
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zhu Y, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), V0, P0, DOI DOI 10.1145/2820783.2820851
   2015, 1900, V36, V0, P3368
NR 200
TC 10
Z9 11
U1 30
U2 122
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 5372
EP 5391
DI 10.1109/JSTARS.2021.3078631
PG 20
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SQ8YW
UT WOS:000660636600008
DA 2023-04-26
ER

PT J
AU Gao, GS
   Liu, QJ
   Wang, YH
AF Gao, Guangshuai
   Liu, Qingjie
   Wang, Yunhong
TI Counting From Sky: A Large-Scale Data Set for Remote Sensing Object Counting and a Benchmark Method
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Attention mechanism; deformable convolution layer; object counting; remote sensing; scale pyramid module (SPM)
AB Object counting, whose aim is to estimate the number of objects from a given image, is an important and challenging computation task. Significant efforts have been devoted to addressing this problem and achieved great progress, yet counting the number of ground objects from remote sensing images is barely studied. In this article, we are interested in counting dense objects from remote sensing images. Compared with object counting in a natural scene, this task is challenging in the following factors: large-scale variation, complex cluttered background, and orientation arbitrariness. More importantly, the scarcity of data severely limits the development of research in this field. To address these issues, we first construct a large-scale object counting data set with remote sensing images, which contains four important geographic objects: buildings, crowded ships in harbors, and large vehicles and small vehicles in parking lots. We then benchmark the data set by designing a novel neural network that can generate a density map of an input image. The proposed network consists of three parts, namely attention module, scale pyramid module, and deformable convolution module (DCM) to attack the aforementioned challenging factors. Extensive experiments are performed on the proposed data set and one crowd counting data set, which demonstrates the challenges of the proposed data set and the superiority and effectiveness of our method compared with state-of-the-art methods.
C1 [Gao, Guangshuai; Liu, Qingjie; Wang, Yunhong] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Gao, Guangshuai; Liu, Qingjie; Wang, Yunhong] Beihang Univ, Hangzhou Innovat Inst, Hangzhou 310051, Peoples R China.
C3 Beihang University; Beihang University
RP Liu, QJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM gaoguangshuai1990@buaa.edu.cn; qingjie.liu@buaa.edu.cn; yhwang@buaa.edu.cn
FU National Natural Science Foundation of China [41871283, U1804157, 61601011]
CR Abd Mubin N, 2019, INT J REMOTE SENS, V40, P7500, DOI 10.1080/01431161.2019.1569282
   Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Bahdanau D, 2016, ARXIV, V0, P0
   Bahmanyar R, 2019, MRCNET CROWD COUNTIN, V0, P1
   Bazi Y, 2009, INT GEOSCI REMOTE SE, V0, PP1235, DOI 10.1109/IGARSS.2009.5418266
   Boominathan L, 2016, MM16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, V0, PP640, DOI 10.1145/2964284.2967300
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chen L, 2017, PROC CVPR IEEE, V0, PP6298, DOI 10.1109/CVPR.2017.667
   Chen XY, 2019, IEEE WINT CONF APPL, V0, PP1941, DOI 10.1109/WACV.2019.00211
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Dai JF, 2017, IEEE I CONF COMP VIS, V0, PP764, DOI 10.1109/ICCV.2017.89
   Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Fan YD, 2017, INT J DISAST RISK SC, V8, P471, DOI 10.1007/s13753-017-0143-8
   French Geoffrey, 2015, BRIT MACH VIS C WORK, V0, P0, DOI DOI 10.5244/C.29.MVAB.7
   Gao GS, 2020, INT CONF ACOUST SPEE, V0, PP4137, DOI 10.1109/ICASSP40776.2020.9053690
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   Guan L, 2016, INT GEOSCI REMOTE SE, V0, PP7299, DOI 10.1109/IGARSS.2016.7730904
   Guerrero-Gomez-Olmedo R, 2015, LECT NOTES COMPUT SC, V9117, P423, DOI 10.1007/978-3-319-19390-8_48
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hossain MA, 2019, IEEE WINT CONF APPL, V0, PP1280, DOI 10.1109/WACV.2019.00141
   Hsieh MR, 2017, IEEE I CONF COMP VIS, V0, PP4165, DOI 10.1109/ICCV.2017.446
   Huang YJ, 2019, AAAI CONF ARTIF INTE, V0, P8497
   Kang D., 2018, BRIT MACHINE VISION, V0, P0
   Lempitsky V., 2010, P 23 INT C NEURAL IN, V23, P1324
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li YH, 2018, PROC CVPR IEEE, V0, PP1091, DOI 10.1109/CVPR.2018.00120
   Liu J, 2018, PROC CVPR IEEE, V0, PP5197, DOI 10.1109/CVPR.2018.00545
   Liu N, 2019, PROC CVPR IEEE, V0, PP3220, DOI 10.1109/CVPR.2019.00334
   Liu WZ, 2019, PROC CVPR IEEE, V0, PP5094, DOI 10.1109/CVPR.2019.00524
   Liu X, 2018, INT GEOSCI REMOTE SE, V0, P7137
   Lowe D. G., 1999, INT C COMP VIS, V0, P0
   Ma ZH, 2019, IEEE I CONF COMP VIS, V0, PP6141, DOI 10.1109/ICCV.2019.00624
   Mundhenk TN, 2016, LECT NOTES COMPUT SC, V9907, P785, DOI 10.1007/978-3-319-46487-9_48
   Onoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Paragios N, 2001, PROC CVPR IEEE, V0, P1034
   Paszke, 2019, ADV NEURAL INFORM PR, V0, P8024
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Rathore MM, 2016, COMPUT NETW, V101, P63, DOI 10.1016/j.comnet.2015.12.023
   REDMON J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salami E, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030316
   Sam DB, 2018, PROC CVPR IEEE, V0, PP3618, DOI 10.1109/CVPR.2018.00381
   Sam DB, 2017, PROC CVPR IEEE, V0, PP4031, DOI 10.1109/CVPR.2017.429
   Sang J, 2019, IEEE ACCESS, V7, P24411, DOI 10.1109/ACCESS.2019.2899939
   Simonyan K, 2015, ARXIV, V0, P0
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, V0, PP1, DOI 10.1109/AVSS.2017.8078491
   Sindagi V. A., 2020, P ECCV, V0, P1
   Sindagi VA, 2017, IEEE I CONF COMP VIS, V0, PP1879, DOI 10.1109/ICCV.2017.206
   Song H, 2018, JOINT INT CONF SOFT, V0, PP718, DOI 10.1109/SCIS-ISIS.2018.00119
   Tao Y, 2017, CHIN CONTR CONF, V0, PP4288, DOI 10.23919/ChiCC.2017.8028032
   Tian Y., 2010, P AS C COMP VIS QUEE, V0, P679
   Varior R. Rama, 2019, ARXIV190106026, V0, P0
   Pham VQ, 2015, IEEE I CONF COMP VIS, V0, PP3253, DOI 10.1109/ICCV.2015.372
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang F, 2017, PROC CVPR IEEE, V0, PP6450, DOI 10.1109/CVPR.2017.683
   Wang Q, 2019, PROC CVPR IEEE, V0, PP8190, DOI 10.1109/CVPR.2019.00839
   Wang SL, 2018, PROC CVPR IEEE, V0, PP2589, DOI 10.1109/CVPR.2018.00274
   Wang Y, 2016, IEEE IMAGE PROC, V0, PP3653, DOI 10.1109/ICIP.2016.7533041
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia GS, 2018, PROC CVPR IEEE, V0, PP3974, DOI 10.1109/CVPR.2018.00418
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   YANG S, 2016, PROC CVPR IEEE, V0, PP5525, DOI 10.1109/CVPR.2016.596
   Yang ZC, 2016, PROC CVPR IEEE, V0, PP21, DOI 10.1109/CVPR.2016.10
   You QZ, 2016, PROC CVPR IEEE, V0, PP4651, DOI 10.1109/CVPR.2016.503
   Yu F., 2015, 1511 ARXIV, V0, P0
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang A, 2019, IEEE I CONF COMP VIS, V0, PP5713, DOI 10.1109/ICCV.2019.00581
   Zhang Hanwang, 2017, PROC CVPR IEEE, V0, PP5532, DOI 10.1109/CVPR.2017.331
   Zhang L, 2018, IEEE WINT CONF APPL, V0, PP1113, DOI 10.1109/WACV.2018.00127
   Zhang SH, 2017, IEEE I CONF COMP VIS, V0, PP3687, DOI 10.1109/ICCV.2017.396
   Zhang YY, 2016, PROC CVPR IEEE, V0, PP589, DOI 10.1109/CVPR.2016.70
   Zhu L., 2019, ARXIV190201115, V0, P0
NR 76
TC 17
Z9 17
U1 0
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD MAY 15
PY 2021
VL 59
IS 5
BP 3642
EP 3655
DI 10.1109/TGRS.2020.3020555
PG 14
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology
GA RQ0FT
UT WOS:000642096400003
DA 2023-04-26
ER

PT J
AU Ranjgar, B
   Razavi-Termeh, SV
   Foroughnia, F
   Sadeghi-Niaraki, A
   Perissin, D
AF Ranjgar, Babak
   Razavi-Termeh, Seyed Vahid
   Foroughnia, Fatemeh
   Sadeghi-Niaraki, Abolghasem
   Perissin, Daniele
TI Land Subsidence Susceptibility Mapping Using Persistent Scatterer SAR Interferometry Technique and Optimized Hybrid Machine Learning Algorithms
SO REMOTE SENSING
LA English
DT Article
DE land subsidence; Geographic Information System (GIS); InSAR; machine learning algorithm; meta-heuristics; Iran
ID google earth engine; cloud computing platform; spatial prediction; sentinel imagery; neural-networks; insar; model; tehran; anfis; plain
AB In this paper, land subsidence susceptibility was assessed for Shahryar County in Iran using the adaptive neuro-fuzzy inference system (ANFIS) machine learning algorithm. Another aim of the present paper was to assess if ensembles of ANFIS with two meta-heuristic algorithms (imperialist competitive algorithm (ICA) and gray wolf optimization (GWO)) would yield a better prediction performance. A remote sensing synthetic aperture radar (SAR) dataset from 2019 to 2020 and the persistent-scatterer SAR interferometry (PS-InSAR) technique were used to obtain a land subsidence inventory of the study area and use it for training and testing models. Resulting PS points were divided into two parts of 70% and 30% for training and testing the models, respectively. For susceptibility analysis, eleven conditioning factors were taken into account: the altitude, slope, aspect, plan curvature, profile curvature, topographic wetness index (TWI), distance to stream, distance to road, stream density, groundwater drawdown, and land use/land cover (LULC). A frequency ratio (FR) was applied to assess the correlation of factors to subsidence occurrence. The prediction power of the models and their generated land subsidence susceptibility maps (LSSMs) were validated using the root mean square error (RMSE) value and area under curve of receiver operating characteristic (AUC-ROC) analysis. The ROC results showed that ANFIS-ICA had the best accuracy (0.932) among the models (ANFIS-GWO (0.926), ANFIS (0.908)). The results of this work showed that optimizing ANFIS with meta-heuristics considerably improves LSSM accuracy although ANFIS alone had an acceptable result.
C1 [Ranjgar, Babak; Razavi-Termeh, Seyed Vahid; Sadeghi-Niaraki, Abolghasem] KN Toosi Univ Technol, Fac Geodesy & Geomat Engn, Geoinformat Tech Ctr Excellence, Tehran 19697, Iran.
   [Foroughnia, Fatemeh] Delft Univ Technol, Dept Geosci & Remote Sensing, Civil Engn & Geosci Fac, NL-2628 CN Delft, Stevinweg, Netherlands.
   [Sadeghi-Niaraki, Abolghasem] Sejong Univ, Dept Comp Sci & Engn, Seoul 143747, South Korea.
   [Perissin, Daniele] Radar & Software Engn Res Co, RASER Ltd, Hong Kong, Peoples R China.
C3 K. N. Toosi University of Technology; Delft University of Technology; Sejong University
RP Foroughnia, F (corresponding author), Delft Univ Technol, Dept Geosci & Remote Sensing, Civil Engn & Geosci Fac, NL-2628 CN Delft, Stevinweg, Netherlands.
EM babakranjgar@email.kntu.ac.ir; vrazavi@mail.kntu.ac.ir; f.foroughnia@tudelft.nl; a.sadeghi@sejong.ac.kr; daniele.perissin@sarproz.com
CR Abdollahi S, 2019, B ENG GEOL ENVIRON, V78, P4017, DOI 10.1007/s10064-018-1403-6
   Amani M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213561
   Amani M, 2020, IEEE J-STARS, V13, P5326, DOI 10.1109/JSTARS.2020.3021052
   Arabameri A, 2020, SCI TOTAL ENVIRON, V726, P0, DOI 10.1016/j.scitotenv.2020.138595
   Arabameri A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030490
   Atashpaz-Gargari E, 2007, IEEE C EVOL COMPUTAT, V0, PP4661, DOI 10.1109/CEC.2007.4425083
   Bianchini S, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11172015
   Chaussard E, 2014, REMOTE SENS ENVIRON, V140, P94, DOI 10.1016/j.rse.2013.08.038
   Chen W, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9183755
   Choi JK, 2010, ENVIRON EARTH SCI, V59, P1009, DOI 10.1007/s12665-009-0093-6
   Conway BD, 2016, HYDROGEOL J, V24, P649, DOI 10.1007/s10040-015-1329-z
   Dehghani M, 2013, ISPRS J PHOTOGRAMM, V79, P157, DOI 10.1016/j.isprsjprs.2013.02.012
   Del Soldato M, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10071146
   Bui DT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18082464
   Bui DT, 2012, COMPUT GEOSCI-UK, V45, P199, DOI 10.1016/j.cageo.2011.10.031
   Ebrahimy H, 2020, ENVIRON EARTH SCI, V79, P0, DOI 10.1007/s12665-020-08953-0
   Ferretti A, 2001, IEEE T GEOSCI REMOTE, V39, P8, DOI 10.1109/36.898661
   Fiaschi S, 2017, GISCI REMOTE SENS, V54, P305, DOI 10.1080/15481603.2016.1269404
   Foroughnia F, 2019, INT J APPL EARTH OBS, V74, P248, DOI 10.1016/j.jag.2018.09.018
   Galloway D., 1999, LAND SUBSIDENCE US, V1182, P0
   Galloway DL, 2011, HYDROGEOL J, V19, P1459, DOI 10.1007/s10040-011-0775-5
   Gargari EA, 2008, INT J INTELL COMPUT, V1, P337, DOI 10.1108/17563780810893446
   Ghorbanian A, 2020, ISPRS J PHOTOGRAMM, V167, P276, DOI 10.1016/j.isprsjprs.2020.07.013
   Ghorbanzadeh Omid, 2020, JOURNAL OF SPATIAL SCIENCE, V65, P401, DOI 10.1080/14498596.2018.1505564
   Ghorbanzadeh O, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7758-y
   Hakim WL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12213627
   Holzer TL, 2005, REV ENG GEOL, V16, P87, DOI 10.1130/2005.4016(08)
   Hooper A, 2007, J GEOPHYS RES-SOL EA, V112, P0, DOI 10.1029/2006JB004763
   Hu BB, 2009, ENVIRON EARTH SCI, V59, P269, DOI 10.1007/s12665-009-0024-6
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Kampes B., 2005, DISPLACEMENT PARAMET, V0, P0
   Kampes B.M., 2006, RADAR INTERFEROMETRY, VVolume 12, P0
   Lee S, 2013, J ENVIRON MANAGE, V127, P166, DOI 10.1016/j.jenvman.2013.04.010
   Lee S, 2012, ENVIRON MANAGE, V49, P347, DOI 10.1007/s00267-011-9766-5
   Mahmoudpour M, 2016, ENG GEOL, V201, P6, DOI 10.1016/j.enggeo.2015.12.004
   Meraj R, 2015, INT J MIN SCI TECHNO, V25, P655, DOI 10.1016/j.ijmst.2015.05.021
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moayedi H, 2020, J ENVIRON MANAGE, V260, P0, DOI 10.1016/j.jenvman.2019.109867
   Modoni G, 2013, ENG GEOL, V167, P59, DOI 10.1016/j.enggeo.2013.10.014
   Mohammady M, 2019, ENVIRON EARTH SCI, V78, P0, DOI 10.1007/s12665-019-8518-3
   Motagh M, 2008, GEOPHYS RES LETT, V35, P0, DOI 10.1029/2008GL033814
   Oh HJ, 2011, ENVIRON EARTH SCI, V64, P347, DOI 10.1007/s12665-010-0855-1
   Pacheco-Martinez J, 2015, REMOTE SENS-BASEL, V7, P17035, DOI 10.3390/rs71215868
   Pepe A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110911
   Perissin D, 2012, ISPRS J PHOTOGRAMM, V73, P58, DOI 10.1016/j.isprsjprs.2012.07.002
   Polykretis C, 2019, B ENG GEOL ENVIRON, V78, P1173, DOI 10.1007/s10064-017-1125-1
   Pourghasemi HR, 2020, J HYDROL, V582, P0, DOI 10.1016/j.jhydrol.2019.124536
   Pourghasemi HR, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, V0, PP147, DOI 10.1016/B978-0-12-815226-3.00006-5
   Pourghasemi HR, 2015, GEOCARTO INT, V30, P662, DOI 10.1080/10106049.2014.966161
   Pradhan B, 2014, NAT HAZARDS, V73, P1019, DOI 10.1007/s11069-014-1128-1
   Rahmati O, 2020, SCI REP-UK, V10, P0, DOI 10.1038/s41598-020-69703-7
   Rahmati O, 2019, SCI TOTAL ENVIRON, V672, P239, DOI 10.1016/j.scitotenv.2019.03.496
   Rahmati O, 2019, J ENVIRON MANAGE, V236, P466, DOI 10.1016/j.jenvman.2019.02.020
   Rahmati O, 2016, GEOCARTO INT, V31, P42, DOI 10.1080/10106049.2015.1041559
   Raspini F, 2016, NAT HAZARDS, V83, PS155, DOI 10.1007/s11069-016-2341-x
   Razavi-Termeh SV, 2020, HYDROLOG SCI J, V65, P2729, DOI 10.1080/02626667.2020.1828589
   Razavi-Termeh SV, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101689
   Razavi-Termeh SV, 2020, GEOMAT NAT HAZ RISK, V11, P0, DOI 10.1080/19475705.2020.1753824
   Regmi AD, 2014, ARAB J GEOSCI, V7, P725, DOI 10.1007/s12517-012-0807-z
   Ren HR, 2020, INT J APPL EARTH OBS, V92, P0, DOI 10.1016/j.jag.2020.102115
   Rezaei M, 2022, GEOCARTO INT, V37, P1465, DOI 10.1080/10106049.2020.1768596
   Shi XQ, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-5019-x
   Stanley JD, 2013, J COASTAL RES, V29, P657, DOI 10.2112/JCOASTRES-D-12A-00011.1
   Suganthi S, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-3207-6
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Taravatrooy N, 2018, NAT HAZARDS, V94, P905, DOI 10.1007/s11069-018-3431-8
   Tarighat F, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13030407
   Termeh SVR, 2019, HYDROGEOL J, V27, P2511, DOI 10.1007/s10040-019-02017-9
   Termeh SVR, 2018, SCI TOTAL ENVIRON, V615, P438, DOI 10.1016/j.scitotenv.2017.09.262
   Tomas R, 2014, ENVIRON EARTH SCI, V71, P163, DOI 10.1007/s12665-013-2422-z
   Wang QQ, 2017, PHYS GEOGR, V38, P318, DOI 10.1080/02723646.2017.1294522
   Xue YQ, 2005, ENVIRON GEOL, V48, P713, DOI 10.1007/s00254-005-0010-6
   Ye SJ, 2016, HYDROGEOL J, V24, P685, DOI 10.1007/s10040-015-1356-9
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Zhou GQ, 2016, COMPUT GEOSCI-UK, V89, P144, DOI 10.1016/j.cageo.2016.02.001
NR 75
TC 25
Z9 25
U1 9
U2 35
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD APR 15
PY 2021
VL 13
IS 7
BP 
EP 
DI 10.3390/rs13071326
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RL2GT
UT WOS:000638798800001
DA 2023-04-26
ER

PT J
AU Rybnikova, N
   Mirkes, EM
   Gorban, AN
AF Rybnikova, Nataliya
   Mirkes, Evgeny M.
   Gorban, Alexander N.
TI CNN-Based Spectral Super-Resolution of Panchromatic Night-Time Light Imagery: City-Size-Associated Neighborhood Effects
SO SENSORS
LA English
DT Article
DE night-time light (NTL); panchromatic; red; green; blue (RGB) bands; international space station (ISS); convolutional neural network (CNN); neighborhood effect
ID artificial-light; economic-activity; exposure; population; pollution; obesity
AB Data on artificial night-time light (NTL), emitted from the areas, and captured by satellites, are available at a global scale in panchromatic format. In the meantime, data on spectral properties of NTL give more information for further analysis. Such data, however, are available locally or on a commercial basis only. In our recent work, we examined several machine learning techniques, such as linear regression, kernel regression, random forest, and elastic map models, to convert the panchromatic NTL images into colored ones. We compared red, green, and blue light levels for eight geographical areas all over the world with panchromatic light intensities and characteristics of built-up extent from spatially corresponding pixels and their nearest neighbors. In the meantime, information from more distant neighboring pixels might improve the predictive power of models. In the present study, we explore this neighborhood effect using convolutional neural networks (CNN). The main outcome of our analysis is that the neighborhood effect goes in line with the geographical extent of metropolitan areas under analysis: For smaller areas, optimal input image size is smaller than for bigger ones. At that, for relatively large cities, the optimal input image size tends to differ for different colors, being on average higher for red and lower for blue lights. Compared to other machine learning techniques, CNN models emerged comparable in terms of Pearson's correlation but showed performed better in terms of WMSE, especially for testing datasets.
C1 [Rybnikova, Nataliya; Mirkes, Evgeny M.; Gorban, Alexander N.] Univ Leicester, Dept Math, Leicester LE1 7RH, Leics, England.
   [Rybnikova, Nataliya] Univ Haifa, Dept Nat Resources & Environm Management, IL-3498838 Haifa, Israel.
   [Rybnikova, Nataliya] Univ Haifa, Dept Geog & Environm Studies, IL-3498838 Haifa, Israel.
   [Mirkes, Evgeny M.; Gorban, Alexander N.] Lobachevsky Univ, Inst Informat Technol Math & Mech, Nizhnii Novgorod 603105, Russia.
C3 University of Leicester; University of Haifa; University of Haifa; Lobachevsky State University of Nizhni Novgorod
RP Rybnikova, N (corresponding author), Univ Leicester, Dept Math, Leicester LE1 7RH, Leics, England.; Rybnikova, N (corresponding author), Univ Haifa, Dept Nat Resources & Environm Management, IL-3498838 Haifa, Israel.; Rybnikova, N (corresponding author), Univ Haifa, Dept Geog & Environm Studies, IL-3498838 Haifa, Israel.
EM nataliya.rybnikova@gmail.com; m322@leicester.ac.uk; a.n.gorban@leicester.ac.uk
FU Council for Higher Education of Israel; Ministry of Science and Higher Education of the Russian Federation [075-15-2021-634]
CR AESCHBACHER J, 2017, P IEEE INT C COMPUTE, V0, P0
   [Anonymous], 2010, OPEN GEOGRAPHY J, V0, P0, DOI DOI 10.2174/1874923201003010147
   ARAD B, 2016, P 14 EUROPEAN C, V0, P0, DOI DOI 10.1007/978-3-319-46478-7
   Arun PV, 2020, SIGNAL PROCESS, V169, P0, DOI 10.1016/j.sigpro.2019.107394
   Bennie J, 2015, REMOTE SENS-BASEL, V7, P2715, DOI 10.3390/rs70302715
   Bugeau A, 2014, IEEE T IMAGE PROCESS, V23, P298, DOI 10.1109/TIP.2013.2288929
   Cajochen C, 2005, J CLIN ENDOCR METAB, V90, P1311, DOI 10.1210/jc.2004-0957
   Can Y. B., 2018, ARXIV180404647, V0, P0
   Cheong JY, 2017, IEEE SIGNAL PROC LET, V24, P1252, DOI 10.1109/LSP.2017.2721104
   Chia AYS, 2011, ACM T GRAPHIC, V30, P0, DOI 10.1145/2024156.2024190
   Cinzano P, 2000, MON NOT R ASTRON SOC, V318, P641, DOI 10.1046/j.1365-8711.2000.03562.x
   Deshpande A, 2015, IEEE I CONF COMP VIS, V0, PP567, DOI 10.1109/ICCV.2015.72
   Doll CNH, 2006, ECOL ECON, V57, P75, DOI 10.1016/j.ecolecon.2005.03.007
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Ebener Steeve, 2005, INT J HEALTH GEOGR, V4, P5, DOI 10.1186/1476-072X-4-5
   Elvidge C.D., 2013, P ASIA PACIFIC ADV N, V35, P0, DOI 10.7125/APAN.35.7
   Elvidge CD, 1997, INT J REMOTE SENS, V18, P1373, DOI 10.1080/014311697218485
   Falchi F, 2019, J ENVIRON MANAGE, V248, P0, DOI 10.1016/j.jenvman.2019.06.128
   Falchi F, 2016, SCI ADV, V2, P0, DOI 10.1126/sciadv.1600377
   Galliani S., 2017, ARXIV170309470, V0, P0, DOI DOI 10.48550/arXiv.1703.09470
   Guk E, 2020, ISPRS J PHOTOGRAMM, V163, P121, DOI 10.1016/j.isprsjprs.2020.02.016
   Haim A., 2013, LIGHT POLLUTION NEW, V0, P0, DOI DOI 10.1007/978-94-007-6220-6
   Hopkins GR, 2018, FRONT ECOL ENVIRON, V16, P472, DOI 10.1002/fee.1828
   Hu ZY, 2018, ENVIRON POLLUT, V239, P30, DOI 10.1016/j.envpol.2018.04.021
   Ironi R., 2005, PROC EGSR, V29, P201
   Kawakami R., 2011, 2011 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), V0, PP2329, DOI 10.1109/CVPR.2011.5995457
   Kloog I, 2009, CHRONOBIOL INT, V26, P108, DOI 10.1080/07420520802694020
   Kloog I, 2010, CANCER CAUSE CONTROL, V21, P2059, DOI 10.1007/s10552-010-9624-4
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   McFadden E, 2014, AM J EPIDEMIOL, V180, P245, DOI 10.1093/aje/kwu117
   Mellander C, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0139779
   Milanfar, 2017, SUPER RESOLUTION IMA, V0, P0
   Naemura, 2009, INT C COMP GRAPH INT, V0, P0, DOI DOI 10.1145/1597990.1598049
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Roman M. O., 2019, BLACK MARBLE USER GU, V0, P0
   Rybnikova NA, 2016, INT J OBESITY, V40, P815, DOI 10.1038/ijo.2015.255
   Rybnikova N, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3076011
   Rybnikova NA, 2017, ISPRS J PHOTOGRAMM, V128, P212, DOI 10.1016/j.isprsjprs.2017.03.021
   Sutton P, 2001, INT J REMOTE SENS, V22, P3061, DOI 10.1080/01431160010007015
   Truong TD, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), V0, PP675, DOI 10.5220/0006752006750682
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Timofte R, 2013, IEEE I CONF COMP VIS, V0, PP1920, DOI 10.1109/ICCV.2013.241
   Tselios V, 2020, ENVIRON PLAN B-URBAN, V47, P553, DOI 10.1177/2399808318788567
   Veitch JA, 2008, LIGHTING RES TECHNOL, V40, P133, DOI 10.1177/1477153507086279
   Wang, 2017, GLOBAL HUMAN BUILT U, V0, P0
   Wang XY, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20041142
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Xiao AR, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18041194
   Zhang XD, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18082587
   Zhiyong H., 2012, IMAGE COLORIZATION U, V0, PP369, DOI 10.1145/2393347.2393402
NR 53
TC 2
Z9 2
U1 1
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD NOV 15
PY 2021
VL 21
IS 22
BP 
EP 
DI 10.3390/s21227662
PG 16
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA XJ3YD
UT WOS:000726726900001
PM 34833738
DA 2023-04-26
ER

PT J
AU Kunwar, S
   Chen, HY
   Lin, MH
   Zhang, HY
   D'Angelo, P
   Cerra, D
   Azimi, SM
   Brown, M
   Hager, G
   Yokoya, N
   Hansch, R
   Le Saux, B
AF Kunwar, Saket
   Chen, Hongyu
   Lin, Manhui
   Zhang, Hongyan
   D'Angelo, Pablo
   Cerra, Daniele
   Azimi, Seyed Majid
   Brown, Myron
   Hager, Gregory
   Yokoya, Naoto
   Hansch, Ronny
   Le Saux, Bertrand
TI Large-Scale Semantic 3-D Reconstruction: Outcome of the 2019 IEEE GRSS Data Fusion Contest-Part A
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Semantics; Three-dimensional displays; Training; Laser radar; Data integration; Satellites; Earth; Classification; convolutional neural network (CNN); Data Fusion Contest (DFC); deep learning; elevation model; height estimation; image analysis and data fusion (IADF); light detection and ranging (LiDAR); multiview; 3-D reconstruction; point cloud; semantic labeling; semantic mapping; stereo
ID high-resolution lidar; land-use
AB In this article, we present the scientific outcomes of the 2019 Data Fusion Contest organized by the Image Analysis and Data Fusion Technical Committee of the IEEE Geoscience and Remote Sensing Society. The 2019 Contest addressed the problem of 3-D reconstruction and 3-D semantic understanding on a large scale. Several competitions were organized to assess specific issues, such as elevation estimation and semantic mapping from a single view, two views, or multiple views. In Part A, we report the results of the best-performing approaches for semantic 3-D reconstruction according to these various setups, whereas 3-D point cloud semantic mapping is discussed in Part B.
C1 [Kunwar, Saket] NestAI, Kathmandu 44600, Nepal.
   [Chen, Hongyu; Lin, Manhui; Zhang, Hongyan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [D'Angelo, Pablo; Cerra, Daniele; Azimi, Seyed Majid; Hansch, Ronny] German Aerosp Ctr, D-82234 Wessling, Germany.
   [Brown, Myron] Johns Hopkins Univ, Appl Phys Lab, Johns Hopkins Rd, Laurel, MD 20723 USA.
   [Hager, Gregory] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Yokoya, Naoto] Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778561, Japan.
   [Yokoya, Naoto] RIKEN, Ctr Adv Intelligence Project, Tokyo 1030027, Japan.
   [Le Saux, Bertrand] ESA Ctr Earth Observat, I Lab, I-00044 Frascati, Italy.
C3 Wuhan University; Helmholtz Association; German Aerospace Centre (DLR); Johns Hopkins University; Johns Hopkins University Applied Physics Laboratory; Johns Hopkins University; University of Tokyo; RIKEN
RP Hansch, R (corresponding author), German Aerosp Ctr, D-82234 Wessling, Germany.
EM saketkunwar2005@gmail.com; hongyuchen@whu.edu.cn; mhlin425@whu.edu.cn; zhanghongyan@whu.edu.cn; Pablo.Angelo@dlr.de; daniele.cerra@dlr.de; seyedmajid.azimi@dlr.de; myron.brown@jhuapl.edu; hager@cs.jhu.edu; naoto.yokoya@riken.jp; rww.haensch@gmail.com; bls@ieee.org
FU Intelligence Advanced Research Projects Activity [2017-17032700004]
CR Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   [Anonymous], 2019, GITHUB DATA FUSION C, V0, P0
   Atienza R, 2018, IEEE INT CONF ROBOT, V0, P3207
   Berger C, 2013, IEEE J-STARS, V6, P1324, DOI 10.1109/JSTARS.2013.2245860
   Bosch Marc, 2016, 2016 IEEE APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP (AIPR), V0, P0, DOI DOI 10.1109/AIPR.2016.8010543
   Bosch M, 2019, IEEE WINT CONF APPL, V0, PP1524, DOI 10.1109/WACV.2019.00167
   Campos-Taberner M, 2016, IEEE J-STARS, V9, P5547, DOI 10.1109/JSTARS.2016.2569162
   Chang JR, 2018, PROC CVPR IEEE, V0, PP5410, DOI 10.1109/CVPR.2018.00567
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Christie G.A., 2020, P IEEECVF C COMPUTER, V0, P14500
   dAngelo P, 2019, INT GEOSCI REMOTE SE, V0, PP5053, DOI 10.1109/IGARSS.2019.8899795
   dAngelo P, 2012, INT GEOSCI REMOTE SE, V0, PP6944, DOI 10.1109/IGARSS.2012.6352565
   dAngelo, 2013, P INT S SAT MAPP TEC, V0, P1
   Debes C, 2014, IEEE J-STARS, V7, P2405, DOI 10.1109/JSTARS.2014.2305441
   Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Eigen D, 2014, ADV NEUR IN, V27, P0
   Facciolo G, 2017, IEEE COMPUT SOC CONF, V0, PP1542, DOI 10.1109/CVPRW.2017.198
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2012, COURSERA NEURAL NETW, V4, P26
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hongyu Chen, 2019, IGARSS 2019 - 2019 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM. PROCEEDINGS, V0, PP4967, DOI 10.1109/IGARSS.2019.8899306
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   JACOBSEN K, 2004, INT ARCH PHOTOGRAMME, V35, P439
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kunwar S, 2019, INT GEOSCI REMOTE SE, V0, PP4959, DOI 10.1109/IGARSS.2019.8899861
   Le Saux B., 2019, IEEE DATAPORT, V0, P0, DOI DOI 10.21227/C6TMVW12
   Liao WZ, 2015, IEEE J-STARS, V8, P2984, DOI 10.1109/JSTARS.2015.2420582
   Licciardi G, 2009, IEEE T GEOSCI REMOTE, V47, P3857, DOI 10.1109/TGRS.2009.2029340
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Mou L, 2017, IEEE J-STARS, V10, P3435, DOI 10.1109/JSTARS.2017.2696823
   OGrady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/344188
   Pacifici F, 2008, IEEE GEOSCI REMOTE S, V5, P331, DOI 10.1109/LGRS.2008.915939
   Pacifici F, 2012, IEEE J-STARS, V5, P3, DOI 10.1109/JSTARS.2012.2186733
   Peng C, 2017, PROC CVPR IEEE, V0, PP1743, DOI 10.1109/CVPR.2017.189
   Perko R., 1900, VII, V0, P165
   Poli D, 2012, PHOTOGRAMM REC, V26, P58, DOI 10.1111/j.1477-9730.2011.00665.x
   Qin RJ, 2019, INT GEOSCI REMOTE SE, V0, PP5057, DOI 10.1109/IGARSS.2019.8900588
   Qin RJ, 2019, INT GEOSCI REMOTE SE, V0, PP4971, DOI 10.1109/IGARSS.2019.8900262
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sutskever I., 2013, INT C MACHINE LEARNI, V0, P1139
   Vo AV, 2016, IEEE J-STARS, V9, P5560, DOI 10.1109/JSTARS.2016.2581843
   Wang ZY, 2018, KDD18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, V0, PP2486, DOI 10.1145/3219819.3219944
   Wehr A, 1999, ISPRS J PHOTOGRAMM, V54, P68, DOI 10.1016/S0924-2716(99)00011-8
   WESTIN T, 1990, PHOTOGRAMM ENG REM S, V56, P247
   Xu YH, 2019, IEEE J-STARS, V12, P1709, DOI 10.1109/JSTARS.2019.2911113
   Yokoya N, 2018, IEEE J-STARS, V11, P1363, DOI 10.1109/JSTARS.2018.2799698
   Zhang L., 2004, INT ARCH PHOTOGRAMME, VXXXV, P128, DOI 10.1109/IGARSS.2007.4423626
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zheng Z, 2019, INT GEOSCI REMOTE SE, V0, PP4963, DOI 10.1109/IGARSS.2019.8897927
NR 53
TC 13
Z9 13
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 922
EP 935
DI 10.1109/JSTARS.2020.3032221
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900029
DA 2023-04-26
ER

PT J
AU Simwanda, M
   Murayama, Y
   Phiri, D
   Nyirenda, VR
   Ranagalage, M
AF Simwanda, Matamyo
   Murayama, Yuji
   Phiri, Darius
   Nyirenda, Vincent R.
   Ranagalage, Manjula
TI Simulating Scenarios of Future Intra-Urban Land-Use Expansion Based on the Neural Network-Markov Model: A Case Study of Lusaka, Zambia
SO REMOTE SENSING
LA English
DT Article
DE intra-urban land use; artificial neural network; Markov model; modeling and simulation; scenario analysis; Lusaka
AB Forecasting scenarios of future intra-urban land-use (intra-urban-LU) expansion can help to curb the historically unplanned urbanization in cities in sub-Saharan Africa (SSA) and promote urban sustainability. In this study, we applied the neural network-Markov model to simulate scenarios of future intra-urban-LU expansion in Lusaka city, Zambia. Data derived from remote sensing (RS) and geographic information system (GIS) techniques including urban-LU maps (from 2000, 2005, 2010, and 2015) and selected driver variables, were used to calibrate and validate the model. We then simulated urban-LU expansion for three scenarios (business as usual/status quo, environmental conservation and protection, and strategic urban planning) to explore alternatives for attaining urban sustainability by 2030. The results revealed that Lusaka had experienced rapid urban expansion dominated by informal settlements. Scenario analysis results suggest that a business-as-usual setup is perilous, as it signals an escalating problem of unplanned settlements. The environmental conservation and protection scenario is insufficient, as most of the green spaces and forests have been depleted. The strategic urban planning scenario has the potential for attaining urban sustainability, as it predicts sufficient control of unplanned settlement expansion and protection of green spaces and forests. The study proffers guidance for strategic policy directions and creating a planning vision.
C1 [Simwanda, Matamyo; Phiri, Darius] Copperbelt Univ, Sch Nat Resources, Dept Plant & Environm Sci, Kitwe 10101, Zambia.
   [Murayama, Yuji; Ranagalage, Manjula] Univ Tsukuba, Fac Life & Environm Sci, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058572, Japan.
   [Nyirenda, Vincent R.] Copperbelt Univ, Sch Nat Resources, Dept Zool & Aquat Sci, Kitwe 10101, Zambia.
   [Ranagalage, Manjula] Rajarata Univ Sri Lanka, Fac Social Sci & Humanities, Dept Environm Management, Mihintale 50300, Sri Lanka.
C3 Copperbelt University; University of Tsukuba; Copperbelt University; Rajarata University of Sri Lanka
RP Simwanda, M (corresponding author), Copperbelt Univ, Sch Nat Resources, Dept Plant & Environm Sci, Kitwe 10101, Zambia.
EM matamyo.simwanda@cbu.ac.zm; mura@geoenv.tsukuba.ac.jp; dariusphiri@rocketmail.com; vincent.nyirenda@cbu.ac.zm; manjularanagalage@gmail.com
FU Monbukagakusho scholarship program of Japan; JSPS [18H00763]; Grants-in-Aid for Scientific Research [18H00763] Funding Source: KAKEN
CR Abdullah SA, 2006, LANDSCAPE URBAN PLAN, V77, P263, DOI 10.1016/j.landurbplan.2005.03.003
   Ahmed B, 2012, ISPRS INT J GEO-INF, V1, P3, DOI 10.3390/ijgi1010003
   Almeida CM, 2008, INT J GEOGR INF SCI, V22, P943, DOI 10.1080/13658810701731168
   [Anonymous], 2016, WORLDS CIT 2016 DAT, V0, P0
   [Anonymous], 2008, LUS CIT STAT ENV REP, V0, P0
   [Anonymous], 2007, ZAMB LUS URB SECT PR, V0, P0
   [Anonymous], 2003, 2000 CENS POP HOUS, V0, P0
   [Anonymous], 2009, ICFAI J URBAN POLICY, V0, P0
   [Anonymous], 2012, SURV URB SUST, V0, P0
   [Anonymous], 2017, CITY PLANNING, V0, P0
   [Anonymous], 2019, PRESS GROWTH RAP URB, V0, P0
   [Anonymous], 2012, 2010 CENS POP HOUS, V0, P0
   Arsanjani JJ, 2013, CITIES, V32, P33, DOI 10.1016/j.cities.2013.01.005
   Arsanjani JJ, 2013, INT J APPL EARTH OBS, V21, P265, DOI 10.1016/j.jag.2011.12.014
   Backhaus J., 1980, ANAL KRITIK, V2, P146, DOI 10.1515/AUK-1980-0203
   Basiago A. D., 1998, ENVIRONMENTALIST, V19, P145, DOI 10.1023/A:1006697118620
   Benenson I, 2002, ENVIRON PLANN B, V29, P491, DOI 10.1068/b1287
   Boadi Kwasi, 2005, ENVIRONMENT DEVELOPMENT AND SUSTAINABILITY, V7, P465, DOI 10.1007/s10668-004-5410-3
   Braimoh AK, 2007, LAND USE POLICY, V24, P502, DOI 10.1016/j.landusepol.2006.09.001
   Chitonge H, 2015, HABITAT INT, V48, P209, DOI 10.1016/j.habitatint.2015.03.012
   Clark Helen, 2016, SUSTAINABLE DEV GOAL, V0, PP36, DOI 10.18356/69725E5A-EN
   CLARKE JI, 1993, SYM S STUD, V32, P260, DOI 10.1017/CBO9780511600494.017
   DUNFORD R, 2014, PLYMOUTH STUD SCI, V7, P140
   Eastman J R., 2006, IDRISI ANDES TUTORIA, V0, P0
   Eastman J.R., 2016, TERRASET MANUAL GEOS, V0, P0
   Elmqvist T, 2015, CURR OPIN ENV SUST, V14, P101, DOI 10.1016/j.cosust.2015.05.001
   Estoque RC, 2012, APPL GEOGR, V35, P316, DOI 10.1016/j.apgeog.2012.08.006
   Freire M.E., 2014, GROWTH DIALOGUE, V7, P1
   Glassman A., 2014, DELIVERING DATA REVO, V0, P0
   Godoy M., 2008, P319, V0, P0, DOI DOI 10.1007/978-3-540-68498-5_12
   Gong H, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6080257
   Grekousis G, 2013, CITIES, V30, P193, DOI 10.1016/j.cities.2012.03.006
   Guan DJ, 2011, ECOL MODEL, V222, P3761, DOI 10.1016/j.ecolmodel.2011.09.009
   Guneralp B, 2018, ENVIRON RES LETT, V13, P0, DOI 10.1088/1748-9326/aa94fe
   Hagenauer J, 2018, INT J APPL EARTH OBS, V65, P46, DOI 10.1016/j.jag.2017.10.003
   Hosseinali F, 2013, CITIES, V31, P105, DOI 10.1016/j.cities.2012.09.002
   Hou H, 2019, SCI TOTAL ENVIRON, V661, P422, DOI 10.1016/j.scitotenv.2019.01.208
   Huchzermeyer M., 2014, CHANGING SPACE, V0, P0
   Iizuka K, 2017, LAND-BASEL, V6, P0, DOI 10.3390/land6020026
   Kamete AY, 2012, PLAN THEOR, V11, P66, DOI 10.1177/1473095211419116
   Kamusoko C, 2015, ISPRS INT J GEO-INF, V4, P447, DOI 10.3390/ijgi4020447
   Karekezi S, 2002, ENERG POLICY, V30, P1015, DOI 10.1016/S0301-4215(02)00048-4
   Kuffer M, 2011, PROCEDIA ENVIRON SCI, V7, P152, DOI 10.1016/j.proenv.2011.07.027
   Lambin EF, 2001, GLOBAL ENVIRON CHANG, V11, P261, DOI 10.1016/S0959-3780(01)00007-3
   Laros M., 2014, STATE AFRICAN CITIES, V0, P0
   Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7
   Li X, 2017, INT J GEOGR INF SCI, V31, P1606, DOI 10.1080/13658816.2017.1301457
   Liu Y, 2012, INT J GEOGR INF SCI, V26, P151, DOI 10.1080/13658816.2011.577434
   Mas JF, 2004, ENVIRON MODELL SOFTW, V19, P461, DOI 10.1016/S1364-8152(03)00161-0
   Mishra VN, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2138-3
   Mulenga C.L., 2003, CASE STUD GLOB REP H, V0, P16
   Mutisya E, 2011, INT TRANS J ENG MANA, V2, P197
   Mutunga Clive, 2012, POPULATION DYNAMICS, V0, P0
   Okeyinka Y.R., 2014, DEV CTRY STUD, V4, P112
   Partanen J, 2017, ENTROPY-SWITZ, V19, P0, DOI 10.3390/e19010012
   Perveen S, 2017, SUSTAINABILITY-BASEL, V9, P0, DOI 10.3390/su9101787
   Pontius RG, 2000, PHOTOGRAMM ENG REM S, V66, P1011
   Pontius RG, 2002, PHOTOGRAMM ENG REM S, V68, P1041
   Pontius RG, 2008, ANN REGIONAL SCI, V42, P11, DOI 10.1007/s00168-007-0138-2
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Rafiee R, 2009, CITIES, V26, P19, DOI 10.1016/j.cities.2008.11.005
   Ranagalage M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151743
   Riccioli F, 2016, ENVIRON MONIT ASSESS, V188, P0, DOI 10.1007/s10661-015-5072-7
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sang LL, 2011, MATH COMPUT MODEL, V54, P938, DOI 10.1016/j.mcm.2010.11.019
   Shafizadeh-Moghadam H, 2017, COMPUT ENVIRON URBAN, V64, P297, DOI 10.1016/j.compenvurbsys.2017.04.002
   Shafizadeh-Moghadam H, 2017, GISCI REMOTE SENS, V54, P639, DOI 10.1080/15481603.2017.1309125
   Simwanda M, 2020, LAND USE POLICY, V92, P0, DOI 10.1016/j.landusepol.2019.104441
   Simwanda M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141645
   Simwanda M, 2018, SUSTAIN CITIES SOC, V39, P262, DOI 10.1016/j.scs.2018.01.039
   Simwanda M, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6040102
   Stoler J, 2012, GISCI REMOTE SENS, V49, P31, DOI 10.2747/1548-1603.49.1.31
   Tewolde MG, 2011, REMOTE SENS-BASEL, V3, P2148, DOI 10.3390/rs3102148
   Thapa RB, 2012, LANDSCAPE URBAN PLAN, V105, P140, DOI 10.1016/j.landurbplan.2011.12.007
   van Vliet J, 2011, ECOL MODEL, V222, P1367, DOI 10.1016/j.ecolmodel.2011.01.017
   Vermeiren K, 2012, LANDSCAPE URBAN PLAN, V106, P199, DOI 10.1016/j.landurbplan.2012.03.006
   Wang JD, 2011, INT J GEOGR INF SCI, V25, P229, DOI 10.1080/13658810903473213
   Yang J, 2018, COMPLEXITY, V0, P0, DOI DOI 10.1155/2018/7202985
   Yeh AGO, 2003, PHOTOGRAMM ENG REM S, V69, P1043, DOI 10.14358/PERS.69.9.1043
   Yin HW, 2018, CITIES, V81, P214, DOI 10.1016/j.cities.2018.04.010
   Zhang DC, 2019, GISCI REMOTE SENS, V56, P282, DOI 10.1080/15481603.2018.1507074
   Zhang WG, 2016, GEOSCI FRONT, V7, P45, DOI 10.1016/j.gsf.2014.10.003
   Zheng HW, 2015, HABITAT INT, V46, P23, DOI 10.1016/j.habitatint.2014.10.008
NR 83
TC 6
Z9 6
U1 3
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR 15
PY 2021
VL 13
IS 5
BP 
EP 
DI 10.3390/rs13050942
PG 25
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QW2OU
UT WOS:000628495300001
DA 2023-04-26
ER

PT J
AU Astray, G
   Soto, B
   Barreiro, E
   Galvez, JF
   Mejuto, JC
AF Astray, Gonzalo
   Soto, Benedicto
   Barreiro, Enrique
   Galvez, Juan F.
   Mejuto, Juan C.
TI Machine Learning Applied to the Oxygen-18 Isotopic Composition, Salinity and Temperature/Potential Temperature in the Mediterranean Sea
SO MATHEMATICS
LA English
DT Article
DE machine learning; artificial neural network; random forest; support vector machine; oxygen isotopic composition; salinity; temperature; potential temperature; modelling
ID support vector machine; surface temperatures; heuristic method; neural-networks; random forests; prediction; oxygen; model; system; foraminifera
AB This study proposed different techniques to estimate the isotope composition (delta O-18), salinity and temperature/potential temperature in the Mediterranean Sea using five different variables: (i-ii) geographic coordinates (Longitude, Latitude), (iii) year, (iv) month and (v) depth. Three kinds of models based on artificial neural network (ANN), random forest (RF) and support vector machine (SVM) were developed. According to the results, the random forest models presents the best prediction accuracy for the querying phase and can be used to predict the isotope composition (mean absolute percentage error (MAPE) around 4.98%), salinity (MAPE below 0.20%) and temperature (MAPE around 2.44%). These models could be useful for research works that require the use of past data for these variables.
C1 [Astray, Gonzalo; Mejuto, Juan C.] Univ Vigo, Fac Ciencias, Dept Quim Fis, Orense 32004, Spain.
   [Soto, Benedicto] Univ Vigo, Dept Biol Vexetal & Ciencias Solo, Vigo 36310, Spain.
   [Barreiro, Enrique; Galvez, Juan F.] Univ Vigo, Dept Informat, Escola Super Enxeriaria Informat, Orense 32004, Spain.
C3 Universidade de Vigo; Universidade de Vigo; Universidade de Vigo
RP Astray, G (corresponding author), Univ Vigo, Fac Ciencias, Dept Quim Fis, Orense 32004, Spain.
EM gastray@uvigo.es; edbene@uvigo.es; enrique@uvigo.es; galvez@uvigo.es; xmejuto@uvigo.es
FU Universidade de Vigo [0000 131H TAL 641]; Xunta de Galicia [ED431C 2018/42]; Xunta de Galicia (Conselleria de Cultura, Educacion e Ordenacion Universitaria) [POS-B/2016/001, K645P.P.0000421S140.08]
CR Aguilar-Martinez S., 2009, INT J OCEANOGRAPHY, V2009, P1, DOI 10.1155/2009/167239
   Ahn JJ, 2011, EXPERT SYST APPL, V38, P2966, DOI 10.1016/j.eswa.2010.08.085
   Ali F, 2020, INFORM FUSION, V63, P208, DOI 10.1016/j.inffus.2020.06.008
   [Anonymous], 2000, PALAEONTOL ELECTRON, V0, P0
   [Anonymous], 2011, ACM T INTEL SYST TEC, V0, P0
   Aparna SG, 2018, INT J REMOTE SENS, V39, P4214, DOI 10.1080/01431161.2018.1454623
   Astray G, 2019, MOLECULES, V24, P0, DOI 10.3390/molecules24050826
   Banaru D, 2014, J PLANKTON RES, V36, P145, DOI 10.1093/plankt/fbt083
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   BEDARD P, 1981, NATURE, V293, P287, DOI 10.1038/293287a0
   Benali L, 2019, RENEW ENERG, V132, P871, DOI 10.1016/j.renene.2018.08.044
   Bigg GR, 2000, J GEOPHYS RES-OCEANS, V105, P8527, DOI 10.1029/2000JC900005
   Boser B. E., 1992, PROCEEDINGS OF THE FIFTH ANNUAL ACM WORKSHOP ON COMPUTATIONAL LEARNING THEORY, V0, PP144, DOI 10.1145/130385.130401
   Nardelli BB, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12193151
   Cerar S, 2018, SCI TOTAL ENVIRON, V631-632, P358, DOI 10.1016/j.scitotenv.2018.03.033
   Chen W., 2017, COMPUT WATER ENERGY, V6, P107, DOI 10.4236/cweee.2017.61009
   Cid A, 2011, TENSIDE SURFACT DET, V48, P477, DOI 10.3139/113.110155
   Dawson CW, 2001, PROG PHYS GEOG, V25, P80, DOI 10.1191/030913301674775671
   Estrada M, 1996, SCI MAR, V60, P55
   Falah F, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, V0, PP323, DOI 10.1016/B978-0-12-815226-3.00014-4
   FRY B, 1984, CONTRIB MAR SCI, V27, P13
   Gat JR, 1996, J GEOPHYS RES-OCEANS, V101, P6441, DOI 10.1029/95JC02829
   Gonzalez-Fernandez I, 2019, CRIT REV FOOD SCI, V59, P1913, DOI 10.1080/10408398.2018.1433628
   Gonzalez-Mora B, 2008, GEOCHEM GEOPHY GEOSY, V9, P0, DOI 10.1029/2007GC001906
   Herbert TD, 2015, EARTH PLANET SC LETT, V409, P307, DOI 10.1016/j.epsl.2014.10.006
   Hijazi A, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10228255
   Hsu C.W., 2003, TECH REP, V0, P0
   Iglesias-Otero MA, 2015, AEROBIOLOGIA, V31, P201, DOI 10.1007/s10453-014-9357-z
   Jing G, 2018, BUILD ENVIRON, V143, P487, DOI 10.1016/j.buildenv.2018.07.037
   Jog A, 2017, MED IMAGE ANAL, V35, P475, DOI 10.1016/j.media.2016.08.009
   Kaminska JA, 2019, SCI TOTAL ENVIRON, V651, P475, DOI 10.1016/j.scitotenv.2018.09.196
   Karimi F, 2019, COMPUT ENVIRON URBAN, V75, P61, DOI 10.1016/j.compenvurbsys.2019.01.001
   Kriesel D, 2007, BRIEF INTRO NEURAL N, V0, P0
   Kumar C, 2021, REMOTE SENS ENVIRON, V255, P0, DOI 10.1016/j.rse.2020.112227
   Li ZY, 2017, EXPERT SYST APPL, V74, P105, DOI 10.1016/j.eswa.2017.01.011
   Lins ID, 2013, COMPUT STAT DATA AN, V61, P187, DOI 10.1016/j.csda.2012.12.003
   Liu HX, 2005, J COMPUT AID MOL DES, V19, P33, DOI 10.1007/s10822-005-0095-8
   Liu ML, 2015, COMPUT GEOSCI-UK, V75, P44, DOI 10.1016/j.cageo.2014.10.016
   Makarynskyy O, 2004, OCEAN ENG, V31, P709, DOI 10.1016/j.oceaneng.2003.05.003
   McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570
   Moguerza JM, 2006, STAT SCI, V21, P322, DOI 10.1214/088342306000000493
   Nirala N, 2019, BIOCYBERN BIOMED ENG, V39, P38, DOI 10.1016/j.bbe.2018.09.007
   Papadopoulos A, 2005, ARTIF INTELL MED, V34, P141, DOI 10.1016/j.artmed.2004.10.001
   Partopour B, 2018, COMPUT CHEM ENG, V115, P286, DOI 10.1016/j.compchemeng.2018.04.019
   Patil K, 2017, OCEAN DYNAM, V67, P357, DOI 10.1007/s10236-017-1032-9
   Pierre C, 1999, MAR GEOL, V153, P41, DOI 10.1016/S0025-3227(98)00090-5
   Pierre C., 1986, MEM SOC GEOL IT, V36, P165
   Quiroz JC, 2018, MEASUREMENT, V116, P273, DOI 10.1016/j.measurement.2017.11.004
   RapidMiner GmbH, 2021, NEUR NET, V0, P0
   RapidMiner GmbH, 2021, RAPIDMINER DOC SUPP, V0, P0
   Rios-Reina R, 2017, FOOD CHEM, V230, P108, DOI 10.1016/j.foodchem.2017.02.118
   Roberts CN, 2010, GLOBAL PLANET CHANGE, V71, P135, DOI 10.1016/j.gloplacha.2010.01.024
   Rohling EJ, 2015, EARTH-SCI REV, V143, P62, DOI 10.1016/j.earscirev.2015.01.008
   Samghani K, 2016, ECOTOX ENVIRON SAFE, V129, P10, DOI 10.1016/j.ecoenv.2016.03.002
   Sanchez-Mesa J. A., 2002, CLINICAL AND EXPERIMENTAL ALLERGY, V32, P1606, DOI 10.1046/j.1365-2222.2002.01510.x
   Sarkar PP, 2020, SN APPL SCI, V2, P0, DOI 10.1007/s42452-020-03239-3
   Schmidt G. A., 1999, GLOBAL SEAWATER OXYG, V0, P0
   Schmidt GA, 1999, PALEOCEANOGRAPHY, V14, P482, DOI 10.1029/1999PA900025
   Schroeder K, 2012, ELSEV INSIGHT, V0, PP187, DOI 10.1016/B978-0-12-416042-2.00003-3
   Srinivasu PN, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21082852
   STAHL W, 1973, METEOR FORSCHUNGSE C, V0014, P0
   Stratford K, 1997, J GEOPHYS RES-OCEANS, V102, P12539, DOI 10.1029/97JC00019
   Stratford K, 1998, J MARINE SYST, V18, P215, DOI 10.1016/S0924-7963(98)00013-X
   Su H, 2019, INT GEOSCI REMOTE SE, V0, PP8139, DOI 10.1109/IGARSS.2019.8898899
   Sunder S, 2020, ISPRS J PHOTOGRAMM, V166, P228, DOI 10.1016/j.isprsjprs.2020.06.008
   Tanhua T, 2013, OCEAN SCI, V9, P789, DOI 10.5194/os-9-789-2013
   Theodor M, 2016, MAR MICROPALEONTOL, V124, P16, DOI 10.1016/j.marmicro.2016.02.001
   Tian Y, 2017, SPECTROCHIM ACTA B, V135, P91, DOI 10.1016/j.sab.2017.07.003
   Vigneau E, 2018, FOOD QUAL PREFER, V68, P135, DOI 10.1016/j.foodqual.2018.02.008
   Wang J, 2007, TALANTA, V73, P147, DOI 10.1016/j.talanta.2007.03.037
   Zhang Z, 2020, J MAR SCI ENG, V8, P0, DOI 10.3390/jmse8040249
   Zhong M, 2013, BIOORG MED CHEM LETT, V23, P3788, DOI 10.1016/j.bmcl.2013.04.087
   Zuo X., 2021, INT S ADV EL EL COMP, V0, P1
NR 75
TC 4
Z9 4
U1 0
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2227-7390
J9 MATHEMATICS-BASEL
JI Mathematics
PD OCT 15
PY 2021
VL 9
IS 19
BP 
EP 
DI 10.3390/math9192523
PG 15
WC Mathematics
SC Mathematics
GA WG6TP
UT WOS:000707127700001
DA 2023-04-26
ER

PT J
AU Gholami, V
   Sahour, H
   Amri, MAH
AF Gholami, Vahid
   Sahour, Hossein
   Amri, Mohammad Ali Hadian
TI Soil erosion modeling using erosion pins and artificial neural networks
SO CATENA
LA English
DT Article
DE Splash erosion; Surface erosion; GFF network; Hillslope; Soil erosion map
ID simulated rainfall; sediment yield; bank erosion; runoff; land; prediction; vegetation; rates; field; streamflow
AB Assessment of soil erosion is crucial for any long-term soil conservation plan. Traditional in-situ measurements provide a precise amount of erosion rate; however, the procedure is costly and time-consuming when applied over an extensive area. This study aimed to investigate the use of erosion pins and artificial neural networks (ANNs) to assess the spatial distribution of annual soil erosion rates in the mountainous areas of the north of Iran. First, annual surface erosion and splash erosion were measured using two types of erosion pins. Next, the variables affecting soil erosion (vegetation canopy, the shape of slope, slope gradient, slope length, and soil properties) were identified and estimated through field studies and analysis of a digital elevation model (DEM) and the data set were divided into three subsets of training, cross-validation, and testing. Seven artificial neural network algorithms were used and evaluated to estimate the annual soil erosion rates for the areas without recorded erosion data. Finally, the modeled values were mapped in GIS, and the longitudinal profiles of soil erosion were extracted. Findings showed that (1) Consideration should be given to the generalized feed forward (GFF) network, given the high accuracy rate (NMSE:0.1; R-sqr:0.9) compared to other tested ANN algorithms. (2) Vegetation canopy was found to be the most significant variable in annual soil erosion rate (R: -0.75 to -0.85) compared to other input variables. And (3) Annual measurements of erosion pins revealed that the splash erosion is higher (contributing 62 percent to total erosion) compared to surface runoff erosion (contributing 38 percent to total erosion).
C1 [Gholami, Vahid] Univ Guilan, Fac Nat Resources, Dept Range & Watershed Management, Sowmeh Sara, Guilan, Iran.
   [Gholami, Vahid] Univ Guilan, Fac Nat Resources, Dept Water Engn & Environm, Sowmeh Sara, Guilan, Iran.
   [Sahour, Hossein] Western Michigan Univ, Dept Geol & Environm Sci, Kalamassoo, MI 49008 USA.
   [Amri, Mohammad Ali Hadian] Agr Res Educ & Extens Org AREEO, Dept Soil Conservat & Watershed Management, Mazandaran Agr & Nat Resources Res & Educ Ctr, Sari, Iran.
C3 University of Guilan; University of Guilan; Western Michigan University
RP Gholami, V (corresponding author), Univ Guilan, Fac Nat Resources, Dept Range & Watershed Management, Sowmeh Sara, Guilan, Iran.; Gholami, V (corresponding author), Univ Guilan, Fac Nat Resources, Dept Water Engn & Environm, Sowmeh Sara, Guilan, Iran.
EM Gholami.vahid@guilan.ac.ir
CR Akay AE, 2008, BUILD ENVIRON, V43, P687, DOI 10.1016/j.buildenv.2007.01.047
   Aldrich GA, 2005, RANGELAND ECOL MANAG, V58, P542, DOI 10.2111/04-164R2.1
   Alshehri F, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091361
   Anctil F, 2005, J HYDROL ENG, V10, P85, DOI 10.1061/(ASCE)1084-0699(2005)10:1(85)
   [Anonymous], 1992, LOWLAND FLOODPLAIN R, V0, P0
   [Anonymous], 1978, AGR HDB, V0, P0
   Beghdad R, 2008, COMPUT SECUR, V27, P168, DOI 10.1016/j.cose.2008.06.001
   Boardman J, 2016, GEOMORPHOLOGICAL TEC, V0, P0
   Boardman J, 2015, EARTH SURF PROC LAND, V40, P2121, DOI 10.1002/esp.3792
   BOHM P, 1995, CATENA, V25, P63, DOI 10.1016/0341-8162(94)00042-D
   Bullock P., 2005, ENCY SOILS ENV, V0, PP254, DOI 10.1016/B0-12-348530-4/00089-8
   Chen ZJ, 2019, SCI TOTAL ENVIRON, V648, P1097, DOI 10.1016/j.scitotenv.2018.08.141
   Clarke ML, 2006, EARTH SURF PROC LAND, V31, P15, DOI 10.1002/esp.1226
   Clayton L., 1971, W122101271 N DAK U W, V0, P1
   Colbert E.H., 1956, PLATEAU, V28, P73
   de la Rosa D, 1999, AGR ECOSYST ENVIRON, V73, P211, DOI 10.1016/S0167-8809(99)00050-X
   DESCROIX L, 1995, B LAB RHOD GEOMORPHO, V33, P1
   Di Stefano C, 2000, WATER RESOUR RES, V36, P607, DOI 10.1029/1999WR900157
   Dixon B., 2004, J SPA HYDROL, V14, P1, DOI 10.1016/j.jhydrol.2004.11.010
   Emmett W.W., 1965, INT ASS HYDROLOGICAL, V66, P89
   Foster G.R., 2001, P SUST GLOB SEL PAP, V0, P0
   Ghimire SK, 2013, LAND-BASEL, V2, P370, DOI 10.3390/land2030370
   Gholami V, 2018, CATENA, V163, P210, DOI 10.1016/j.catena.2017.12.027
   Gholami V, 2013, SOIL WATER RES, V8, P158, DOI 10.17221/13/2012-SWR
   Gholzom EH, 2012, SOIL WATER RES, V7, P166, DOI 10.17221/18/2012-SWR
   Gray D, 2016, J CIV ENV ENG, V6, P1, DOI 10.4172/2165- 784X.10 00231
   Haigh M. J., 1977, TECHNICAL BULLETIN, V0, P31
   Hancock GR, 2008, GEOGR RES, V46, P333, DOI 10.1111/j.1745-5871.2008.00527.x
   Hancock GR, 2015, HYDROL PROCESS, V29, P4809, DOI 10.1002/hyp.10608
   Harden CP, 2009, PHYS GEOGR, V30, P1, DOI 10.2747/0272-3646.30.1.1
   Harris TM, 1998, NATO ASI SER SER I, V55, P461
   Harvey A. M., 1974, I BRIT GEOGRAPHERS S, V6, P45
   Ireland H.A., 1939, 167374 US DEP AGR EC, V167374, P0, DOI 10.22004/ag.econ.167374
   Isik S, 2013, J HYDROL, V485, P103, DOI 10.1016/j.jhydrol.2012.08.032
   JUNGERIUS PD, 1989, CATENA, V16, P369, DOI 10.1016/0341-8162(89)90021-0
   JUNGERIUS PD, 1981, EARTH SURF PROC LAND, V6, P375, DOI 10.1002/esp.3290060316
   Kearney SP, 2018, CATENA, V163, P427, DOI 10.1016/j.catena.2017.12.008
   Keay-Bright J, 2009, GEOMORPHOLOGY, V103, P455, DOI 10.1016/j.geomorph.2008.07.011
   Keim RF, 2006, ADV WATER RESOUR, V29, P974, DOI 10.1016/j.advwatres.2005.07.017
   Khaleghi MR, 2018, ACTA GEOPHYS, V66, P109, DOI 10.1007/s11600-018-0110-9
   Khaleghi Mohammad Reza, 2017, JOURNAL OF FOREST SCIENCE (PRAGUE), V63, P245, DOI 10.17221/130/2016-JFS
   Kirkby A.V.T., 1974, Z GEOMORPHOL, V21, P151
   Kirkby MJ, 2005, CATENA, V62, P136, DOI 10.1016/j.catena.2005.05.002
   Lawler D.M., 1978, SWANSEA GEOGRAPHER, V16, P9
   LAWLER DM, 1993, EARTH SURF PROC LAND, V18, P777, DOI 10.1002/esp.3290180905
   LAWLER DM, 1991, WATER RESOUR RES, V27, P2125, DOI 10.1029/91WR01191
   Li JY, 2020, SCI TOTAL ENVIRON, V709, P0, DOI 10.1016/j.scitotenv.2019.136060
   Licznar P, 2003, CATENA, V51, P89, DOI 10.1016/S0341-8162(02)00147-9
   Livingstone I, 2003, EARTH SURF PROC LAND, V28, P1025, DOI 10.1002/esp.1000
   LOUGHRAN RJ, 1989, PROG PHYS GEOG, V13, P216, DOI 10.1177/030913338901300203
   Luetzenburg G, 2020, SCI TOTAL ENVIRON, V704, P0, DOI 10.1016/j.scitotenv.2019.135389
   Martinez-Casasnovas J.A., 1998, THESIS, V0, P0
   Masson JM., 1971, THESIS, V0, P0
   MOEYERSONS J, 1990, Z GEOMORPHOL, V34, P385
   Mohamed MA, 2010, INT J COMPUT SCI NET, V10, P86
   Moreno-de las Heras M, 2010, WATER RESOUR RES, V46, P0, DOI 10.1029/2009WR007875
   Nadal-Romero E, 2011, PROG PHYS GEOG, V35, P297, DOI 10.1177/0309133311400330
   Naghdi R, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-017-6758-7
   Pastor M., 1995, OLIVA, V0, P64
   Pickup G, 2000, EARTH SURF PROC LAND, V25, P535, DOI 10.1002/(SICI)1096-9837(200005)25:5<535::AID-ESP91>3.0.CO;2-N
   Pierson FB, 2007, RANGELAND ECOL MANAG, V60, P285, DOI 10.2111/1551-5028(2007)60[285:RAEACW]2.0.CO;2
   RANWELL DS, 1964, J ECOL, V52, P79, DOI 10.2307/2257784
   Rosas MA, 2020, SCI TOTAL ENVIRON, V703, P0, DOI 10.1016/j.scitotenv.2019.135474
   Sahour H, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030533
   Samani N, 2007, J HYDROL, V340, P1, DOI 10.1016/j.jhydrol.2007.03.017
   Sattari MT, 2012, APPL MATH MODEL, V36, P2649, DOI 10.1016/j.apm.2011.09.048
   SCHUMM SA, 1956, GEOL SOC AM BULL, V67, P597, DOI 10.1130/0016-7606(1956)67[597:EODSAS]2.0.CO;2
   SHI Z, 2013, CHINA APPL RAD ISOT, V69, P1343
   Streeter D.T., 1975, PRELIMINARY OBSERVAT, V0, P0
   SUMMER RM, 1986, J SOIL WATER CONSERV, V41, P126
   Sun JM, 2016, CATENA, V136, P128, DOI 10.1016/j.catena.2015.02.019
   Tehrani EN, 2019, THEOR APPL CLIMATOL, V136, P85, DOI 10.1007/s00704-018-2470-0
   United States Department of Agriculture Natural Resources Conservation Service, 2010, NATURAL RESOURCES CO, V0, P0
   Uson A., 1998, THESIS, V0, P0
   WIGGS GFS, 1995, EARTH SURF PROC LAND, V20, P515, DOI 10.1002/esp.3290200604
   World reference base for soil resources (WRB), 2014, FOOD AGR ORG UNITED, V0, P193
   Yair A., 1974, GEOM, V0, P0
   Zhang ZD, 2020, SCI TOTAL ENVIRON, V702, P0, DOI 10.1016/j.scitotenv.2019.134716
   Zhao ZY, 2009, COMPUT ELECTRON AGR, V65, P36, DOI 10.1016/j.compag.2008.07.008
NR 79
TC 29
Z9 30
U1 8
U2 137
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0341-8162
EI 1872-6887
J9 CATENA
JI Catena
PD JAN 15
PY 2021
VL 196
IS 
BP 
EP 
DI 10.1016/j.catena.2020.104902
PG 11
WC Geosciences, Multidisciplinary; Soil Science; Water Resources
SC Geology; Agriculture; Water Resources
GA OJ4TF
UT WOS:000583955200057
DA 2023-04-26
ER

PT J
AU Ajadi, OA
   Barr, J
   Liang, SZ
   Ferreira, R
   Kumpatla, SP
   Patel, R
   Swatantran, A
AF Ajadi, Olaniyi A.
   Barr, Jeremiah
   Liang, Sang-Zi
   Ferreira, Rogerio
   Kumpatla, Siva P.
   Patel, Rinkal
   Swatantran, Anu
TI Large-scale crop type and crop area mapping across Brazil using synthetic aperture radar and optical imagery
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Synthetic aperture radar; SAR; Machine learning; Xgboost; Crop classification; Neural networks; Harmonic function; Time series; Deep learning
ID time; classification; minimization; phenology; stress; maize; sar
AB Improved data on crop type and crop area from satellite imagery are invaluable for agronomy managers and are crucial for balancing agricultural expansion and forest degradation. However, large-scale maps of crop type and crop area using satellite imagery are not easily available in some regions, especially Brazil. Reasons for this include limited ground truth data, inadequate spatial and temporal satellite data availability, computational challenges, lack of cropland data and field boundaries. In this paper, we attempted to overcome some of these obstacles by using an ensemble of approaches to generate crop classification maps for Brazil. In order to compensate for the lack of abundant ground truth data in Brazil, we combined extensive field data and satellite input features from the United States with available field data and satellite input features from Brazil to train crop classification model for Brazil. Before applying the crop classification model for Brazil, we classified cropland areas using harmonic functions and delineated field boundaries using a supervised deep learning approach. Cropland masking and field boundary delineation allowed field-level mapping of crop type and crop area. Applying the crop classification model for Brazil in the states of Mato Grosso and Goias gave a true positive accuracy of 88% in the 2017/2018 summer growing season for soybean classification, 95% in the 2018 safrinha growing season for corn classification, and 86% in the 2018/2019 summer growing season for soybean classification. Our crop area estimates also showed a good agreement (correlation of 0.95 and mean absolute error of 0.64) with state-scale statistical data provided by the Companhia Nacional de Abastecimento (CONAB) in both summer and safrinha growing seasons adding further confidence to the results. These results suggest that extensive data from one geography can be used to train machine learning models in conjunction with limited field data from another geography. Accuracy assessments support the portability of crop classification model for Brazil with reasonable accuracy spatially, as tested in the state of Parana, and temporally, to the following year. The approaches and datasets presented in this paper provide building blocks for large-scale crop monitoring benefitting both public and private sectors.
C1 [Ajadi, Olaniyi A.; Barr, Jeremiah; Liang, Sang-Zi; Ferreira, Rogerio; Kumpatla, Siva P.; Swatantran, Anu] Corteva AgriscienceTM, 7000 NW 62nd Ave, Johnston, IA 50131 USA.
   [Patel, Rinkal] Granular, 8700 Crescent Chase, Johnston, IA 50131 USA.
RP Ajadi, OA (corresponding author), Corteva AgriscienceTM, 7000 NW 62nd Ave, Johnston, IA 50131 USA.
EM olaniyi.ajadi@corteva.com
FU Corteva Agriscience(TM)
CR Ajadi OA, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060482
   [Anonymous], 2014, SCIPY OPEN SOURCE SC, V0, P0
   Picoli MCA, 2018, ISPRS J PHOTOGRAMM, V145, P328, DOI 10.1016/j.isprsjprs.2018.08.007
   Arvor D, 2011, INT J REMOTE SENS, V32, P7847, DOI 10.1080/01431161.2010.531783
   Bendini HD, 2019, INT J APPL EARTH OBS, V82, P0, DOI 10.1016/j.jag.2019.05.005
   Branch MA, 1999, SIAM J SCI COMPUT, V21, P1, DOI 10.1137/S1064827595289108
   BYRD RH, 1988, MATH PROGRAM, V40, P247, DOI 10.1007/BF01580735
   Chen YL, 2018, INT J APPL EARTH OBS, V69, P133, DOI 10.1016/j.jag.2018.03.005
   Man CD, 2018, INT J REMOTE SENS, V39, P1243, DOI 10.1080/01431161.2017.1399477
   da Silva CA, 2020, COMPUT ELECTRON AGR, V169, P0, DOI 10.1016/j.compag.2019.105194
   Gitelson A.A., 2003, REMOTE ESTIMATION LE, V0, P0
   Gusso A, 2006, WORKSHOP P REMOTE SE, V36, P0
   Gusso A, 2017, ACTA AMAZON, V47, P281, DOI 10.1590/1809-4392201700543
   Gusso A, 2014, SCI WORLD J, V0, P0, DOI DOI 10.1155/2014/863141
   Jayne T. S., 2010, VALUE ACCURATE CROP, V0, P0
   Kastens JH, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0176168
   Li WK, 2014, IEEE T GEOSCI REMOTE, V52, P4621, DOI 10.1109/TGRS.2013.2283082
   Li WK, 2013, ECOGRAPHY, V36, P788, DOI 10.1111/j.1600-0587.2013.07585.x
   Liu CA, 2019, J INTEGR AGR, V18, P506, DOI 10.1016/S2095-3119(18)62016-7
   Loggenberg K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020202
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Meyer FJ, 2015, ISPRS J PHOTOGRAMM, V100, P106, DOI 10.1016/j.isprsjprs.2014.05.009
   More J. J., 1978, PROCEEDINGS OF THE BIENNIAL CONFERENCE ON NUMERICAL ANALYSIS, V0, P105
   Mustapha IB, 2016, MOLECULES, V21, P0, DOI 10.3390/molecules21080983
   Planells M., 2019, USING DENSE TIME SER, V0, P6231
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sakamoto T, 2013, REMOTE SENS ENVIRON, V131, P215, DOI 10.1016/j.rse.2012.12.017
   Sakamoto T, 2010, REMOTE SENS ENVIRON, V114, P2146, DOI 10.1016/j.rse.2010.04.019
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Shumway RH, 2011, SPRINGER TEXTS STAT, V0, PP1, DOI 10.1007/978-1-4419-7865-3
   Skakun S, 2016, IEEE J-STARS, V9, P3712, DOI 10.1109/JSTARS.2015.2454297
   Ustuner M., 2019, INT CONF AGRO-GEOINF, V0, P1
   Van Tricht K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101642
   Xia YF, 2017, EXPERT SYST APPL, V78, P225, DOI 10.1016/j.eswa.2017.02.017
   Xiong J, 2017, ISPRS J PHOTOGRAMM, V126, P225, DOI 10.1016/j.isprsjprs.2017.01.019
   Zalles V, 2019, P NATL ACAD SCI USA, V116, P428, DOI 10.1073/pnas.1810301115
   Zeng LL, 2016, REMOTE SENS ENVIRON, V181, P237, DOI 10.1016/j.rse.2016.03.039
   Zhang F, 2015, REMOTE SENS-BASEL, V7, P15203, DOI 10.3390/rs71115203
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
NR 40
TC 16
Z9 17
U1 10
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD MAY 15
PY 2021
VL 97
IS 
BP 
EP 
DI 10.1016/j.jag.2020.102294
PG 16
WC Remote Sensing
SC Remote Sensing
GA QE6AN
UT WOS:000616288400001
DA 2023-04-26
ER

PT J
AU Li, CY
   Zheng, YH
   Jeon, B
AF Li, Chunyu
   Zheng, Yuhui
   Jeon, Byeungwoo
TI Pansharpening via Subpixel Convolutional Residual Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Pansharpening; Feature extraction; Convolutional neural networks; Computer architecture; Interpolation; Spatial resolution; Task analysis; Convolutional neural network (CNN); data fusion; guided filter; pansharpening; remote sensing; subpixel
ID spectral resolution images; fusion; quality; ms
AB In this article, we propose a new pansharpening architecture called subpixel convolutional residual network to obtain high-resolution multispectral (MS) images. Different from previous works, we extract features from MS images in a low-resolution space and pay more attention to the balance of spectral and spatial information. Our architecture consists of two branches: the feature extraction branch and the residual branch. The former adopts a four-layer convolutional network to extract features, and then upsamples the feature maps using a subpixel convolution layer. For the latter, we combine the nearest neighbor interpolation and guided filter to yield a preliminary image with fundamental spectral and spatial information. With the outputs of the two branches, we can merge them and yield a pansharpened image. The proposed method was compared with several representative methods. The experimental results demonstrate that our method achieves high fusion accuracy while maintaining a good balance between the spectral and the spatial resolution.
C1 [Li, Chunyu; Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Li, Chunyu; Zheng, Yuhui] Minist Educ, Engn Res Ctr Digital Forens, Nanjing 210044, Peoples R China.
   [Jeon, Byeungwoo] Sungkyunkwan Univ, Sch Elect & Elect Engn, Suwon 440746, South Korea.
C3 Nanjing University of Information Science & Technology; Sungkyunkwan University (SKKU)
RP Zheng, YH (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.; Zheng, YH (corresponding author), Minist Educ, Engn Res Ctr Digital Forens, Nanjing 210044, Peoples R China.
EM 72421@163.com; zhengyh@vip.126.com; bjeon@skku.edu
FU National Natural Science Foundation of China [U20B2065, 61972206, 62011540407]; Natural Science Foundation of Jiangsu Province [BK20211539]; 15th Six Talent Peaks Project in Jiangsu Province [RJFW-015]; Qing Lan Project; National Research Foundation of Korea [NRF-2020K2A9A2A06036255]; Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD)
CR Aiazzi B, 2003, 2ND GRSS/ISPRS JOINT WORKSHOP ON REMOTE SENSING AND DATA FUSION OVER URBAN AREAS, V0, PP90, DOI 10.1109/DFUA.2003.1219964
   Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Ballester C, 2006, INT J COMPUT VISION, V69, P43, DOI 10.1007/s11263-006-6852-x
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Doi K, 2019, INT GEOSCI REMOTE SE, V0, PP3141, DOI 10.1109/IGARSS.2019.8897928
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang FM, 2013, IEEE T IMAGE PROCESS, V22, P2822, DOI 10.1109/TIP.2013.2258355
   Garzelli A., 2005, INFORMATION FUSION, V6, P213, DOI 10.1016/j.inffus.2004.06.008
   Garzelli A, 2008, IEEE T GEOSCI REMOTE, V46, P228, DOI 10.1109/TGRS.2007.907604
   Garzelli A, 2009, IEEE GEOSCI REMOTE S, V6, P662, DOI 10.1109/LGRS.2009.2022650
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He L, 2019, IEEE J-STARS, V12, P3092, DOI 10.1109/JSTARS.2019.2917584
   Lei D., 1900, DOI 10.1109/TGRS.2021.3067097, V0, P0
   Li KY, 2019, IEEE T GEOSCI REMOTE, V57, P8011, DOI 10.1109/TGRS.2019.2917759
   Liao WZ, 2015, IEEE J-STARS, V8, P2984, DOI 10.1109/JSTARS.2015.2420582
   Liu JG, 2000, INT J REMOTE SENS, V21, P3461, DOI 10.1080/014311600750037499
   Masi G, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070594
   Meng XC, 2019, INFORM FUSION, V46, P102, DOI 10.1016/j.inffus.2018.05.006
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Shahdoosti HR, 2015, IEEE GEOSCI REMOTE S, V12, P611, DOI 10.1109/LGRS.2014.2353135
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Shi WZ, 2016, PROC CVPR IEEE, V0, PP1874, DOI 10.1109/CVPR.2016.207
   Simoes M, 2015, IEEE T GEOSCI REMOTE, V53, P3373, DOI 10.1109/TGRS.2014.2375320
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wald L., 2002, DATA FUSION DEFINITI, V0, P0
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei Q, 2015, IEEE J-STSP, V9, P1117, DOI 10.1109/JSTSP.2015.2407855
   Wei YC, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017), V0, P0
   Wei YC, 2017, IEEE GEOSCI REMOTE S, V14, P1795, DOI 10.1109/LGRS.2017.2736020
   Yang JF, 2017, IEEE I CONF COMP VIS, V0, PP1753, DOI 10.1109/ICCV.2017.193
   Yuhas R.H., 1992, PROC SUMMARIES 3 ANN, V1, P147
   Zhang L., 2021, IEEE T GEOSCI REMOTE, V0, P0, DOI DOI 10.1109/TGRS.2021.3054641
   Zhang YF, 2009, IEEE T GEOSCI REMOTE, V47, P3834, DOI 10.1109/TGRS.2009.2017737
   Zheng YX, 2020, IEEE GEOSCI REMOTE S, V17, P1435, DOI 10.1109/LGRS.2019.2945424
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
NR 43
TC 3
Z9 3
U1 5
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 10303
EP 10313
DI 10.1109/JSTARS.2021.3117944
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WN2ZC
UT WOS:000711641000006
DA 2023-04-26
ER

PT J
AU Sha, YK
   Gagne, DJ
   West, G
   Stull, R
AF Sha, Yingkai
   Gagne, David John
   West, Gregory
   Stull, Roland
TI Deep-Learning-Based Precipitation Observation Quality Control
SO JOURNAL OF ATMOSPHERIC AND OCEANIC TECHNOLOGY
LA English
DT Article
DE Precipitation; Data quality control; Classification; Deep learning; Machine learning
ID time-series; assurance procedures; gauge observations; air-temperature; performance; rain; impacts; project; runoff
AB We present a novel approach for the automated quality control (QC) of precipitation for a sparse station observation network within the complex terrain of British Columbia, Canada. Our QC approach uses convolutional neural networks (CNNs) to classify bad observation values, incorporating a multiclassifier ensemble to achieve better QC performance. We train CNNs using human QC'd labels from 2016 to 2017 with gridded precipitation and elevation analyses as inputs. Based on the classification evaluation metrics, our QC approach shows reliable and robust performance across different geographical environments (e.g., coastal and inland mountains), with 0.927 area under curve (AUC) and type I/type II error lower than 15%. Based on the saliency-map-based interpretation studies, we explain the success of CNN-based QC by showing that it can capture the precipitation patterns around, and upstream of the station locations. This automated QC approach is an option for eliminating bad observations for various applications, including the preprocessing of training datasets for machine learning. It can be used in conjunction with human QC to improve upon what could be accomplished with either method alone.
C1 [Sha, Yingkai; Stull, Roland] Univ British Columbia, Vancouver, BC, Canada.
   [Gagne, David John] Natl Ctr Atmospher Res, POB 3000, Boulder, CO 80307 USA.
   [West, Gregory] BC Hydro & Power Author, Burnaby, BC, Canada.
C3 University of British Columbia; National Center Atmospheric Research (NCAR) - USA
RP Sha, YK (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM yingkai@eoas.ubc.ca
FU Four Year Doctoral Fellowship (4YF) program of the University of British Columbia; Canadian Natural Science and Engineering Research Council (NSERC); National Science Foundation; MITACS; BC Hydro; Casper cluster [Computational and Information Systems Laboratory (CISL)]; National Center for Atmospheric Research (NCAR); Advanced Study Program (ASP)
CR Adam JC, 2003, J GEOPHYS RES-ATMOS, V108, P0, DOI 10.1029/2002JD002499
   Adler RF, 2003, J HYDROMETEOROL, V4, P1147, DOI 10.1175/1525-7541(2003)004<1147:TVGPCP>2.0.CO;2
   Amante C, 2009, NGDC24 NOAA NESDIS, V0, P0, DOI DOI 10.7289/V5C8276M
   [Anonymous], 2011, STAT METHODS ATMOSPH, V0, P0
   Banta R.M., 2013, OBSERVATIONAL TECHNI, V0, PP409, DOI 10.1007/978-94-007-4098-3_8
   BC Hydro, 2020, GENERATION SYSTEM EF, V0, P0
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Breiman L., 1984, CLASSIFICATION REGRE, V0, P0, DOI DOI 10.1002/widm.8
   Canadian Centre for Climate Services, 2019, TECHNICAL DOCUMENTAT, V0, P0
   Carrera ML, 2010, J HYDROMETEOROL, V11, P1123, DOI 10.1175/2010JHM1274.1
   Chilton R.R.H., 1981, MINISTRY ENV ASSESSM, V0, P0
   Computational and Information Systems Laboratory, 2017, CHEYENN HPE SGI ICE, V0, P0, DOI DOI 10.5065/D6RX99HX
   Eischeid JK, 2000, J APPL METEOROL, V39, P1580, DOI 10.1175/1520-0450(2000)039<1580:CASCND>2.0.CO;2
   EISCHEID JK, 1995, J APPL METEOROL, V34, P2787, DOI 10.1175/1520-0450(1995)034<2787:TQCOLT>2.0.CO;2
   Fortin V, 2018, ATMOS OCEAN, V56, P178, DOI 10.1080/07055900.2018.1474728
   Fortin V, 2015, J HYDROL, V531, P296, DOI 10.1016/j.jhydrol.2015.08.003
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Goodison B.E., 1998, 67 WMO, V67, P0
   GROISMAN PY, 1994, B AM METEOROL SOC, V75, P215, DOI 10.1175/1520-0477(1994)075<0215:TAOUSP>2.0.CO;2
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Hubbard KG, 2005, J ATMOS OCEAN TECH, V22, P105, DOI 10.1175/JTECH-1657.1
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang S, 2018, COMPLEXITY, V0, P0, DOI DOI 10.1155/2018/1048756
   Jorgensen HK, 1998, WATER SCI TECHNOL, V37, P113, DOI 10.2166/wst.1998.0448
   Kienzle SW, 2008, HYDROL PROCESS, V22, P5067, DOI 10.1002/hyp.7131
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Lakshmanan V, 2007, J APPL METEOROL CLIM, V46, P288, DOI 10.1175/JAM2460.1
   Lakshmanan V, 2014, J ATMOS OCEAN TECH, V31, P1234, DOI 10.1175/JTECH-D-13-00073.1
   Lespinas F, 2015, J HYDROMETEOROL, V16, P2045, DOI 10.1175/JHM-D-14-0191.1
   Liu Y, 2016, APPL DEEP CONVOLUTIO, V0, P0
   Liu Y., 2018, HYDROL EARTH SYST SC, V0, P0, DOI DOI 10.5194/hess-2018-307
   Mahfouf JF, 2007, ATMOS OCEAN, V45, P1
   Martinaitis SM, 2015, J HYDROMETEOROL, V16, P2345, DOI 10.1175/JHM-D-15-0020.1
   Maul-Kotter B, 1998, WATER SCI TECHNOL, V37, P155, DOI 10.2166/wst.1998.0458
   MEEK DW, 1994, AGR FOREST METEOROL, V69, P85, DOI 10.1016/0168-1923(94)90083-3
   MOTOYAMA H, 1990, J APPL METEOROL, V29, P1104, DOI 10.1175/1520-0450(1990)029<1104:SOSSBO>2.0.CO;2
   Mourad M, 2002, WATER SCI TECHNOL, V45, P263, DOI 10.2166/wst.2002.0601
   Nearing MA, 2005, CATENA, V61, P131, DOI 10.1016/j.catena.2005.03.007
   Neiman PJ, 2008, J HYDROMETEOROL, V9, P22, DOI 10.1175/2007JHM855.1
   Niculescu-Mizil A., 2005, P 22 INT C MACHINE L, V0, P625
   Null SE, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0009932
   Odon P, 2018, J APPL METEOROL CLIM, V57, P2091, DOI 10.1175/JAMC-D-18-0058.1
   Piatyszek E, 2000, J HYDROL, V230, P258, DOI 10.1016/S0022-1694(00)00213-4
   Platt JC, 2000, ADV NEUR IN, V0, P61
   Qi YC, 2016, J HYDROMETEOROL, V17, P1675, DOI 10.1175/JHM-D-15-0188.1
   Raileanu LE, 2004, ANN MATH ARTIF INTEL, V41, P77, DOI 10.1023/B:AMAI.0000018580.96245.c6
   Rasmussen R, 2012, B AM METEOROL SOC, V93, P811, DOI 10.1175/BAMS-D-11-00052.1
   Read W.A., 2015, CLIMATOLOGY METEOROL, V0, P0, DOI DOI 10.14288/1.0166485
   Schneider U, 2014, THEOR APPL CLIMATOL, V115, P15, DOI 10.1007/s00704-013-0860-x
   Sciuto G, 2009, J HYDROL, V364, P13, DOI 10.1016/j.jhydrol.2008.10.008
   Simonyan K, 2015, ARXIV, V0, P0
   Springenberg J. T., 2015, ICLR WORKSHOP, V0, P0
   Stepanek P, 2009, ADV SCI RES, V3, P23
   Tompson J, 2015, PROC CVPR IEEE, V0, PP648, DOI 10.1109/CVPR.2015.7298664
   Vandal T, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P5389
   Wong JS, 2017, HYDROL EARTH SYST SC, V21, P2163, DOI 10.5194/hess-21-2163-2017
   Xie PP, 1996, J CLIMATE, V9, P840, DOI 10.1175/1520-0442(1996)009<0840:AOGMPU>2.0.CO;2
   Xu CD, 2014, J APPL METEOROL CLIM, V53, P1538, DOI 10.1175/JAMC-D-13-0179.1
   Yang DQ, 2005, GEOPHYS RES LETT, V32, P0, DOI 10.1029/2005GL024057
   You JS, 2007, J ATMOS OCEAN TECH, V24, P821, DOI 10.1175/JTECH2002.1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao Q, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10121712
NR 64
TC 5
Z9 5
U1 4
U2 16
PU AMER METEOROLOGICAL SOC
PI BOSTON
PA 45 BEACON ST, BOSTON, MA 02108-3693 USA
SN 0739-0572
EI 1520-0426
J9 J ATMOS OCEAN TECH
JI J. Atmos. Ocean. Technol.
PD MAY 15
PY 2021
VL 38
IS 5
BP 1075
EP 1091
DI 10.1175/JTECH-D-20-0081.1
PG 17
WC Engineering, Ocean; Meteorology & Atmospheric Sciences
SC Engineering; Meteorology & Atmospheric Sciences
GA SR1OX
UT WOS:000660815200011
DA 2023-04-26
ER

PT J
AU Wang, XH
   Wan, TY
   Yang, Q
   Zhang, ML
   Sun, YN
AF Wang, Xiaohua
   Wan, Tianyu
   Yang, Qing
   Zhang, Mengli
   Sun, Yingnan
TI Research on Innovation Non-Equilibrium of Chinese Urban Agglomeration Based on SOM Neural Network
SO SUSTAINABILITY
LA English
DT Article
DE regional innovation; urban agglomeration; Theil index; neural network
ID smart-city; efficiency
AB Different indicators, such as the number of patent applications, the number of grants, and the patent conversion rate, were proposed in this study to analyze the issue of innovation imbalance within and between urban agglomerations from a new perspective. First, a preliminary analysis of the current state of innovation and development of China's nine urban agglomerations was conducted. Then the Theil index, widely used in equilibrium research, was employed to measure the overall innovation gap of China's urban agglomerations. The study innovatively used the self-organizing feature map to identify the correlation characteristics of the innovation and development within China's urban agglomerations and visualize them through Geographic Information Science. The research findings show that the hierarchical differentiation of the innovation and development of China's urban agglomerations is becoming increasingly clear, and that the imbalance in regional innovation development is pronounced. The imbalance in innovation development within urban agglomerations is more significant than the imbalance in innovation development among urban agglomerations. The analysis indicated that a possible cause is the crowding effect and administrative standard effect of the central city. The key to addressing this problem is promoting innovative and coordinated development between regions.
C1 [Wang, Xiaohua; Yang, Qing] Wuhan Univ Technol, Sch Safety Sci & Emergency Management, Wuhan 430070, Peoples R China.
   [Wan, Tianyu] Wuhan Univ Technol, Sch Management, Wuhan 430070, Peoples R China.
   [Zhang, Mengli] Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.
   [Sun, Yingnan] Henan Univ Technol, Sch Econ & Trade, Zhengzhou 450001, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology; Central South University; Henan University of Technology
RP Sun, YN (corresponding author), Henan Univ Technol, Sch Econ & Trade, Zhengzhou 450001, Peoples R China.
EM wxh3707@whut.edu.cn; 282280@whut.edu.cn; yangq@whut.edu.cn; docmcy@whut.edu.cn; Sunyingnan@stu.haut.edu.cn
FU National Social Science Fund of China [16ZDA045]; National Natural Science Foundation of China [71603197]
CR Agbali M, 2017, INT J CIV ENV STRUCT, V11, P600
   [Anonymous], 2015, MEASURING ENV INNOVA, V0, P0
   [Anonymous], 2000, OXF DEV STUD, V0, P0, DOI DOI 10.1080/713688313
   [Anonymous], 2001, IND CORP CHANGE, V0, P0, DOI DOI 10.1093/ICC/10.4.945
   Bai J.h., 2011, FINANCE TRADE EC, V10, P104
   Ben T.M., 2011, ASIAN SOC SCI, V7, P56, DOI 10.5539/ass.v7n5p56
   Berry BJL, 2012, CITIES, V29, PS17, DOI 10.1016/j.cities.2011.11.007
   Bibri SE, 2018, SUSTAIN CITIES SOC, V38, P758, DOI 10.1016/j.scs.2017.12.032
   Bulkeley H, 2016, CURR OPIN ENV SUST, V22, P13, DOI 10.1016/j.cosust.2017.02.003
   Caragliu A, 2019, TECHNOL FORECAST SOC, V142, P373, DOI 10.1016/j.techfore.2018.07.022
   [陈丹玲 Chen Danling], 2018, 中国人口·资源与环境 CHINA POPULATION RESOURCES AND ENVIRONMENT, V28, P106
   Chen G.L, 2016, CHINA IND EC, V8, P76, DOI 10.19581/J.CNKI.CIEJOURNAL.2016.08.006
   Cheng Q., 2015, IND EC RES, V4, P10
   Datta A, 2015, DIALOGUES HUM GEOGR, V5, P3, DOI 10.1177/2043820614565748
   Deng Y.W, 2020, PLANNER, V36, P69
   Ebel R, 2020, HORTTECHNOLOGY, V30, P13, DOI 10.21273/HORTTECH04310-19
   Fan F, 2021, J CLEAN PROD, V287, P0, DOI 10.1016/j.jclepro.2020.125060
   Fang CL, 2017, LANDSCAPE URBAN PLAN, V162, P126, DOI 10.1016/j.landurbplan.2017.02.014
   Feng F, 2011, SCI SCI MANAG S T, V12, P109
   Feng Y.T., 2019, RES FINANC ISSUES, V423, P115
   Guoping L, 2014, EC MANAG, V6, P13
   Gutierrez-Avila I, 2021, INT J CLIMATOL, V41, P4095, DOI 10.1002/joc.7060
   Hong J, 2016, TECHNOVATION, V57-58, P4, DOI 10.1016/j.technovation.2016.06.001
   Jefferson GH, 2006, ECON INNOV NEW TECH, V15, P345, DOI 10.1080/10438590500512851
   Lang R, 2009, REG STUD, V43, P789, DOI 10.1080/00343400701654251
   Li B., 2020, MATH STAT MANAG, V39, P139
   Li YC, 2018, URBAN STUD, V55, P443, DOI 10.1177/0042098016656971
   Liu MG, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2017), V0, PP447, DOI 10.1109/INFOMAN.2017.7950425
   Liu S.L, 2018, GANSU SOC SCI, V5, P1
   [刘云强 Liu Yunqiang], 2018, 长江流域资源与环境 RESOURCES AND ENVIRONMENT IN THE YANGTZE BASIN, V27, P2395
   Liu Z.J., 2009, SCI TECHNOL EC, V22, P14
   Mora L, 2017, J URBAN TECHNOL, V24, P3, DOI 10.1080/10630732.2017.1285123
   Nam T., 2011, P 5 INT C THEORY PRA, V0, PP185, DOI 10.1145/2072069.2072100
   Nasierowski W., 2003, SOCIO-ECON PLAN SCI, V37, P215, DOI 10.1016/S0038-0121(02)00046-0
   Porfiryev B.N., 2018, STUD RUSS EC DEV, V29, P116, DOI 10.1134/S1075700718020119
   Powson E, 2008, PROG HUM GEOG, V32, P441, DOI 10.1177/0309132508089097
   Qin K.X., 2021, TECHNOL PROG COUNTER, V1, P36
   Spivak AA, 2016, IZV ATMOS OCEAN PHY+, V52, P841, DOI 10.1134/S0001433816080107
   Terando AJ, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0102261
   Tomokiyo T., 2003, P ACL 2003 WORKSH MU, V0, P33
   Villani E, 2021, J TECHNOL TRANSFER, V46, P1017, DOI 10.1007/s10961-020-09803-8
   Wang C.Z, 2015, CHINA SOFT SCI, V11, P68
   Wang Q, 2018, QUANTITATIVE EC TECH, V35, P77, DOI 10.13653/J.CNKI.JQTE.2018.11.005
   Wang Q, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11216071
   Xie S.H, 2017, URBAN ISSUES, V8, P92
   Xu J.Y., 2015, MANAGE WORLD, V10, P7, DOI 10.19744/J.CNKI.11-1235/F.2015.10.003
   Yu J.K, 2018, GEOGR SCI, V38, P1875
   Zeng JY, 2019, APPL SPAT ANAL POLIC, V12, P1031, DOI 10.1007/s12061-019-09300-y
   Zhang AM, 2003, J COMP ECON, V31, P444, DOI 10.1016/S0147-5967(03)00055-6
   Zhang C.Z., 2012, IND EC RES, V6, P17
   [张欢 Zhang Huan], 2018, 中国人口·资源与环境 CHINA POPULATION RESOURCES AND ENVIRONMENT, V28, P73
   Zhang JX, 2020, SUSTAIN CITIES SOC, V57, P0, DOI 10.1016/j.scs.2020.102123
   [周灿 Zhou Can], 2017, 地理研究 GEOGRAPHICAL RESEARCH, V36, P1297
   Zhou X.Y, 2009, EC MANAG, V31, P28
   Zhou Z.H, 2002, SHANGHAI EC RES, V4, P23
NR 55
TC 4
Z9 4
U1 4
U2 42
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2071-1050
J9 SUSTAINABILITY-BASEL
JI Sustainability
PD SEP 15
PY 2021
VL 13
IS 17
BP 
EP 
DI 10.3390/su13179506
PG 21
WC Green & Sustainable Science & Technology; Environmental Sciences; Environmental Studies
SC Science & Technology - Other Topics; Environmental Sciences & Ecology
GA UO1RL
UT WOS:000694479100001
DA 2023-04-26
ER

PT J
AU Feng, F
   Wang, ST
   Zhang, J
   Wang, CY
AF Feng Fan
   Wang Shuangting
   Zhang Jin
   Wang Chunyang
TI Hyperspectral Images Classification Based on Multi-Feature Fusion and Hybrid Convolutional Neural Networks
SO LASER & OPTOELECTRONICS PROGRESS
LA Chinese
DT Article
DE image processing; hyperspectral images; multi-feature fusion; residual connection; hybrid convolutional neural network
AB Aiming at the problem that the classification accuracy of hyperspectral images is not ideal when the amount of training samples of three-dimensional convolutional network is limited, an efficient classification model based on multi-feature fusion and hybrid convolutional neural networks is proposed in this paper. First, after the dimensionality reduction processing is performed on hyperspectral images, the three-dimensional convolutional layer is used to extract deep hierarchical spatial-spectral joint features. Then, the residual connection is introduced to perform multi -feature fusion through feature map concatenation and pixel-wise addition to realize feature reuse and enhance information transmission. Finally, a two-dimensional convolutional layer is used to enhance the spatial information of the extracted features and realize image classification. The experimental results show that in the three publicly available hyperspectral data sets Indian Pines, Salinas and University of Pavia, 5%, 1% and 1% of the labeled samples are used as training data, respectively, the classification accuracy of the model is 97.09%, 99.30% and 97. 60%, respectively, which can effectively improve the classification accuracy of hyperspectral images for under small sample condition.
C1 [Feng Fan; Wang Shuangting; Zhang Jin; Wang Chunyang] Henan Polytech Univ, Sch Surveying & Land Informat Engn, Jiaozuo 454000, Henan, Peoples R China.
C3 Henan Polytechnic University
RP Wang, CY (corresponding author), Henan Polytech Univ, Sch Surveying & Land Informat Engn, Jiaozuo 454000, Henan, Peoples R China.
EM wcy@hpu.edu.cn
CR Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   BiXJ ZhouZ Y, 2019, ACTA OPTICA SINICA, V39, P10
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chollet F, 2017, PROC CVPR IEEE, V0, PP1800, DOI 10.1109/CVPR.2017.195
   [杜培军 Du Peijun], 2016, 遥感学报 JOURNAL OF REMOTE SENSING, V20, P236
   Eldan R, 2020, POWER DEPTH FEEDFORW, V0, P0
   Feng F, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19235276
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang GL, 2017, IEEE ICC, V0, P0
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040331
   LiS Y, 2019, INFRARED LASER ENG, V48, P0
   Liu B, 2019, IEEE T GEOSCI REMOTE, V57, P2290, DOI 10.1109/TGRS.2018.2872830
   Liu YZ, 2019, LASER OPTOELECTRON P, V56, P0, DOI 10.3788/LOP56.111007
   Makantasis K, 2015, INT GEOSCI REMOTE SE, V0, PP4959, DOI 10.1109/IGARSS.2015.7326945
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Veit A, 2020, RESIDUAL NETWORKS BE, V0, P0
   Wei XP, 2019, LASER OPTOELECTRON P, V56, P0, DOI 10.3788/LOP56.151006
   Yan MJ, 2020, ACTA OPT SIN, V40, P0, DOI 10.3788/AOS202010.1628002
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   [张号逵 Zhang Haokui], 2018, 自动化学报 ACTA AUTOMATICA SINICA, V44, P961
   ZhangJ WeiF Y, 2020, J SENSORS, V20, P5191
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhou YC, 2016, IEEE T CYBERNETICS, V46, P1667, DOI 10.1109/TCYB.2015.2453359
NR 26
TC 4
Z9 4
U1 4
U2 14
PU SHANGHAI INST OPTICS & FINE MECHANICS, CHINESE ACAD SCIENCE
PI SHANGHAI
PA 390, QINGHE LU, SHANGHAI, JIADING-QU, PEOPLES R CHINA
SN 1006-4125
EI 
J9 LASER OPTOELECTRON P
JI Laser Optoelectron. Prog.
PD APR 15
PY 2021
VL 58
IS 8
BP 
EP 
DI 10.3788/LOP202158.0810010
PG 11
WC Engineering, Electrical & Electronic; Optics
SC Engineering; Optics
GA UC4GG
UT WOS:000686485400012
DA 2023-04-26
ER

PT J
AU Wang, WN
   Liu, WQ
   Chen, H
AF Wang, Weina
   Liu, Wanquan
   Chen, Hui
TI Information Granules-Based BP Neural Network for Long-Term Prediction of Time Series
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Time series analysis; Market research; Predictive models; Neural networks; Forecasting; Hidden Markov models; Semantics; Back-propagation neural network; information granulation; long-term prediction; time series forecasting
ID fuzzy cognitive maps; models
AB Long-term time series prediction is a challenging and essential task both in theory and practice. Recently, information granulation is shown to be an appropriate tool for the long-term forecast. Though some models for the long-term prediction problem have been proposed using information granulation recently, there is still a growing need to develop new prediction approaches for time series data based on information granule, which can capture the dynamic trend change with high accuracy. In this article, a long-term prediction approach, based on back-propagation neural network and information granule, is proposed. First, the individual numerical intervals for the time series are obtained by using the principle of justifiable granularity in information granule. Then, an automatic linear trend extraction method is developed to extract the trend change, which is inherited in granules. Finally, a hierarchy of neural network is constructed to carry out prediction by using information granule as input. Experiments using publicly available time series datasets demonstrate that the proposed approach can achieve better performance than the existing models for long-term prediction.
C1 [Wang, Weina] Jilin Inst Chem Technol, Sch Sci, Jilin 132022, Jilin, Peoples R China.
   [Liu, Wanquan] Curtin Univ, Dept Comp, Perth, WA 6102, Australia.
   [Chen, Hui] Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
C3 Jilin Institute of Chemical Technology; Curtin University; Shanghai University of Electric Power
RP Chen, H (corresponding author), Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
EM wangweina406@sina.com; w.liu@curtin.edu.au; chenhui@shiep.edu.cn
FU Natural Science Foundation of China [51705304]; "Thirteen Five" Science and Technology Program of Department of Education of Jilin Province [JJKH20200234KJ]; Natural Science Foundation of Shanghai [16ZR1413400]; Science and Technology Innovation Development Program of Jilin City [201831769, 20190104204]
CR Al-Hmouz R, 2016, KNOWL INF SYST, V48, P561, DOI 10.1007/s10115-015-0868-x
   Al-Hmouz R, 2015, EXPERT SYST APPL, V42, P4830, DOI 10.1016/j.eswa.2015.01.060
   [Anonymous], 1976, HOLDEN DAY SERIES TI, V0, P0
   Bargiela A., 2003, P IEEE P 22 INT C N, V0, P24
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Benmouiza K, 2013, ENERG CONVERS MANAGE, V75, P561, DOI 10.1016/j.enconman.2013.07.003
   Bodyanskiy Y, 2006, EUR J OPER RES, V175, P1357, DOI 10.1016/j.ejor.2005.02.012
   Chen H., 2007, NEUROCOMPUTING, V70, P697, DOI 10.1016/J.NEUCOM.2006.10.005
   Chen SM, 2011, IEEE T FUZZY SYST, V19, P1, DOI 10.1109/TFUZZ.2010.2073712
   Chen SM, 2010, IEEE T SYST MAN CY B, V40, P1343, DOI 10.1109/TSMCB.2009.2038358
   Cheng SH, 2016, INFORM SCIENCES, V327, P272, DOI 10.1016/j.ins.2015.08.024
   Das G., 1998, PROCEEDINGS FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, P16
   Dincer NG, 2018, ECOL INFORM, V43, P157, DOI 10.1016/j.ecoinf.2017.12.001
   Dong XF, 2018, INFORM SCIENCES, V424, P39, DOI 10.1016/j.ins.2017.09.067
   Franses PH, 2005, INT J FORECASTING, V21, P87, DOI 10.1016/j.ijforecast.2004.05.005
   Froelich W, 2017, KNOWL-BASED SYST, V115, P110, DOI 10.1016/j.knosys.2016.10.017
   Guo HY, 2018, IEEE T FUZZY SYST, V26, P2807, DOI 10.1109/TFUZZ.2018.2802924
   Guo HY, 2016, J APPL STAT, V43, P2897, DOI 10.1080/02664763.2016.1155111
   Jang H, 2018, IEEE ACCESS, V6, P5427, DOI 10.1109/ACCESS.2017.2779181
   Kang IB, 2003, INT J FORECASTING, V19, P387, DOI 10.1016/S0169-2070(02)00010-9
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476
   Nguyen L, 2019, FUZZY SET SYST, V361, P114, DOI 10.1016/j.fss.2018.09.010
   Liu H, 2013, APPL ENERG, V107, P191, DOI 10.1016/j.apenergy.2013.02.002
   Liu S, 2018, ENG APPL ARTIF INTEL, V71, P60, DOI 10.1016/j.engappai.2018.02.012
   Pedrycz W, 2001, IEEE T SYST MAN CY B, V31, P106, DOI 10.1109/3477.907568
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Rahman MM, 2016, IEEE T CYBERNETICS, V46, P270, DOI 10.1109/TCYB.2015.2401038
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P26, DOI 10.1016/B978-1-4832-1446-7.50010-8
   Sadownik R, 1999, J FORECASTING, V18, P215, DOI 10.1002/(SICI)1099-131X(199905)18:3<215::AID-FOR719>3.0.CO;2-B
   Sagheer A, 2019, NEUROCOMPUTING, V323, P203, DOI 10.1016/j.neucom.2018.09.082
   Sivakumar S, 2018, IEEE T CYBERNETICS, V48, P2836, DOI 10.1109/TCYB.2017.2751005
   Wang L, 2018, APPL SOFT COMPUT, V66, P1, DOI 10.1016/j.asoc.2018.02.004
   Wang WN, 2015, ENG APPL ARTIF INTEL, V41, P17, DOI 10.1016/j.engappai.2015.01.006
   Wang WN, 2015, INFORM SCIENCES, V294, P78, DOI 10.1016/j.ins.2014.09.027
   Wang XN, 2016, INT J INNOV COMPUT I, V12, P15
   Yang SC, 2018, IEEE T FUZZY SYST, V26, P3391, DOI 10.1109/TFUZZ.2018.2831640
   Yang XY, 2017, INT J APPROX REASON, V81, P1, DOI 10.1016/j.ijar.2016.10.010
   Yao JT, 2013, IEEE T CYBERNETICS, V43, P1977, DOI 10.1109/TSMCC.2012.2236648
   Zadeh L.A., 1979, ADV FUZZY SET THEORY, V11, P3
   Zhang G., 1998, THESIS KENT STATE U, V0, P0
   Zhang GP, 2001, J OPER RES SOC, V52, P652, DOI 10.1057/palgrave.jors.2601133
NR 43
TC 8
Z9 9
U1 9
U2 52
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD OCT 15
PY 2021
VL 29
IS 10
BP 2975
EP 2987
DI 10.1109/TFUZZ.2020.3009764
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA WC2XW
UT WOS:000704125600016
DA 2023-04-26
ER

PT J
AU Liu, T
   Chen, T
   Niu, RQ
   Plaza, A
AF Liu, Tong
   Chen, Tao
   Niu, Ruiqing
   Plaza, Antonio
TI Landslide Detection Mapping Employing CNN, ResNet, and DenseNet in the Three Gorges Reservoir, China
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Terrain factors; Reservoirs; Convolutional neural networks; Soil; Indexes; Training; Rivers; Deep neural network; dense convolutional neural network (DenseNet); feature selection; landslide detection; Three Gorges Reservoir (TGR)
ID fully convolutional densenet; logistic-regression; susceptibility maps; risk-assessment; decision tree; random forest; networks; classifier; hazard; areas
AB Landslide detection mapping (LDM) is the basis of the field of landslide disaster prevention; however, it has faced certain difficulties. The Three Gorges Reservoir area of the Yangtze River has been one of the most intensively evaluated areas for landslide prevention in the world, due to the high frequency of landslide disasters here. In this article, we constructed an accurate LDM model based on convolutional neural networks, residual neural networks, and dense convolutional neural networks (DenseNets) that considers "ZY-3" high spatial resolution (HSR) data and conditioning factors (CFs). In this article, 19 factors based on remote sensing (RS) images, topographical and geological data associated with historical landslide locations were randomly divided into training (70% of total) and testing (30%) datasets. The experimental results show that the accuracy (ACC) of these three LDM models is above 0.95, indicating that the deep neural networks aimed at landslide detection performed well. Furthermore, DenseNet with RS images and CFs can accurately detect landslides. Specifically, DenseNet with RS images and CFs outperforms the other five models by considering the evaluation metrics, which exhibited Kappa coefficient improvements of 0.01-0.04 and ACC improvements of 0.02-0.3%. Among all the factors, elevation factor has a high importance of 0.727, which is the most important factors found in this landslide model construction experiment.
C1 [Liu, Tong; Chen, Tao; Niu, Ruiqing] China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
   [Chen, Tao] Geomat Technol & Applicat Key Lab Qinghai Prov, Xining 810001, Peoples R China.
   [Chen, Tao] Beijing Key Lab Urban Spatial Informat Engn, Beijing 100038, Peoples R China.
   [Plaza, Antonio] Univ Extremadura, Escuela Politecn, Hyperspectral Comp Lab, Dept Technol Comp & Commun, Caceres 10071, Spain.
C3 China University of Geosciences; Universidad de Extremadura
RP Chen, T (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
EM zhinian@cug.edu.cn; taochen@cug.edu.cn; niuruiqing@cug.edu.cn; aplaza@unex.es
FU National Natural Science Foundation of China [62071439, 61871259]; Opening Foundation of Qilian Mountain National Park Research Center (Qinghai) [GKQ2019-01]; Opening Foundation of Beijing Key Laboratory of Urban Spatial Information Engineering [20210209]; Opening Foundation of Geomatics Technology and Application Key Laboratory of Qinghai Province [QHDX-2019-01]
CR Pham BT, 2018, J INDIAN SOC REMOTE, V46, P1457, DOI 10.1007/s12524-018-0791-1
   Cai HJ, 2021, IEEE J-STARS, V14, P5235, DOI 10.1109/JSTARS.2021.3079196
   Chen T, 2020, J MT SCI-ENGL, V17, P670, DOI 10.1007/s11629-019-5839-3
   Chen T, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040333
   Chen T, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5317-y
   Chen T, 2015, ENVIRON EARTH SCI, V73, P5571, DOI 10.1007/s12665-014-3811-7
   Chen THK, 2019, REMOTE SENS ENVIRON, V225, P317, DOI 10.1016/j.rse.2019.03.013
   Chen W, 2018, CATENA, V164, P135, DOI 10.1016/j.catena.2018.01.012
   Chen WT, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010082
   Dai FC, 2002, ENG GEOL, V64, P65, DOI 10.1016/S0013-7952(01)00093-X
   Deng ZR, 2020, SIGNAL PROCESS-IMAGE, V85, P0, DOI 10.1016/j.image.2020.115836
   Bui D, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101527
   Bui DT, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5919-4
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), V0, PP444, DOI 10.1109/YAC.2016.7804935
   Dou J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060638
   Gao X, 2021, IEEE J-STARS, V14, P7881, DOI 10.1109/JSTARS.2021.3101203
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11172046
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Guns M, 2012, NAT HAZARD EARTH SYS, V12, P1937, DOI 10.5194/nhess-12-1937-2012
   Guo HN, 2021, REMOTE SENS ENVIRON, V264, P0, DOI 10.1016/j.rse.2021.112589
   Hao X, 2016, INT J SEMANT COMPUT, V10, P417, DOI 10.1142/S1793351X16500045
   He D., 2020, IEEE T GEOSCI ELECT, V0, P0, DOI DOI 10.1109/TGRS.2020.3032475
   He D, 2021, IEEE T GEOSCI REMOTE, V59, P10628, DOI 10.1109/TGRS.2021.3050824
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KQ, 2008, ENVIRON GEOL, V55, P55, DOI 10.1007/s00254-007-0964-7
   Hong HY, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4866-9
   Hu Q, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212530
   Hua L., 2005, REMOTE SENS LAND RES, V17, P7345
   Hua Y, 2021, LANDSLIDES, V18, P281, DOI 10.1007/s10346-020-01444-0
   Huang FM, 2018, ENVIRON EARTH SCI, V77, P0, DOI 10.1007/s12665-018-7334-5
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Huang QQ, 2020, IEEE GEOSCI REMOTE S, V17, P312, DOI 10.1109/LGRS.2019.2918254
   [黄汀 Huang Ting], 2018, 测绘通报 BULLETIN OF SURVEYING AND MAPPING, V0, P67
   Jiankun Wang, 2020, IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, V17, P1748, DOI 10.1109/TASE.2020.2976560
   Kimura H, 2000, PHOTOGRAMM ENG REM S, V66, P337
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2015, LENET 5 CONVOLUTIONA, V20, P5
   Lee S, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10228189
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li LW, 2020, MULTIMED TOOLS APPL, V79, P6727, DOI 10.1007/s11042-019-08429-9
   Lin QG, 2017, ADVANCING CULTURE OF LIVING WITH LANDSLIDES, VOL 2: ADVANCES IN LANDSLIDE SCIENCE, P61, DOI 10.1007/978-3-319-53498-5_8
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI 10.1109/TGRS.2020.3018879
   Long LJ, 2021, J SUPERCOMPUT, V77, P8728, DOI 10.1007/s11227-020-03604-4
   Lu P, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111235
   Lv ZY, 2021, IEEE GEOSCI REMOTE S, V18, P1284, DOI 10.1109/LGRS.2020.2998684
   Mandal S, 2018, MODEL EARTH SYST ENV, V4, P69, DOI 10.1007/s40808-018-0426-0
   Martha TR, 2013, GEOMORPHOLOGY, V184, P139, DOI 10.1016/j.geomorph.2012.12.001
   McKean J, 2004, GEOMORPHOLOGY, V57, P331, DOI 10.1016/S0169-555X(03)00164-8
   Metternicht G, 2005, REMOTE SENS ENVIRON, V98, P284, DOI 10.1016/j.rse.2005.08.004
   Naghibi SA, 2016, ENVIRON MONIT ASSESS, V188, P0, DOI 10.1007/s10661-015-5049-6
   Oh HJ, 2011, COMPUT GEOSCI-UK, V37, P1264, DOI 10.1016/j.cageo.2010.10.012
   Peng L, 2014, GEOMORPHOLOGY, V204, P287, DOI 10.1016/j.geomorph.2013.08.013
   Pham B. T., 2015, INT J ENG RES TECHNO, V4, P338, DOI 10.17577/IJERTV4IS110285
   Pourghasemi HR, 2012, CATENA, V97, P71, DOI 10.1016/j.catena.2012.05.005
   Qu Z, 2020, IEEE ACCESS, V8, P54564, DOI 10.1109/ACCESS.2020.2981561
   Reichenbach P, 2018, EARTH-SCI REV, V180, P60, DOI 10.1016/j.earscirev.2018.03.001
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   Santangelo M, 2010, NAT HAZARD EARTH SYS, V10, P2539, DOI 10.5194/nhess-10-2539-2010
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shi Q, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3085870
   Shi Q, 2021, IEEE T GEOSCI REMOTE, V59, P10348, DOI 10.1109/TGRS.2020.3045273
   Shirzadi A, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-016-6374-y
   Simonyan K, 2015, ARXIV, V0, P0
   Singh KK, 2016, NAT HAZARDS, V83, P1027, DOI 10.1007/s11069-016-2361-6
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Tavakkoli Piralilou S, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212575
   Tong N, 2019, INT J RADIAT ONCOL, V105, PS93, DOI 10.1016/j.ijrobp.2019.06.570
   Tong W, 2020, IEEE J-STARS, V13, P4121, DOI 10.1109/JSTARS.2020.3009352
   Tsangaratos P, 2017, LANDSLIDES, V14, P1091, DOI 10.1007/s10346-016-0769-4
   Tsangaratos P, 2016, CATENA, V145, P164, DOI 10.1016/j.catena.2016.06.004
   Tzouvaras M, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101560
   Ortiz JAV, 2018, GEOMAT NAT HAZ RISK, V9, P1106, DOI 10.1080/19475705.2018.1513083
   Viet-Ha Nhu, 2020, FORESTS, V11, P0, DOI 10.3390/f11080830
   Wang AL, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20041151
   Wang LJ, 2016, GEOSCI J, V20, P117, DOI 10.1007/s12303-015-0026-1
   Wang LJ, 2020, PHYS MED BIOL, V65, P0, DOI 10.1088/1361-6560/abaeb7
   Wu XL, 2013, ENVIRON EARTH SCI, V70, P1307, DOI 10.1007/s12665-013-2217-2
   Xiao LM, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18124436
   Yi YN, 2020, IEEE J-STARS, V13, P6166, DOI 10.1109/JSTARS.2020.3028855
   Yildirim O, 2020, NEURAL COMPUT APPL, V32, P15857, DOI 10.1007/s00521-018-3889-z
   [于欢 YU Huan], 2010, 中国图象图形学报 JOURNAL OF IMAGE AND GRAPHICS, V15, P352
   Yu Y, 2019, COMPUT ELECTRON AGR, V163, P0, DOI 10.1016/j.compag.2019.06.001
   Zhang LF, 2021, IEEE T CYBERNETICS, V51, P673, DOI 10.1109/TCYB.2019.2910151
   ZhiYong L, 2022, IEEE GEOSC REM SEN M, V10, P44, DOI 10.1109/MGRS.2021.3088865
   Zhou J., 2020, SHOCK VIB, V0, P0
   Zhu DY, 2021, J ENVIRON MANAGE, V299, P0, DOI 10.1016/j.jenvman.2021.113655
NR 87
TC 14
Z9 14
U1 16
U2 57
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11417
EP 11428
DI 10.1109/JSTARS.2021.3117975
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XA2YM
UT WOS:000720519100011
DA 2023-04-26
ER

PT J
AU Meng, XJ
   Gao, F
   Xu, T
   Zhou, KJ
   Li, W
   Wu, Q
AF Meng, Xiangjian
   Gao, Feng
   Xu, Tao
   Zhou, Kangjia
   Li, Wei
   Wu, Qiang
TI Inverter-Data-Driven Second-Level Power Forecasting for Photovoltaic Power Plant
SO IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
LA English
DT Article
DE Power generation; Forecasting; Cloud computing; Arrays; Artificial neural networks; Inverters; Clouds; Artificial neural network (ANN); inverter; photovoltaic (PV) power generation; power forecasting; virtual cloud image
ID parameter extraction; energy; model; generation; storage
AB Globally, the installed capacity of photovoltaic (PV) power plants is undergoing rapid growth. However, the random output power fluctuation of PV plants has brought great challenge to power system stable operation. One of the most effective approaches to counteract the impact of power fluctuation is to carry out power forecasting under ultra-short-term scales, among which the second-level power forecasting technique is still absent since the pure historical data analysis of PV plant output power cannot deal with the sudden output power change induced by moving cloud and the traditional cloud image detection methods actually fail to achieve accurate PV power forecasting in high temporal and spatial resolutions. This article proposes an inverter-data-driven method to achieve the second-level PV power forecasting. In specific, multilayer feed-forward artificial neural network based on the error back propagation algorithm is applied to first establish the mapping relations from shading conditions of PV array to its corresponding output power. Combining with output power of neighboring PV arrays as well as their geographical location information, the shading conditions of those shaded PV array can be reversely deduced. And then, the deduced shading conditions of all PV arrays will be converted into one virtual cloud image to identify the instant cloud characteristics. In consequence, the consecutively generated virtual cloud images can depict the moving direction, speed, and shape of shading cloud and then help easily realize the second-level power forecasting of PV plant. Case study and experimental results verified the performance of the proposed method.
C1 [Meng, Xiangjian; Gao, Feng; Xu, Tao; Zhou, Kangjia; Li, Wei] Shandong Univ, Minist Educ, Key Lab Power Syst Intelligent Dispatch & Control, Jinan 250061, Peoples R China.
   [Wu, Qiang] Shandong Univ, Sch Informat Sci & Engn, Qingdao 266237, Peoples R China.
C3 Shandong University; Shandong University
RP Gao, F (corresponding author), Shandong Univ, Minist Educ, Key Lab Power Syst Intelligent Dispatch & Control, Jinan 250061, Peoples R China.
EM el15xm@163.com; fgao@sdu.edu.cn; txu@sdu.edu.cn; 201914266@mail.sdu.edu.cn; eeleev@mail.sdu.edu.cn; wuqiang@sdu.edu.cn
FU National Natural Science Foundation of China [51722704]; Shandong Provincial Natural Science Foundation, China [JQ201717]; Foundation for Innovative Research Groups of National Natural Science Foundation of China [61821004]; Program for Scientific Research Innovation Team of Young Scholar in Colleges and Universities of Shandong Province [2019KJN039]
CR Cardenas AA, 2017, IEEE T IND ELECTRON, V64, P1468, DOI 10.1109/TIE.2016.2615590
   Bao GJ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, V0, PP1148, DOI 10.1109/ICInfA.2015.7279459
   Batzelis EI, 2016, IEEE T SUSTAIN ENERG, V7, P504, DOI 10.1109/TSTE.2015.2503435
   Bo Jing, 2017, THE JOURNAL OF ENGINEERING, V0, P0, DOI DOI 10.1049/joe.2017.0790
   Bragard M, 2010, IEEE T POWER ELECTR, V25, P3049, DOI 10.1109/TPEL.2010.2085455
   Calbo J, 2008, J ATMOS OCEAN TECH, V25, P3, DOI 10.1175/2007JTECHA959.1
   Chatterjee P, 2002, IEEE IJCNN, V0, PP339, DOI 10.1109/IJCNN.2002.1005494
   Chau TK, 2018, IEEE T POWER SYST, V33, P1811, DOI 10.1109/TPWRS.2017.2726160
   Cros S, 2014, INT GEOSCI REMOTE SE, V0, PP4123, DOI 10.1109/IGARSS.2014.6947394
   Huang CJ, 2019, IEEE ACCESS, V7, P74822, DOI 10.1109/ACCESS.2019.2921238
   Jang HS, 2016, IEEE T SUSTAIN ENERG, V7, P1255, DOI 10.1109/TSTE.2016.2535466
   Toledo FJ, 2018, IEEE T IND ELECTRON, V65, P6301, DOI 10.1109/TIE.2018.2793216
   Kuo YC, 2001, IEEE T IND ELECTRON, V48, P594, DOI 10.1109/41.925586
   Kushwaha V, 2017, 2017 7TH INTERNATIONAL CONFERENCE ON POWER SYSTEMS (ICPS), V0, P430
   Li SH, 2019, IEEE T SMART GRID, V10, P5564, DOI 10.1109/TSG.2018.2887080
   Najera Y., 2011, P 37 IEEE PHOT SPEC, V0, P0
   National Renewable Energy Lab. (NREL), 2010, 1 2 GLOBAL HORIZONTA, V0, P0
   Patel H, 2008, IEEE T IND ELECTRON, V55, P1689, DOI 10.1109/TIE.2008.917118
   Rene MQ, 2019, IEEE T IND INFORM, V15, P4624, DOI 10.1109/TII.2018.2882598
   Saleh M, 2018, IEEE T IND INFORM, V14, P403, DOI 10.1109/TII.2017.2767038
   Sarwar Adil, 2015, 2015 INTERNATIONAL CONFERENCE ON ENERGY ECONOMICS AND ENVIRONMENT (ICEEE), V0, PP1, DOI 10.1109/EnergyEconomics.2015.7235079
   Shanghai Acrel Electric Co. LTD, 2017, ARCEL 2000 POWER MON, V0, P0
   Sharma RK, 2018, IEEE T IND APPL, V54, P526, DOI 10.1109/TIA.2017.2756032
   Sheng HM, 2018, IEEE T IND ELECTRON, V65, P300, DOI 10.1109/TIE.2017.2714127
   Stein J. S, 2012, P IEEE 38 PHOT SPEC, V0, P1
   Subudhi B, 2018, IEEE T SUSTAIN ENERG, V9, P381, DOI 10.1109/TSTE.2017.2736060
   Syed MH, 2018, IEEE T POWER SYST, V33, P3199, DOI 10.1109/TPWRS.2018.2799483
   Tanaka Takafumi, 2019, IEEE NETWORKING LETTERS, V1, P60, DOI 10.1109/LNET.2019.2897295
   Tascikaraoglu A, 2016, IEEE T SUSTAIN ENERG, V7, P1295, DOI 10.1109/TSTE.2016.2544929
   Wan C, 2017, IEEE T POWER SYST, V32, P2471, DOI 10.1109/TPWRS.2016.2608740
   Wei Liaoliao, 2017, THE JOURNAL OF ENGINEERING, V0, P0, DOI DOI 10.1049/joe.2017.0726
   Wei W, 2015, IEEE T SMART GRID, V6, P369, DOI 10.1109/TSG.2014.2317744
   Xiao WD, 2007, IEEE T IND ELECTRON, V54, P1696, DOI 10.1109/TIE.2007.894732
   Yang M, 2018, IEEE ACCESS, V6, P51200, DOI 10.1109/ACCESS.2018.2868478
   Yang Y, 2018, IEEE T IND ELECTRON, V65, P394, DOI 10.1109/TIE.2017.2721878
   Zhan YJ, 2017, IEEE GEOSCI REMOTE S, V14, P1785, DOI 10.1109/LGRS.2017.2735801
   Zhen Z, 2019, IEEE T IND APPL, V55, P3331, DOI 10.1109/TIA.2019.2904927
   Zhou L, 2017, 2017 32ND YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), V0, PP452, DOI 10.1109/YAC.2017.7967451
NR 38
TC 5
Z9 6
U1 5
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0046
EI 1557-9948
J9 IEEE T IND ELECTRON
JI IEEE Trans. Ind. Electron.
PD AUG 15
PY 2021
VL 68
IS 8
BP 7034
EP 7044
DI 10.1109/TIE.2020.3005098
PG 11
WC Automation & Control Systems; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Automation & Control Systems; Engineering; Instruments & Instrumentation
GA RX8QT
UT WOS:000647484000060
DA 2023-04-26
ER

PT J
AU Li, PL
   He, XH
   Qiao, MJ
   Miao, DS
   Cheng, XJ
   Song, DJ
   Chen, MY
   Li, JMA
   Zhou, T
   Guo, XY
   Yan, XY
   Tian, ZH
AF Li, Panle
   He, Xiaohui
   Qiao, Mengjia
   Miao, Disheng
   Cheng, Xijie
   Song, Dingjun
   Chen, Mingyang
   Li, Jiamian
   Zhou, Tao
   Guo, Xiaoyu
   Yan, Xinyu
   Tian, Zhihui
TI Exploring multiple crowdsourced data to learn deep convolutional neural networks for road extraction*
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Road extraction; Deep convolutional neural networks; Multiple crowdsourced data; Multi-map integration model; Refined labels
ID image classification; building extraction; segmentation; multiscale; labels; aware
AB Road extraction from high-resolution remote sensing images (HRSIs) is essential for applications in various areas. Although deep convolutional neural networks (DCNNs) have exhibited remarkable success in road extraction, the performance relies on a large amount of training samples which are hard to obtain. To address this issue, multiple crowdsourced data are used in this study, including OpenStreetMap (OSM), Zmap and GPS. And a multi-map integration model (MMIM) is developed to improve the noise robustness of DCNNs for road extraction tasks. Specifically, rich geographical road information are obtained from multiple crowdsourced data, including main roads, new construction roads, midsize and small roads, which can generate complete road training samples and reduce the label noise. Meanwhile, by exploring the true road label information hidden in different crowdsourced data, the MMIM is used to generate high-quality refined labels for learning DCNNs. In this case, the DCNN-based road extraction methods have more opportunities to learn true road distribution and avoid the overfitting problems of label noise. Experiments based on real road extraction dataset indicate that the proposed method shows great performance, and road extraction results are smoother and more complete.
C1 [Li, Panle; Qiao, Mengjia; Miao, Disheng; Cheng, Xijie; Song, Dingjun; Chen, Mingyang; Li, Jiamian; Zhou, Tao] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
   [He, Xiaohui; Guo, Xiaoyu; Yan, Xinyu; Tian, Zhihui] Zhengzhou Univ, Sch Geosci & Technol, Zhengzhou 450001, Peoples R China.
   [He, Xiaohui; Guo, Xiaoyu; Tian, Zhihui] Zhengzhou Univ, Ecometeorol Joint Lab, Zhengzhou 450001, Peoples R China.
   [He, Xiaohui; Guo, Xiaoyu; Tian, Zhihui] Chinese Acad Meteorol Sci, Zhengzhou 450001, Peoples R China.
C3 Zhengzhou University; Zhengzhou University; Zhengzhou University; Chinese Academy of Meteorological Sciences (CAMS)
RP He, XH (corresponding author), Zhengzhou Univ, Sch Geosci & Technol, Zhengzhou 450001, Peoples R China.
EM hexh@zzu.edu.cn
FU Science and Technology Major Project of Henan Province [201400210900]
CR Ali AL, 2017, ISPRS J PHOTOGRAMM, V127, P3, DOI 10.1016/j.isprsjprs.2016.06.003
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bottou L., 2012, NEURAL NETWORKS TRIC, V0, PP421, DOI 10.1007/978-3-642-35289-8_25
   Chen JY, 2019, IEEE T GEOSCI REMOTE, V57, P1713, DOI 10.1109/TGRS.2018.2868748
   Chen JY, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP771, DOI 10.1145/3041021.3054250
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Ding L., 2020, IEEE T MED IMAGING, V0, P1
   Dong R., 2021, IEEE T GEOSCI ELECT, V0, P1
   Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Gevaert CM, 2018, IEEE J-STARS, V11, P2731, DOI 10.1109/JSTARS.2017.2762905
   Grinias I, 2016, ISPRS J PHOTOGRAMM, V122, P145, DOI 10.1016/j.isprsjprs.2016.10.010
   Han B, 2019, IEEE T NEUR NET LEAR, V30, P3774, DOI 10.1109/TNNLS.2019.2899045
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Jiang JJ, 2019, IEEE T GEOSCI REMOTE, V57, P851, DOI 10.1109/TGRS.2018.2861992
   Jiang L., 2018, MENTORNET REGULARIZI, V0, P0
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Li PL, 2021, IEEE T GEOSCI REMOTE, V59, P6182, DOI 10.1109/TGRS.2020.3023112
   Li PL, 2019, IEEE ACCESS, V7, P122784, DOI 10.1109/ACCESS.2019.2938215
   Li YS, 2021, IEEE T CYBERNETICS, V51, P1756, DOI 10.1109/TCYB.2020.2989241
   Li Y, 2019, IEEE GEOSCI REMOTE S, V16, P613, DOI 10.1109/LGRS.2018.2878771
   Liu YH, 2019, IEEE T GEOSCI REMOTE, V57, P2043, DOI 10.1109/TGRS.2018.2870871
   Lu XY, 2019, IEEE T GEOSCI REMOTE, V57, P9362, DOI 10.1109/TGRS.2019.2926397
   Martins VS, 2020, ISPRS J PHOTOGRAMM, V168, P56, DOI 10.1016/j.isprsjprs.2020.08.004
   Mattyus G, 2017, IEEE I CONF COMP VIS, V0, PP3458, DOI 10.1109/ICCV.2017.372
   Menon AK, 2018, MACH LEARN, V107, P1561, DOI 10.1007/s10994-018-5715-3
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Qiu J, 2016, PHOTOGRAMM ENG REM S, V82, P593, DOI 10.14358/PERS.82.8.593
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rowland M., 2018, P MACHINE LEARNING R, V84, P29
   Sun T, 2019, PROC CVPR IEEE, V0, PP7501, DOI 10.1109/CVPR.2019.00769
   Tao C, 2019, ISPRS J PHOTOGRAMM, V158, P155, DOI 10.1016/j.isprsjprs.2019.10.001
   Tu B, 2019, IEEE T GEOSCI REMOTE, V57, P5085, DOI 10.1109/TGRS.2019.2896471
   Upadhyay D, 2021, IEEE T NETW SCI ENG, V8, P2559, DOI 10.1109/TNSE.2021.3099371
   Volodymyr Mnih, 2013, INT C MACH LEARN, V0, P0
   Wang EP, 2019, FOOD POLICY, V89, P0, DOI 10.1016/j.foodpol.2019.101791
   Wang WX, 2016, J TRAFFIC TRANSP ENG, V3, P271, DOI 10.1016/j.jtte.2016.05.005
   Wiedemann C., 1998, EMPIRICAL EVALUATION, V12, P172
   Yuan JY, 2018, IEEE T PATTERN ANAL, V40, P2793, DOI 10.1109/TPAMI.2017.2750680
   Zang Y, 2016, IEEE T GEOSCI REMOTE, V54, P3322, DOI 10.1109/TGRS.2016.2514602
   Zhang J, 2021, IEEE T KNOWL DATA EN, V33, P2083, DOI 10.1109/TKDE.2019.2951668
   Zhang JF, 2020, J CLEAN PROD, V271, P0, DOI 10.1016/j.jclepro.2020.122429
   Zhang J, 2021, IEEE T GEOSCI REMOTE, V59, P1836, DOI 10.1109/TGRS.2020.3003425
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou MT, 2020, ISPRS J PHOTOGRAMM, V168, P288, DOI 10.1016/j.isprsjprs.2020.08.019
   Zhu QQ, 2021, ISPRS J PHOTOGRAMM, V175, P353, DOI 10.1016/j.isprsjprs.2021.03.016
NR 45
TC 5
Z9 5
U1 7
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 15
PY 2021
VL 104
IS 
BP 
EP 
DI 10.1016/j.jag.2021.102544
PG 14
WC Remote Sensing
SC Remote Sensing
GA WD0OU
UT WOS:000704648000004
DA 2023-04-26
ER

PT J
AU Fasipe, OA
   Izinyon, OC
AF Fasipe, O. A.
   Izinyon, O. C.
TI Feasibility assessment of SHP potential using GIS-enhanced RS approach in poorly gauged river basin in Nigeria
SO RENEWABLE ENERGY FOCUS
LA English
DT Article
ID curve number; runoff; storage; energy; soil; tool
AB In this paper, we present the result obtained by application of Remote Sensing (RS) data & Geographic Information System (GIS) procedure in the identification and selection of feasible sites for small hydropower (SHP) projects in Oyanmi River in the Benin-Owena drainage Basin in Nigeria, using Natural Resource Conservation Service-Curve Number (NRCS-CN) model. Catchment delineation, Sub-basin Area size, slope, Curve Number (CN), Land Use Land Cover (LULC), Digital Elevation Model (DEM), rainfall intensity, etc. were obtained by RS and Arc GIS tools. Data on rainfall were obtained from Precipitation Estimation from Remotely Sensed Information using Artificial Neural Networks-Climate Data Record (PERSIANN-CDR) for the year 2018 and validated using Nigerian Meteorological Services Agency (NIMET) Lokoja synoptic station data and then utilized for the computation of simulated discharge. The simulated discharge were correlated with observed data obtained from a gauging station in the study area. The correlation between observed and simulated data yielded a good correlation result of 65% and 63% for rainfall and discharge respectively with good statistical significance P-value. Elevation values extracted from the DEM were used in calculating the available head utilized in evaluating the hydropower potentials across the 58 hydrometric mapped-out points. Based on the criteria that a viable SHP should have a minimum slope of 2% and 10 m available head, 11 points were identified in Oyanmi sub-basin with feasible power potential ranging from 393.849 kW to 16038.194 kW at 92% annual flow exceedance which if developed would improve access to energy and socio-economic development of the study area.
C1 [Fasipe, O. A.] Energy Commiss Nigeria, Plot 701C,PMB 358, Abuja 900211, Nigeria.
   [Izinyon, O. C.] Univ Benin, Fac Engn, Dept Civil Engn, PMB 1154,Ugbowo Campus, Benin 300283, Edo State, Nigeria.
C3 University of Benin
RP Fasipe, OA (corresponding author), Energy Commiss Nigeria, Plot 701C,PMB 358, Abuja 900211, Nigeria.
EM fasipeo@gmail.com; izinyon@uniben.edu
CR Abdallah L, 2013, J ENG-NY, V2013, P0, DOI 10.1155/2013/845051
   Aggidis GA, 2010, RENEW ENERG, V35, P2632, DOI 10.1016/j.renene.2010.04.008
   [Anonymous], 2004, NAT ENG HDB 630, V0, P0
   Carroll G., 2004, ESRI US C SAN DIEG C, V0, P0
   Castellarin A, 2004, ADV WATER RESOUR, V27, P953, DOI 10.1016/j.advwatres.2004.08.005
   Cheng SJ, 2011, NAT HAZARDS, V56, P853, DOI 10.1007/s11069-010-9596-4
   Costache R, 2014, CENT EUR J GEOSCI, V6, P363, DOI 10.2478/s13533-012-0181-0
   Das S., 2006, J SPAT HYDROL, V6, P18
   Devian S., 2010, PRACTICALLY CHEATING, V2nd, P0
   Dudhani S, 2006, ENERG POLICY, V34, P3195, DOI 10.1016/j.enpol.2005.06.011
   ECN, 2014, EN IMPL VIS 20 2020, V0, P0
   ECN, 2005, REN EN MAST PLAN, V0, P0
   ECREEE, 2012, ECREE WORKSH ECOWAS, V0, P0
   FAO, 2008, MIN C 15 17 DEC 2008, V0, P0
   Fasipe O.A., 2017, INT J HYDROPOWER DAM, V24, P0
   Gassman PW, 2007, SOIL WATER ASSESSMEN, V0, P0
   Hoes OAC, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0171844
   IMF, 2018, IMF WORLD EC OUTLOOK, V0, P0
   Karamouz M., 1991, WATER RESOURCES SYST, V0, P0
   Kusre BC, 2010, APPL ENERG, V87, P298, DOI 10.1016/j.apenergy.2009.07.019
   Li MH, 2008, TRANSP RES RECORD, V0, PP133, DOI 10.3141/2060-15
   Magar RB, 2011, J EARTH SYST SCI, V120, P1067, DOI 10.1007/s12040-011-0127-9
   McLean E, 2014, ENRGY PROCED, V46, P152, DOI 10.1016/j.egypro.2014.01.168
   McMahon TA., 2005, WATER RESOURCES YIEL, V0, P0
   Michel C, 2005, WATER RESOUR RES, V41, P0, DOI 10.1029/2004WR003191
   Mishra SK, 2005, HYDROL PROCESS, V19, P2845, DOI 10.1002/hyp.5735
   Niel H, 2003, J HYDROL, V278, P213, DOI 10.1016/S0022-1694(03)00158-6
   Pandey A, 2015, HYDROLOG SCI J, V60, P1651, DOI 10.1080/02626667.2014.943669
   Pokharel S, 2000, INT J GEOGR INF SCI, V14, P855, DOI 10.1080/136588100750022822
   Ponce VM, 1996, J HYDROL ENG, V1, P11, DOI 10.1061/(ASCE)1084-0699(1996)1:1(11)
   Ramachandra TV, 2004, J APPL SCI, V4, P596, DOI 10.3923/JAS.2004.596.604
   Roussel M.C., 2005, 046962 TEX DEP TRANS, V0, P0
   Ryo M, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0133833
   Sahu S., 2015, THESIS, V0, P0
   Salimi ET, 2017, PADDY WATER ENVIRON, V15, P123, DOI 10.1007/s10333-016-0534-2
   Smakhtin VU, 2001, J HYDROL, V240, P147, DOI 10.1016/S0022-1694(00)00340-1
   Sobamowo Gbeminiyi M., 2018, JOURNAL OF ENERGY, V2018, P0, DOI 10.1155/2018/4860252
   STUEBE MM, 1990, WATER RESOUR BULL, V26, P611
   Sule B.F., 2011, ASSESSMENT HYDROELEC, V0, P0
   Taiwo A., 2012, WATER QUALITY MONITO, V0, PP302, DOI 10.5772/33720
   Taulo J.L., 2007, THESIS, V0, P0
   Travers JC, 2017, LEARN DISABIL RES PR, V32, P208, DOI 10.1111/ldrp.12147
   USDA, 1997, NRCS PONDS PLANN DES, V0, P0
   World Bank, 2018, AFRICAS PULSE, V17, P0
   World Bank, 2017, AFRICAS PULSE, V15, P0
   World Resources Institute, 2018, UNLOCKING INCLUSIVE, V0, P0
   Yi CS, 2010, RENEW ENERG, V35, P852, DOI 10.1016/j.renene.2009.08.003
   Zhan XY, 2004, ENVIRON MODELL SOFTW, V19, P875, DOI 10.1016/j.envsoft.2004.03.001
NR 48
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1755-0084
EI 1878-0229
J9 RENEW ENERG FOCUS
JI Renew. Energ. Focus
PD MAR 15
PY 2021
VL 36
IS 
BP 65
EP 78
DI 10.1016/j.ref.2020.12.005
EA JAN 2021
PG 14
WC Energy & Fuels
SC Energy & Fuels
GA QP2RF
UT WOS:000623685200007
DA 2023-04-26
ER

PT J
AU Pessiglione, M
   Daunizeau, J
AF Pessiglione, Mathias
   Daunizeau, Jean
TI Bridging Across Functional Models: The OFC as a Value-Making Neural Network
SO BEHAVIORAL NEUROSCIENCE
LA English
DT Article
DE orbitofrontal cortex; artificial neural network; subjective value; likeability rating; economic choice
ID orbitofrontal cortex; decision-making; valuation system; visual fixations; cognitive map; mechanisms; choice; representations; computations; metaanalysis
AB Many functions have been attributed to the orbitofrontal cortex (OFC)-some classical roles, such as signaling the value of action outcomes, being challenged by more recent ones, such as signaling the position of a trial within a task space. In this paper, we propose a unifying neural network architecture, whose function is to generate a value from a set of attributes attached to a particular object. Our model reverses the logic of perceptual choice models, by considering values as outputs of (and not inputs to) the neural network. In doing so, the model explains why univariate value signals have been observed in both likeability rating and economic choice tasks, while the features associated with a particular task trial can be decoded using multivariate analysis. Moreover, simulations show that a globally positive correlation with subjective value at the population level can coexist with a variety of correlation coefficients at the single-unit level, bridging typical observations made in human neuroimaging and monkey electrophysiology studies of OFC activity. To better explain binary choice, we equipped the neural network with recurrent feedback connections that enable simultaneous coding of values associated with currently attended and previously considered objects. Simulations of this augmented model show that virtual lesions produce systematically intransitive preferences, as observed in patients with damage to the OFC. Thus, our neural network model is sufficiently general and flexible to account for a core set of observations and make specific predictions about both OFC activity during value judgment and behavioral consequence of OFC damage.
C1 [Pessiglione, Mathias; Daunizeau, Jean] Sorbonne Univ, Motivat Brain & Behav MBB Lab, Paris Brain Inst ICM, INSERM,CNRS,Pitie Salpetriere Hosp, Paris, France.
C3 Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Pitie-Salpetriere - APHP; Centre National de la Recherche Scientifique (CNRS); Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; Sorbonne Universite
RP Pessiglione, M (corresponding author), Sorbonne Univ, Motivat Brain & Behav MBB Lab, Paris Brain Inst ICM, INSERM,CNRS,Pitie Salpetriere Hosp, Paris, France.
EM mathias.pessiglione@gmail.com
CR Abitbol R, 2015, J NEUROSCI, V35, P2308, DOI 10.1523/JNEUROSCI.1878-14.2015
   Aridan N, 2019, NEUROIMAGE, V185, P446, DOI 10.1016/j.neuroimage.2018.10.051
   Bao XJ, 2019, NEURON, V102, P1066, DOI 10.1016/j.neuron.2019.03.034
   Bartra O, 2013, NEUROIMAGE, V76, P412, DOI 10.1016/j.neuroimage.2013.02.063
   Bastin J, 2012, NEUROIMAGE, V63, P339, DOI 10.1016/j.neuroimage.2012.07.011
   Camille N, 2011, J NEUROSCI, V31, P7527, DOI 10.1523/JNEUROSCI.6527-10.2011
   Chib VS, 2009, J NEUROSCI, V29, P12315, DOI 10.1523/JNEUROSCI.2575-09.2009
   Cisek P, 2010, ANNU REV NEUROSCI, V33, P269, DOI 10.1146/annurev.neuro.051508.135409
   Clithero JA, 2014, SOC COGN AFFECT NEUR, V9, P1289, DOI 10.1093/scan/nst106
   Constantinescu AO, 2016, SCIENCE, V352, P1464, DOI 10.1126/science.aaf0941
   De Martino B, 2013, NAT NEUROSCI, V16, P105, DOI 10.1038/nn.3279
   Fleming SM, 2010, P NATL ACAD SCI USA, V107, P6005, DOI 10.1073/pnas.0910380107
   Fouragnan E, 2018, HUM BRAIN MAPP, V39, P2887, DOI 10.1002/hbm.24047
   Garrison J, 2013, NEUROSCI BIOBEHAV R, V37, P1297, DOI 10.1016/j.neubiorev.2013.03.023
   Gherman S, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.38293
   Grueschow M, 2015, NEURON, V85, P874, DOI 10.1016/j.neuron.2014.12.054
   Hare TA, 2009, SCIENCE, V324, P646, DOI 10.1126/science.1168450
   Harvey AH, 2010, J NEUROSCI, V30, P9597, DOI 10.1523/JNEUROSCI.1086-10.2010
   Hayden BY, 2011, NAT NEUROSCI, V14, P933, DOI 10.1038/nn.2856
   Hebscher M, 2016, CEREB CORTEX, V26, P4590, DOI 10.1093/cercor/bhv220
   Hunt LT, 2012, NAT NEUROSCI, V15, P470, DOI 10.1038/nn.3017
   Ito A, 2020, HUM BRAIN MAPP, V41, P3045, DOI 10.1002/hbm.24996
   Juechems K, 2019, TRENDS COGN SCI, V23, P836, DOI 10.1016/j.tics.2019.07.012
   Kim H, 2007, P NATL ACAD SCI USA, V104, P18253, DOI 10.1073/pnas.0703101104
   Kolling N, 2012, SCIENCE, V336, P95, DOI 10.1126/science.1216930
   Krajbich I, 2011, P NATL ACAD SCI USA, V108, P13852, DOI 10.1073/pnas.1101328108
   Krajbich I, 2010, NAT NEUROSCI, V13, P1292, DOI 10.1038/nn.2635
   Lebreton M, 2015, NAT NEUROSCI, V18, P1159, DOI 10.1038/nn.4064
   Lebreton M, 2013, PLOS BIOL, V11, P0, DOI 10.1371/journal.pbio.1001684
   Lebreton M, 2009, NEURON, V64, P431, DOI 10.1016/j.neuron.2009.09.040
   Lench HC, 2014, COGNITION, V133, P429, DOI 10.1016/j.cognition.2014.08.001
   Levy DJ, 2012, CURR OPIN NEUROBIOL, V22, P1027, DOI 10.1016/j.conb.2012.06.001
   Levy I, 2011, J NEUROSCI, V31, P118, DOI 10.1523/JNEUROSCI.3214-10.2011
   Lim SL, 2011, J NEUROSCI, V31, P13214, DOI 10.1523/JNEUROSCI.1246-11.2011
   Logothetis NK, 2001, NATURE, V412, P150, DOI 10.1038/35084005
   Lopez-Gamundi P., 2021, NEUROSCIENCE, V0, P0
   Lopez-Persem A, 2020, NAT NEUROSCI, V23, P664, DOI 10.1038/s41593-020-0615-9
   Lopez-Persem A, 2016, ELIFE, V5, P0, DOI 10.7554/eLife.20317
   Morrison SE, 2009, J NEUROSCI, V29, P11471, DOI 10.1523/JNEUROSCI.1815-09.2009
   ODoherty JP, 2014, NEUROSCI BIOBEHAV R, V43, P259, DOI 10.1016/j.neubiorev.2014.03.027
   Padoa-Schioppa C, 2006, NATURE, V441, P223, DOI 10.1038/nature04676
   Padoa-Schioppa C, 2017, NEURON, V96, P736, DOI 10.1016/j.neuron.2017.09.031
   Padoa-Schioppa C, 2011, ANNU REV NEUROSCI, V34, P333, DOI 10.1146/annurev-neuro-061010-113648
   Palminteri S, 2012, NEURON, V76, P998, DOI 10.1016/j.neuron.2012.10.017
   Palminteri S, 2009, J NEUROSCI, V29, P13465, DOI 10.1523/JNEUROSCI.1500-09.2009
   Papageorgiou GK, 2017, NAT COMMUN, V8, P0, DOI 10.1038/s41467-017-01833-5
   Pauli WM, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-08922-7
   Pelletier G, 2019, J NEUROSCI, V39, P4124, DOI 10.1523/JNEUROSCI.2969-18.2019
   Peters J, 2010, BEHAV BRAIN RES, V213, P135, DOI 10.1016/j.bbr.2010.04.031
   Piguet O, 2011, LANCET NEUROL, V10, P162, DOI 10.1016/S1474-4422(10)70299-4
   Plassmann H, 2008, P NATL ACAD SCI USA, V105, P1050, DOI 10.1073/pnas.0706929105
   Pleskac T.J., 2015, INT ENCY SOCIAL BEHA, V13, P895, DOI 10.1016/B978-0-08-097086-8.43031-X
   Polania R, 2019, NAT NEUROSCI, V22, P134, DOI 10.1038/s41593-018-0292-0
   Pouget A, 2013, NAT NEUROSCI, V16, P1170, DOI 10.1038/nn.3495
   Ratcliff R, 2016, TRENDS COGN SCI, V20, P260, DOI 10.1016/j.tics.2016.01.007
   Ray S, 2008, J NEUROSCI, V28, P11526, DOI 10.1523/JNEUROSCI.2848-08.2008
   Rich EL, 2014, J COGNITIVE NEUROSCI, V26, P1347, DOI 10.1162/jocn_a_00573
   Rustichini A, 2015, J NEUROPHYSIOL, V114, P1382, DOI 10.1152/jn.00184.2015
   Saez I, 2018, CURR BIOL, V28, P2889, DOI 10.1016/j.cub.2018.07.045
   Scheeringa R, 2011, NEURON, V69, P572, DOI 10.1016/j.neuron.2010.11.044
   Schneider B, 2017, NEUROPSYCHOLOGIA, V107, P84, DOI 10.1016/j.neuropsychologia.2017.09.035
   Schuck NW, 2016, NEURON, V91, P1402, DOI 10.1016/j.neuron.2016.08.019
   Strait CE, 2014, NEURON, V82, P1357, DOI 10.1016/j.neuron.2014.04.032
   Sutton R., 1998, INTRO REINFORCEMENT, V0, P0, DOI DOI 10.1109/TNN.1998.712192
   Suzuki S, 2017, NAT NEUROSCI, V20, P1780, DOI 10.1038/s41593-017-0008-x
   Tajima S, 2019, NAT NEUROSCI, V22, P1503, DOI 10.1038/s41593-019-0453-9
   Tappin BM, 2017, J EXP PSYCHOL GEN, V146, P1143, DOI 10.1037/xge0000298
   Tom SM, 2007, SCIENCE, V315, P515, DOI 10.1126/science.1134239
   Tremblay L, 1999, NATURE, V398, P704, DOI 10.1038/19525
   Tsetsos K, 2014, ELIFE, V3, P0, DOI 10.7554/eLife.03701
   Vaidya AR, 2018, CEREB CORTEX, V28, P3857, DOI 10.1093/cercor/bhx246
   Vinckier F, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-03774-z
   Wang XJ, 2002, NEURON, V36, P955, DOI 10.1016/S0896-6273(02)01092-9
   Wilson RC, 2014, NEURON, V81, P267, DOI 10.1016/j.neuron.2013.11.005
   Wong KF, 2006, J NEUROSCI, V26, P1314, DOI 10.1523/JNEUROSCI.3733-05.2006
   Wunderlich K, 2009, P NATL ACAD SCI USA, V106, P17199, DOI 10.1073/pnas.0901077106
NR 76
TC 6
Z9 6
U1 1
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0735-7044
EI 1939-0084
J9 BEHAV NEUROSCI
JI Behav. Neurosci.
PD APR 15
PY 2021
VL 135
IS 2
BP 277
EP 290
DI 10.1037/bne0000464
PG 14
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA SM0IN
UT WOS:000657296600019
PM 34060880
DA 2023-04-26
ER

PT J
AU Bergkvist, H
   Davidsson, P
   Exner, P
AF Bergkvist, Hannes
   Davidsson, Paul
   Exner, Peter
TI Positioning with Map Matching using Deep Neural Networks
SO PROCEEDINGS OF THE 17TH EAI INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS SYSTEMS: COMPUTING, NETWORKING AND SERVICES (MOBIQUITOUS 2020)
LA English
DT Proceedings Paper
DE Deep neural networks; Localization; Positioning; Map matching; Loss function; Adaptation
AB Deep neural networks for positioning can improve accuracy by adapting to inhomogeneous environments. However, they are still susceptible to noisy data, often resulting in invalid positions. A related task, map matching, can be used for reducing geographical invalid positions by aligning observations to a model of the real world. In this paper, we propose an approach for positioning, enhanced with map matching, within a single deep neural network model. We introduce a novel way of reducing the number of invalid position estimates by adding map information to the input of the model and using a map-based loss function. Evaluating on real-world Received Signal Strength Indicator data from an asset tracking application, we show that our approach gives both increased position accuracy and a decrease of one order of magnitude in the number of invalid positions.
C1 [Bergkvist, Hannes; Exner, Peter] Sony, R&D Ctr Europe, Lund, Sweden.
   [Davidsson, Paul] Malmo Univ, Malmo, Sweden.
C3 Malmo University
RP Bergkvist, H (corresponding author), Sony, R&D Ctr Europe, Lund, Sweden.
EM hannes.bergkvist@sony.com; paul.davidsson@mau.se; peter.exner@sony.com
CR [Anonymous], 2015, ARM CORT A53 MPCORE, V0, P1
   [Anonymous], 1996, TECHNOLOGY, V0, P0
   Cavallini, 2013, IEEE VEH TECHN C, V0, P1
   Collin, 2008, TKT2546, V0, P0
   Davidsson Paul, 2020, NEURIPS WORKSH INT I, V0, P0
   Espressif, 2019, ESPR SYST, V0, P1
   Felix G, 2016, INT CONF UBIQ FUTUR, V0, PP1006, DOI 10.1109/ICUFN.2016.7536949
   Nair V., 2010, P 27 INT C MACH LEAR, V0, P807
   Newson P., 2009, P 17 ACM SIGSPATIAL, V0, PP336, DOI 10.1145/1653771.1653818
   Nordic Semiconductors, 1900, P0, V0, P0
   OASIS, 2019, MQTT VERS 5 0, V0, P0
   Obradovic D, 2006, J VLSI SIG PROC SYST, V45, P111, DOI 10.1007/s11265-006-9775-4
   Paszke, 2019, ADV NEURAL INFORM PR, V0, P8024
   Pereira F.C., 2009, EUR TRANSP RES REV, V0, PP107, DOI 10.1007/S12544-009-0013-6
   Xiao L., 2018, LEARNING LOCALIZATIO, V0, P0
   Zanella A, 2016, IEEE COMMUN SURV TUT, V18, P2662, DOI 10.1109/COMST.2016.2553452
   Zhao K, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), V0, PP452, DOI 10.1145/3347146.3359090
NR 18
TC 0
Z9 0
U1 2
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 177
EP 183
DI 10.1145/3448891.3448946
PG 7
WC Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Telecommunications
SC Computer Science; Telecommunications
GA BS5EL
UT WOS:000728389400019
DA 2023-04-26
ER

PT J
AU Miniello, G
   La Salandra, M
AF Miniello, Giorgia
   La Salandra, Marco
TI A new method for geomorphological studies on aerial images and land-cover classification using Machine Learning techniques
SO IMAGE AND SIGNAL PROCESSING FOR REMOTE SENSING XXVII
LA English
DT Proceedings Paper
DE Photogrammetry; Free Open-Source Software; Computing Clusters; Unmanned Aerial Vehicles; ReCaS-Bari; High-Resolution Data; Machine Learning; Land Cover Classification; Deep Neural Networks
ID structure-from-motion
AB The processing of high-resolution aerial images is key to territorial mapping and change detection studies in hydro-geomorphological high-risk areas. A new method has been developed in the context of "CLOSE (Close to the Earth)" project, resulting in a workflow based on open source MicMac photogrammetric suite and on High-Performance Computing. The workflow allowed to process a sequence of more than 1000 drone images captured along a reach belonging to the Basento River in Basilicata (Italy) during one single run. The workflow optimisation aims to extract the orthophotomosaic, the point cloud and the Digital Surface Model (DSM) of selected areas. The high quality of the image details can be used for land-cover classification and extrapolating features useful to mitigate the hydro-geomorphological hazard, through machine learning models trained with satellite public data. Several Convolutional Neural Networks have been tested using progressively more complex layer sequences, data augmentation and callback techniques for training procedures. The results are given in terms of model accuracy and loss.
C1 [Miniello, Giorgia] Univ Bari Aldo Moro, Dept Phys, Bari, Italy.
   [Miniello, Giorgia] Ist Nazl Fis Nucl, Bari, Italy.
   [La Salandra, Marco] Univ Bari Aldo Moro, Dept Earth & Environm Sci, Bari, Italy.
C3 Universita degli Studi di Bari Aldo Moro; Istituto Nazionale di Fisica Nucleare (INFN); Universita degli Studi di Bari Aldo Moro
RP Miniello, G (corresponding author), Univ Bari Aldo Moro, Dept Phys, Bari, Italy.; Miniello, G (corresponding author), Ist Nazl Fis Nucl, Bari, Italy.
EM giorgia.miniello@ba.infn.it; marco.lasalandra@uniba.it
FU MIUR (Italian Ministry for Education, University and Research) [PONa3 00052, Avviso 254/Ric, PON04a2_A]
CR Erickson RA, 2018, PLOS COMPUT BIOL, V14, P0, DOI 10.1371/journal.pcbi.1006468
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Lowe D. G., 1999, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, V0, PP1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez-Rubi O., 2017, OPEN GEOSPATIAL DATA, V0, P0, DOI DOI 10.1186/s40965-017-0024-5
   McGlone J.C., 2004, MANUAL PHOTOGRAMMETR, V0, P0
   Simonyan K., 2015, ICLR, V0, P0
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Vandana S., 2020, INT J ENG TECH RES, V9, P0, DOI 10.17577/IJERTV9IS060881
   Wang X, 2019, ISPRS J PHOTOGRAMM, V147, P19, DOI 10.1016/j.isprsjprs.2018.11.009
   Westoby MJ, 2012, GEOMORPHOLOGY, V179, P300, DOI 10.1016/j.geomorph.2012.08.021
   Wolf P. R., 2000, ELEMENTS PHOTOGRAMME, V0, P0
NR 13
TC 0
Z9 0
U1 1
U2 4
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
J9 PROC SPIE
PD JUN 15
PY 2021
VL 11862
IS 
BP 
EP 
DI 10.1117/12.2593110
PG 8
WC Computer Science, Artificial Intelligence; Remote Sensing; Optics; Imaging Science & Photographic Technology
SC Computer Science; Remote Sensing; Optics; Imaging Science & Photographic Technology
GA BS7DU
UT WOS:000759218100006
DA 2023-04-26
ER

PT J
AU Feng, XX
   Li, PJ
   Cheng, T
AF Feng, Xiaoxue
   Li, Peijun
   Cheng, Tao
TI Detection of Urban Built-Up Area Change From Sentinel-2 Images Using Multiband Temporal Texture and One-Class Random Forest
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Spatial resolution; Correlation; Remote sensing; Feature extraction; Covariance matrices; Mathematical model; Earth; Built-up area change; improved one-class random forest (iOCRF); multiband temporal texture; multitemporal data; pseudo cross multivariate variogram (PCMV)
ID land-cover classification; neural-networks; expansion; variogram; support; model
AB Detection of urban land expansion is important for understanding the urbanization process and improving urban planning. Spatio-temporal contextual information derived from multitemporal high-resolution imagery is useful for highlighting urban land cover changes. This article proposes a new method for detecting urban built-up area change from multitemporal high spatial resolution imagery by combining spectral and spatio-temporal features. A multiband temporal texture measured using pseudo cross multivariate variogram (PCMV) is adopted to quantify the local spatio-temporal dependence between bitemporal multispectral images. The PCMV textures at multiple scales, bitemporal spectral features, and normalized difference vegetation indices are together input to an improved one-class random forest classifier for urban built-up area change mapping. The proposed method is evaluated in urban built-up area change detection using multitemporal Sentinel-2 images of Tianjin area acquired from 2015 to 2019. It is also compared with three feature combinations and an existing postclassification comparison method based on one-class support vector machine. Experimental results demonstrate that the proposed method outperformed the traditional ones, with increases of 2.15%-7.38%, 2.07%-5.45%, 1.93%-6.76%, and 5.98%-13.11% in overall accuracy. Moreover, the proposed method also achieves the best performance using the bitemporal Sentinel-2 images over the east of Beijing area. The proposed method is promising as a simple and reliable way to detect urban built-up area change with multitemporal Sentinel-2 imagery.
C1 [Feng, Xiaoxue; Li, Peijun] Peking Univ, Inst Remote Sensing & GIS, Sch Earth & Space Sci, Beijing 100871, Peoples R China.
   [Feng, Xiaoxue; Li, Peijun] Peking Univ, Beijing Key Lab Spatial Informat Integrat & Its A, Beijing 100871, Peoples R China.
   [Cheng, Tao] Nanjing Agr Univ, MARA Key Lab Crop Syst Anal & Decis Making, Jiangsu Key Lab Informat Agr, Natl Engn & Technol Ctr Informat Agr, Nanjing 210095, Peoples R China.
C3 Peking University; Peking University; Nanjing Agricultural University
RP Li, PJ (corresponding author), Peking Univ, Inst Remote Sensing & GIS, Sch Earth & Space Sci, Beijing 100871, Peoples R China.
EM fengxx@pku.edu.cn; pjli@pku.edu.cn; tcheng@njau.edu.cn
FU National Science Foundation of China [42071307]
CR Alghamdi A, 2019, LAND-BASEL, V8, P0, DOI 10.3390/land8120193
   Angel S, 2011, PROG PLANN, V75, P53, DOI 10.1016/j.progress.2011.04.001
   Berberoglu S, 2000, COMPUT GEOSCI-UK, V26, P385, DOI 10.1016/S0098-3004(99)00119-3
   BOURGAULT G, 1992, MATH GEOL, V24, P463, DOI 10.1007/BF00890530
   BOURGAULT G, 1991, MATH GEOL, V23, P899, DOI 10.1007/BF02066732
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brodu N, 2017, IEEE T GEOSCI REMOTE, V55, P4610, DOI 10.1109/TGRS.2017.2694881
   Cai YT, 2020, IEEE J-STARS, V13, P341, DOI 10.1109/JSTARS.2019.2962550
   Chai BH, 2019, LANDSCAPE URBAN PLAN, V190, P0, DOI 10.1016/j.landurbplan.2019.103595
   Chen YQ, 2001, IEEE IMAGE PROC, V0, PP34, DOI 10.1109/ICIP.2001.958946
   CLARK I., 1989, P C GEOST SENS UNC M, V0, P473
   Congalton R.G., 2019, ASSESSING ACCURACY R, V0, P0
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Deng JS, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101230
   Desir C, 2013, PATTERN RECOGN, V46, P3490, DOI 10.1016/j.patcog.2013.05.022
   Desir C, 2012, LECT NOTES COMPUT SC, V7626, P282, DOI 10.1007/978-3-642-34166-3_31
   Dhanaraj K, 2022, GEOJOURNAL, V87, P1133, DOI 10.1007/s10708-020-10302-4
   Feng X., 2019, IEEE INFOCOM 2019 IE, V0, PP1, DOI 10.1109/APPEEC45492.2019.8994702
   Ferro CJS, 2002, PHOTOGRAMM ENG REM S, V68, P51
   Fichera CR, 2012, EUR J REMOTE SENS, V45, P1, DOI 10.5721/EuJRS20124501
   Gueguen L, 2013, IEEE J-STARS, V6, P2410, DOI 10.1109/JSTARS.2013.2246547
   Guo QL, 2021, IEEE J-STARS, V14, P4417, DOI 10.1109/JSTARS.2021.3074538
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Jiang DG, 2017, IOP C SER EARTH ENV, V57, P0, DOI 10.1088/1755-1315/57/1/012056
   Jin HR, 2012, INT J REMOTE SENS, V33, P101, DOI 10.1080/01431161.2011.584077
   Koga Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010124
   Lefebvre A, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070606
   Li PJ, 2007, INT GEOSCI REMOTE SE, V0, PP1922, DOI 10.1109/IGARSS.2007.4423202
   Li PJ, 2010, PHOTOGRAMM ENG REM S, V76, P255, DOI 10.14358/PERS.76.3.255
   [李淑坤 LI Shu-kun], 2009, 国土资源遥感 REMOTE SENSING FOR LAND & RESOURCES, V0, P35
   Liu H, 2004, INT J REMOTE SENS, V25, P1037, DOI 10.1080/0143116031000150004
   Lu DS, 2011, ISPRS J PHOTOGRAMM, V66, P298, DOI 10.1016/j.isprsjprs.2010.10.010
   Luo H, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10070980
   Maimaiti B, 2017, J ARID LAND, V9, P458, DOI 10.1007/s40333-017-0099-y
   Mclachlan G., 1999, RESONANCE, V4, P20, DOI 10.1007/BF02834632
   Mellor A, 2015, ISPRS J PHOTOGRAMM, V105, P155, DOI 10.1016/j.isprsjprs.2015.03.014
   Mertes CM, 2015, REMOTE SENS ENVIRON, V158, P331, DOI 10.1016/j.rse.2014.09.023
   Morris A. E. J., 2013, HIST URBAN FORM BEFO, V0, P0
   Moya L, 2019, ISPRS J PHOTOGRAMM, V149, P14, DOI 10.1016/j.isprsjprs.2019.01.008
   MYERS DE, 1991, MATH GEOL, V23, P805, DOI 10.1007/BF02068776
   Onojeghuo AO, 2011, INT J REMOTE SENS, V32, P8121, DOI 10.1080/01431161.2010.532822
   Onyango A. O., 2018, WORLD ENV, V8, P47
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, V0, PP214, DOI 10.1109/IGARSS.2019.8900330
   Pesaresi M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8040299
   Pesaresi M, 2008, IEEE J-STARS, V1, P180, DOI 10.1109/JSTARS.2008.2002869
   Qian YG, 2015, LANDSCAPE ECOL, V30, P1165, DOI 10.1007/s10980-015-0195-3
   Qiu CP, 2019, ISPRS J PHOTOGRAMM, V154, P151, DOI 10.1016/j.isprsjprs.2019.05.004
   Richter R., 2012, EUR SPACE AGENCY ESA, V49, P1
   Safia A, 2015, ISPRS J PHOTOGRAMM, V105, P169, DOI 10.1016/j.isprsjprs.2015.04.003
   Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Seto KC, 2012, P NATL ACAD SCI USA, V109, P16083, DOI 10.1073/pnas.1211658109
   Shi Zhongkuil, 2018, ACTA SCIENTIARUM NATURALIUM UNIVERSITATIS PEKINENSIS, V54, P105, DOI 10.13209/j.0479-8023.2017.073
   [宋桔尔 Song Juer], 2012, 遥感学报 JOURNAL OF REMOTE SENSING, V16, P1233
   Yeh AGO, 2001, PHOTOGRAMM ENG REM S, V67, P83
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zhang ZX, 2018, CHINESE GEOGR SCI, V28, P727, DOI 10.1007/s11769-018-0988-9
   Zhou YX, 2021, IEEE J-STARS, V14, P3967, DOI 10.1109/JSTARS.2021.3064311
NR 58
TC 2
Z9 2
U1 10
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 6974
EP 6986
DI 10.1109/JSTARS.2021.3092064
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TQ5RV
UT WOS:000678338200006
DA 2023-04-26
ER

PT J
AU Lee, C
   Hogan, J
AF Lee, Christopher
   Hogan, James
TI Automated crater detection with human level performance
SO COMPUTERS & GEOSCIENCES
LA English
DT Article
DE Deep learning; Crater Detection Algorithms; Mars
ID martian impact craters; lunar; identification; classification; distributions; topography; mars
AB Crater cataloging is an important yet time-consuming part of geological mapping. We present an automated Crater Detection Algorithm (CDA) that is competitive with expert-human researchers and hundreds of times faster. The CDA uses multiple neural networks to process digital terrain model and thermal infra-red imagery to identify and locate craters across the surface of Mars. We use additional post-processing filters to refine and remove potential false crater detections, improving our precision and recall by 10% compared to Lee (2019). We now find 80% of known craters above 3km in diameter, and identify 7,000 potentially new craters (13% of the identified craters). The median differences between our catalog and other independent catalogs is 2%-4% in location and diameter, in-line with other inter-catalog comparisons. The CDA has been used to process global terrain maps and infra-red imagery for Mars, and the software and generated global catalog are available at https://doi.org/10.5683/SP2/CFUNII.
C1 [Lee, Christopher; Hogan, James] Univ Toronto, Dept Phys, 60 St George St, Toronto, ON M5S 1A7, Canada.
C3 University of Toronto
RP Lee, C (corresponding author), Univ Toronto, Dept Phys, 60 St George St, Toronto, ON M5S 1A7, Canada.
EM clee@atmosp.physics.utoronto.ca; james.hogan@mail.utoronto.ca
FU Undergraduate Student Research Award from the Natural Sciences and Engineering Research Council of Canada
CR Ali-Dib M., 2019, AUTOMATED CRATER SHA, V0, P0
   ARVIDSON RE, 1974, ICARUS, V22, P264, DOI 10.1016/0019-1035(74)90176-6
   Aye KM, 2019, ICARUS, V319, P558, DOI 10.1016/j.icarus.2018.08.018
   Barlow NG, 2003, J GEOPHYS RES-PLANET, V108, P0, DOI 10.1029/2002JE002036
   BARLOW NG, 1988, ICARUS, V75, P285, DOI 10.1016/0019-1035(88)90006-1
   Bickel VT, 2019, IEEE T GEOSCI REMOTE, V57, P3501, DOI 10.1109/TGRS.2018.2885280
   Bue BD, 2006, COMPUT GEOSCI-UK, V32, P604, DOI 10.1016/j.cageo.2005.09.004
   Chollet F, 2015, KERAS, V0, P0
   Cintala M.J., 1976, P LUNAR PLANET SCI C, V0, P3575
   Di KC, 2014, ADV SPACE RES, V54, P2419, DOI 10.1016/j.asr.2014.08.018
   Edwards CS, 2011, J GEOPHYS RES-PLANET, V116, P0, DOI 10.1029/2010JE003755
   Fergason R., 2018, US GEOL SURV, V0, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   He KM, 2017, IEEE I CONF COMP VIS, V0, PP2980, DOI 10.1109/TPAMI.2018.2844175
   Kinczyk MJ, 2020, ICARUS, V341, P0, DOI 10.1016/j.icarus.2020.113637
   Krogli SO, 2010, COMPUT GEOSCI-UK, V36, P477, DOI 10.1016/j.cageo.2009.07.010
   Lee C., 2018, AM GEOPH UN FALL M, V0, PP41D
   Lee C, 2019, PLANET SPACE SCI, V170, P16, DOI 10.1016/j.pss.2019.03.008
   Milletari F, 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Naegeli TJ, 2019, COMPUT GEOSCI-UK, V123, P1, DOI 10.1016/j.cageo.2018.10.011
   Palafox LF, 2017, COMPUT GEOSCI-UK, V101, P48, DOI 10.1016/j.cageo.2016.12.015
   Palucis MC, 2020, ICARUS, V341, P0, DOI 10.1016/j.icarus.2020.113623
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pedrosa MM, 2017, GEOMAT NAT HAZ RISK, V8, P1306, DOI 10.1080/19475705.2017.1327463
   PROJ Contributors, 2018, PROJ COORD TRANSF SO, V0, P0
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Robbins S.J., 2018, POTPOURRI RELATED CR, V0, P0, DOI DOI 10.1023/A
   Robbins SJ, 2018, METEORIT PLANET SCI, V53, P583, DOI 10.1111/maps.12956
   Robbins SJ, 2018, METEORIT PLANET SCI, V53, P891, DOI 10.1111/maps.12990
   Robbins SJ, 2014, ICARUS, V234, P109, DOI 10.1016/j.icarus.2014.02.022
   Robbins SJ, 2012, J GEOPHYS RES-PLANET, V117, P0, DOI 10.1029/2011JE003967
   Robbins SJ, 2012, J GEOPHYS RES-PLANET, V117, P0, DOI 10.1029/2011JE003966
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salamuniccar G, 2012, PLANET SPACE SCI, V60, P236, DOI 10.1016/j.pss.2011.09.003
   Salamuniccar G, 2011, PLANET SPACE SCI, V59, P111, DOI 10.1016/j.pss.2010.11.003
   Silburt A, 2019, ICARUS, V317, P27, DOI 10.1016/j.icarus.2018.06.022
   SODERBLOM LA, 1974, ICARUS, V22, P239, DOI 10.1016/0019-1035(74)90175-4
   Stepinski T. F., 2009, LUNAR AND PLANETARY, V0, P0, DOI DOI 10.2174/138920312803582960(Electronic)1389-2037(Linking)1875-5550
   Stepinski TF, 2009, ICARUS, V203, P77, DOI 10.1016/j.icarus.2009.04.026
   van der Walt S, 2014, PEERJ, V2, P0, DOI 10.7717/peerj.453
   Wang YC, 2020, ICARUS, V341, P0, DOI 10.1016/j.icarus.2020.113645
   Wronkiewicz M., 2018, AGU FALL M, V0, PP41D
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zuo W, 2016, COMPUT GEOSCI-UK, V97, P79, DOI 10.1016/j.cageo.2016.07.013
NR 44
TC 7
Z9 7
U1 3
U2 17
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0098-3004
EI 1873-7803
J9 COMPUT GEOSCI-UK
JI Comput. Geosci.
PD FEB 15
PY 2021
VL 147
IS 
BP 
EP 
DI 10.1016/j.cageo.2020.104645
PG 9
WC Computer Science, Interdisciplinary Applications; Geosciences, Multidisciplinary
SC Computer Science; Geology
GA PU7QM
UT WOS:000609495800005
DA 2023-04-26
ER

PT J
AU Niu, C
   Tan, K
   Jia, XP
   Wang, X
AF Niu, Chao
   Tan, Kun
   Jia, Xiuping
   Wang, Xue
TI Deep learning based regression for optically inactive inland water quality parameter estimation using airborne hyperspectral imagery*
SO ENVIRONMENTAL POLLUTION
LA English
DT Article
DE Optically inactive water quality parameters; Airborne hyperspectral imagery; Deep learning based regression
ID chlorophyll-a concentration; support vector machines; remote estimation; neural-networks; in-situ; model; river; classification; phytoplankton; algorithms
AB Airborne hyperspectral remote sensing has the characteristics of high spatial and spectral resolutions, and provides an opportunity for accurate and efficient inland water qauality monitoring. Many studies have focused on evaluating and quantifying the concentrations of the optically active water quality parameters, for parameters such as chlorophyll-a (Chla), cyanobacteria, and colored dissolved organic matter (CDOM). For the optically inactive parameters, such as the permanganate index (CODMn), total nitrogen (TN), total phosphorus (TP), ammoniacal nitrogen (NH3-N), and heavy metals, it is difficult to estimate the concentrations directly, and the traditional indirect estimation models cannot meet the accuracy requirements, especially in heavily polluted inland waters. In this study, 60 water samples were collected at a depth of 50 cm from the Guanhe River in China, at the same time as the airborne data acquisition. We also developed and investigated two deep learning based regression models-a pixel-based deep neural network regression (pixel_DNNR) model and a patch-based deep neural network regression (patch_DNNR) model-to estimate seven optically inactive water quality parameters. Compared with the partial least squares regression (PLSR) and support vector regression (SVR) models, the deep learning based regression models can obtain a superior accuracy, especially the patch_DNNR model, which obtained a superior prediction accuracy for all parameters, with the prediction dataset coefficient of determination (Rp2) and the residual prediction deviation (RPD) values being greater than 0.6 and 1.6, respectively. In addition, thematic maps of the water quality classification results and water parameter concentrations were generated and the overall water quality and pollution sources were analyzed in the study area. The experimental results demonstrate that the deep learning based regression models show a good performance in the feature extraction and image understanding of high-dimensional data, and they provide us with a new approach for optically inactive inland water quality parameter estimation.
C1 [Niu, Chao; Tan, Kun; Wang, Xue] East China Normal Univ, Key Lab Geog Informat Sci, Minist Educ, Shanghai 200241, Peoples R China.
   [Tan, Kun] China Univ Min & Technol, NASG Key Lab Land Environm & Disaster Monitoring, Xuzhou 221116, Jiangsu, Peoples R China.
   [Jia, Xiuping] Univ New South Wales, Sch Engn & Informat Technol, Canberra, ACT 2600, Australia.
C3 East China Normal University; China University of Mining & Technology; University of New South Wales Sydney
RP Tan, K (corresponding author), East China Normal Univ, Key Lab Geog Informat Sci, Minist Educ, Shanghai 200241, Peoples R China.
EM tankuncu@gmail.com
FU National Natural Science Foundation of China [41871337]
CR Allali K, 1997, J GEOPHYS RES-OCEANS, V102, P12413, DOI 10.1029/97JC00380
   [Anonymous], 2011, ACM T INTEL SYST TEC, V0, P0
   Brereton RG, 2010, ANALYST, V135, P230, DOI 10.1039/b918972f
   Brezonik P, 2005, LAKE RESERV MANAGE, V21, P373, DOI 10.1080/07438140509354442
   Brooks BW, 2016, ENVIRON TOXICOL CHEM, V35, P6, DOI 10.1002/etc.3220
   CARPENTER DJ, 1983, REMOTE SENS ENVIRON, V13, P345, DOI 10.1016/0034-4257(83)90035-4
   Chen CQ, 2010, INT GEOSCI REMOTE SE, V0, PP4216, DOI 10.1109/IGARSS.2010.5648845
   Chen J, 2017, IEEE T GEOSCI REMOTE, V55, P2201, DOI 10.1109/TGRS.2016.2638828
   Dekker A.G., 1993, THESIS FREE U AMSTER, V0, P0
   Dekker AG, 2001, SCI TOTAL ENVIRON, V268, P197, DOI 10.1016/S0048-9697(00)00679-3
   Dekker AG, 2002, INT J REMOTE SENS, V23, P15, DOI 10.1080/01431160010006917
   Di Noia A, 2015, ATMOS MEAS TECH, V8, P281, DOI 10.5194/amt-8-281-2015
   El Din ES, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.046008
   El Din ES, 2017, INT J REMOTE SENS, V38, P1023, DOI 10.1080/01431161.2016.1275056
   Gholizadeh MH, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16081298
   Gitelson AA, 1997, INT J REMOTE SENS, V18, P2691, DOI 10.1080/014311697217558
   Gitelson AA, 2008, REMOTE SENS ENVIRON, V112, P3582, DOI 10.1016/j.rse.2008.04.015
   Gong ZQ, 2019, IEEE T GEOSCI REMOTE, V57, P3599, DOI 10.1109/TGRS.2018.2886022
   GORDON HR, 1988, J GEOPHYS RES-ATMOS, V93, P10909, DOI 10.1029/JD093iD09p10909
   Han LH, 2005, INT J REMOTE SENS, V26, P5235, DOI 10.1080/01431160500219133
   Han Z.-X, 2018, ACAD J SCI RES, V3, P0
   Harma P, 2001, SCI TOTAL ENVIRON, V268, P107, DOI 10.1016/S0048-9697(00)00688-4
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kallio K, 2001, SCI TOTAL ENVIRON, V268, P59, DOI 10.1016/S0048-9697(00)00685-9
   Kar D, 2008, INT J ENVIRON SCI TE, V5, P119, DOI 10.1007/BF03326004
   Keith DJ, 2014, INT J REMOTE SENS, V35, P2927, DOI 10.1080/01431161.2014.894663
   Koponen S, 2002, REMOTE SENS ENVIRON, V79, P51, DOI 10.1016/S0034-4257(01)00238-3
   Kutser T, 2004, LIMNOL OCEANOGR, V49, P2179, DOI 10.4319/lo.2004.49.6.2179
   Kutser T, 2005, REMOTE SENS ENVIRON, V94, P535, DOI 10.1016/j.rse.2004.11.009
   KUTSER T, 1995, INT J REMOTE SENS, V16, P3069, DOI 10.1080/01431169508954609
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P0, DOI 10.5555/303568.303704
   Lei SH, 2020, SCI TOTAL ENVIRON, V700, P0, DOI 10.1016/j.scitotenv.2019.134524
   Li J., 2014, P INTERSPEECH, V0, P1910
   Li J, 2015, ISPRS J PHOTOGRAMM, V106, P145, DOI 10.1016/j.isprsjprs.2015.05.009
   Li JW, 2017, ISPRS J PHOTOGRAMM, V128, P98, DOI 10.1016/j.isprsjprs.2017.03.015
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li YS, 2017, PATTERN RECOGN, V63, P371, DOI 10.1016/j.patcog.2016.10.019
   Okujeni A, 2013, REMOTE SENS ENVIRON, V137, P184, DOI 10.1016/j.rse.2013.06.007
   Olmanson LG, 2013, REMOTE SENS ENVIRON, V130, P254, DOI 10.1016/j.rse.2012.11.023
   Palmer SCJ, 2015, REMOTE SENS ENVIRON, V157, P1, DOI 10.1016/j.rse.2014.09.021
   PENUELAS J, 1995, PHOTOSYNTHETICA, V31, P221
   Peters J, 2017, ADAPT COMPUT MACH LE, V0, P0
   Pyo JC, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081180
   Pyo J, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111350
   Ritchie JC, 2003, PHOTOGRAMM ENG REM S, V69, P695, DOI 10.14358/PERS.69.6.695
   Schwarz A, 2015, INT CONF ACOUST SPEE, V0, PP4380, DOI 10.1109/ICASSP.2015.7178798
   Segal-Rozenhaimer M, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111446
   Simis SGH, 2005, LIMNOL OCEANOGR, V50, P237, DOI 10.4319/lo.2005.50.1.0237
   Singh KP, 2011, ANAL CHIM ACTA, V703, P152, DOI 10.1016/j.aca.2011.07.027
   Song KS, 2013, REMOTE SENS ENVIRON, V136, P342, DOI 10.1016/j.rse.2013.05.017
   Song KS, 2012, WATER AIR SOIL POLL, V223, P1481, DOI 10.1007/s11270-011-0959-6
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun DY, 2009, IEEE T GEOSCI REMOTE, V47, P2957, DOI 10.1109/TGRS.2009.2014688
   Tyler AN, 2006, INT J REMOTE SENS, V27, P1521, DOI 10.1080/01431160500419311
   Vakili T, 2020, J CLEAN PROD, V247, P0, DOI 10.1016/j.jclepro.2019.119134
   Wang JZ, 2020, ENVIRON POLLUT, V266, P0, DOI 10.1016/j.envpol.2020.115412
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P7232, DOI 10.1109/TGRS.2019.2912468
   Wang ZM, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030264
   Wass PD, 1997, SCI TOTAL ENVIRON, V194, P263, DOI 10.1016/S0048-9697(96)05370-3
   Williams, 1987, NEAR INFRARED TECHNO, V0, P0
   Xing QG, 2013, IEEE J-STARS, V6, P731, DOI 10.1109/JSTARS.2013.2238659
   Xu M, 2019, IEEE T GEOSCI REMOTE, V57, P4758, DOI 10.1109/TGRS.2019.2892899
   Yang J., 2020, ENVIRON POLLUT, V269, P0
   Yao Qian, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, V0, P3829, DOI 10.1109/ICASSP.2014.6854318
   Zhang C, 2015, INT J REMOTE SENS, V36, P1890, DOI 10.1080/01431161.2015.1029096
   Zheng J, 1982, OCEANOL LIMNOL SINIC, V13, P523
NR 67
TC 27
Z9 27
U1 27
U2 128
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0269-7491
EI 1873-6424
J9 ENVIRON POLLUT
JI Environ. Pollut.
PD OCT 1
PY 2021
VL 286
IS 
BP 
EP 
DI 10.1016/j.envpol.2021.117534
EA JUN 2021
PG 13
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA UC5VA
UT WOS:000686592000007
PM 34119861
DA 2023-04-26
ER

PT J
AU Moran-Sanchez, J
   Santisteban-Espejo, A
   Martin-Piedra, MA
   Perez-Requena, J
   Garcia-Rojo, M
AF Moran-Sanchez, Julia
   Santisteban-Espejo, Antonio
   Martin-Piedra, Miguel Angel
   Perez-Requena, Jose
   Garcia-Rojo, Marcial
TI Translational Applications of Artificial Intelligence and Machine Learning for Diagnostic Pathology in Lymphoid Neoplasms: A Comprehensive and Evolutive Analysis
SO BIOMOLECULES
LA English
DT Article
DE artificial intelligence; hematopathology; lymphoid neoplasms; digital image analysis; machine learning
ID co-word analysis; targeted therapy; neural-network; omics era; classification; prediction; efficiency; leukemia; history
AB Genomic analysis and digitalization of medical records have led to a big data scenario within hematopathology. Artificial intelligence and machine learning tools are increasingly used to integrate clinical, histopathological, and genomic data in lymphoid neoplasms. In this study, we identified global trends, cognitive, and social framework of this field from 1990 to 2020. Metadata were obtained from the Clarivate Analytics Web of Science database in January 2021. A total of 525 documents were assessed by document type, research areas, source titles, organizations, and countries. SciMAT and VOSviewer package were used to perform scientific mapping analysis. Geographical distribution showed the USA and People's Republic of China as the most productive countries, reporting up to 190 (36.19%) of all documents. A third-degree polynomic equation predicts that future global production in this area will be three-fold the current number, near 2031. Thematically, current research is focused on the integration of digital image analysis and genomic sequencing in Non-Hodgkin lymphomas, prediction of chemotherapy response and validation of new prognostic models. These findings can serve pathology departments to depict future clinical and research avenues, but also, public institutions and administrations to promote synergies and optimize funding allocation.
C1 [Moran-Sanchez, Julia] Puerta Mar Hosp, Div Hematol & Hemotherapy, Cadiz 11009, Spain.
   [Moran-Sanchez, Julia] Univ Cadiz, PhD Program Clin Med & Surg, Cadiz 11009, Spain.
   [Santisteban-Espejo, Antonio; Perez-Requena, Jose; Garcia-Rojo, Marcial] Puerta Mar Hosp, Pathol Dept, Cadiz 11009, Spain.
   [Santisteban-Espejo, Antonio; Garcia-Rojo, Marcial] Univ Cadiz, Inst Res & Innovat Biomed Sci Prov Cadiz INiBICA, Cadiz 11009, Spain.
   [Martin-Piedra, Miguel Angel] Univ Granada, Dept Histol, Tissue Engn Grp, Granada 18016, Spain.
C3 Universidad de Cadiz; Universidad de Cadiz; University of Granada
RP Santisteban-Espejo, A (corresponding author), Puerta Mar Hosp, Pathol Dept, Cadiz 11009, Spain.; Santisteban-Espejo, A (corresponding author), Univ Cadiz, Inst Res & Innovat Biomed Sci Prov Cadiz INiBICA, Cadiz 11009, Spain.
EM juliamorsan@gmail.com; antoniosantistebanespejo@gmail.com; mmartin@ugr.es; jose.perez.sspa@juntadeandalucia.es; marcial.garcia.sspa@juntadeandalucia.es
FU Andalusia Health System [RH-0145-2020]; EU FEDER ITI Grant for Cadiz Province [PI-0032-2017]
CR Abramo G, 2009, RES POLICY, V38, P206, DOI 10.1016/j.respol.2008.11.001
   Acs B, 2020, J INTERN MED, V288, P62, DOI 10.1111/joim.13030
   Aghamaleki FS, 2019, CUREUS, V11, P0, DOI 10.7759/cureus.4004
   Agius R, 2020, NAT COMMUN, V11, P0, DOI 10.1038/s41467-019-14225-8
   Ando T, 2003, CANCER SCI, V94, P906, DOI 10.1111/j.1349-7006.2003.tb01374.x
   [Anonymous], 1970, STRUCTURE SCI REVOLU, V0, P0
   Beam AL, 2018, JAMA-J AM MED ASSOC, V319, P1317, DOI 10.1001/jama.2017.18391
   Beaulac C, 2020, APPL ARTIF INTELL, V34, P1100, DOI 10.1080/08839514.2020.1815151
   Birkle C, 2020, QUANT SCI STUD, V1, P363, DOI 10.1162/qss_a_00018
   Blanc-Durand P, 2021, EUR J NUCL MED MOL I, V48, P1362, DOI 10.1007/s00259-020-05080-7
   Bobee V, 2020, BLOOD CANCER J, V10, P0, DOI 10.1038/s41408-020-0322-5
   Bucinski A, 2010, EUR J CANCER PREV, V19, P308, DOI 10.1097/CEJ.0b013e32833ad353
   CALLON M, 1983, SOC SCI INFORM, V22, P191, DOI 10.1177/053901883022002003
   CALLON M, 1991, SCIENTOMETRICS, V22, P155, DOI 10.1007/BF02019280
   Capobianco N, 2021, J NUCL MED, V62, P30, DOI 10.2967/jnumed.120.242412
   Chang HY, 2019, J PATHOL TRANSL MED, V53, P1
   Chen HM, 2018, DRUG DISCOV TODAY, V23, P1241, DOI 10.1016/j.drudis.2018.01.039
   Chinese State Council, 2017, NOT STAT COUNC ISS D, V0, P0
   Clark G., 2019, AI SECTOR DEAL, V0, P0
   Cobo MJ, 2012, J AM SOC INF SCI TEC, V63, P1609, DOI 10.1002/asi.22688
   Cobo MJ, 2011, J INFORMETR, V5, P146, DOI 10.1016/j.joi.2010.10.002
   Coulter N, 1998, J AM SOC INFORM SCI, V49, P1206, DOI 10.1002/(SICI)1097-4571(1998)49:13<1206::AID-ASI7>3.0.CO;2-F
   Davis N, 2018, BLOOD, V132, P0, DOI 10.1182/blood-2018-99-119639
   deAndres-Galiana EJ, 2015, CLIN TRANSL ONCOL, V17, P612, DOI 10.1007/s12094-015-1285-z
   Deeb SJ, 2015, MOL CELL PROTEOMICS, V14, P2947, DOI 10.1074/mcp.M115.050245
   Die Bundesregierung, 2018, ECKP BUND STRAT KUNS, V0, P0
   DiNardo CD, 2020, BLOOD, V135, P85, DOI 10.1182/blood.2019001239
   El Achi H, 2020, CANCERS, V12, P0, DOI 10.3390/cancers12040797
   European Commission, 2018, COORD PLAN ART INT, V0, P0
   Executive Office of the President of the United States, 2016, ARTIFICIAL INTELLIGE, V0, P0
   Executive Office of the President of the United States, 2016, PREP FUT ART INT, V0, P0
   Executive Office of the President of the United States, 2016, NAT ART INT RES DEV, V0, P0
   Flores M, 2013, PERS MED, V10, P565, DOI 10.2217/pme.13.57
   Gaidano V, 2020, CANCERS, V12, P0, DOI 10.3390/cancers12061684
   GOFFMAN W, 1970, NATURE, V226, P922, DOI 10.1038/226922a0
   Gonon-Demoulian R, 2014, B CANCER, V101, P56, DOI 10.1684/bdc.2013.1876
   Hall D. W., 2017, GROWING ARTIFICIAL I, V1st, P0
   KESSLER MM, 1963, AM DOC, V14, P10, DOI 10.1002/asi.5090140103
   Kiechle FL, 2004, ARCH PATHOL LAB MED, V128, P1337
   Lartizien C, 2014, IEEE J BIOMED HEALTH, V18, P946, DOI 10.1109/JBHI.2013.2283658
   Lee VH, 2018, INT J INNOV LEARN, V23, P145
   Ma HQ, 2015, BIOMED RES INT, V2015, P0, DOI 10.1155/2015/157570
   Mohlman J, 2018, AM J CLIN PATHOL, V150, PS119, DOI 10.1093/ajcp/aqy099.286
   Moral-Munoz JA, 2020, PROF INFORM, V29, P0, DOI 10.3145/epi.2020.ene.03
   Munoz-Leiva F, 2012, QUAL QUANT, V46, P1077, DOI 10.1007/s11135-011-9565-3
   Niazi MKK, 2019, LANCET ONCOL, V20, PE253, DOI 10.1016/S1470-2045(19)30154-8
   Orts F, 2019, J SUPERCOMPUT, V75, P1038, DOI 10.1007/s11227-018-2285-x
   Ostertagova E, 2012, PROCEDIA ENGINEER, V48, P500, DOI 10.1016/j.proeng.2012.09.545
   Parodi S, 2018, HEALTH INFORM J, V24, P54, DOI 10.1177/1460458216655188
   PRICE DJD, 1976, J AM SOC INFORM SCI, V27, P292, DOI 10.1002/asi.4630270505
   Radakovich N, 2020, CURR HEMATOL MALIG R, V15, P203, DOI 10.1007/s11899-020-00575-4
   Robertson S, 2018, TRANSL RES, V194, P19, DOI 10.1016/j.trsl.2017.10.010
   Roig-Tierno N, 2017, J INNOV KNOWL, V2, P15, DOI 10.1016/j.jik.2016.12.002
   Rosas SR, 2011, PLOS ONE, V6, P0, DOI 10.1371/journal.pone.0017428
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, P0, DOI 10.1002/widm.1249
   Santisteban-Espejo A, 2018, TISSUE ENG PT A, V24, P1504, DOI 10.1089/ten.tea.2018.0007
   Santisteban-Espejo A, 2019, TISSUE ENG PART C-ME, V25, P37, DOI 10.1089/ten.TEC.2018.0213
   Shouval R, 2021, BRIT J HAEMATOL, V192, P239, DOI 10.1111/bjh.16915
   Shouval R, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0150637
   Sibille L, 2020, RADIOLOGY, V294, P445, DOI 10.1148/radiol.2019191114
   Thomas X, 2019, ONCOL THER, V7, P33, DOI 10.1007/s40487-018-0091-5
   Turki T, 2017, IEEE ACCESS, V5, P7381, DOI 10.1109/ACCESS.2017.2696523
   Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5
   van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3
   van Karnebeek CDM, 2018, J INHERIT METAB DIS, V41, P571, DOI 10.1007/s10545-017-0128-1
   VILLANI C., 2018, MEANINGFUL ARTIFICIA, V0, P0
   Wang L, 2020, SIGNAL TRANSDUCT TAR, V5, P0, DOI 10.1038/s41392-020-0113-2
   Weisman AJ, 2020, EJNMMI PHYS, V7, P0, DOI 10.1186/s40658-020-00346-3
   Xu-Monette ZY, 2020, BLOOD ADV, V4, P28, DOI 10.1182/bloodadvances.2020001949
   Zhao M, 2020, CYTOM PART A, V97, P1073, DOI 10.1002/cyto.a.24159
   Zhao ST, 2016, CANCER MED-US, V5, P837, DOI 10.1002/cam4.650
NR 71
TC 1
Z9 1
U1 3
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2218-273X
J9 BIOMOLECULES
JI Biomolecules
PD JUN 15
PY 2021
VL 11
IS 6
BP 
EP 
DI 10.3390/biom11060793
PG 24
WC Biochemistry & Molecular Biology
SC Biochemistry & Molecular Biology
GA SY0HW
UT WOS:000665577100001
PM 34070632
DA 2023-04-26
ER

PT J
AU Luo, H
   He, BA
   Guo, RZ
   Wang, WX
   Kuai, X
   Xia, BL
   Wan, Y
   Ma, D
   Xie, LF
AF Luo, Heng
   He, Biao
   Guo, Renzhong
   Wang, Weixi
   Kuai, Xi
   Xia, Bilu
   Wan, Yuan
   Ma, Ding
   Xie, Linfu
TI Urban Building Extraction and Modeling Using GF-7 DLC and MUX Images
SO REMOTE SENSING
LA English
DT Article
DE building extraction; building modeling; Gaofen-7 image; deep learning; digital surface model
ID neural-networks; random forest; generation
AB Urban modeling and visualization are highly useful in the development of smart cities. Buildings are the most prominent features in the urban environment, and are necessary for urban decision support; thus, buildings should be modeled effectively and efficiently in three dimensions (3D). In this study, with the help of Gaofen-7 (GF-7) high-resolution stereo mapping satellite double-line camera (DLC) images and multispectral (MUX) images, the boundary of a building is segmented via a multilevel features fusion network (MFFN). A digital surface model (DSM) is generated to obtain the elevation of buildings. The building vector with height information is processed using a 3D modeling tool to create a white building model. The building model, DSM, and multispectral fused image are then imported into the Unreal Engine 4 (UE4) to complete the urban scene level, vividly rendered with environmental effects for urban visualization. The results of this study show that high accuracy of 95.29% is achieved in building extraction using our proposed method. Based on the extracted building vector and elevation information from the DSM, building 3D models can be efficiently created in Level of Details 1 (LOD1). Finally, the urban scene is produced for realistic 3D visualization. This study shows that high-resolution stereo mapping satellite images are useful in 3D modeling for urban buildings and can support the generation and visualization of urban scenes in a large area for different applications.
C1 [Luo, Heng; He, Biao; Guo, Renzhong; Wang, Weixi; Kuai, Xi; Ma, Ding; Xie, Linfu] Shenzhen Univ, Sch Architecture & Urban Planning, Res Inst Smart Cities, Shenzhen 518060, Peoples R China.
   [Luo, Heng; He, Biao; Guo, Renzhong; Wang, Weixi; Kuai, Xi; Wan, Yuan; Ma, Ding; Xie, Linfu] Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518034, Peoples R China.
   [Luo, Heng] Guangxi Zhuang Autonomous Reg Inst Nat Resources, Nanning 530023, Peoples R China.
   [Guo, Renzhong; Wang, Weixi; Kuai, Xi; Ma, Ding; Xie, Linfu] Guangdong Hong Kong Macau Joint Lab Smart Cities, Shenzhen 518060, Peoples R China.
   [Xia, Bilu] Guangxi Vocat & Tech Coll Commun, Traff Informat Engn Inst, Nanning 530023, Peoples R China.
   [Wan, Yuan] Hubei Normal Univ, Coll Urban & Environm Sci, Huangshi 435002, Hubei, Peoples R China.
C3 Shenzhen University; Ministry of Natural Resources of the People's Republic of China; Hubei Normal University
RP He, BA (corresponding author), Shenzhen Univ, Sch Architecture & Urban Planning, Res Inst Smart Cities, Shenzhen 518060, Peoples R China.; He, BA (corresponding author), Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518034, Peoples R China.
EM luoheng@szu.edu.cn; hebiao@szu.edu.cn; guorz@szu.edu.cn; wangwx@szu.edu.cn; kuaixi@szu.edu.cn; rachelpipi@126.com; wanyuan14@whu.edu.cn; dingma@szu.edu.cn; linfuxie@szu.edu.cn
FU National Natural Science Foundation of China [41971354, 42001331]; National Key Research and Development Program of China [2019YFB2103104]; Guangdong Science and Technology Strategic Innovation Fund (the Guangdong-Hong Kong-Macau Joint Laboratory Program) [2020B1212030009]; Open Fund of Key Laboratory of Urban Land Resource Monitoring and Simulation, Ministry of Land and Resource [KF-2018-03-031]; Ministry of Natural Resources of the People's Republic of China (MNR) [42-Y30B04-9001-19/21]; Guangxi Innovative Development Grand Program [GuikeAA18118038]; High-Resolution Remote Sensing Surveying Application Demonstration System of the Land Satellite Remote Sensing Application Center (LASAC)
CR Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Batty M, 2018, ENVIRON PLAN B-URBAN, V45, P817, DOI 10.1177/2399808318796416
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Chen Liang- Chieh, 2018, STUDY INFLUENCE EXTE, V0, P0
   Dembski F, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/su12062307
   Dowman I., 2000, P 26 ANN C REM SENS, V0, P0
   Feng WQ, 2019, INT GEOSCI REMOTE SE, V0, PP52, DOI 10.1109/IGARSS.2019.8899163
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Fu G, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050498
   Grigillo D, 2012, INT J REMOTE SENS, V33, P5149, DOI 10.1080/01431161.2012.659356
   Haala N., 2008, P 21 ISPRS C BEIJ CH, V0, P0
   Haala N, 2010, ISPRS J PHOTOGRAMM, V65, P570, DOI 10.1016/j.isprsjprs.2010.09.006
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Huang J, 2019, NANOCELLULOSE, V0, P0, DOI DOI 10.1002/9783527807437.CH11
   Huang ZM, 2016, INT GEOSCI REMOTE SE, V0, PP1835, DOI 10.1109/IGARSS.2016.7729471
   Lee DS, 2003, PHOTOGRAMM ENG REM S, V69, P143, DOI 10.14358/PERS.69.2.143
   Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7
   Li L, 2014, REMOTE SENS-BASEL, V6, P4409, DOI 10.3390/rs6054409
   Liu PH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070830
   Liu T, 2018, GISCI REMOTE SENS, V55, P243, DOI 10.1080/15481603.2018.1426091
   Mnih V., 2013, ARXIV, V0, P0
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Shahrabi B., 2002, THESIS U STUTTGART S, V0, P0
   Shiramizu K, 2017, POLAR SCI, V14, P30, DOI 10.1016/j.polar.2017.10.002
   Sohn G., 2002, INT ARCH PHOTOGRAMM, V34, P336
   Sohn G, 2007, ISPRS J PHOTOGRAMM, V62, P43, DOI 10.1016/j.isprsjprs.2007.01.001
   Sun K, 2019, PROC CVPR IEEE, V0, PP5686, DOI 10.1109/CVPR.2019.00584
   [徐胜军 Xu Shengjun], 2020, 光学精密工程 OPTICS AND PRECISION ENGINEERING, V28, P1588
   [唐新明 Tang Xinming], 2021, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V50, P384
   [唐新明 Tang Xinming], 2012, 测绘学报 ACTA GEODETICA ET CARTOGRAPHICA SINICA, V41, P191
   Thomson C, 2015, REMOTE SENS-BASEL, V7, P11753, DOI 10.3390/rs70911753
   [王长杰 Wang Changjie], 2020, 航天返回与遥感 SPACECRAFT RECOVERY & REMOTE SENSING, V41, P29
   Xiong XH, 2013, AUTOMAT CONSTR, V31, P325, DOI 10.1016/j.autcon.2012.10.006
   Yang H, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111768
   [杨居奎 Yang Jukui], 2020, 航天器工程 SPACECRAFT ENGINEERING, V29, P61
   Yi YN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151774
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
NR 38
TC 7
Z9 7
U1 5
U2 39
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2021
VL 13
IS 17
BP 
EP 
DI 10.3390/rs13173414
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UO1SA
UT WOS:000694480600001
DA 2023-04-26
ER

PT J
AU Shu, Z
   Hu, XY
   Dai, HM
AF Shu, Zhen
   Hu, Xiangyun
   Dai, Hengming
TI Progress Guidance Representation for Robust Interactive Extraction of Buildings from Remotely Sensed Images
SO REMOTE SENSING
LA English
DT Article
DE building extraction; interactive segmentation network; deep learning; iterative training; remote sensing images
ID segmentation
AB Accurate building extraction from remotely sensed images is essential for topographic mapping, cadastral surveying and many other applications. Fully automatic segmentation methods still remain a great challenge due to the poor generalization ability and the inaccurate segmentation results. In this work, we are committed to robust click-based interactive building extraction in remote sensing imagery. We argue that stability is vital to an interactive segmentation system, and we observe that the distance of the newly added click to the boundaries of the previous segmentation mask contains progress guidance information of the interactive segmentation process. To promote the robustness of the interactive segmentation, we exploit this information with the previous segmentation mask, positive and negative clicks to form a progress guidance map, and feed it to a convolutional neural network (CNN) with the original RGB image, we name the network as PGR-Net. In addition, an adaptive zoom-in strategy and an iterative training scheme are proposed to further promote the stability of PGR-Net. Compared with the latest methods FCA and f-BRS, the proposed PGR-Net basically requires 1-2 fewer clicks to achieve the same segmentation results. Comprehensive experiments have demonstrated that the PGR-Net outperforms related state-of-the-art methods on five natural image datasets and three building datasets of remote sensing images.
C1 [Shu, Zhen; Hu, Xiangyun; Dai, Hengming] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Hu, Xiangyun] Wuhan Univ, Inst Artificial Intelligence Geomat, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University
RP Hu, XY (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.; Hu, XY (corresponding author), Wuhan Univ, Inst Artificial Intelligence Geomat, Wuhan 430079, Peoples R China.
EM zhenshu1994@whu.edu.cn; huxy@whu.edu.cn; hengmingdai@whu.edu.cn
CR Badrinarayanan V., 2015, ARXIV150507293, V0, P0
   Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Q, 2019, ISPRS J PHOTOGRAMM, V147, P42, DOI 10.1016/j.isprsjprs.2018.11.011
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Gulshan V, 2010, PROC CVPR IEEE, V0, PP3129, DOI 10.1109/CVPR.2010.5540073
   Hariharan B, 2011, IEEE I CONF COMP VIS, V0, PP991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ho Kei Cheng, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP8887, DOI 10.1109/CVPR42600.2020.00891
   Jang WD, 2019, PROC CVPR IEEE, V0, PP5292, DOI 10.1109/CVPR.2019.00544
   King DB, 2015, ACS SYM SER, V1214, P1
   Li ZW, 2018, PROC CVPR IEEE, V0, PP577, DOI 10.1109/CVPR.2018.00067
   Liew JH, 2017, IEEE I CONF COMP VIS, V0, PP2746, DOI 10.1109/ICCV.2017.297
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin Z, 2020, P IEEE CVF C COMP VI, V0, P13339
   Mahadevan S., 2018, BRIT MACHINE VISION, V0, P212
   Majumder S, 2019, PROC CVPR IEEE, V0, PP11594, DOI 10.1109/CVPR.2019.01187
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Mortensen E. N., 1995, COMPUTER GRAPHICS PROCEEDINGS. SIGGRAPH 95, V0, PP191, DOI 10.1145/218380.218442
   Perazzi F, 2016, PROC CVPR IEEE, V0, PP724, DOI 10.1109/CVPR.2016.85
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sofiiuk K, 2020, P IEEE CVF C COMP VI, V0, P8623
   Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34
   Xu N, 2016, PROC CVPR IEEE, V0, PP373, DOI 10.1109/CVPR.2016.47
   Yu HK, 2017, IEEE IMAGE PROC, V0, P3335
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
NR 32
TC 1
Z9 1
U1 1
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 15
PY 2021
VL 13
IS 24
BP 
EP 
DI 10.3390/rs13245111
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA XY9RF
UT WOS:000737301100001
DA 2023-04-26
ER

PT J
AU Liu, ZY
   Chen, ZY
   Luo, L
   Hua, M
   Li, WQ
   Xia, B
AF Liu, Zhenyu
   Chen, Zhiyong
   Luo, Ling
   Hua, Min
   Li, Wenqing
   Xia, Bin
TI Age of Information-based Scheduling for Wireless Device-to-Device Communications using Deep Learning
SO 2021 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC)
LA English
DT Proceedings Paper
ID networks; throughput
AB Device-to-device (D2D) links scheduling for avoiding excessive interference is critical to the success of wireless D2D communications. Most of the traditional scheduling schemes only consider the maximum throughput or fairness of the system and do not consider the freshness of information. In this paper, we propose a novel D2D links scheduling scheme to minimize the average age of information (AoI) of wireless D2D communications. It is motivated by the fact that the more links are activated, the greater the interference with each other, which reduces the probability of successful transmission and in turn increases the AoI. We thus derive the accurate expression of the overall average AoI of the network based on the transmission success probability under the interfering channels. Moreover, a neural network structure is proposed to learn the mapping from the geographic location to the minimum AoI scheduling under a stationary randomized policy, where the scheduling decision can be made without estimating the channel state information. Finally, numerical results reveal that the performance of the deep learning approach is close to that of a local optimal algorithm which has a higher computational complexity.
C1 [Liu, Zhenyu; Chen, Zhiyong; Xia, Bin] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Luo, Ling; Hua, Min; Li, Wenqing] State Grid Shanghai Elect Power Res Inst, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Liu, ZY (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM liuzhy@sjtu.edu.cn; zhiyongchen@sjtu.edu.cn; bxia@sjtu.edu.cn
FU State Grid Shanghai Municipal Electric Power Company [52094019007K]; Ministry of Education of China (MOE) - China Mobile Communication Corporation (CMCC) Science Joint Foundation [MCM20180102]
CR [Anonymous], 2019, BT50014 ITU R, V0, P0
   Costa M, 2016, IEEE T INFORM THEORY, V62, P1897, DOI 10.1109/TIT.2016.2533395
   Cui W, 2019, IEEE J SEL AREA COMM, V37, P1248, DOI 10.1109/JSAC.2019.2904352
   Emara M, 2020, IEEE INTERNET THINGS, V7, P6762, DOI 10.1109/JIOT.2020.2981924
   Gu J, 2016, IEEE T WIREL COMMUN, V15, P769, DOI 10.1109/TWC.2015.2477998
   Kadota I, 2019, IEEE ACM T NETWORK, V27, P1359, DOI 10.1109/TNET.2019.2918736
   Kaul S, 2012, IEEE INFOCOM SER, V0, PP2731, DOI 10.1109/INFCOM.2012.6195689
   Lee MC, 2018, IEEE T WIREL COMMUN, V17, P7500, DOI 10.1109/TWC.2018.2867596
   Mankar P. D., 2020, SPATIAL DISTRIBUTION, V0, P0
   Shen KM, 2017, IEEE INT SYMP INFO, V0, PP2323, DOI 10.1109/ISIT.2017.8006944
   Sun YP, 2019, IEEE T COMMUN, V67, P7573, DOI 10.1109/TCOMM.2019.2920594
   Sun Y, 2017, IEEE T INFORM THEORY, V63, P7492, DOI 10.1109/TIT.2017.2735804
   Talak R, 2020, IEEE ACM T NETWORK, V28, P15, DOI 10.1109/TNET.2019.2946481
   Yang H. H., 2020, IEEE T MOBILE COMPUT, V0, P1
NR 14
TC 5
Z9 5
U1 0
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1525-3511
EI 
J9 IEEE WCNC
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/WCNC49053.2021.9417493
PG 6
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA BS2OB
UT WOS:000704226500247
DA 2023-04-26
ER

PT J
AU Wang, Z
   Guo, JX
   Huang, WZ
   Zhang, SW
AF Wang, Zhen
   Guo, Jianxin
   Huang, Wenzhun
   Zhang, Shanwen
TI High-resolution remote sensing image semantic segmentation based on a deep feature aggregation network
SO MEASUREMENT SCIENCE AND TECHNOLOGY
LA English
DT Article
DE high resolution remote sensing image; semantic segmentation; convolution neural networks (CNNs); deep feature aggregation network (DFANet); conditional random field (CRF)
ID hierarchical segmentation; texture
AB Semantic segmentation of high-resolution remote sensing images has a wide range of applications, such as territorial planning, geographic monitoring and smart cities. The proper operation of semantic segmentation for remote sensing images remains challenging due to the complex and diverse transitions between different ground areas. Although several convolution neural networks (CNNs) have been developed for remote sensing semantic segmentation, the performance of CNNs is far from the expected target. This study presents a deep feature aggregation network (DFANet) for remote sensing image semantic segmentation. It is composed of a basic feature representation layer, an intermediate feature aggregation layer, a deep feature aggregation layer and a feature aggregation module (FAM). Specially, the basic feature representation layer is used to obtain feature maps with different resolutions: the intermediate feature aggregation layer and deep feature aggregation layer can fuse various resolution features and multi-scale features; the FAM is used to splice the features and form more abundant spatial feature maps; and the conditional random field module is used to optimize semantic segmentation results. We have performed extensive experiments on the ISPRS two-dimensional Vaihingen and Potsdam remote sensing image datasets and compared the proposed method with several variations of semantic segmentation networks. The experimental results show that DFANet outperforms the other state-of-the-art approaches.
C1 [Wang, Zhen] Air Force Engn Univ, Coll Informat & Nav, Xian 710077, Peoples R China.
   [Wang, Zhen; Guo, Jianxin; Huang, Wenzhun; Zhang, Shanwen] Xijing Univ, Coll Informat Engn, Xian 710123, Peoples R China.
C3 Air Force Engineering University; Xijing University
RP Wang, Z (corresponding author), Air Force Engn Univ, Coll Informat & Nav, Xian 710077, Peoples R China.; Wang, Z (corresponding author), Xijing Univ, Coll Informat Engn, Xian 710123, Peoples R China.
EM wangzhen4013@163.com
CR Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   [Anonymous], 2001, 18 INT C MACHINE LEA, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Basaeed E, 2016, INT J REMOTE SENS, V37, P1671, DOI 10.1080/01431161.2016.1159745
   Chen GZ, 2018, IEEE J-STARS, V11, P1633, DOI 10.1109/JSTARS.2018.2810320
   Chen J, 2014, INT J REMOTE SENS, V35, P6914, DOI 10.1080/01431161.2014.960617
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YY, 2019, EARTH SCI INFORM, V12, P341, DOI 10.1007/s12145-019-00383-2
   Cheng J, 2013, EURASIP J WIREL COMM, V0, P0, DOI DOI 10.1186/1687-1499-2013-263
   Gerke M., 2014, USE STAIR VISION LIB, V0, P0, DOI DOI 10.13140/2.1.5015.9683
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2382, DOI 10.1109/TGRS.2013.2260552
   Hao X, 2016, INT J SEMANT COMPUT, V10, P417, DOI 10.1142/S1793351X16500045
   Jiao LC, 2010, IEEE COMPUT INTELL M, V5, P78, DOI 10.1109/MCI.2010.936307
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kumar S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS
   Li RR., 2019, IEEE J-STARS, V11, P126
   Li XH, 2015, ISPRS J PHOTOGRAMM, V109, P108, DOI 10.1016/j.isprsjprs.2015.09.009
   Liu ZW, 2015, IEEE I CONF COMP VIS, V0, PP1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   MARMANIS D, 2016, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/J.ISPRSJPRS.2017.11.009
   Mei T, 2017, IEEE GEOENCE REMOTE, V12, P938
   Miao ZM, 2018, IEEE GEOSCI REMOTE S, V15, P602, DOI 10.1109/LGRS.2018.2794545
   Mou L., 2018, ARXIV180502091, V0, P0
   Pan X, 2019, INT J REMOTE SENS, V40, P5892, DOI 10.1080/01431161.2019.1584687
   Pan X, 2017, INT J REMOTE SENS, V38, P6554, DOI 10.1080/01431161.2017.1362131
   Pan XR, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113774
   Quang NT., 2015, P 6 INT S INF COMM, V0, P282
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha I, 2012, IEEE GEOSCI REMOTE S, V9, P52, DOI 10.1109/LGRS.2011.2160150
   Serban A, 2020, ACM COMPUT SURV, V53, P0, DOI 10.1145/3398394
   Sherrah J., 2016, ARXIV160602585, V0, P0
   Speldekamp T., 2015, AUTOMATIC SEMANTIC L, V0, P0, DOI DOI 10.13140/RG.2.1.3345.0408
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   Sun X, 2021, IEEE T IND ELECTRON, V68, P3588, DOI 10.1109/TIE.2020.2977553
   Trias-Sanz R, 2008, ISPRS J PHOTOGRAMM, V63, P156, DOI 10.1016/j.isprsjprs.2007.08.005
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wan F., 2011, ADV RES COMPUTER ED, V176, P1021
   Wang C, 2014, OPTIK, V125, P5588, DOI 10.1016/j.ijleo.2014.07.002
   Wang Q, 2012, PHYSCS PROC, V33, P1286, DOI 10.1016/j.phpro.2012.05.212
   Wang YJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10050781
   Yansong L., 2017, P IEEE C COMP VIS PA, V0, P76
   Yin SL, 2018, IEEE ACCESS, V6, P26069, DOI 10.1109/ACCESS.2018.2834960
   Yuan JY, 2014, IEEE T GEOSCI REMOTE, V52, P16, DOI 10.1109/TGRS.2012.2234755
   Yue K, 2019, ISPRS J PHOTOGRAMM, V156, P1, DOI 10.1016/j.isprsjprs.2019.07.007
   Zhang H, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20020393
   Zhang R, 2018, ISPRS J PHOTOGRAMM, V143, P85, DOI 10.1016/j.isprsjprs.2018.04.022
   Zhang XL, 2014, PHOTOGRAMM ENG REM S, V80, P71, DOI 10.14358/PERS.80.1.71
   Zhang XL, 2013, ISPRS J PHOTOGRAMM, V78, P15, DOI 10.1016/j.isprsjprs.2013.01.002
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhao J, 2015, IEEE T GEOSCI REMOTE, V53, P2440, DOI 10.1109/TGRS.2014.2360100
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P4141, DOI 10.1109/TGRS.2017.2689018
   Zhou JX, 2015, IET IMAGE PROCESS, V9, P389, DOI 10.1049/iet-ipr.2014.0393
   Zhou L, 2020, PATTERN RECOGN LETT, V130, P54, DOI 10.1016/j.patrec.2018.08.030
NR 54
TC 5
Z9 5
U1 11
U2 73
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0957-0233
EI 1361-6501
J9 MEAS SCI TECHNOL
JI Meas. Sci. Technol.
PD SEP 15
PY 2021
VL 32
IS 9
BP 
EP 
DI 10.1088/1361-6501/abfbfd
PG 19
WC Engineering, Multidisciplinary; Instruments & Instrumentation
SC Engineering; Instruments & Instrumentation
GA SM3DD
UT WOS:000657489100001
DA 2023-04-26
ER

PT J
AU Kulkarni, K
   Vijaya, PA
AF Kulkarni, Keerti
   Vijaya, P. A.
TI Using Combination Technique for Land Cover Classification of Optical Multispectral Images
SO INTERNATIONAL JOURNAL OF APPLIED GEOSPATIAL RESEARCH
LA English
DT Article
DE Bangalore Urban District; Dempster-Shafer Combination Theory (DSCT); Land Cover Classification; Normalized Difference Vegetation Index (NDVI); Random Forest (RF) Algorithm; Support Vector Machine (SVM)
ID neural-network; gis techniques; pixel
AB The need for efficient planning of the land is exponentially increasing because of the unplanned human activities, especially in the urban areas. A land cover map gives a detailed report on temporal dynamics of a given geographical area. The land cover map can be obtained by using machine learning classifiers on the raw satellite images. In this work, the authors propose a combination method for the land cover classification. This method combines the outputs of two classifiers, namely, random forests (RF) and support vector machines (SVM), using Dempster-Shafer combination theory (DSCT), also called the theory of evidence. This combination is possible because of the inherent uncertainties associated with the output of each classifier. The experimental results indicate an improved accuracy (89.6%, kappa = 0.86 as versus accuracy of RF [87.31%, kappa = 0.83] and SVM [82.144%, kappa = 0.76]). The results are validated using the normalized difference vegetation index (NDVI), and the overall accuracy (OA) has been used as a comparison basis.
C1 [Kulkarni, Keerti; Vijaya, P. A.] BNM Inst Technol, Dept ECE, Bengaluru, India.
RP Kulkarni, K (corresponding author), BNM Inst Technol, Dept ECE, Bengaluru, India.
CR Adam E, 2010, WETL ECOL MANAG, V18, P281, DOI 10.1007/s11273-009-9169-z
   Akar O., 2012, CLASSIFICATION MULTI, V0, P0, DOI DOI 10.9733/ jgg.241212.1
   Benediktsson J.A., 2007, MULTIPLE CLASSIFIER, V0, P0
   ChepinogaV. VLiuH, 2018, EPA PUBL ACC, V0, P0, DOI DOI 10.3390/rs10040580
   Cui GQ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081238
   Deborah H, 2015, IEEE J-STARS, V8, P3224, DOI 10.1109/JSTARS.2015.2403257
   Den T, 2014, DEMPSTER SHAFER THEO, V0, P0
   Denoeux T, 2000, IEEE T SYST MAN CY A, V30, P131, DOI 10.1109/3468.833094
   Ferrato L.-J., 2013, J GEOGR GEOL, V5, P92, DOI 10.5539/JGG.V5N1P92
   Gandhi GM, 2015, PROCEDIA COMPUT SCI, V57, P1199, DOI 10.1016/j.procs.2015.07.415
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Hammond TO, 1996, INT J REMOTE SENS, V17, P1261, DOI 10.1080/01431169608949085
   Hegazy I. R., 2015, INT J SUSTAINABLE BU, V4, P117, DOI 10.1016/J.IJSBE.2015.02.005
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Kulkarni A. D, 2016, RANDOM FOREST ALGORI, V0, P0
   Kulkarni AV, 2007, CURR SCI INDIA, V92, P69
   Kulkarni K., 2019, PARAMETRIC METHODS M, V0, P0, DOI DOI 10.35940/ijitee.B1061.1292S19
   Kulkarni K, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), V0, PP36, DOI 10.1109/ICCMC.2017.8282720
   Kulkarni Keerti V.P, 1900, DOI 10.35940/IJITEE.F1018.0486S419, V0, P0
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Mercier G, 2003, INT GEOSCI REMOTE SE, V0, P288
   Millard K, 2015, REMOTE SENS-BASEL, V7, P8489, DOI 10.3390/rs70708489
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Qian YG, 2015, REMOTE SENS-BASEL, V7, P153, DOI 10.3390/rs70100153
   Rawat JS, 2015, EGYPT J REMOTE SENS, V18, P77, DOI 10.1016/j.ejrs.2015.02.002
   Rizvi IA, 2011, IEEE T GEOSCI REMOTE, V49, P4815, DOI 10.1109/TGRS.2011.2171695
   Rujoiu-Mare MR, 2016, PROCEDIA ENVIRON SCI, V32, P244, DOI 10.1016/j.proenv.2016.03.029
   Shi G, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10020426
   Shrawankar U, 2016, INT C RES INT COMP E, V0, P0
   Sinha S, 2015, EGYPT J REMOTE SENS, V18, P217, DOI 10.1016/j.ejrs.2015.09.005
   Smith C., 2017, DECISION TREES RANDO, V0, P0
   Song C, 2001, REMOTE SENS ENVIRON, V75, P230, DOI 10.1016/S0034-4257(00)00169-3
   Starovoitov V., 2008, DIGIT EARTH SUMMIT G, V0, P369
   Taufik A., 2016, J TELECOMMUNICATION, V8, P37
   Themistocleous K., 2008, IMPORTANCE CONSIDERI, V0, P0
   West A., 2012, RANDOM FORESTS BASED, V0, P0
   Xie ZL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020164
   Xinjiang R., 2016, RANDOM FOREST CLASSI, V0, P0, DOI DOI 10.3390/rs8110954
   Xu SP, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.014521
   Ye S, 2018, ISPRS J PHOTOGRAMM, V141, P137, DOI 10.1016/j.isprsjprs.2018.04.002
   Young NE, 2021, ECOLOGY, V0, P0, DOI DOI 10.1002/ecy.1730
   Zhang XY, 2003, REMOTE SENS ENVIRON, V84, P471, DOI 10.1016/S0034-4257(02)00135-9
   Zope PE, 2015, NAT HAZARDS, V75, P887, DOI 10.1007/s11069-014-1356-4
NR 44
TC 0
Z9 0
U1 0
U2 1
PU IGI GLOBAL
PI HERSHEY
PA 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA
SN 1947-9654
EI 1947-9662
J9 INT J APPL GEOSPAT R
JI Int. J. Appl. Geospat. Res.
PD OCT-DEC 15
PY 2021
VL 12
IS 4
BP 22
EP 39
DI 10.4018/IJAGR.2021100102
PG 18
WC Geography
SC Geography
GA XF7DW
UT WOS:000724229300002
DA 2023-04-26
ER

PT J
AU Roy, SK
   Mondal, R
   Paoletti, ME
   Haut, JM
   Plaza, A
AF Roy, Swalpa Kumar
   Mondal, Ranjan
   Paoletti, Mercedes E.
   Haut, Juan M.
   Plaza, Antonio
TI Morphological Convolutional Neural Networks for Hyperspectral Image Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Convolution; Data mining; Morphological operations; Kernel; Data models; Three-dimensional displays; Classification; convolutional neural networks (CNNs); deep learning (DL); hyperspectral images (HSIs); latent feature space transfer; morphological transformations
AB Convolutional neural networks (CNNs) have become quite popular for solving many different tasks in remote sensing data processing. The convolution is a linear operation, which extracts features from the input data. However, nonlinear operations are able to better characterize the internal relationships and hidden patterns within complex remote sensing data, such as hyperspectral images (HSIs). Morphological operations are powerful nonlinear transformations for feature extraction that preserve the essential characteristics of the image, such as borders, shape, and structural information. In this article, a new end-to-end morphological deep learning framework (called MorphConvHyperNet) is introduced. The proposed approach efficiently models nonlinear information during the training process of HSI classification. Specifically, our method includes spectral and spatial morphological blocks to extract relevant features from the HSI input data. These morphological blocks consist of two basic 2-D morphological operators (erosion and dilation) in the respective layers, followed by a weighted combination of the feature maps. Both layers can successfully encode the nonlinear information related to shape and size, playing an important role in classification performance. Our experimental results, obtained on five widely used HSIs, reveal that our newly proposed MorphConvHyperNet offers comparable (and even superior) performance when compared to traditional 2-D and 3-D CNNs for HSI classification.
C1 [Roy, Swalpa Kumar] Jalpaiguri Govt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri 735102, India.
   [Mondal, Ranjan] Indian Stat Inst, Elect & Commun Sci Unit, Kolkata 700108, India.
   [Haut, Juan M.] Univ Extremadura, Dept Technol Comp & Commun, Hyperspectral Comp Lab, Caceres 28015, Spain.
   [Paoletti, Mercedes E.; Plaza, Antonio] Natl Distance Educ Univ, Higher Sch Comp Engn, Dept Commun & Control Syst, Madrid 10003, Spain.
C3 Jalpaiguri Government Engineering College; Indian Statistical Institute; Indian Statistical Institute Kolkata; Universidad de Extremadura; Universidad Nacional de Educacion a Distancia (UNED)
RP Plaza, A (corresponding author), Natl Distance Educ Univ, Higher Sch Comp Engn, Dept Commun & Control Syst, Madrid 10003, Spain.
EM swalpa@cse.jgec.ac.in; ranjan15_r@isical.ac.in; mpaoletti@unex.es; jmhaut@scc.uned.es; aplaza@unex.es
FU Junta de Extremadura [GR18060]; Spanish Ministerio de Ciencia e Innovacion [PID2019-110315RB-I00]; European Unionas Horizon 2020 Research and Innovation Program [734541]
CR Akcay HG, 2008, IEEE T GEOSCI REMOTE, V46, P2097, DOI 10.1109/TGRS.2008.916644
   Alipour-Fard T, 2021, IEEE GEOSCI REMOTE S, V18, P1089, DOI 10.1109/LGRS.2020.2990971
   Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Bera S, 2020, INT J REMOTE SENS, V41, P2664, DOI 10.1080/01431161.2019.1694725
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Cho K., 2014, PROC 8 WORKSHOP SYNT, V0, PP103, DOI 10.3115/V1/W14-4012
   Dalla Mura M, 2011, IEEE GEOSCI REMOTE S, V8, P542, DOI 10.1109/LGRS.2010.2091253
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116
   Dos Santos J.A., 2019, ARXIV190601751, V0, P0
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Franchi G, 2020, PATTERN RECOGN, V102, P0, DOI 10.1016/j.patcog.2020.107246
   Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9
   Haut J. M., 2017, P 17 INT C COMPUTATI, V0, P1063
   Hu W, 2015, J SENSORS, V2015, P0, DOI 10.1155/2015/258619
   Huang X, 2009, INT J REMOTE SENS, V30, P3205, DOI 10.1080/01431160802559046
   King DB, 2015, ACS SYM SER, V1214, P1
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Makantasis K, 2015, INT GEOSCI REMOTE SE, V0, PP4959, DOI 10.1109/IGARSS.2015.7326945
   Manna S., 2021, IEEE T GEOSCI REMOTE, V59, P7831, DOI 10.1109/TGRS.2020.3043267
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mellouli D, 2019, IEEE T NEUR NET LEAR, V30, P2876, DOI 10.1109/TNNLS.2018.2890334
   Mondal R., 2019, ARXIV190100109, V0, P0
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Paoletti ME, 2020, J SUPERCOMPUT, V76, P8866, DOI 10.1007/s11227-020-03187-0
   Ramamurthy M, 2020, MICROPROCESS MICROSY, V79, P0, DOI 10.1016/j.micpro.2020.103280
   Roy Swalpa Kumar, 2022, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, V60, P0, DOI 10.1109/TGRS.2021.3052048
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Roy SK, 2018, DIGIT SIGNAL PROCESS, V82, P152, DOI 10.1016/j.dsp.2018.06.016
   Shen Y., 2019, ARXIV190901532, V1909, P01532
   Soille P., 2013, MORPHOLOGICAL IMAGE, V0, P0
   Spinoulas L, 2015, IEEE COMPUT SOC CONF, V0, P0
   Tobar MC, 2007, LECT NOTES COMPUT SC, V4478, P467
   VANDENBOOMGAARD R, 1994, IEEE T PATTERN ANAL, V16, P1101, DOI 10.1109/34.334389
   Wang JW, 2020, IEEE J-STARS, V13, P4133, DOI 10.1109/JSTARS.2020.3008949
   Xu X, 2016, INT GEOSCI REMOTE SE, V0, PP3575, DOI 10.1109/IGARSS.2016.7729926
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
NR 41
TC 24
Z9 23
U1 3
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 8689
EP 8702
DI 10.1109/JSTARS.2021.3088228
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UO4XN
UT WOS:000694698900015
DA 2023-04-26
ER

PT J
AU Papakonstantinou, A
   Batsaris, M
   Spondylidis, S
   Topouzelis, K
AF Papakonstantinou, Apostolos
   Batsaris, Marios
   Spondylidis, Spyros
   Topouzelis, Konstantinos
TI A Citizen Science Unmanned Aerial System Data Acquisition Protocol and Deep Learning Techniques for the Automatic Detection and Mapping of Marine Litter Concentrations in the Coastal Zone
SO DRONES
LA English
DT Article
DE unmanned aerial systems; marine litter; deep learning; convolutional neural networks; computer vision; marine litter detection
ID beach litter; satellite; pollution; plastics
AB Marine litter (ML) accumulation in the coastal zone has been recognized as a major problem in our time, as it can dramatically affect the environment, marine ecosystems, and coastal communities. Existing monitoring methods fail to respond to the spatiotemporal changes and dynamics of ML concentrations. Recent works showed that unmanned aerial systems (UAS), along with computer vision methods, provide a feasible alternative for ML monitoring. In this context, we proposed a citizen science UAS data acquisition and annotation protocol combined with deep learning techniques for the automatic detection and mapping of ML concentrations in the coastal zone. Five convolutional neural networks (CNNs) were trained to classify UAS image tiles into two classes: (a) litter and (b) no litter. Testing the CCNs' generalization ability to an unseen dataset, we found that the VVG19 CNN returned an overall accuracy of 77.6% and an f-score of 77.42%. ML density maps were created using the automated classification results. They were compared with those produced by a manual screening classification proving our approach's geographical transferability to new and unknown beaches. Although ML recognition is still a challenging task, this study provides evidence about the feasibility of using a citizen science UAS-based monitoring method in combination with deep learning techniques for the quantification of the ML load in the coastal zone using density maps.
C1 [Papakonstantinou, Apostolos; Spondylidis, Spyros; Topouzelis, Konstantinos] Univ Aegean, Dept Marine Sci, Mitilini 81100, Greece.
   [Batsaris, Marios] Univ Aegean, Geog Dept, Mitilini 81100, Greece.
C3 University of Aegean; University of Aegean
RP Papakonstantinou, A (corresponding author), Univ Aegean, Dept Marine Sci, Mitilini 81100, Greece.
EM apapak@aegean.gr; m.batsaris@aegean.gr; sspo@aegean.gr; topouzelis@marine.aegean.gr
FU European Union (European Social FundESF) through the Operational Programme "Human Resources Development, Education and Lifelong Learning" [MIS-5033021]
CR Abadi M., 2016, TENSORFLOW LARGE SCA, V0, P0
   Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Acosta J., 2012, SEAFLOOR GEOMORPHOLO, V0, Pxxxi xlv
   Andriolo U, 2020, SCI TOTAL ENVIRON, V736, P0, DOI 10.1016/j.scitotenv.2020.139632
   [Anonymous], 2017, G20 ANN G20 LEAD DEC, V0, P0
   Bao ZC, 2018, MAR POLLUT BULL, V137, P388, DOI 10.1016/j.marpolbul.2018.08.009
   Benassai G, 2017, NAT HAZARD EARTH SYS, V17, P1493, DOI 10.5194/nhess-17-1493-2017
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Cheshire A., 2009, IOC TECHNICAL SERIES, V83, P0
   Chircop A, 2018, OCEAN YEARB, V32, P752, DOI 10.1163/22116001-03201028
   Cicin-Sain B., 2015, UN CHRON, V51, P32, DOI 10.18356/8fcfd5a1-en
   Costanzo LG, 2020, J MAR SCI ENG, V8, P0, DOI 10.3390/jmse8090656
   Cox J, 2015, COMPUT SCI ENG, V17, P28, DOI 10.1109/MCSE.2015.65
   Deidun A, 2018, MAR POLLUT BULL, V131, P212, DOI 10.1016/j.marpolbul.2018.04.033
   Doukari M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161913
   Duarte D., 2020, ISPRS ANN PHOTOGRAMM, V3-2020, P439, DOI 10.5194/isprs-annals-v-3-2020-439-2020.-2020
   Fallati L, 2019, SCI TOTAL ENVIRON, V693, P0, DOI 10.1016/j.scitotenv.2019.133581
   Ferrari R, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8020113
   Fortson L, 2012, CH CRC DATA MIN KNOW, V0, P213
   Galgani F, 2013, ICES J MAR SCI, V70, P1055, DOI 10.1093/icesjms/fst122
   Galgani F., 2019, REP STUD GESAMP, V0, P130
   Galgani F, 2015, FRONT MAR SCI, V2, P0, DOI 10.3389/fmars.2015.00087
   Geraeds M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11172045
   Goncalves G, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162599
   Goncalves G, 2020, MAR POLLUT BULL, V155, P0, DOI 10.1016/j.marpolbul.2020.111158
   Goncalves G, 2020, SCI TOTAL ENVIRON, V706, P0, DOI 10.1016/j.scitotenv.2019.135742
   Haarr ML, 2019, MAR POLLUT BULL, V139, P117, DOI 10.1016/j.marpolbul.2018.12.025
   Haseler M, 2018, J COAST CONSERV, V22, P27, DOI 10.1007/s11852-017-0497-5
   He K., 2016, P IEEE C COMP VIS PA, V2016, P1512.03385, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Husson E, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030247
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kylili K, 2020, ENVIRON SCI POLLUT R, V27, P42631, DOI 10.1007/s11356-020-10105-7
   Kylili K, 2019, ENVIRON SCI POLLUT R, V26, P17091, DOI 10.1007/s11356-019-05148-4
   Lo HS, 2020, MAR POLLUT BULL, V151, P0, DOI 10.1016/j.marpolbul.2019.110823
   Lohr A, 2017, CURR OPIN ENV SUST, V28, P90, DOI 10.1016/j.cosust.2017.08.009
   Maes T, 2019, MAR POLLUT BULL, V146, P274, DOI 10.1016/j.marpolbul.2019.06.019
   Martin C, 2018, MAR POLLUT BULL, V131, P662, DOI 10.1016/j.marpolbul.2018.04.045
   Maximenko N, 2019, FRONT MAR SCI, V6, P0, DOI 10.3389/fmars.2019.00447
   Morseletto P, 2020, MAR POLICY, V117, P0, DOI 10.1016/j.marpol.2020.103956
   Munari C, 2016, WASTE MANAGE, V49, P483, DOI 10.1016/j.wasman.2015.12.010
   Mury A, 2020, DRONES-BASEL, V4, P0, DOI 10.3390/drones4020025
   Nazerdeylami A, 2021, OCEAN COAST MANAGE, V200, P0, DOI 10.1016/j.ocecoaman.2020.105478
   Painting SJ, 2020, OCEAN SCI, V16, P235, DOI 10.5194/os-16-235-2020
   Papachristopoulou I, 2020, MAR POLLUT BULL, V150, P0, DOI 10.1016/j.marpolbul.2019.110684
   Papakonstantinou A., 2017, P 5 INT C REM SENS G, V0, P0
   Papakonstantinou A., 2020, HABITAT MAPPING USIN, V12, P554, DOI 10.3390/rs12030554
   Papathanassiou A., 2019, IEEE 5G TECH FOCUS, V1, P1
   REES G, 1995, MAR POLLUT BULL, V30, P103, DOI 10.1016/0025-326X(94)00192-C
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Riihimaki H, 2019, REMOTE SENS ENVIRON, V224, P119, DOI 10.1016/j.rse.2019.01.030
   Rios N, 2018, MAR POLLUT BULL, V133, P304, DOI 10.1016/j.marpolbul.2018.05.038
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schulz M, 2017, MAR POLLUT BULL, V122, P166, DOI 10.1016/j.marpolbul.2017.06.045
   Schulz M, 2015, MAR ENVIRON RES, V109, P21, DOI 10.1016/j.marenvres.2015.04.007
   Simonyan K, 2015, ARXIV, V0, P0
   Simpson R, 2014, WWW14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP1049, DOI 10.1145/2567948.2579215
   Smail EA, 2019, J OPER OCEANOGR, V12, PS1, DOI 10.1080/1755876X.2019.1634959
   Taddia Y, 2020, DRONES-BASEL, V4, P0, DOI 10.3390/drones4020009
   Topouzelis K., 2016, C PAP, V0, P81100
   Topouzelis K, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12122013
   Topouzelis K, 2019, INT J APPL EARTH OBS, V79, P175, DOI 10.1016/j.jag.2019.03.011
   United Nations Environmental Programme (UNEP), 2014, PLAST DEBR OC UNEP Y, V0, P0
   Valavanidis A., 2012, SCI ADV ENV TOXICOLO, V0, P1
   Velegrakis A., 2016, P COMM INT EXPL SCI, V0, P0
   Vikas M, 2015, AQUAT PR, V4, P381, DOI 10.1016/j.aqpro.2015.02.051
   Vlachogianni T., 2016, JRC TECHNICAL REPORT, V0, P0
   Wenneker B., 2010, GUIDELINE MONITORING, V0, P0, DOI DOI 10.25607/OBP-968
   Xanthos D, 2017, MAR POLLUT BULL, V118, P17, DOI 10.1016/j.marpolbul.2017.02.048
NR 72
TC 30
Z9 30
U1 3
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2504-446X
J9 DRONES-BASEL
JI Drones-Basel
PD MAR 15
PY 2021
VL 5
IS 1
BP 
EP 
DI 10.3390/drones5010006
PG 20
WC Remote Sensing
SC Remote Sensing
GA RC9HK
UT WOS:000633102700001
DA 2023-04-26
ER

PT J
AU Liu, W
   Zhang, XD
   He, F
   Xiong, Q
   Zan, XL
   Liu, Z
   Sha, DX
   Yang, CW
   Li, SM
   Zhao, YY
AF Liu, Wei
   Zhang, Xiaodong
   He, Fei
   Xiong, Quan
   Zan, Xuli
   Liu, Zhe
   Sha, Dexuan
   Yang, Chaowei
   Li, Shaoming
   Zhao, Yuanyuan
TI Open-air grape classification and its application in parcel-level risk assessment of late frost in the eastern Helan Mountains
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Open-air grape parcel; Late frost; Google Earth Engine; Crop classification; Sentinel-2; OpenStreetMap; Eastern Helan Mountains
ID land-surface temperature; high-spatial-resolution; random forest; image classification; neural-network; crop classification; training samples; sentinel-2 data; seed maize; cover
AB The eastern Helan Mountains are one of the most important plantings and production bases for high-quality grapes in China. In winter, grape root is prone to freezing damage owing to natural phenomenon such as early and late frost, and methods to assess disaster risk at the grape parcel level is one of the current research hotspots. However, there are two problems at present; first is the lack of grape parcel maps and second is that scale of disaster risk assessment is limited to the level of administrative divisions and grid systems. Therefore, according to the perennial characteristics of the grapes and clear texture of the open-air grape parcels based on public data sets (Sentinel-2A/B) and high-quality winery address information, combined with Google Earth engine (GEE) platform, Google Earth, and Ovitalmap, this study designs a collection scheme of open-air grape parcel samples and non-grape parcel samples, analyzes the environmental characteristics of the distribution of high-quality wineries, constructs a classification feature database in three aspects (time, terrain, and vegetation), uses the random forest classification method to classify open-air grape parcels in the eastern Helan Mountains in 2019, and conducts a late frost disaster risk assessment of the open-air grape parcel. The results show that: (1) The high-quality wineries are mainly distributed in the elevation of 1106-1240 m, with the average slope of 0.82., the organic matter content of 10.79-14.27 g/kg, the P content of 24.87-37.58 mg/kg, the K content of 116-166 mg/kg, the pH 8.38-8.55, N content of 0.65-0.98 g/kg, annual average active accumulated temperature >= 10 degrees C of 3490-3590 degrees C, annual average rainfall of 189-201 mm, the annual average sunshine duration of 7.3-7.6 h, annual average air temperature of 8.8-9.4 degrees C, annual average temperature difference of 12.7-13.2 degrees C, annual average frost-free period at 263-270 d and annual average relative air Humidity of 50-54%. (2) The overall classification accuracy of open-air grape parcels reached 98.96% and the verification accuracy of ground truth parcel samples reached 87.89%. The open-air grape parcels in the eastern Helan Mountains are mainly distributed in Helan County, Xixia District, Yongning County, and Qingtongxia City. (3) The highest risk of late frost was found in Xixia District and the lowest risk in Yongning County. Helan County was higher than Qingtongxia City in the medium risk of late frost. The typical small area high risk includes Liangtian Town, the experimental field of Ningxia Academy of Agricultural and Forestry Sciences in Zhenbeibao Town, Yuhuang Winery in Ganchengzi Village, and the State-run Warm Spring Farm in Helan County. Thus, the sample collection and augmentation scheme are feasible, the open-air grape classification accuracy is high and its result is consistent with field investigation, which can provide accurate parcel-level disaster risk assessment and provide decision support for agricultural departments and farmers.Y
C1 [Liu, Wei; Zhang, Xiaodong; Xiong, Quan; Zan, Xuli; Liu, Zhe; Li, Shaoming; Zhao, Yuanyuan] China Agr Univ, Coll Land Sci & Technol, Beijing 100083, Peoples R China.
   [He, Fei] China Agr Univ, Coll Food Sci & Nutr Engn, Beijing 100083, Peoples R China.
   [Sha, Dexuan; Yang, Chaowei] George Mason Univ, NSF Spatiotemporal Innovat Ctr, Fairfax, VA 22030 USA.
C3 China Agricultural University; China Agricultural University; George Mason University
RP Zhang, XD (corresponding author), China Agr Univ, Coll Land Sci & Technol, Beijing 100083, Peoples R China.
EM zhangxd@cau.edu.cn
FU National Natural Science Foundation of China [41771104]
CR Arikan M., 2004, P ISPRS S IST INT AR, VVolume 34, P0
   Benali A, 2012, REMOTE SENS ENVIRON, V124, P108, DOI 10.1016/j.rse.2012.04.024
   Brinkhoff J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142245
   Coakley C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202397
   Cogato A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111896
   Cu Zhu-jun, 2008, YINGYONG SHENGTAI XUEBAO, V19, P1296
   Diaz BM, 2003, INT J REMOTE SENS, V24, P53, DOI 10.1080/01431160305012
   Duan X.F., 2014, J SHANXI AGR SCI, V42, P1148
   Duddu HSN, 2018, CAN J REMOTE SENS, V44, P169, DOI 10.1080/07038992.2018.1462660
   [樊晓春 Fan Xiaochun], 2013, 中国农学通报 CHINESE AGRICULTURAL SCIENCE BULLETIN, V29, P194
   Fayad I, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121976
   Feng ZY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223708
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Fritz S, 2009, REMOTE SENS-BASEL, V1, P345, DOI 10.3390/rs1030345
   Fu X, 2014, BEIJING AGR, V18, P66
   Huang C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071163
   Huang HB, 2020, ISPRS J PHOTOGRAMM, V161, P27, DOI 10.1016/j.isprsjprs.2020.01.010
   [李红英 Li Hongying], 2014, 自然灾害学报 JOURNAL OF NATURAL DISASTERS, V23, P167
   [李华 LI Hua], 2007, 科技导报 SCIENCE & TECHNOLOGY REVIEW, V25, P16
   Li X, 2012, SINO OVERSEAS GRAPEV, V0, PP39, DOI 10.13414/j.cnki.zwpp.2012.01.009
   Liu Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111780
   Maghsoudi Y, 2013, IEEE J-STARS, V6, P1531, DOI 10.1109/JSTARS.2013.2259219
   Malambo L, 2020, ISPRS J PHOTOGRAMM, V160, P107, DOI 10.1016/j.isprsjprs.2019.11.026
   Meier M, 2018, INT J BIOMETEOROL, V62, P991, DOI 10.1007/s00484-018-1501-y
   Molitor D, 2014, AUST J GRAPE WINE R, V20, P160, DOI 10.1111/ajgw.12059
   Mosedale JR, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0141218
   Murmu S, 2015, AQUAT PR, V4, P1203, DOI 10.1016/j.aqpro.2015.02.153
   Murphy ME, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030477
   Nevavuori P, 2019, COMPUT ELECTRON AGR, V163, P0, DOI 10.1016/j.compag.2019.104859
   Ning C., 2017, J NINGXIA U, V38, P186
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Pena JM, 2014, REMOTE SENS-BASEL, V6, P5019, DOI 10.3390/rs6065019
   Pena MA, 2017, ISPRS J PHOTOGRAMM, V128, P158, DOI 10.1016/j.isprsjprs.2017.03.019
   Pena-Barragan JM, 2011, REMOTE SENS ENVIRON, V115, P1301, DOI 10.1016/j.rse.2011.01.009
   Phalke AR, 2020, ISPRS J PHOTOGRAMM, V167, P104, DOI 10.1016/j.isprsjprs.2020.06.022
   Pinheiro ACT, 2004, IEEE T GEOSCI REMOTE, V42, P1941, DOI 10.1109/TGRS.2004.831886
   Qin G., 2019, AGR TECHNOL, V39, P159, DOI 10.19754/j.nyyjs.20191115068
   Qin W., 2019, JIANGSU AGR SCI, V33, P0
   Rahman MM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081313
   Ren TW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12132140
   Semeraro T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060907
   Song A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050799
   [宋晓倩 Song Xiaoqian], 2020, 江苏农业学报 JIANGSU JOURNAL OF AGRICULTURAL SCIENCES, V36, P689
   Song Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040449
   Sozzi MM, 2020, OENO ONE, V54, P189, DOI 10.20870/oeno-one.2020.54.2.2557
   Sun M., 2012, CHIN HORTICULT ABSTR, V28, P155, DOI 10.3969/j.issn.1672-0873.2012.09.077
   Sun YQ, 2017, GEOSCI FRONT, V8, P1051, DOI 10.1016/j.gsf.2016.10.008
   Tang K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020193
   Teluguntla P, 2018, ISPRS J PHOTOGRAMM, V144, P325, DOI 10.1016/j.isprsjprs.2018.07.017
   Thonfeld F, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071057
   Tian YL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091383
   Vivone G, 2020, INFORM FUSION, V61, P71, DOI 10.1016/j.inffus.2020.03.012
   WALD A, 1949, ANN MATH STAT, V20, P595, DOI 10.1214/aoms/1177729952
   Wang DZ, 2020, INT J APPL EARTH OBS, V85, P0, DOI 10.1016/j.jag.2019.101986
   Wang J., 2017, CHINESE J AGR RESOUR, V38, P122
   Wang KC, 2009, REMOTE SENS ENVIRON, V113, P1556, DOI 10.1016/j.rse.2009.03.009
   Wang S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182957
   [王素艳 Wang Suyan], 2017, 生态学报 ACTA ECOLOGICA SINICA, V37, P3776
   Wang X., 2017, JIANGXI AGR, V13, P15, DOI 10.19394/j.cnki.issn1674-4179.2017.13.013
   Weng QH, 2014, REMOTE SENS ENVIRON, V145, P55, DOI 10.1016/j.rse.2014.02.003
   Wulder MA, 2019, REMOTE SENS ENVIRON, V225, P127, DOI 10.1016/j.rse.2019.02.015
   Xu XJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040546
   Xue JR, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/1353691
   Yan YL, 2021, ISPRS J PHOTOGRAMM, V171, P278, DOI 10.1016/j.isprsjprs.2020.11.022
   Yang MD, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060583
   Yang N, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121500
   Yang W., 2018, GUANGDONG AGR SCI, V0, PP127, DOI 10.16768/j.issn.1004-874X.2018.05.021
   [杨洋 Yang Yang], 2019, 甘肃农业大学学报 JOURNAL OF GANSU AGRICULTURAL UNIVERSITY, V54, P149
   [杨洋 Yang Yang], 2017, 自然灾害学报 JOURNAL OF NATURAL DISASTERS, V26, P84
   Yuan H, 2009, REMOTE SENS-BASEL, V1, P243, DOI 10.3390/rs1030243
   Yuan JF, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060945
   Zhang DY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222647
   Zhang L., 2018, J SHANXI AGR SCI, V46, P260, DOI 10.3969/j.issn.1002-2481.2018.02.25
   Zhang L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030362
   Zhang L, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11185052
   Zhang ZM, 2013, INT J REMOTE SENS, V34, P7369, DOI 10.1080/01431161.2013.820368
   Zhao XiNi, 2019, JOURNAL OF HENAN AGRICULTURAL SCIENCES, V48, P153
   Zhou FQ, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111628
NR 79
TC 3
Z9 3
U1 9
U2 54
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2021
VL 174
IS 
BP 132
EP 150
DI 10.1016/j.isprsjprs.2021.02.004
EA FEB 2021
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO4AQ
UT WOS:000640987800010
DA 2023-04-26
ER

PT J
AU Suresh, V
   Zheng, Y
   Li, BW
AF Suresh, Vignesh
   Zheng, Yi
   Li, Beiwen
TI PMENet: phase map enhancement for Fourier transform profilometry using deep learning
SO MEASUREMENT SCIENCE AND TECHNOLOGY
LA English
DT Article
DE fringe projection; deep learning; Fourier transform; phase shifting profilometry; 3D shape measurement
ID 3d shape measurement; projection
AB Fringe projection profilometry (FPP) is a three-dimensional (3D) shape measurement method that involves projecting fringe patterns onto the object. A phase map retrieved from these fringe images is used for reconstructing the 3D surface of the object. Fourier transform and phase-shifting are two of the widely used fringe analysis techniques for performing 3D shape measurement using FPP. Fourier transform profilometry (FTP) has the advantage of performing high-speed measurement due to its single-shot nature. However, the reconstructed 3D surface has artifacts and high noise, specifically on the edges. On the other hand, phase-shifting profilometry (PSP) has the advantage of higher accuracy (relatively less noise level) but compromises on measurement speed. In this research, we propose a deep learning method to enhance the quality of the FTP phase maps using an efficient deep learning model called phase map enhancement net (PMENet). PMENet takes an FTP phase map as input and predicts a high-quality phase map in a supervised manner by using the phase maps obtained from 18-step PSP as ground truth. The training dataset was generated using a virtual FPP system. Validations were conducted on both the simulated data (generated by virtual FPP system) and the real-world data. The experimental results demonstrate that the trained neural network model can successfully improve the quality of the 3D geometric reconstruction with FTP and reduced the mean and root-mean-square error by 66% and 43%, respectively.
C1 [Suresh, Vignesh; Zheng, Yi; Li, Beiwen] Iowa State Univ, Dept Mech Engn, Ames, IA 50011 USA.
C3 Iowa State University
RP Li, BW (corresponding author), Iowa State Univ, Dept Mech Engn, Ames, IA 50011 USA.
EM beiwen@iastate.edu
FU Iowa State University (College of Engineering Faculty Startup fund)
CR [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Community Blender Online, 2018, BLENDER A 3D MODELLI, V0, P0
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Ding LJ, 2001, PATTERN RECOGN, V34, P721, DOI 10.1016/S0031-3203(00)00023-6
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   DORSCH RG, 1994, APPL OPTICS, V33, P1306, DOI 10.1364/AO.33.001306
   Feng SJ, 2019, ADV PHOTONICS, V1, P0, DOI 10.1117/1.AP.1.2.025001
   Gorthi SS, 2010, OPT LASER ENG, V48, P133, DOI 10.1016/j.optlaseng.2009.09.001
   Hyun JS, 2016, APPL OPTICS, V55, P4395, DOI 10.1364/AO.55.004395
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krizhevsky Alex, 2017, COMMUNICATIONS OF THE ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li BW, 2014, APPL OPTICS, V53, P3415, DOI 10.1364/AO.53.003415
   Lichti DD., 2002, TC, V2, P1
   Liu XJ, 2021, IEEE T IND INFORM, V17, P1882, DOI 10.1109/TII.2020.2991458
   Malacara D., 2007, OPTICAL SHOP TESTING, V0, P0
   MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029
   Mikolov T., 2011, 2011 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU), V0, PP196, DOI 10.1109/ASRU.2011.6163930
   Nguyen H., 2019, ARXIV190907766, V0, P0
   Pandey RK, 2018, LECT NOTES COMPUT SC, V11306, P566, DOI 10.1007/978-3-030-04224-0_49
   Pettersson B., 2009, US PATENT, V0, Patent No. [7,591,077, 7591077]
   Qi C.R., 2017, ADV NEUR IN, V0, P5099
   Qian JM, 2020, APL PHOTONICS, V5, P0, DOI 10.1063/5.0003217
   Qian JM, 2020, OPT LETT, V45, P1842, DOI 10.1364/OL.388994
   Sansoni G, 1999, APPL OPTICS, V38, P6565, DOI 10.1364/AO.38.006565
   Su XY, 2010, OPT LASER ENG, V48, P191, DOI 10.1016/j.optlaseng.2009.03.012
   TAKEDA M, 1983, APPL OPTICS, V22, P3977, DOI 10.1364/AO.22.003977
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Van der Jeught S, 2019, OPT EXPRESS, V27, P17091, DOI 10.1364/OE.27.017091
   Xie J., 2012, PROC INT C NEURAL IN, V1, P341
   Yan KT, 2020, OPT LASER ENG, V128, P0, DOI 10.1016/j.optlaseng.2019.105999
   Yan KT, 2019, OPT COMMUN, V437, P148, DOI 10.1016/j.optcom.2018.12.058
   Yang YQ, 2018, PROC CVPR IEEE, V0, PP206, DOI 10.1109/CVPR.2018.00029
   Yin W, 2020, J PHYS-PHOTONICS, V2, P0, DOI 10.1088/2515-7647/abbcd9
   Yu HT, 2020, OPT EXPRESS, V28, P21692, DOI 10.1364/OE.398492
   Yu LQ, 2018, PROC CVPR IEEE, V0, PP2790, DOI 10.1109/CVPR.2018.00295
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang S, 2018, OPT LASER ENG, V106, P119, DOI 10.1016/j.optlaseng.2018.02.017
   Zhang S, 2010, OPT LASER ENG, V48, P149, DOI 10.1016/j.optlaseng.2009.03.008
   Zheng Y, 2020, OPT EXPRESS, V28, P36568, DOI 10.1364/OE.410428
NR 40
TC 5
Z9 5
U1 10
U2 47
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0957-0233
EI 1361-6501
J9 MEAS SCI TECHNOL
JI Meas. Sci. Technol.
PD OCT 15
PY 2021
VL 32
IS 10
BP 
EP 
DI 10.1088/1361-6501/abf805
PG 13
WC Engineering, Multidisciplinary; Instruments & Instrumentation
SC Engineering; Instruments & Instrumentation
GA ST8EL
UT WOS:000662670900001
DA 2023-04-26
ER

PT J
AU Koehler, M
   Hanelli, D
   Schaefer, S
   Barth, A
   Knobloch, A
   Hielscher, P
   Cardoso-Fernandes, J
   Lima, A
   Teodoro, AC
AF Koehler, Martin
   Hanelli, Delira
   Schaefer, Stefan
   Barth, Andreas
   Knobloch, Andreas
   Hielscher, Peggy
   Cardoso-Fernandes, Joana
   Lima, Alexandre
   Teodoro, Ana C.
TI Lithium Potential Mapping Using Artificial Neural Networks: A Case Study from Central Portugal
SO MINERALS
LA English
DT Article
DE lithium; mineral predictive mapping; exploration targeting; artificial neural networks; Portugal
ID central-iberian zone; granitic pegmatites; spain; constraints; exhumation; sentinel-2; mineralogy; resources; complex; arc
AB The growing importance and demand of lithium (Li) for industrial applications, in particular rechargeable Li-ion batteries, have led to a significant increase in exploration efforts for Li-bearing minerals. To ensure and expand a stable Li supply to the global economy, extensive research and exploration are necessary. Artificial neural networks (ANNs) provide powerful tools for exploration target identification. They can be cost-effectively applied in various geological settings. This article presents an integrated approach of Li exploration targeting using ANNs for data interpretation. Based on medium resolution geological maps (1:50,000) and stream sediment geochemical data (1 sample per 0.25 km(2)), the Li potential was calculated for an area of approximately 1200 km(2) in the surroundings of Bajoca Mine (Northeast Portugal). Extensive knowledge about geological processes leading to Li mineralisation (such as weathering conditions and diverse Li minerals) proved to be a determining factor in the exploration model. Furthermore, Sentinel-2 satellite imagery was used in a separate ANN model to identify potential Li mine sites exposed on the ground surface by analysing the spectral signature of surface reflectance in well-known Li locations. Finally, the results were combined to design a final map of predicted Li mineralisation occurrences in the study area. The proposed approach reveals how remote sensing data in combination with geological and geochemical data can be used for delineating and ranking exploration targets of almost any deposit type.</p>
C1 [Koehler, Martin; Hanelli, Delira; Schaefer, Stefan; Barth, Andreas; Knobloch, Andreas; Hielscher, Peggy] Beak Consultants GmbH, St Niclas Schacht 13, D-09599 Freiberg, Germany.
   [Cardoso-Fernandes, Joana; Lima, Alexandre; Teodoro, Ana C.] Univ Porto, Fac Sci, Dept Geosci Environm & Spatial Planning, P-4169007 Porto, Portugal.
   [Cardoso-Fernandes, Joana; Lima, Alexandre; Teodoro, Ana C.] Pole Univ Porto, Inst Earth Sci ICT, P-4169007 Porto, Portugal.
C3 Universidade do Porto; Universidade do Porto
RP Koehler, M (corresponding author), Beak Consultants GmbH, St Niclas Schacht 13, D-09599 Freiberg, Germany.
EM martin.koehler@beak.de; delira.hanelli@beak.de; st.schaefer.geo@googlemail.com; andreas.barth@beak.de; andreas.knobloch@beak.de; peggy.hielscher@beak.de; joana.fernandes@fc.up.pt; allima@fc.up.pt; amteodor@fc.up.pt
FU EU H2020 ERAMIN-2 network [ERA-MIN/0001/2017-LIGHTS]; EU Horizon 2020; ANR-Agence Nationale de la Recherche (France); BMBF Julich-Bundesministerium fur Bildung und Forschung (Germany); FCT-Fundacao para a Ciencia e a Tecnologia (Portugal); Portuguese National Funds through the FCT [UIDB/04683/2020-ICT]; MCTES through FCT [SFRH/BD/136108/2018]; European Social Fund (ESF) through POCH-Programa Operacional Capital Humano; NORTE 2020 regional program; Fundação para a Ciência e a Tecnologia [SFRH/BD/136108/2018] Funding Source: FCT
CR Aires S.C.M., 2018, THESIS U PORTO PORTO, V0, P0
   Al Rawashdeh S, 2006, CYBERGEO, V0, P0, DOI DOI 10.4000/cybergeo.2856
   Angel J.M., 1981, NOTEGMX748 BRGM, V0, P6
   [Anonymous], 1999, NEURAL NETWORKS COMP, V0, P0
   Bahr T, 2019, WORK HYPERSP IMAG, V0, P0
   Bea F, 2003, J GEOL, V111, P579, DOI 10.1086/376767
   Bea F., 1987, GEOLOGIA GRANITOIDES, V0, P0
   BROOKS K, 2020, GEOL TODAY, V36, P192, DOI 10.1111/gto.12326
   Brown WM, 2000, AUST J EARTH SCI, V47, P757, DOI 10.1046/j.1440-0952.2000.00807.x
   Cardoso-Fernandes J, 2019, PROC SPIE, V11156, P0, DOI 10.1117/12.2532577
   Cardoso-Fernandes J, 2020, PROC SPIE, V11534, P0, DOI 10.1117/12.2573941
   Cardoso-Fernandes J, 2018, PROC SPIE, V10790, P0, DOI 10.1117/12.2326285
   Cardoso-Fernandes J., 2021, TOOLS REMOTE EXPLORA, V0, P0
   Cardoso-Fernandes J., 2021, P EGU GEN ASS 2021 O, V0, P0, DOI DOI 10.5194/egusphere-egu21-2364
   Cardoso-Fernandes J, 2020, INT GEOSCI REMOTE SE, V0, PP557, DOI 10.1109/IGARSS39084.2020.9323852
   Cardoso-Fernandes J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142319
   Cardoso-Fernandes J, 2019, INT J APPL EARTH OBS, V76, P10, DOI 10.1016/j.jag.2018.11.001
   Carvalho J.M.F., 2004, P 17 IND MINERALS IN, V0, P1
   Carvalhosa A., 1960, CARTA GEOLOGICA PORT, V0, P0
   Costa J.C.S., 1950, NOT CIA CARTA GEOLOG, V0, P0
   DIAS R, 1995, TECTONOPHYSICS, V246, P113, DOI 10.1016/0040-1951(94)00253-6
   European Commission, 2020, COM2020380FIN, V0, P0
   Ferreira JA, 2019, INT J EARTH SCI, V108, P2153, DOI 10.1007/s00531-019-01755-1
   Gaspar LM, 2000, ECON GEOL BULL SOC, V95, P1259, DOI 10.2113/95.6.1259
   Gourcerol B, 2019, ORE GEOL REV, V109, P494, DOI 10.1016/j.oregeorev.2019.04.015
   ilva D., 2018, FRONT INFORMAT SYST, V0, P0, DOI DOI 10.2174/9781681086118118010006
   Kesler SE, 2012, ORE GEOL REV, V48, P55, DOI 10.1016/j.oregeorev.2012.05.006
   Lanaras C, 2018, ISPRS J PHOTOGRAMM, V146, P305, DOI 10.1016/j.isprsjprs.2018.09.018
   Linnen RL, 2012, ELEMENTS, V8, P275, DOI 10.2113/gselements.8.4.275
   Catalan JRM, 2012, INT J EARTH SCI, V101, P1299, DOI 10.1007/s00531-011-0715-6
   Oh H.-J., 2010, NAT RESOUR RES, V19, P103, DOI 10.1007/S11053-010-9112-2
   Pereira I, 2017, J GEOL SOC LONDON, V174, P1004, DOI 10.1144/jgs2016-159
   Pour AB, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081186
   Ribeiro M.L., 1990, CARTA GEOLOGICA SIMP, V0, P0
   Rigol-Sanchez JP, 2003, INT J REMOTE SENS, V24, P1151, DOI 10.1080/0143116021000031791
   Robles ER, 1999, MINERAL MAG, V63, P535
   Roda E., 1993, THESIS UPV EHU BIBAO, V0, P0
   Roda-Robles E, 2018, ORE GEOL REV, V95, P408, DOI 10.1016/j.oregeorev.2018.02.027
   Roda-Robles E, 2016, MINERAL MAG, V80, P103, DOI 10.1180/minmag.2016.080.049
   Rodriguez-Galiano V, 2015, ORE GEOL REV, V71, P804, DOI 10.1016/j.oregeorev.2015.01.001
   Silva A.F., 1990, CARTA GEOLOGICA PORT, V0, P0
   Silva A.F.d., 1994, NOTICIA EXPLICATIVA, V0, P48
   Silva A.F.d., 1991, NOTICIA EXPLICATIVA, V0, P52
   Teixeira C., 1955, NOTAS GEOLOGIA PORTU, V0, P48
   van der Meer FD, 2014, REMOTE SENS ENVIRON, V148, P124, DOI 10.1016/j.rse.2014.03.022
   Viallefond L., 1981, NOTEGMX738 BRGM, V0, P17
   Viallefond L., 1981, NOTEGMX732 BRGM, V0, P27
   Vieira R., 2010, THESIS FACULDADE CIE, V0, P0
   Vieira R, 2011, AM MINERAL, V96, P637, DOI 10.2138/am.2011.3584
NR 49
TC 9
Z9 9
U1 4
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2075-163X
J9 MINERALS-BASEL
JI Minerals
PD OCT 15
PY 2021
VL 11
IS 10
BP 
EP 
DI 10.3390/min11101046
PG 23
WC Geochemistry & Geophysics; Mineralogy; Mining & Mineral Processing
SC Geochemistry & Geophysics; Mineralogy; Mining & Mineral Processing
GA WP9JF
UT WOS:000713440400001
DA 2023-04-26
ER

PT J
AU Du, L
   Jin, ZL
   Chen, BW
   Chen, BW
   Gao, W
   Yang, J
   Shi, S
   Song, SL
   Wang, MM
   Gong, W
   Wang, W
AF Du, Lin
   Jin, Zhili
   Chen, Bowen
   Chen, Biwu
   Gao, Wei
   Yang, Jian
   Shi, Shuo
   Song, Shalei
   Wang, Mengmeng
   Gong, Wei
   Wang, Wei
TI Application of Hyperspectral LiDAR on 3-D Chlorophyll-Nitrogen Mapping of Rohdea Japonica in Laboratory
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Vegetation mapping; Three-dimensional displays; Silicon; Mirrors; Indexes; Laser radar; Estimation; Artificial neural network (ANN); broadband spectral index; Chl-N content mapping; hyperspectral LiDAR (HSL)
ID terrestrial laser scanner; backscatter intensity; vegetation index; remote estimation; broad-band; k-fold; leaf; reflectance; canopy; meter
AB Biochemicals, such as chlorophyll (Chl) and nitrogen (N), are closely related to photosynthesis process of vegetation. Their accurate estimation is an important topic in remote sensing of vegetation. Previous studies mainly focused on Chl-N content inversion in leaf and canopy level, and few cared about their 3-D distributions, which was also an important indicator for the growth status of vegetation (GSV). Hyperspectral LiDAR (HSL) is a novel active remote sensing technology, which has target-sensitive band with hyperspectra resolution. Its 3-D point cloud data simultaneously contains rich spectral and precise geometrical characteristics of the target. This work aims to apply HSL data on 3-D Chl-N content mapping in vegetation through constructing HSL-based spectral indices (SIs). Except for following the SI forms of previous works, the normalized differential vegetation index and ratio index (RI) with four broadbands in an HSL spectral space were successively proposed to invert Chl-N content for the whole vegetation based on the artificial neural network (ANN) method. These four broadbands were transformed based on the relative spectral response curve of detector and the feature weights (FWs) of multiwavelength, respectively. Results show that most HSL-based ANN models can accurately invert Chl-N content with a mean R-2 of >0.75, and some that fusing broadband data with convolution transformation, namely the FW-based RI, can even obtain a model R-2 of 0.84 for N content inversion. Thus, HSL can be efficiently applied to 3-D Chl-N content mapping of vegetation and has great potential in GSV monitoring.
C1 [Du, Lin; Wang, Mengmeng] China Univ Geosci, Fac Informat Engn, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
   [Du, Lin; Wang, Mengmeng] Wuchang Univ Technol, Artificial Intelligence Sch, Wuhan 430223, Peoples R China.
   [Gao, Wei; Yang, Jian] China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
   [Jin, Zhili; Wang, Wei] Cent South Univ, Sch Geosci & Infophys, Changsha 410083, Peoples R China.
   [Chen, Bowen; Chen, Biwu; Shi, Shuo; Gong, Wei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Song, Shalei] Chinese Acad Sci, Wuhan Inst Phys & Math, Key Lab Magnet Resonance & Atom & Mol Phys, Wuhan 430071, Peoples R China.
C3 China University of Geosciences; Wuchang University of Technology; China University of Geosciences; Central South University; Wuhan University; Chinese Academy of Sciences; Wuhan Institute of Physics & Mathematics, CAS
RP Gao, W (corresponding author), China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China.
EM dulin@cug.edu.cn; jinzhili@csu.edn.cn; chenbowen1204@whu.edu.cn; cbw_think@whu.edu.cn; gaowei@cug.edu.cn; yangjian@cug.edu.cn; shishuo@whu.edu.cn; songshalei@gmail.com; wangmm@cug.edu.cn; weigong@whu.edu.cn; wangweicn@csu.edu.cn
FU National Key R&D Program of China [2018YFB0504500]; National Natural Science Foundation of China [41971307]; Fundamental Research Funds for the Central Universities, China University of Geosciences (Wuhan) [CUG170662]
CR Asner GP, 2008, REMOTE SENS ENVIRON, V112, P3958, DOI 10.1016/j.rse.2008.07.003
   Barutcular C, 2016, FRESEN ENVIRON BULL, V25, P1258
   Beck PSA, 2006, REMOTE SENS ENVIRON, V100, P321, DOI 10.1016/j.rse.2005.10.021
   Bi KY, 2020, IEEE T GEOSCI REMOTE, V58, P8125, DOI 10.1109/TGRS.2020.2987436
   Broge NH, 2001, REMOTE SENS ENVIRON, V76, P156, DOI 10.1016/S0034-4257(00)00197-8
   Carrea D, 2016, ISPRS J PHOTOGRAMM, V113, P17, DOI 10.1016/j.isprsjprs.2015.12.004
   CHAPPELLE EW, 1992, REMOTE SENS ENVIRON, V39, P239, DOI 10.1016/0034-4257(92)90089-3
   Chen BW, 2019, OPT EXPRESS, V27, P24043, DOI 10.1364/OE.27.024043
   Danson FM, 2014, AGR FOREST METEOROL, V198, P7, DOI 10.1016/j.agrformet.2014.07.007
   Daughtry CST, 2000, REMOTE SENS ENVIRON, V74, P229, DOI 10.1016/S0034-4257(00)00113-9
   Delegido J, 2010, INT J APPL EARTH OBS, V12, P165, DOI 10.1016/j.jag.2010.02.003
   DICKSON RE, 1989, ANN SCI FOREST, V46, PS631, DOI 10.1051/forest:198905ART0142
   Du L, 2020, FRONT PLANT SCI, V11, P0, DOI 10.3389/fpls.2020.00533
   Du L, 2018, OPT LASER TECHNOL, V107, P372, DOI 10.1016/j.optlastec.2018.06.019
   Du L, 2016, INT J APPL EARTH OBS, V44, P136, DOI 10.1016/j.jag.2015.08.008
   Eitel JUH, 2016, REMOTE SENS ENVIRON, V186, P372, DOI 10.1016/j.rse.2016.08.018
   Eitel JUH, 2014, ISPRS J PHOTOGRAMM, V97, P229, DOI 10.1016/j.isprsjprs.2014.09.009
   Eitel JUH, 2014, FIELD CROP RES, V159, P21, DOI 10.1016/j.fcr.2014.01.008
   Eitel JUH, 2011, AGR FOREST METEOROL, V151, P1338, DOI 10.1016/j.agrformet.2011.05.015
   Eitel JUH, 2010, REMOTE SENS ENVIRON, V114, P2229, DOI 10.1016/j.rse.2010.04.025
   ELVIDGE CD, 1995, REMOTE SENS ENVIRON, V54, P38, DOI 10.1016/0034-4257(95)00132-K
   Erdle K, 2011, FIELD CROP RES, V124, P74, DOI 10.1016/j.fcr.2011.06.007
   Gastellu-Etchegorry JP, 2015, REMOTE SENS-BASEL, V7, P1667, DOI 10.3390/rs70201667
   Gaulton R, 2013, REMOTE SENS ENVIRON, V132, P32, DOI 10.1016/j.rse.2013.01.001
   Gitelson AA, 2005, GEOPHYS RES LETT, V32, P0, DOI 10.1029/2005GL022688
   Gitelson AA, 2006, GEOPHYS RES LETT, V33, P0, DOI 10.1029/2006GL026457
   Goel N., 1994, REMOTE SENSING REV, V10, P309, DOI 10.1080/02757259409532252
   Haboudane D, 2002, REMOTE SENS ENVIRON, V81, P416, DOI 10.1016/S0034-4257(02)00018-4
   Hakala T, 2012, OPT EXPRESS, V20, P7119, DOI 10.1364/OE.20.007119
   Hosoi F, 2012, ISPRS J PHOTOGRAMM, V74, P11, DOI 10.1016/j.isprsjprs.2012.08.001
   Hu PL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060919
   Hu YB, 2020, PLANT PHYSIOL BIOCH, V154, P530, DOI 10.1016/j.plaphy.2020.06.053
   Huang HG, 2013, REMOTE SENS ENVIRON, V132, P221, DOI 10.1016/j.rse.2013.01.013
   Huang R, 2005, IEEE GEOSCI REMOTE S, V2, P156, DOI 10.1109/LGRS.2005.844658
   Humair F, 2015, EUR J REMOTE SENS, V48, P541, DOI 10.5721/EuJRS20154831
   Hunt ER, 2014, AGRON J, V106, P931, DOI 10.2134/agronj13.0322
   Jacquemoud S, 2009, REMOTE SENS ENVIRON, V113, PS56, DOI 10.1016/j.rse.2008.01.026
   Jung Y, 2018, J NONPARAMETR STAT, V30, P197, DOI 10.1080/10485252.2017.1404598
   Kaasalainen S., 2014, INT ARCH PHOTOGRAMM, V40, P109
   Kaasalainen S, 2007, IEEE GEOSCI REMOTE S, V4, P211, DOI 10.1109/LGRS.2006.888848
   Kaasalainen S, 2018, INTERFACE FOCUS, V8, P0, DOI 10.1098/rsfs.2017.0033
   Kim M.S., 1994, P 6 INT S PHYS MEASU, V0, P0
   Koetz B, 2007, REMOTE SENS ENVIRON, V106, P449, DOI 10.1016/j.rse.2006.09.013
   Li W, 2016, OPT EXPRESS, V24, P4771, DOI 10.1364/OE.24.004771
   Li XL, 2013, OPT ENG, V52, P0, DOI 10.1117/1.OE.52.11.116110
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Magney TS, 2014, NEW PHYTOL, V201, P344, DOI 10.1111/nph.12453
   Merton R.N., 1999, P 8 ANN JPL AIRB EAR, V0, P0
   Mkhabela MS, 2011, AGR FOREST METEOROL, V151, P385, DOI 10.1016/j.agrformet.2010.11.012
   Naus J, 2010, PHOTOSYNTH RES, V105, P265, DOI 10.1007/s11120-010-9587-z
   Nevalainen O., 2013, REMOTE SENS SPAT INF, V2, P205, DOI 10.5194/ISPRSANNALS-II-5-W2-205-2013
   Nevalainen O, 2014, AGR FOREST METEOROL, V198, P250, DOI 10.1016/j.agrformet.2014.08.018
   Ni-Meister W, 2001, IEEE T GEOSCI REMOTE, V39, P1943, DOI 10.1109/36.951085
   Olfs HW, 2005, J PLANT NUTR SOIL SC, V168, P414, DOI 10.1002/jpln.200520526
   Peng S, 1996, FIELD CROP RES, V47, P243, DOI 10.1016/0378-4290(96)00018-4
   Reyniers M, 2006, INT J REMOTE SENS, V27, P4159, DOI 10.1080/01431160600791650
   Schlemmer M, 2013, INT J APPL EARTH OBS, V25, P47, DOI 10.1016/j.jag.2013.04.003
   Shi S, 2015, IEEE GEOSCI REMOTE S, V12, P1421, DOI 10.1109/LGRS.2015.2405573
   Sims DA, 2002, REMOTE SENS ENVIRON, V81, P337, DOI 10.1016/S0034-4257(02)00010-X
   Takashima T, 2004, PLANT CELL ENVIRON, V27, P1047, DOI 10.1111/j.1365-3040.2004.01209.x
   Tan K, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9080853
   Thenkabail PS, 2000, REMOTE SENS ENVIRON, V71, P158, DOI 10.1016/S0034-4257(99)00067-X
   Uddling J, 2007, PHOTOSYNTH RES, V91, P37, DOI 10.1007/s11120-006-9077-5
   Vincini M, 2008, PRECIS AGRIC, V9, P303, DOI 10.1007/s11119-008-9075-z
   Wagner W, 2008, INT J REMOTE SENS, V29, P1433, DOI 10.1080/01431160701736398
   Wagner W, 2010, ISPRS J PHOTOGRAMM, V65, P505, DOI 10.1016/j.isprsjprs.2010.06.007
   Wang B, 2016, MITOCHONDRIAL DNA A, V27, P2913, DOI 10.3109/19401736.2015.1060436
   Wang GY, 2014, CROP SCI, V54, P817, DOI 10.2135/cropsci2013.03.0160
   Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
   Woodhouse IH, 2011, IEEE GEOSCI REMOTE S, V8, P839, DOI 10.1109/LGRS.2011.2113312
   Xiong DL, 2015, SCI REP-UK, V5, P0, DOI 10.1038/srep13389
   Yang J, 2020, OPT EXPRESS, V28, P18728, DOI 10.1364/OE.395478
   Yegnanarayana B, 2009, ARTIFICIAL NEURAL NE, V0, P201
   Yl QX, 2007, ENVIRON SCI TECHNOL, V41, P6770, DOI 10.1021/es070144e
   Zhang CS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12172855
   Zhang ZJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020298
   Zhu X, 2015, ISPRS J PHOTOGRAMM, V110, P14, DOI 10.1016/j.isprsjprs.2015.10.001
NR 77
TC 8
Z9 8
U1 10
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9667
EP 9679
DI 10.1109/JSTARS.2021.3111295
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WD3DB
UT WOS:000704824700002
DA 2023-04-26
ER

PT J
AU Lv, N
   Ma, HX
   Chen, C
   Pei, QQ
   Zhou, Y
   Xiao, FL
   Li, J
AF Lv, Ning
   Ma, Hongxiang
   Chen, Chen
   Pei, Qingqi
   Zhou, Yang
   Xiao, Fenglin
   Li, Ji
TI Remote Sensing Data Augmentation Through Adversarial Training
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Remote sensing; Generative adversarial networks; Generators; Semantics; Training; Task analysis; Image synthesis; Data augmentation; deep supervision; downsampling; GAN
ID classification
AB The lack of remote sensing images and poor quality limit the performance improvement of follow-up research such as remote sensing interpretation. In this article, a generative adversarial network (GAN) is proposed for data augmentation of remote sensing images abstracted from Jiangxi and Anhui Provinces in China, i.e., deeply supervised GAN (D-sGAN). D-sGAN can generate high-quality images that are rich in changes, greatly shorten the generation time, and provide data support for applications such as semantic interpretation of remote sensing images. First, to modulate the layer activations, a downsampling scheme is designed based on the segmentation map. Then, the architecture of the generator is Unet++ with the proposed downsampling module. Next, the generator of this net is deeply supervised by the discriminator using deep convolutional neural network. This article further proved that the proposed downsampling module and the dense connection characteristics of UNet++ are significantly beneficial to the retention of semantic information of remote sensing images. Numerical results demonstrated that the images generated by D-sGAN could be used to improve accuracy of the segmentation network, with the faster generation speed compared to the CoGAN, SimGAN, and CycleGAN models. Furthermore, the remote sensing data generated by the model helped the interpretation network to increase the accuracy by 9%, meeting actual generation requirements.
C1 [Lv, Ning; Ma, Hongxiang; Chen, Chen; Pei, Qingqi] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
   [Zhou, Yang; Xiao, Fenglin; Li, Ji] Minist Water Resources China, Beijing 101400, Peoples R China.
C3 Xidian University
RP Chen, C (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
EM nlv@mail.xidian.edu.cn; mhongxiang@163.com; cc2000@mail.xidian.edu.cn; qqpei@mail.xidian.edu.cn; zhy@mwr.gov.cn; xiaofl@goldenwater.com.cn; liji@goldenwater.com.cn
FU National Key Research and Development Program of China [2020YFB1807500]; National Natural Science Foundation of China [62072360, 62001357, 61672131, 61901367]; Key Research and Development Plan of Shaanxi province [2021ZDLGY02-09, 2020JQ-844]; Key Laboratory of Embedded System and Service Computing (Tongji University) [ESSCKF2019-05]; Ministry of Education, Xi'an Science and Technology Plan [20RGZN0005]; Xi'an Key Laboratory of Mobile Edge Computing and Security [201805052-ZD3CG36]
CR Abdollahi A, 2021, IEEE ACCESS, V9, P64381, DOI 10.1109/ACCESS.2021.3075951
   Nguyen A, 2017, PROC CVPR IEEE, V0, PP3510, DOI 10.1109/CVPR.2017.374
   Bae HJ, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-36047-2
   Bredemeyer S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10101514
   Chen C, 2019, IEEE ACM T NETWORK, V27, P2324, DOI 10.1109/TNET.2019.2944595
   Chen C, 2019, IEEE ACCESS, V7, P133839, DOI 10.1109/ACCESS.2019.2941234
   Chen C, 2019, IEEE T INTELL TRANSP, V20, P1604, DOI 10.1109/TITS.2018.2828025
   Chen C, 2019, IEEE T MOBILE COMPUT, V18, P2811, DOI 10.1109/TMC.2018.2883312
   Denton E. L., 2015, ADV NEURAL INFORM PR, V0, P0
   Dieleman S, 2015, MON NOT R ASTRON SOC, V450, P1441, DOI 10.1093/mnras/stv632
   Fawzi A, 2016, IEEE IMAGE PROC, V0, PP3688, DOI 10.1109/ICIP.2016.7533048
   Gauthier J., 2014, CLASS PROJECT STANFO, V2, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Im D. J, 2016, ARXIV160205110, V0, P0
   Isola P, 2017, PROC CVPR IEEE, V0, PP5967, DOI 10.1109/CVPR.2017.632
   Jiang JJ, 2018, IEEE T GEOSCI REMOTE, V56, P4581, DOI 10.1109/TGRS.2018.2828029
   Kingma D. P., 2013, AUTOENCODING VARIATI, V0, P0
   Lai R, 2019, IEEE ACCESS, V7, P753, DOI 10.1109/ACCESS.2018.2885803
   Li C, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070588
   Li W, 2019, IEEE GEOSCI REMOTE S, V16, P593, DOI 10.1109/LGRS.2018.2878773
   Liu MY, 2016, ADV NEUR IN, V29, P0
   Mirza M., 2014, CONDITIONAL GENERATI, V0, P2672
   Mnih V., 2013, MACHINE LEARNING AER, V0, P0
   Nguyen A., 2016, ADV NEURAL INF PROCE, V0, P0
   Owens A, 2016, PROC CVPR IEEE, V0, PP2405, DOI 10.1109/CVPR.2016.264
   Park T, 2019, PROC CVPR IEEE, V0, PP2332, DOI 10.1109/CVPR.2019.00244
   Reed S, 2016, PR MACH LEARN RES, V48, P0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T, 2016, ADV NEUR IN, V29, P0
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Shrivastava A, 2017, PROC CVPR IEEE, V0, PP2242, DOI 10.1109/CVPR.2017.241
   Sonderby C. K., 2016, ARXIV161004490, V0, P0
   Tan WR, 2017, IEEE IMAGE PROC, V0, P3760
   Tang B, 2018, IEEE ACCESS, V6, P15713, DOI 10.1109/ACCESS.2018.2815741
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Xu T, 2018, PROC CVPR IEEE, V0, PP1316, DOI 10.1109/CVPR.2018.00143
   Yan YM, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8060276
   Yang JF, 2019, IEEE ACCESS, V7, P28894, DOI 10.1109/ACCESS.2019.2902121
   Yin Luo, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL ENGINEERING AND COMPUTER APPLICATIONS (AEECA), V0, PP219, DOI 10.1109/AEECA49918.2020.9213654
   Zhang H, 2017, IEEE I CONF COMP VIS, V0, PP5908, DOI 10.1109/ICCV.2017.629
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 46
TC 15
Z9 15
U1 8
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9318
EP 9333
DI 10.1109/JSTARS.2021.3110842
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UU5SL
UT WOS:000698859700009
DA 2023-04-26
ER

PT J
AU Li, Y
   Xu, WP
   Chen, HH
   Jiang, JH
   Li, X
AF Li, Ying
   Xu, Weipan
   Chen, Haohui
   Jiang, Junhao
   Li, Xun
TI A Novel Framework Based on Mask R-CNN and Histogram Thresholding for Scalable Segmentation of New and Old Rural Buildings
SO REMOTE SENSING
LA English
DT Article
DE deep learning; rural buildings; instance segmentation; Mask R-CNN; histogram thresholding
ID remote-sensing images; extraction
AB Mapping new and old buildings are of great significance for understanding socio-economic development in rural areas. In recent years, deep neural networks have achieved remarkable building segmentation results in high-resolution remote sensing images. However, the scarce training data and the varying geographical environments have posed challenges for scalable building segmentation. This study proposes a novel framework based on Mask R-CNN, named Histogram Thresholding Mask Region-Based Convolutional Neural Network (HTMask R-CNN), to extract new and old rural buildings even when the label is scarce. The framework adopts the result of single-object instance segmentation from the orthodox Mask R-CNN. Further, it classifies the rural buildings into new and old ones based on a dynamic grayscale threshold inferred from the result of a two-object instance segmentation task where training data is scarce. We found that the framework can extract more buildings and achieve a much higher mean Average Precision (mAP) than the orthodox Mask R-CNN model. We tested the novel framework's performance with increasing training data and found that it converged even when the training samples were limited. This framework's main contribution is to allow scalable segmentation by using significantly fewer training samples than traditional machine learning practices. That makes mapping China's new and old rural buildings viable.
C1 [Li, Ying; Xu, Weipan; Jiang, Junhao; Li, Xun] Sun Yat Sen Univ, China Reg Coordinated Dev & Rural Construct Inst, Sch Geog & Planning, Dept Urban & Reg Planning,Urbanizat Inst, Guangzhou 510275, Peoples R China.
   [Chen, Haohui] Commonwealth Sci & Ind Res Org CSIRO, Data61, Canberra, ACT 2601, Australia.
C3 Sun Yat Sen University; Commonwealth Scientific & Industrial Research Organisation (CSIRO)
RP Li, X (corresponding author), Sun Yat Sen Univ, China Reg Coordinated Dev & Rural Construct Inst, Sch Geog & Planning, Dept Urban & Reg Planning,Urbanizat Inst, Guangzhou 510275, Peoples R China.
EM liying268@mail2.sysu.edu.cn; xuweipan@mail2.sysu.edu.cn; caronhaohui.chen@data61.csiro.au; jiangjh26@mail2.sysu.edu.cn; lixun@mail.sysu.edu.cn
FU National Natural Science Foundation of China [41971157]; Key R&D Programs in Guangdong Province; Major National Science and Technology Projects of China [2020B0202010002]
CR Arnab A, 2018, IEEE SIGNAL PROC MAG, V35, P37, DOI 10.1109/MSP.2017.2762355
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Bachofer F, 2019, DATA, V4, P0, DOI 10.3390/data4030105
   Bhuiyan MA, 2020, J IMAGING, V6, P0, DOI 10.3390/jimaging6120137
   Bottou L, 2010, COMPSTAT2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, V0, PP177, DOI 10.1007/978-3-7908-2604-3_16
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen M, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13020294
   Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM19), V0, PP2276, DOI 10.1145/3343031.3350535
   Ghanea M, 2016, INT J REMOTE SENS, V37, P5234, DOI 10.1080/01431161.2016.1230287
   Guo MQ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091400
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Hongshun Chen, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON IMAGE, Vision and Computing (ICIVC), P227, DOI 10.1109/ICIVC47709.2019.8981046
   Huang X, 2012, IEEE J-STARS, V5, P161, DOI 10.1109/JSTARS.2011.2168195
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jin XY, 2005, EURASIP J APPL SIG P, V2005, P2196, DOI 10.1155/ASP.2005.2196
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Kang WC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232813
   Kuffer M., 2019, P 2019 JOINT URB REM, V0, P1
   Kuffer M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060455
   Kurnaz MN, 2005, PATTERN RECOGN LETT, V26, P1096, DOI 10.1016/j.patrec.2004.10.004
   Li C, 2021, J INDIAN SOC REMOTE, V49, P233, DOI 10.1007/s12524-020-01209-1
   Li Q., 2020, ARXIV200603858, V0, P0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luo LF, 2016, BIOSYST ENG, V151, P90, DOI 10.1016/j.biosystemseng.2016.08.026
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   Mahmoud A.S., 2020, INT J INTELLIGENT EN, V13, P65, DOI 10.22266/ijies2020.0229.07
   Mitra P, 2004, PATTERN RECOGN LETT, V25, P1067, DOI 10.1016/j.patrec.2004.03.004
   Mnih V., 2013, CITESEER, V0, P0
   National Bureau of Statistics of China, 2019, CHIN STAT YB 2018, V0, P0
   Pan ZK, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101574
   Patino JE, 2013, COMPUT ENVIRON URBAN, V37, P1, DOI 10.1016/j.compenvurbsys.2012.06.003
   Qi Z., 2018, CHINA EC WKLY, V0, P78
   Sekertekin A, 2021, ARCH COMPUT METHOD E, V28, P1335, DOI 10.1007/s11831-020-09416-2
   Srikanth MV, 2020, INT J COGN INFORM NA, V14, P60, DOI 10.4018/IJCINI.2020070104
   Tang YC, 2019, ROBOT CIM-INT MANUF, V59, P36, DOI 10.1016/j.rcim.2019.03.001
   Tupin F, 2005, IEEE T GEOSCI REMOTE, V43, P1920, DOI 10.1109/TGRS.2005.852080
   Wang SS, 2020, IEEE ACCESS, V8, P7313, DOI 10.1109/ACCESS.2020.2964043
   Wu T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182910
   Yang R, 2016, J RURAL STUD, V47, P413, DOI 10.1016/j.jrurstud.2016.05.013
   Zha K, 2018, IEEE COMPUT SOC CONF, V0, PP242, DOI 10.1109/CVPRW.2018.00045
   Zhang L, 2010, IEEE T PATTERN ANAL, V32, P1406, DOI 10.1109/TPAMI.2009.145
   Zhang WX, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071085
   Zhao X, 2019, ECOL INDIC, V105, P398, DOI 10.1016/j.ecolind.2018.01.006
NR 43
TC 24
Z9 24
U1 5
U2 25
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR 15
PY 2021
VL 13
IS 6
BP 
EP 
DI 10.3390/rs13061070
PG 11
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SE3AU
UT WOS:000651944500001
DA 2023-04-26
ER

PT J
AU Liu, K
   Jiang, ZY
   Xu, ML
   Perc, M
   Li, XL
AF Liu, Kang
   Jiang, Zhiyu
   Xu, Mingliang
   Perc, Matjaz
   Li, Xuelong
TI Tilt Correction Toward Building Detection of Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Buildings; Synthetic aperture radar; Remote sensing; Detectors; Optical sensors; Object detection; Laser radar; Building detection; cost of building partition (CoBP); deep neural network (DNN); remote sensing; tilt correction (TC)
ID reconstruction; saliency
AB Building detection is a crucial task in the field of remote sensing, which can facilitate urban construction planning, disaster survey, and emergency landing. However, for large-size remote sensing images, the great majority of existing works have ignored the image tilt problem. This problem can result in partitioning buildings into separately oblique parts when the large-size images are partitioned. This is not beneficial to preserve semantic completeness of the building objects. Motivated by the above fact, we first propose a framework for detecting objects in a large-size image, particularly for building detection. The framework mainly consists of two phases. In the first phase, we particularly propose a tilt correction (TC) algorithm, which contains three steps: texture mapping, tilt angle assessment, and image rotation. In the second phase, building detection is performed with object detectors, especially deep-neural-network-based methods. Last but not least, the detection results will be inversely mapped to the original large-size image. Furthermore, a challenging dataset named Aerial Image Building Detection is contributed for the public research. To evaluate the TC method, we also define an evaluation metric to compute the cost of building partition. The experimental results demonstrate the effects of the proposed method for building detection.
C1 [Liu, Kang] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Shaanxi Key Lab Ocean Opt, Xian 710119, Peoples R China.
   [Liu, Kang] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Jiang, Zhiyu; Li, Xuelong] Northwestern Polytech Univ, Minist Ind & Informat Technol, Key Lab Intelligent Interact & Applicat, Xian 710072, Peoples R China.
   [Jiang, Zhiyu; Li, Xuelong] Northwestern Polytech Univ, Sch Artificial Intelligence Opt & Elect, Xian 710072, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
   [Perc, Matjaz] Univ Maribor, Fac Nat Sci & Math, SL-2000 Maribor, Slovenia.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Northwestern Polytechnical University; Northwestern Polytechnical University; Zhengzhou University; University of Maribor
RP Li, XL (corresponding author), Northwestern Polytech Univ, Minist Ind & Informat Technol, Key Lab Intelligent Interact & Applicat, Xian 710072, Peoples R China.; Li, XL (corresponding author), Northwestern Polytech Univ, Sch Artificial Intelligence Opt & Elect, Xian 710072, Peoples R China.
EM liukang@opt.ac.cn; jiangzhiyu@nwpu.edu.cn; iexumingliang@zzu.edu.cn; matjaz.perc@gmail.com; li@nwpu.edu.cn
FU Key Research Program of Frontier Sciences, Chinese Academy of Sciences [QYZDY-SSW-JSC044]; National Natural Science Foundation of China [61871470, 62001397]; Natural Science Basic Research Program of Shaanxi [2020JQ-212]; Open-Ended Foundation of National Radar Signal Processing Laboratory [61424010207]
CR Adelipour S, 2018, IEEE J-STARS, V11, P4808, DOI 10.1109/JSTARS.2018.2876910
   Agarwal L, 2018, INT GEOSCI REMOTE SE, V0, P4831
   Alidoost F, 2018, PFG-J PHOTOGRAMM REM, V86, P235, DOI 10.1007/s41064-018-0060-5
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Bai T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050762
   Cai Z, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070848
   Chen K., 2019, ARXIV190607155, V0, P0
   Chen YM, 2014, IEEE J-STARS, V7, P4081, DOI 10.1109/JSTARS.2014.2306003
   Dey EK, 2020, IEEE J-STARS, V13, P4030, DOI 10.1109/JSTARS.2020.3006258
   Dong Z., 2020, P IEEE C COMPUTER VI, V0, P10519
   Dong ZP, 2020, IEEE T GEOSCI REMOTE, V58, P2104, DOI 10.1109/TGRS.2019.2953119
   Du L, 2020, IEEE T GEOSCI REMOTE, V58, P3366, DOI 10.1109/TGRS.2019.2953936
   Duan KW, 2019, IEEE I CONF COMP VIS, V0, PP6568, DOI 10.1109/ICCV.2019.00667
   Dubois C, 2016, ISPRS J PHOTOGRAMM, V114, P228, DOI 10.1016/j.isprsjprs.2016.02.009
   Fang H, 2019, IEEE J-STARS, V12, P2695, DOI 10.1109/JSTARS.2019.2917605
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Ferro A, 2013, IEEE T GEOSCI REMOTE, V51, P935, DOI 10.1109/TGRS.2012.2205156
   Girshick R, 2014, PROC CVPR IEEE, V0, PP580, DOI 10.1109/CVPR.2014.81
   Hamaguchi R, 2018, INT GEOSCI REMOTE SE, V0, P1280
   Huang J, 2018, INT GEOSCI REMOTE SE, V0, P3991
   Huang X, 2017, IEEE J-STARS, V10, P654, DOI 10.1109/JSTARS.2016.2587324
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang X, 2021, IEEE J-STARS, V14, P2699, DOI 10.1109/JSTARS.2020.3017934
   Karadag OO, 2015, IEEE J-STARS, V8, P3305, DOI 10.1109/JSTARS.2015.2403617
   Karimzadeh S, 2018, IEEE J-STARS, V11, P2668, DOI 10.1109/JSTARS.2018.2825399
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li JJ, 2020, REMOTE SENS LETT, V11, P640, DOI 10.1080/2150704X.2020.1750729
   Li PY, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, V0, P400
   Li X., 1900, DOI 10.1360/SSI-2020-0165, V0, P0
   Li XL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2201
   Li XL, 2017, AAAI CONF ARTIF INTE, V0, P4147
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu BL, 2018, J PHYS CONF SER, V976, P0, DOI 10.1088/1742-6596/976/1/012013
   Liu W, 2021, IEEE J-STARS, V14, P2236, DOI 10.1109/JSTARS.2021.3052495
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YB, 2018, IEEE J-STARS, V11, P3688, DOI 10.1109/JSTARS.2018.2866284
   Lv ZY, 2021, IEEE GEOSCI REMOTE S, V18, P1284, DOI 10.1109/LGRS.2020.2998684
   Maggiori E, 2017, INT GEOSCI REMOTE SE, V0, P3226
   Mahphood A, 2020, INT J REMOTE SENS, V41, P1067, DOI 10.1080/01431161.2019.1655176
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831
   Mousavi SM, 2020, IEEE T GEOSCI REMOTE, V58, P8211, DOI 10.1109/TGRS.2020.2988770
   Norman M, 2020, GEOCARTO INT, V35, P1124, DOI 10.1080/10106049.2019.1573853
   Reda K, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142240
   REDMON J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren S., 2015, PROC INT C NEURAL IN, V0, PP91, DOI 10.1109/ICCV.2015.169.
   Shahzad M, 2019, IEEE T GEOSCI REMOTE, V57, P1100, DOI 10.1109/TGRS.2018.2864716
   Shu Z, 2018, IEEE GEOSCI REMOTE S, V15, P1100, DOI 10.1109/LGRS.2018.2822760
   Triggs, 2005, PROC CVPR IEEE, V1, P886, DOI 10.1109/CVPR.2005.177
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Xie Y., 1900, V34, V0, P777
   Xu CY, 2020, IEEE T GEOSCI REMOTE, V58, P4353, DOI 10.1109/TGRS.2019.2963243
   Yang DD, 2018, CAN J ELECT COMPUT E, V41, P145, DOI 10.1109/CJECE.2018.2867591
   Yang JR, 2019, INT J REMOTE SENS, V40, P6036, DOI 10.1080/01431161.2019.1587200
   Yao XW, 2015, NEUROCOMPUTING, V164, P162, DOI 10.1016/j.neucom.2015.02.073
   Zhao ZZ, 2019, IEEE GEOSCI REMOTE S, V16, P1299, DOI 10.1109/LGRS.2019.2894896
   Zhu DJ, 2020, NEUROCOMPUTING, V381, P40, DOI 10.1016/j.neucom.2019.10.065
NR 58
TC 6
Z9 6
U1 4
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 5854
EP 5866
DI 10.1109/JSTARS.2021.3083481
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SV0RU
UT WOS:000663535500017
DA 2023-04-26
ER

PT J
AU Qi, TJ
   Zhao, Y
   Meng, XM
   Chen, G
   Dijkstra, T
AF Qi, Tianjun
   Zhao, Yan
   Meng, Xingmin
   Chen, Guan
   Dijkstra, Tom
TI AI-Based Susceptibility Analysis of Shallow Landslides Induced by Heavy Rainfall in Tianshui, China
SO REMOTE SENSING
LA English
DT Article
DE heavy rainfall; landslide inventory; machine learning; susceptibility mapping
ID logistic-regression; neural-networks; debris flow; region; loess; river; area; thresholds; prediction; inventory
AB Groups of landslides induced by heavy rainfall are widely distributed on a global basis and they usually result in major losses of human life and economic damage. However, compared with landslides induced by earthquakes, inventories of landslides induced by heavy rainfall are much less common. In this study we used high-precision remote sensing images before and after continuous heavy rainfall in southern Tianshui, China, from 20 June to 25 July 2013, to produce an inventory of 14,397 shallow landslides. Based on the results of landslide inventory, we utilized machine learning and the geographic information system (GIS) to map landslide susceptibility in this area and evaluated the relative weight of various factors affecting landslide development. First, 18 variables related to geomorphic conditions, slope material, geological conditions, and human activities were selected through collinearity analysis; second, 21 selected machine learning models were trained and optimized in the Python environment to evaluate the susceptibility of landslides. The results showed that the ExtraTrees model was the most effective for landslide susceptibility assessment, with an accuracy of 0.91. This predictive ability means that our landslide susceptibility results can be used in the implementation of landslide prevention and mitigation measures in the region. Analysis of the importance of the factors showed that the contribution of slope aspect (SA) was significantly higher than that of the other factors, followed by planar curvature (PLC), distance to river (DR), distance to fault (DTF), normalized difference vehicle index (NDVI), distance to road (DTR), and other factors. We conclude that factors related to geomorphic conditions are principally responsible for controlling landslide susceptibility in the study area.
C1 [Qi, Tianjun; Meng, Xingmin] Lanzhou Univ, MOE Key Lab Western Chinas Environm Syst, Coll Earth & Environm Sci, Lanzhou 730000, Peoples R China.
   [Zhao, Yan; Meng, Xingmin; Chen, Guan] Lanzhou Univ, Sch Earth Sci, Lanzhou 730000, Peoples R China.
   [Dijkstra, Tom] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
C3 Lanzhou University; Lanzhou University; Loughborough University
RP Meng, XM (corresponding author), Lanzhou Univ, MOE Key Lab Western Chinas Environm Syst, Coll Earth & Environm Sci, Lanzhou 730000, Peoples R China.; Meng, XM (corresponding author), Lanzhou Univ, Sch Earth Sci, Lanzhou 730000, Peoples R China.
EM qitj16@lzu.edu.cn; zhaoyandz@lzu.edu.cn; xmmeng@lzu.edu.cn; gchen@lzu.edu.cn; T.A.Dijkstra@lboro.ac.uk
FU National Key R&D Program of China [2018YFC1504704]; Science and Technology Major Project of Gansu Province [19ZD2FA002]; Program for International S&T Cooperation Projects of Gansu Province [2018-0204-GJC0043]; Fundamental Research Funds for the Central Universities [lzujbky-2018-46]; Key Research and Development Program of Gansu Province [18YF1WA114]
CR Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   Alvioli MA, 2020, GEOMORPHOLOGY, V358, P0, DOI 10.1016/j.geomorph.2020.107124
   [Anonymous], 2000, TERRAIN ANAL PRINCIP, V0, P0
   Ayalew L, 2004, LANDSLIDES, V1, P73, DOI 10.1007/s10346-003-0006-9
   Baeza C, 2001, EARTH SURF PROC LAND, V26, P1251, DOI 10.1002/esp.263
   Begueria S, 2006, GEOMORPHOLOGY, V74, P196, DOI 10.1016/j.geomorph.2005.07.018
   Pham BT, 2017, CATENA, V149, P52, DOI 10.1016/j.catena.2016.09.007
   Bisong E., 2019, BUILDING MACHINE LEA, V0, PP59, DOI 10.1007/978-1-4842-4470-8_7
   Brezny M, 2017, GEOMORPHOLOGY, V285, P44, DOI 10.1016/j.geomorph.2017.02.007
   Burnett BN, 2008, J GEOPHYS RES-EARTH, V113, P0, DOI 10.1029/2007JF000789
   Carlini M, 2018, LANDSLIDES, V15, P283, DOI 10.1007/s10346-017-0871-2
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen H, 2006, GEOMORPHOLOGY, V77, P112, DOI 10.1016/j.geomorph.2006.01.002
   Clague J.J., 2012, LANDSLIDES TYPES MEC, V0, P159
   COOPER ARTHUR W., 1960, SOIL SCI, V90, P109, DOI 10.1097/00010694-196008000-00007
   Dai FC, 2003, INT J REMOTE SENS, V24, P4817, DOI 10.1080/014311601131000082424
   Demir G, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104211
   Di Napoli M, 2020, LANDSLIDES, V17, P1897, DOI 10.1007/s10346-020-01392-9
   DIJKSTRA TA, 1994, ENG GEOL, V36, P153, DOI 10.1016/0013-7952(94)90001-9
   Fustos I, 2020, NAT HAZARDS, V102, P115, DOI 10.1007/s11069-020-03913-0
   Gallart F., 1988, GEOMORPHIC PROCESSES, V2, P79
   Gariano SL, 2016, EARTH-SCI REV, V162, P227, DOI 10.1016/j.earscirev.2016.08.011
   Glenn NF, 2006, GEOMORPHOLOGY, V73, P131, DOI 10.1016/j.geomorph.2005.07.006
   Goetz JN, 2015, COMPUT GEOSCI-UK, V81, P1, DOI 10.1016/j.cageo.2015.04.007
   [郭富赟 Guo Fuyun], 2015, 山地学报 MOUNTAIN RESEARCH, V33, P100
   Guzzetti F, 2005, GEOMORPHOLOGY, V72, P272, DOI 10.1016/j.geomorph.2005.06.002
   Guzzetti F, 2004, ENG GEOL, V73, P229, DOI 10.1016/j.enggeo.2004.01.006
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Haneberg WC, 2009, B ENG GEOL ENVIRON, V68, P263, DOI 10.1007/s10064-009-0204-3
   Hong Y, 2006, GEOPHYS RES LETT, V33, P0, DOI 10.1029/2006GL028010
   [黄润秋 HUANG Runqiu], 2007, 岩石力学与工程学报 CHINESE JOURNAL OF ROCK MECHANICS AND ENGINEERING, V26, P433
   Hussein J, 1998, GEODERMA, V85, P63, DOI 10.1016/S0016-7061(98)00014-7
   Kanungo DP, 2014, LANDSLIDES, V11, P629, DOI 10.1007/s10346-013-0438-9
   KEEFER DK, 1984, GEOL SOC AM BULL, V95, P406, DOI 10.1130/0016-7606(1984)95<406:LCBE>2.0.CO;2
   Kirschbaum D., 2014, LANDSLIDE SCI SAFER, V0, PP809, DOI 10.1007/978-3-319-05050-8_125
   Korup O, 2005, LANDSLIDES, V2, P43, DOI 10.1007/s10346-004-0042-0
   Larsen IJ, 2012, NAT GEOSCI, V5, P468, DOI 10.1038/ngeo1479
   Marc O, 2018, EARTH SURF DYNAM, V6, P903, DOI 10.5194/esurf-6-903-2018
   Marjanovic M, 2011, ENG GEOL, V123, P225, DOI 10.1016/j.enggeo.2011.09.006
   Mishra BK, 2018, NAT HAZARDS, V92, P673, DOI 10.1007/s11069-018-3219-x
   Nefeslioglu HA, 2008, GEOMORPHOLOGY, V94, P401, DOI 10.1016/j.geomorph.2006.10.036
   Nevo E, 1999, ISR J PLANT SCI, V47, P49, DOI 10.1080/07929978.1999.10676751
   OKIMURA T, 1983, P JAPAN SOC CIVIL EN, V338, P131
   Owen LA, 2008, GEOMORPHOLOGY, V94, P1, DOI 10.1016/j.geomorph.2007.04.007
   Oyagi N., 1984, P 4 INT S LANDSL TOR, V0, P1
   Palladino MR, 2018, GEOMORPHOLOGY, V303, P53, DOI 10.1016/j.geomorph.2017.11.009
   Pandey P, 2019, GEOMORPHOLOGY, V340, P103, DOI 10.1016/j.geomorph.2019.05.001
   Panek T, 2019, GEOMORPHOLOGY, V346, P0, DOI 10.1016/j.geomorph.2019.106852
   Panek T, 2011, LANDSLIDES, V8, P507, DOI 10.1007/s10346-011-0268-6
   Passalacqua P, 2010, WATER RESOUR RES, V46, P0, DOI 10.1029/2009WR008812
   Peng JB, 2015, ENG GEOL, V186, P79, DOI 10.1016/j.enggeo.2014.08.015
   Pires LF, 2005, NUCL INSTRUM METH B, V229, P443, DOI 10.1016/j.nimb.2004.12.118
   Pradhan B, 2010, LANDSLIDES, V7, P13, DOI 10.1007/s10346-009-0183-2
   Qing F, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182933
   REID ME, 1992, WATER RESOUR RES, V28, P939, DOI 10.1029/91WR02695
   ROMANOWICZ B, 1993, SCIENCE, V260, P1923, DOI 10.1126/science.260.5116.1923
   Roy J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232866
   Saha AK, 2005, LANDSLIDES, V2, P61, DOI 10.1007/s10346-004-0039-8
   Santangelo M, 2010, NAT HAZARD EARTH SYS, V10, P2539, DOI 10.5194/nhess-10-2539-2010
   Sato HP, 2009, LANDSLIDES, V6, P153, DOI 10.1007/s10346-009-0147-6
   Stokes A, 2009, PLANT SOIL, V324, P1, DOI 10.1007/s11104-009-0159-y
   Sun P, 2019, B ENG GEOL ENVIRON, V78, P4363, DOI 10.1007/s10064-018-1420-5
   Tanyas H, 2019, EARTH SURF PROC LAND, V44, P900, DOI 10.1002/esp.4543
   Tarolli P, 2006, HYDROL EARTH SYST SC, V10, P663, DOI 10.5194/hess-10-663-2006
   Tarolli P, 2012, NAT HAZARDS, V61, P65, DOI 10.1007/s11069-010-9695-2
   Tsou CY, 2015, ENG GEOL, V196, P126, DOI 10.1016/j.enggeo.2015.07.005
   Wang JJ, 2014, LANDSLIDES, V11, P141, DOI 10.1007/s10346-013-0418-0
   Wang Z., 1994, INT J ROCK MECH MIN, V31, P259
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   [薛文鹏 Xue Wenpeng], 2003, 西北农林科技大学学报. 自然科学版 JOURNAL OF NORTHWEST SCI-TECH UNIVERSITY OF AGRICULTURE AND FORESTRY, V31, P27
   Yamagishi H, 2007, LANDSLIDES, V4, P389, DOI 10.1007/s10346-007-0093-0
   Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002
   Zaruba Q., 1969, LANDSLIDES THEIR CON, V0, P236
   Zhao Y, 2020, GEOMORPHOLOGY, V359, P0, DOI 10.1016/j.geomorph.2020.107125
NR 74
TC 12
Z9 12
U1 9
U2 47
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY 15
PY 2021
VL 13
IS 9
BP 
EP 
DI 10.3390/rs13091819
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SC5VN
UT WOS:000650738500001
DA 2023-04-26
ER

PT J
AU Yu, SS
   Wang, C
   Yu, ZL
   Li, X
   Cheng, M
   Zang, Y
AF Yu, Shangshu
   Wang, Cheng
   Yu, Zenglei
   Li, Xin
   Cheng, Ming
   Zang, Yu
TI Deep regression for LiDAR-based localization in dense urban areas
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE LiDAR-based localization; Deep regression; Multi-task learning; Residual connection; Inter-task constraint loss
ID registration; histograms; efficient
AB LiDAR-based localization in a city-scale map is a fundamental question in autonomous driving research. As a reasonable localization scheme, the localization can be performed by global retrieval (that suggests potential candidates from the database) followed by geometric registration (that obtains an accurate relative pose). In this work, we develop a novel end-to-end, deep multi-task network that simultaneously performs global retrieval and geometric registration for LiDAR-based localization. Both retrieval and registration are formulated and solved as regression problems, and they can be deployed independently during inference time. We also design two mechanisms to enhance our multi-task regression network's performance: residual connections for point clouds and a new loss function with learnable parameters. To alleviate the common phenomenon of vanishing gradients in neural networks, we employ residual connections to support constructing a deeper network effectively. At the same time, to solve the problem of huge differences in scale and units between different tasks, we propose a loss function that can automatically balance multi-tasks. Experiments on two public benchmarks validate the state-of-the-art performance of our algorithm in large-scale LiDAR-based localization.
C1 [Yu, Shangshu; Wang, Cheng; Yu, Zenglei; Cheng, Ming; Zang, Yu] Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart Cities, 422 Siming Rd South, Xiamen 361005, Peoples R China.
   [Yu, Shangshu; Wang, Cheng; Yu, Zenglei; Cheng, Ming; Zang, Yu] Xiamen Univ, Digital Fujian Inst Urban Traff Big Data Res, Xiamen, Peoples R China.
   [Li, Xin] Louisiana State Univ, Sch Elect Engn & Comp Sci, Baton Rouge, LA USA.
C3 Xiamen University; Xiamen University; Louisiana State University System; Louisiana State University
RP Wang, C (corresponding author), Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart Cities, 422 Siming Rd South, Xiamen 361005, Peoples R China.
EM cwang@xmu.edu.cn
FU National Natural Science Foundation of China (NSFC) [U1605254]
CR Aoki Y, 2019, PROC CVPR IEEE, V0, PP7156, DOI 10.1109/CVPR.2019.00733
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI 10.1109/CVPR.2016.572
   Arandjelovic R, 2013, PROC CVPR IEEE, V0, PP1578, DOI 10.1109/CVPR.2013.207
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bresson G, 2017, IEEE T INTELL VEHICL, V2, P194, DOI 10.1109/TIV.2017.2749181
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Campbell D, 2015, IEEE I CONF COMP VIS, V0, PP4292, DOI 10.1109/ICCV.2015.488
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638
   Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, V0, P15, DOI 10.1109/ISWC.2008.4911577
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Ding MY, 2019, IEEE I CONF COMP VIS, V0, PP2871, DOI 10.1109/ICCV.2019.00296
   Dube R, 2020, INT J ROBOT RES, V39, P339, DOI 10.1177/0278364919863090
   Elbaz G, 2017, PROC CVPR IEEE, V0, PP2472, DOI 10.1109/CVPR.2017.265
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), V0, PP231, DOI 10.1109/IROS.2016.7759060
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Jegou H, 2010, PROC CVPR IEEE, V0, PP3304, DOI 10.1109/CVPR.2010.5540039
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kendall A, 2017, PROC CVPR IEEE, V0, PP6555, DOI 10.1109/CVPR.2017.694
   Kim G, 2018, IEEE INT C INT ROBOT, V0, PP4802, DOI 10.1109/IROS.2018.8593953
   Kim H, 2017, IEEE ROBOT AUTOM LET, V2, P1518, DOI 10.1109/LRA.2017.2673868
   Klein George, 2007, P1, V0, P0
   Li W, 2020, ISPRS J PHOTOGRAMM, V163, P284, DOI 10.1016/j.isprsjprs.2020.01.021
   Liu XY, 2019, PROC CVPR IEEE, V0, PP529, DOI 10.1109/CVPR.2019.00062
   Lu WX, 2019, IEEE I CONF COMP VIS, V0, PP12, DOI 10.1109/ICCV.2019.00010
   Lu WX, 2019, PROC CVPR IEEE, V0, PP6382, DOI 10.1109/CVPR.2019.00655
   Lucas B. D., 1981, P 7 INT JOINT C ART, V0, P0
   Ma Y, 2016, RULE LAW CHINA COMPA, V0, P1
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Middelberg S, 2014, LECT NOTES COMPUT SC, V8690, P268, DOI 10.1007/978-3-319-10605-2_18
   Ott F., 2020, PROC IEEECVF C COMPU, V0, P42
   Paszke A, 2019, ADV NEUR IN, V32, P0
   PHAM QH, 2020, AAAI C ART INT, V0, P0
   Qi C. R., 2017, ADV NEURAL INFORM PR, V0, P5099
   Rozenberszki D, 2020, IEEE INT CONF ROBOT, V0, PP4379, DOI 10.1109/ICRA40945.2020.9197450
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, P0
   Rusu RB, 2009, IEEE INT CONF ROBOT, V0, P1848
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Sarlin PE, 2019, PROC CVPR IEEE, V0, PP12708, DOI 10.1109/CVPR.2019.01300
   Sattler T, 2018, PROC CVPR IEEE, V0, PP8601, DOI 10.1109/CVPR.2018.00897
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662
   Schonberger JL, 2018, PROC CVPR IEEE, V0, PP6896, DOI 10.1109/CVPR.2018.00721
   Steder B., 2010, WORKSH DEF SOLV REAL, V0, P0
   Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331
   Tang L, 2019, AUTON ROBOT, V43, P197, DOI 10.1007/s10514-018-9724-7
   Uy MA, 2018, PROC CVPR IEEE, V0, PP4470, DOI 10.1109/CVPR.2018.00470
   Wang B., 2020, 34 AAAI C ART INT, V0, P0
   WU ZR, 2015, PROC CVPR IEEE, V0, PP1912, DOI 10.1109/CVPR.2015.7298801
   Yang N, 2020, PROC CVPR IEEE, V0, PP1278, DOI 10.1109/CVPR42600.2020.00136
   Yang YQ, 2018, PROC CVPR IEEE, V0, PP206, DOI 10.1109/CVPR.2018.00029
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Zeng A, 2017, PROC CVPR IEEE, V0, PP199, DOI 10.1109/CVPR.2017.29
   Zhang J., 2014, ROBOTICS SCI SYSTEMS, V10, P0
   Zhang WX, 2019, PROC CVPR IEEE, V0, PP12428, DOI 10.1109/CVPR.2019.01272
NR 55
TC 6
Z9 6
U1 5
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD FEB 15
PY 2021
VL 172
IS 
BP 240
EP 252
DI 10.1016/j.isprsjprs.2020.12.013
EA JAN 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PV7TY
UT WOS:000610187300016
DA 2023-04-26
ER

PT J
AU Shafizadeh-Moghadam, H
   Khazaei, M
   Alavipanah, SK
   Weng, QH
AF Shafizadeh-Moghadam, Hossein
   Khazaei, Morteza
   Alavipanah, Seyed Kazem
   Weng, Qihao
TI Google Earth Engine for large-scale land use and land cover mapping: an object-based classification approach using spectral, textural and topographical factors
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Land use and land cover; simple non-iterative clustering; multi-temporal NDVI; topographic data; arid and semi-arid region mapping; climate zones
ID neural-network; climate; accuracy; dynamics; index
AB Mapping the distribution and type of land use and land cover (LULC) is essential for watershed management. The Tigris-Euphrates basin is a transboundary region in the Middle East shared between six countries, but a recent fine-scale LULC map of the area is lacking. Using Landsat-8 time series, a 30-m resolution LULC map was produced for the Tigris-Euphrates basin. In total, 1184 Landsat scenes were processed within the Google Earth Engine (GEE). For the collection of ground truth data, differential manifestations of green cover were considered by dividing the study area into five climatic regions and the training samples were taken from each sub-region. To account for the temporal variation of LULC types, six two-month interval composite layers, including the spectral and thermal bands of Landsat-8, texture and spectral indices, as well as topographic factors were created for the target year 2019. Image segmentation and classification were performed using the simple non-iterative clustering (SNIC) and Random Forest (RF) algorithms, respectively. A computationally effective parallel processing approach was developed, which created a number of tiles and sub-tiles and a bulk command was converted into smaller parallel commands. The generated LULC map showed a satisfactory overall accuracy of 91.7%, with the highest User's accuracy in water and wetland, and the lowest in rainfed crop and rangeland and the highest Producer's accuracy in water and barren areas, and the lowest in garden and rangeland. This study highlights the necessity of using multi-temporal data for LULC mapping, in particular, multi-temporal NDVI, for the separation of different green cover types in arid and semi-arid environment.
C1 [Shafizadeh-Moghadam, Hossein] Tarbiat Modares Univ, Dept Water Engn & Management, Tehran, Iran.
   [Khazaei, Morteza; Alavipanah, Seyed Kazem] Univ Tehran, Fac Geog, Dept Remote Sensing & GIS, Tehran, Iran.
   [Weng, Qihao] Indiana State Univ, Ctr Urban & Environm Change, Dept Earth & Environm Syst, Terre Haute, IN 47809 USA.
C3 Tarbiat Modares University; University of Tehran; Indiana State University
RP Shafizadeh-Moghadam, H (corresponding author), Tarbiat Modares Univ, Dept Water Engn & Management, Tehran, Iran.
EM h_shafizadeh@modares.ac.ir
CR Al-Asadi SAR., 2017, J GEOGR GEOLO, V9, P24, DOI 10.5539/JGG.V9N2P24
   Amani M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070842
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Breuer L, 2009, ADV WATER RESOUR, V32, P129, DOI 10.1016/j.advwatres.2008.10.003
   Chen WT, 2014, REMOTE SENS ENVIRON, V152, P291, DOI 10.1016/j.rse.2014.07.004
   Cochran W., 1953, SAMPLING TECHNIQUES, V0, P0
   Daughtry CST, 2006, SOIL TILL RES, V91, P101, DOI 10.1016/j.still.2005.11.013
   Foody GM, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111630
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Ghorbanian A, 2020, ISPRS J PHOTOGRAMM, V167, P276, DOI 10.1016/j.isprsjprs.2020.07.013
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Gumma MK, 2020, GISCI REMOTE SENS, V57, P302, DOI 10.1080/15481603.2019.1690780
   Hall-Beyer M, 2017, INT J REMOTE SENS, V38, P1312, DOI 10.1080/01431161.2016.1278314
   Hansen MC, 2013, SCIENCE, V342, P850, DOI 10.1126/science.1244693
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   Issa I., 2013, HYDROL EARTH SYST SC, V10, P14617, DOI 10.5194/hessd-10-14617-2013
   Jensen J.R., 2015, INTRO IMAGE PROCESSI, V0, P0
   Jia K, 2014, ISPRS J PHOTOGRAMM, V93, P49, DOI 10.1016/j.isprsjprs.2014.04.004
   Kottek M, 2006, METEOROL Z, V15, P259, DOI 10.1127/0941-2948/2006/0130
   Kuhn M., 2013, APPL PREDICTIVE MODE, V0, P0, DOI DOI 10.1007/978-1-4614-6849-3
   Lambin EF, 2001, GLOBAL ENVIRON CHANG, V11, P261, DOI 10.1016/S0959-3780(01)00007-3
   Lambin EF, 2010, LAND USE POLICY, V27, P108, DOI 10.1016/j.landusepol.2009.09.003
   Li F, 2018, ECOSYST SERV, V31, P12, DOI 10.1016/j.ecoser.2018.03.009
   Li KW, 2020, GISCI REMOTE SENS, V57, P1026, DOI 10.1080/15481603.2020.1841489
   Liu XP, 2020, NAT SUSTAIN, V3, P564, DOI 10.1038/s41893-020-0521-x
   Liu XP, 2018, REMOTE SENS ENVIRON, V209, P227, DOI 10.1016/j.rse.2018.02.055
   Long TF, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050489
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Mahdianpari M, 2020, GISCI REMOTE SENS, V57, P1102, DOI 10.1080/15481603.2020.1846948
   Mahdianpari M, 2020, CAN J REMOTE SENS, V46, P360, DOI 10.1080/07038992.2020.1802584
   Oliphant AJ, 2019, INT J APPL EARTH OBS, V81, P110, DOI 10.1016/j.jag.2018.11.014
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Peng Gong, 2016, ANNALS OF GIS, V22, P87, DOI 10.1080/19475683.2016.1164247
   Phalke AR, 2020, ISPRS J PHOTOGRAMM, V167, P104, DOI 10.1016/j.isprsjprs.2020.06.022
   Noi PT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010018
   Pielke RA, 2005, SCIENCE, V310, P1625, DOI 10.1126/science.1120529
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Rodriguez-Galiano VF, 2012, REMOTE SENS ENVIRON, V121, P93, DOI 10.1016/j.rse.2011.12.003
   Rubel F, 2017, METEOROL Z, V26, P115, DOI 10.1127/metz/2016/0816
   Rubel F, 2010, METEOROL Z, V19, P135, DOI 10.1127/0941-2948/2010/0430
   Sbafizadeh-Moghadam H, 2019, INT J APPL EARTH OBS, V78, P240, DOI 10.1016/j.jag.2019.01.003
   Serra P, 2014, APPL GEOGR, V55, P71, DOI 10.1016/j.apgeog.2014.09.005
   Shao Y, 2012, ISPRS J PHOTOGRAMM, V70, P78, DOI 10.1016/j.isprsjprs.2012.04.001
   Shetty S, 2019, THESIS U TWENTE ENSC, V0, P0
   Song XF, 2012, INT J REMOTE SENS, V33, P3301, DOI 10.1080/01431161.2011.568531
   Tamiminia H, 2020, ISPRS J PHOTOGRAMM, V164, P152, DOI 10.1016/j.isprsjprs.2020.04.001
   Valavi R, 2019, METHODS ECOL EVOL, V10, P225, DOI 10.1111/2041-210X.13107
   Whiteside TG, 2011, INT J APPL EARTH OBS, V13, P884, DOI 10.1016/j.jag.2011.06.008
   Xie YH, 2019, ISPRS J PHOTOGRAMM, V155, P136, DOI 10.1016/j.isprsjprs.2019.07.005
   Xiong J, 2017, ISPRS J PHOTOGRAMM, V126, P225, DOI 10.1016/j.isprsjprs.2017.01.019
   Yuan H, 2009, REMOTE SENS-BASEL, V1, P243, DOI 10.3390/rs1030243
   Zha Y, 2003, INT J REMOTE SENS, V24, P583, DOI 10.1080/01431160304987
   Zhang L, 2016, ISPRS J PHOTOGRAMM, V113, P86, DOI 10.1016/j.isprsjprs.2016.01.003
   Zurqani HA, 2018, INT J APPL EARTH OBS, V69, P175, DOI 10.1016/j.jag.2017.12.006
NR 56
TC 18
Z9 18
U1 12
U2 51
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD AUG 18
PY 2021
VL 58
IS 6
BP 914
EP 928
DI 10.1080/15481603.2021.1947623
EA JUL 2021
PG 15
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA UR5NM
UT WOS:000677763600001
DA 2023-04-26
ER

PT J
AU Aeberli, A
   Johansen, K
   Robson, A
   Lamb, DW
   Phinn, S
AF Aeberli, Aaron
   Johansen, Kasper
   Robson, Andrew
   Lamb, David W.
   Phinn, Stuart
TI Detection of Banana Plants Using Multi-Temporal Multispectral UAV Imagery
SO REMOTE SENSING
LA English
DT Article
DE unoccupied aerial vehicle; UAV; banana plant; geographic object-based image analysis; convolutional neural network; CNN; template matching; local maximum filter
ID tree crown detection; unmanned aircraft systems; vegetation index; canopy structure; delineation; classification; segmentation; reflectance; plantations; phenology
AB Unoccupied aerial vehicles (UAVs) have become increasingly commonplace in aiding planning and management decisions in agricultural and horticultural crop production. The ability of UAV-based sensing technologies to provide high spatial (<1 m) and temporal (on-demand) resolution data facilitates monitoring of individual plants over time and can provide essential information about health, yield, and growth in a timely and quantifiable manner. Such applications would be beneficial for cropped banana plants due to their distinctive growth characteristics. Limited studies have employed UAV data for mapping banana crops and to our knowledge only one other investigation features multi-temporal detection of banana crowns. The purpose of this study was to determine the suitability of multiple-date UAV-captured multi-spectral data for the automated detection of individual plants using convolutional neural network (CNN), template matching (TM), and local maximum filter (LMF) methods in a geographic object-based image analysis (GEOBIA) software framework coupled with basic classification refinement. The results indicate that CNN returns the highest plant detection accuracies, with the developed rule set and model providing greater transferability between dates (F-score ranging between 0.93 and 0.85) than TM (0.86-0.74) and LMF (0.86-0.73) approaches. The findings provide a foundation for UAV-based individual banana plant counting and crop monitoring, which may be used for precision agricultural applications to monitor health, estimate yield, and to inform on fertilizer, pesticide, and other input requirements for optimized farm management.
C1 [Aeberli, Aaron; Robson, Andrew] Univ New England, Sch Sci & Technol, Appl Agr Remote Sensing Ctr, Armidale, NSW 2351, Australia.
   [Aeberli, Aaron; Phinn, Stuart] Univ Queensland, Sch Earth & Environm Sci, Remote Sensing Res Ctr, St Lucia, Qld 4072, Australia.
   [Johansen, Kasper] King Abdullah Univ Sci & Technol, Water Desalinat & Reuse Ctr, Hydrol Agr & Land Observat, Thuwal 239556900, Saudi Arabia.
   [Lamb, David W.] Food Agil Cooperat Res Ctr Ltd, 81 Broadway, Ultimo, NSW 2007, Australia.
   [Lamb, David W.] Univ New England, Precis Agr Res Grp, Armidale, NSW 2351, Australia.
C3 University of New England; University of Queensland; King Abdullah University of Science & Technology; University of New England
RP Aeberli, A (corresponding author), Univ New England, Sch Sci & Technol, Appl Agr Remote Sensing Ctr, Armidale, NSW 2351, Australia.; Aeberli, A (corresponding author), Univ Queensland, Sch Earth & Environm Sci, Remote Sensing Res Ctr, St Lucia, Qld 4072, Australia.
EM aaeberli@myune.edu.au; kasper.johansen@kaust.edu.sa; andrew.robson@une.edu.au; dave.lamb@foodagility.com; s.phinn@uq.edu.au
FU Horticulture Innovation; Department of Agriculture and Water Resources, Australian Government,Rural R&D for Profit Program's subproject "Multi-Scale Monitoring Tools for Managing Australia Tree Crops-Industry Meets Innovation
CR BARKER WG, 1962, ANN BOT-LONDON, V26, P413, DOI 10.1093/oxfordjournals.aob.a083803
   Basso B, 2016, PRECIS AGRIC, V17, P168, DOI 10.1007/s11119-015-9414-9
   Blozan W., 2006, B E NATIV TREE SOC, V1, P3
   Bolton DK, 2013, AGR FOREST METEOROL, V173, P74, DOI 10.1016/j.agrformet.2013.01.007
   Bouwman AF, 2017, SCI REP-UK, V7, P0, DOI 10.1038/srep40366
   Bunting P, 2006, REMOTE SENS ENVIRON, V101, P230, DOI 10.1016/j.rse.2005.12.015
   Bureau of Meteorology, 2019, CLIM STAT AUSTR LOC, V0, P0
   Chlingaryan A, 2018, COMPUT ELECTRON AGR, V151, P61, DOI 10.1016/j.compag.2018.05.012
   Clark A, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10062017
   Csillik O, 2018, DRONES-BASEL, V2, P0, DOI 10.3390/drones2040039
   Erikson M, 2005, MACH VISION APPL, V16, P258, DOI 10.1007/s00138-005-0180-y
   Gitelson AA, 1996, J PLANT PHYSIOL, V148, P501, DOI 10.1016/S0176-1617(96)80285-9
   Good AG, 2011, PLOS BIOL, V9, P0, DOI 10.1371/journal.pbio.1001124
   Handique B.K., 2020, INT ARCH PHOTOGRAMME, VXLIII-B3-2020, P67, DOI 10.5194/isprs-archives-XLIII-B3-2020-67-2020
   Harto A. B., 2019, HAYATI JOURNAL OF BIOSCIENCES, V26, P7
   Jiang ZY, 2008, REMOTE SENS ENVIRON, V112, P3833, DOI 10.1016/j.rse.2008.06.006
   Johansen K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060854
   Johansen K, 2014, REMOTE SENS-BASEL, V6, P8261, DOI 10.3390/rs6098261
   Johansen K, 2009, PHOTOGRAMM ENG REM S, V75, P1069, DOI 10.14358/PERS.75.9.1069
   Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436
   Ke YH, 2011, INT J REMOTE SENS, V32, P4725, DOI 10.1080/01431161.2010.494184
   Kestur R, 2018, J INDIAN SOC REMOTE, V46, P991, DOI 10.1007/s12524-018-0756-4
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   KNIPLING E B, 1970, REMOTE SENSING OF ENVIRONMENT, V1, P155
   Lamar WR, 2005, REMOTE SENS ENVIRON, V94, P133, DOI 10.1016/j.rse.2004.09.003
   Lamour J, 2021, PRECIS AGRIC, V22, P873, DOI 10.1007/s11119-020-09762-y
   Lamour J., 2019, PRECISION AGR 19, V0, P407
   Larsen M, 1998, PATTERN RECOGN LETT, V19, P1153, DOI 10.1016/S0167-8655(98)00092-0
   Larsen M, 2011, INT J REMOTE SENS, V32, P5827, DOI 10.1080/01431161.2010.507790
   Li WJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010011
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Maes WH, 2019, TRENDS PLANT SCI, V24, P152, DOI 10.1016/j.tplants.2018.11.007
   Mahlein AK, 2016, PLANT DIS, V100, P241, DOI 10.1094/PDIS-03-15-0340-FE
   McCarthy, 2004, AGRILINK SERIES, VQI04011, P0
   Memon N., 2005, INTERNATIONAL JOURNAL OF AGRICULTURE AND BIOLOGY, V7, P824
   Neupane B, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0223906
   Norzaki N, 2019, INT J REMOTE SENS, V40, P7477, DOI 10.1080/01431161.2018.1524182
   Picq C., 1999, BANANAS FOOD SECURIT, V0, P0
   PINZ AJ, 1991, NASA CONF P, V3099, P111
   Pollock R. J., 1994, PROCEEDINGS OF THE SPIE - THE INTERNATIONAL SOCIETY FOR OPTICAL ENGINEERING, V2315, P526, DOI 10.1117/12.196753
   Pouliot DA, 2002, REMOTE SENS ENVIRON, V82, P322, DOI 10.1016/S0034-4257(02)00050-0
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scott GJ, 2021, INT J FOOD SCI TECH, V56, P1093, DOI 10.1111/ijfs.14778
   Selvaraj MG, 2020, ISPRS J PHOTOGRAMM, V169, P110, DOI 10.1016/j.isprsjprs.2020.08.025
   Sims DA, 2002, REMOTE SENS ENVIRON, V81, P337, DOI 10.1016/S0034-4257(02)00010-X
   Soares J. D. R., 2012, AFRICAN JOURNAL OF BIOTECHNOLOGY, V11, P10682
   Susic N, 2018, SENSOR ACTUAT B-CHEM, V273, P842, DOI 10.1016/j.snb.2018.06.121
   Swarupa V, 2014, PLANTA, V239, P735, DOI 10.1007/s00425-013-2024-8
   Tang YC, 2020, FRONT PLANT SCI, V11, P0, DOI 10.3389/fpls.2020.00510
   TAYLOR SE, 1972, ECOLOGY, V53, P143, DOI 10.2307/1935720
   Thomas DS, 2001, SCI HORTIC-AMSTERDAM, V90, P93, DOI 10.1016/S0304-4238(00)00260-0
   Torres-Sanchez J, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0130479
   Trimble, 2020, ECOGNITION DEV, V0, P0
   Tu YH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030269
   Tu YH, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111684
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Turner David W., 2007, BRAZ. J. PLANT PHYSIOL., V19, P463, DOI 10.1590/S1677-04202007000400013
   TURNER DW, 1983, AUST J PLANT PHYSIOL, V10, P43, DOI 10.1071/PP9830043
   TWYFORD IT, 1967, J SCI FOOD AGR, V18, P177, DOI 10.1002/jsfa.2740180501
   Vina A, 2004, AGRON J, V96, P1139, DOI 10.2134/agronj2004.1139
   Wang CY, 2015, IEEE J-STARS, V8, P1876, DOI 10.1109/JSTARS.2015.2422716
   Wang J, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17030538
   Watts AC, 2012, REMOTE SENS-BASEL, V4, P1671, DOI 10.3390/rs4061671
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111402
   Wu D, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101647
   Wu D, 2020, INT J APPL EARTH OBS, V89, P0, DOI 10.1016/j.jag.2020.102091
   Zenger-Landolt B., 2016, P GEOB 2016 SOL SYN, V0, P0
   Zou XC, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9100994
NR 73
TC 9
Z9 9
U1 5
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 15
PY 2021
VL 13
IS 11
BP 
EP 
DI 10.3390/rs13112123
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SQ8JG
UT WOS:000660595800001
DA 2023-04-26
ER

PT J
AU Wang, H
   Hu, J
   Fu, HQ
   Wang, CC
   Wang, ZH
AF Wang, Hai
   Hu, Jun
   Fu, Haiqiang
   Wang, Changcheng
   Wang, Zhenhai
TI A Novel Quality-Guided Two-Dimensional InSAR Phase Unwrapping Method via GAUNet
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Deep learning; Training; Strain; Coherence; Classification algorithms; Synthetic aperture radar; Optical sensors; 2-D phase unwrapping (2-D PU); ambiguity gradient; class imbalance; deep learning (DL); interferometric synthetic aperture radar (InSAR); quality-guided
ID convolutional neural-network; tutorial
AB Phase unwrapping (PU) has always been a critical and challenging step in interferometric synthetic aperture radar (InSAR) data processing. Inspired by existing research, i.e., the PGNet, we propose a novel quality-guided 2-D InSAR PU method via deep learning, and regard PU as a two-stage process. In the first stage, the ambiguity gradient is estimated using the proposed global attention U-Net (GAUNet) architecture, which combines the classic U-Net structure and global attention mechanism. Then, in the second stage, the classical PU framework (e.g., the L1- or L2-norm) is applied as a post-processing operation to retrieve the absolute phase. Since class imbalance is a key factor affecting the estimation of ambiguity gradient, different strategies based on four commonly used quality maps are adopted to deal with the problem. The quality map is not only input as additional information for the guidance of the training process, but also participates in the construction of loss function. As a result, GAUNet can pay more attention to the nonzero ambiguity gradients. By using the number of residues as the evaluation metric, we can choose the optimum strategy for the restoration of the absolute phase. In addition to the simulated interferograms, the proposed method is tested both on a real topographic interferogram exhibiting rugged topography and phase aliasing and a differential interferogram measuring the deformation from MW 6.9 Hawaii earthquake, all yield state-of-art performance when comparing with the widely used traditional 2-D PU methods.
C1 [Wang, Hai; Hu, Jun; Fu, Haiqiang; Wang, Changcheng; Wang, Zhenhai] Cent South Univ, Sch Geosci & Infophys, Changsha 410083, Peoples R China.
C3 Central South University
RP Hu, J (corresponding author), Cent South Univ, Sch Geosci & Infophys, Changsha 410083, Peoples R China.
EM csu_wangh@csu.edu.cn; csuhujun@csu.edu.cn; haiqiangfu@csu.edu.cn; wangchangcheng@csu.edu.cn; zhenhai.com@csu.edu.cn
FU National Natural Science Foundation of China [42030112]; Hunan Natural Science Foundation [2020JJ2043]; Project of Innovation-Driven Plan of Central South University [2019CX007]; Fundamental Research Funds for the Central Universities of Central South University [2021zzts0852]
CR Ahujia RK, 1993, NETWORK FLOWS THEORY, V0, P0
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P698, DOI 10.1109/TIP.2006.888351
   BONE DJ, 1991, APPL OPTICS, V30, P3627, DOI 10.1364/AO.30.003627
   Chen CW, 2001, J OPT SOC AM A, V18, P338, DOI 10.1364/JOSAA.18.000338
   Costantini M, 1998, IEEE T GEOSCI REMOTE, V36, P813, DOI 10.1109/36.673674
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.32
   Farr TG, 2007, REV GEOPHYS, V45, P0, DOI 10.1029/2005RG000183
   Flynn TJ, 1996, INT GEOSCI REMOTE SE, V0, PP2057, DOI 10.1109/IGARSS.1996.516887
   Ghiglia D. C., 1998, 2 DIMENSIONAL PHASE, V0, P0
   Ghiglia DC, 1996, J OPT SOC AM A, V13, P1999, DOI 10.1364/JOSAA.13.001999
   GHIGLIA DC, 1994, J OPT SOC AM A, V11, P107, DOI 10.1364/JOSAA.11.000107
   GOLDSTEIN RM, 1988, RADIO SCI, V23, P713, DOI 10.1029/RS023i004p00713
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   HUNTLEY JM, 1989, APPL OPTICS, V28, P3268, DOI 10.1364/AO.28.003268
   ITOH K, 1982, APPL OPTICS, V21, P2470, DOI 10.1364/AO.21.002470
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krieger G, 2007, IEEE T GEOSCI REMOTE, V45, P3317, DOI 10.1109/TGRS.2007.900693
   Lei T., 2020, MED IMAGE SEGMENTATI, V0, P0
   Li H, 2018, ARXIV180510180, V0, P0
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Liu CL, 2018, GEOPHYS RES LETT, V45, P9508, DOI 10.1029/2018GL079349
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Milletari F, 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Minaee S., 2020, ARXIV, V0, P0
   Moreira A, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2248301
   Oktay O, 2018, ARXIV180403999, V0, P0
   RODRIGUEZ E, 1992, IEE PROC-F, V139, P147, DOI 10.1049/ip-f-2.1992.0018
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sica F, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2020.3029565
   Spoorthi GE, 2020, IEEE T IMAGE PROCESS, V29, P4862, DOI 10.1109/TIP.2020.2977213
   Spoorthi GE, 2019, IEEE SIGNAL PROC LET, V26, P54, DOI 10.1109/LSP.2018.2879184
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Wang KQ, 2019, OPT EXPRESS, V27, P15100, DOI 10.1364/OE.27.015100
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xue FY, 2020, IEEE GEOSC REM SEN M, V8, P22, DOI 10.1109/MGRS.2019.2956165
   Yu HW, 2019, IEEE GEOSC REM SEN M, V7, P40, DOI 10.1109/MGRS.2018.2873644
   Yu HW, 2016, IEEE T GEOSCI REMOTE, V54, P5217, DOI 10.1109/TGRS.2016.2558541
   Zhang JC, 2019, OPT EXPRESS, V27, P14903, DOI 10.1364/OE.27.014903
   Zhang T, 2019, OPT EXPRESS, V27, P23173, DOI 10.1364/OE.27.023173
   Zhou LF, 2021, IEEE GEOSC REM SEN M, V9, P10, DOI 10.1109/MGRS.2021.3065811
   Zhou LF, 2020, IEEE T GEOSCI REMOTE, V58, P4653, DOI 10.1109/TGRS.2020.2965918
   Zhu XX, 2021, IEEE GEOSC REM SEN M, V9, P143, DOI 10.1109/MGRS.2020.3046356
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 50
TC 5
Z9 5
U1 11
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7840
EP 7856
DI 10.1109/JSTARS.2021.3099485
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UI2JZ
UT WOS:000690441600001
DA 2023-04-26
ER

PT J
AU Li, H
   Gong, MG
   Zhang, MY
   Wu, Y
AF Li, Hao
   Gong, Maoguo
   Zhang, Mingyang
   Wu, Yue
TI Spatially Self-Paced Convolutional Networks for Change Detection in Heterogeneous Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Training; Synthetic aperture radar; Optical sensors; Task analysis; Optical imaging; Image sensors; Speckle; Change detection; convolutional neural networks (CNNs); heterogeneous images; self-paced learning (SPL)
ID unsupervised change detection; remote-sensing images; statistical-model; framework
AB Change detection in heterogeneous remote sensing images is a challenging problem because it is hard to make a direct comparison in the original observation spaces, and most methods rely on a set of manually labeled samples. In this article, a spatially self-paced convolutional network (SSPCN) is constructed for change detection in an unsupervised way. Self-paced learning (SPL) is incorporated into convolutional networks to dynamically select reliable samples and learn the representation of the relations between the two heterogeneous images. In the proposed method, the pseudo labels are initialized by a classification-based method, and each sample is assigned to a weight to reflect the easiness of the sample. Then, SPL is used to learn the easy samples at first and then gradually take more complex samples into account. In the training process, the sample weights are dynamically updated based on the network parameters. Finally, a binary change map is acquired based on the trained convolutional network. The proposed SSPCN has three main advantages compared to the traditional methods. First, the proposed method is robust to noisy samples because the SSPCN involves the reliable samples into training. Second, the samples have different learning rates for converging to better values, and the learning rates are dynamically changed based on the current sample weights during iterations. Finally, we take the spatial information among the samples into account for further enhancing the robustness of the proposed method. Experimental results on four pairs of heterogeneous remote sensing images confirm the effectiveness of the proposed technique.
C1 [Li, Hao; Gong, Maoguo; Zhang, Mingyang] Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ China, Xian 710071, Peoples R China.
   [Wu, Yue] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
C3 Ministry of Education, China; Xidian University; Xidian University
RP Gong, MG (corresponding author), Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ China, Xian 710071, Peoples R China.
EM omegalihao@gmail.com; gong@ieee.org; OMEGAZhangMY@gmail.com; ywu@xidian.edu.cn
FU National Natural Science Foundation of China [61906146, 62036006]; Fundamental Research Funds for the Central Universities [JB210210]
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bengio Y., 2009, P 26 ANN INT C MACH, V0, P0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bujor F, 2004, IEEE T GEOSCI REMOTE, V42, P2073, DOI 10.1109/TGRS.2004.835304
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Gleich D, 2018, IEEE T GEOSCI REMOTE, V56, P6674, DOI 10.1109/TGRS.2018.2841191
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2014, IEEE T GEOSCI REMOTE, V52, P4328, DOI 10.1109/TGRS.2013.2281391
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   Hao M, 2014, IEEE GEOSCI REMOTE S, V11, P210, DOI 10.1109/LGRS.2013.2252879
   Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP547, DOI 10.1145/2647868.2654918
   Jiang L, 2015, AAAI CONF ARTIF INTE, V0, P2694
   Jiang L, 2014, ADV NEUR IN, V27, P0
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Kumar M. P., 2010, ADV NEURAL INFORM PR, V0, P1189
   Kumar MP, 2011, IEEE I CONF COMP VIS, V0, PP1800, DOI 10.1109/ICCV.2011.6126446
   Lee YJ, 2011, PROC CVPR IEEE, V0, PP1721, DOI 10.1109/CVPR.2011.5995523
   Li H, 2021, IEEE T CYBERNETICS, V51, P4187, DOI 10.1109/TCYB.2019.2935762
   Li H, 2016, AAAI CONF ARTIF INTE, V0, P1802
   Liang BQ, 2011, IEEE J-STARS, V4, P43, DOI 10.1109/JSTARS.2010.2060316
   Liu G, 2019, IEEE T GEOSCI REMOTE, V57, P3904, DOI 10.1109/TGRS.2018.2888985
   Liu SC, 2019, IEEE J-STARS, V12, P3578, DOI 10.1109/JSTARS.2019.2929514
   Liu ZG, 2014, IEEE GEOSCI REMOTE S, V11, P168, DOI 10.1109/LGRS.2013.2250908
   Meng DY, 2017, INFORM SCIENCES, V414, P319, DOI 10.1016/j.ins.2017.05.043
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Omati M, 2018, IEEE J-STARS, V11, P4170, DOI 10.1109/JSTARS.2018.2874517
   Prendes J, 2015, INT CONF ACOUST SPEE, V0, PP1513, DOI 10.1109/ICASSP.2015.7178223
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Shang R, 2018, SIGNAL PROCESS, V142, P375, DOI 10.1016/j.sigpro.2017.07.023
   Supancic JS, 2013, PROC CVPR IEEE, V0, PP2379, DOI 10.1109/CVPR.2013.308
   Tang Kevin, 2012, ADV NEURAL INFORM PR, V0, P638
   Tong XH, 2020, IEEE J-STARS, V13, P2056, DOI 10.1109/JSTARS.2020.2990481
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   Zhang DW, 2015, IEEE I CONF COMP VIS, V0, PP594, DOI 10.1109/ICCV.2015.75
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhao Q, 2015, AAAI CONF ARTIF INTE, V0, P3196
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 41
TC 11
Z9 11
U1 3
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4966
EP 4979
DI 10.1109/JSTARS.2021.3078437
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SN5OZ
UT WOS:000658340100006
DA 2023-04-26
ER

PT J
AU Rong, SA
   He, LN
   Du, L
   Li, ZY
   Yu, SW
AF Rong, Shuaiang
   He, Lina
   Du, Liang
   Li, Zuyi
   Yu, Shiwen
TI Intelligent Detection of Vegetation Encroachment of Power Lines With Advanced Stereovision
SO IEEE TRANSACTIONS ON POWER DELIVERY
LA English
DT Article
DE Vegetation mapping; Vegetation; Monitoring; Three-dimensional displays; Transforms; Inspection; Poles and towers; Deep learning; digital image; hough transform; power lines; stereovision; short circuit fault; vegetation management
ID transmission-lines; inspection; system
AB Vegetation encroaching on overhead power lines can cause short circuit faults and pose a major threat to the security and stability of power grids. Therefore, establishing an effective visual detection algorithm to oversee potential circuit failures of the power lines is critical to the ongoing inspection of vegetation encroachment. This paper establishes a deep learning-based detection framework that utilizes the images obtained from vision sensors mounted on power transmission towers. The proposed detection framework includes three cascaded modules: (1) detection of vegetation regions based on the Faster Region Convolution Neural Network (Faster R-CNN), (2) detection of power lines based on the Hough transform, and (3) detection of vegetation encroachment based on an advanced stereovision (SV) algorithm. In particular, the proposed SV algorithm converts the detected two-dimensional (2D) image data of the vegetation and power lines to three-dimensional (3D) height and location results in order to obtain precise geographical locations. Case studies using field captured images provided by a Transmission System Operator (TSO) demonstrate the effectiveness of the proposed framework in detecting vegetation failures, thus improving overall reliability and reducing economic loss.
C1 [Rong, Shuaiang; He, Lina; Yu, Shiwen] Univ Illinois, Elect & Comp Engn Dept, Chicago, IL 60607 USA.
   [Du, Liang] Temple Univ, Elect & Comp Engn Dept, Philadelphia, PA 19122 USA.
   [Li, Zuyi] IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
C3 University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Illinois Institute of Technology
RP He, LN (corresponding author), Univ Illinois, Elect & Comp Engn Dept, Chicago, IL 60607 USA.
EM srong4@uic.edu; lhe@uic.edu; ldu@temple.edu; lizu@iit.edu; syu65@uic.edu
CR Ahmad J, 2013, ELECTR POW SYST RES, V95, P339, DOI 10.1016/j.epsr.2012.07.015
   Anagnostatos SD, 2011, IEEE T POWER DELIVER, V26, P2053, DOI 10.1109/TPWRD.2011.2123471
   [Anonymous], 2016, PROD BROCH DS 2DE42, V0, P0
   [Anonymous], 2008, FUT INSP OV TRANSM L, V0, P0
   [Anonymous], 2012, REQUIREMENTS ALL LIN, V0, P0
   Ashidate S, 2002, IEEE T POWER DELIVER, V17, P644, DOI 10.1109/61.997953
   Babinec A., 2016, INT J T SCI TECH, V5, P152
   Baker L, 2016, INT CONF IMAG VIS, V0, P134
   Boyd S., 2004, CONVEX OPTIMIZATION, V0, P0, DOI DOI 10.1017/CBO9780511804441
   Cottini N, 2011, IEEE J EM SEL TOP C, V1, P299, DOI 10.1109/JETCAS.2011.2167072
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fateh B, 2013, IEEE T SMART GRID, V4, P1076, DOI 10.1109/TSG.2013.2241796
   Gugel H, 2018, IEEE POW ENER SOC GE, V0, P0
   Ise T., 2018, AUTOMATIC CLASSIFICA, V0, P0
   Krizhevsky Alex, 2009, TECHNICAL REPORT, V0, P0
   Kurinsky B., 2015, INT J RES GEOGR, V1, P38
   Le Zhen-chun, 2014, EAST CHINA ELECTRIC POWER, V42, P61
   Li H, 2005, P IEEE, V93, P918, DOI 10.1109/JPROC.2005.847260
   Li QW, 2017, COMPUT MATH METHOD M, V2017, P0, DOI 10.1155/2017/4964287
   Lifu He, 2019, 2019 IEEE 3RD CONFERENCE ON ENERGY INTERNET AND ENERGY SYSTEM INTEGRATION (EI2), V0, PP2241, DOI 10.1109/EI247390.2019.9061993
   Lowe D. G., 1999, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, V0, PP1150, DOI 10.1109/ICCV.1999.790410
   Luque-Vega LF, 2014, IEEE MEDITERR ELECT, V0, PP393, DOI 10.1109/MELCON.2014.6820566
   Mason T, 2018, P COL BROADC SYST DE, V0, P0
   Qayyum A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SMART INSTRUMENTATION, V0, P0
   Ren S., 2015, PROC INT C NEURAL IN, V0, PP91, DOI 10.1109/ICCV.2015.169.
   Scribner D, 1998, ARLTR1598, V0, P0
   Shuai C, 2017, INT C INTEL HUM MACH, V0, PP69, DOI 10.1109/IHMSC.2017.131
   Sikorska-Lukasiewicz K., 2020, P SPE RAD SYST C JAC, V0, P0
   Songde M, 1998, COMPUTER VISION COMP, V0, P0
   Transmission VegetationManagement, 2016, FAC0034 NERC, V0, P0
   Nguyen VN, 2018, INT J ELEC POWER, V99, P107, DOI 10.1016/j.ijepes.2017.12.016
NR 31
TC 7
Z9 7
U1 7
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0885-8977
EI 1937-4208
J9 IEEE T POWER DELIVER
JI IEEE Trans. Power Deliv.
PD DEC 15
PY 2021
VL 36
IS 6
BP 3477
EP 3485
DI 10.1109/TPWRD.2020.3043433
PG 9
WC Engineering, Electrical & Electronic
SC Engineering
GA XC4ST
UT WOS:000722005300023
DA 2023-04-26
ER

PT J
AU Xiong, ZX
   Guo, Q
   Liu, ML
   Li, A
AF Xiong, Zhangxi
   Guo, Qing
   Liu, Mingliang
   Li, An
TI Pan-Sharpening Based on Convolutional Neural Network by Using the Loss Function With No-Reference
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Training data; Training; Spatial resolution; Remote sensing; Multiresolution analysis; Deep learning; Convolutional neural network; deep learning; feature enhancement; loss function; pan-sharpening; remote sensing image fusion
ID fusion; wavelet; regression; quality; images
AB In order to preserve the spatial and spectral information of the original panchromatic and multispectral images, this article designs a loss function suitable for pan-sharpening and a four-layer convolutional neural network that could adequately extract spectral and spatial features from original source images. The major advantage of this study is that the designed loss function does not need the reference fused image, and then the proposed pan-sharpening method does not need to make the simulation data for training. This is the big difference from most existing pan-sharpening methods. Moreover, the loss function takes into account the characteristics of remote sensing images, including the spatial and spectral evaluation indicators. We also add the feature enhancement layer in convolutional neural network, thus, the proposed four-layer network contains feature extraction, feature enhancement, linear mapping and reconstruction. In order to evaluate the effectiveness and universality of the proposed fusion model, we selected thousands of remote sensing images that include different sensors, different times and different land-cover types to make the training dataset. By evaluating the performance on the WorldView-2, Pleiades and Gaofen-1 experimental data, the results show that the proposed method achieves optimal performance in terms of both the subjective visual effect and the object assessment. Furthermore, the codes will be available at https://github.com/Zhangxi-Xiong/pan-sharpening.
C1 [Xiong, Zhangxi; Guo, Qing; Li, An] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100094, Peoples R China.
   [Xiong, Zhangxi; Liu, Mingliang] Heilongjiang Univ, Key Lab Informat Fus Estimat & Detect, Harbin 150080, Peoples R China.
C3 Chinese Academy of Sciences; Heilongjiang University
RP Guo, Q (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100094, Peoples R China.
EM pairs719@163.com; guoqing@aircas.ac.cn; mll_0608@163.com; lian@aircas.ac.cn
FU National Natural Science Foundation of China [61771470, 41590853]; Key Research Program of Frontier Sciences, Chinese Academy of Sciences [QYZDY-SSWDQC026]; Strategic Priority Research Program of the Chinese Academy of Sciences [XDA19060103]
CR Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Anoop Suraj A., 2014, J ELECT SYST INF TEC, V1, P72, DOI 10.1016/j.jesit.2014.03.006
   Azarang A, 2019, IEEE ACCESS, V7, P35673, DOI 10.1109/ACCESS.2019.2905511
   Azarang A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), V0, PP1, DOI 10.1109/PRIA.2017.7983017
   Chen SH, 2010, IEEE SENS J, V10, P737, DOI 10.1109/JSEN.2009.2038661
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Garzelli A, 2008, IEEE T GEOSCI REMOTE, V46, P228, DOI 10.1109/TGRS.2007.907604
   Gharbia R, 2014, ADV INTELL SYST, V303, P311, DOI 10.1007/978-3-319-08156-4_31
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Jelenek J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100794
   Jing Yao, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12374), V0, PP208, DOI 10.1007/978-3-030-58526-6_13
   Kong WW, 2013, OPT ENG, V52, P0, DOI 10.1117/1.OE.52.1.017001
   Li ZQ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222606
   Liu C., 2018, ENG SURV MAPP, V27, P9
   Masi G, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8070594
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   Palsson F, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081290
   Rao YZ, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017), V0, P0
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Tao, 2018, IEEE INT C IM PROC, V0, P3215
   Te-Ming Tu, 2001, INFORMATION FUSION, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Vivone G, 2019, IEEE T GEOSCI REMOTE, V57, P6421, DOI 10.1109/TGRS.2019.2906073
   Vivone G, 2018, IEEE T IMAGE PROCESS, V27, P3418, DOI 10.1109/TIP.2018.2819501
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wald L., 2002, DATA FUSION DEFINITI, V0, P200
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Q, 2015, IEEE T GEOSCI REMOTE, V53, P3658, DOI 10.1109/TGRS.2014.2381272
   Wei YC, 2017, IEEE GEOSCI REMOTE S, V14, P1795, DOI 10.1109/LGRS.2017.2736020
   Wencheng Wang, 2011, JOURNAL OF COMPUTERS, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Yang JF, 2017, IEEE I CONF COMP VIS, V0, PP1753, DOI 10.1109/ICCV.2017.193
   Yang SY, 2010, INFORM FUSION, V11, P78, DOI 10.1016/j.inffus.2009.05.001
   Yuhas R.H., 1992, PROC SUMMARIES 3 ANN, V1, P147
   Zhao Ziyi, 2012, COMPUTER ENGINEERING AND APPLICATIONS, V48, P164, DOI 10.3778/j.issn.1002-8331.2012.15.034
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
   Zhu, 2011, J IMAGE GRAPH, V6, P1130
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 44
TC 15
Z9 16
U1 0
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 897
EP 906
DI 10.1109/JSTARS.2020.3038057
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900028
DA 2023-04-26
ER

PT J
AU Mehltretter, M
   Heipke, C
AF Mehltretter, Max
   Heipke, Christian
TI Aleatoric uncertainty estimation for dense stereo matching via CNN-based cost volume analysis
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Depth reconstruction; Uncertainty quantification; Confidence; Deep learning
AB Motivated by the need to identify erroneous disparity estimates, various methods for the estimation of aleatoric uncertainty in the context of dense stereo matching have been presented in recent years. Especially, the introduction of deep learning based methods and the accompanying significant improvement in accuracy have greatly increased the popularity of this field. Despite this remarkable development, most of these methods rely on features learned from disparity maps only, neglecting the corresponding 3-dimensional cost volumes. However, conventional hand-crafted methods have already demonstrated that the additional information contained in such cost volumes are beneficial for the task of uncertainty estimation. In this paper, we combine the advantages of deep learning and cost volume based features and present a new Convolutional Neural Network (CNN) architecture to directly learn features for the task of aleatoric uncertainty estimation from volumetric 3D data. Furthermore, we discuss and apply three different uncertainty models to train our CNN without the need to provide ground truth for uncertainty. In an extensive evaluation on three datasets using three common dense stereo matching methods, we investigate the effects of these uncertainty models and demonstrate the generality and state-of-the-art accuracy of the proposed method.
C1 [Mehltretter, Max; Heipke, Christian] Leibniz Univ Hannover, Inst Photogrammetry & GeoInformat, Hannover, Germany.
C3 Leibniz University Hannover
RP Mehltretter, M (corresponding author), Leibniz Univ Hannover, Inst Photogrammetry & GeoInformat, Hannover, Germany.
EM mehltretter@ipi.uni-hannover.de; heipke@ipi.uni-hannover.de
FU German Research Foundation (DFG) as a part of the Research Training Group i.c.sens [GRK2159]; MOBILISE initiative of the Leibniz University Hannover; TU Braunschweig, Germany; NVIDIA Corporation
CR [Anonymous], 2010, P 13 INT C ARTIFICIA, V0, P0
   Batsos K, 2018, PROC CVPR IEEE, V0, PP2060, DOI 10.1109/CVPR.2018.00220
   Coenen M, 2019, IEEE INT CONF COMP V, V0, PP822, DOI 10.1109/ICCVW.2019.00110
   Fu Z., 2019, REPRESENTATIONS ANAL, V0, P69
   Geiger A, 2012, PROC CVPR IEEE, V0, PP3354, DOI 10.1109/CVPR.2012.6248074
   Hacking Ian., 1975, EMERGENCE PROBABILIT, V0, P0
   Haeusler R, 2013, PROC CVPR IEEE, V0, PP305, DOI 10.1109/CVPR.2013.46
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hollmann M., 2020, ISPRS ANN PHOTOGRAMM, VV-2-2020, P151
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Johns E, 2016, PROC CVPR IEEE, V0, PP3813, DOI 10.1109/CVPR.2016.414
   Kang J., 2020, INT ARCH PHOTOGRAMME, V0, P135
   Kendall A., 2017, PROC 31 INT C NEURAL, V0, P5574
   Kendall A., 2017, THESIS, V0, P0
   Kendall A, 2017, IEEE I CONF COMP VIS, V0, PP66, DOI 10.1109/ICCV.2017.17
   Kim S, 2019, IEEE T IMAGE PROCESS, V28, P1299, DOI 10.1109/TIP.2018.2878325
   King DB, 2015, ACS SYM SER, V1214, P1
   Kiureghian AD, 2009, STRUCT SAF, V31, P105, DOI 10.1016/j.strusafe.2008.06.020
   Li Y., 2016, ADV NEURAL INFORM PR, V0, P307
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Mayer N, 2016, PROC CVPR IEEE, V0, PP4040, DOI 10.1109/CVPR.2016.438
   Mehltretter M., 2020, ISPRS ANN PHOTOGRAMM, VV-2-2020, P161
   Mehltretter M, 2019, IEEE INT CONF COMP V, V0, PP2070, DOI 10.1109/ICCVW.2019.00262
   Mehltretter Max, 2018, GERM C PATT REC, V0, P3
   Menze M, 2015, PROC CVPR IEEE, V0, PP3061, DOI 10.1109/CVPR.2015.7298925
   Nguyen U, 2020, ISPRS J PHOTOGRAMM, V166, P347, DOI 10.1016/j.isprsjprs.2020.05.002
   Park MG, 2015, PROC CVPR IEEE, V0, PP101, DOI 10.1109/CVPR.2015.7298605
   Poggi M., 2016, P BRIT MACH VIS C, V0, P0
   Poggi M., 2017, PROC IEEE C COMPUT V, V0, P76
   Poggi M, 2017, PROC CVPR IEEE, V0, PP4541, DOI 10.1109/CVPR.2017.483
   Poggi M, 2016, INT CONF 3D VISION, V0, PP138, DOI 10.1109/3DV.2016.22
   Poggi M, 2016, INT CONF 3D VISION, V0, PP509, DOI 10.1109/3DV.2016.61
   Qi CR, 2016, PROC CVPR IEEE, V0, PP5648, DOI 10.1109/CVPR.2016.609
   Riegler G, 2017, PROC CVPR IEEE, V0, PP6620, DOI 10.1109/CVPR.2017.701
   Riesch H., 2012, HDB RISK THEORY EPIS, V1, P88
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schonberger J.L., 2018, EUROPEAN C COMPUTER, V0, P739
   Seki A., 2016, BMVC, V0, P0
   Shaked A., 2017, CVPR, V0, P0
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Spyropoulos A, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, V0, PP73, DOI 10.1109/3DV.2015.16
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stucker C., 2020, P IEEE CVF C COMP VI, V0, P184
   Su H, 2015, IEEE I CONF COMP VIS, V0, PP945, DOI 10.1109/ICCV.2015.114
   Sullivan T.J, 2015, ORTHOGONAL POLYNOMIA, V0, P0
   Sun L, 2017, IEEE T IMAGE PROCESS, V26, P3331, DOI 10.1109/TIP.2017.2687101
   Tosi F., 2018, P IEEE EUR C COMP VI, V0, P319
   Tulyakov S, 2018, ADV NEUR IN, V31, P0
   van Asselt MBA, 2002, CLIMATIC CHANGE, V54, P75, DOI 10.1023/A:1015783803445
   Veld ROH, 2018, IEEE IMAGE PROC, V0, PP644, DOI 10.1109/ICIP.2018.8451500
   Wu ZR, 2015, PROC CVPR IEEE, V0, PP1912, DOI 10.1109/CVPR.2015.7298801
   Zabih R., 1994, COMPUTER VISION - ECCV 94. THIRD EUROPEAN CONFERENCE ON COMPUTER VISION. PROCEEDINGS. VOL.II, V0, PP151, DOI 10.1007/BFb0028345
   Zbontar J, 2016, J MACH LEARN RES, V17, P0
NR 53
TC 4
Z9 4
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN 15
PY 2021
VL 171
IS 
BP 63
EP 75
DI 10.1016/j.isprsjprs.2020.11.003
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PN3UD
UT WOS:000604406500005
DA 2023-04-26
ER

PT J
AU Khoshboresh-Masouleh, M
   Shah-Hosseini, R
AF Khoshboresh-Masouleh, Mehdi
   Shah-Hosseini, Reza
TI A Deep Multi-Modal Learning Method and a New RGB-Depth Data Set for Building Roof Extraction
SO PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING
LA English
DT Article
ID convolutional neural-networks; dsm
AB This study focuses on tackling the challenge of building mapping in multi-modal remote sensing data by proposing a novel, deep superpixel-wise convolutional neural network called DeepQuantized-Net, plus a new red, green, blue (RGB)-depth data set named IND. DeepQuantized-Net incorporated two practical ideas in segmentation: first, improving the object pattern with the exploitation of superpixels instead of pixels, as the imaging unit in DeepQuantized-Net. Second, the reduction of computational cost. The generated data set includes 294 RGB-depth images (256 training images and 38 test images) from different locations in the state of Indiana in the U.S., with 1024 x 1024 pixels and a spatial resolution of 0.5 ft that covers different cities. The experimental results using the IND data set demonstrates the mean F1 scores and the average Intersection over Union scores could increase by approximately 7.0% and 7.2% compared to other methods, respectively.
C1 [Khoshboresh-Masouleh, Mehdi; Shah-Hosseini, Reza] Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran, Iran.
C3 University of Tehran
RP Khoshboresh-Masouleh, M (corresponding author), Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran, Iran.
EM m.khoshboresh@ut.ac.ir
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akbulut Z, 2018, J INDIAN SOC REMOTE, V46, P2057, DOI 10.1007/s12524-018-0871-2
   Bayanlou MR, 2020, PROC SPIE, V11525, P0, DOI 10.1117/12.2580533
   Bi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1603, DOI 10.1109/LGRS.2019.2949930
   Bi Q, 2020, IEEE T IMAGE PROCESS, V29, P4911, DOI 10.1109/TIP.2020.2975718
   Bi Q, 2020, NEUROCOMPUTING, V377, P345, DOI 10.1016/j.neucom.2019.11.068
   Bi Q, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050482
   Chen HH, 2014, MULTIMED TOOLS APPL, V72, P1961, DOI 10.1007/s11042-013-1492-y
   Gavankar NL, 2018, EUR J REMOTE SENS, V51, P182, DOI 10.1080/22797254.2017.1416676
   Gersho A., 1992, VECTOR QUANTIZATION, V0, P587
   Gray R. M., 1992, IMAGE AND TEXT COMPRESSION, V0, P3
   Gu LJ, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.045501
   Hu JL, 2019, COMPUT INTEL NEUROSC, V2019, P0, DOI 10.1155/2019/5065214
   Jin DB, 2020, TRAIT SIGNAL, V37, P807, DOI 10.18280/ts.370513
   Khoshboresh Masouleh M., 2019, INT ARCH PHOTOGRAMM, V0, PP615, DOI 10.5194/ISPRSARCHIVES-XLII-4-W18-615-2019
   Khoshboresh-Masouleh M, 2020, EUR J REMOTE SENS, V53, P316, DOI 10.1080/22797254.2020.1850179
   Khoshboresh-Masouleh M, 2020, COMPUT INTEL NEUROSC, V2020, P0, DOI 10.1155/2020/8811630
   Khoshboresh-Masouleh M, 2020, J APPL REMOTE SENS, V14, P0, DOI 10.1117/1.JRS.14.034503
   Kohonen T., 1995, SELF ORG MAPS, V0, PP175, DOI 10.1007/978-3-642-97610-0_6
   Koppanyi Z, 2019, MULTIMODAL SCENE UNDERSTANDING: ALGORITHMS, V0, P41, DOI 10.1016/B978-0-12-817358-9.00009-3
   Laurent C, 2016, INT CONF ACOUST SPEE, V0, PP2657, DOI 10.1109/ICASSP.2016.7472159
   Liu L, 2021, POSTGRAD MED, V133, P265, DOI 10.1080/00325481.2020.1803666
   Maier A, 2019, Z MED PHYS, V29, P86, DOI 10.1016/j.zemedi.2018.12.003
   Masouleh MK, 2020, APPL GEOMAT, V12, P107, DOI 10.1007/s12518-019-00285-4
   Masouleh MK, 2019, ISPRS J PHOTOGRAMM, V155, P172, DOI 10.1016/j.isprsjprs.2019.07.009
   Masouleh MK, 2019, J APPL REMOTE SENS, V13, P0, DOI 10.1117/1.JRS.13.024508
   Masouleh MK, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.046018
   Mohammedhasan M, 2020, TRAIT SIGNAL, V37, P711, DOI 10.18280/ts.370503
   Mousa YA, 2019, PHOTOGRAMM REC, V34, P85, DOI 10.1111/phor.12275
   ODDO LA, 1992, P SOC PHOTO-OPT INS, V1623, P91, DOI 10.1117/12.58059
   Salhi Khalid, 2019, IAENG INTERNATIONAL JOURNAL OF COMPUTER SCIENCE, V46, P134
   Sefercik UG, 2014, EUR J REMOTE SENS, V47, P575, DOI 10.5721/EuJRS20144732
   Shi WZ, 2018, J INDIAN SOC REMOTE, V46, P2003, DOI 10.1007/s12524-018-0868-x
   Singh G, 2015, PROC SPIE, V9401, P0, DOI 10.1117/12.2083500
   Sun JX, 2019, PROC SPIE, V11155, P0, DOI 10.1117/12.2532662
   Trastour F., 2019, P SPIE, V11155, P0, DOI 10.1117/12.2533149
   Uzar M, 2014, EUR J REMOTE SENS, V47, P1, DOI 10.5721/EuJRS20144701
   Wang C., 2020, INT J APPL MATH, V50, P1
   Wang RS, 2016, J APPL REMOTE SENS, V10, P0, DOI 10.1117/1.JRS.10.016022
   Wicht M, 2019, EUR J REMOTE SENS, V52, P58, DOI 10.1080/22797254.2019.1617642
   Wu GM, 2019, INT GEOSCI REMOTE SE, V0, PP158, DOI 10.1109/IGARSS.2019.8900475
   WuDunn M, 2020, PROC SPIE, V11398, P0, DOI 10.1117/12.2558399
   Xiang HH, 2020, APPL INTELL, V50, P2411, DOI 10.1007/s10489-020-01678-4
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, P0, DOI 10.1155/2015/832093
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010144
   Zhang CS, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.026005
   Zhang XR, 2020, TRAIT SIGNAL, V37, P793, DOI 10.18280/ts.370511
   Zheng QH, 2020, ENG LET, V28, P80
NR 48
TC 7
Z9 7
U1 1
U2 12
PU AMER SOC PHOTOGRAMMETRY
PI BETHESDA
PA 5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA
SN 0099-1112
EI 2374-8079
J9 PHOTOGRAMM ENG REM S
JI Photogramm. Eng. Remote Sens.
PD OCT 15
PY 2021
VL 87
IS 10
BP 759
EP 766
DI 10.14358/PERS.21-00007R2
PG 8
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UU0GQ
UT WOS:000698484400008
DA 2023-04-26
ER

PT J
AU Cerecedo, LOL
   Pitalua-Diaz, N
   Palafox, JFH
   Marin, JA
   Zavala, SR
AF Lara Cerecedo, Luis Omar
   Pitalua-Diaz, Nun
   Hinojosa Palafox, Jesus Fernando
   Anzurez Marin, Juan
   Ramirez Zavala, Salvador
TI Intelligent predictive model of electrical power in photovoltaic systems through solar radiation and temperature on site
SO PROCEEDINGS OF THE 2021 XXIII IEEE INTERNATIONAL AUTUMN MEETING ON POWER, ELECTRONICS AND COMPUTING (ROPEC 2021)
LA English
DT Proceedings Paper
DE Photovoltaic systems; Fuzzy neural networks; Hybrid intelligent systems; Prediction algorithms; Estimation error; Solar power generation
AB A Neuro-fuzzy ANFIS model is presented that allows predicting the generation of electrical power in a photovoltaic system considering the solar radiation and environmental temperature of the geographical area. This model enables fuzzy modeling to learn from the data set and, as a result, compute the most appropriate membership function parameters. It also makes use of neural networks' abilities to classify data and find patterns. The algorithm is developed using MATLAB((R)) software and is trained with the acquired data weather station located in Hermosillo, Sonora City, and the electrical power output of the system at the site. The algorithm is evaluated using rigorous evaluation factors which shows how much the predicted value differs from the actual value, resulting in the following predicted values: RSME: 295.2686, NRMSE: 0.09496, RMSPE: 9.4306, MAE: 218.6996, and MAPE: 6.985, respectively.
C1 [Lara Cerecedo, Luis Omar; Pitalua-Diaz, Nun; Hinojosa Palafox, Jesus Fernando] Univ Sonora Hermosillo, Hermosillo, Sonora, Mexico.
   [Anzurez Marin, Juan; Ramirez Zavala, Salvador] Univ Michoacan San Nicolas Hidalgo, Morelia, Michoacan, Mexico.
RP Cerecedo, LOL (corresponding author), Univ Sonora Hermosillo, Hermosillo, Sonora, Mexico.
EM olaracer@gmail.com; nun.pitalua@unison.mx; fernando.hinojosa@unison.mx; juan.anzurez@umich.mx; salvador.ramirez@umich.mx
FU CONACYT, Mexico
CR Altman N, 2015, NAT METHODS, V12, P999, DOI 10.1038/nmeth.3627
   [Anonymous], 2020, CO2 EMISSIONS FUEL C, V0, P0
   Aros Nelson, 2010, IBEROAMERICAN J PROJ, V1, P0
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P37, DOI 10.1007/978-3-642-00296-0_5
   Brio M., 2001, REDES NEURONALES SIS, V0, P0
   Castanon-Castanon J. P., 2016, SECTOR ENERGETICO CO, V0, P0
   Duarte O., 1999, REV ING INVEST, V42, P22
   Eduardo C., 2006, REV AMERICANA MEDICI, V6, P126
   Escamilla Chito J, 2015, SISTEMA FOTOVOLTAICO, V0, P0
   IEA, 2019, WORLD EN OUTL 2019, V0, P0, DOI DOI 10.1787/caf32f3b-en
   IEA G.E., 2019, GLOB EN CO2 STAT REP, V0, P562
   Ito M, 2011, CRYSTALLINE SILICON - PROPERTIES AND USES, V0, P297
   Kazem HA, 2017, ENERG CONVERS MANAGE, V148, P1070, DOI 10.1016/j.enconman.2017.06.058
   Krose B., 1993, INTRO NEURAL NETWORK, V0, P0
   Li YX, 2020, APPL ENERG, V259, P0, DOI 10.1016/j.apenergy.2019.114133
   Nguyen D. H., 1990, IEEE CONTROL SYSTEMS MAGAZINE, V10, P18, DOI 10.1109/37.55119
   Organizacion meteorologica Mundial, 2019, CAMBIO CLIMATICO MED, V0, P0
   Pita Fernandez S., 1997, CAD ATEN PRIMARIA, V4, P141
   Pitalua-Diaz N, 2019, ENERGIES, V12, P0, DOI 10.3390/en12142662
   Ruz-Hernandez JA, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9081649
   Yazdanbaksh O, 2013, PROCEEDINGS OF THE 2013 JOINT IFSA WORLD CONGRESS AND NAFIPS ANNUAL MEETING (IFSA/NAFIPS), V0, PP1243, DOI 10.1109/IFSA-NAFIPS.2013.6608579
   Yousif JH, 2019, CASE STUD THERM ENG, V13, P0, DOI 10.1016/j.csite.2019.100407
   Yudha HM, 2018, IOP C SER EARTH ENV, V124, P0, DOI 10.1088/1755-1315/124/1/012005
NR 23
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2381-5515
EI 
J9 IEEE INT AUT MEET
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/ROPEC53248.2021.9667977
PG 6
WC Energy & Fuels; Engineering, Electrical & Electronic
SC Energy & Fuels; Engineering
GA BT7HW
UT WOS:000848679300004
DA 2023-04-26
ER

PT J
AU Brito, LC
   da Silva, MB
   Duarte, MAV
AF Brito, Lucas Costa
   da Silva, Marcio Bacci
   Viana Duarte, Marcus Antonio
TI Identification of cutting tool wear condition in turning using self-organizing map trained with imbalanced data
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article
DE Tool wear monitoring; Self-organizing map neural network; Imbalanced data; Unsupervised learning; Vibration measurement
ID support vector machine; classification; algorithm; svm; features; system; signal
AB One of the most important parameters in machining process is tool wear. Thus, monitoring the wear of cutting tools is essential to ensure product quality, increase productivity, reduce environmental impact and avoid catastrophic damages. As wear is related to the vibrations of the process, the vibration signal is commonly used to monitor the process non-intrusively. Traditional wear monitoring techniques present a number of problems such as: the difficulty of identifying vibration features sensitive to wear evolution, the specialist requirement for supervising the model training and an endless series of tests to work with balanced data. To overcome these difficulties, this paper aims to propose a new approach in the application of unsupervised artificial intelligence technique with imbalanced data to identify the cutting tool wear condition during the turning process. The methodology will allow industrial applications since no supervision is required in the model training when machining condition is changed. From vibration signals collected during each tool pass, a self-organizing map model was used to identify the ideal moment of tool change. The classifier used was compared to benchmark supervised methods (weighted k-nearest neighbor and support vector machine). Imbalanced data sets were used to simulate the industrial reality. Tool tests were performed under different wear conditions and changing the cutting parameters. The results showed that it is possible to predict the cutting tool wear condition with a self-organizing map neural for imbalanced data, using only the vibration signal with up to 92% accuracy.
C1 [Brito, Lucas Costa; da Silva, Marcio Bacci; Viana Duarte, Marcus Antonio] Fed Univ Uberlandia UFU, Sch Mech Engn, Av Joao Naves de Avila 2121,Campus Santa Monica, Uberlandia, MG, Brazil.
C3 Universidade Federal de Uberlandia
RP Brito, LC (corresponding author), Fed Univ Uberlandia UFU, Sch Mech Engn, Av Joao Naves de Avila 2121,Campus Santa Monica, Uberlandia, MG, Brazil.
EM brito.lcb@gmail.com
FU Brazilian research funding agency CNPq (National Council for Scientific and Technological Development); Brazilian research funding agency CAPES (Federal Agency for the Support and Improvement of Higher Education); Brazilian research funding agency FAPEMIG (Minas Gerais State Research Foundation)
CR Arabmakki E, 2017, NEUROCOMPUTING, V262, P120, DOI 10.1016/j.neucom.2016.11.088
   Burnap P, 2018, COMPUT SECUR, V73, P399, DOI 10.1016/j.cose.2017.11.016
   Cai Q, 2014, NEUROCOMPUTING, V133, P258, DOI 10.1016/j.neucom.2013.11.010
   Changhao Xia, 2018, JOURNAL OF ELECTRICAL SYSTEMS AND INFORMATION TECHNOLOGY, V5, P681, DOI 10.1016/j.jesit.2017.05.008
   Demircan S, 2018, NEURAL COMPUT APPL, V29, P59, DOI 10.1007/s00521-016-2712-y
   Dudani S. A., 1976, IEEE TRANSACTIONS ON SYSTEMS, V0, P0
   Fix E., 1951, PROJECT 21 49 004, V0, P0
   Gajate A, 2012, J INTELL MANUF, V23, P869, DOI 10.1007/s10845-010-0443-y
   GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761
   Hassan M, 2018, PROC CIRP, V72, P1451, DOI 10.1016/j.procir.2018.03.201
   Huang ZW, 2020, J INTELL MANUF, V31, P953, DOI 10.1007/s10845-019-01488-7
   Jain DK, 2018, J COMPUT SCI-NETH, V25, P252, DOI 10.1016/j.jocs.2017.07.016
   Jurkovic Z, 2018, J INTELL MANUF, V29, P1683, DOI 10.1007/s10845-016-1206-1
   Kannatey-Asibu E, 2017, MECH SYST SIGNAL PR, V85, P651, DOI 10.1016/j.ymssp.2016.08.035
   Kohonen T, 1995, SELF ORG MAPS, V0, P0
   Kong DD, 2019, MECH SYST SIGNAL PR, V127, P573, DOI 10.1016/j.ymssp.2019.03.023
   Lee WJ, 2019, PROC CIRP, V80, P506, DOI 10.1016/j.procir.2018.12.019
   Li ZF, 2018, COMPUT IND ENG, V116, P37, DOI 10.1016/j.cie.2017.12.002
   Liu CQ, 2018, INT J ADV MANUF TECH, V97, P229, DOI 10.1007/s00170-018-1916-y
   Liu M, 2004, J MATER PROCESS TECH, V150, P234, DOI 10.1016/j.jmatprotec.2004.02.038
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P209, DOI 10.1007/s11042-016-4265-6
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   da Silva RHL, 2016, MACH SCI TECHNOL, V20, P386, DOI 10.1080/10910344.2016.1191026
   Lu MC, 2013, INT J ADV MANUF TECH, V66, P1785, DOI 10.1007/s00170-012-4458-8
   Lu SY, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, V0, P826
   Meng X, 2019, COMPUT ELECTR ENG, V77, P120, DOI 10.1016/j.compeleceng.2019.05.013
   Mikaeil R, 2018, GEOTECH GEOL ENG, V36, P1309, DOI 10.1007/s10706-017-0394-6
   Mikolajczyk T, 2018, MECH SYST SIGNAL PR, V104, P503, DOI 10.1016/j.ymssp.2017.11.022
   Mutheneni Srinivasa Rao, 2018, PARASITE EPIDEMIOL CONTROL, V3, P52, DOI 10.1016/j.parepi.2016.11.001
   Nguwi YY, 2010, EXPERT SYST APPL, V37, P8303, DOI 10.1016/j.eswa.2010.05.054
   Nouni M, 2015, INT J MACH TOOL MANU, V89, P1, DOI 10.1016/j.ijmachtools.2014.10.011
   Pandiyan V, 2018, J MANUF PROCESS, V31, P199, DOI 10.1016/j.jmapro.2017.11.014
   Prasad BS, 2017, ENG SCI TECHNOL, V20, P197, DOI 10.1016/j.jestch.2016.06.011
   Rizal M, 2017, WEAR, V376, P1759, DOI 10.1016/j.wear.2017.02.017
   Rmili W, 2016, MEASUREMENT, V77, P117, DOI 10.1016/j.measurement.2015.09.010
   Santhanam T, 2015, PROCEDIA COMPUT SCI, V47, P76, DOI 10.1016/j.procs.2015.03.185
   Sevilla-Camacho PY, 2015, INT J ADV MANUF TECH, V81, P1187, DOI 10.1007/s00170-015-7302-0
   Sevilla-Camacho PY, 2015, MEASUREMENT, V64, P81, DOI 10.1016/j.measurement.2014.12.037
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Siddhpura A, 2013, INT J ADV MANUF TECH, V65, P371, DOI 10.1007/s00170-012-4177-1
   Sun HT, 2019, OPTIK, V184, P214, DOI 10.1016/j.ijleo.2019.02.126
   Trent E.M., 2000, METAL CUTTING, V0, P0
   Unler A, 2011, INFORM SCIENCES, V181, P4625, DOI 10.1016/j.ins.2010.05.037
   Vapnik V, 1997, ADV NEUR IN, V9, P281
   Wang C, 2018, MEASUREMENT, V117, P312, DOI 10.1016/j.measurement.2017.12.015
   Wang GF, 2019, J INTELL MANUF, V30, P113, DOI 10.1007/s10845-016-1235-9
   Wu XY, 2018, MULTIMED TOOLS APPL, V77, P3745, DOI 10.1007/s11042-016-3931-z
   Xie ZY, 2019, INT J ADV MANUF TECH, V100, P3197, DOI 10.1007/s00170-018-2926-5
   Yen CL, 2013, MECH SYST SIGNAL PR, V34, P353, DOI 10.1016/j.ymssp.2012.05.001
   Zendehboudi A, 2018, J CLEAN PROD, V199, P272, DOI 10.1016/j.jclepro.2018.07.164
   Zhou YQ, 2018, INT J ADV MANUF TECH, V96, P2509, DOI 10.1007/s00170-018-1768-5
NR 51
TC 14
Z9 14
U1 7
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD JAN 15
PY 2021
VL 32
IS 1
BP 127
EP 140
DI 10.1007/s10845-020-01564-3
EA AUG 2020
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
SC Computer Science; Engineering
GA PT8BE
UT WOS:000559403100001
DA 2023-04-26
ER

PT J
AU Zou, SY
   Wang, L
AF Zou, Shengyuan
   Wang, Le
TI Detecting individual abandoned houses from google street view: A hierarchical deep learning approach
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Residential housing abandonment; Street view; Knowledge-guided deep learning; Patch-based classification
ID vacancy; addresses
AB Abandoned houses (AH) are focal points in urban communities by threatening local security, destroying housing markets, and burdening government finance in the U.S. legacy cities. In particular, individual-level AH detection provides essential information for fine-resolution urban studies, government decision-makers, and private sector practitioners. However, three primary conventional data sources (field data, utility data, and remote sensing data) cannot suffice to collect such fine-resolution data in the large spatial area via a cost-effective approach. To this end, Google Street View (GSV) imagery, which emerges as the mainstream open-access data source with global coverage, provides an opportunity to address this issue. Subsequently, a follow-up challenge confronting the detection of AH arises from the fact that it lacks an effective method that can discern authentic visual features from the redundant noise in GSV images. In this study, we aim to develop an effective method to detect individual-level AH from GSV imagery. Specifically, we developed a new hierarchical deep learning method to leverage both global and local visual features of AH in the detection. The method can be further divided into three steps: (1) Scene-based classification that can extract global visual features of AH was implemented through fine-tuning a pre-trained deep convolutional neural network (CNN) model. (2) We developed a patch-based classification method that can extract specific local features of AH. In this method, patches were generated from GSV images based on auto-detected local features, followed by being labeled as three categories: building patches, vegetation patches, and others. Two deep CNN models were employed to identify deteriorated building facade patches and overgrown vegetation patches, respectively. (3) Individual-level AH were detected by integrating scene classification results and patch classification results in a decision-tree model. Experimental results showed that the F-score of AH was 0.84 in a well-prepared dataset collected from five different Rust Belt cities. The proposed hierarchical deep learning approach effectively improved the accuracy comparing with the traditional scene-based method. In addition, the proposed method was applied to generate an AH map in a new site in Detroit, MI. Our study demonstrated the feasibility of GSV imagery in AH detection and showed great potential to detect AH in a large spatial extent.
C1 [Zou, Shengyuan; Wang, Le] Univ Buffalo State Univ New York, Dept Geog, Amherst, NY 14261 USA.
RP Wang, L (corresponding author), Univ Buffalo State Univ New York, Dept Geog, Amherst, NY 14261 USA.
EM szou2@buffalo.edu; lewang@buffalo.edu
CR Abbott G.R, 2007, BUILDING CONDITION A, V0, P0
   Accordino J, 2000, J URBAN AFF, V22, P301, DOI 10.1111/0735-2166.00058
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   Bentley GC, 2016, URBAN GEOGR, V37, P785, DOI 10.1080/02723638.2015.1112642
   Bosch A, 2007, IEEE I CONF COMP VIS, V0, P1863
   Chen ZQ, 2015, IEEE J-STARS, V8, P2188, DOI 10.1109/JSTARS.2015.2418201
   Deng CB, 2015, LANDSCAPE URBAN PLAN, V141, P88, DOI 10.1016/j.landurbplan.2015.05.002
   Deng CB, 2010, INT J REMOTE SENS, V31, P5673, DOI 10.1080/01431161.2010.496806
   Du MZ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121920
   Elwood S, 2012, ANN ASSOC AM GEOGR, V102, P571, DOI 10.1080/00045608.2011.595657
   Frazier AE, 2013, APPL GEOGR, V41, P55, DOI 10.1016/j.apgeog.2013.02.014
   Griffin T.L, 2015, MAPPING AMERICAS LEG, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hillier AE, 2003, J URBAN AFF, V25, P91, DOI 10.1111/1467-9906.00007
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Kang J, 2018, ISPRS J PHOTOGRAMM, V145, P44, DOI 10.1016/j.isprsjprs.2018.02.006
   Koch D, 2018, RETECH18: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON MULTIMEDIA FOR REAL ESTATE TECH, V0, PP12, DOI 10.1145/3210499.3210526
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kumagai K, 2016, INT ARCH PHOTOGRAMM, V41, P709, DOI 10.5194/isprsarchives-XLI-B2-709-2016
   Kurth Joel, 2015, DETROIT NEWS, V0, P0
   Laumer D, 2020, ISPRS J PHOTOGRAMM, V162, P125, DOI 10.1016/j.isprsjprs.2020.02.001
   Law S, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3342240
   Li XJ, 2017, GISCI REMOTE SENS, V54, P819, DOI 10.1080/15481603.2017.1338389
   Li XJ, 2015, URBAN FOR URBAN GREE, V14, P675, DOI 10.1016/j.ufug.2015.06.006
   Li Z., 2019, SHRINKING CITIES CHI, V0, PP141, DOI 10.1007/978-981-13-2646-2_8
   Lin CY, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20102907
   Lynch A, 2017, CITIES, V60, P301, DOI 10.1016/j.cities.2016.09.011
   Mallach A., 2018, EMPTY HOUSE NEXT DOO, V0, P0
   Mallach A., 2012, DEPOPULATION MARKET, V0, P85
   Molloy R, 2016, REG SCI URBAN ECON, V59, P118, DOI 10.1016/j.regsciurbeco.2016.06.002
   Morckel V, 2014, COMMUNITY DEV, V45, P121, DOI 10.1080/15575330.2014.892019
   Morckel VC, 2014, APPL GEOGR, V48, P8, DOI 10.1016/j.apgeog.2014.01.001
   Morckel VC, 2013, HOUS POLICY DEBATE, V23, P469, DOI 10.1080/10511482.2013.788051
   Raleigh E, 2015, J URBAN AFF, V37, P367, DOI 10.1111/juaf.12102
   Raman A, 2019, CHEERS STREET VIEWS, V0, P0
   Scafidi BP, 1998, J HOUS ECON, V7, P287, DOI 10.1006/jhec.1998.0235
   Silverman RM, 2013, J URBAN AFF, V35, P131, DOI 10.1111/j.1467-9906.2012.00627.x
   Simonyan K, 2015, ARXIV, V0, P0
   U.S. Government Accountability Office, 1978, HOUS AB NAT PROBL NE, V0, P0
   U.S. Government Accountability Office (GAO), 2011, VAC PROP GROW NUMB I, V0, P0
   Wang L, 2019, IEEE INT CONF ADV LE, V0, PP1, DOI 10.1109/ICALT.2019.00007
   Weiss Karl, 2016, JOURNAL OF BIG DATA, V3, P0, DOI 10.1186/s40537-016-0043-6
   Wiechmann T, 2012, INT J URBAN REGIONAL, V36, P261, DOI 10.1111/j.1468-2427.2011.01095.x
   Yin L, 2015, ISPRS INT J GEO-INF, V4, P1184, DOI 10.3390/ijgi4031184
   Yongling Yao, 2011, PROCEEDINGS OF THE 2011 IEEE INTERNATIONAL CONFERENCE ON SPATIAL DATA MINING AND GEOGRAPHICAL KNOWLEDGE SERVICES (ICSDM 2011), V0, PP457, DOI 10.1109/ICSDM.2011.5969087
   Zeppelzauer M, 2018, ICMR 18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP126, DOI 10.1145/3206025.3206060
   Zhang F, 2019, ISPRS J PHOTOGRAMM, V153, P48, DOI 10.1016/j.isprsjprs.2019.04.017
   Zhang WX, 2017, COMPUT ENVIRON URBAN, V64, P215, DOI 10.1016/j.compenvurbsys.2017.03.001
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zou SY, 2020, ANN AM ASSOC GEOGR, V110, P449, DOI 10.1080/24694452.2019.1665492
NR 50
TC 8
Z9 9
U1 8
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY 15
PY 2021
VL 175
IS 
BP 298
EP 310
DI 10.1016/j.isprsjprs.2021.03.020
EA APR 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT8HA
UT WOS:000644695700021
DA 2023-04-26
ER

PT J
AU Wang, L
   Chen, SS
   Li, D
   Wang, CY
   Jiang, H
   Zheng, Q
   Peng, ZP
AF Wang, Li
   Chen, Shuisen
   Li, Dan
   Wang, Chongyang
   Jiang, Hao
   Zheng, Qiong
   Peng, Zhiping
TI Estimation of Paddy Rice Nitrogen Content and Accumulation Both at Leaf and Plant Levels from UAV Hyperspectral Imagery
SO REMOTE SENSING
LA English
DT Article
DE paddy rice; growth stages; phenology; hyperspectral; nitrogen
ID red edge position; chlorophyll content; vegetation index; reflectance measurement; spectral reflectance; n status; wheat; prediction; agriculture; algorithms
AB Remote sensing-based mapping of crop nitrogen (N) status is beneficial for precision N management over large geographic regions. Both leaf/canopy level nitrogen content and accumulation are valuable for crop nutrient diagnosis. However, previous studies mainly focused on leaf nitrogen content (LNC) estimation. The effects of growth stages on the modeling accuracy have not been widely discussed. This study aimed to estimate different paddy rice N traits-LNC, plant nitrogen content (PNC), leaf nitrogen accumulation (LNA) and plant nitrogen accumulation (PNA)-from unmanned aerial vehicle (UAV)-based hyperspectral images. Additionally, the effects of the growth stage were evaluated. Univariate regression models on vegetation indices (VIs), the traditional multivariate calibration method, partial least squares regression (PLSR) and modern machine learning (ML) methods, including artificial neural network (ANN), random forest (RF), and support vector machine (SVM), were evaluated both over the whole growing season and in each single growth stage (including the tillering, jointing, booting and heading growth stages). The results indicate that the correlation between the four nitrogen traits and the other three biochemical traits-leaf chlorophyll content, canopy chlorophyll content and aboveground biomass-are affected by the growth stage. Within a single growth stage, the performance of selected VIs is relatively constant. For the full-growth-stage models, the performance of the VI-based models is more diverse. For the full-growth-stage models, the transformed chlorophyll absorption in the reflectance index/optimized soil-adjusted vegetation index (TCARI/OSAVI) performs best for LNC, PNC and PNA estimation, while the three band vegetation index (TBVITian) performs best for LNA estimation. There are no obvious patterns regarding which method performs the best of the PLSR, ANN, RF and SVM in either the growth-stage-specific or full-growth-stage models. For the growth-stage-specific models, a lower mean relative error (MRE) and higher R-2 can be acquired at the tillering and jointing growth stages. The PLSR and ML methods yield obviously better estimation accuracy for the full-growth-stage models than the VI-based models. For the growth-stage-specific models, the performance of VI-based models seems optimal and cannot be obviously surpassed. These results suggest that building linear regression models on VIs for paddy rice nitrogen traits estimation is still a reasonable choice when only a single growth stage is involved. However, when multiple growth stages are involved or missing the phenology information, using PLSR or ML methods is a better option.
C1 [Wang, Li; Chen, Shuisen; Li, Dan; Wang, Chongyang; Jiang, Hao; Zheng, Qiong] Guangdong Acad Sci, Res Ctr Guangdong Prov Engn Technol Applicat Remo, Key Lab Guangdong Utilizat Remote Sensing & Geog, Guangdong Open Lab Geospatial Informat Technol &, Guangzhou 510070, Peoples R China.
   [Peng, Zhiping] Guangdong Acad Agr Sci, Inst Agr Resources & Environm, Guangzhou 510640, Peoples R China.
C3 Guangdong Academy of Sciences; Guangdong Academy of Agricultural Sciences
RP Chen, SS (corresponding author), Guangdong Acad Sci, Res Ctr Guangdong Prov Engn Technol Applicat Remo, Key Lab Guangdong Utilizat Remote Sensing & Geog, Guangdong Open Lab Geospatial Informat Technol &, Guangzhou 510070, Peoples R China.
EM wangli1990@nwsuaf.edu.cn; css@gdas.ac.cn; lidan@gdas.ac.cn; wangchongyang@gdas.ac.cn; jianghao@gdas.ac.cn; zhengqiong@gdas.ac.cn; ytifei@aliyun.com
FU GDAS Project of Science and Technology Development [2020GDASYL-20200103011]; Guangdong Province Agricultural Science and Technology Innovation and Promotion Project [2021KJ102, 2020KJ102, 2019KJ102]; Guangzhou Basic Research Project [202002020076]
CR Awais M, 2021, ENVIRON TECHNOL INNO, V22, P0, DOI 10.1016/j.eti.2021.101465
   Baret F, 2007, J EXP BOT, V58, P869, DOI 10.1093/jxb/erl231
   Berger K, 2020, INT J APPL EARTH OBS, V92, P0, DOI 10.1016/j.jag.2020.102174
   Berger K, 2020, REMOTE SENS ENVIRON, V242, P0, DOI 10.1016/j.rse.2020.111758
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Cerovic ZG, 2012, PHYSIOL PLANTARUM, V146, P251, DOI 10.1111/j.1399-3054.2012.01639.x
   Chlingaryan A, 2018, COMPUT ELECTRON AGR, V151, P61, DOI 10.1016/j.compag.2018.05.012
   Cho MA, 2006, REMOTE SENS ENVIRON, V101, P181, DOI 10.1016/j.rse.2005.12.011
   Clarke TR, 2001, INT GEOSCI REMOTE SE, V0, PP1279, DOI 10.1109/IGARSS.2001.976818
   Dash J, 2004, INT J REMOTE SENS, V25, P5403, DOI 10.1080/0143116042000274015
   Dunn BW, 2016, J NEAR INFRARED SPEC, V24, P473, DOI 10.1255/jnirs.1246
   Fitzgerald G, 2010, FIELD CROP RES, V116, P318, DOI 10.1016/j.fcr.2010.01.010
   Gitelson AA, 2003, J PLANT PHYSIOL, V160, P271, DOI 10.1078/0176-1617-00887
   Guo JB, 2021, PRECIS AGRIC, V22, P1634, DOI 10.1007/s11119-021-09804-z
   Guyot G., 1988, P 4 INT C SPECTR SIG, V0, P0, DOI DOI 10.1007/S13398-014-0173-7.2
   Haboudane D, 2002, REMOTE SENS ENVIRON, V81, P416, DOI 10.1016/S0034-4257(02)00018-4
   Hansen PM, 2003, REMOTE SENS ENVIRON, V86, P542, DOI 10.1016/S0034-4257(03)00131-7
   Huang SY, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030227
   Huang Z, 2004, REMOTE SENS ENVIRON, V93, P18, DOI 10.1016/j.rse.2004.06.008
   HUETE AR, 1988, REMOTE SENS ENVIRON, V25, P295, DOI 10.1016/0034-4257(88)90106-X
   JACQUEMOUD S, 1990, REMOTE SENS ENVIRON, V34, P75, DOI 10.1016/0034-4257(90)90100-Z
   Karatzoglou A., 2004, J STAT SOFTW, V11, P1, DOI 10.18637/jss.v011.i09
   Kokaly RF, 2009, REMOTE SENS ENVIRON, V113, PS78, DOI 10.1016/j.rse.2008.10.018
   Kuhn M, 2020, PLSMOD MODEL WRAPPER, V0, P0
   Lee YJ, 2008, AGRON J, V100, P205, DOI 10.2134/agrojnl2007.0018
   Lemaire G, 2008, EUR J AGRON, V28, P614, DOI 10.1016/j.eja.2008.01.005
   Li DL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12162578
   Li F, 2014, EUR J AGRON, V52, P198, DOI 10.1016/j.eja.2013.09.006
   Li F, 2012, FIELD CROP RES, V138, P21, DOI 10.1016/j.fcr.2012.09.002
   Li F, 2010, PRECIS AGRIC, V11, P335, DOI 10.1007/s11119-010-9165-6
   Li FL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111331
   Li MH, 2021, AGRICULTURE-BASEL, V11, P0, DOI 10.3390/agriculture11060563
   Marang IJ, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13081428
   MILLER JR, 1990, INT J REMOTE SENS, V11, P1755, DOI 10.1080/01431169008955128
   Moharana S, 2016, ISPRS J PHOTOGRAMM, V122, P17, DOI 10.1016/j.isprsjprs.2016.09.002
   Nigon TJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081234
   Onojeghuo AO, 2018, INT J APPL EARTH OBS, V64, P62, DOI 10.1016/j.jag.2017.09.005
   Onoyama H, 2015, PRECIS AGRIC, V16, P558, DOI 10.1007/s11119-015-9394-9
   Pancorbo JL, 2021, EUR J AGRON, V127, P0, DOI 10.1016/j.eja.2021.126287
   Patel MK, 2021, COMPUT ELECTRON AGR, V182, P0, DOI 10.1016/j.compag.2021.106000
   QI J, 1994, REMOTE SENS ENVIRON, V48, P119, DOI 10.1016/0034-4257(94)90134-1
   Rondeaux G, 1996, REMOTE SENS ENVIRON, V55, P95, DOI 10.1016/0034-4257(95)00186-7
   Schlemmer M, 2013, INT J APPL EARTH OBS, V25, P47, DOI 10.1016/j.jag.2013.04.003
   Sims DA, 2002, REMOTE SENS ENVIRON, V81, P337, DOI 10.1016/S0034-4257(02)00010-X
   Slaton, 2001, RICE PRODUCTION HDB, V0, P7
   Stroppiana D, 2009, FIELD CROP RES, V111, P119, DOI 10.1016/j.fcr.2008.11.004
   Sun J, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090951
   [田明璐 Tian Minglu], 2016, 农业机械学报 TRANSACTIONS OF THE CHINESE SOCIETY FOR AGRICULTURAL MACHINERY, V47, P285
   Tian YC, 2011, FIELD CROP RES, V120, P299, DOI 10.1016/j.fcr.2010.11.002
   Tian YC, 2011, PLANT PROD SCI, V14, P270, DOI 10.1626/pps.14.270
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Venables W.N., 2002, MODERN APPL STAT S, V0, P0
   Verrelst J, 2019, SURV GEOPHYS, V40, P589, DOI 10.1007/s10712-018-9478-y
   Wang BJ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9030291
   Wang FM, 2013, PRECIS AGRIC, V14, P172, DOI 10.1007/s11119-012-9285-2
   Wang L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030361
   Wang LA, 2017, COMPUT ELECTRON AGR, V140, P327, DOI 10.1016/j.compag.2017.05.023
   Wu CY, 2008, AGR FOREST METEOROL, V148, P1230, DOI 10.1016/j.agrformet.2008.03.005
   Yang GJ, 2015, J APPL REMOTE SENS, V9, P0, DOI 10.1117/1.JRS.9.095976
   Yao X, 2015, REMOTE SENS-BASEL, V7, P14939, DOI 10.3390/rs71114939
   Yi QX, 2010, INT J REMOTE SENS, V31, P931, DOI 10.1080/01431160902912061
   Yu K, 2013, ISPRS J PHOTOGRAMM, V78, P102, DOI 10.1016/j.isprsjprs.2013.01.008
   Zhao HT, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141724
   Zheng HB, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10122026
NR 65
TC 20
Z9 20
U1 19
U2 80
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG 15
PY 2021
VL 13
IS 15
BP 
EP 
DI 10.3390/rs13152956
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TW2MI
UT WOS:000682240700001
DA 2023-04-26
ER

PT J
AU Shirazy, A
   Ziaii, M
   Hezarkhani, A
   Timkin, TV
   Voroshilov, VG
AF Shirazy, Adel
   Ziaii, Mansour
   Hezarkhani, Ardeshir
   Timkin, Timofey, V
   Voroshilov, Valery G.
TI GEOCHEMICAL BEHAVIOR INVESTIGATION BASED ON K-MEANS AND ARTIFICIAL NEURAL NETWORK PREDICTION FOR TITANIUM AND ZINC, KIVI REGION, IRAN
SO BULLETIN OF THE TOMSK POLYTECHNIC UNIVERSITY-GEO ASSETS ENGINEERING
LA English
DT Article
DE Titanium; zinc; Kivi region; K-means clustering method; artificial neural network; estimation of the elements grade
ID deposits; area; mineralization; segmentation; intelligent; elements; belt
AB The relevance. These are the first studies in the Kivi region. Due to the presence of titanium and zinc in the area, these studies are necessary. Artificial Neural Network and K-means methods for element behavior measurement are new methods in mineral exploration. The main aim of the research is to identify Ti and Zn geochemical behavior for prediction Ti by ANN and K-means methods. Object: Kivi 1:100000 geochemical map in Ardabil province, Iran. Methods. The samples taken from bottom sediments of the Kiwi region, which were analyzed by the ICP-MS method, served as the initial data. Then, the behavior of these elements in relation to each other and their geographical coordinates was analyzed by the K-means clustering method. The amount of titanium was also predicted with the artificial neural network (ANN- GRNN). Results. The Ti and Zn elements relationship was determined using this K-means method taking into account the latitude and longitude of the samples to estimate the grade and more accurate estimation of the appearance and extent of the geochemical halos in the studied area. According to the results obtained during processing of these elements, a regression equation was drawn up to estimate the titanium content based on three parameters: Zn content, the length and width of the sampling points, the correlation coefficient. According to the K-means cluster centers and artificial neural network, the Ti element grade was predicted and the correlation coefficient was reported 0,51. Both methods produce the desired results, but the artificial neural network method has more accurate data. Schematic maps of the initial and predicted Ti content were constructed. The results of the study can be used in the course of geological exploration to forecast and identify new promising areas.
C1 [Shirazy, Adel; Ziaii, Mansour] Shahrood Univ Technol, Bolvar Daneshka 3619995161, Shahrood, Iran.
   [Hezarkhani, Ardeshir] Amirkabir Univ Technol, Tehran 1591634311, Iran.
   [Timkin, Timofey, V; Voroshilov, Valery G.] Natl Res Tomsk Polytech Univ, 30 Lenin Ave, Tomsk 634050, Russia.
C3 Shahrood University of Technology; Amirkabir University of Technology; Tomsk Polytechnic University
RP Shirazy, A (corresponding author), Shahrood Univ Technol, Bolvar Daneshka 3619995161, Shahrood, Iran.
EM Adel.shirazy@shahroodut.ac.ir; mziaii@shahroodut.ac.ir; Ardehez@aut.ac.ir; timkin@tpu.ru; v_g_v@tpu.ru
FU RFBR [18-45-700019]; Competitiveness Enhancement Program Grant at Tomsk Polytechnic University
CR Abolhassani B., 2005, P CAN C EL COMP ENG, V0, P2117
   Alahgholi S., 2018, OPEN J GEOL, V8, P697, DOI 10.4236/ojg.2018.87041
   Beale M. H., 2010, NEURAL NETWORK TOOLB, V0, P0
   Carranza EJM, 2017, GEOCHEM-EXPLOR ENV A, V17, P183, DOI 10.1144/geochem2017-901
   Chen TW, 2009, INT CONF ACOUST SPEE, V0, PP573, DOI 10.1109/ICASSP.2009.4959648
   Ghannadpour S.S., 2013, J TETHYS, V1, P291
   Grosan C., 2011, ARTIFICIAL NEURAL NE, V0, P281
   GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761
   Hassanipak A.A., 2005, EXPLORATION DATA ANA, V1, P0
   Hezarkhani A., 2015, GEOCHEMICAL BEHAV IN, V0, P0
   Hezarkhani A, 2015, J ANALYTICAL NUMERIC, V5, P77
   Isaeva ER, 2018, BULL TOMSK POLYTECH, V329, P132
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kalisch M, 2016, COMM COM INF SC, V613, P79, DOI 10.1007/978-3-319-34099-9_5
   Madala G. S., 1992, INTRO ECONOMETRICS, V0, P0
   Malyszko D, 2007, 6TH INTERNATIONAL CONFERENCE ON COMPUTER INFORMATION SYSTEMS AND INDUSTRIAL MANAGEMENT APPLICATIONS, V0, P299, DOI 10.1109/CISIM.2007.63
   MENARD JJ, 1995, MINER DEPOSITA, V30, P268, DOI 10.1007/BF00196362
   Meshkani SA, 2011, J GEOCHEM EXPLOR, V108, P183, DOI 10.1016/j.gexplo.2011.01.006
   Mora JL, 2012, J ARID ENVIRON, V87, P58, DOI 10.1016/j.jaridenv.2012.07.016
   Najmodini M., 2013, J ANAL NUMERICAL MET, V3, P69
   Osterholt V., 2018, ADV APPL STRATEGIC M, V0, PP335, DOI 10.1007/978-3-319-69320-0_22
   Ozkan E, 2019, INT J MIN RECLAM ENV, V33, P183, DOI 10.1080/17480930.2017.1381219
   Pak aa Hassani, 2013, GEOSTATISTICAL, V5, P0
   Rooki R, 2016, MEASUREMENT, V85, P184, DOI 10.1016/j.measurement.2016.02.037
   Saha S, 2013, APPL SOFT COMPUT, V13, P89, DOI 10.1016/j.asoc.2012.08.005
   Sfidari E, 2012, J PETROL SCI ENG, V86-87, P190, DOI 10.1016/j.petrol.2012.03.024
   Shin HW, 2004, EXPERT SYST APPL, V27, P27, DOI 10.1016/j.eswa.2003.12.002
   Shirazi A., 2018, GLOB J COMPUT SCI TH, V8, P62, DOI 10.18844/gjcs.v8i2.3264
   Shirazi A., 2018, INT J GEOL EARTH SCI, V4, P36, DOI 10.18178/IJGES
   Shirazi A., 2018, OPEN J GEOL, V8, P841, DOI 10.4236/ojg.2018.89049
   Shirazi A., 2018, J GEOL RESOUR ENG, V6, P124, DOI 10.17265/2328-2193/2018.03.004
   Shirazy A., 2020, MINERALS-BASEL, V10, P1
   Shirazy A., 2018, J MINERAL RESOURCES, V2, P11
   Shirazy A., 2019, OPEN J GEOL, V9, P306, DOI 10.4236/ojg.2019.96021
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Tarkian M, 1999, MINER PETROL, V65, P161, DOI 10.1007/BF01161959
   Timkin T., 2015, IOP C SERIES EARTH E, V27, P1
   Voroshilov V., 2016, IOP C SERIES EARTH E, V43, P1
   Wegner T, 2012, ATMOS ENVIRON, V61, P350, DOI 10.1016/j.atmosenv.2012.07.048
   Xu LL, 2012, ORE GEOL REV, V48, P460, DOI 10.1016/j.oregeorev.2012.05.010
   Yang JG, 2012, COMPUT GEOSCI-UK, V49, P238, DOI 10.1016/j.cageo.2012.06.007
   Zhou SG, 2018, FRONT EARTH SCI-PRC, V12, P491, DOI 10.1007/s11707-017-0682-8
   Ziaii M, 2019, J GEOCHEM EXPLOR, V199, P16, DOI 10.1016/j.gexplo.2019.01.004
NR 43
TC 6
Z9 6
U1 0
U2 1
PU TOMSK POLYTECHNIC UNIV, PUBLISHING HOUSE
PI TOMSK
PA 30, LENIN AVE, TOMSK, 634050, RUSSIA
SN 2500-1019
EI 2413-1830
J9 BULL TOMSK POLYTECH
JI Bull. Tomsk Polytech. Univ.-Geo Assets Eng.
PD JUN 15
PY 2021
VL 332
IS 3
BP 113
EP 125
DI 10.18799/24131830/2021/03/3106
PG 13
WC Engineering, Geological
SC Engineering
GA RG7LR
UT WOS:000635716100009
DA 2023-04-26
ER

PT J
AU Lucchese, LV
   de Oliveira, GG
   Pedrollo, OC
AF Lucchese, Luisa Vieira
   de Oliveira, Guilherme Garcia
   Pedrollo, Olavo Correa
TI Mamdani fuzzy inference systems and artificial neural networks for landslide susceptibility mapping
SO NATURAL HAZARDS
LA English
DT Article
DE Rule set; Mass movement; Natural disasters; Map analysis; Map validation; Fuzzy rule interpretation
AB Two Artificial Intelligence (AI) methods, Fuzzy Inference System (FIS) and Artificial Neural Network (ANN), are applied to Landslide Susceptibility Mapping (LSM), to compare complementary aspects of the potentials of the two methods and to extract physical relationships from data. An index is proposed in order to rank and filter the FIS rules, selecting a certain number of readable rules for further interpretation of the physical relationships among variables. The area of study is Rolante river basin, southern Brazil. Eleven attributes are generated from a Digital Elevation Model (DEM), and landslide scars from an extreme rainfall event are used. Average accuracy and area under Receiver Operating Characteristic curve (AUC) resulted, respectively, in 81.27% and 0.8886 for FIS, and 89.45% and 0.9409 for ANN. ANN provides a map with more amplitude of outputs and less area classified as high susceptibility. Among the 40 (10%) best-ranked FIS rules, 13 have high susceptibility output, while 27 have low; a cause is that low susceptibility areas are larger on the map. Slope is highly connected to susceptibility. Elevation, when high (plateau) or low (floodplain), inhibits high susceptibility. Six attributes show the same fuzzy set for the 18 best-ranked rules, meaning this fuzzy set is common on the map. Overall findings point out that ANN is best suited for LSM map generation, but, based on them, using FIS is important to help researchers understand more about AI models for LSM and about landslide phenomenon.
C1 [Lucchese, Luisa Vieira; Pedrollo, Olavo Correa] Univ Fed Rio Grande do Sul, Inst Pesquisas Hidraul, Av Bento Goncalves 9500, BR-91501970 Porto Alegre, RS, Brazil.
   [de Oliveira, Guilherme Garcia] Univ Fed Rio Grande do Sul, Dept Interdisciplinar, Rodovia RS 030,11700,Km 92, BR-95590000 Tramandai, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul; Universidade Federal do Rio Grande do Sul
RP Lucchese, LV (corresponding author), Univ Fed Rio Grande do Sul, Inst Pesquisas Hidraul, Av Bento Goncalves 9500, BR-91501970 Porto Alegre, RS, Brazil.
EM luisa.lucchese@ufrgs.br
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq); Fundacao de Amparo a Pesquisa do Estado do Rio Grande do Sul (FAPERGS) [01/2017ARD, 17/2551-0000894-4]
CR Alaska Satellite Facility Distributed Active Archive Centre, 2014, ALOS PALSAR RTC RAD, V0, P0
   [Anonymous], 1990, NEUROCOMPUTING, V0, P0
   [Anonymous], 2009, PESQUISAS GEOCIE NCI, V0, P0, DOI DOI 10.22456/1807-9806.17874
   Arnone E, 2016, ENVIRON MODELL SOFTW, V84, P467, DOI 10.1016/j.envsoft.2016.07.016
   Benitez JM, 1997, IEEE T NEURAL NETWOR, V8, P1156, DOI 10.1109/72.623216
   Biswajeet P, 2010, DISASTER ADV, V3, P26
   Brenning A, 2005, NAT HAZARD EARTH SYS, V5, P853, DOI 10.5194/nhess-5-853-2005
   Cruden D., 1991, B INT ASS ENG GEOL, V43, P27, DOI 10.1007/BF02590167
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Dou J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060638
   DOURADO F, 2012, ANU INST GEOCIENC, V35, P43
   Driankov D, 1996, INTRO FUZZY CONTROL, V2nd, P0
   Ercanoglu M, 2002, ENVIRON GEOL, V41, P720, DOI 10.1007/s00254-001-0454-2
   FRANZMEIER DP, 1969, SOIL SCI SOC AM PRO, V33, P755, DOI 10.2136/sssaj1969.03615995003300050037x
   Guha-Sapir D., 2019, EM DAT EMERGENCY EVE, V0, P0
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huffman GJ, 2007, J HYDROMETEOROL, V8, P38, DOI 10.1175/JHM560.1
   ISARD SA, 1986, ARCTIC ALPINE RES, V18, P83, DOI 10.2307/1551216
   Kanungo DP, 2006, ENG GEOL, V85, P347, DOI 10.1016/j.enggeo.2006.03.004
   Kosko B., 1992, NEURAL NETWORKS FUZZ, V0, P0
   LEE CC, 1990, IEEE T SYST MAN CYB, V20, P404, DOI 10.1109/21.52551
   LEE CC, 1990, IEEE T SYST MAN CYB, V20, P419, DOI 10.1109/21.52552
   Lee S, 2004, GEOSCI J, V8, P51, DOI 10.1007/BF02910278
   Lucchese LV, 2021, CATENA, V198, P0, DOI 10.1016/j.catena.2020.105067
   Lucchese LV, 2020, ENVIRON MONIT ASSESS, V192, P0, DOI 10.1007/s10661-019-7968-0
   MAMDANI EH, 1977, IEEE T COMPUT, V26, P1182, DOI 10.1109/TC.1977.1674779
   Minsky M, 1961, I RADIO ENG, V0, P0
   Murphy K. P., 2012, MACHINE LEARNING PRO, V0, P0
   Neuhauser B, 2007, GEOMORPHOLOGY, V86, P12, DOI 10.1016/j.geomorph.2006.08.002
   Peethambaran B, 2019, NAT HAZARDS, V96, P121, DOI 10.1007/s11069-018-3532-4
   Pourghasemi HR, 2012, NAT HAZARDS, V63, P965, DOI 10.1007/s11069-012-0217-2
   Pradhan B, 2010, INT J COMPUT INT SYS, V3, P370, DOI 10.2991/ijcis.2010.3.3.12
   Rasmussen KL, 2013, GEOPHYS RES LETT, V40, P3457, DOI 10.1002/grl.50651
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Secretaria Estadual do Meio Ambiente Grupo de Pesquisa em Desastres Naturais, 2017, DIAGNOSTICO PRELIMIN, V0, P0
   Sen Z, 2010, FUZZY LOGIC HYDROLOG, V0, P0
   Servi?o Geol?gico do Brasil-CPRM, 2011, ATL PLUV BRAS IS ME, V0, P0
   TURNER S, 1994, EARTH PLANET SC LETT, V121, P333, DOI 10.1016/0012-821X(94)90076-0
   VOGL TP, 1988, BIOL CYBERN, V59, P257, DOI 10.1007/BF00332914
   Wang L, 2011, CATENA, V87, P90, DOI 10.1016/j.catena.2011.05.010
   WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466
   WANG LX, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, V0, PP1163, DOI 10.1109/FUZZY.1992.258721
   White IC, 1908, REPORT COAL MEASURES, V0, P0
   Xiao T, 2019, ACTA GEOCHIM, V38, P654, DOI 10.1007/s11631-019-00341-1
   ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhu AX, 2014, GEOMORPHOLOGY, V214, P128, DOI 10.1016/j.geomorph.2014.02.003
NR 47
TC 13
Z9 13
U1 1
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0921-030X
EI 1573-0840
J9 NAT HAZARDS
JI Nat. Hazards
PD APR 15
PY 2021
VL 106
IS 3
BP 2381
EP 2405
DI 10.1007/s11069-021-04547-6
EA FEB 2021
PG 25
WC Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources
SC Geology; Meteorology & Atmospheric Sciences; Water Resources
GA RM3RF
UT WOS:000616157900001
DA 2023-04-26
ER

PT J
AU Ghosh, S
   Konar, A
   Nagar, AK
AF Ghosh, Sayantani
   Konar, Amit
   Nagar, Atulya K.
TI Decoding Subjective Creativity Skill from Visuo-Spatial Reasoning Ability Using Capsule Graph Neural Network
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
LA English
DT Proceedings Paper
DE creativity; visuo-spatial reasoning; EEG; capsule graph neural network
AB Scientific creativity refers to the development of new and innovative ideas that foster technological growth and advancement. This paper attempts to identify creative individuals in scientific domain by evaluating their visuo-spatial reasoning ability using EEG analysis system. The main objective of the present work is achieved by first procuring EEG signals from the scalp of subjects involved in a mental paper folding task. The acquired signals are pre-processed and transformed into a topological map using correlation analysis to investigate the connectivity patterns amongst different brain lobes pertaining to different degrees of spatial abilities (high and low). The acquired brain networks depict strong interconnections amongst bilateral supramarginal gyrus, right anterior prefrontal and right superior temporal lobes for subject possessing high spatial skills. Since, the correlation based brain network analysis provides a qualitative illustration of the connectivity patterns, centrality induced quantitative analysis have been performed. Such an evaluation has been conducted using two categories of centrality measures viz. degree centrality and betweenness centrality. The results obtained from centrality analysis also infer the active involvement of the aforesaid brain regions during mental paper folding activity. Finally, the centrality based network features are transferred to a novel Capsule Graph Neural Network (CapsGNN) based classifier to categorize the desired class labels. Performance analysis undertaken confirms the superior functionality of the proposed network with respect to the conventional models. Moreover, statistical evaluation conducted also assures the supercilious performance of the proposed classifier. Thus, the present methodology can be utilized for recruiting creative individuals to different sectors of industries associated with innovation such as architecture, game designing and the like.
C1 [Ghosh, Sayantani; Konar, Amit] Jadavpur Univ, Elect & Telecommun Engn Dept, Kolkata, W Bengal, India.
   [Nagar, Atulya K.] Liverpool Hope Univ, Dept Math & Comp Sci, Liverpool, Merseyside, England.
C3 Jadavpur University; Liverpool Hope University
RP Ghosh, S (corresponding author), Jadavpur Univ, Elect & Telecommun Engn Dept, Kolkata, W Bengal, India.
EM sayantani.sonrisa25@gmail.com; konaramit@yahoo.co.in; nagara@hope.ac.uk
FU Ministry of Human Resource Development (MHRD)
CR [Anonymous], 2008, P 7 PYTHON SCI C SCI, V0, P0
   Berkan S.T., 2020, DESIGN TECHNOLOGY ED, V25, P103
   Chen, 2018, INT C LEARN REPR, V0, P0
   Davis B., 2015, SPATIAL REASONING EA, V0, P0
   Defferrard M., 2016, ADV NEURAL INFORM PR, V29, P3837, DOI 10.5555/3157382.3157527
   Ghosh L, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), V0, PP950, DOI 10.1109/SSCI.2018.8628779
   Glass L, 2013, CEREB CORTEX, V23, P1663, DOI 10.1093/cercor/bhs153
   Grover A, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP855, DOI 10.1145/2939672.2939754
   Howard A, 2019, IEEE I CONF COMP VIS, V0, PP1314, DOI 10.1109/ICCV.2019.00140
   Kachenoura A, 2008, IEEE SIGNAL PROC MAG, V25, P57, DOI 10.1109/MSP.2008.4408442
   Karlik B, 2011, INT J ARTIFICIAL INT, V4, P111
   Kell HJ, 2013, PSYCHOL SCI, V24, P1831, DOI 10.1177/0956797613478615
   Kipf T. N., 2016, ARXIV, V0, P0
   Konar A., 2018, ARTIFICIAL INTELLIGE, V0, P0
   Li R., 2018, PROC IEEE GLOBECOM W, V0, P1
   Lourenco SF, 2018, HETEROGENEITY OF FUNCTION IN NUMERICAL COGNITION, V0, PP177, DOI 10.1016/B978-0-12-811529-9.00010-8
   Lovett A., 2013, P ANN M COGN SCI SOC, V35, P0
   Ma F, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212586
   Maas Andrew L., 2013, PROC 30 INT C MACH L, V0, P0
   Manoilov P, 2006, P INT C COMP SYST TE, V0, P15
   MATLIN MW, 2005, COGNITION, V0, P0
   Milivojevic B, 2003, NEUROPSYCHOLOGIA, V41, P1345, DOI 10.1016/S0028-3932(03)00060-5
   Palmiero M., 2015, COGNITION EXPERIENCE, V1, P189
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Sabour S., 2017, DYNAMIC ROUTING CAPS, V0, P0
   Suh J, 2020, THINK SKILLS CREAT, V35, P0, DOI 10.1016/j.tsc.2020.100628
   Sun X., 2008, SAS GLOB FORUM, V382, P1
   Thee KW, 2018, IEEE ACCESS, V6, P64708, DOI 10.1109/ACCESS.2018.2877035
   van Wijk BCM, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0013701
   Verma S., 2018, ARXIV180508090, V0, P0
   Wang FW, 2018, RSC ADV, V8, P29745, DOI 10.1039/c8ra04846k
   Widmann A, 2015, J NEUROSCI METH, V250, P34, DOI 10.1016/j.jneumeth.2014.08.002
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   ZHANG Q, 2019, COMPUT SOC NETW, V6, P1, DOI 10.14504/AJR.6.S1.1
   Zhao Z., 2019, ARXIV190309662, V0, P0
   Zhuang CY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), V0, PP499, DOI 10.1145/3178876.3186116
NR 36
TC 0
Z9 0
U1 7
U2 11
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-4393
EI 
J9 IEEE IJCNN
PD JUN 15
PY 2021
VL 0
IS 
BP 
EP 
DI 10.1109/IJCNN52387.2021.9533417
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA BS4TO
UT WOS:000722581701007
DA 2023-04-26
ER

PT J
AU Li, H
   Zech, J
   Ludwig, C
   Fendrich, S
   Shapiro, A
   Schultz, M
   Zipf, A
AF Li, Hao
   Zech, Johannes
   Ludwig, Christina
   Fendrich, Sascha
   Shapiro, Aurelie
   Schultz, Michael
   Zipf, Alexander
TI Automatic mapping of national surface water with OpenStreetMap and Sentinel-2 MSI data using deep learning
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Volunteered geographical information; Inland surface water; SDG 6; Copernicus; Deep learning; OpenStreetMap; Superpixel
ID high-spatial-resolution; time-series; land-cover; index ndwi; classification; extraction; accuracy; image; wetlands; quality
AB Large-scale mapping activities can benefit from the vastly increasing availability of earth observation (EO) data, especially when combined with volunteered geographical information (VGI) using machine learning (ML). Highresolution maps of inland surface water bodies are important for water supply and natural disaster mitigation as well as for monitoring, managing, and preserving landscapes and ecosystems. In this paper, we propose an automatic surface water mapping workflow by training a deep residual neural network (ResNet) based on OpenStreetMap (OSM) data and Sentinel-2 multispectral data, where the Simple Non-Iterative Clustering (SNIC) superpixel algorithm was employed for generating object-based training samples. As a case study, we produced an open surface water layer for Germany using a national ResNet model at a 10 m spatial resolution, which was then harmonized with OSM data for final surface water products. Moreover, we evaluated the mapping accuracy of our open water products via conducting expert validation campaigns, and comparing to existing water products, namely the WasserBLIcK and Global Surface Water Layer (GSWL). Using 4,600 validation samples in Germany, the proposed model (ResNet+SNIC) achieved an overall accuracy of 86.32% and competitive detection rates over the WasserBLIcK (87.47%) and GSWL (98.61%). This study provides comprehensive insights into how to best explore the synergy of VGI and ML of EO data in a large-scale surface water mapping task.
C1 [Li, Hao; Zech, Johannes; Ludwig, Christina; Schultz, Michael; Zipf, Alexander] Heidelberg Univ, Inst Geog, GISci Chair, D-69120 Heidelberg, Germany.
   [Fendrich, Sascha; Zipf, Alexander] Heidelberg Univ, HeiGIT, Schloss Wolfsbrunnenweg 33, D-69118 Heidelberg, Germany.
   [Shapiro, Aurelie] United Nations FAO, Food & Agr Org, Viale Terme di Caracalla, I-00153 Rome, Italy.
C3 Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg; Food & Agriculture Organization of the United Nations (FAO)
RP Li, H (corresponding author), Heidelberg Univ, Inst Geog, GISci Chair, D-69120 Heidelberg, Germany.
EM hao.li@uni-heidelberg.de; johannes.zech@alumni.uni-heidelberg.de; christina.ludwig@uni-heidelberg.de; sascha.fendrich@heigit.org; aurelie.shapiro@fao.org; michael.schultz@uni-heidelberg.de; zipf@uni-heidelberg.de
FU Klaus Tschira Stiftung (KTS) Heidelberg
CR Abadi M, 2016, PROCEEDINGS OF OSDI16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, V0, P265
   Achanta R, 2017, PROC CVPR IEEE, V0, PP4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2015, AUST J EMERG MANAG, V30, P9
   [Anonymous], 2016, WORLD DISASTERS REPO, V0, P0
   Arle J., 2017, WATERS GERMANY STATU, V0, P0
   Arsanjani JJ, 2013, INT J GEOGR INF SCI, V27, P2264, DOI 10.1080/13658816.2013.800871
   Barron C, 2014, T GIS, V18, P877, DOI 10.1111/tgis.12073
   BfG, 2021, WASSERBLICK, V0, P0
   BfG, 2020, RIV CATCHM DISTR GER, V0, P0
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Cao ZG, 2019, ISPRS J PHOTOGRAMM, V153, P110, DOI 10.1016/j.isprsjprs.2019.05.001
   Chen JY, 2019, IEEE T GEOSCI REMOTE, V57, P1713, DOI 10.1109/TGRS.2018.2868748
   Chollet F., 2015, KERAS, V0, P0
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Davranche A, 2013, REMOTE SENS ENVIRON, V138, P165, DOI 10.1016/j.rse.2013.07.015
   Desnos YL, 2014, IEEE GEOSC REM SEN M, V2, P37, DOI 10.1109/MGRS.2014.2319270
   Donchyts G, 2016, NAT CLIM CHANGE, V6, P810, DOI 10.1038/nclimate3111
   Donchyts G, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050386
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Du SH, 2015, ISPRS J PHOTOGRAMM, V105, P107, DOI 10.1016/j.isprsjprs.2015.03.011
   Ebrahimy H, 2021, ISPRS J PHOTOGRAMM, V172, P17, DOI 10.1016/j.isprsjprs.2020.11.024
   Erwin KL, 2009, WETL ECOL MANAG, V17, P71, DOI 10.1007/s11273-008-9119-1
   Fan HC, 2014, INT J GEOGR INF SCI, V28, P700, DOI 10.1080/13658816.2013.867495
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   Fisher A, 2016, REMOTE SENS ENVIRON, V175, P167, DOI 10.1016/j.rse.2015.12.055
   Fluet-Chouinard E, 2015, REMOTE SENS ENVIRON, V158, P348, DOI 10.1016/j.rse.2014.10.015
   Fonte CC, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6040125
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Ghamisi P, 2017, IEEE GEOSCI REMOTE S, V14, P659, DOI 10.1109/LGRS.2017.2669304
   GOETZ AFH, 1985, SCIENCE, V228, P1147, DOI 10.1126/science.228.4704.1147
   Goodchild MF, 1997, INT J GEOGR INF SCI, V11, P299, DOI 10.1080/136588197242419
   Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y
   Goodchild MF, 2012, SPAT STAT-NETH, V1, P110, DOI 10.1016/j.spasta.2012.03.002
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2
   Hansen MC, 2008, REMOTE SENS ENVIRON, V112, P2495, DOI 10.1016/j.rse.2007.11.012
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Herfort B, 2021, SCI REP-UK, V11, P0, DOI 10.1038/s41598-021-82404-z
   Herfort B, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151799
   Hrudey SE, 2006, ENVIRON INT, V32, P948, DOI 10.1016/j.envint.2006.06.004
   Huang ZM, 2016, INT GEOSCI REMOTE SE, V0, PP1835, DOI 10.1109/IGARSS.2016.7729471
   Isikdogan F, 2017, IEEE J-STARS, V10, P4909, DOI 10.1109/JSTARS.2017.2735443
   Karpatne A, 2016, STUD COMPUT INTELL, V645, P121, DOI 10.1007/978-3-319-31858-5_7
   Li H, 2020, ISPRS J PHOTOGRAMM, V166, P41, DOI 10.1016/j.isprsjprs.2020.05.007
   Ludwig C, 2019, REMOTE SENS ENVIRON, V224, P333, DOI 10.1016/j.rse.2019.01.017
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   OpenStreetMap Wiki,, 2020, EL OP WIK, V0, P0
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Raifer Martin, 2019, OPEN GEOSPATIAL DATA, V0, P0, DOI 10.1186/s40965-019-0061-3
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS
   Russwurm M, 2020, ISPRS J PHOTOGRAMM, V169, P421, DOI 10.1016/j.isprsjprs.2020.06.006
   Sarukhan J., 2005, ECOSYSTEMS HUMAN WEL, V0, P0
   Schmitt M, 2020, PFG-J PHOTOGRAMM REM, V88, P271, DOI 10.1007/s41064-020-00111-2
   Scholz S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081239
   Schroter D., 2005, KLIMASTATUSBERICHT D, V2005, P44
   Schultz M, 2017, INT J APPL EARTH OBS, V63, P206, DOI 10.1016/j.jag.2017.07.014
   Sivanpillai R, 2010, ECOL INFORM, V5, P73, DOI 10.1016/j.ecoinf.2009.09.013
   Talukdar S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071135
   Tulbure MG, 2016, REMOTE SENS ENVIRON, V178, P142, DOI 10.1016/j.rse.2016.02.034
   United Nations, 2015, TRANSF OUR WORLD 203, V0, P0
   Vargas-Munoz JE, 2021, IEEE GEOSC REM SEN M, V9, P184, DOI 10.1109/MGRS.2020.2994107
   Verpoorter C, 2014, GEOPHYS RES LETT, V41, P6396, DOI 10.1002/2014GL060641
   Willig M, 2018, PYSNIC, V0, P0
   Wu Z., 2020, P ACAD TRACK STATE M, V0, P0
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Xu YY, 2019, T GIS, V23, P224, DOI 10.1111/tgis.12514
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091461
   Yang XC, 2020, REMOTE SENS ENVIRON, V244, P0, DOI 10.1016/j.rse.2020.111803
   Yang XC, 2018, REMOTE SENS ENVIRON, V219, P259, DOI 10.1016/j.rse.2018.09.016
   Zhang GY, 2015, IEEE T GEOSCI REMOTE, V53, P5861, DOI 10.1109/TGRS.2015.2423688
   Zhang T, 2013, REMOTE SENS-BASEL, V5, P4470, DOI 10.3390/rs5094470
   Zhou YA, 2014, IEEE J-STARS, V7, P4301, DOI 10.1109/JSTARS.2014.2360436
   Zhu XX, 2020, IEEE GEOSC REM SEN M, V8, P76, DOI 10.1109/MGRS.2020.2964708
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 76
TC 6
Z9 6
U1 5
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 15
PY 2021
VL 104
IS 
BP 
EP 
DI 10.1016/j.jag.2021.102571
PG 16
WC Remote Sensing
SC Remote Sensing
GA XC2JQ
UT WOS:000721846200004
DA 2023-04-26
ER

PT J
AU Ferles, C
   Papanikolaou, Y
   Savaidis, SP
   Mitilineos, SA
AF Ferles, Christos
   Papanikolaou, Yannis
   Savaidis, Stylianos P.
   Mitilineos, Stelios A.
TI Deep Self-Organizing Map of Convolutional Layers for Clustering and Visualizing Image Data
SO MACHINE LEARNING AND KNOWLEDGE EXTRACTION
LA English
DT Article
DE deep learning; unsupervised learning; convolutional neural network (CNN); self-organizing map (SOM); clustering; visualization
ID neural-network
AB The self-organizing convolutional map (SOCOM) hybridizes convolutional neural networks, self-organizing maps, and gradient backpropagation optimization into a novel integrated unsupervised deep learning model. SOCOM structurally combines, architecturally stacks, and algorithmically fuses its deep/unsupervised learning components. The higher-level representations produced by its underlying convolutional deep architecture are embedded in its topologically ordered neural map output. The ensuing unsupervised clustering and visualization operations reflect the model's degree of synergy between its building blocks and synopsize its range of applications. Clustering results are reported on the STL-10 benchmark dataset coupled with the devised neural map visualizations. The series of conducted experiments utilize a deep VGG-based SOCOM model.
C1 [Ferles, Christos; Papanikolaou, Yannis; Savaidis, Stylianos P.; Mitilineos, Stelios A.] Univ West Attica, Dept Elect & Elect Engn, GR-12241 Aegaleo, Attica, Greece.
RP Ferles, C (corresponding author), Univ West Attica, Dept Elect & Elect Engn, GR-12241 Aegaleo, Attica, Greece.
EM christos.ferles@gmail.com
FU European Union (European Social Fund-ESF) [MIS 5050185]
CR Aly S, 2020, IEEE ACCESS, V8, P107035, DOI 10.1109/ACCESS.2020.3000829
   Nguyen A, 2015, PROC CVPR IEEE, V0, PP427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], 2009, ICML 2009 WORKSH LEA, V0, P0
   Bach S, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0130140
   Bo L., 2013, EXPT ROBOTICS, V0, PP387, DOI 10.1007/978-3-319-00065-7
   Braga PHM, 2020, IEEE IJCNN, V0, P0
   Brugger D, 2008, IEEE T NEURAL NETWOR, V19, P442, DOI 10.1109/TNN.2007.909556
   Carter S., 2019, DISTILL, V4, PE15, DOI 10.23915/DISTILL.00015
   Chang JL, 2017, IEEE I CONF COMP VIS, V0, PP5880, DOI 10.1109/ICCV.2017.626
   Coates A., 2011, AISTATS, V0, P0
   Dosovitskiy A., 2014, ADV NEURAL INFORM PR, V0, P0
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Dundar Aysegul., 2015, CONVOLUTIONAL CLUSTE, V0, P0
   Ferles C., 2021, P 2 INT C ART INT BI, V0, P25
   Ferles C, 2018, NEURAL NETWORKS, V105, P112, DOI 10.1016/j.neunet.2018.04.016
   Ferles C, 2017, METHODS MOL BIOL, V1552, P83, DOI 10.1007/978-1-4939-6753-7_6
   Ferles C, 2013, NEURAL NETWORKS, V48, P133, DOI 10.1016/j.neunet.2013.07.011
   Forti A, 2006, NEURAL NETWORKS, V19, P1568, DOI 10.1016/j.neunet.2006.02.009
   Friedlander D., 2018, ARXIV180308996, V0, P0
   Glorot X., 2010, P 13 INT C ART INT S, V0, P249
   Goodfellow Ian J, 2014, ARXIV14126572, V0, P0
   Haeusser P., 2018, GERM C PATT REC, V0, P18
   Hankins R, 2018, LECT NOTES COMPUT SC, V11314, P838, DOI 10.1007/978-3-030-03493-1_87
   Heskes T, 1999, KOHONEN MAPS, V0, PP303, DOI 10.1016/B978-044450270-4/50024-3
   Hoffer E., 2016, ARXIV, V0, P0
   Hsu AL, 2003, BIOINFORMATICS, V19, P2131, DOI 10.1093/bioinformatics/btg296
   Ji X, 2019, IEEE I CONF COMP VIS, V0, PP9864, DOI 10.1109/ICCV.2019.00996
   Jin HD, 2004, INFORM SCIENCES, V163, P157, DOI 10.1016/j.ins.2003.03.020
   King DB, 2015, ACS SYM SER, V1214, P1
   Kohonen T., 1995, SELF ORG MAPS, V0, PP30, DOI 10.1007/978-3-642-97610-0
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Liu N, 2015, IEEE IJCNN, V0, P0
   Loshchilov I., 2017, ARXIV171105101, V0, P0
   Mahendran A, 2015, PROC CVPR IEEE, V0, PP5188, DOI 10.1109/CVPR.2015.7299155
   Malondkar A, 2019, INFORM SCIENCES, V496, P572, DOI 10.1016/j.ins.2018.12.007
   Miclut B, 2014, LECT NOTES COMPUT SC, V8753, P736, DOI 10.1007/978-3-319-11752-2_62
   Nakayama H, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.100
   Nam W.-J., 2020, ARXIV201203434, V0, P0
   Nguyen A., 2016, ADV NEURAL INFORM PR, V0, P0
   Northcutt C. G., 2021, PERVASIVE LABEL ERRO, V0, P0
   Olah C., 2017, DISTILL, V2, P0, DOI 10.23915/DISTILL.00007
   Olah Chris, 2018, BUILDING BLOCKS INTE, V3, P10, DOI 10.23915/distill. 00010
   Paine T. L., 2014, ARXIV14126597, V0, P0
   Pampalk E, 2002, LECT NOTES COMPUT SC, V2415, P871
   Part Jose L, 2016, WORKSH BIOINSP SOC R, V0, P0
   Pesteie M., 2018, ICLR WORKSH VANC BC, V0, P0
   Polzlbauer G, 2006, NEURAL NETWORKS, V19, P911, DOI 10.1016/j.neunet.2006.05.013
   Pointer I., 2019, PROGRAMMING PYTORCH, V0, P0
   Razavian AS, 2014, IEEE COMPUT SOC CONF, V0, PP512, DOI 10.1109/CVPRW.2014.131
   Sakkari M, 2020, MULTIMED TOOLS APPL, V79, P19451, DOI 10.1007/s11042-020-08822-9
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K., 2013, P INT C LEARNING REP, V0, P0
   Simonyan K, 2015, ARXIV, V0, P0
   Smith LN, 2017, IEEE WINT CONF APPL, V0, PP464, DOI 10.1109/WACV.2017.58
   Stuhr B., 2019, P 2019 18 IEEE INT C, V0, P0
   Sutskever I., 2013, INT C MACHINE LEARNI, V0, P1139
   Szegedy, 2014, INTRIGUING PROPERTIE, V0, P0, DOI DOI 10.1109/CVPR.2015.7298594
   Tasdemir K, 2009, IEEE T NEURAL NETWOR, V20, P549, DOI 10.1109/TNN.2008.2005409
   Ultsch, 2005, P WORKSH SELF ORG MA, V0, P75
   Ultsch A., 2003, P WORKSH SELF ORG MA, V0, P225
   Vesanto J., 1999, INTELL DATA ANAL, V3, P111, DOI 10.1016/S1088-467X(99)00013-X
   Wang D, 2016, PATTERN RECOGN, V60, P473, DOI 10.1016/j.patcog.2016.06.001
   Wang M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM17), V0, PP1707, DOI 10.1145/3123266.3123415
   Wickramasinghe CS, 2019, IEEE T IND INFORM, V15, P5837, DOI 10.1109/TII.2019.2906083
   Xie JY, 2016, PR MACH LEARN RES, V48, P0
   Yin HJ, 2002, IEEE T NEURAL NETWOR, V13, P237, DOI 10.1109/72.977314
   Yosinski J., 2015, ARXIV150606579, V0, P0
   Yosinski J, 2014, ADV NEUR IN, V27, P0
   Yu W., 2016, P 33 RD INT C MACHIN, V0, P0
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zintgraf L. M., 2016, ARXIV160302518, V0, P0
NR 71
TC 1
Z9 1
U1 0
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2504-4990
J9 MACH LEARN KNOW EXTR
JI Mach. Learn. Knowl. Extr.
PD DEC 15
PY 2021
VL 3
IS 4
BP 879
EP 899
DI 10.3390/make3040044
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA XY7CB
UT WOS:000737124400001
DA 2023-04-26
ER

PT J
AU Zeng, W
   Lin, CQ
   Lin, JC
   Jiang, JC
   Xia, JZ
   Turkay, C
   Chen, W
AF Zeng, Wei
   Lin, Chengqiao
   Lin, Juncong
   Jiang, Jincheng
   Xia, Jiazhi
   Turkay, Cagatay
   Chen, Wei
TI Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE MAUP; traffic prediction; deep learning; model diagnostic; visual analytics
ID aggregation; scales
AB Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a Bivariate Map equipped with an advanced bivariate colormap to simultaneously depict input traffic and prediction errors across space, 2) a Moran's I Scatterplot that provides local indicators of spatial association analysis, and 3) a Multi-scale Attribution View that arranges non-linear dot plots in a tree layout to promote model analysis and comparison across scales. We evaluate our approach through a series of case studies involving a real-world dataset of Shenzhen taxi trips, and through interviews with domain experts. We observe that geographical scale variations have important impact on prediction performances, and interactive visual exploration of dynamically varying inputs and outputs benefit experts in the development of deep traffic prediction models.
C1 [Zeng, Wei; Jiang, Jincheng] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
   [Lin, Chengqiao; Lin, Juncong] Xiamen Univ, Xiamen, Peoples R China.
   [Xia, Jiazhi] Cent South Univ, Changsha, Peoples R China.
   [Turkay, Cagatay] Univ Warwick, Coventry, W Midlands, England.
   [Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Xiamen University; Central South University; University of Warwick; Zhejiang University
RP Lin, JC (corresponding author), Xiamen Univ, Xiamen, Peoples R China.
EM wei.zeng@siat.ac.cn; linchengqiao@xmu.edu.cn; jclin@xmu.edu.cn; jc.jiang@siat.ac.cn; xiajiazhi@csu.edu.cn; cagatay.turkay@warwick.ac.uk; chenwei@cad.zju.edu.cn
FU National Natural Science Foundation of China [61772456, U1609217, 61802388, 61702433, 61872389, 41701452]
CR Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   [Anonymous], 1954, INCORPORATED STAT, V0, P0
   ANSELIN L, 1995, GEOGR ANAL, V27, P93, DOI 10.1111/j.1538-4632.1995.tb00338.x
   Brunsdon C, 1996, GEOGR ANAL, V28, P281, DOI 10.1111/j.1538-4632.1996.tb00936.x
   Cao K, 2021, IEEE T IND INFORM, V17, P494, DOI 10.1109/TII.2020.2975897
   Correll M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), V0, P0, DOI DOI 10.1145/3173574.3174216
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Duque JC, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0207377
   Gehlke CE, 1934, J AM STAT ASSOC, V29, P169, DOI 10.2307/2277827
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Guo DS, 2009, IEEE T VIS COMPUT GR, V15, P1041, DOI 10.1109/TVCG.2009.143
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Huang Z., 2019, IEEE TVCG, V26, P2576
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lapuschkin S, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-08987-4
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Ming Y, 2017, IEEE CONF VIS ANAL, V0, PP13, DOI 10.1109/VAST.2017.8585721
   Moeckel R, 2015, ENVIRON PLANN B, V42, P888, DOI 10.1068/b130199p
   Moorthy C. K., 1988, TRANSPORT PLAN TECHN, V12, P45, DOI 10.1080/03081068808717359
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, V0, PP86, DOI 10.1109/CVPR.2017.17
   MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.1093/biomet/37.1-2.17
   Nelson JK, 2017, CARTOGR GEOGR INF SC, V44, P35, DOI 10.1080/15230406.2015.1093431
   Openshaw S., 1984, CONCEPTS TECHNIQUES, V38, P41
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pena-Araya V, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI20), V0, P0, DOI DOI 10.1145/3313831.3376350
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Rodrigues N, 2018, IEEE T VIS COMPUT GR, V24, P616, DOI 10.1109/TVCG.2017.2744018
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Shen QM, 2020, IEEE PAC VIS SYMP, V0, PP61, DOI 10.1109/PacificVis48177.2020.2785
   Shen QM, 2018, IEEE T VIS COMPUT GR, V24, P1004, DOI 10.1109/TVCG.2017.2744159
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Turkay C, 2014, IEEE T VIS COMPUT GR, V20, P2033, DOI 10.1109/TVCG.2014.2346265
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang DD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, V0, P0, DOI DOI 10.1145/3290605.3300831
   Wang P, 2012, SCI REP-UK, V2, P0, DOI 10.1038/srep01001
   Wang YZ, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13882
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wilkinson L, 1999, AM STAT, V53, P276, DOI 10.2307/2686111
   Williams BM, 1998, TRANSPORT RES REC, V0, PP132, DOI 10.3141/1644-14
   Wu WC, 2017, IEEE PAC VIS SYMP, V0, PP91, DOI 10.1109/PACIFICVIS.2017.8031583
   Xu YY, 2014, IEEE T INTELL TRANSP, V15, P2457, DOI 10.1109/TITS.2014.2315794
   Yao HX, 2018, AAAI CONF ARTIF INTE, V0, P2588
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng W, 2013, COMPUT GRAPH FORUM, V32, P271, DOI 10.1111/cgf.12114
   Zhang JW, 2016, COMPUT GRAPH FORUM, V35, P441, DOI 10.1111/cgf.12920
   Zhang JB, 2017, AAAI CONF ARTIF INTE, V0, P1655
   Zhang Y, 2016, COMPUT GRAPH FORUM, V35, P101, DOI 10.1111/cgf.12886
   Zhang YF, 2017, IEEE T VIS COMPUT GR, V23, P371, DOI 10.1109/TVCG.2016.2598541
   Zheng S, 2016, PROC CVPR IEEE, V0, PP4480, DOI 10.1109/CVPR.2016.485
NR 54
TC 15
Z9 16
U1 6
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 15
PY 2021
VL 27
IS 2
BP 839
EP 848
DI 10.1109/TVCG.2020.3030410
PG 10
WC Computer Science, Software Engineering
SC Computer Science
GA WF5FO
UT WOS:000706330100069
PM 33074818
DA 2023-04-26
ER

PT J
AU Gavrilov, AI
   Parfentiev, KV
AF Gavrilov, Alexandr Igorevich
   Parfentiev, Kirill Victorovich
TI Solving the Problem of Autonomous Navigation Using Underlying Surface Models Tolerant to Survey Conditions
SO XLIV ACADEMIC SPACE CONFERENCE: DEDICATED TO THE MEMORY OF ACADEMICIAN S.P. KOROLEV AND OTHER OUTSTANDING RUSSIAN SCIENTISTS - PIONEERS OF SPACE EXPLORATION
LA English
DT Proceedings Paper
DE Unmanned aerial vehicle; artificial neural networks; underlying surface; digital image processing; boundary detection; autonomous navigation
ID uav; system
AB The problem of autonomous navigation becomes more relevant in the aerospace industry. To solve it successfully, it is necessary to build underlying surface models tolerant to survey conditions. Such models can serve as a basis for solving wide variety of tasks, such as building topographic map of the terrain, navigating the underlying surface, automatic landing of the aircraft. The main problem with building underlying surface models according to monitoring data in the visible spectrum are changes in the survey conditions, such as time of year, time of day, various weather events. The problem can be solved by using algorithms of integration of data collected in various frequency bands and image preprocessing. The paper looks at the task of using data obtained through remote sensing of the underlying surface in optical and radar ranges with the purpose of determining navigational parameters and binding objects to space axes. The paper also considers different approaches to image preprocessing. Comparative studies of existing methods in this sphere were carried out. The algorithm for conversion of digital images into a tolerant to survey conditions form was suggested and realized. We developed the structure and software implementation of the system for determining geographical coordinates using preprocessed underlying surface image. Effectiveness of the suggested algorithms and software was validated by solving the problem of determining positions on images obtained with the help of satellite, radar, and aerial photography under different environmental and lighting conditions.
C1 [Gavrilov, Alexandr Igorevich; Parfentiev, Kirill Victorovich] Bauman Moscow State Tech Univ, Moscow, Russia.
C3 Bauman Moscow State Technical University
RP Gavrilov, AI (corresponding author), Bauman Moscow State Tech Univ, Moscow, Russia.
EM alexandre.gavrilov@iul.bmstu.ru; parfentiev@bmstu.ru
CR Bandini F, 2020, REMOTE SENS ENVIRON, V237, P0, DOI 10.1016/j.rse.2019.111487
   Brown M. P., 2004, APPL PHYS LETT, V85, P2503
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Coffey T., 2002, DEFENSE HORIZ, V22, P1
   Filippelli SK, 2019, REMOTE SENS ENVIRON, V224, P154, DOI 10.1016/j.rse.2019.01.029
   Gavrilov AI, 2019, AIP CONF PROC, V2171, P0, DOI 10.1063/1.5133235
   Gohl P, 2014, APPL ROB POW IND CAR, V2014, P1
   Goncalves JA, 2015, ISPRS J PHOTOGRAMM, V104, P101, DOI 10.1016/j.isprsjprs.2015.02.009
   [柯芳 Ke Fang], 2010, 兵工学报 ACTA ARMAMENTARII, V31, P939
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Moriano P, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL WORKSHOP ON MANAGING INSIDER SECURITY THREATS (MIST17), V0, PP1, DOI 10.1145/3139923.3139928
   Nelson, 2004, P AIAA 4 AV TECHN IN, V0, P6243
   Neusypin K. A., 2014, JOURNAL OF NANJING UNIVERSITY OF SCIENCE AND TECHNOLOGY, V38, P602
   Shakhtarin BI, 2016, J COMMUN TECHNOL EL+, V61, P1252, DOI 10.1134/S1064226916110115
   Shen K, 2018, MEAS TECH+, V60, P991, DOI 10.1007/s11018-018-1306-8
   Sobel I., 1968, P PATT CLASS SCEN AN, V0, P271
   Tkachev Sergey B., 2015, IFAC - PAPERS ONLINE, V48, P10, DOI 10.1016/j.ifacol.2015.09.152
   Tokekar P, 2016, IEEE T ROBOT, V32, P1498, DOI 10.1109/TRO.2016.2603528
   Valavanis K. P., 2015, HDB UNMANNED AERIAL, V0, PP2639, DOI 10.1007/978-90-481-9707-1_151
   Voronov E. M., 2010, OPT MEMORY NEURAL, V19, P291
   Walker O, 2019, AEROSP CONF PROC, V0, P0
   Wang YN, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, V0, PP2580, DOI 10.1109/ICInfA.2015.7279720
   Yuan C, 2015, INT CONF UNMAN AIRCR, V0, PP639, DOI 10.1109/ICUAS.2015.7152345
   Zhou YM, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE ROBIO 2017), V0, P2515
NR 24
TC 0
Z9 0
U1 0
U2 2
PU AMER INST PHYSICS
PI MELVILLE
PA 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA
SN 0094-243X
EI 
J9 AIP CONF PROC
PD JUN 15
PY 2021
VL 2318
IS 
BP 
EP 
DI 10.1063/5.0038605
PG 6
WC Engineering, Aerospace; Astronomy & Astrophysics
SC Engineering; Astronomy & Astrophysics
GA BR6UN
UT WOS:000664196200217
DA 2023-04-26
ER

PT J
AU Chen, WC
   Hu, MC
   Chen, CS
AF Chen, Wen-Cheng
   Hu, Min-Chun
   Chen, Chu-Song
TI STR-GQN: Scene Representation and Rendering for Unknown Cameras Based on Spatial Transformation Routing
SO 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021)
LA English
DT Proceedings Paper
AB Geometry-aware modules are widely applied in recent deep learning architectures for scene representation and rendering. However, these modules require intrinsic camera information that might not be obtained accurately. In this paper, we propose a Spatial Transformation Routing (STR) mechanism to model the spatial properties without applying any geometric prior. The STR mechanism treats the spatial transformation as the message passing process, and the relation between the view poses and the routing weights is modeled by an end-to-end trainable neural network. Besides, an Occupancy Concept Mapping (OCM) framework is proposed to provide explainable rationals for scene-fusion processes. We conducted experiments on several datasets and show that the proposed STR mechanism improves the performance of the Generative Query Network (GQN). The visualization results reveal that the routing process can pass the observed information from one location of some view to the associated location in the other view, which demonstrates the advantage of the proposed model in terms of spatial cognition.
C1 [Chen, Wen-Cheng] Natl Cheng Kung Univ, Tainan, Taiwan.
   [Hu, Min-Chun] Natl Tsing Hua Univ, Hsinchu, Taiwan.
   [Chen, Chu-Song] Natl Taiwan Univ, Taipei, Taiwan.
C3 National Cheng Kung University; National Tsing Hua University; National Taiwan University
RP Chen, WC (corresponding author), Natl Cheng Kung Univ, Tainan, Taiwan.
EM jerrywiston@mislab.csie.ncku.edu.tw; anitahu@cs.nthu.edu.tw; chusong@csie.ntu.edu.tw
CR Chen X, 2019, IEEE I CONF COMP VIS, V0, PP4089, DOI 10.1109/ICCV.2019.00419
   Choi I, 2019, IEEE I CONF COMP VIS, V0, PP7780, DOI 10.1109/ICCV.2019.00787
   Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170
   Godard C, 2017, PROC CVPR IEEE, V0, PP6602, DOI 10.1109/CVPR.2017.699
   Gordon A, 2019, IEEE I CONF COMP VIS, V0, PP8976, DOI 10.1109/ICCV.2019.00907
   Gregor K, 2016, ADV NEUR IN, V29, P0
   Hinton G. E., 2018, INT C LEARNING REPRE, V0, P0
   Lombardi S, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3306346.3323020
   Mildenhall B., 2020, ECCV, V0, PP405, DOI 10.1007/978-3-030-58452-8_24
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Olszewski K, 2019, IEEE I CONF COMP VIS, V0, PP7647, DOI 10.1109/ICCV.2019.00774
   Park E, 2017, PROC CVPR IEEE, V0, PP702, DOI 10.1109/CVPR.2017.82
   Schonberger JL, 2016, PROC CVPR IEEE, V0, PP4104, DOI 10.1109/CVPR.2016.445
   Sitzmann V, 2019, PROC CVPR IEEE, V0, PP2432, DOI 10.1109/CVPR.2019.00254
   Sitzmann Vincent, 2019, NEURIPS, V0, P0
   Sun SH, 2018, LECT NOTES COMPUT SC, V11207, P162, DOI 10.1007/978-3-030-01219-9_10
   Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Tobin Joshua, 2019, ADV NEURAL INFORM PR, V0, P11559
   Tulsiani S, 2018, PROC CVPR IEEE, V0, PP2897, DOI 10.1109/CVPR.2018.00306
   Tulsiani S, 2017, PROC CVPR IEEE, V0, PP209, DOI 10.1109/CVPR.2017.30
   Tung HYF, 2019, PROC CVPR IEEE, V0, PP2590, DOI 10.1109/CVPR.2019.00270
   Wiles Olivia, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP7465, DOI 10.1109/CVPR42600.2020.00749
   Wu J., 2017, ARXIV171103129, V0, P0
   Yan XC, 2016, ADV NEUR IN, V29, P0
   Zhan HY, 2018, PROC CVPR IEEE, V0, PP340, DOI 10.1109/CVPR.2018.00043
   Zhou TH, 2017, PROC CVPR IEEE, V0, PP6612, DOI 10.1109/CVPR.2017.700
   Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18
NR 28
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 
PD JUN 15
PY 2021
VL 0
IS 
BP 5946
EP 5955
DI 10.1109/ICCV48922.2021.00591
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory & Methods
SC Computer Science
GA BT1IF
UT WOS:000797698906018
DA 2023-04-26
ER

PT J
AU Shen, F
   Liu, J
   Wu, K
AF Shen, Fang
   Liu, Jing
   Wu, Kai
TI Multivariate Time Series Forecasting Based on Elastic Net and High-Order Fuzzy Cognitive Maps: A Case Study on Human Action Prediction Through EEG Signals
SO IEEE TRANSACTIONS ON FUZZY SYSTEMS
LA English
DT Article
DE Time series analysis; Electroencephalography; Forecasting; Prediction algorithms; Brain modeling; Predictive models; Proposals; 1D-convolutional neural network (1D-CNN); elastic net; electroencephalogram (EEG); fuzzy cognitive map (FCM); time series prediction
ID management-system; neural-network; design; classification; performance; extraction; selection; auc
AB Fuzzy cognitive maps (FCMs) have been successfully applied to time series forecasting. However, it still remains challenging to handle multivariate long nonstationary time series, such as EEG data, which may change rapidly and have patterns of trend. To overcome this limitation, in this article, we propose a fast prediction model to deal with multivariate long nonstationary time series based on the combination of elastic net and high order fuzzy cognitive map (HFCM), which is termed as ElasticNet(HFCM). The designed FCM models each variable by one node and the high-order FCM helps to capture the patterns of trend. A case study on predicting human actions through the Electroencephalogram (EEG) data in the form of multichannel long nonstationary time series is investigated based on the proposed prediction model. Specifically, we first predict EEG signals based on the historical data, then a 1D-convolutionary neural network (1D-CNN) is developed to classify the predicted time series. The experimental results on the Grasp-and-Lift dataset show that the proposal can predict the EEG data with lower prediction error compared with the other regression methods. The area under the curve scores obtained on the Grasp-and-Lift dataset by 1D-CNN are higher than those obtained by state-of-the-art classification methods for EEG data in most cases. These results illustrate that the proposal can predict and classify multivariate long nonstationary time series with high accuracy and efficiency.
C1 [Shen, Fang; Liu, Jing; Wu, Kai] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
C3 Xidian University
RP Liu, J (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
EM f.shen@qq.com; neouma@163.com; kaiwu@stu.xidian.edu.cn
FU General Program of National Natural Science Foundation of China [61773300]
CR Aguilar J., 2005, INT J COMPUT COGN, V3, P27
   Ahmed A, 2018, CATENA, V170, P36, DOI 10.1016/j.catena.2018.06.003
   Alghzawi A. Z., 2017, P INT C INT DEC TECH, V0, P246
   Alomari MH, 2013, INT J ADV COMPUT SC, V4, P208
   An J, 2016, INT CONF BIG DATA, V0, PP427, DOI 10.1109/BIGCOMP.2016.7425963
   Anezakis VD, 2016, LECT NOTES ARTIF INT, V9875, P175, DOI 10.1007/978-3-319-45243-2_16
   [Anonymous], 2015, GRASP LIFTEEGDETECTI, V0, P0
   Barachant A., 2016, P 6 INT BRAIN COMP I, V0, P0
   Buitinck L, 2013, ECML PKDD WORKSHOP L, V0, P108
   Castillo O, 2011, APPL SOFT COMPUT, V11, P5590, DOI 10.1016/j.asoc.2011.04.005
   Chi YX, 2016, IEEE T FUZZY SYST, V24, P71, DOI 10.1109/TFUZZ.2015.2426314
   Cho H, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18041055
   De Maio C, 2017, NEUROCOMPUTING, V256, P35, DOI 10.1016/j.neucom.2016.06.090
   El-Kafrawy NM, 2014, COMM COM INF SC, V488, P189
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Froelich W, 2014, INT J APPROX REASON, V55, P1319, DOI 10.1016/j.ijar.2014.02.006
   Hernandez LG, 2018, LECT NOTES COMPUT SC, V10880, P126, DOI 10.1007/978-3-319-92198-3_13
   Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299, DOI 10.1109/TKDE.2005.50
   Jayashree LS, 2015, NEURAL COMPUT APPL, V26, P1963, DOI 10.1007/s00521-015-1864-5
   Jochumsen M., 2015, MED BIOL ENG COMPUT, V54, P1
   Kang J, 2016, SAFETY SCI, V87, P92, DOI 10.1016/j.ssci.2016.03.023
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Koulouriotis DE, 2001, IEEE C EVOL COMPUTAT, V0, PP364, DOI 10.1109/CEC.2001.934413
   Kyriakarakos G, 2017, APPL ENERG, V187, P575, DOI 10.1016/j.apenergy.2016.11.077
   Lobo JM, 2008, GLOBAL ECOL BIOGEOGR, V17, P145, DOI 10.1111/j.1466-8238.2007.00358.x
   Lu W, 2014, KNOWL-BASED SYST, V70, P242, DOI 10.1016/j.knosys.2014.07.004
   Luciw MD, 2014, SCI DATA, V1, P0, DOI 10.1038/sdata.2014.47
   Lynn-Evans S, 2018, READING MINDS DEEP L, V0, P0
   Melin P, 2012, EXPERT SYST APPL, V39, P3494, DOI 10.1016/j.eswa.2011.09.040
   Papageorgiou EI, 2012, IEEE T INF TECHNOL B, V16, P143, DOI 10.1109/TITB.2011.2175937
   Parsopoulos KE, 2003, IEEE C EVOL COMPUTAT, V0, P1440
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Poczeta K, 2018, STUD COMPUT INTELL, V717, P153, DOI 10.1007/978-3-319-59861-1_10
   Rodin V, 2009, IEEE INT C BIOINF BI, V0, PP236, DOI 10.1109/BIBE.2009.23
   Salmeron JL, 2016, KNOWL-BASED SYST, V105, P29, DOI 10.1016/j.knosys.2016.04.023
   Solana-Gutierrez J, 2017, ECOL MODEL, V360, P260, DOI 10.1016/j.ecolmodel.2017.07.010
   Song HJ, 2010, NEURAL NETWORKS, V23, P1264, DOI 10.1016/j.neunet.2010.08.003
   Song HJ, 2010, IEEE T FUZZY SYST, V18, P233, DOI 10.1109/TFUZZ.2009.2038371
   Soto J., 2014, INT J HYBRID INTELL, V11, P211, DOI 10.3233/HIS-140196
   Soto J, 2017, STUD COMPUT INTELL, V667, P141, DOI 10.1007/978-3-319-47054-2_9
   Soto J, 2015, ADV INTEL SYS RES, V89, P994
   Stach W, 2005, FUZZY SET SYST, V153, P371, DOI 10.1016/j.fss.2005.01.009
   Stach W., 2005, P S HUM CTR COMP C, V0, P64
   Stach W, 2008, IEEE T FUZZY SYST, V16, P61, DOI 10.1109/TFUZZ.2007.902020
   Stach W, 2006, NAFIPS 2006 - 2006 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, VOLS 1 AND 2, P166, DOI 10.1109/NAFIPS.2006.365402
   Szwed P, 2016, MULTIMED TOOLS APPL, V75, P10667, DOI 10.1007/s11042-014-2047-6
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tsadiras AK, 2008, INFORM SCIENCES, V178, P3880, DOI 10.1016/j.ins.2008.05.015
   Varszegi K., 1900, DOI 10.1109/SMC.2016.7844566, V0, P0
   Wu K, 2016, KNOWL-BASED SYST, V113, P23, DOI 10.1016/j.knosys.2016.09.010
   Yang SC, 2018, IEEE T FUZZY SYST, V26, P3391, DOI 10.1109/TFUZZ.2018.2831640
   Zeiler M.D., 2012, ARXIV12125701, V0, P0
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 53
TC 9
Z9 10
U1 8
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6706
EI 1941-0034
J9 IEEE T FUZZY SYST
JI IEEE Trans. Fuzzy Syst.
PD AUG 15
PY 2021
VL 29
IS 8
BP 2336
EP 2348
DI 10.1109/TFUZZ.2020.2998513
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA TU6HA
UT WOS:000681134100025
DA 2023-04-26
ER

PT J
AU Narin, OG
   Gullu, M
AF Narin, Omer Gokberk
   Gullu, Mevlut
TI Evaluating the Planimetric Accuracy of a Historical Map (Europe and the Mediterranean Sea by Piri Reis): A New Method and Cartographic Analysis
SO CARTOGRAPHIC JOURNAL
LA English
DT Article
DE Historical maps; planimetric accuracy; topological accuracy; mapanalyst; RBFANN
ID artificial neural-network; transformation; gis; classification; region
AB Historical maps are popular reference tools for historical, archaeological and temporal analysis, and there has recently been an increase in their use. However, for various reasons, the planimetric accuracy of maps produced before the nineteenth century is usually considered to be lower than today. In this paper, a new method for assessing maps is proposed, using a series of processes, such as radial-based function artificial neural network, magnetic declination, and also MapAnalyst software. The map used in the current study (of Europe and the Mediterranean Sea) is a small-scale map; therefore, control points were produced by taking reference from large-scale maps drawn by the same cartographer, Piri Reis (c.1465-1553). While developing this method, affine transformation (six parameters) was compared in terms of planimetric accuracy. The results indicate that Piri Reis's Mediterranean map offers us unique information in many areas.
C1 [Narin, Omer Gokberk; Gullu, Mevlut] Afyon Kocatepe Univ, Dept Geomat Engn, Afyon, Turkey.
C3 Afyon Kocatepe University
RP Narin, OG (corresponding author), Afyon Kocatepe Univ, Dept Geomat Engn, Afyon, Turkey.
EM gokberknarin@aku.edu.tr
CR Audisio C, 2009, COMPUT GEOSCI-UK, V35, P1735, DOI 10.1016/j.cageo.2009.01.012
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Bernhard J., 2006, E PERIMETRON, V1, P239
   Brigante R, 2014, GEOGR TECH, V9, P10
   Bromberg KD, 2005, ESTUARIES, V28, P823, DOI 10.1007/BF02696012
   Brown M., 2020, AVAILABLE MODELS, V0, P0
   Gregory I., 2007, HIST GIS TECHNOLOGIE, V0, P0
   Gullu M, 2019, ACTA GEOD GEOPHYS, V54, P387, DOI 10.1007/s40328-019-00255-7
   Gullu M, 2010, SCI RES ESSAYS, V5, P3141
   Haykin S., 2009, NEURAL NETWORKS LEAR, V0, P0
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Jenny B., 2010, E PERIMETRON, V5, P176
   Jenny B., 2007, CARTOGRAPHICA INT J, V42, P89, DOI 10.3138/CART0-V42-1-089
   Jenny B, 2011, COMPUT GRAPH-UK, V35, P402, DOI 10.1016/j.cag.2011.01.005
   Jongepier I, 2016, CARTOGR J, V53, P114, DOI 10.1179/1743277414Y.0000000095
   Kemp KK, 2009, INT J HUMANIT ARTS C, V3, P15, DOI 10.3366/ijhac.2009.0006
   Kent A.J., 1998, THESIS OXFORD BROOKE, V0, P0, DOI DOI 10.13140/RG.2.2.13662.59202/3
   Korte M, 2011, PHYS EARTH PLANET IN, V188, P247, DOI 10.1016/j.pepi.2011.06.017
   Lilley KD, 2009, IMAGO MUNDI, V61, P1, DOI 10.1080/03085690802456228
   Mackaness W.A., 2014, ABSTRACTING GEOGRAPH, V0, PP1, DOI 10.1007/978-3-319-00203-3_1
   Manzano-Agugliaro F, 2013, COMPUT GEOSCI-UK, V57, P124, DOI 10.1016/j.cageo.2013.04.010
   Mapasyst, 2019, CALC YOUR MAP ACC US, V0, P0
   McIntosh G. C., 2000, PIRI REIS MAP 1513, V0, P0
   Mikhail EM, 1997, J SURV ENG-ASCE, V123, P32, DOI 10.1061/(ASCE)0733-9453(1997)123:1(32)
   MILLER DM, 1995, COMPUT GEOSCI, V21, P377, DOI 10.1016/0098-3004(94)00082-6
   Narin OG., 2018, 7 UZAL CBS ESKISEHIR, V0, P18
   Nobajas A, 2015, CARTOGR GEOGR INF SC, V42, P211, DOI 10.1080/15230406.2014.998285
   Novak D., 2004, INT PIR REIS S IST 2, V0, P0
   Novak D., 2005, KARTOGRAFIJA GEOINFO, V4, P78
   Onder M., 2002, PRESENT ILLUSTRATED, V0, P0
   Ozdemir K., 1992, OTTOMAN NAUTICAL CHA, V0, P0
   Pul, 2014, SELCUK U TURKIYAT AR, V35, P263, DOI 10.21563/sutad.187095
   Sagiroglu S., 2003, ARTIF INTELL, V0, P0
   Schaffer G, 2016, CARTOGR GEOGR INF SC, V43, P154, DOI 10.1080/15230406.2015.1029519
   Selvi HZ, 2019, CARTOGR J, V56, P280, DOI 10.1080/00087041.2018.1532703
   Taylor F., 2013, HIST GIS, V0, P111
   Tekeli, 1985, AMERIKA HARITASINI C, V1, P653
   Tierra A, 2008, COMPUT GEOSCI-UK, V34, P181, DOI 10.1016/j.cageo.2007.03.011
   Timar G., 2013, MAP GRIDS DATUMS, V0, P0
   Timar G, 2008, GLOBAL PLANET CHANGE, V62, P29, DOI 10.1016/j.gloplacha.2007.11.002
   Wikipedia, 2020, RUM, V0, P0
   Wiktionary, 2020, NEMC, V0, P0
   Yilmaz I, 2012, EXP TECHNIQUES, V36, P15, DOI 10.1111/j.1747-1567.2010.00694.x
   Yilmaz I, 2010, PHYS EARTH PLANET IN, V182, P170, DOI 10.1016/j.pepi.2010.07.011
   Yilmaz M., 2017, P EUR MED C ENV INT, V0, P1205
   Yuan H, 2009, REMOTE SENS-BASEL, V1, P243, DOI 10.3390/rs1030243
   Zaletnyik P., 2004, INT S MOD TECHN ED P, V0, P471
   Zhu JZ, 2014, TRANSPORT RES C-EMER, V47, P139, DOI 10.1016/j.trc.2014.06.011
   Zohar M, 2019, CARTOGR GEOGR INF SC, V46, P532, DOI 10.1080/15230406.2019.1577176
NR 49
TC 0
Z9 0
U1 10
U2 12
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0008-7041
EI 1743-2774
J9 CARTOGR J
JI Cartogr. J.
PD OCT 2
PY 2021
VL 58
IS 4
BP 341
EP 352
DI 10.1080/00087041.2021.1956064
EA FEB 2022
PG 12
WC Geography
SC Geography
GA 8V2XI
UT WOS:000769360200001
DA 2023-04-26
ER

PT J
AU Park, S
   Rysz, M
   Fair, KL
   Pardalos, PM
AF Park, Seonho
   Rysz, Maciej
   Fair, Kaitlin L.
   Pardalos, Panos M.
TI SYNTHETIC-APERTURE RADAR IMAGE BASED POSITIONING IN GPS-DENIED ENVIRONMENTS USING DEEP COSINE SIMILARITY NEURAL NETWORKS
SO INVERSE PROBLEMS AND IMAGING
LA English
DT Article
DE Synthetic Aperture Radar (SAR); polarimetric SAR (PolSAR); Deep Cosine Similarity Neural Networks; image graphs; image retrieval; image registration; scale-invariant feature transform (SIFT); SAR-SIFT; remote sensing
AB Navigating unmanned aerial vehicles in precarious environments is of great importance. It is necessary to rely on alternative information processing techniques to attain spatial information that is required for navigation in such settings. This paper introduces a novel deep learning-based approach for navigating that exclusively relies on synthetic aperture radar (SAR) images. The proposed method utilizes deep neural networks (DNNs) for image matching, retrieval, and registration. To this end, we introduce Deep Cosine Similarity Neural Networks (DCSNNs) for mapping SAR images to a global descriptive feature vector. We also introduce a fine-tuning algorithm for DC-SNNs, and DCSNNs are used to generate a database of feature vectors for SAR images that span a geographic area of interest, which, in turn, are compared against a feature vector of an inquiry image. Images similar to the inquiry are retrieved from the database by using a scalable distance measure between the feature vector outputs of DCSNN. Methods for reranking the retrieved SAR images that are used to update position coordinates of an inquiry SAR image by estimating from the best retrieved SAR image are also introduced. Numerical experiments comparing with baselines on the Polarimetric SAR (PolSAR) images are presented.
C1 [Park, Seonho; Pardalos, Panos M.] Univ Florida, Dept Ind & Syst Engn, Gainesville, FL 32611 USA.
   [Rysz, Maciej] Miami Univ, Dept Informat Syst & Analyt, Oxford, OH 45056 USA.
   [Fair, Kaitlin L.] Air Force Res Lab AFRL RWWI, Eglin Air Force Base, FL 32542 USA.
C3 State University System of Florida; University of Florida; University System of Ohio; Miami University
RP Rysz, M (corresponding author), Miami Univ, Dept Informat Syst & Analyt, Oxford, OH 45056 USA.
EM seonhopark@ufl.edu; ryszmw@miamioh.edu; kaitlin.fair@us.af.mil; pardalos@ufl.edu
FU U.S. Air Force grant [FA8651-08-D-0108/048, FA9453-20-1-0007]
CR [Anonymous], 2004, UNDERSTANDING SYNTHE, V0, P0
   [Anonymous], 2020, DATASET UAVSAR POLSA, V0, P0
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Balamurugan G., 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, V0, Power and Embedded System (SCOPES)
   Bhatti J, 2017, NAVIGATION-US, V64, P51, DOI 10.1002/navi.183
   Caballero F, 2009, J INTELL ROBOT SYST, V54, P137, DOI 10.1007/s10846-008-9257-y
   Cao Y, 2016, AAAI CONF ARTIF INTE, V0, P3457
   Cesetti A, 2010, J INTELL ROBOT SYST, V57, P233, DOI 10.1007/s10846-009-9373-3
   Conte G, 2009, EURASIP J ADV SIG PR, V0, P0, DOI DOI 10.1155/2009/387308
   Dalal N, 2005, PROC CVPR IEEE, V0, PP886, DOI 10.1109/cvpr.2005.177
   Dellinger F, 2015, IEEE T GEOSCI REMOTE, V53, P453, DOI 10.1109/TGRS.2014.2323552
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Grant A, 2009, J NAVIGATION, V62, P173, DOI 10.1017/S0373463308005213
   Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Joe Yue-Hei Ng, 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP53, DOI 10.1109/CVPRW.2015.7301272
   Kaiser MK, 2010, IEEE T AERO ELEC SYS, V46, P1064, DOI 10.1109/TAES.2010.5545174
   Kang WC, 2016, AAAI CONF ARTIF INTE, V0, P1230
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li P, 2017, IEEE GEOSCI REMOTE S, V14, P464, DOI 10.1109/LGRS.2017.2651056
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Liu HM, 2016, PROC CVPR IEEE, V0, PP2064, DOI 10.1109/CVPR.2016.227
   Lowe D. G., 1999, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, V0, PP1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacQueen J.B., 1967, PROC 5 BERKELEY S MA, V0, P281
   Nemra A, 2010, IEEE SENS J, V10, P789, DOI 10.1109/JSEN.2009.2034730
   Nister D, 2004, PROC CVPR IEEE, V0, P652
   Nitti DO, 2015, SENSORS-BASEL, V15, P18334, DOI 10.3390/s150818334
   Noh H, 2017, IEEE I CONF COMP VIS, V0, PP3476, DOI 10.1109/ICCV.2017.374
   Park S, 2020, J OPTIMIZ THEORY APP, V184, P953, DOI 10.1007/s10957-019-01624-6
   Paszke A, 2019, ADV NEUR IN, V32, P0
   Shan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), V0, PP114, DOI 10.1109/ROBIO.2015.7418753
   Shen FM, 2015, PROC CVPR IEEE, V0, PP37, DOI 10.1109/CVPR.2015.7298598
   Sim DG, 2002, IEEE T PATTERN ANAL, V24, P1, DOI 10.1109/34.982881
   Simonyan K, 2015, ARXIV, V0, P0
   Uhl J, 2009, 75 ANN ASPRS C, V0, P0
   Wang BS, 2015, IEEE GEOSCI REMOTE S, V12, P1426, DOI 10.1109/LGRS.2015.2406336
   Wessel B, 2007, 2007 PIA PHOTOGRAMME, V3, P179
   Williams P, 2012, P 28 INT C AER SCI, V0, P0
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zhao S., 2012, AIAA GUID NAV CONTR, V0, P5033
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhu H, 2016, AAAI CONF ARTIF INTE, V0, P2415
   Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 51
TC 1
Z9 1
U1 0
U2 17
PU AMER INST MATHEMATICAL SCIENCES-AIMS
PI SPRINGFIELD
PA PO BOX 2604, SPRINGFIELD, MO 65801-2604, UNITED STATES
SN 1930-8337
EI 1930-8345
J9 INVERSE PROBL IMAG
JI Inverse Probl. Imaging
PD AUG 15
PY 2021
VL 15
IS 4
BP 763
EP 785
DI 10.3934/ipi.2021013
PG 23
WC Mathematics, Applied; Physics, Mathematical
SC Mathematics; Physics
GA RZ4MQ
UT WOS:000648571700007
DA 2023-04-26
ER

PT J
AU Levy, JJ
   Lebeaux, RM
   Hoen, AG
   Christensen, BC
   Vaickus, LJ
   MacKenzie, TA
AF Levy, Joshua J.
   Lebeaux, Rebecca M.
   Hoen, Anne G.
   Christensen, Brock C.
   Vaickus, Louis J.
   MacKenzie, Todd A.
TI Using Satellite Images and Deep Learning to Identify Associations Between County-Level Mortality and Residential Neighborhood Features Proximal to Schools: A Cross-Sectional Study
SO FRONTIERS IN PUBLIC HEALTH
LA English
DT Article
DE deep learning; satellite images; mortality; remote sensing; public health
ID united-states; socioeconomic-status; built environment; life expectancy; fast-food; race; ethnicity; health; income; white
AB What is the relationship between mortality and satellite images as elucidated through the use of Convolutional Neural Networks?Background: Following a century of increase, life expectancy in the United States has stagnated and begun to decline in recent decades. Using satellite images and street view images, prior work has demonstrated associations of the built environment with income, education, access to care, and health factors such as obesity. However, assessment of learned image feature relationships with variation in crude mortality rate across the United States has been lacking.Objective: We sought to investigate if county-level mortality rates in the U.S. could be predicted from satellite images.Methods: Satellite images of neighborhoods surrounding schools were extracted with the Google Static Maps application programming interface for 430 counties representing ~68.9% of the US population. A convolutional neural network was trained using crude mortality rates for each county in 2015 to predict mortality. Learned image features were interpreted using Shapley Additive Feature Explanations, clustered, and compared to mortality and its associated covariate predictors.Results: Predicted mortality from satellite images in a held-out test set of counties was strongly correlated to the true crude mortality rate (Pearson r = 0.72). Direct prediction of mortality using a deep learning model across a cross-section of 430 U.S. counties identified key features in the environment (e.g., sidewalks, driveways, and hiking trails) associated with lower mortality. Learned image features were clustered, and we identified 10 clusters that were associated with education, income, geographical region, race, and age.Conclusions: The application of deep learning techniques to remotely-sensed features of the built environment can serve as a useful predictor of mortality in the United States. Although we identified features that were largely associated with demographic information, future modeling approaches that directly identify image features associated with health-related outcomes have the potential to inform targeted public health interventions.
C1 [Levy, Joshua J.; Lebeaux, Rebecca M.; Hoen, Anne G.; Christensen, Brock C.; MacKenzie, Todd A.] Geisel Sch Med Dartmouth, Dept Epidemiol, Lebanon, NH 03756 USA.
   [Levy, Joshua J.; Lebeaux, Rebecca M.; Hoen, Anne G.] Geisel Sch Med Dartmouth, Program Quantitat Biomed Sci, Lebanon, NH 03756 USA.
   [Levy, Joshua J.; Vaickus, Louis J.] Dartmouth Hitchcock Med Ctr, Emerging Diagnost & Investigative Technol, Dept Pathol & Lab Med, Lebanon, NH 03766 USA.
   [Hoen, Anne G.; MacKenzie, Todd A.] Geisel Sch Med Dartmouth, Dept Biomed Data Sci, Lebanon, NH USA.
   [MacKenzie, Todd A.] Geisel Sch Med Dartmouth, Dartmouth Inst Hlth Policy & Clin Practice, Lebanon, NH USA.
C3 Dartmouth College; Dartmouth College; Dartmouth College; Dartmouth College; Dartmouth College
RP Levy, JJ (corresponding author), Geisel Sch Med Dartmouth, Dept Epidemiol, Lebanon, NH 03756 USA.; Levy, JJ (corresponding author), Geisel Sch Med Dartmouth, Program Quantitat Biomed Sci, Lebanon, NH 03756 USA.; Levy, JJ (corresponding author), Dartmouth Hitchcock Med Ctr, Emerging Diagnost & Investigative Technol, Dept Pathol & Lab Med, Lebanon, NH 03766 USA.
EM joshua.j.levy@dartmouth.edu
CR Aneshensel C. S., 2016, HDB AGING SOCIAL SCI, V0, P315
   Austin SB, 2005, AM J PUBLIC HEALTH, V95, P1575, DOI 10.2105/AJPH.2004.056341
   Backlund E, 1996, ANN EPIDEMIOL, V6, P12, DOI 10.1016/1047-2797(95)00090-9
   Bansal Naman, 2019, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION, V0, P375, DOI 10.1007/978-981-13-1217-5_37
   Bayer P, 2007, J POLIT ECON, V115, P588, DOI 10.1086/522381
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bhopal R, 1998, AM J PUBLIC HEALTH, V88, P1303, DOI 10.2105/AJPH.88.9.1303
   Bischke B, 2019, IEEE IMAGE PROC, V0, PP1480, DOI 10.1109/ICIP.2019.8803050
   Bruzelius E, 2019, J AM MED INFORM ASSN, V26, P806, DOI 10.1093/jamia/ocz111
   Burkhalter JE, 2016, LGBT HEALTH, V3, P19, DOI 10.1089/lgbt.2015.0118
   Carter BD, 2015, NEW ENGL J MED, V372, P631, DOI 10.1056/NEJMsa1407211
   Case A, 2017, BROOKINGS PAP ECO AC, V0, P397
   Case A, 2015, P NATL ACAD SCI USA, V112, P15078, DOI 10.1073/pnas.1518393112
   Chetty R, 2016, JAMA-J AM MED ASSOC, V315, P1750, DOI 10.1001/jama.2016.4226
   Ching T, 2018, J R SOC INTERFACE, V15, P0, DOI 10.1098/rsif.2017.0387
   Clayton JA, 2016, JAMA-J AM MED ASSOC, V316, P1863, DOI 10.1001/jama.2016.16405
   Corke P, 2013, IEEE INT C INT ROBOT, V0, PP2085, DOI 10.1109/IROS.2013.6696648
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Dyer O, 2018, BMJ-BRIT MED J, V363, P0, DOI 10.1136/bmj.k5118
   El-Sayed AM., 2014, AMA J ETHICS, V16, P450, DOI 10.1001/VIRTUALMENTOR.2014.16.6.STAS1-1406
   Engelberg JK, 2016, BMC PUBLIC HEALTH, V16, P0, DOI 10.1186/s12889-016-3055-4
   Flanagin A, 2021, JAMA-J AM MED ASSOC, V326, P621, DOI 10.1001/jama.2021.13304
   Flanagin A, 2021, JAMA-J AM MED ASSOC, V325, P1049, DOI 10.1001/jama.2021.2104
   Fu H., 1900, V10, V0, P0
   Gebru T, 2017, P NATL ACAD SCI USA, V114, P13108, DOI 10.1073/pnas.1700035114
   Gelormino Elena, 2015, PREV MED REP, V2, P737, DOI 10.1016/j.pmedr.2015.08.019
   Hamidi S, 2018, INT J ENV RES PUB HE, V15, P0, DOI 10.3390/ijerph15050861
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hirt S, 2013, J PLAN EDUC RES, V33, P292, DOI 10.1177/0739456X13494242
   Hubbard T, 2011, LTD ACCESS HLTH FOOD, V0, P0
   Iglovikov V., 2017, SATELLITE IMAGERY FE, V0, P0
   Ioannidis JPA, 2021, JAMA-J AM MED ASSOC, V325, P623, DOI 10.1001/jama.2021.0003
   Jean N., 2018, TILE2VEC UNSUPERVISE, V0, P0, DOI DOI 10.1609/aaai.v33i01.33013967
   Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
   Jensen J.R, 1999, PHOTOGRAMM ENG REM S, V0, PP153, DOI 10.1002/9780470979587.ch22
   Keralis JM, 2020, BMC PUBLIC HEALTH, V20, P0, DOI 10.1186/s12889-020-8300-1
   Kestens Y, 2010, AM J PREV MED, V39, P33, DOI 10.1016/j.amepre.2010.03.014
   Khunti K, 2021, J PUBLIC HEALTH-UK, V43, PE270, DOI 10.1093/pubmed/fdaa198
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kwate NOA, 2010, PREV MED, V51, P153, DOI 10.1016/j.ypmed.2010.04.020
   Kwatra V., 2012, COMP PHOT ICCP 2012, V0, PP1, DOI 10.1109/ICCPHOT.2012.6215222
   Lareau A., 2014, CHOOSING HOMES CHOOS, V0, P0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee C, 2009, SOC SCI MED, V68, P1183, DOI 10.1016/j.socscimed.2008.12.036
   Lo CP, 1997, REMOTE SENS ENVIRON, V62, P143, DOI 10.1016/S0034-4257(97)00088-6
   Lundberg SM, 2017, ADV NEUR IN, V30, P0
   Maharana A, 2018, JAMA NETW OPEN, V1, P0, DOI 10.1001/jamanetworkopen.2018.1535
   Mays VM, 2003, ANNU REV PUBL HEALTH, V24, P83, DOI 10.1146/annurev.publhealth.24.100901.140927
   McInnes L, 2018, UMAP UNIFORM MANIFOL, V0, P0
   Mennis J, 2015, CITYSCAPE, V17, P115
   Montez JK, 2013, AM J PUBLIC HEALTH, V103, P473, DOI 10.2105/AJPH.2012.301128
   Moore LV, 2008, AM J PREV MED, V34, P16, DOI 10.1016/j.amepre.2007.09.021
   Muennig PA, 2018, AM J PUBLIC HEALTH, V108, P1626, DOI 10.2105/AJPH.2018.304585
   Muller A, 2002, BRIT MED J, V324, P23, DOI 10.1136/bmj.324.7328.23
   Nguyen QC, 2019, PREV MED REP, V14, P0, DOI 10.1016/j.pmedr.2019.100859
   Nguyen QC, 2018, J EPIDEMIOL COMMUN H, V72, P260, DOI 10.1136/jech-2017-209456
   Olufadeji A, 2021, J NATL MED ASSOC, V113, P428, DOI 10.1016/j.jnma.2021.02.005
   Quinn GP, 2015, CA-CANCER J CLIN, V65, P384, DOI 10.3322/caac.21288
   Robinson C, 2017, GEOHUMANITIES17: PROCEEDINGS OF THE 1ST ACM SIGSPATIAL WORKSHOP ON GEOSPATIAL HUMANITIES, V0, PP47, DOI 10.1145/3149858.3149863
   Routen A, 2021, JAMA-J AM MED ASSOC, V326, P674, DOI 10.1001/jama.2021.9268
   Rutt CD, 2005, PREV MED, V40, P831, DOI 10.1016/j.ypmed.2004.09.035
   Salas LA, 2021, EPIGENOMICS-UK, V13, P1761, DOI 10.2217/epi-2020-0080
   Shermeyer J, 2019, IEEE COMPUT SOC CONF, V0, PP1432, DOI 10.1109/CVPRW.2019.00184
   Streed CG, 2020, AM J PUBLIC HEALTH, V110, P991, DOI 10.2105/AJPH.2020.305722
   Suel E, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-42036-w
   Tapiador FJ, 2011, INT J REMOTE SENS, V32, P6437, DOI 10.1080/01431161.2010.512928
   Thornton RLJ, 2016, HEALTH AFFAIR, V35, P1416, DOI 10.1377/hlthaff.2015.1357
   von Elm E, 2014, INT J SURG, V12, P1495, DOI 10.1016/j.ijsu.2014.07.013
   Weichenthal S, 2019, ENVIRON INT, V122, P3, DOI 10.1016/j.envint.2018.11.042
   White K, 2020, INT J EQUITY HEALTH, V19, P0, DOI 10.1186/s12939-020-1137-5
   Wilson DK, 2004, ANN BEHAV MED, V28, P20, DOI 10.1207/s15324796abm2801_4
   Woolf SH, 2019, JAMA-J AM MED ASSOC, V322, P1996, DOI 10.1001/jama.2019.16932
   Woolhandler S, 2017, ANN INTERN MED, V167, P424, DOI 10.7326/M17-1403
   Xu HF, 2018, JAMA NETW OPEN, V1, P0, DOI 10.1001/jamanetworkopen.2018.4587
   Zhu JY, 2017, IEEE I CONF COMP VIS, V0, PP2242, DOI 10.1109/ICCV.2017.244
NR 82
TC 0
Z9 0
U1 5
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 2296-2565
J9 FRONT PUBLIC HEALTH
JI Front. Public Health
PD NOV 5
PY 2021
VL 9
IS 
BP 
EP 
DI 10.3389/fpubh.2021.766707
PG 14
WC Public, Environmental & Occupational Health
SC Public, Environmental & Occupational Health
GA WZ7WH
UT WOS:000720173800001
PM 34805078
DA 2023-04-26
ER

PT J
AU Zhu, LL
   Zhang, YH
   Wang, JG
   Tian, W
   Liu, Q
   Ma, GY
   Kan, X
   Chu, Y
AF Zhu, Linglong
   Zhang, Yonghong
   Wang, Jiangeng
   Tian, Wei
   Liu, Qi
   Ma, Guangyi
   Kan, Xi
   Chu, Ya
TI Downscaling Snow Depth Mapping by Fusion of Microwave and Optical Remote-Sensing Data Based on Deep Learning
SO REMOTE SENSING
LA English
DT Article
DE downscaling; deep learning; snow depth; MWRI; data fusion
AB Accurate high spatial resolution snow depth mapping in arid and semi-arid regions is of great importance for snow disaster assessment and hydrological modeling. However, due to the complex topography and low spatial-resolution microwave remote-sensing data, the existing snow depth datasets have large errors and uncertainty, and actual spatiotemporal heterogeneity of snow depth cannot be effectively detected. This paper proposed a deep learning approach based on downscaling snow depth retrieval by fusion of satellite remote-sensing data with multiple spatial scales and diverse characteristics. The (Fengyun-3 Microwave Radiation Imager) FY-3 MWRI data were downscaled to 500 m resolution to match Moderate-resolution Imaging Spectroradiometer (MODIS) snow cover, meteorological and geographic data. A deep neural network was constructed to capture detailed spectral and radiation signals and trained to retrieve the higher spatial resolution snow depth from the aforementioned input data and ground observation. Verified by in situ measurements, downscaled snow depth has the lowest root mean square error (RMSE) and mean absolute error (MAE) (8.16 cm, 4.73 cm respectively) among Environmental and Ecological Science Data Center for West China Snow Depth (WESTDC_SD, 9.38 cm and 5.36 cm), the Microwave Radiation Imager (MWRI) Ascend Snow Depth (MWRI_A_SD, 9.45 cm and 5.49 cm) and MWRI Descend Snow Depth (MWRI_D_SD, 10.55 cm and 6.13 cm) in the study area. Meanwhile, downscaled snow depth could provide more detailed information in spatial distribution, which has been used to analyze the decrease of retrieval accuracy by various topography factors.
C1 [Zhu, Linglong; Zhang, Yonghong] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Zhu, Linglong; Ma, Guangyi] Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210044, Peoples R China.
   [Zhang, Yonghong] Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
   [Wang, Jiangeng] Nanjing Univ Informat Sci & Technol, Sch Atmospher Phys, Nanjing 210044, Peoples R China.
   [Tian, Wei; Liu, Qi] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Kan, Xi] Nanjing Univ Informat Sci & Technol, Binjiang Coll, Wuxi 214105, Jiangsu, Peoples R China.
   [Chu, Ya] China Meteorol Adm, Huayun Informat Technol Engn Co Ltd, Beijing 100081, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; Wuxi University; China Meteorological Administration
RP Zhang, YH (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.; Zhang, YH (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
EM llzhu@nuist.edu.cn; zyh@nuist.edu.cn; jgwang@nuist.edu.cn; tw@nuist.edu.cn; qi.liu@nuist.edu.cn; xzmgy@nuist.edu.cn; kanxi@nuist.edu.cn; chuya@huaxin-hitec.com
FU National Natural Science Foundation of China [41875027, 41871238]; 2019-Postgraduate research and innovation project in Jiangsu Province [1344051901073]; National Key Research and Development Program of China [2018YFC1506502]
CR Ahmad JA, 2019, FRONT EARTH SC-SWITZ, V7, P0, DOI 10.3389/feart.2019.00212
   [Anonymous], 1987, ANN GLACIOL, V0, P0
   Aschbacher J., 1989, THESIS U INNSBRUCK I, V0, P0
   Che T., 2006, RES PASSIVE MICROWAV, V0, P0
   Che T, 2008, ANN GLACIOL-SER, V49, P145, DOI 10.3189/172756408787814690
   Chen CT, 2001, IEEE T GEOSCI REMOTE, V39, P1744, DOI 10.1109/36.942553
   Chen WQ, 2020, PEERJ, V8, P0, DOI 10.7717/peerj.8861
   Chen XY, 2020, IEEE T IMAGE PROCESS, V29, P7090, DOI 10.1109/TIP.2020.2998297
   Dai LY, 2017, CRYOSPHERE, V11, P1933, DOI 10.5194/tc-11-1933-2017
   Dai LY, 2015, REMOTE SENS-BASEL, V7, P7212, DOI 10.3390/rs70607212
   De Gregorio L, 2019, IEEE J-STARS, V12, P2873, DOI 10.1109/JSTARS.2019.2920676
   Deronde B, 2014, INT J REMOTE SENS, V35, P2402, DOI 10.1080/01431161.2014.883102
   Di Marco N, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10040134
   DOZIER J, 1989, REMOTE SENS ENVIRON, V28, P9, DOI 10.1016/0034-4257(89)90101-6
   Foster JL, 2005, REMOTE SENS ENVIRON, V94, P187, DOI 10.1016/j.rse.2004.09.012
   Gao JL, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050475
   Guo YC, 2019, CMC-COMPUT MATER CON, V58, P829, DOI 10.32604/cmc.2019.03729
   HARRISON AR, 1989, INT J REMOTE SENS, V10, P907, DOI 10.1080/01431168908903930
   Huai BJ, 2018, NAT HAZARDS, V93, P1105, DOI 10.1007/s11069-018-3341-9
   Hung CW, 2019, INTELL AUTOM SOFT CO, V25, P329
   Jiang LM, 2014, SCI CHINA EARTH SCI, V57, P1278, DOI 10.1007/s11430-013-4798-8
   Josberger EG, 2002, HYDROL PROCESS, V16, P1557, DOI 10.1002/hyp.1020
   Kan X, 2018, CMC-COMPUT MATER CON, V57, P49, DOI 10.32604/cmc.2018.02376
   Kelly RE, 2003, IEEE T GEOSCI REMOTE, V41, P230, DOI 10.1109/TGRS.2003.809118
   Liang JY, 2015, REMOTE SENS ENVIRON, V156, P500, DOI 10.1016/j.rse.2014.10.016
   Lievens H, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-12566-y
   Liu CY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060962
   Liu JP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232864
   Liu MY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030460
   Masson T, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040619
   Mhawej M, 2014, J HYDROL, V513, P274, DOI 10.1016/j.jhydrol.2014.03.058
   Notarnicola C, 2013, REMOTE SENS-BASEL, V5, P1568, DOI 10.3390/rs5041568
   Notarnicola C, 2013, REMOTE SENS-BASEL, V5, P110, DOI 10.3390/rs5010110
   Painter TH, 2009, REMOTE SENS ENVIRON, V113, P868, DOI 10.1016/j.rse.2009.01.001
   Pulliainen JT, 1999, IEEE T GEOSCI REMOTE, V37, P1378, DOI 10.1109/36.763302
   Qin YH, 2020, COLD REG SCI TECHNOL, V175, P0, DOI 10.1016/j.coldregions.2020.103067
   Rittger K., 2013, ADV WATER RESOUR, V51, P367, DOI 10.1016/J.ADVWATRES.2012.03.002
   Rodell M, 2004, B AM METEOROL SOC, V85, P381, DOI 10.1175/BAMS-85-3-381
   Salomonson VV, 2004, REMOTE SENS ENVIRON, V89, P351, DOI 10.1016/j.rse.2003.10.016
   Senthilnath J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12020245
   Shen YJ, 2020, CATENA, V187, P0, DOI 10.1016/j.catena.2019.104343
   [孙俊 Sun Jun], 2012, 高原气象 PLATEAU METEOROLOGY, V31, P920
   [孙知文 Sun Zhiwen], 2015, 国土资源遥感 REMOTE SENSING FOR LAND & RESOURCES, V27, P9
   Tabari H, 2010, NEURAL COMPUT APPL, V19, P625, DOI 10.1007/s00521-009-0320-9
   Tan ML, 2018, WATER RESOUR MANAG, V32, P4591, DOI 10.1007/s11269-018-2072-8
   Tedesco M, 2004, REMOTE SENS ENVIRON, V90, P76, DOI 10.1016/j.rse.2003.12.002
   Tedesco M, 2010, IEEE J-STARS, V3, P141, DOI 10.1109/JSTARS.2010.2040462
   Walters RD, 2014, REMOTE SENS ENVIRON, V152, P413, DOI 10.1016/j.rse.2014.07.001
   Wang JG, 2018, WATER-SUI, V10, P0, DOI 10.3390/w10111514
   Wang T, 2012, ISPRS J PHOTOGRAMM, V68, P184, DOI 10.1016/j.isprsjprs.2012.01.001
   Wang Y.B., 2017, P 31 C NEUR INF PROC, V0, P0
   Wang YL, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111268
   Wu H, 2019, CMC-COMPUT MATER CON, V60, P575, DOI 10.32604/cmc.2019.03595
   Wufu A, 2020, PEERJ, V8, P0, DOI 10.7717/peerj.9683
   Xiao XX, 2018, REMOTE SENS ENVIRON, V210, P48, DOI 10.1016/j.rse.2018.03.008
   Xu F, 2019, CMC-COMPUT MATER CON, V58, P697, DOI 10.32604/cmc.2019.05375
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091461
   Xue Y, 2015, REMOTE SENS ENVIRON, V170, P153, DOI 10.1016/j.rse.2015.09.009
   Yang JW, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11161879
   Yang SH, 2020, GEODERMA, V377, P0, DOI 10.1016/j.geoderma.2020.114583
   Yu HC, 2020, INT J ENV RES PUB HE, V17, P0, DOI 10.3390/ijerph17134865
   Yu H, 2012, HYDROL PROCESS, V26, P3052, DOI 10.1002/hyp.8253
   Zhang X, 2019, CMC-COMPUT MATER CON, V61, P601, DOI 10.32604/cmc.2019.06045
NR 63
TC 15
Z9 15
U1 12
U2 42
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 15
PY 2021
VL 13
IS 4
BP 
EP 
DI 10.3390/rs13040584
PG 25
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QQ3SJ
UT WOS:000624443700001
DA 2023-04-26
ER

PT J
AU Tabarestani, ES
   Afzalimehr, H
AF Shahiri Tabarestani, Ehsan
   Afzalimehr, Hossein
TI Artificial neural network and multi-criteria decision-making models for flood simulation in GIS: Mazandaran Province, Iran
SO STOCHASTIC ENVIRONMENTAL RESEARCH AND RISK ASSESSMENT
LA English
DT Article
DE ANN; Flood susceptibility map; GIS; Mazandaran province; Multi-criteria decision analysis; ROC
ID remote-sensing data; susceptibility assessment; frequency ratio; spatial prediction; landslide hazard; logistic-regression; risk-assessment; areas; vulnerability; algorithms
AB Flood is one of the most destructive natural disasters globally and is a concern due to its high vulnerability. In this study for identification of flood susceptible areas, artificial neural network (ANN) and Multi-Attributive Border Approximation Area Comparison (MABAC) combined with Weights of Evidence (WoE) and Analytical Hierarchy Process (AHP) Models were used in Mazandaran province, Iran. MABAC method was used for the first time to evaluate the flood-prone areas in this study, and Attempts have been made for evaluate the performance of this new method by comparing with ANN model. The output of the neural network was discharge values in hydrometric stations. Using Geographic Information System (GIS) with eight effective factors including rainfall, distance from rivers, slope, soil, geology, elevation, drainage density, and land use, a flood model developed. Three precision parameters containing R-2, RMSE and MAE were applied to show the performance of the ANN model which yielded the values of 0.89, 0.0024 m(3)/s, and 0.0018 m(3)/s, respectively for testing data. The verification results indicated satisfactory agreement between the predicted and the real hydrological records. Also, based on flood inventory map and using the area under receiver operating curve, predictive power of the MABAC-WoE-AHP model was evaluated. The AUC value for prediction rate of this model was 86.1% which indicates the very good accuracy in predicting flood-prone areas. Comparison of flood susceptibility maps for ANN and MABAC-WoE-AHP models showed the good agreement between two models, that clarifies the efficiency of the new proposed method for future preventive measures.
C1 [Shahiri Tabarestani, Ehsan; Afzalimehr, Hossein] Iran Univ Sci & Technol, Dept Civil Engn, Tehran, Iran.
C3 Iran University Science & Technology
RP Afzalimehr, H (corresponding author), Iran Univ Sci & Technol, Dept Civil Engn, Tehran, Iran.
EM ehsan_shahiri96@civileng.iust.ac.ir; hafzali@iust.ac.ir
CR [Anonymous], 1994, P 19 ANN SAS USERS G, V0, P0
   Arora MK, 2004, INT J REMOTE SENS, V25, P559, DOI 10.1080/0143116031000156819
   Athmaja S, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, V0, P0
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   BISHOP CM, 1994, REV SCI INSTRUM, V65, P1803, DOI 10.1063/1.1144830
   Biswajeet P, 2010, DISASTER ADV, V3, P26
   BONHAMCARTER GF, 1988, PHOTOGRAMM ENG REM S, V54, P1585
   Bubeck P, 2012, RISK ANAL, V32, P1481, DOI 10.1111/j.1539-6924.2011.01783.x
   Buyukozkan G, 2012, EXPERT SYST APPL, V39, P3000, DOI 10.1016/j.eswa.2011.08.162
   Chapi K, 2017, ENVIRON MODELL SOFTW, V95, P229, DOI 10.1016/j.envsoft.2017.06.012
   Costache R, 2020, J ENVIRON MANAGE, V265, P0, DOI 10.1016/j.jenvman.2020.110485
   Costache R, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010106
   Dahal RK, 2008, ENVIRON GEOL, V54, P311, DOI 10.1007/s00254-007-0818-3
   Dalalah D, 2011, EXPERT SYST APPL, V38, P8384, DOI 10.1016/j.eswa.2011.01.031
   Dewan AM, 2013, FLOODS IN A MEGACITY, V0, PP35, DOI 10.1016/J.GLOENVCHA.2006.02.006
   Bui DT, 2018, SCI REP-UK, V8, P0, DOI 10.1038/s41598-018-33755-7
   Dixon B, 2005, J HYDROL, V309, P17, DOI 10.1016/j.jhydrol.2004.11.010
   Elsafi SH, 2014, ALEX ENG J, V53, P655, DOI 10.1016/j.aej.2014.06.010
   Fernandez DS, 2010, ENG GEOL, V111, P90, DOI 10.1016/j.enggeo.2009.12.006
   Gigovic L, 2017, RENEW ENERG, V103, P501, DOI 10.1016/j.renene.2016.11.057
   Guo EL, 2014, NAT HAZARDS, V74, P947, DOI 10.1007/s11069-014-1238-9
   Hall J., 2013, HYDROL EARTH SYST SC, V10, P15525
   Haq M, 2012, EGYPT J REMOTE SENS, V15, P135, DOI 10.1016/j.ejrs.2012.07.002
   Hernando D, 2015, J HYDROL HYDROMECH, V63, P55, DOI 10.1515/johh-2015-0003
   Hong HY, 2018, SCI TOTAL ENVIRON, V625, P575, DOI 10.1016/j.scitotenv.2017.12.256
   Hwang C.L., 1981, LECT NOTES EC MATH S, V0, P0, DOI DOI 10.1007/978-3-642-48318-9
   Islam MM, 2001, IAHS-AISH P, V0, P455
   Islam MM, 2002, J HYDROL ENG, V7, P346, DOI 10.1061/(ASCE)1084-0699(2002)7:5(346)
   Jaafari A, 2014, INT J ENVIRON SCI TE, V11, P909, DOI 10.1007/s13762-013-0464-0
   Jahangir MH, 2019, WEATHER CLIM EXTREME, V25, P0, DOI 10.1016/j.wace.2019.100215
   Kalteh AM, 2008, RAINFALL RUNOFF MODE, V0, P0
   Kazakis N, 2015, SCI TOTAL ENVIRON, V538, P555, DOI 10.1016/j.scitotenv.2015.08.055
   Khosravi K, 2019, J HYDROL, V573, P311, DOI 10.1016/j.jhydrol.2019.03.073
   Khosravi K, 2018, SCI TOTAL ENVIRON, V627, P744, DOI 10.1016/j.scitotenv.2018.01.266
   Kia MB, 2012, ENVIRON EARTH SCI, V67, P251, DOI 10.1007/s12665-011-1504-z
   Kourgialas NN, 2011, HYDROLOG SCI J, V56, P212, DOI 10.1080/02626667.2011.555836
   Kron W, 2002, P FLOOD DEFENCE, V0, P0
   Lee MJ, 2012, INT GEOSCI REMOTE SE, V0, PP895, DOI 10.1109/IGARSS.2012.6351414
   Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X
   Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7
   Li GF, 2013, STOCH ENV RES RISK A, V27, P1683, DOI 10.1007/s00477-013-0706-1
   Liang WZ, 2019, TUNN UNDERGR SP TECH, V83, P533, DOI 10.1016/j.tust.2018.09.037
   Lin KR, 2020, J HYDROL, V584, P0, DOI 10.1016/j.jhydrol.2020.124696
   Malczewski J, 2006, INT J GEOGR INF SCI, V20, P703, DOI 10.1080/13658810600661508
   Manandhar B, 2010, FLOOD PLAIN ANAL RIS, V0, P64
   Mas JF, 2004, ESTUAR COAST SHELF S, V59, P219, DOI 10.1016/j.ecss.2003.08.011
   Mohammady M, 2012, J ASIAN EARTH SCI, V61, P221, DOI 10.1016/j.jseaes.2012.10.005
   Morgan RPC., 2005, SOIL EROSION CONSERV, V0, P16
   Ogato GS, 2020, J HYDROL-REG STUD, V27, P0, DOI 10.1016/j.ejrh.2019.100659
   Ohlmacher GC, 2003, ENG GEOL, V69, P331, DOI 10.1016/S0013-7952(03)00069-3
   Ouma YO, 2014, WATER-SUI, V6, P1515, DOI 10.3390/w6061515
   Pamucar D, 2015, EXPERT SYST APPL, V42, P3016, DOI 10.1016/j.eswa.2014.11.057
   Patel DP, 2013, WATER RESOUR MANAG, V27, P2353, DOI 10.1007/s11269-013-0291-6
   Pourghasemi HR, 2014, ARAB J GEOSCI, V7, P1857, DOI 10.1007/s12517-012-0825-x
   Pourghasemi HR, 2012, NAT HAZARDS, V63, P965, DOI 10.1007/s11069-012-0217-2
   Pourghasemi H, 2013, GEOMAT NAT HAZ RISK, V4, P93, DOI 10.1080/19475705.2012.662915
   Pourtaghi ZS, 2014, HYDROGEOL J, V22, P643, DOI 10.1007/s10040-013-1089-6
   Powell RL, 2007, REMOTE SENS ENVIRON, V106, P253, DOI 10.1016/j.rse.2006.09.005
   Pradhan B, 2010, PHOTOGRAMM FERNERKUN, V0, PP17, DOI 10.1127/1432-8364/2010/0037
   Pradhan B, 2010, ENVIRON EARTH SCI, V60, P1037, DOI 10.1007/s12665-009-0245-8
   Radmehr A, 2014, J COMPUT CIVIL ENG, V28, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000360
   Rahman M, 2019, EARTH SYST ENVIRON, V3, P585, DOI 10.1007/s41748-019-00123-y
   Rahmani s., 2019, IRAN WATER RESOUR RE, V15, P339
   Rahmati O, 2016, GEOCARTO INT, V31, P42, DOI 10.1080/10106049.2015.1041559
   Rahmati O, 2015, ARAB J GEOSCI, V8, P7059, DOI 10.1007/s12517-014-1668-4
   Rimba AB, 2017, URBAN SCI, V1, P0, DOI 10.3390/urbansci1010007
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Sadeghi-Pouya A, 2017, INT J DISAST RISK RE, V22, P304, DOI 10.1016/j.ijdrr.2017.02.013
   SANDHYA, 2020, INT RES J ENG TECHNO, V7, P6245
   Subramanian N, 2012, INT J PROD ECON, V138, P215, DOI 10.1016/j.ijpe.2012.03.036
   Suthirat K., 2020, INT J DISAST RISK RE, V48, P0
   Targ S, 2016, ARXIV160308029, V0, P0
   Tehrany MS, 2017, GEOMAT NAT HAZ RISK, V8, P1538, DOI 10.1080/19475705.2017.1362038
   Tehrany MS, 2015, STOCH ENV RES RISK A, V29, P1149, DOI 10.1007/s00477-015-1021-9
   Tehrany MS, 2013, J HYDROL, V504, P69, DOI 10.1016/j.jhydrol.2013.09.034
   Varoonchotikul P, 2003, FLOOD FORECASTING US, V0, P102
   Xie S, 2021, J HYDROL, V592, P0, DOI 10.1016/j.jhydrol.2020.125605
   Xu C, 2012, J EARTH SCI-CHINA, V23, P97, DOI 10.1007/s12583-012-0236-7
   Yesilnacar E. K., 2005, THESIS U MELBOURNE M, V0, P0
   Youssef AM, 2011, ENVIRON EARTH SCI, V62, P611, DOI 10.1007/s12665-010-0551-1
   Youssef AM, 2015, GEOSCI J, V19, P449, DOI 10.1007/s12303-014-0065-z
   Yu JJ, 2013, STOCH ENV RES RISK A, V27, P725, DOI 10.1007/s00477-012-0635-4
   Zhang Y, 2017, INT CONF ACOUST SPEE, V0, PP4845, DOI 10.1109/ICASSP.2017.7953077
   Zhao G, 2020, J HYDROL, V590, P0, DOI 10.1016/j.jhydrol.2020.125235
   Zou Q, 2013, STOCH ENV RES RISK A, V27, P525, DOI 10.1007/s00477-012-0598-5
NR 85
TC 13
Z9 13
U1 2
U2 20
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1436-3240
EI 1436-3259
J9 STOCH ENV RES RISK A
JI Stoch. Environ. Res. Risk Assess.
PD DEC 15
PY 2021
VL 35
IS 12
BP 2439
EP 2457
DI 10.1007/s00477-021-01997-z
EA MAR 2021
PG 19
WC Engineering, Environmental; Engineering, Civil; Environmental Sciences; Statistics & Probability; Water Resources
SC Engineering; Environmental Sciences & Ecology; Mathematics; Water Resources
GA WU4BD
UT WOS:000630265700002
DA 2023-04-26
ER

PT J
AU Farooq, S
   Akram, MS
AF Farooq, Salman
   Akram, Mian Sohail
TI COMPARISON OF DATA-DRIVEN LANDSLIDE SUSCEPTIBILITY ASSESSMENT USING WEIGHT OF EVIDENCE, INFORMATION VALUE, FREQUENCY RATIO AND CERTAINTY FACTOR METHODS
SO ACTA GEODYNAMICA ET GEOMATERIALIA
LA English
DT Article
DE Landslide susceptibility; Weight of evidence; Information value method; Frequency ratio; Certainty factor; Geographic information system
ID bala rock avalanche; logistic-regression; kashmir earthquake; spatial prediction; neural-network; hazard; gis; models; inventory; himalayas
AB Landslide susceptibility assessment is essential for development activities and disaster management in the mountainous regions to identify the landslide-prone areas. The present study aimed to evaluate and compare the efficacy of data driven quantitative models of landslide susceptibility assessment using geospatial tools in Jhelum valley of the Himalayas. This area suffers from extreme rainfall events due to the local climate and has experienced significant and widespread landslide events in recent years. Four probabilistic data-driven models are employed for this purpose, which includes the weight of evidence (WOE), information value method (IVM), frequency ratio (FR), and certainty factor (CF). These assessed models are based on integrating landslide contributing factors and a ground truthing-based landslide inventory of 437 landslides. The landslide susceptibility maps were presented by categorizing the study area into very low to very high susceptibility zone by Jenks natural breaks method. The performance of models was evaluated by a sensitivity analysis using Receiver Operator Curve (ROC) method. The ROC validated results of success rate curves for WOE, IVM, FR and CF were 80 %, 78 %, 77 %, and 76 % respectively. The prediction rate curve of WOE, IVM, FR, and CF was 78 %, 77 %, 75 %, and 78 % respectively. The results showed the reasonable efficiency of applied models for landslide susceptibility assessment in the study area and applicable to regions with similar geomorphological conditions. Conclusively, the comparison of applied models revealed the promising results of used approaches.
C1 [Farooq, Salman; Akram, Mian Sohail] Univ Punjab, Inst Geol, Lahore, Pakistan.
C3 University of Punjab
RP Farooq, S (corresponding author), Univ Punjab, Inst Geol, Lahore, Pakistan.
EM salman.geo@pu.edu.pk
CR Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   ANBALAGAN R, 1992, ENG GEOL, V32, P269, DOI 10.1016/0013-7952(92)90053-2
   Basharat M, 2012, J EARTH SCI-CHINA, V23, P213, DOI 10.1007/s12583-012-0248-3
   Begueria S, 2006, NAT HAZARDS, V37, P315, DOI 10.1007/s11069-005-5182-6
   Binaghi E, 1998, NAT HAZARDS, V17, P77, DOI 10.1023/A:1008001724538
   Bonham-Carter G. F., 1994, GEOGRAPHIC INFORM SY, V0, P0, DOI DOI 10.1016/C2013-0-03864-9
   Bonham-Carter GF, 1989, STAT APPT EARTH SCI, V0, PP171, DOI 10.4095/128059
   BOSSART P, 1989, ECLOGAE GEOL HELV, V82, P133
   Burton, 2010, PRELIMINARY DAMAGE E, V0, P5
   CARRARA A, 1995, ADV NAT TECHNOL HAZ, V5, P135
   Castellanos Abella EA, 2008, GEOMORPHOLOGY, V94, P453, DOI 10.1016/j.geomorph.2006.10.038
   Chang ZL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030502
   Chen T, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-016-5317-y
   Chen W, 2017, CATENA, V151, P147, DOI 10.1016/j.catena.2016.11.032
   Chen W, 2016, ARAB J GEOSCI, V9, P0, DOI 10.1007/s12517-015-2150-7
   Chen W, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-4829-1
   Chung CJF, 1999, PHOTOGRAMM ENG REM S, V65, P1389
   Corominas J, 2014, B ENG GEOL ENVIRON, V73, P209, DOI 10.1007/s10064-013-0538-8
   Devkota KC, 2013, NAT HAZARDS, V65, P135, DOI 10.1007/s11069-012-0347-6
   Dikshit A, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10040131
   Du GL, 2017, J MT SCI-ENGL, V14, P249, DOI 10.1007/s11629-016-4126-9
   Duman TY, 2005, ENG GEOL, V77, P99, DOI 10.1016/j.enggeo.2004.08.005
   Dunning SA, 2007, ENG GEOL, V93, P130, DOI 10.1016/j.enggeo.2007.07.003
   Ghosh S, 2012, ENG GEOL, V128, P49, DOI 10.1016/j.enggeo.2011.03.016
   Guo CB, 2015, GEOMORPHOLOGY, V248, P93, DOI 10.1016/j.geomorph.2015.07.012
   GUPTA RP, 1990, ENG GEOL, V28, P119, DOI 10.1016/0013-7952(90)90037-2
   Guri PK, 2015, ENVIRON MONIT ASSESS, V187, P0, DOI 10.1007/s10661-015-4535-1
   Guzzetti F., 2002, P 4 EGS PLINIUS C, V0, P0
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Harp E.L., 2006, US GEOLOGICAL SURVEY, V0, P0
   Heckerman D., 1992, ENCY ARTIFICIAL INTE, V0, P131
   Iqbal J, 2021, ACTA GEODYN GEOMATER, V18, P137, DOI 10.13168/AGG.2021.0010
   Kanungo DP, 2011, NAT HAZARDS, V59, P1491, DOI 10.1007/s11069-011-9847-z
   Kumar P., 2012, P INT S DIS MIT DEBR, V0, P617
   Lee S, 2005, ENVIRON GEOL, V47, P982, DOI 10.1007/s00254-005-1228-z
   Liu M., 2014, LANDSLIDE SCI SAFER, V0, P457
   Mahmood Irfan, 2015, PLOS CURR, V7, P0, DOI 10.1371/currents.dis.0bc3ebc5b8adf5c7fe9fd3d702d44a99
   Martha TR, 2013, GEOMORPHOLOGY, V184, P139, DOI 10.1016/j.geomorph.2012.12.001
   Meena SR, 2019, ISPRS INT GEO-INF, V8, P0, DOI 10.3390/ijgi8020094
   Nath SK, 2004, NAT HAZARDS, V31, P319
   Nohani E, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11071402
   Owen LA, 2008, GEOMORPHOLOGY, V94, P1, DOI 10.1016/j.geomorph.2007.04.007
   Pasang S, 2020, GEOSCIENCES, V10, P0, DOI 10.3390/geosciences10110430
   Pourghasemi HR, 2013, ARAB J GEOSCI, V6, P2351, DOI 10.1007/s12517-012-0532-7
   Pradhan A.M.S., 2012, J NEPAL GEOSOC, V44, P1, DOI 10.3126/jngs.v44i0.24483
   Raja NB, 2017, NAT HAZARDS, V85, P1323, DOI 10.1007/s11069-016-2591-7
   Regmi NR, 2010, GEOMORPHOLOGY, V115, P172, DOI 10.1016/j.geomorph.2009.10.002
   Reichenbach P., 2005, LANDSLIDE RISK ASSES, V0, PP429, DOI 10.1002/9780470012659.CH15
   Rowena H., 2018, EC LOSSES POVERTY DI, V0, P0
   Saha S, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10113772
   Sarkar S, 2013, J GEOL SOC INDIA, V82, P351, DOI 10.1007/s12594-013-0162-z
   Schneider JF, 2009, J SEISMOL, V13, P387, DOI 10.1007/s10950-008-9103-5
   Shafique M, 2016, J ASIAN EARTH SCI, V118, P68, DOI 10.1016/j.jseaes.2016.01.002
   Shortliffe E. H., 1975, MATHEMATICAL BIOSCIENCES, V23, P351, DOI 10.1016/0025-5564(75)90047-4
   Shu HP, 2019, SCI TOTAL ENVIRON, V693, P0, DOI 10.1016/j.scitotenv.2019.07.363
   Sujatha ER, 2012, J EARTH SYST SCI, V121, P1337, DOI 10.1007/s12040-012-0230-6
   SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615
   TIBALDI A, 1995, GEOMORPHOLOGY, V11, P215, DOI 10.1016/0169-555X(94)00060-5
   Van Westen C., 2002, USE WEIGHTS EVIDENCE, V0, P0
   van Westen CJ, 2008, ENG GEOL, V102, P112, DOI 10.1016/j.enggeo.2008.03.010
   Van Westen CJ, 2003, NAT HAZARDS, V30, P399, DOI 10.1023/B:NHAZ.0000007097.42735.9e
   Van Westen CJ, 1993, ITC PUBL, V15, P245
   [王佳佳 Wang Jiajia], 2014, 岩石力学与工程学报 CHINESE JOURNAL OF ROCK MECHANICS AND ENGINEERING, V33, P797
   Wang QQ, 2019, GEOMAT NAT HAZ RISK, V10, P820, DOI 10.1080/19475705.2018.1549111
   WITTICH KP, 1995, INT J BIOMETEOROL, V38, P209, DOI 10.1007/BF01245391
   Xu C, 2012, ENVIRON EARTH SCI, V66, P1603, DOI 10.1007/s12665-012-1624-0
   Yalcin A, 2011, CATENA, V85, P274, DOI 10.1016/j.catena.2011.01.014
   Yalcin A, 2008, CATENA, V72, P1, DOI 10.1016/j.catena.2007.01.003
   Yin K L, 1988, INT S LANDSL, V5, P1269
   Zhao X, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10010016
NR 70
TC 2
Z9 2
U1 2
U2 12
PU ACAD SCI CZECH REPUBLIC INST ROCK STRUCTURE & MECHANICS
PI PRAGUE 8
PA IRSM AS CR, V HOLESOVICKACH 41, PRAGUE 8, 182 09, CZECH REPUBLIC
SN 1214-9705
EI 
J9 ACTA GEODYN GEOMATER
JI Acta Geodyn. Geomater.
PD JUN 15
PY 2021
VL 18
IS 3
BP 301
EP 317
DI 10.13168/AGG.2021.0021
PG 17
WC Geochemistry & Geophysics; Mining & Mineral Processing
SC Geochemistry & Geophysics; Mining & Mineral Processing
GA XN7AQ
UT WOS:000729653600002
DA 2023-04-26
ER

PT J
AU Ghorbani, Z
   Behzadan, AH
AF Ghorbani, Zahra
   Behzadan, Amir H.
TI Monitoring offshore oil pollution using multi-class convolutional neural networks
SO ENVIRONMENTAL POLLUTION
LA English
DT Article
DE Convolutional neural networks; Drone; Image classification; Instance segmentation; Object detection; Oil pollution
ID of-the-art; spill detection; leak detection; economic-growth; deep; segmentation; consumption; impact; mri
AB Oil and gas production operations are a major source of environmental pollution that expose people and habitats in many coastal communities around the world to adverse health effects. Detecting oil spills in a timely and precise manner can help improve the oil spill response process and channel required resources more effectively to affected regions. In this research, convolutional neural networks, a branch of artificial intelligence (AI), are trained on a visual dataset of oil spills containing images from different altitudes and geographical locations. In particular, a VGG16 model is adopted through transfer learning for oil spill classification (i.e., detecting if there is oil spill in an image) with an accuracy of 92%. Next, Mask R-CNN and PSPNet models are used for oil spill segmentation (i.e., pixel-level detection of oil spill boundaries) with a mean intersection over union (IoU) of 49% and 68%, respectively. Lastly, to determine if there is an oil rig or vessel in the vicinity of a detected oil spill and provide a holistic view of the oil spill surroundings, a YOLOv3 model is trained and used, yielding a maximum mean average precision (mAP) of similar to 71%. Findings of this research can improve the current practices of oil pollution cleanup and predictive maintenance, ultimately leading to more resilient and healthy coastal communities.
C1 [Ghorbani, Zahra; Behzadan, Amir H.] Texas A&M Univ, Dept Construct Sci, 3137 TAMU, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station
RP Behzadan, AH (corresponding author), Texas A&M Univ, Dept Construct Sci, 3137 TAMU, College Stn, TX 77843 USA.
EM zahraghorabani@tamu.edu; abehzadan@tamu.edu
CR Abdallah Y.M.Y., 2016, J BIOMED ENG MED IMA, V3, P0, DOI 10.14738/jbemi.32.1702
   Ahmed F, 2019, LECT NOTE DATA ENG, V29, P271, DOI 10.1007/978-3-030-12839-5_25
   Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Al-Qizwini M, 2017, IEEE INT VEH SYM, V0, PP89, DOI 10.1109/IVS.2017.7995703
   Alexopoulos A.B., 2003, ASSESSMENT VESSEL SO, V0, P0
   Alipour M, 2019, J COMPUT CIVIL ENG, V33, P0, DOI 10.1061/(ASCE)CP.1943-5487.0000854
   Alom M. Z., 2018, ARXIV 180301164, V0, P0
   Alshayef MS, 2020, J GEOVIS SPAT ANAL, V4, P0, DOI 10.1007/s41651-020-00058-3
   Alshayef MS, 2019, J GEOVIS SPAT ANAL, V3, P0, DOI 10.1007/s41651-019-0043-0
   [Anonymous], 2016, NAT METHODS, V0, P0, DOI DOI 10.1038/nmeth.3707
   [Anonymous], 1900, P740, V0, P0
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Arnab A, 2017, PROC CVPR IEEE, V0, PP879, DOI 10.1109/CVPR.2017.100
   Baruque B, 2010, INFORM SCIENCES, V180, P2029, DOI 10.1016/j.ins.2009.12.032
   Beyer J, 2016, MAR POLLUT BULL, V110, P28, DOI 10.1016/j.marpolbul.2016.06.027
   Bianchi FM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142260
   Bloch H, 2015, ECON MODEL, V44, P104, DOI 10.1016/j.econmod.2014.09.017
   Chang SE, 2014, ECOL SOC, V19, P0, DOI 10.5751/ES-06406-190226
   Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009
   Chollet F., 2018, DEEP LEARNING WITH R, V0, P0
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Deepak S, 2019, COMPUT BIOL MED, V111, P0, DOI 10.1016/j.compbiomed.2019.103345
   Deng J, 2009, PROC CVPR IEEE, V0, PP248, DOI 10.1109/CVPRW.2009.5206848
   Dunham MH, 2006, DATA MINING INTRO AD, V0, P0
   Ejiba Ikenna., 2016, J SCI RES REPORTS, V12, P1, DOI 10.9734/JSRR/2016/26633
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Farrington JW, 2014, ENVIRONMENT, V56, P16, DOI 10.1080/00139157.2014.922382
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fingas M., 2016, OIL SPILL SCI TECHNO, V2nd, P0
   Fingas M, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010091
   Fingas M, 2014, MAR POLLUT BULL, V83, P9, DOI 10.1016/j.marpolbul.2014.03.059
   Fiscella B, 2000, INT J REMOTE SENS, V21, P3561, DOI 10.1080/014311600750037589
   García Herrera Arístides Lázaro, 2017, REV.MED.ELECTRÓN., V0, P1
   Garcia-Borboroglu P, 2006, MAR POLLUT BULL, V52, P193, DOI 10.1016/j.marpolbul.2005.11.004
   Gately D, 2012, ENERG POLICY, V47, P57, DOI 10.1016/j.enpol.2012.04.011
   Ge CH, 2008, COMPUT CHEM ENG, V32, P1669, DOI 10.1016/j.compchemeng.2007.08.011
   Geiger I.G, 2005, PRINCIPLES LEAK DETE, V399, P0
   Ghorbani Z, 2019, THESIS TEXAS A M U C, V0, P0
   Ghorbani Z., 2020, CSEE 2020, V0, P0
   Gin KYH, 2001, MAR POLLUT BULL, V42, P590, DOI 10.1016/S0025-326X(00)00205-8
   Girard-Ardhuid F, 2003, OCEANS 2003 MTS/IEEE: CELEBRATING THE PAST...TEAMING TOWARD THE FUTURE, V0, P164
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Henrik B., 2017, REAL WORLD MACHINE L, V0, P0
   Hussain Zeshan, 2017, AMIA ANNU SYMP PROC, V2017, P979
   Jaderberg M., 2015, ADV NEURAL INFORM PR, V2, P2017, DOI 10.5555/2969442.2969465
   Jha MN, 2008, SENSORS-BASEL, V8, P236, DOI 10.3390/s8010236
   Jia SJ, 2017, CHIN AUTOM CONGR, V0, P4165
   Jiao ZY, 2019, COMPUT IND ENG, V135, P1300, DOI 10.1016/j.cie.2018.11.008
   Johnson BA, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111772
   Joseph R, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Kavukcuoglu K, 2009, PROC CVPR IEEE, V0, PP1605, DOI 10.1109/CVPRW.2009.5206545
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kolar Z, 2018, AUTOMAT CONSTR, V89, P58, DOI 10.1016/j.autcon.2018.01.003
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Lachinov D, 2019, LECT NOTES COMPUT SC, V11384, P189, DOI 10.1007/978-3-030-11726-9_17
   Li Y., 2018, GEO SPATIAL KNOWLEDG, V848, P353
   Liashchynskyi P., 2019, ARXIV, V0, P0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lysenko G., 2010, INTERACTIONS FOOD AG, VI, P0
   Truong MTN, 2018, SOFT COMPUT, V22, P4197, DOI 10.1007/s00500-017-2709-1
   Mao B, 2020, J GEOVIS SPAT ANAL, V4, P0, DOI 10.1007/s41651-019-0045-y
   McLaughlin N, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), V0, P0
   Meng LY, 2012, J LOSS PREVENT PROC, V25, P90, DOI 10.1016/j.jlp.2011.07.001
   Mikolajczyk A., 2018, 2018 INT INT PHD WOR, V0, PP117, DOI 10.1109/IIPHDW.2018.8388338
   Milletari F, 2017, COMPUT VIS IMAGE UND, V164, P92, DOI 10.1016/j.cviu.2017.04.002
   Molnar C., 2016, SCI REP-UK, V6, P1
   Murvay PS, 2012, J LOSS PREVENT PROC, V25, P966, DOI 10.1016/j.jlp.2012.05.010
   Muttin F, 2011, APPL OCEAN RES, V33, P332, DOI 10.1016/j.apor.2011.06.004
   Nath ND, 2020, AUTOMAT CONSTR, V112, P0, DOI 10.1016/j.autcon.2020.103085
   Nath ND, 2019, J INF TECHNOL CONSTR, V24, P511, DOI 10.36680/j.itcon.2019.028
   National Academies of Sciences Engineering and Medicine, 2018, DAY 2 P WORKSH, V0, P0
   Nieto-Hidalgo M, 2018, IEEE T GEOSCI REMOTE, V56, P5217, DOI 10.1109/TGRS.2018.2812619
   Nriagu J, 2016, INT J ENV RES PUB HE, V13, P0, DOI 10.3390/ijerph13030346
   Odonkor P, 2019, SWARM EVOL COMPUT, V46, P52, DOI 10.1016/j.swevo.2019.01.005
   Oquab M, 2014, PROC CVPR IEEE, V0, PP1717, DOI 10.1109/CVPR.2014.222
   Orfanidis G, 2018, IEEE IMAGE PROC, V0, PP3773, DOI 10.1109/ICIP.2018.8451113
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pi YL, 2020, ADV ENG INFORM, V43, P0, DOI 10.1016/j.aei.2019.101009
   Pisano A, 2015, REMOTE SENS-BASEL, V7, P1112, DOI 10.3390/rs70101112
   Powers D. M. W., 2011, J MACH LEARN TECHNOL, V2, P37
   Rattner BA, 2009, ECOTOXICOLOGY, V18, P773, DOI 10.1007/s10646-009-0354-x
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Rodriguez-Trigo G, 2007, ARCH BRONCONEUMOL, V43, P628
   Shi WZ, 2017, IEEE IMAGE PROC, V0, P977
   Shorten C, 2019, J BIG DATA-GER, V6, P0, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, ARXIV, V0, P0
   Soekhoe D, 2016, LECT NOTES COMPUT SC, V9897, P50, DOI 10.1007/978-3-319-46349-0_5
   Solberg AHS, 1999, IEEE T GEOSCI REMOTE, V37, P1916, DOI 10.1109/36.774704
   Solberg AHS, 2007, IEEE T GEOSCI REMOTE, V45, P746, DOI 10.1109/TGRS.2006.887019
   Sow P, 2018, PROJ MANAG WORLD J P, VVII, P1
   Sumaila UR, 2012, CAN J FISH AQUAT SCI, V69, P499, DOI 10.1139/F2011-171
   Suris-Regueiro JC, 2007, DISASTERS, V31, P201, DOI 10.1111/j.1467-7717.2007.01004.x
   Taylor L., 2017, IMPROVING DEEP LEARN, V0, P0
   Thada V., 2013, INT J INNOVATIONS EN, V2, P202
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang MC, 2019, J GEOVIS SPAT ANAL, V3, P0, DOI 10.1007/s41651-019-0039-9
   Weiss Karl, 2016, JOURNAL OF BIG DATA, V3, P0, DOI 10.1186/s40537-016-0043-6
   Wiese FK, 2004, J WILDLIFE MANAGE, V68, P627, DOI 10.2193/0022-541X(2004)068[0627:ASMFCO]2.0.CO;2
   Wilson M., 2017, GOMSGG17004, V0, P0
   Woolley C., 2014, CUDNN EFFICIENT PRIM, V0, P0
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zou GL, 2006, ENERG POLICY, V34, P3644, DOI 10.1016/j.enpol.2005.08.009
NR 105
TC 15
Z9 16
U1 8
U2 34
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0269-7491
EI 1873-6424
J9 ENVIRON POLLUT
JI Environ. Pollut.
PD NOV 15
PY 2021
VL 289
IS 
BP 
EP 
DI 10.1016/j.envpol.2021.117884
EA AUG 2021
PG 11
WC Environmental Sciences
SC Environmental Sciences & Ecology
GA UR9ME
UT WOS:000697063100003
PM 34364118
DA 2023-04-26
ER

PT J
AU Lobov, SA
   Zharinov, AI
   Makarov, VA
   Kazantsev, VB
AF Lobov, Sergey A.
   Zharinov, Alexey I.
   Makarov, Valeri A.
   Kazantsev, Victor B.
TI Spatial Memory in a Spiking Neural Network with Robot Embodiment
SO SENSORS
LA English
DT Article
DE spiking neural networks; STDP; learning; neurorobotics; cognitive maps; vector field of synaptic connections; vector field of functional connections
ID timing-dependent plasticity; internal representation; synaptic plasticity; electrical stimuli; cultured networks; simple-model; power-law; synchronization; organization; hippocampus
AB Cognitive maps and spatial memory are fundamental paradigms of brain functioning. Here, we present a spiking neural network (SNN) capable of generating an internal representation of the external environment and implementing spatial memory. The SNN initially has a non-specific architecture, which is then shaped by Hebbian-type synaptic plasticity. The network receives stimuli at specific loci, while the memory retrieval operates as a functional SNN response in the form of population bursts. The SNN function is explored through its embodiment in a robot moving in an arena with safe and dangerous zones. We propose a measure of the global network memory using the synaptic vector field approach to validate results and calculate information characteristics, including learning curves. We show that after training, the SNN can effectively control the robot's cognitive behavior, allowing it to avoid dangerous regions in the arena. However, the learning is not perfect. The robot eventually visits dangerous areas. Such behavior, also observed in animals, enables relearning in time-evolving environments. If a dangerous zone moves into another place, the SNN remaps positive and negative areas, allowing escaping the catastrophic interference phenomenon known for some AI architectures. Thus, the robot adapts to changing world.
C1 [Lobov, Sergey A.; Zharinov, Alexey I.; Makarov, Valeri A.; Kazantsev, Victor B.] Lobachevsky State Univ Nizhny Novgorod, Neurotechnol Dept, 23 Gagarin Ave, Nizhnii Novgorod 603950, Russia.
   [Lobov, Sergey A.; Kazantsev, Victor B.] Innopolis Univ, Ctr Technol Robot & Mech Components, Neurosci & Cognit Technol Lab, 1 Univ Skaya Str, Innopolis 420500, Russia.
   [Lobov, Sergey A.; Kazantsev, Victor B.] Immanuel Kant Baltic Fed Univ, Ctr Neurotechnol & Machine Learning, 14 Nevsky Str, Kaliningrad 236016, Russia.
   [Makarov, Valeri A.] Univ Complutense Madrid, Fac Ciencias Matemat, Inst Matemat Interdisciplinar, Madrid 28040, Spain.
   [Kazantsev, Victor B.] Russian State Sci Ctr Robot & Tech Cybernet, Lab Neurocybernet, 21 Tikhoretsky Ave, St Petersburg 194064, Russia.
C3 Lobachevsky State University of Nizhni Novgorod; Innopolis University; Immanuel Kant Baltic Federal University; Complutense University of Madrid
RP Lobov, SA (corresponding author), Lobachevsky State Univ Nizhny Novgorod, Neurotechnol Dept, 23 Gagarin Ave, Nizhnii Novgorod 603950, Russia.; Lobov, SA (corresponding author), Innopolis Univ, Ctr Technol Robot & Mech Components, Neurosci & Cognit Technol Lab, 1 Univ Skaya Str, Innopolis 420500, Russia.; Lobov, SA (corresponding author), Immanuel Kant Baltic Fed Univ, Ctr Neurotechnol & Machine Learning, 14 Nevsky Str, Kaliningrad 236016, Russia.
EM lobov@neuro.nnov.ru; zharinov.lexa.az@gmail.com; vmakarov@ucm.es; kazantsev@neuro.nnov.ru
FU Ministry of Science and Higher Education of the Russian Federation [075-15-2020-808]; Spanish Ministry of Science, Innovation [FIS2017-82900P]
CR Anderson RB, 2001, MEM COGNITION, V29, P1061, DOI 10.3758/BF03195767
   Anokhin KV, 2010, HER RUSS ACAD SCI+, V80, P237, DOI 10.1134/S101933161003007X
   Villacorta-Atienza JA, 2013, IEEE T NEUR NET LEAR, V24, P2075, DOI 10.1109/TNNLS.2013.2271645
   Villacorta-Atienza JA, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0057440
   Villacorta-Atienza JA, 2010, BIOL CYBERN, V103, P285, DOI 10.1007/s00422-010-0398-2
   Bakkum DJ, 2008, J NEURAL ENG, V5, P310, DOI 10.1088/1741-2560/5/3/004
   Baruchi I, 2007, PHYS REV E, V75, P0, DOI 10.1103/PhysRevE.75.050901
   Bazhanova MV, 2020, RADIOPHYS QUANT EL+, V63, P298, DOI 10.1007/s11141-021-10054-2
   Bell CC, 1997, NATURE, V387, P278, DOI 10.1038/387278a0
   Bi GQ, 1998, J NEUROSCI, V18, P10464, DOI 10.1523/jneurosci.18-24-10464.1998
   Bing ZS, 2020, NEURAL NETWORKS, V121, P21, DOI 10.1016/j.neunet.2019.05.019
   Bing ZS, 2018, FRONT NEUROROBOTICS, V12, P0, DOI 10.3389/fnbot.2018.00035
   Borisyuk R, 2013, BIOSYSTEMS, V112, P214, DOI 10.1016/j.biosystems.2013.03.018
   Tapia CC, 2020, FRONT NEUROROBOTICS, V14, P0, DOI 10.3389/fnbot.2020.00004
   Tapia CC, 2018, PHYS REV E, V97, P0, DOI 10.1103/PhysRevE.97.052308
   Chao ZC, 2005, NEUROINFORMATICS, V3, P263, DOI 10.1385/NI:3:3:263
   Chao ZC, 2007, J NEURAL ENG, V4, P294, DOI 10.1088/1741-2560/4/3/015
   Chou TS, 2015, FRONT NEUROROBOTICS, V9, P0, DOI 10.3389/fnbot.2015.00006
   CROSSMAN ERF, 1958, ERGONOMICS, V2, P153
   [Дегтерев А.А. Degterev A.A.], 2015, МАТЕМАТИЧЕСКАЯ БИОЛОГИЯ И БИОИНФОРМАТИКА MATHEMATICAL BIOLOGY AND BIOINFORMATICS MATEMATICHESKAYA BIOLOGIYA I BIOINFORMATIKA, V10, P234
   Ebbinghaus H., 1885, MEMORY CONTRIBUTION, V0, P0
   Eichenbaum H, 2017, ANNU REV PSYCHOL, V68, P19, DOI 10.1146/annurev-psych-010416-044131
   Fernandez-Ruiz A, 2012, FRONT NEURAL CIRCUIT, V6, P0, DOI 10.3389/fncir.2012.00071
   Frankland PW, 2005, NAT REV NEUROSCI, V6, P119, DOI 10.1038/nrn1607
   Gong PL, 2009, PLOS COMPUT BIOL, V5, P0, DOI 10.1371/journal.pcbi.1000611
   Gritsun TA, 2012, PLOS ONE, V7, P0, DOI 10.1371/journal.pone.0043352
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Kampa BM, 2007, TRENDS NEUROSCI, V30, P456, DOI 10.1016/j.tins.2007.06.010
   Kandel ER, 2001, SCIENCE, V294, P1030, DOI 10.1126/science.1067020
   Kawasaki F, 2014, BIOL CYBERN, V108, P423, DOI 10.1007/s00422-014-0611-9
   Krichmar JL, 2005, NEUROINFORMATICS, V3, P197, DOI 10.1385/NI:3:3:197
   le Feber J, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0008871
   Lobov S, 2016, EUR PHYS J-SPEC TOP, V225, P29, DOI 10.1140/epjst/e2016-02614-y
   [Лобов С.А. Lobov S.A.], 2019, МАТЕМАТИЧЕСКАЯ БИОЛОГИЯ И БИОИНФОРМАТИКА MATEMATICHESKAYA BIOLOGIYA I BIOINFORMATIKA, V14, P649
   Lobov SA, 2017, MATH MODEL NAT PHENO, V12, P109, DOI 10.1051/mmnp/201712409
   Lobov SA, 2020, FRONT NEUROSCI-SWITZ, V14, P0, DOI 10.3389/fnins.2020.00088
   Lobov SA, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20020500
   Masquelier T, 2008, PLOS ONE, V3, P0, DOI 10.1371/journal.pone.0001377
   Morrison A, 2008, BIOL CYBERN, V98, P459, DOI 10.1007/s00422-008-0233-1
   Murre JMJ, 2011, PSYCHON B REV, V18, P592, DOI 10.3758/s13423-011-0076-y
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949
   Palmer JHC, 2014, FRONT COMPUT NEUROSC, V8, P0, DOI 10.3389/fncom.2014.00079
   Pimashkin A, 2013, FRONT NEURAL CIRCUIT, V7, P0, DOI 10.3389/fncir.2013.00087
   Ponulak F, 2013, FRONT COMPUT NEUROSC, V7, P0, DOI 10.3389/fncom.2013.00098
   Quiroga RQ, 2013, PRINCIPLES OF NEURAL CODING, V0, PP1, DOI 10.1201/b14756
   Roberts PD, 2010, FRONT COMPUT NEUROSC, V4, P0, DOI 10.3389/fncom.2010.00156
   Rosenbloom PS, 2006, TUTOR QUANT METHODS, V2, P43, DOI 10.20982/tqmp.02.2.p043
   Segev R, 2001, PHYS REV E, V64, P0, DOI 10.1103/PhysRevE.64.011920
   Shahaf G, 2001, J NEUROSCI, V21, P8782, DOI 10.1523/JNEUROSCI.21-22-08782.2001
   Sjostrom PJ, 2001, NEURON, V32, P1149, DOI 10.1016/s0896-6273(01)00542-6
   Snoddy GS, 1926, J APPL PSYCHOL, V10, P1, DOI 10.1037/h0075814
   Song S, 2000, NAT NEUROSCI, V3, P919, DOI 10.1038/78829
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Tsodyks M, 1998, NEURAL COMPUT, V10, P821, DOI 10.1162/089976698300017502
   Villacorta-Atienza JA, 2021, J ADV RES, V28, P111, DOI 10.1016/j.jare.2020.08.008
NR 58
TC 4
Z9 4
U1 3
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD APR 15
PY 2021
VL 21
IS 8
BP 
EP 
DI 10.3390/s21082678
PG 15
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA RT9WU
UT WOS:000644805000001
PM 33920246
DA 2023-04-26
ER

PT J
AU Li, XL
   Kong, WW
   Liu, XL
   Zhang, X
   Wang, W
   Chen, RQ
   Sun, YQ
   Liu, F
AF Li, Xiaolong
   Kong, Wenwen
   Liu, Xiaoli
   Zhang, Xi
   Wang, Wei
   Chen, Rongqin
   Sun, Yongqi
   Liu, Fei
TI Application of Laser-Induced Breakdown Spectroscopy Coupled With Spectral Matrix and Convolutional Neural Network for Identifying Geographical Origins of Gentiana rigescens Franch
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE geographical origin identification; variable importance measured; convolutional neural network; spectral matrix; Gentiana rigescens franch
ID identification; classification
AB Accurate geographical origin identification is of great significance to ensure the quality of traditional Chinese medicine (TCM). Laser-induced breakdown spectroscopy (LIBS) was applied to achieve the fast geographical origin identification of wild Gentiana rigescens Franch (G. rigescens Franch). However, LIBS spectra with too many variables could increase the training time of models and reduce the discrimination accuracy. In order to solve the problems, we proposed two methods. One was reducing the number of variables through two consecutive variable selections. The other was transforming the spectrum into spectral matrix by spectrum segmentation and recombination. Combined with convolutional neural network (CNN), both methods could improve the accuracy of discrimination. For the underground parts of G. rigescens Franch, the optimal accuracy in the prediction set for the two methods was 92.19 and 94.01%, respectively. For the aerial parts, the two corresponding accuracies were the same with the value of 94.01%. Saliency map was used to explain the rationality of discriminant analysis by CNN combined with spectral matrix. The first method could provide some support for LIBS portable instrument development. The second method could offer some reference for the discriminant analysis of LIBS spectra with too many variables by the end-to-end learning of CNN. The present results demonstrated that LIBS combined with CNN was an effective tool to quickly identify the geographical origin of G. rigescens Franch.
C1 [Li, Xiaolong; Wang, Wei; Chen, Rongqin; Liu, Fei] Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou, Peoples R China.
   [Kong, Wenwen] Zhejiang A&F Univ, Coll Math & Comp Sci, Hangzhou, Peoples R China.
   [Liu, Xiaoli; Zhang, Xi] Yunnan Univ Chinese Med, Sch Chinese Mat Med, Kunming, Yunnan, Peoples R China.
   [Liu, Xiaoli] Yunnan Prov Key Lab Mol Biol Sinomed, Kunming, Yunnan, Peoples R China.
   [Sun, Yongqi] Hangzhou Landa Sci & Technol Co Ltd, Hangzhou, Peoples R China.
   [Liu, Fei] Minist Agr & Rural Affairs, Key Lab Spect Sensing, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang A&F University; Yunnan University of Chinese Medicine; Ministry of Agriculture & Rural Affairs
RP Liu, F (corresponding author), Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou, Peoples R China.; Liu, XL (corresponding author), Yunnan Univ Chinese Med, Sch Chinese Mat Med, Kunming, Yunnan, Peoples R China.; Liu, XL (corresponding author), Yunnan Prov Key Lab Mol Biol Sinomed, Kunming, Yunnan, Peoples R China.; Liu, F (corresponding author), Minist Agr & Rural Affairs, Key Lab Spect Sensing, Hangzhou, Peoples R China.
EM kmxunzi@aliyun.com; fliu@zju.edu.cn
FU Science and Technology Department of Zhejiang Province [2021C02023]; National Natural Science Foundation of China [8166063]
CR Acquarelli J, 2017, ANAL CHIM ACTA, V954, P22, DOI 10.1016/j.aca.2016.12.010
   An S., 2003, J HARBIN U COMMER NA, V19, P14
   Badmos S, 2020, FOOD RES INT, V134, P0, DOI 10.1016/j.foodres.2020.109218
   Belayneh A, 2014, J HYDROL, V508, P418, DOI 10.1016/j.jhydrol.2013.10.052
   Benos L, 2021, SENSORS-BASEL, V21, P0, DOI 10.3390/s21113758
   Bolger JA, 2000, APPL SPECTROSC, V54, P181, DOI 10.1366/0003702001949375
   Boucher TF, 2015, SPECTROCHIM ACTA B, V107, P1, DOI 10.1016/j.sab.2015.02.003
   Bronzi B, 2020, FOOD CHEM, V315, P0, DOI 10.1016/j.foodchem.2020.126248
   Chu YW, 2018, OPT EXPRESS, V26, P10119, DOI 10.1364/OE.26.010119
   Dong X., 2015, HUBEI AGR SCI, V54, P5641
   Feng L, 2019, IEEE ACCESS, V7, P64494, DOI 10.1109/ACCESS.2019.2917267
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kim D, 2018, APPL SPECTROSC, V72, P896, DOI 10.1177/0003702818758046
   Li W, 2018, IEEE GEOSC REM SEN M, V6, P15, DOI 10.1109/MGRS.2018.2793873
   Liu F, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19061453
   Liu QS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9121330
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Nie PC, 2019, SENSOR ACTUAT B-CHEM, V296, P0, DOI 10.1016/j.snb.2019.126630
   Noll R, 2018, J ANAL ATOM SPECTROM, V33, P945, DOI 10.1039/c8ja00076j
   Peng JY, 2017, SCI REP-UK, V7, P0, DOI 10.1038/srep44551
   Shen Tao, 2019, YINGYONG SHENGTAI XUEBAO, V30, P2291, DOI 10.13287/j.1001-9332.201907.003
   Shen T, 2019, MOLECULES, V24, P0, DOI 10.3390/molecules24142562
   Shen TT, 2018, MOLECULES, V23, P0, DOI 10.3390/molecules23112930
   Shi Ting-Ting, 2019, ZHONGGUO ZHONG YAO ZA ZHI, V44, P4073, DOI 10.19540/j.cnki.cjcmm.20190731.104
   Stefas D, 2019, ATOMS, V7, P0, DOI 10.3390/atoms7030079
   Strobl C, 2009, PSYCHOL METHODS, V14, P323, DOI 10.1037/a0016973
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042
   Wu S, 2019, IEEE T NEUR NET LEAR, V30, P2043, DOI 10.1109/TNNLS.2018.2876179
   Yan TY, 2021, FRONT PLANT SCI, V12, P0, DOI 10.3389/fpls.2021.604510
   Yu KQ, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep27574
   Yu XJ, 2018, CHEMOMETR INTELL LAB, V172, P188, DOI 10.1016/j.chemolab.2017.12.010
   Zhang JN, 2020, FRONT PLANT SCI, V11, P0, DOI 10.3389/fpls.2020.00821
   Zhao J, 2010, BRIEF BIOINFORM, V11, P417, DOI 10.1093/bib/bbp063
   Zhao Y, 2020, MEAT SCI, V165, P0, DOI 10.1016/j.meatsci.2020.108129
   Zhao YL, 2020, ANAL METHODS-UK, V12, P2260, DOI 10.1039/d0ay00309c
NR 37
TC 1
Z9 1
U1 10
U2 28
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 2624-8212
J9 FRONT ARTIF INTELL
JI Front. Artif. Intell.
PD JUN 15
PY 2021
VL 4
IS 
BP 
EP 
DI 10.3389/frai.2021.735533
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA YT9WW
UT WOS:000751704800149
PM 34957390
DA 2023-04-26
ER

PT J
AU Zhang, Y
   Han, J
   Yuan, CS
   Yang, S
   Li, CL
   Sun, XM
AF Zhang, Yan
   Han, Jin
   Yuan, Chengsheng
   Yang, Shuo
   Li, Chuanlong
   Sun, Xingming
TI A Rasterized Lightning Disaster Risk Method for Imbalanced Sets Using Neural Network
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Lightning disaster; neural network; imbalanced data
AB Over the past 10 years, lightning disaster has caused a large number of casualties and considerable economic loss worldwide. Lightning poses a huge threat to various industries. In an attempt to reduce the risk of lightning-caused disaster, many scholars have carried out in-depth research on lightning. However, these studies focus primarily on the lightning itself and other meteorological elements are ignored. In addition, the methods for assessing the risk of lightning disaster fail to give detailed attention to regional features (lightning disaster risk). This paper proposes a grid-based risk assessment method based on data from multiple sources. First, this paper considers the impact of lightning, the population density, the economy, and geographical environment data on the occurrence of lightning disasters; Second, this paper solves the problem of imbalanced lightning disaster data in geographic grid samples based on the K-means clustering algorithm; Third, the method calculates the feature of lightning disaster in each small field with the help of neural network structure, and the calculation results are then visually reflected in a zoning map by the Jenks natural breaks algorithm. The experimental results show that our method can solve the problem of imbalanced lightning disaster data, and offer 81% accuracy in lightning disaster risk assessment.
C1 [Zhang, Yan; Han, Jin; Yuan, Chengsheng; Li, Chuanlong; Sun, Xingming] Nanjing Univ Informat Sci & Technol, Nanjing 210044, Peoples R China.
   [Zhang, Yan; Han, Jin; Yuan, Chengsheng; Li, Chuanlong; Sun, Xingming] Minist Educ, Engn Res Ctr Digital Forens, Nanjing 201144, Peoples R China.
   [Yang, Shuo] Waterford Inst Technol, Waterford X91K 0EK, Ireland.
C3 Nanjing University of Information Science & Technology; South East Technological University (SETU)
RP Han, J (corresponding author), Nanjing Univ Informat Sci & Technol, Nanjing 210044, Peoples R China.; Han, J (corresponding author), Minist Educ, Engn Res Ctr Digital Forens, Nanjing 201144, Peoples R China.
EM hjhaohj@126.com
FU National Key R&D Program of China [2018YFB1003205]; National Natural Science Foundation of China [U1836208, U1536206, U1836110, 61602253, 61672294]; Startup Foundation for Introducing Talent of NUIST [1441102001002]; Jiangsu Basic Research Programs-Natural Science Foundation [BK20181407]; Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD) fund; Postgraduate Research and Innovation Plan Project in Jiangsu Province [KYCX20_0934]; Collaborative Innovation Center of Atmospheric Environment and Equipment Technology (CICAEET) fund, China
CR Ayzel G, 2019, PROCEDIA COMPUT SCI, V150, P186, DOI 10.1016/j.procs.2019.02.036
   Biswas RN, 2020, SPAT INF RES, V28, P507, DOI 10.1007/s41324-019-00311-y
   Cao WP, 2018, NEUROCOMPUTING, V275, P278, DOI 10.1016/j.neucom.2017.08.040
   Cerin E, 2017, INT J BEHAV NUTR PHY, V14, P0, DOI 10.1186/s12966-017-0471-5
   [陈广昌 Chen Guangchang], 2017, 灾害学 JOURNAL OF CATASTROPHOLOGY, V32, P32
   [陈柳彤 Chen Liutong], 2019, 灾害学 JOURNAL OF CATASTROPHOLOGY, V34, P189
   Chen XW, 2012, ELECTROMAGNETICS, V32, P1, DOI 10.1080/02726343.2012.633875
   Cui Xun, 2015, JOURNAL OF NATURAL DISASTERS, V24, P187, DOI 10.13577/j.jnd.2015.0623
   Farid DM, 2016, EXPERT SYST APPL, V64, P305, DOI 10.1016/j.eswa.2016.08.008
   Han J, 2020, CMC-COMPUT MATER CON, V64, P1171, DOI 10.32604/cmc.2019.07447
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Klein B., 2016, P IEEE C COMP VIS PA, V0, P4840
   Li YJ, 2017, IEEE PHOTONICS J, V9, P0, DOI 10.1109/JPHOT.2017.2674022
   Liu P. Y., 2018, J METEOROLOGICAL SCI, V38, P824
   Luo Y, 2020, IEEE T NEUR NET LEAR, V31, P685, DOI 10.1109/TNNLS.2019.2909737
   Nastos PT, 2014, ATMOS RES, V144, P207, DOI 10.1016/j.atmosres.2013.10.021
   Tian Y.T., 2012, J METEOROLOGICAL SCI, V40, P507, DOI 10.19517/j.1671-6345.2012.03.032
   Wang BW, 2019, IEEE ACCESS, V7, P69524, DOI 10.1109/ACCESS.2019.2917277
   [王惠 Wang Hui], 2007, 气象 METEOROLOGICAL MONTHLY, V33, P83
   Yeung D, 2015, NIPS 15 P 28 INT C N, V0, P802
   Zhu TF, 2019, KNOWL-BASED SYST, V166, P140, DOI 10.1016/j.knosys.2018.12.021
NR 21
TC 2
Z9 2
U1 4
U2 21
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PD JUN 15
PY 2021
VL 66
IS 1
BP 563
EP 574
DI 10.32604/cmc.2020.012502
PG 12
WC Computer Science, Information Systems; Materials Science, Multidisciplinary
SC Computer Science; Materials Science
GA OO7CT
UT WOS:000587534300036
DA 2023-04-26
ER

PT J
AU Bianchi, FM
   Grahn, J
   Eckerstorfer, M
   Malnes, E
   Vickers, H
AF Bianchi, Filippo Maria
   Grahn, Jakob
   Eckerstorfer, Markus
   Malnes, Eirik
   Vickers, Hannah
TI Snow Avalanche Segmentation in SAR Images With Fully Convolutional Neural Networks
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Synthetic aperture radar; Image segmentation; Peak to average power ratio; Deep learning; Snow; Radar imaging; Backscatter; Convolutional neural networks (CNNs); deep learning; saliency segmentation; Sentinel-1 (S1); snow avalanches; synthetic aperture radar (SAR)
AB Knowledge about frequency and location of snow avalanche activity is essential for forecasting and mapping of snow avalanche hazard. Traditional field monitoring of avalanche activity has limitations, especially when surveying large and remote areas. In recent years, avalanche detection in Sentinel-1 radar satellite imagery has been developed to improve monitoring. However, the current state-of-the-art detection algorithms, based on radar signal processing techniques, are still much less accurate than human experts. To reduce this gap, we propose a deep learning architecture for detecting avalanches in Sentinel-1 radar images. We trained a neural network on 6345 manually labeled avalanches from 117 Sentinel-1 images, each one consisting of six channels that include backscatter and topographical information. Then, we tested our trained model on a new synthetic aperture radar image. Comparing to the manual labeling (the gold standard), we achieved an F1 score above 66%, whereas the state-of-the-art detection algorithm sits at an F1 score of only 38%. A visual inspection of the results generated by our deep learning model shows that only small avalanches are undetected, whereas some avalanches that were originally not labeled by the human expert are discovered.
C1 [Bianchi, Filippo Maria] UiT Arctic Univ Norway, Dept Math & Stat, N-9019 Tromso, Norway.
   [Bianchi, Filippo Maria; Grahn, Jakob; Eckerstorfer, Markus; Malnes, Eirik; Vickers, Hannah] NORCE Norwegian Res Ctr AS, N-5008 Bergen, Norway.
C3 UiT The Arctic University of Tromso; Norwegian Research Centre (NORCE)
RP Bianchi, FM (corresponding author), UiT Arctic Univ Norway, Dept Math & Stat, N-9019 Tromso, Norway.
EM filippo.m.bianchi@uit.no; jgra@norceresearch.no; maec@norceresearch.no; eima@norceresearch.no; havi@norceresearch.no
FU 'Satskred' Project - Norwegian Space Centre [NIT.01.20.5]; Norwegian Water and Energy Resource Directorate; Norwegian Public Road Administration
CR Bakkehoi S., 1983, ANNALS OF GLACIOLOGY, V4, P24
   Berman M, 2018, PROC CVPR IEEE, V0, PP4413, DOI 10.1109/CVPR.2018.00464
   Bianchi FM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142260
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, PP801, DOI 10.1007/978-3-030-01234-2_49
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.32
   Delparte D, 2008, COLD REG SCI TECHNOL, V54, P183, DOI 10.1016/j.coldregions.2008.07.006
   Eckerstorfer M, 2017, COLD REG SCI TECHNOL, V144, P39, DOI 10.1016/j.coldregions.2017.08.004
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Jones, 2011, P 5 CAN C GEOT NAT, V49, P1309
   Kampffmeyer M, 2018, IEEE J-STARS, V11, P1758, DOI 10.1109/JSTARS.2018.2834961
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, V0, PP680, DOI 10.1109/CVPRW.2016.90
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krestenitis M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151762
   Kummervold Per Egil, 2018, P INT SNOW SCI WORKS, V0, P377
   Larsen, 2018, P 12 EUR C SYNTH AP, V0, P1
   Luppino LT, 2018, IEEE INT WORKS MACH, V0, P0
   Luppino LT, 2019, IEEE T GEOSCI REMOTE, V57, P9960, DOI 10.1109/TGRS.2019.2930348
   Penatti Otavio A. B., 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP44, DOI 10.1109/CVPRW.2015.7301382
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sinha, 2019, P CLIM INF PAR FRANC, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vickers H, 2017, LECT NOTES COMPUT SC, V10270, P136, DOI 10.1007/978-3-319-59129-2_12
   Waldeland AU, 2018, INT GEOSCI REMOTE SE, V0, P2386
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 26
TC 13
Z9 13
U1 3
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 75
EP 82
DI 10.1109/JSTARS.2020.3036914
PG 8
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900003
DA 2023-04-26
ER

PT J
AU Yu, T
   Wu, WJ
   Gong, C
   Li, XW
AF Yu, Tong
   Wu, Wenjin
   Gong, Chen
   Li, Xinwu
TI Residual Multi-Attention Classification Network for A Forest Dominated Tropical Landscape Using High-Resolution Remote Sensing Imagery
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE remote sensing; deep convolution network; image analysis; land use and land cover (LULC); tropical forest
ID cover
AB Tropical forests are of vital importance for maintaining biodiversity, regulating climate and material cycles while facing deforestation, agricultural reclamation, and managing various pressures. Remote sensing (RS) can support effective monitoring and mapping approaches for tropical forests, and to facilitate this we propose a deep neural network with an encoder-decoder architecture here to classify tropical forests and their environment. To deal with the complexity of tropical landscapes, this method utilizes a multi-scale convolution neural network (CNN) to expand the receptive field and extract multi-scale features. The model refines the features with several attention modules and fuses them through an upsampling module. A two-stage training strategy is proposed to alleviate misclassifications caused by sample imbalances. A joint loss function based on cross-entropy loss and the generalized Dice loss is applied in the first stage, and the second stage used the focal loss to fine-tune the weights. As a case study, we use Hainan tropical reserves to test the performance of this model. Compared with four state-of-the-art (SOTA) semantic segmentation networks, our network achieves the best performance with two Hainan datasets (mean intersection over union (MIoU) percentages of 85.78% and 82.85%). We also apply the new model to classify a public true color dataset which has 17 semantic classes and obtain results with an 83.75% MIoU. This further demonstrates the applicability and potential of this model in complex classification tasks.
C1 [Yu, Tong; Wu, Wenjin; Gong, Chen; Li, Xinwu] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Yu, Tong] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
   [Wu, Wenjin; Li, Xinwu] Sanya Inst Remote Sensing, Sanya 572029, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Gong, C (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
EM yutong@aircas.ac.cn; wuwj@radi.ac.cn; gongchen@radi.ac.cn; lixw@aircas.ac.cn
FU Key Research and Development Program of Hainan Province [ZDYF2019005]; Aerospace Information Research Institute, Chinese Academy of Sciences [Y951150Z2F]
CR [Anonymous], 2015, LEARNING REPRESENTAT, V0, P0
   [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   [Anonymous], 2015, GLOB FOR RES ASS 201, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bullock EL, 2020, REMOTE SENS ENVIRON, V238, P0, DOI 10.1016/j.rse.2018.11.011
   Cabrera-Barona PF, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9070453
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, PP801, DOI 10.1007/978-3-030-01234-2_49
   Ghosh SM, 2018, APPL GEOGR, V96, P29, DOI 10.1016/j.apgeog.2018.05.011
   Hame T, 2001, REMOTE SENS ENVIRON, V77, P76, DOI 10.1016/S0034-4257(01)00195-X
   Hame T, 2013, IEEE J-STARS, V6, P74, DOI 10.1109/JSTARS.2013.2241019
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, V0, PP1026, DOI 10.1109/ICCV.2015.123
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101667
   Huang G, 2017, PROC CVPR IEEE, V0, PP2261, DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lin Tsung-Yi, 2020, IEEE TRANS PATTERN ANAL MACH INTELL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu PH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070830
   Liu Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111780
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Park, 2018, BRIT MACH VIS C, V0, P0
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), V0, PP1, DOI 10.1109/ICPHM.2017.7998297
   Rahman Md Atiqur, 2016, ADVANCES IN VISUAL COMPUTING. 12TH INTERNATIONAL SYMPOSIUM, V0, P234, DOI 10.1007/978-3-319-50835-1_22
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shao ZF, 2020, IEEE J-STARS, V13, P318, DOI 10.1109/JSTARS.2019.2961634
   Shao ZF, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060964
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao H., 1999, J SOIL WATER CONSERV, V5, P75
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091461
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010144
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 37
TC 3
Z9 3
U1 1
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD JAN 15
PY 2021
VL 10
IS 1
BP 
EP 
DI 10.3390/ijgi10010022
PG 20
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA PV9AU
UT WOS:000610272800001
DA 2023-04-26
ER

PT J
AU Zhang, XN
   Ge, Y
   Ling, F
   Chen, J
   Chen, YH
   Jia, YX
AF Zhang, Xining
   Ge, Yong
   Ling, Feng
   Chen, Jin
   Chen, Yuehong
   Jia, Yuanxin
TI Graph Convolutional Networks-Based Super-Resolution Land Cover Mapping
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Deep neural networks (DNNs); graph convolutional networks (GCNs); land cover; subpixel; super-resolution mapping (SRM).
ID neural-network; pixel; classification; patterns
AB Super-resolution mapping (SRM) is an effective technology to solve the problem of mixed pixels because it can be used to generate fine-resolution land cover maps from coarse-resolution remote sensing images. Current methods based on deep neural networks have been successfully applied to SRM, as they can learn complex spatial patterns from training data. However, they lack the ability to learn structural information between adjacent land cover classes, which is vital in the reconstruction of spatial distribution. In this article, an SRM method based on graph convolutional networks (GCNs), named SRMGCN, is proposed to improve SRM results by capturing structure information on the graph. In SRMGCN, a supervised inductive learning strategy with mini-graphs as input is considered, which is an extension of the GCN framework. Furthermore, two operations are designed in terms of adjacency matrix construction and an information propagation rule to help reconstruct detailed information of geographical objects. Experiments on three datasets with different spatial resolutions demonstrate the qualitative and quantitative superiority of SRMGCN over three other popular SRM methods.
C1 [Zhang, Xining; Ge, Yong] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.
   [Zhang, Xining; Ge, Yong] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Ling, Feng] Chinese Acad Sci, Innovat Acad Precis Measurement Sci & Technol, Key Lab Monitoring & Estimate Environm & Disaster, Wuhan 430077, Peoples R China.
   [Chen, Jin] Beijing Normal Univ, State Key Lab Earth Surface Proc & Resource Ecol, Beijing 100875, Peoples R China.
   [Chen, Yuehong] Hohai Univ, Coll Hydrol & Water Resources, Nanjing 210098, Peoples R China.
   [Jia, Yuanxin] Acad Forest Inventory & Planning, Natl Forestry & Grassland Adm, Beijing 100714, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Beijing Normal University; Hohai University
RP Ge, Y (corresponding author), Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.; Chen, J (corresponding author), Beijing Normal Univ, State Key Lab Earth Surface Proc & Resource Ecol, Beijing 100875, Peoples R China.
EM zhangxn@lreis.ac.cn; gey@lreis.ac.cn; lingf@whigg.ac.cn; chenjin@bnu.edu.cn; chenyh@lreis.ac.cn; jiayx@lreis.ac.cn
FU National Natural Science Foundation for Distinguished Young Scholars of China [41725006]
CR Arun PV, 2018, NEUROCOMPUTING, V311, P51, DOI 10.1016/j.neucom.2018.05.051
   Arun PV, 2019, PATTERN RECOGN, V88, P431, DOI 10.1016/j.patcog.2018.11.033
   Atkinson P. M., 1997, INNOVATIONS GIS, V4, P166
   Atkinson PM, 2013, INT J APPL EARTH OBS, V22, P106, DOI 10.1016/j.jag.2012.04.012
   Atkinson PM, 2009, INT J REMOTE SENS, V30, P5293, DOI 10.1080/01431160903131034
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Chen Y., 2017, IEEE T GEOSCI ELECT, V56, P328
   Chen YH, 2018, IEEE T GEOSCI REMOTE, V56, P5097, DOI 10.1109/TGRS.2018.2808410
   Chen YH, 2015, IEEE J-STARS, V8, P2040, DOI 10.1109/JSTARS.2015.2417191
   Defferrard M., 2016, ADV NEURAL INFORM PR, V29, P3837, DOI 10.5555/3157382.3157527
   Fey M, 2018, PROC CVPR IEEE, V0, PP869, DOI 10.1109/CVPR.2018.00097
   Fisher P, 1997, INT J REMOTE SENS, V18, P679, DOI 10.1080/014311697219015
   Ge Y, 2019, EARTH-SCI REV, V197, P0, DOI 10.1016/j.earscirev.2019.102897
   Ge Y, 2014, INT J REMOTE SENS, V35, P1756, DOI 10.1080/01431161.2014.882034
   Ge Y, 2013, INT J APPL EARTH OBS, V22, P115, DOI 10.1016/j.jag.2012.04.013
   Ge Y, 2009, IEEE T GEOSCI REMOTE, V47, P2155, DOI 10.1109/TGRS.2008.2010863
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   He D., 2020, IEEE T GEOSCI ELECT, V0, P0, DOI DOI 10.1109/TGRS.2020.3032475
   He HS, 2000, LANDSCAPE ECOL, V15, P591, DOI 10.1023/A:1008102521322
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Jia YX, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151815
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kipf T. N., 2017, ICLR, V0, P0
   LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ling F, 2019, REMOTE SENS LETT, V10, P598, DOI 10.1080/2150704X.2019.1587196
   Ling F, 2016, IEEE T GEOSCI REMOTE, V54, P3794, DOI 10.1109/TGRS.2016.2527841
   Liu QJ, 2021, IEEE T GEOSCI REMOTE, V59, P10227, DOI 10.1109/TGRS.2020.3042974
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu Y, 2021, IEEE T COGN DEV SYST, V13, P631, DOI 10.1109/TCDS.2020.2998497
   Ma AL, 2018, IEEE T GEOSCI REMOTE, V56, P422, DOI 10.1109/tgrs.2017.2748701
   Ma XF, 2019, IEEE J-STARS, V12, P4930, DOI 10.1109/JSTARS.2019.2941089
   Ma XF, 2020, INT J REMOTE SENS, V41, P2818, DOI 10.1080/01431161.2019.1698079
   Mertens KC, 2006, INT J REMOTE SENS, V27, P3293, DOI 10.1080/01431160500497127
   Monti F, 2017, PROC CVPR IEEE, V0, PP5425, DOI 10.1109/CVPR.2017.576
   Oliphant TE, 2007, COMPUT SCI ENG, V9, P10, DOI 10.1109/MCSE.2007.58
   Paszke, 2019, ADV NEURAL INFORM PR, V0, P8024
   Song M, 2020, IEEE T GEOSCI REMOTE, V58, P8176, DOI 10.1109/TGRS.2020.2987910
   Tatem AJ, 2003, INT J GEOGR INF SCI, V17, P647, DOI 10.1080/1365881031000135519
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5
   Volpi M, 2015, IEEE COMPUT SOC CONF, V0, P0, DOI DOI 10.1109/CVPRW.2015.7301377
   Wan S, 2021, IEEE T GEOSCI REMOTE, V59, P597, DOI 10.1109/TGRS.2020.2994205
   Wan S, 2020, IEEE T GEOSCI REMOTE, V58, P3162, DOI 10.1109/TGRS.2019.2949180
   Wang L., 2013, IEEE T GEOSCI ELECT, V52, P2940
   Wang LG, 2006, LECT NOTES CONTR INF, V345, P755
   Wang P, 2019, IEEE J-STARS, V12, P1835, DOI 10.1109/JSTARS.2019.2910539
   Wang QM, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112054
   Wu K, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, V0, PP742, DOI 10.1109/ICIG.2007.65
   Xu X, 2018, IEEE T GEOSCI REMOTE, V56, P6763, DOI 10.1109/TGRS.2018.2842748
   Xu X, 2013, IEEE J-STARS, V6, P580, DOI 10.1109/JSTARS.2012.2227246
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Yang Y, 2021, PATTERN RECOGN, V112, P0, DOI 10.1016/j.patcog.2020.107798
   Zhang LP, 2008, NEUROCOMPUTING, V71, P2046, DOI 10.1016/j.neucom.2007.08.033
   Zhang YH, 2014, IEEE J-STARS, V7, P1271, DOI 10.1109/JSTARS.2014.2305652
NR 57
TC 4
Z9 4
U1 6
U2 26
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7667
EP 7681
DI 10.1109/JSTARS.2021.3100400
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA TZ8CP
UT WOS:000684698600009
DA 2023-04-26
ER

PT J
AU Saha, TK
   Pal, S
   Sarkar, R
AF Saha, Tamal Kanti
   Pal, Swades
   Sarkar, Raju
TI Prediction of wetland area and depth using linear regression model and artificial neural network based cellular automata
SO ECOLOGICAL INFORMATICS
LA English
DT Article
DE Atreyee river basin; Wetland inventory; NDWI; Prediction of wetland area; Linear regression; Artificial neural network
ID atreyee river-basin; water index ndwi; land-use; logistic-regression; vulnerability; china; sensitivity
AB Wetlands are an integral part of the socio-ecological setup of the earth, but their fast transformation beg careful consideration. In this regard, the flood plain wetlands of the Atreyee river basin of India and Bangladesh are not exceptional. The main goal of this study is the mapping of the floodplain wetlands, along with arriving at predictions of their area up to 2039 using the advanced technique of artificial neural network based cellular automata (ANN-CA). Apart from this, prediction of wetland depth using linear regression model is another aim of the present research work. The analysis is executed using 27 Landsat images and Digital Elevation Model (DEM). Results reveal that the present wetland area is 52.92 km2 in pre-monsoon and 518.68 km2 in post-monsoon season, respectively. The composite wetland map from 1987 to 2019 of post-monsoon clearly indicates that 10.48km2 wetlands are identified as hydro-ecologically consistent wetlands. Simulated models reveal that the wetland area from 2009 to 2019 has declined by 66.16km2 and is expected to decrease by 164.62km2 in the next 20 years. Normalized Difference Water Index (NDWI) depth indicates that water availability also may decline significantly in the next 20 years as per regression model-based simulation. All the simulated models were validated with observed wetland area by kappa coefficient, receiver operating curve. The present study will definitely be useful for decision-makers by aiding them in initiatives that take a significant step toward maintaining the wetland landscape, as well as the environment.
C1 [Saha, Tamal Kanti; Pal, Swades] Univ Gour Banga, Dept Geog, Malda 732103, W Bengal, India.
   [Sarkar, Raju] Delhi Technol Univ, Dept Civil Engn, Delhi 110042, India.
C3 University of Gour Banga; Delhi Technological University
RP Sarkar, R (corresponding author), Delhi Technol Univ, Dept Civil Engn, Delhi 110042, India.
EM rajusarkar@dce.ac.in
FU University Grants Commission, New Delhi, India
CR Afzaal H, 2020, WATER-SUI, V12, P0, DOI 10.3390/w12010005
   Ahmadlou M, 2019, J INDIAN SOC REMOTE, V47, P53, DOI 10.1007/s12524-018-0866-z
   [Anonymous], 2015, INT J ENG RES GEN SC, V0, P0
   Atlas National Wetland, 2011, SACRESAAFEGNWIAATLAS, V0, P0
   Blanchard T, 2020, WIND ENG, V44, P33, DOI 10.1177/0309524X19849846
   Buckland CE, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-40429-5
   Byeon CW, 2020, ECOL ENG, V145, P0, DOI 10.1016/j.ecoleng.2020.105723
   Byun E, 2018, CARBON BAL MANAGE, V13, P0, DOI 10.1186/s13021-018-0094-4
   Cai YB, 2012, CHINESE GEOGR SCI, V22, P568, DOI 10.1007/s11769-012-0564-7
   Chaparro G, 2019, SCI TOTAL ENVIRON, V667, P338, DOI 10.1016/j.scitotenv.2019.02.147
   Colvin SAR, 2019, FISHERIES, V44, P73, DOI 10.1002/fsh.10229
   Das R.T., 2016, J WETLANDS ENV MANAG, V4, P0
   de Oliveira GG, 2019, NAT HAZARDS, V99, P1049, DOI 10.1007/s11069-019-03795-x
   Debanshi S, 2020, ECOL INDIC, V108, P0, DOI 10.1016/j.ecolind.2019.105757
   Dey N, 2016, 2016 INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL POWER AND INSTRUMENTATION (ICICPI), V0, PP27, DOI 10.1109/ICICPI.2016.7859667
   Bui DT, 2012, MATH PROBL ENG, V2012, P0, DOI 10.1155/2012/974638
   Dixon B, 2005, J HYDROL, V309, P17, DOI 10.1016/j.jhydrol.2004.11.010
   Ekumah B, 2020, OCEAN COAST MANAGE, V193, P0, DOI 10.1016/j.ocecoaman.2020.105226
   Endter-Wada J, 2020, ENVIRON SCI POLICY, V108, P37, DOI 10.1016/j.envsci.2020.01.016
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gittman RK, 2019, FRONT MAR SCI, V6, P0, DOI 10.3389/fmars.2019.00511
   Govindaraju RS, 2000, J HYDROL ENG, V5, P124
   Graf WL, 2006, GEOMORPHOLOGY, V79, P336, DOI 10.1016/j.geomorph.2006.06.022
   Hajian-Tilaki K, 2013, CASP J INTERN MED, V4, P627
   Hossain Mostafa A. R., 2009, LAKES & RESERVOIRS RESEARCH AND MANAGEMENT, V14, P3, DOI 10.1111/j.1440-1770.2009.00387.x
   Katsuki K, 2019, ESTUAR COAST SHELF S, V222, P205, DOI 10.1016/j.ecss.2019.04.016
   Lamacova A, 2014, SOIL WATER RES, V9, P169, DOI 10.17221/110/2013-SWR
   Li Z, 2020, ECOL INDIC, V117, P0, DOI 10.1016/j.ecolind.2020.106677
   Liao HM, 2020, REMOTE SENS ENVIRON, V251, P0, DOI 10.1016/j.rse.2020.112051
   Lu CY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212581
   Mahato S, 2019, NAT RESOUR RES, V28, P523, DOI 10.1007/s11053-018-9404-5
   Mahdianpari M, 2020, CAN J REMOTE SENS, V46, P15, DOI 10.1080/07038992.2019.1711366
   Mao DH, 2020, ISPRS J PHOTOGRAMM, V164, P11, DOI 10.1016/j.isprsjprs.2020.03.020
   Mao DH, 2018, LAND DEGRAD DEV, V29, P2644, DOI 10.1002/ldr.2939
   Martins VS, 2020, INT J APPL EARTH OBS, V93, P0, DOI 10.1016/j.jag.2020.102215
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Memarzadeh G, 2020, ENERG CONVERS MANAGE, V213, P0, DOI 10.1016/j.enconman.2020.112824
   Mu SJ, 2020, SCI TOTAL ENVIRON, V725, P0, DOI 10.1016/j.scitotenv.2020.138096
   Munishi S, 2019, PHYS CHEM EARTH, V112, P216, DOI 10.1016/j.pce.2019.03.008
   Ondiek RA, 2020, FRONT ENV SCI-SWITZ, V7, P0, DOI 10.3389/fenvs.2019.00207
   Ouma YO, 2006, INT J REMOTE SENS, V27, P3153, DOI 10.1080/01431160500309934
   Pal S, 2018, ECOHYDROL HYDROBIOL, V18, P66, DOI 10.1016/j.ecohyd.2017.11.001
   Pal S, 2018, HUM ECOL RISK ASSESS, V24, P1291, DOI 10.1080/10807039.2017.1411781
   Pal S, 2017, ENVIRON DEV SUSTAIN, V19, P2115, DOI 10.1007/s10668-016-9833-4
   Pal S, 2016, INT J RIVER BASIN MA, V14, P459, DOI 10.1080/15715124.2016.1194282
   Pal S, 2016, ENVIRON DEV SUSTAIN, V18, P921, DOI 10.1007/s10668-015-9679-1
   Paul S, 2020, REMOTE SENS APPL, V19, P0, DOI 10.1016/j.rsase.2020.100338
   Perennou C, 2018, ADV ECOL RES, V58, P243, DOI 10.1016/bs.aecr.2017.12.002
   Pickens AH, 2020, REMOTE SENS ENVIRON, V243, P0, DOI 10.1016/j.rse.2020.111792
   Pourghasemi HR, 2013, ARAB J GEOSCI, V6, P2351, DOI 10.1007/s12517-012-0532-7
   Ramsar Convention Secretariat, 2016, INTR RAMS CONV WETL, V0, P0
   Ramsar Convention Secretariat, 2010, RAMS HDB WIS US WETL, V15, P0
   Rashid B., 2014, AM J EARTH SCI, V1, P86
   Rasyid A.R., 2016, GEOENVIRONMENTAL DIS, V3, P19, DOI 10.1186/s40677-016-0053-x
   Reiter ME, 2018, PEERJ, V6, P0, DOI 10.7717/peerj.5147
   Roy-Basu A, 2020, SCI TOTAL ENVIRON, V698, P0, DOI 10.1016/j.scitotenv.2019.134203
   Saha TK, 2019, ENVIRON DEV SUSTAIN, V21, P1485, DOI 10.1007/s10668-018-0099-x
   Saha TK, 2019, ECOL INDIC, V98, P251, DOI 10.1016/j.ecolind.2018.11.009
   Sanchez-Espinosa A, 2019, J ENVIRON MANAGE, V247, P484, DOI 10.1016/j.jenvman.2019.06.084
   Saputra MH, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11113024
   Sarkar D, 2020, APPL WATER SCI, V10, P0, DOI 10.1007/s13201-019-1102-x
   SETH J, 2017, ECOL INDIC, V83, P0, DOI 10.1016/J.ECOLIND.2017.07.037
   SHROUT PE, 1987, ARCH GEN PSYCHIAT, V44, P172
   Slagter B, 2020, INT J APPL EARTH OBS, V86, P0, DOI 10.1016/j.jag.2019.102009
   Song F, 2020, J CLEAN PROD, V248, P0, DOI 10.1016/j.jclepro.2019.119236
   Space Applications Centre (SAC), 2011, NAT WETL ATL, V0, P0
   Steinfeld CMM, 2020, J HYDROL, V588, P0, DOI 10.1016/j.jhydrol.2020.125009
   Sunayana, 2020, ENVIRON DEV SUSTAIN, V22, P2801, DOI 10.1007/s10668-019-00319-2
   Talukdar S, 2020, J CLEAN PROD, V261, P0, DOI 10.1016/j.jclepro.2020.120767
   Tesch N., 2020, CENT ASIAN J WATER R, V6, P39, DOI 10.29258/CAJWR/2020-R1.v6-1/39-65.eng
   Thapa S, 2020, WETLANDS, V40, P1071, DOI 10.1007/s13157-020-01303-7
   Uniyal B, 2020, SCI TOTAL ENVIRON, V744, P0, DOI 10.1016/j.scitotenv.2020.140737
   Varin M, 2019, J ENVIRON MANAGE, V246, P334, DOI 10.1016/j.jenvman.2019.05.115
   Varoonchotikul P, 2003, FLOOD FORECASTING US, V0, P0
   Wang XX, 2020, ISPRS J PHOTOGRAMM, V163, P312, DOI 10.1016/j.isprsjprs.2020.03.014
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Weise K, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111892
   Wen L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101683
   Werbos Paul, 1974, REGRESSION NEW TOOLS, V0, P0
   Wizor CH, 2020, ASIAN J GEOGRAPH RES, V3, P35, DOI 10.9734/ajgr/2020/v3i1300993
   Wu H, 2019, INT J GEOGR INF SCI, V33, P1040, DOI 10.1080/13658816.2019.1568441
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Xu T, 2019, INT J ENV RES PUB HE, V16, P0, DOI 10.3390/ijerph16101818
   Xu WH, 2019, CURR BIOL, V29, P3065, DOI 10.1016/j.cub.2019.07.053
   Yang H, 2020, J EARTH SYST SCI, V129, P0, DOI 10.1007/s12040-020-1347-7
   ZHANG CX, 2020, SUSTAINABILITY-BASEL, V12, P0, DOI 10.3390/SU12041442
   ZHANG X, 2016, WATER-SUI, V8, P0, DOI 10.3390/W8120590
   Zheng YX, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11102038
NR 88
TC 19
Z9 19
U1 2
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-9541
EI 1878-0512
J9 ECOL INFORM
JI Ecol. Inform.
PD MAY 15
PY 2021
VL 62
IS 
BP 
EP 
DI 10.1016/j.ecoinf.2021.101272
EA MAR 2021
PG 15
WC Ecology
SC Environmental Sciences & Ecology
GA RM7PO
UT WOS:000639851100007
DA 2023-04-26
ER

PT J
AU Naghadehi, SZ
   Asadi, M
   Maleki, M
   Tavakkoli-Sabour, SM
   Van Genderen, JL
   Saleh, SS
AF Naghadehi, Saeid Zare
   Asadi, Milad
   Maleki, Mohammad
   Tavakkoli-Sabour, Seyed-Mohammad
   Van Genderen, John Lodewijk
   Saleh, Samira-Sadat
TI Prediction of Urban Area Expansion with Implementation of MLC, SAM and SVMs' Classifiers Incorporating Artificial Neural Network Using Landsat Data
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE urban expansion; change detection; change prediction; Support Vector Machines (SVMs); Maximum Likelihood Classifier (MLC); Spectral Angle Mapper (SAM); Artificial Neural Network
ID underground space; use/cover change; cover; intensity; science
AB A reliable land cover (LC) map is essential for planners, as missing proper land cover maps may deviate a project. This study is focusing on land cover classification and prediction using three well known classifiers and remote sensing data. Maximum Likelihood classifier (MLC), Spectral Angle Mapper (SAM), and Support Vector Machines (SVMs) algorithms are used as the representatives for parametric, non-parametric and subpixel capable methods for change detection and change prediction of Urmia City (Iran) and its suburbs. Landsat images of 2000, 2010, and 2020 have been used to provide land cover information. The results demonstrated 0.93-0.94 overall accuracies for MLC and SVMs' algorithms, but it was around 0.79 for the SAM algorithm. The MLC performed slightly better than SVMs' classifier. Cellular Automata Artificial neural network method was used to predict land cover changes. Overall accuracy of MLC was higher than others at about 0.94 accuracy, although, SVMs were slightly more accurate for large area segments. Land cover maps were predicted for 2030, which demonstrate the city's expansion from 5500 ha in 2000 to more than 9000 ha in 2030.
C1 [Naghadehi, Saeid Zare] SUNY Syracuse, Coll Environm Sci & Forestry, Dept Environm Resources Engn, 1 Forestry Dr, Syracuse, NY 13210 USA.
   [Asadi, Milad] Univ Daneshpajoohan, Dept Urban Planning, Esfahan 8174747144, Iran.
   [Maleki, Mohammad; Tavakkoli-Sabour, Seyed-Mohammad; Saleh, Samira-Sadat] Kharazmi Univ, Dept Remote Sensing, Tehran 3755131979, Iran.
   [Tavakkoli-Sabour, Seyed-Mohammad] Tauber Delaburat, D-99099 Erfurt, Germany.
   [Van Genderen, John Lodewijk] Int Inst Geoinformat Sci & Earth Observat ITC, NL-7500 Enschede, Netherlands.
C3 State University of New York (SUNY) System; State University of New York (SUNY) College of Environmental Science & Forestry; Kharazmi University
RP Tavakkoli-Sabour, SM (corresponding author), Kharazmi Univ, Dept Remote Sensing, Tehran 3755131979, Iran.; Tavakkoli-Sabour, SM (corresponding author), Tauber Delaburat, D-99099 Erfurt, Germany.
EM szarenaghadehi@esf.edu; Miladasadi19908@gmail.com; Std_mohammad.maleki@khu.ac.ir; tavakkoli@khu.ac.ir; genderen@alumni.itc.nl; sa.saleh@epedc.ir
CR Abedini A, 2019, J URBAN MANAG, V8, P316, DOI 10.1016/j.jum.2019.04.001
   Alharthi A, 2020, SAUDI J BIOL SCI, V27, P3169, DOI 10.1016/j.sjbs.2020.07.021
   Arsiso BK, 2018, PHYS CHEM EARTH, V105, P212, DOI 10.1016/j.pce.2018.02.009
   Asadi Y., 2019, DESERT, V24, P293, DOI 10.22059/jdesert.2019.76386
   Bajracharya P, 2020, PROF GEOGR, V72, P181, DOI 10.1080/00330124.2019.1674668
   Batty M, 1997, ENVIRON PLANN B, V24, P175, DOI 10.1068/b240175
   Boardman J. W, 1992, P SUMM ANN JPL AIRB, V1, P147
   Centre for Health Development World Health Organization, 2010, HIDD CIT UNM OV HLTH, V0, P0
   Claudia A., 2005, P AN 12 S BRAS SENS, V0, P3697
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cuentas S, 2017, INT J ADV MANUF TECH, V91, P485, DOI 10.1007/s00170-016-9693-y
   Dezhkam S, 2014, GEOJOURNAL, V79, P591, DOI 10.1007/s10708-013-9515-9
   Estoque RC, 2015, LAND USE POLICY, V48, P213, DOI 10.1016/j.landusepol.2015.05.017
   Geng J, 2020, GEO-SPAT INF SCI, V23, P237, DOI 10.1080/10095020.2020.1785958
   Gibril MBA, 2017, GEOCARTO INT, V32, P735, DOI 10.1080/10106049.2016.1170893
   Hersperger AM, 2018, GLOBAL ENVIRON CHANG, V51, P32, DOI 10.1016/j.gloenvcha.2018.05.001
   Huang B, 2020, GEO-SPAT INF SCI, V23, P125, DOI 10.1080/10095020.2020.1754138
   Huang X, 2021, GEO-SPAT INF SCI, V24, P528, DOI 10.1080/10095020.2021.1892459
   Idowu T., 2020, PREPRINTS, V0, P0, DOI DOI 10.20944/preprints202007.0560.v1
   Iran Statistic Center, 2013, POP CENS RES DIFF YE, V0, P0
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Kadavi PR, 2018, GEOSCI J, V22, P652, DOI 10.1007/s12303-018-0023-2
   Kong XY, 2018, J OCEANOL LIMNOL, V36, P249, DOI 10.1007/s00343-017-6224-0
   Lotfata Y., 2018, J SUSTAIN DEV, V11, Pp174, DOI 10.5539/jsd.v11n4p174
   Magliocca NR, 2015, REG ENVIRON CHANGE, V15, P211, DOI 10.1007/s10113-014-0626-8
   Maitima J. M., 2009, AFRICAN JOURNAL OF ENVIRONMENTAL SCIENCE AND TECHNOLOGY, V3, P310
   Maleki M, 2020, GEOGR TECH, V15, P93, DOI 10.21163/GT_2020.152.10
   Mallouk A, 2018, INT ARCH PHOTOGRAMM, V42-4, P139, DOI 10.5194/isprs-archives-XLII-4-W12-139-2019
   Mobaraki Omid, 2012, J GEOGRAPHY GEOLOGY, V4, P1, DOI 10.5539/JGG.V4N2P1
   Mohammadi A, 2020, CHEMOSPHERE, V246, P0, DOI 10.1016/j.chemosphere.2019.125769
   MohanRajan SN, 2020, ENVIRON SCI POLLUT R, V27, P29900, DOI 10.1007/s11356-020-09091-7
   NasrEsfahani R, 2018, J URBAN ECON MANAG, V6, P95, DOI 10.29252/iueam.6.22.95
   Omid M., 2014, ROM REV REG STUD, V10, P47
   Peled A, 2013, APPL GEOMAT, V5, P109, DOI 10.1007/s12518-013-0100-1
   Peng J, 2018, TUNN UNDERGR SP TECH, V74, P82, DOI 10.1016/j.tust.2018.01.002
   Qiao YK, 2017, LAND USE POLICY, V69, P12, DOI 10.1016/j.landusepol.2017.08.037
   Rashmi S., 2014, INT J INNOV SCI ENG, V1, P201, DOI 10.1109/CISP.2013.6745277
   Salem J., 2017, ENV RESOUR RES, V5, P143
   Saputra MH, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11113024
   Seki HA, 2018, AFR J ECOL, V56, P518, DOI 10.1111/aje.12488
   Shao ZF, 2021, GEO-SPAT INF SCI, V24, P372, DOI 10.1080/10095020.2020.1864232
   Shao ZF, 2021, GEO-SPAT INF SCI, V24, P241, DOI 10.1080/10095020.2020.1787800
   Shin JI, 2019, FORESTS, V10, P0, DOI 10.3390/f10111025
   Simwanda M, 2018, SUSTAIN CITIES SOC, V39, P262, DOI 10.1016/j.scs.2018.01.039
   Sivakumar V, 2014, INT ARCH PHOTOGRAMM, V40-8, P967, DOI 10.5194/isprsarchives-XL-8-967-2014
   Song K., 2009, P 2009 IEEE INT GEOS, V4, P310
   Subasinghe S, 2016, ISPRS INT GEO-INF, V5, P0, DOI 10.3390/ijgi5110197
   Tadese Semegnew, 2021, SCIENTIFICWORLDJOURNAL, V2021, P6685045, DOI 10.1155/2021/6685045
   Talukdar S, 2020, ECOL INDIC, V112, P0, DOI 10.1016/j.ecolind.2020.106121
   Terama E, 2019, REG ENVIRON CHANGE, V19, P667, DOI 10.1007/s10113-017-1194-5
   Trinder J, 2020, GEO-SPAT INF SCI, V23, P20, DOI 10.1080/10095020.2019.1710438
   Turner BL, 2007, P NATL ACAD SCI USA, V104, P20666, DOI 10.1073/pnas.0704119104
   U.S. Census Bureau, 2012, GROWTH URB POP OUTP, V0, P0
   Vandansambuu ABB, 2020, PROC SPIE, V11535, P0, DOI 10.1117/12.2574032
   Verburg PH, 2015, ANTHROPOCENE, V12, P29, DOI 10.1016/j.ancene.2015.09.004
   Wang D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020169
   Wang S.W., 2021, ENV CHALL, V2, P17, DOI 10.1016/j.envc.2020.100017
   Wellmann T, 2018, ECOL INDIC, V85, P190, DOI 10.1016/j.ecolind.2017.10.029
   Williams R.E., 1987, URISA, V3, P150
   Woo H., 2020, PREPRINTS, V0, P0, DOI DOI 10.18494/SAM.2021.3365
   Wu X, 2015, GEO-SPAT INF SCI, V18, P159, DOI 10.1080/10095020.2015.1116206
   Yang XL, 2016, HYDROL RES, V47, P1161, DOI 10.2166/nh.2016.108
   Yuan H, 2019, SUSTAIN CITIES SOC, V48, P0, DOI 10.1016/j.scs.2019.101541
   Zhang T, 2020, ENVIRON SCI POLLUT R, V27, P14977, DOI 10.1007/s11356-020-07706-7
   Zhou XL, 2011, GEOGR RES-AUST, V49, P23, DOI 10.1111/j.1745-5871.2010.00686.x
   Zhu XY, 2019, GEO-SPAT INF SCI, V22, P193, DOI 10.1080/10095020.2019.1649192
NR 66
TC 5
Z9 5
U1 1
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD AUG 15
PY 2021
VL 10
IS 8
BP 
EP 
DI 10.3390/ijgi10080513
PG 14
WC Computer Science, Information Systems; Geography, Physical; Remote Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA UG8AT
UT WOS:000689468600001
DA 2023-04-26
ER

PT J
AU Xin, HR
   Lu, XJ
   Xu, T
   Liu, H
   Gu, JJ
   Dou, DJ
   Xiong, H
AF Xin, Haoran
   Lu, Xinjiang
   Xu, Tong
   Liu, Hao
   Gu, Jingjing
   Dou, Dejing
   Xiong, Hui
TI Out-of-Town Recommendation with Travel Intention Modeling
SO THIRTY-FIFTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THIRTY-THIRD CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND THE ELEVENTH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
LA English
DT Proceedings Paper
AB Out-of-town recommendation is designed for those users who leave their home-town areas and visit the areas they have never been to before. It is challenging to recommend Point-of-Interests (POIs) for out-of-town users since the out-of-town check-in behavior is determined by not only the user's home-town preference but also the user's travel intention. Besides, the user's travel intentions are complex and dynamic, which leads to big difficulties in understanding such intentions precisely. In this paper, we propose a TRAvel-INtention-aware Out-of-town Recommendation framework, named TRAINOR. The proposed TRAINOR framework distinguishes itself from existing out-of-town recommenders in three aspects. First, graph neural networks are explored to represent users' home-town check-in preference and geographical constraints in out-of-town check-in behaviors. Second, a user-specific travel intention is formulated as an aggregation combining home-town preference and generic travel intention together, where the generic travel intention is regarded as a mixture of inherent intentions that can be learned by Neural Topic Model (NTM). Third, a non-linear mapping function, as well as a matrix factorization method, are employed to transfer users' home-town preference and estimate out-of-town POI's representation, respectively. Extensive experiments on real-world data sets validate the effectiveness of the TRAINOR framework. Moreover, the learned travel intention can deliver meaningful explanations for understanding a user's travel purposes.
C1 [Xin, Haoran; Xu, Tong] Univ Sci & Technol China, Hefei, Peoples R China.
   [Xin, Haoran; Lu, Xinjiang; Liu, Hao; Dou, Dejing] Baidu Res, Business Intelligence Lab, Beijing, Peoples R China.
   [Lu, Xinjiang; Liu, Hao; Dou, Dejing] Natl Engn Lab Deep Learning Technol & Applicat, Beijing, Peoples R China.
   [Gu, Jingjing] Nanjing Univ Aeronaut & Astronaut, Nanjing, Peoples R China.
   [Xiong, Hui] Rutgers State Univ, New Brunswick, NJ USA.
C3 Chinese Academy of Sciences; University of Science & Technology of China, CAS; Baidu; Nanjing University of Aeronautics & Astronautics; Rutgers State University New Brunswick
RP Lu, XJ (corresponding author), Baidu Res, Business Intelligence Lab, Beijing, Peoples R China.; Lu, XJ (corresponding author), Natl Engn Lab Deep Learning Technol & Applicat, Beijing, Peoples R China.
EM xinhaoran@mail.ustc.edu.cn; luxinjiang@baidu.com; tongxu@ustc.edu.cn; liuhao30@baidu.com; gujingjing@nuaa.edu.cn; doudejing@baidu.com; hxiong@rutgers.edu
FU NSFC [71531001, 61725205, 91746301, 61703386]
CR Alvarez, 2018, ARXIV PREPRINT ARXIV, V0, P0
   Brilhante I, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, PP757, DOI 10.1145/2505515.2505643
   Cho K., 2014, PROC 8 WORKSHOP SYNT, V0, PP103, DOI 10.3115/V1/W14-4012
   Ference G, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM13), V0, PP721, DOI 10.1145/2505515.2505637
   GENG X, 2019, AAAI 19, V0, P3656
   Hidasi B., 2015, INT C LEARN REPR, V0, P0
   Hu G, 2017, SIGIR17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, V0, PP893, DOI 10.1145/3077136.3080672
   Kingma D. P., 2013, ARXIV13126114, V0, P0
   Kipf T. N., 2016, ARXIV, V0, P0
   Li Y, 2015, ARXIV, V0, P0
   LIU Q, 2011, ICDM 11, V0, P0
   Luo H, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR 20), V0, PP781, DOI 10.1145/3397271.3401090
   Man T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P2464
   Miao YS, 2017, PR MACH LEARN RES, V70, P0
   Miao YS, 2016, PR MACH LEARN RES, V48, P0
   PENG WJ, 2020, KDD 20, V0, P0
   Rendle Steffen, 2009, PROC 25 C UNCERTAINT, V0, P452
   Shen DZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, V0, P3542
   Srivastava A., 2017, ARXIV170301488, V0, P1
   Pham TAN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP401, DOI 10.1145/3038912.3052667
   WANG H, 2017, SIGKDD 17, V0, PP1135, DOI 10.1145/3097983.3098122
   Wang J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), V0, PP1401, DOI 10.1145/3184558.3191583
   WEI PH, 2019, SIGIR 19, V0, PP1173, DOI 10.1145/3331184.3331367
   Wu S, 2019, AAAI CONF ARTIF INTE, V0, P346
   Xu T., 2017, ARXIV PREPRINT ARTIC, V0, P0
   Yin HZ, 2016, ACM T INFORM SYST, V35, P0, DOI 10.1145/2873055
   Yin HZ, 2014, ACM T INFORM SYST, V32, P0, DOI 10.1145/2629461
   Zhang WJ, 2020, AAAI CONF ARTIF INTE, V34, P1186
   ZHOU X, 2019, SIGKDD 17, V0, PP3018, DOI 10.1145/3292500.3330781
NR 29
TC 6
Z9 6
U1 3
U2 5
PU ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE
PI PALO ALTO
PA 2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA
SN 2159-5399
EI 2374-3468
J9 AAAI CONF ARTIF INTE
PD JUN 15
PY 2021
VL 35
IS 
BP 4529
EP 4536
DI 
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Education, Scientific Disciplines
SC Computer Science; Education & Educational Research
GA BR9ZM
UT WOS:000680423504073
DA 2023-04-26
ER

PT J
AU Hafeez, A
   Shah, M
   Ehsan, M
   Jamjareegulgarn, P
   Ahmed, J
   Tariq, MA
   Iqbal, S
   Naqvi, NA
AF Hafeez, Amna
   Shah, Munawar
   Ehsan, Muhsan
   Jamjareegulgarn, Punyawi
   Ahmed, Junaid
   Tariq, M. Arslan
   Iqbal, Shahid
   Naqvi, Najam Abbas
TI Possible Atmosphere and Ionospheric Anomalies of the 2019 Pakistan Earthquake Using Statistical and Machine Learning Procedures on MODIS LST, GPS TEC, and GIM TEC
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE MODIS; Global Positioning System; Satellites; Terrestrial atmosphere; Land surface temperature; Ionosphere; Electric shock; Earthquake; global ionospheric map (GIM) total electron content (TEC); Global Positioning System (GPS) TEC; lithosphere-atmosphere-ionosphere coupling; moderate resolution imaging spectroradiometer (MODIS) land surface temperature (LST)
ID temperature; precursors
AB Identifying atmospheric and ionospheric anomalies based on remote sensing satellites has contributed highly to develop the hypothesis of lithosphere-atmosphere-ionosphere coupling over the earthquake (EQ) epicenter during the seismic preparation period. This article has investigated the variations of potential EQ precursor in daytime and nighttime land surface temperature (LST) before and after the 2019 Pakistan EQ from Moderate Resolution Imaging Spectroradiometer (MODIS) satellite. The nighttime LST values of MODIS exhibit temporal anomalies during nighttime period within a time window of five days before and after the main shock day. Furthermore, the LST values predicted by artificial neural network (ANN) validate the significant enhancement in nighttime time series of MODIS. The nighttime LST anomalies obtained from the observation and ANN prediction are more than 20% and 7% of normal distribution beyond the confidence bounds, respectively, within five days after the main shock. Likewise, the ionospheric anomaly from daily total electron content (TEC) values at Sukkur Global Positioning System (GPS) station confirms the EQ associated ionospheric perturbations on the day after the main shock. The Global Ionospheric Maps (GIMs) also show the TEC anomalies during 1000-1400 LT on September 25, 2019.
C1 [Hafeez, Amna; Shah, Munawar; Naqvi, Najam Abbas] GNSS Lab Natl Ctr GIS & Space Applicat, Inst Space Technol, Dept Space Sci Space Educ, Islamabad 44000, Pakistan.
   [Ehsan, Muhsan] Bahria Univ, Dept Earth & Environm Sci, Islamabad 44000, Pakistan.
   [Jamjareegulgarn, Punyawi] King Mongkuts Inst Technol Ladkrabang, Prince Chumphon Campus, Chumphon 86160, Thailand.
   [Ahmed, Junaid; Tariq, M. Arslan] Natl Ctr Phys, Ctr Earthquake Studies, Islamabad 44000, Pakistan.
   [Iqbal, Shahid] Quaid i Azam Univ, Dept Earth Sci, Islamabad 15320, Pakistan.
C3 King Mongkuts Institute of Technology Ladkrabang; National Centre for Physics - Pakistan; Quaid I Azam University
RP Jamjareegulgarn, P (corresponding author), King Mongkuts Inst Technol Ladkrabang, Prince Chumphon Campus, Chumphon 86160, Thailand.
EM amnahafeez016@gmail.com; shahmunawar1@gmail.com; muhsanehsan98@hotmail.com; kjpunyaw@gmail.com; junaid.ahmed@ncp.edu.pk; arslan@ncp.edu.pk; shahid_lefty@hotmail.com; najam.naqvi@ist.edu.pk
CR Bellaoui M, 2017, ADV SPACE RES, V59, P2645, DOI 10.1016/j.asr.2017.03.004
   DOBROVOLSKY IP, 1979, PURE APPL GEOPHYS, V117, P1025, DOI 10.1007/BF00876083
   Dunajecka MA, 2005, ATMOSFERA, V18, P235
   Freund F., 2017, EUR PHYS J, V230, P1
   Freund FT, 2009, J ATMOS SOL-TERR PHY, V71, P1824, DOI 10.1016/j.jastp.2009.07.013
   Hulley GC, 2019, TAKING THE TEMPERATURE OF THE EARTH: STEPS TOWARDS INTEGRATED UNDERSTANDING OF VARIABILITY AND CHANGE, V0, PP57, DOI 10.1016/B978-0-12-814458-9.00003-4
   Inyurt S, 2019, ANN GEOPHYS-GERMANY, V37, P143, DOI 10.5194/angeo-37-143-2019
   Khan MR, 2016, J EARTH SCI-CHINA, V27, P981, DOI 10.1007/s12583-016-0681-9
   Khan SA, 2018, EARTHQ ENG ENG VIB, V17, P787, DOI 10.1007/s11803-018-0476-3
   [马瑾 Ma Jin], 2010, 地学前缘 EARTH SCIENCE FRONTIERS, V17, P1
   Mohamed EK, 2021, J ATMOS SOL-TERR PHY, V216, P0, DOI 10.1016/j.jastp.2021.105595
   Muster S, 2015, REMOTE SENS ENVIRON, V168, P1, DOI 10.1016/j.rse.2015.06.017
   Ouzounov D., 2004, P 35 COSPAR SCI ASS, V0, P0
   Pulinets S, 2011, J ASIAN EARTH SCI, V41, P371, DOI 10.1016/j.jseaes.2010.03.005
   Pulinets SA, 2006, ANN GEOPHYS-GERMANY, V24, P835, DOI 10.5194/angeo-24-835-2006
   Pulinets SA, 2009, ADV SPACE RES, V44, P767, DOI 10.1016/j.asr.2009.04.038
   Saraf AK, 2008, NAT HAZARDS, V47, P119, DOI 10.1007/s11069-007-9201-7
   Sekertekin A, 2020, J ATMOS SOL-TERR PHY, V200, P0, DOI 10.1016/j.jastp.2020.105218
   Shah M, 2021, J ATMOS SOL-TERR PHY, V215, P0, DOI 10.1016/j.jastp.2021.105568
   Shah M, 2020, ACTA ASTRONAUT, V175, P268, DOI 10.1016/j.actaastro.2020.06.005
   Tronin AA, 2002, J GEODYN, V33, P519, DOI 10.1016/S0264-3707(02)00013-3
   Tronin AA, 2010, REMOTE SENS-BASEL, V2, P124, DOI 10.3390/rs2010124
   Ulukavak M, 2020, ACTA ASTRONAUT, V166, P123, DOI 10.1016/j.actaastro.2019.09.033
   Wan Z., 2015, MOD11A1 MODIS TERRA, V0, P0, DOI DOI 10.5067/MODIS/MOD11A1.006
   Wan ZM, 1997, IEEE T GEOSCI REMOTE, V35, P980, DOI 10.1109/36.602541
   Zhao W, 2020, REMOTE SENS ENVIRON, V247, P0, DOI 10.1016/j.rse.2020.111931
   Zhao W, 2019, REMOTE SENS ENVIRON, V221, P635, DOI 10.1016/j.rse.2018.12.008
NR 27
TC 6
Z9 6
U1 1
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 11126
EP 11133
DI 10.1109/JSTARS.2021.3119382
PG 8
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WW2RC
UT WOS:000717769500003
DA 2023-04-26
ER

PT J
AU Petrovich, E
AF Petrovich, Eugenio
TI Science Mapping and Science Maps
SO KNOWLEDGE ORGANIZATION
LA English
DT Article
DE science mapping; science maps; visualization; visualization methods
ID neural-network research; citation counts measure; author cocitation; scientific literature; software tools; knowledge; humanity; patterns; history; system
AB Science maps are visual representations of the structure and dynamics of scholarly knowledge. They aim to show how fields, disciplines, journals, scientists, publications, and scientific terms relate to each other. Science mapping is the body of methods and techniques that have been developed for generating science maps. This entry is an introduction to science maps and science mapping. It focuses on the conceptual, theoretical, and methodological issues of science mapping, rather than on the mathematical formulation of science mapping techniques. After a brief history of science mapping, we describe the general procedure for building a science map, presenting the data sources and the methods to select, clean, and pre-process the data. Next, we examine in detail how the most common types of science maps, namely the citation-based and the term-based, are generated. Both are based on networks: the former on the network of publications connected by citations, the latter on the network of terms co-occurring in publications. We review the rationale behind these mapping approaches, as well as the techniques and methods to build the maps (from the extraction of the network to the visualization and enrichment of the map). We also present less-common types of science maps, including co-authorship networks, interlocking editorship networks, maps based on patents' data, and geographic maps of science. Moreover, we consider how time can be represented in science maps to investigate the dynamics of science. We also discuss some epistemological and sociological topics that can help in the interpretation, contextualization, and assessment of science maps. Then, we present some possible applications of science maps in science policy. In the conclusion, we point out why science mapping may be interesting for all the branches of meta-science, from knowledge organization to epistemology.
C1 [Petrovich, Eugenio] Dept Econ & Stat, Piazza San Francesco 7-8, I-53100 Siena, Italy.
RP Petrovich, E (corresponding author), Dept Econ & Stat, Piazza San Francesco 7-8, I-53100 Siena, Italy.
EM eugenio.petrovich@unisi.it
FU Institute for New Economic Thinking (INET) [INO19-00023]
CR Ahlgren P, 2003, J AM SOC INF SCI TEC, V54, P550, DOI 10.1002/asi.10242
   Aksnes DW, 2019, SAGE OPEN, V9, P0, DOI 10.1177/2158244019829575
   AMSTERDAMSKA O, 1989, SCIENTOMETRICS, V15, P449, DOI 10.1007/BF02017065
   [Anonymous], 2014, LINKED EVERYTHING IS, V0, P0
   [Anonymous], 2003, PUTTING SCI ITS PLAC, V0, P0
   [Anonymous], 2002, PATENTS CITATIONS IN, V0, P0, DOI DOI 10.7551/MITPRESS/5263.001.0001
   [Anonymous], 1972, INVISIBLE COLL DIFFU, V0, P0
   Astrom F, 2017, INFORM RES, V22, P0
   Baccini A, 2020, QUANT SCI STUD, V1, P277, DOI 10.1162/qss_a_00006
   Baccini A, 2010, SCIENTOMETRICS, V82, P365, DOI 10.1007/s11192-009-0053-7
   Bazerman C., 1988, SHAPING WRITTEN KNOW, V0, P0
   Bloor D, 1991, KNOWLEDGE SOCIAL IMA, V0, P0
   Borner K, 2012, PLOS ONE, V7, P0, DOI 10.1371/journal.pone.0039464
   Borg I., 2005, MODERN MULTIDIMENSIO, V0, P0
   Borner Katy, 2015, BULLETIN OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY, V41, P12
   Borner K, 2003, ANNU REV INFORM SCI, V37, P179, DOI 10.1002/aris.1440370106
   Borner K., 2010, ATLAS SCI VISUALIZIN, V0, P0
   Borner K, 2006, SCIENTOMETRICS, V68, P415, DOI 10.1007/s11192-006-0120-2
   Bornmann L, 2008, J DOC, V64, P45, DOI 10.1108/00220410810844150
   Boyack KW, 2008, J INFORMETR, V2, P173, DOI 10.1016/j.joi.2008.03.001
   Boyack KW, 2019, SPRINGER HBK, V0, PP187, DOI 10.1007/978-3-030-02511-3_8
   Boyack KW, 2010, J AM SOC INF SCI TEC, V61, P2389, DOI 10.1002/asi.21419
   Boyack KW, 2005, SCIENTOMETRICS, V64, P351, DOI 10.1007/s11192-005-0255-6
   Buonomo V, 2018, PHILOS INQ, V6, P149
   CALLON M, 1983, SOC SCI INFORM, V22, P191, DOI 10.1177/053901883022002003
   CALLON M, 1991, SCIENTOMETRICS, V22, P155, DOI 10.1007/BF02019280
   Callon M., 1998, MAPPING DYNAMICS SCI, V0, P0
   Catherine H, 2018, J ECON METHODOL, V25, P311, DOI 10.1080/1350178X.2018.1529172
   Chen C., 2013, MAPPING SCI FRONTIER, V0, P0
   Chen CM, 2017, J DATA INFO SCI, V2, P1, DOI 10.1515/jdis-2017-0006
   Chen CM, 2010, J AM SOC INF SCI TEC, V61, P1386, DOI 10.1002/asi.21309
   Chen CM, 2006, J AM SOC INF SCI TEC, V57, P359, DOI 10.1002/asi.20317
   Cherrier B, 2017, J ECON LIT, V55, P545, DOI 10.1257/jel.20151296
   Cobo MJ, 2011, J AM SOC INF SCI TEC, V62, P1382, DOI 10.1002/asi.21525
   Cobo MJ, 2011, J INFORMETR, V5, P146, DOI 10.1016/j.joi.2010.10.002
   Courtial JP, 1998, J AM SOC INFORM SCI, V49, P98, DOI 10.1002/(SICI)1097-4571(199801)49:1<98::AID-ASI14>3.3.CO;2-T
   COZZENS SE, 1989, SCIENTOMETRICS, V15, P437, DOI 10.1007/BF02017064
   CRANE D, 1967, AM SOCIOL, V2, P195
   Cronin B, 2001, J AM SOC INF SCI TEC, V52, P558, DOI 10.1002/asi.1097
   Cronin B., 1984, CITATION PROCESS ROL, V0, P0
   Daston Lorraine, 2007, OBJECTIVITY, V0, P0
   Elkana Y., 1978, METRIC SCI ADVENT SC, V0, P0
   Federico P, 2017, IEEE T VIS COMPUT GR, V23, P2179, DOI 10.1109/TVCG.2016.2610422
   Finnegan Diarmid, 2015, INT ENCY SOCIAL BEHA, V21, P236
   Franssen T, 2019, J ASSOC INF SCI TECH, V70, P1124, DOI 10.1002/asi.24206
   Frenken K, 2009, J INFORMETR, V3, P222, DOI 10.1016/j.joi.2009.03.005
   Garfield E, 2004, J INF SCI, V30, P119, DOI 10.1177/0165551504042802
   Garfield Eugene, 1973, THEORY LIBRARIANSHIP, V0, P380
   Gates AJ, 2019, NATURE, V575, P32, DOI 10.1038/d41586-019-03308-7
   Glanzel W, 2001, SCIENTOMETRICS, V51, P69, DOI 10.1023/A:1010512628145
   Gross AG, 2002, COMMUNICATING SCI SC, V0, P0
   Hammarfelt Bjorn, 2017, BULLETIN OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY, V43, P33, DOI 10.1002/bul2.2017.1720430508
   Hammarfelt B, 2016, RESEARCH ASSESSMENT IN THE HUMANITIES: TOWARDS CRITERIA AND PROCEDURES, V0, PP115, DOI 10.1007/978-3-319-29016-4_10
   Harzing AW, 2019, SCIENTOMETRICS, V120, P341, DOI 10.1007/s11192-019-03114-y
   He Q, 1999, LIBR TRENDS, V48, P133
   Hellqvist B, 2010, J AM SOC INF SCI TEC, V61, P310, DOI 10.1002/asi.21256
   Hennig C., 2015, HDB CLUSTER ANAL, V0, PP1, DOI 10.1201/B19706
   Hjorland B, 2013, INFORM PROCESS MANAG, V49, P1313, DOI 10.1016/j.ipm.2013.07.001
   Hyland K, 2008, ANNU REV INFORM SCI, V42, P297
   International Committee of Medical Journal Editors (ICMJE), 2019, REC COND REP ED PUBL, V0, P0
   JONES WP, 1987, J AM SOC INFORM SCI, V38, P420, DOI 10.1002/(SICI)1097-4571(198711)38:6<420::AID-ASI3>3.0.CO;2-S
   KAPLAN N, 1965, AM DOC, V16, P179, DOI 10.1002/asi.5090160305
   Katz JS, 1997, RES POLICY, V26, P1, DOI 10.1016/S0048-7333(96)00917-1
   KESSLER MM, 1963, INFORM STORAGE RET, V1, P169, DOI 10.1016/0020-0271(63)90016-0
   KNORRCETINA K, 1999, EPISTEMIC CULTURES S, V0, P0
   Kreuzman H, 2001, SCIENTOMETRICS, V51, P525, DOI 10.1023/A:1019647103469
   KUHN T, 2000, ROAD SINCE STRUCTURE, V0, P0
   Lariviere V, 2016, SOC STUD SCI, V46, P417, DOI 10.1177/0306312716650046
   Latour B., 1986, LAB LIFE CONSTRUCTIO, V0, P0
   Latour B., 1987, SCI ACTION FOLLOW SC, V0, P0
   Laudel G, 2002, RES EVALUAT, V11, P3, DOI 10.3152/147154402781776961
   Laurens P, 2010, SCIENTOMETRICS, V82, P647, DOI 10.1007/s11192-010-0177-9
   LAW J, 1992, SCIENTOMETRICS, V23, P417, DOI 10.1007/BF02029807
   Lee S, 2009, TECHNOVATION, V29, P481, DOI 10.1016/j.technovation.2008.10.006
   Leydesdorff L, 2004, J DOC, V60, P371, DOI 10.1108/00220410410548144
   LEYDESDORFF L, 1987, SCIENTOMETRICS, V11, P295, DOI 10.1007/BF02279351
   Leydesdorff L, 1997, J AM SOC INFORM SCI, V48, P418
   Leydesdorff L., 2001, CHALLENGE SCIENTOMET, V0, P0
   Leydesdorff L, 2008, J AM SOC INF SCI TEC, V59, P1810, DOI 10.1002/asi.20891
   Leydesdorff L, 2008, J AM SOC INF SCI TEC, V59, P77, DOI 10.1002/asi.20732
   Leydesdorff L, 2007, J AM SOC INF SCI TEC, V58, P1303, DOI 10.1002/asi.20614
   Leydesdorff L, 2014, J ASSOC INF SCI TECH, V65, P164, DOI 10.1002/asi.22953
   Leydesdorff L, 2010, J AM SOC INF SCI TEC, V61, P1622, DOI 10.1002/asi.21347
   Leydesdorff L, 2009, J AM SOC INF SCI TEC, V60, P348, DOI 10.1002/asi.20967
   Lima Manuel, 2014, BOOK TREES VISUALIZI, V0, P0
   Liu XM, 2005, INFORM PROCESS MANAG, V41, P1462, DOI 10.1016/j.ipm.2005.03.012
   Lucio-Arias D, 2009, J INFORMETR, V3, P261, DOI 10.1016/j.joi.2009.03.003
   MacRoberts MH, 2018, J ASSOC INF SCI TECH, V69, P474, DOI 10.1002/asi.23970
   MARSHAKOVA IV, 1973, NAUCH-TEKHN INFORM 2, V0, P3
   Matthiessen CW, 2002, URBAN STUD, V39, P903, DOI 10.1080/00420980220128372
   Mazzocchi F, 2018, KNOWL ORGAN, V45, P54, DOI 10.5771/0943-7444-2018-1-54
   MCCAIN KW, 1991, J AM SOC INFORM SCI, V42, P290, DOI 10.1002/(SICI)1097-4571(199105)42:4<290::AID-ASI5>3.0.CO;2-9
   MCCAIN KW, 1990, J AM SOC INFORM SCI, V41, P433, DOI 10.1002/(SICI)1097-4571(199009)41:6<433::AID-ASI11>3.0.CO;2-Q
   Merton R. K., 1973, SOCIOLOGY SCI THEORE, V0, P0
   Meyer M, 2000, RES POLICY, V29, P409, DOI 10.1016/S0048-7333(99)00040-2
   Moral-Munoz JA, 2019, SPRINGER HBK, V0, PP159, DOI 10.1007/978-3-030-02511-3_7
   Murray F, 2002, RES POLICY, V31, P1389, DOI 10.1016/S0048-7333(02)00070-7
   Mutschke P, 2001, SCIENTOMETRICS, V52, P487, DOI 10.1023/A:1014256102041
   Nederhof AJ, 2006, SCIENTOMETRICS, V66, P81, DOI 10.1007/s11192-006-0007-2
   Newman MEJ, 2001, PHYS REV E, V64, P0, DOI 10.1103/PhysRevE.64.016132
   Nicolaisen J, 2007, ANNU REV INFORM SCI, V41, P609, DOI 10.1002/aris.2007.1440410120
   Noyons ECM, 2009, SCIENTOMETRICS, V79, P261, DOI 10.1007/s11192-009-0417-z
   Pan XL, 2018, J INFORMETR, V12, P481, DOI 10.1016/j.joi.2018.03.005
   PERSSON O, 1994, J AM SOC INFORM SCI, V45, P31, DOI 10.1002/(SICI)1097-4571(199401)45:1<31::AID-ASI4>3.0.CO;2-G
   Petrovich E, 2018, SCIENTOMETRICS, V116, P1123, DOI 10.1007/s11192-018-2796-5
   Petrovich Eugenio, 2019, THESIS U MILAN, V0, P0
   Petrovich Eugenio, 2019, J INTERD HIST IDEAS, V8, P1, DOI 10.13135/2280-8574/4304
   Petrovich Eugenio, 2019, STOREP 2019, V0, P0
   PRICE DJD, 1965, SCIENCE, V149, P510
   Radicchi F., 2012, MODELS SCI DYNAMICS, V0, P0
   Radicchi F, 2009, PHYS REV E, V80, P0, DOI 10.1103/PhysRevE.80.056103
   Rafols I, 2010, J AM SOC INF SCI TEC, V61, P1871, DOI 10.1002/asi.21368
   Ranaei S, 2019, SPRINGER HBK, V0, PP957, DOI 10.1007/978-3-030-02511-3_39
   Reiss J., 2020, STANFORD ENCY PHILOS, V0, P0
   Rosvall M, 2010, PLOS ONE, V5, P0, DOI 10.1371/journal.pone.0008694
   Salton G., 1983, INTRO MODERN INFORM, V0, P0
   Scharnhorst Andrea, 2012, MODELS SCI DYNAMICS, V0, P0
   Skupin A, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0058779
   SMALL H, 1973, J AM SOC INFORM SCI, V24, P265, DOI 10.1002/asi.4630240406
   SMALL H, 1974, SCI STUD, V4, P17, DOI 10.1177/030631277400400102
   Small H, 1999, J AM SOC INFORM SCI, V50, P799, DOI 10.1002/(SICI)1097-4571(1999)50:9<799::AID-ASI9>3.0.CO;2-G
   SMALL HG, 1977, SOC STUD SCI, V7, P139, DOI 10.1177/030631277700700202
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Strotmann A, 2012, J AM SOC INF SCI TEC, V63, P1820, DOI 10.1002/asi.22695
   Sugimoto CR, 2015, J DOC, V71, P775, DOI 10.1108/JD-06-2014-0082
   Swales J.M., 2004, RES GENRES, V0, P0
   Tahamtan I, 2019, SCIENTOMETRICS, V121, P1635, DOI 10.1007/s11192-019-03243-4
   Tahamtan I, 2018, J INFORMETR, V12, P203, DOI 10.1016/j.joi.2018.01.002
   Taheo Jo., 2018, STUDIES BIG DATA, V45, P0
   Thijs B, 2019, SPRINGER HBK, V0, PP213, DOI 10.1007/978-3-030-02511-3_9
   TIJSSEN RJW, 1993, SCIENTOMETRICS, V28, P111, DOI 10.1007/BF02016288
   Townsend Keith, 2009, METHOD MADNESS RES S, V0, P0
   Tseng YH, 2007, INFORM PROCESS MANAG, V43, P1216, DOI 10.1016/j.ipm.2006.11.011
   Van Eck N.J., 2014, MEASURING SCHOLARLY, P285, DOI [DOI 10.1007/978, 1900, DOI 10.1007/978-3-319-10377-8_13.78G 10.1007/978-3-319-10377-8_13(INENG.) DOI 10.1007/978-3-319-10377-8_13, V0, P0
   van Eck NJ, 2008, J AM SOC INF SCI TEC, V59, P1653, DOI 10.1002/asi.20872
   van Eck NJ, 2010, J AM SOC INF SCI TEC, V61, P2405, DOI 10.1002/asi.21421
   van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3
   van Eck NJ, 2009, J AM SOC INF SCI TEC, V60, P1635, DOI 10.1002/asi.21075
   Van Raan AFJ, 1998, SCIENTOMETRICS, V43, P129, DOI 10.1007/BF02458401
   van Raan A, 2019, SPRINGER HBK, V0, PP237, DOI 10.1007/978-3-030-02511-3_10
   VANRAAN AFJ, 1993, SCIENTOMETRICS, V26, P169, DOI 10.1007/BF02016799
   Visser M, 2020, ARXIV, V0, P0, DOI DOI 10.48550/arXiv.2005.10732
   von Wartburg I, 2005, RES POLICY, V34, P1591, DOI 10.1016/j.respol.2005.08.001
   Waltman L, 2012, J AM SOC INF SCI TEC, V63, P2378, DOI 10.1002/asi.22748
   Waltman L, 2010, J INFORMETR, V4, P629, DOI 10.1016/j.joi.2010.07.002
   Weingart SB, 2015, ERKENNTNIS, V80, P201, DOI 10.1007/s10670-014-9621-1
   WHITE HD, 1981, J AM SOC INFORM SCI, V32, P163, DOI 10.1002/asi.4630320302
   White HD, 1998, J AM SOC INFORM SCI, V49, P327, DOI 10.1002/(SICI)1097-4571(19980401)49:4<327::AID-ASI4>3.0.CO;2-W
   Wislar JS, 2011, BRIT MED J, V343, P0, DOI 10.1136/bmj.d6128
   Wolfe AW, 1997, AM ETHNOL, V24, P219, DOI 10.1525/ae.1997.24.1.219
   Wouters P, 1999, SCIENTOMETRICS, V44, P561, DOI 10.1007/BF02458496
   Wouters Paul, 1999, THESIS U AMSTERDAM, V0, P0
   Zhao Dangzhi, 2009, P AM SOC INFORM SCI, V46, P1, DOI 10.1002/meet.2009
   Zhou QJ, 2016, J ASSOC INF SCI TECH, V67, P2805, DOI 10.1002/asi.23603
   Zitt M, 2006, INFORM PROCESS MANAG, V42, P1513, DOI 10.1016/j.ipm.2006.03.016
   Zitt M, 2019, SPRINGER HBK, V0, PP25, DOI 10.1007/978-3-030-02511-3_2
NR 156
TC 1
Z9 1
U1 13
U2 18
PU NOMOS VERLAGSGESELLSCHAFT MBH & CO KG
PI BADEN-BADEN
PA WALDSEESTR 3 5, BADEN-BADEN, 76530, GERMANY
SN 0943-7444
EI 
J9 KNOWL ORGAN
JI Knowl. Organ.
PD JUN 15
PY 2021
VL 48
IS 7-8
BP 535
EP 562
DI 10.5771/0943-7444-7-8-535
PG 28
WC Information Science & Library Science
SC Information Science & Library Science
GA 3M8JS
UT WOS:000835703300002
DA 2023-04-26
ER

PT J
AU Su, ZY
   Chow, JK
   Tan, PS
   Wu, J
   Ho, YK
   Wang, YH
AF Su, Zhaoyu
   Chow, Jun Kang
   Tan, Pin Siang
   Wu, Jimmy
   Ho, Ying Kit
   Wang, Yu-Hsing
TI Deep convolutional neural network-based pixel-wise landslide inventory mapping
SO LANDSLIDES
LA English
DT Article
DE Landslide inventory map; Deep convolutional neural network; On-the-fly data augmentation; Data fusion
ID classification; hazard; imagery; multiresolution; susceptibility; earthquake; lidar
AB This paper reports a feasible alternative to compile a landslide inventory map (LIM) from remote sensing datasets using the application of an artificial intelligence-driven methodology. A deep convolutional neural network model, called LanDCNN, was developed to generate segmentation maps of landslides, and its performance was compared with the benchmark model, named U-Net, and other conventional object-based methods. The landslides that occurred in Lantau Island, Hong Kong, were taken as the case study, in which the pre- and post-landslide aerial images, and a rasterized digital terrain model (DTM) were used. The assessment reveals that LanDCNN trained with bitemporal images and DTM yields the smoothest and most semantically meaningfully LIM, compared to other methods. This LIM is the most balanced segmentation results, represented by the highest F-1 measure among all analyzed cases. With the encoding capability of LanDCNN, the application of DTM as the input renders better LIM production, especially when the landslide signatures are relatively subtle. With the computational setup used in this study, LanDCNN requires similar to 3 min to map landslides from the datasets of approximately 25 km(2) in area and with a resolution of 0.5 m. In short, the proposed landslide mapping framework, featured LanDCNN, is scalable to handle the vast amount of remote sensing data from different types of measurements within a short processing period.
C1 [Su, Zhaoyu; Chow, Jun Kang; Tan, Pin Siang; Wu, Jimmy; Wang, Yu-Hsing] Hong Kong Univ Sci & Technol, Dept Civil & Environm Engn, Hong Kong, Peoples R China.
   [Ho, Ying Kit] Dev Bur, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Wang, YH (corresponding author), Hong Kong Univ Sci & Technol, Dept Civil & Environm Engn, Hong Kong, Peoples R China.
EM zsuad@connect.ust.hk; junkangchow@ust.hk; pstan@connect.ust.hk; jwuah@connect.ust.hk; tonyykho@cedd.gov.hk; ceyhwang@ust.hk
FU Hong Kong Research Grants Council [T22-603/15N]; Hong Kong PhD Fellowship Scheme; Geotechnical Engineering Office, Civil Engineering and Development Department and Lands Department of HKSAR
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI 10.1145/3022670.2976746
   Aleotti P., 1999, B ENG GEOL ENVIRON, V58, P21, DOI 10.1007/s100640050066
   Amit SNKB, 2016, INT GEOSCI REMOTE SE, V0, PP5189, DOI 10.1109/IGARSS.2016.7730352
   Antonini G., 2002, B SOC GEOL ITAL, V121, P843
   Ardizzone F, 2007, NAT HAZARD EARTH SYS, V7, P637, DOI 10.5194/nhess-7-637-2007
   Ardizzone F, 2002, NAT HAZARD EARTH SYS, V2, P3, DOI 10.5194/nhess-2-3-2002
   Atkinson PM, 1998, COMPUT GEOSCI-UK, V24, P373, DOI 10.1016/S0098-3004(97)00117-9
   Behling R, 2016, REMOTE SENS ENVIRON, V186, P88, DOI 10.1016/j.rse.2016.07.017
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Blaschke T., 2000, ENV INFORM PLANNING, VVolume 2, P555
   Blaschke T., 2001, GEOBITGIS, V14, P12
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Burnett C, 2003, ECOL MODEL, V168, P233, DOI 10.1016/S0304-3800(03)00139-X
   Cai KH, 2012, INT CONF SIGN PROCES, V0, PP993, DOI 10.1109/ICoSP.2012.6491746
   Can R, 2019, ISPRS INT J GEO-INF, V8, P0, DOI 10.3390/ijgi8070300
   Cardinali M, 1990, PRELIMINARY MAP SHOW, V0, P0
   Chen, 2012, ADV NEURAL INFORM PR, V0, PP341, DOI 10.5555/2999134.2999173
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen T, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040333
   Chen XY, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), V0, PP181, DOI 10.1109/ACPR.2013.33
   CHEN Z, 2018, SENSORS BASEL, V18, P0
   Cheng G, 2013, INT J REMOTE SENS, V34, P45, DOI 10.1080/01431161.2012.705443
   Cheng KS, 2004, ADV SPACE RES-SERIES, V33, P296, DOI 10.1016/S0273-1177(03)00471-X
   Choi KY, 2013, J ROCK MECH GEOTECH, V5, P354, DOI 10.1016/j.jrmge.2013.07.007
   Dai FC, 2002, ENG GEOL, V64, P65, DOI 10.1016/S0013-7952(01)00093-X
   Derron MH, 2010, NAT HAZARD EARTH SYS, V10, P1877, DOI 10.5194/nhess-10-1877-2010
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), V0, PP444, DOI 10.1109/YAC.2016.7804935
   Duric D, 2017, LANDSLIDES, V14, P1467, DOI 10.1007/s10346-017-0847-2
   Flanders D, 2003, CAN J REMOTE SENS, V29, P441, DOI 10.5589/m03-006
   Galli M, 2008, GEOMORPHOLOGY, V94, P268, DOI 10.1016/j.geomorph.2006.09.023
   GERON A, 2019, HANDS MACHINE LEARNI, V0, P0
   GHORBANZADEH O, 2019, REMOTE SENS BASEL, V11, P0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Haneberg WC, 2009, B ENG GEOL ENVIRON, V68, P263, DOI 10.1007/s10064-009-0204-3
   Hay GJ, 2003, ISPRS J PHOTOGRAMM, V57, P327, DOI 10.1016/S0924-2716(02)00162-4
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Hervis J, 2009, LANDSLIDES - DISASTER RISK REDUCTION, V0, PP321, DOI 10.1007/978-3-540-69970-5_19
   Holbling D, 2015, EARTH SCI INFORM, V8, P327, DOI 10.1007/s12145-015-0217-3
   Huang FM, 2020, LANDSLIDES, V17, P217, DOI 10.1007/s10346-019-01274-9
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Hungr O, 2014, LANDSLIDES, V11, P167, DOI 10.1007/s10346-013-0436-y
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Konecny J, 2016, IEEE J-STSP, V10, P242, DOI 10.1109/JSTSP.2015.2505682
   Lee CF, 2017, ADVANCING CULTURE OF LIVING WITH LANDSLIDES, VOL 2: ADVANCES IN LANDSLIDE SCIENCE, P767, DOI 10.1007/978-3-319-53498-5_88
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Liu Y, 2018, PROCEDIA COMPUT SCI, V139, P529, DOI 10.1016/j.procs.2018.10.237
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Liu YX, 2006, CHINESE GEOGR SCI, V16, P282, DOI 10.1007/s11769-006-0282-0
   Lu P, 2011, IEEE GEOSCI REMOTE S, V8, P701, DOI 10.1109/LGRS.2010.2101045
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Martha TR, 2012, ISPRS J PHOTOGRAMM, V67, P105, DOI 10.1016/j.isprsjprs.2011.11.004
   Martha TR, 2010, GEOMORPHOLOGY, V116, P24, DOI 10.1016/j.geomorph.2009.10.004
   Milletari F, 2016, INT CONF 3D VISION, V0, PP565, DOI 10.1109/3DV.2016.79
   Nichol JE, 2006, GEOMORPHOLOGY, V76, P68, DOI 10.1016/j.geomorph.2005.10.001
   Otukei JR, 2010, INT J APPL EARTH OBS, V12, PS27, DOI 10.1016/j.jag.2009.11.002
   Paek J, 1975, B INT ASS ENG GEOL, V12, P73
   Parker RN, 2011, NAT GEOSCI, V4, P449, DOI 10.1038/ngeo1154
   Rau JY, 2014, IEEE T GEOSCI REMOTE, V52, P1336, DOI 10.1109/TGRS.2013.2250293
   Razak KA, 2011, GEOMORPHOLOGY, V126, P186, DOI 10.1016/j.geomorph.2010.11.003
   Rib HT, 1978, LANDSLIDE ANAL CONTR, V0, P64
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schiewe J., 2002, INT ARCH PHOTOGRAMME, V34, P380
   SPEIGHT JG, 1977, PHOTOGRAMMETRIA, V32, P161, DOI 10.1016/0031-8663(77)90012-6
   Stumpf A, 2011, REMOTE SENS ENVIRON, V115, P2564, DOI 10.1016/j.rse.2011.05.013
   Szegedy C, 2017, AAAI CONF ARTIF INTE, V0, P4278
   Tanoli JI, 2017, ARAB J GEOSCI, V10, P0, DOI 10.1007/s12517-017-3026-9
   Tarolli P, 2012, NAT HAZARDS, V61, P65, DOI 10.1007/s11069-010-9695-2
   Travelletti J, 2014, INT J APPL EARTH OBS, V32, P1, DOI 10.1016/j.jag.2014.03.022
   van Westen CJ, 2008, ENG GEOL, V102, P112, DOI 10.1016/j.enggeo.2008.03.010
   Van Westen CJ, 1996, TRANSPORTATION RES B, V247, P129
   van Zuidam R.A., 1985, AERIAL PHOTOINTERPRE, V0, P0
   Wang Y, 2019, SCI TOTAL ENVIRON, V666, P975, DOI 10.1016/j.scitotenv.2019.02.263
   Xiao LM, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18124436
   Xu C, 2015, GEOMORPHOLOGY, V248, P77, DOI 10.1016/j.geomorph.2015.07.002
   Yang BB, 2019, LANDSLIDES, V16, P677, DOI 10.1007/s10346-018-01127-x
   Yang XJ, 2010, INT J APPL EARTH OBS, V12, P487, DOI 10.1016/j.jag.2010.05.006
   Zhan QM, 2005, INT J REMOTE SENS, V26, P2953, DOI 10.1080/01431160500057764
NR 81
TC 19
Z9 19
U1 7
U2 55
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1612-510X
EI 1612-5118
J9 LANDSLIDES
JI Landslides
PD APR 15
PY 2021
VL 18
IS 4
BP 1421
EP 1443
DI 10.1007/s10346-020-01557-6
EA OCT 2020
PG 23
WC Engineering, Geological; Geosciences, Multidisciplinary
SC Engineering; Geology
GA RM9KN
UT WOS:000584932700001
DA 2023-04-26
ER

PT J
AU Xie, GY
   Niculescu, S
AF Xie, Guanyao
   Niculescu, Simona
TI Mapping and Monitoring of Land Cover/Land Use (LCLU) Changes in the Crozon Peninsula (Brittany, France) from 2007 to 2018 by Machine Learning Algorithms (Support Vector Machine, Random Forest, and Convolutional Neural Network) and by Post-classification Comparison (PCC)
SO REMOTE SENSING
LA English
DT Article
DE remote sensing; machine learning; GEOBIA; CNN; land cover/land use; SPOT 5; Sentinel 2; change detection
ID remote-sensing analysis; decision trees; accuracy; urbanization; imagery; segmentation; vegetation; selection; impacts; multiresolution
AB Land cover/land use (LCLU) is currently a very important topic, especially for coastal areas that connect the land and the coast and tend to change frequently. LCLU plays a crucial role in land and territory planning and management tasks. This study aims to complement information on the types and rates of LCLU multiannual changes with the distributions, rates, and consequences of these changes in the Crozon Peninsula, a highly fragmented coastal area. To evaluate the multiannual change detection (CD) capabilities using high-resolution (HR) satellite imagery, we implemented three remote sensing algorithms: a support vector machine (SVM), a random forest (RF) combined with geographic object-based image analysis techniques (GEOBIA), and a convolutional neural network (CNN), with SPOT 5 and Sentinel 2 data from 2007 and 2018. Accurate and timely CD is the most important aspect of this process. Although all algorithms were indicated as efficient in our study, with accuracy indices between 70% and 90%, the CNN had significantly higher accuracy than the SVM and RF, up to 90%. The inclusion of the CNN significantly improved the classification performance (5-10% increase in the overall accuracy) compared with the SVM and RF classifiers applied in our study. The CNN eliminated some of the confusion that characterizes a coastal area. Through the study of CD results by post-classification comparison (PCC), multiple changes in LCLU could be observed between 2007 and 2018: both the cultivated and non-vegetated areas increased, accompanied by high deforestation, which could be explained by the high rate of urbanization in the peninsula.
C1 [Xie, Guanyao; Niculescu, Simona] IUEM UBO, Lab LETG Brest, Geomer, UMR 6554,CNRS, F-29200 Brest, France.
   [Niculescu, Simona] Univ Western Brittany, Dept Geog, 3 Rue Arch, F-29238 Brest, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute of Ecology & Environment (INEE); Universite de Bretagne Occidentale; Universite de Bretagne Occidentale
RP Xie, GY (corresponding author), IUEM UBO, Lab LETG Brest, Geomer, UMR 6554,CNRS, F-29200 Brest, France.
EM Guanyao.Xie@univ-brest.fr; Simona.Niculescu@univ-brest.fr
FU Fondation de France
CR Alberg AJ, 2004, J GEN INTERN MED, V19, P460, DOI 10.1111/j.1525-1497.2004.30091.x
   Angelos T, 2006, P OBIA, V0, P0
   [Anonymous], 2003, INT J APPL EARTH OBS, V0, P0
   [Anonymous], 2016, NAT METHODS, V0, P0, DOI DOI 10.1038/nmeth.3707
   ASRAR G, 1984, AGRON J, V76, P300, DOI 10.2134/agronj1984.00021962007600020029x
   Baatz M., 2000, ANGEW GEOGRAPHISCHE, V0, PP12, DOI 10.3390/RS5010183
   Bannari A., 1995, REMOTE SENS REV, V13, P95, DOI 10.1080/02757259509532298
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Briassoulis H., 2020, ANAL LAND USE CHANGE, V2nd, P0
   Briem GJ, 2002, IEEE T GEOSCI REMOTE, V40, P2291, DOI 10.1109/TGRS.2002.802476
   Brink AB, 2014, INT J APPL EARTH OBS, V28, P60, DOI 10.1016/j.jag.2013.11.006
   Chan JCW, 2008, REMOTE SENS ENVIRON, V112, P2999, DOI 10.1016/j.rse.2008.02.011
   Chughtai AH, 2021, REMOTE SENS APPL, V22, P0, DOI 10.1016/j.rsase.2021.100482
   Cihlar J, 2000, INT J REMOTE SENS, V21, P1093, DOI 10.1080/014311600210092
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Crowell M, 2007, J COASTAL RES, V23, PIII, DOI 10.2112/07A-0017.1
   Darwish A, 2003, INT GEOSCI REMOTE SE, V0, P2039
   de Bem PP, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060901
   Devadas R, 2012, INT ARCH PHOTOGRAMM, V39, P185
   Dewan AM, 2009, APPL GEOGR, V29, P390, DOI 10.1016/j.apgeog.2008.12.005
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Dou P, 2017, INT J REMOTE SENS, V38, P5388, DOI 10.1080/01431161.2017.1339926
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Frohn RC, 1996, INT J REMOTE SENS, V17, P3233, DOI 10.1080/01431169608949141
   Fu TY, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.025010
   Gao J, 2010, INT J APPL EARTH OBS, V12, P9, DOI 10.1016/j.jag.2009.08.003
   Giri C, 2013, INT J APPL EARTH OBS, V25, P30, DOI 10
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   Gitelson AA, 1996, REMOTE SENS ENVIRON, V58, P289, DOI 10.1016/S0034-4257(96)00072-7
   Guan YW, 2020, IEEE J-STARS, V13, P4166, DOI 10.1109/JSTARS.2020.3007562
   Han Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060983
   Tran H, 2015, REMOTE SENS-BASEL, V7, P2899, DOI 10.3390/rs70302899
   He CY, 2017, REMOTE SENS ENVIRON, V193, P65, DOI 10.1016/j.rse.2017.02.027
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   Jiang ZY, 2008, REMOTE SENS ENVIRON, V112, P3833, DOI 10.1016/j.rse.2008.06.006
   Jing R, 2020, IEEE ACCESS, V8, P228070, DOI 10.1109/ACCESS.2020.3045740
   Jozdani SE, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141713
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Lavrakas PJ., 2008, ENCY SURVEY RES METH, V0, P0, DOI DOI 10.4135/9781412963947
   Li HT, 2010, INT J REMOTE SENS, V31, P1453, DOI 10.1080/01431160903475266
   Li J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071130
   Liu H, 2004, INT J REMOTE SENS, V25, P1037, DOI 10.1080/0143116031000150004
   Lu DS, 2014, INT J IMAGE DATA FUS, V5, P13, DOI 10.1080/19479832.2013.868372
   Ma J, 2019, ATMOS ENVIRON, V214, P0, DOI 10.1016/j.atmosenv.2019.116885
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mahmood R, 2010, B AM METEOROL SOC, V91, P37, DOI 10.1175/2009BAMS2769.1
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Munoz DF, 2021, IEEE J-STARS, V14, P1768, DOI 10.1109/JSTARS.2020.3048724
   Niculescu S., 2020, INT ARCH PHOTOGRAMM, V43, P727, DOI 10.5194/ISPRS--ARCHIVESXLIII--B3-2020-727-2020
   Niculescu S, 2018, PROC SPIE, V10783, P0, DOI 10.1117/12.2325546
   Niu X, 2013, INT J REMOTE SENS, V34, P1, DOI 10.1080/01431161.2012.700133
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Otukei JR, 2010, INT J APPL EARTH OBS, V12, PS27, DOI 10.1016/j.jag.2009.11.002
   Pal M, 2006, INT J REMOTE SENS, V27, P2877, DOI 10.1080/01431160500242515
   Pal M, 2005, INT J REMOTE SENS, V26, P1007, DOI 10.1080/01431160512331314083
   Noi PT, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18010018
   Rodriguez-Galiano VF, 2012, REMOTE SENS ENVIRON, V121, P93, DOI 10.1016/j.rse.2011.12.003
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Sheykhmousa M, 2020, IEEE J-STARS, V13, P6308, DOI 10.1109/JSTARS.2020.3026724
   Shi D, 2015, SPRING REMOTE SENS P, V0, PP265, DOI 10.1007/978-94-017-9813-6_13
   Song XF, 2012, INT J REMOTE SENS, V33, P3301, DOI 10.1080/01431161.2011.568531
   Srivastava PK, 2012, ADV SPACE RES, V50, P1250, DOI 10.1016/j.asr.2012.06.032
   STORY M, 1986, PHOTOGRAMM ENG REM S, V52, P397
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Timilsina S., 2019, ISPRS ANN PHOTOGRAMM, V4, P111, DOI 10.5194/isprs-annals-IV-5-W2-111-2019
   TUNG F, 1988, PHOTOGRAMM ENG REM S, V54, P1449
   Tzotsos A., 2008, OBJECT BASED IMAGE A, V0, PP663, DOI 10.1007/978-3-540-77058-9_36
   Varma MKS, 2016, INT CONF ADV COMPU, V0, PP51, DOI 10.1109/IACC.2016.20
   Waldhoff G, 2017, INT J APPL EARTH OBS, V61, P55, DOI 10.1016/j.jag.2017.04.009
   Wang MC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121933
   Wang ZH, 2018, INT J APPL EARTH OBS, V69, P88, DOI 10.1016/j.jag.2018.03.001
   Weng Q, 2018, INT J REMOTE SENS, V39, P6281, DOI 10.1080/01431161.2018.1458346
   Wilson JS, 2003, REMOTE SENS ENVIRON, V86, P303, DOI 10.1016/S0034-4257(03)00084-1
   Witharana C, 2014, ISPRS J PHOTOGRAMM, V87, P108, DOI 10.1016/j.isprsjprs.2013.11.006
   Xie YC, 2008, J PLANT ECOL, V1, P9, DOI 10.1093/jpe/rtm005
   Xiong YZ, 2012, REMOTE SENS-BASEL, V4, P2033, DOI 10.3390/rs4072033
   Xu H, 2000, LAND DEGRAD DEV, V11, P301, DOI 10.1002/1099-145X(200007/08)11:4<301::AID-LDR392>3.0.CO;2-N
   Xue JR, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/1353691
   Zafari A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11050575
   Zeng T, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151777
   Zhang CH, 2012, PRECIS AGRIC, V13, P693, DOI 10.1007/s11119-012-9274-5
   Zhu LH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11101234
NR 88
TC 9
Z9 9
U1 7
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD OCT 15
PY 2021
VL 13
IS 19
BP 
EP 
DI 10.3390/rs13193899
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA ZB3ZJ
UT WOS:000756783900001
DA 2023-04-26
ER

PT J
AU Pena, A
   Patino, A
   Chiclana, F
   Caraffini, F
   Gongora, M
   Gonzalez-Ruiz, JD
   Duque-Grisales, E
AF Pena, Alejandro
   Patino, Alejandro
   Chiclana, Francisco
   Caraffini, Fabio
   Gongora, Mario
   Gonzalez-Ruiz, Juan David
   Duque-Grisales, Eduardo
TI Fuzzy convolutional deep-learning model to estimate the operational risk capital using multi-source risk events
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Financial modeling; Stochastic modeling; Fuzzy Cognitive Maps; Log-logistic activation function; Financial scenarios; Project finance
ID neural-networks; market
AB Operational Risk (OR) is usually caused by losses due to human errors, inadequate or defective internal processes, system failures or external events that affect an organization. According to the Basel II agreement, OR is defined by seven risk events: internal fraud, external fraud, labor relations, clients, damage to fixed assets, technological failures and failures in the execution & administration of processes. However, due to the large amount of qualitative information, the uncertainty and the low frequency at which these risk events are generated in an organization, their modeling is still a technological challenge. This paper takes up this challenge and presents a fuzzy convolutional deep-learning model to estimate, based on the Basel III recommendations, the ORLoss Component (OR-LC) in an organization. The proposed model integrates qualitative information as linguistic random variables, as well as risk events data from different sources using multi-dimensional fuzzy credibility concepts. The results show the stability of the proposed model with respect to the OR-LC estimation from both structural and dimensional point of views, making it an ideal tool for modeling OR from the perspective of: (a) the regulators (Basel Committee on Banking Supervision) by allowing the integration of experts' criteria into the OR-LC; (b) the insurers by allowing the integration of risk events from different sources; and (c) organizations and financial entities by allowing the a priori evaluation of the OR-LC of new financial products based on technological platforms and electronic channels. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Pena, Alejandro; Patino, Alejandro] EIA Univ, Computat Intelligence & Automat Res Grp, Envigado, Antioquia, Colombia.
   [Chiclana, Francisco; Caraffini, Fabio; Gongora, Mario] De Montfort Univ, Sch Comp Sci & Informat, Inst Artificial Intelligence, Leicester, Leics, England.
   [Chiclana, Francisco] Univ Granada, Andalusian Res Inst Data Sci & Computat Intellige, Granada, Spain.
   [Gonzalez-Ruiz, Juan David] Univ Nacl Colombia, Dept Econ, Medellin, Colombia.
   [Duque-Grisales, Eduardo] Inst Univ Pascual Bravo, Fac Ingn, Medellin, Colombia.
C3 De Montfort University; University of Granada; Universidad Nacional de Colombia
RP Caraffini, F (corresponding author), De Montfort Univ, Sch Comp Sci & Informat, Inst Artificial Intelligence, Leicester, Leics, England.
EM juan.pena@eia.edu.co; hector.patino@eia.edu.co; chiclana@dmu.ac.uk; fabio.caraffini@dmu.ac.uk; mgongora@dmu.ac.uk; jdgonza3@unal.edu.co; e.duque@pascualbravo.edu.co
CR [Anonymous], 2016, STAND MEAS APPR OP R, V0, P0
   Aramburu G., 2014, REV U EUR, V20, P46
   Azar A., 2018, EXPERT SYST APPL, V115, P0
   Aziz S, 2019, PALGR ST DIG BUS ENA, V0, PP33, DOI 10.1007/978-3-030-02330-0_3
   Bank for International Settlements, 2011, PRINC SOUND MAN OP R, V0, P0
   Blasch E., 2019, AUTOMATIC TARGET REC, V10988, P0
   Bonet I., 2014, INF SYST TECHN CISTI, V0, P1
   Bouveret A., 2018, 18143 INT MON FUND, V0, P0
   Buhlmann H., 2009, J OPER RISK, V2, P0
   Cao WP, 2018, NEUROCOMPUTING, V275, P278, DOI 10.1016/j.neucom.2017.08.040
   Celikoglu HB, 2006, MATH COMPUT MODEL, V44, P640, DOI 10.1016/j.mcm.2006.02.002
   Cheng-Ping C., 2018, ASIAN EC FINANC REV, V8, P831
   Cohen R., 2018, J OPER RISK, V13, P0
   Crisanto J., 2017, 2 FSI, V0, P20
   Cruz MG., 2015, FUNDAMENTAL ASPECTS, V0, P0, DOI DOI 10.1002/9781118573013
   Gonzalez-Ruiz JD, 2019, APPL SOFT COMPUT, V85, P0, DOI 10.1016/j.asoc.2019.105818
   Davila-Aragon G., 2017, REV MEXICANA EC FINA, V12, P363
   Di Lascio FML, 2018, J BANK FINANC, V96, P236, DOI 10.1016/j.jbankfin.2018.07.002
   Dorogovs P, 2013, PROCD SOC BEHV, V99, P911, DOI 10.1016/j.sbspro.2013.10.564
   Drewk J., 2018, POLICE PRACT RES, V19, P549
   Dziwok E., 2018, INT J TRADE GLOB MAR, V11, P1
   El Arif F.Z., 2014, AM J ENG RES, V03, P238
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   Franke U, 2017, COMPUT SECUR, V68, P130, DOI 10.1016/j.cose.2017.04.010
   G. of Canada, 2011, GUID CORP RISK PROF, V2016, P0
   Gurrea-Martinez A, 2019, J INT ECON LAW, V22, P125, DOI 10.1093/jiel/jgz002
   HSBC, 2007, REISG OP BAS LI, V0, P0
   Isazi P., 2004, REDES NEURONAS ARTIF, V0, P0
   Ivanov D, 2019, INT J PROD RES, V57, P829, DOI 10.1080/00207543.2018.1488086
   Kamil J., 2018, J OPER RES SOC, V69, P371
   Karshenas H, 2013, APPL SOFT COMPUT, V13, P2412, DOI 10.1016/j.asoc.2012.11.049
   Kim JY, 2019, ADV INTELL SYST, V771, P134, DOI 10.1007/978-3-319-94120-2_13
   Kishino H, 2001, ENCY GENETICS, V0, PP1157, DOI 10.1006/RWGN.2001.0803
   Liu KF, 2006, INT J GEOGR INF SCI, V20, P857, DOI 10.1080/13658810600711345
   McConnell P, 2018, J OPER RISK, V13, P47, DOI 10.21314/JOP.2018.211
   Milkau U, 2018, RISKS, V6, P0, DOI 10.3390/risks6020041
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Mora Valencia A, 2010, CUADERNOS ADM, V25, P185
   Mora-Valencia A., 2017, P 7 EUR AC RES C GLO, V0, P0
   Mubalaike AM, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), V0, PP598, DOI 10.1109/UBMK.2018.8566574
   Naseer S, 2018, IEEE ACCESS, V6, P48231, DOI 10.1109/ACCESS.2018.2863036
   Neifar S, 2018, RES INT BUS FINANC, V46, P43, DOI 10.1016/j.ribaf.2017.09.006
   Nerurkar P, 2018, PROCEDIA COMPUT SCI, V125, P770, DOI 10.1016/j.procs.2017.12.099
   OReilly M., 2018, FUTURE OPERATIONAL R, V0, P0
   Otero P., 2009, QUANTUM, V1, P58
   Park OH, 2007, ATMOS ENVIRON, V41, P6095, DOI 10.1016/j.atmosenv.2007.04.010
   Pena A., 1900, P1, V0, P0
   Pena A, 2018, KNOWL-BASED SYST, V159, P98, DOI 10.1016/j.knosys.2018.06.007
   Pena A, 2018, APPL SOFT COMPUT, V65, P614, DOI 10.1016/j.asoc.2018.01.024
   Pena A, 2018, EXPERT SYST APPL, V98, P11, DOI 10.1016/j.eswa.2018.01.001
   Pena A, 2010, ENVIRON MODELL SOFTW, V25, P1890, DOI 10.1016/j.envsoft.2010.04.013
   Potapov A., 2014, IFIP ADV INFORM COMM, V436, P0
   Schugoreva VA, 2019, ADV INTELL SYST, V854, P91, DOI 10.1007/978-3-319-99993-7_9
   Shevchenko P., 2013, SSRN, V0, P0
   Tsai CF, 2008, EXPERT SYST APPL, V34, P2639, DOI 10.1016/j.eswa.2007.05.019
   Vasiliev I.I., 2018, RSF-RUS SAGE J SOC S, V7, P524, DOI 10.14419/ijet.v7i4.36.24130
   Wei L., 2018, ANN DATA SCI, V0, P0
   Xu C., 2018, PHYSICA A, V516, P0
   Yang X. -S., 2019, INTRO ALGORITHMS DAT, V0, P0
   Yildirim O, 2018, COGN SYST RES, V52, P198, DOI 10.1016/j.cogsys.2018.07.004
   Yoe C., 2019, PRINCIPLES RISK ANAL, V0, P848
NR 61
TC 1
Z9 1
U1 3
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD AUG 15
PY 2021
VL 107
IS 
BP 
EP 
DI 10.1016/j.asoc.2021.107381
EA APR 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications
SC Computer Science
GA SO4AE
UT WOS:000658916600004
DA 2023-04-26
ER

PT J
AU Wang, YF
   Ding, WR
   Zhang, RQ
   Li, HG
AF Wang, Yufeng
   Ding, Wenrui
   Zhang, Ruiqian
   Li, Hongguang
TI Boundary-Aware Multitask Learning for Remote Sensing Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Task analysis; Remote sensing; Semantics; Image segmentation; Estimation; Feature extraction; Earth; Boundary regularization (BR); convolutional neural network (CNN); height estimation; multitask learning (MTL); remote sensing imagery (RSI); scene understanding; semantic segmentation
ID fully convolutional networks; semantic segmentation; classification; multiscale; height
AB Semantic segmentation and height estimation play fundamental roles in the scene understanding of remote sensing images with their wide variety of aerial applications. Recently, deep convolutional neural networks (DCNNs) have achieved state-of-the-art performance in both tasks. However, DCNN-based methods learn to accumulate contextual information over large receptive fields while lose the local detailed information, resulting in blurry object boundaries. The complicated ground object distribution and low interclass variance further aggravate the difficulty in generating accurate predictions. To address the above-mentioned issues, we propose a novel boundary-aware multitask learning (BAMTL) framework to perform three tasks, semantic segmentation, height estimation, and boundary detection, within a unified model. The boundary detection is employed as an auxiliary task to regularize the other two master tasks at both the feature space and output space. We present a boundary attentive module to build the cross-task interaction for master tasks, which enforce the networks to filter out the confident area and focus on learning the high-frequency details. We then introduce a boundary regularized loss term to further refine the prediction maps to be locally consistent while preserving boundary structures. With these formulations, our model improves the performance of both segmentation and height tasks, especially along the boundaries. Experimental results on two publicly available remote sensing datasets demonstrate that the proposed approach performs favorably against the state-of-the-art methods.
C1 [Wang, Yufeng] Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.
   [Ding, Wenrui; Li, Hongguang] Beihang Univ, Unmanned Syst Res Inst, Beijing 100191, Peoples R China.
   [Zhang, Ruiqian] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
C3 Beihang University; Beihang University; Wuhan University
RP Li, HG (corresponding author), Beihang Univ, Unmanned Syst Res Inst, Beijing 100191, Peoples R China.
EM wyfeng@buaa.edu.cn; ding@buaa.edu.cn; zhangruiqian@whu.edu.cn; lihongguang@buaa.edu.cn
FU National Natural Science Foundation of China [62076019, U20B2042]
CR Amirkolaee HA, 2019, ISPRS J PHOTOGRAMM, V149, P50, DOI 10.1016/j.isprsjprs.2019.01.013
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bilinski P, 2018, PROC CVPR IEEE, V0, PP6596, DOI 10.1109/CVPR.2018.00690
   Bischke B, 2019, IEEE IMAGE PROC, V0, PP1480, DOI 10.1109/ICIP.2019.8803050
   Bottou L, 2010, COMPSTAT2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, V0, PP177, DOI 10.1007/978-3-7908-2604-3_16
   Cao ZY, 2019, IEEE GEOSCI REMOTE S, V16, P1766, DOI 10.1109/LGRS.2019.2907009
   Carvalho M, 2020, IEEE GEOSCI REMOTE S, V17, P1391, DOI 10.1109/LGRS.2019.2947783
   Carvalho M, 2018, IEEE IMAGE PROC, V0, PP2915, DOI 10.1109/ICIP.2018.8451312
   Chen GZ, 2018, IEEE J-STARS, V11, P1633, DOI 10.1109/JSTARS.2018.2810320
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Z, 2018, PR MACH LEARN RES, V80, P0
   Cheng DC, 2017, IEEE J-STARS, V10, P5769, DOI 10.1109/JSTARS.2017.2747599
   Cheng DC, 2017, IEEE GEOSCI REMOTE S, V14, P247, DOI 10.1109/LGRS.2016.2637439
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Ding L, 2020, IEEE T GEOSCI REMOTE, V58, P5367, DOI 10.1109/TGRS.2020.2964675
   Eigen D, 2014, ADV NEUR IN, V27, P0
   Eigen D, 2015, IEEE I CONF COMP VIS, V0, PP2650, DOI 10.1109/ICCV.2015.304
   Fu G, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050498
   Gao Y, 2019, PROC CVPR IEEE, V0, PP3200, DOI 10.1109/CVPR.2019.00332
   Gerke M., 2014, USE STAIR VISION LIB, V0, P0, DOI DOI 10.13140/2.1.5015.9683
   Ghamisi P, 2018, IEEE GEOSCI REMOTE S, V15, P794, DOI 10.1109/LGRS.2018.2806945
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Godard C, 2019, IEEE I CONF COMP VIS, V0, PP3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, V0, PP6602, DOI 10.1109/CVPR.2017.699
   Guo M, 2018, LECT NOTES COMPUT SC, V11220, P282, DOI 10.1007/978-3-030-01270-0_17
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P1424, DOI 10.1109/TGRS.2020.3003341
   Hang RL, 2020, IEEE T GEOSCI REMOTE, V58, P4939, DOI 10.1109/TGRS.2020.2969024
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hung WC, 2017, IEEE I CONF COMP VIS, V0, PP2650, DOI 10.1109/ICCV.2017.287
   Kendall A, 2018, PROC CVPR IEEE, V0, PP7482, DOI 10.1109/CVPR.2018.00781
   Kokkinos I, 2017, PROC CVPR IEEE, V0, PP5454, DOI 10.1109/CVPR.2017.579
   Kuznietsov Y, 2017, PROC CVPR IEEE, V0, PP2215, DOI 10.1109/CVPR.2017.238
   Li J, 2017, IEEE I CONF COMP VIS, V0, PP3392, DOI 10.1109/ICCV.2017.365
   Lian Zhuo, 2020, 2020 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR). PROCEEDINGS, V0, PP7956, DOI 10.1109/CVPR42600.2020.00798
   Lin GS, 2017, PROC CVPR IEEE, V0, PP5168, DOI 10.1109/CVPR.2017.549
   Liu SK, 2019, PROC CVPR IEEE, V0, PP1871, DOI 10.1109/CVPR.2019.00197
   Liu S, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091339
   Liu Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060522
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P7092, DOI 10.1109/TGRS.2017.2740362
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Mi L, 2020, ISPRS J PHOTOGRAMM, V159, P140, DOI 10.1016/j.isprsjprs.2019.11.006
   Misra I, 2016, PROC CVPR IEEE, V0, PP3994, DOI 10.1109/CVPR.2016.433
   Mou LC, 2019, PROC CVPR IEEE, V0, PP12408, DOI 10.1109/CVPR.2019.01270
   Mou Lichao., 2018, ARXIV180210249, V0, P0
   Papadomanolaki M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060684
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), V0, PP1, DOI 10.1109/ICPHM.2017.7998297
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sebastian, 2017, ARXIV170605098, V0, P0
   Sener O., 2018, ADV NEURAL INFORM PR, V0, P527
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Srivastava S, 2017, INT GEOSCI REMOTE SE, V0, P5173
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   Vandenhende S., 2020, REVISITING MULTITASK, V0, P0
   Volpi M, 2018, ISPRS J PHOTOGRAMM, V144, P48, DOI 10.1016/j.isprsjprs.2018.06.007
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang YF, 2020, IEEE T CIRC SYST VID, V30, P2590, DOI 10.1109/TCSVT.2019.2919482
   Xu D, 2018, PROC CVPR IEEE, V0, PP675, DOI 10.1109/CVPR.2018.00077
   Xu D, 2018, PROC CVPR IEEE, V0, PP3917, DOI 10.1109/CVPR.2018.00412
   Xu X., 2017, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Yang MK, 2018, PROC CVPR IEEE, V0, PP3684, DOI 10.1109/CVPR.2018.00388
   Yi YN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151774
   Yu F., 2015, 1511 ARXIV, V0, P0
   Zhan HY, 2018, PROC CVPR IEEE, V0, PP340, DOI 10.1109/CVPR.2018.00043
   Zhang H, 2018, PROC CVPR IEEE, V0, PP7151, DOI 10.1109/CVPR.2018.00747
   Zhang MM, 2020, IEEE T CYBERNETICS, V50, P100, DOI 10.1109/TCYB.2018.2864670
   Zhang YT, 2019, IEEE INT CONF MULTI, V0, PP186, DOI 10.1109/ICMEW.2019.00-89
   Zhao XD, 2020, IEEE T GEOSCI REMOTE, V58, P7355, DOI 10.1109/TGRS.2020.2982064
   Zheng Z, 2019, INT GEOSCI REMOTE SE, V0, PP4963, DOI 10.1109/IGARSS.2019.8897927
   Zhou F, 2021, IEEE T GEOSCI REMOTE, V59, P2245, DOI 10.1109/TGRS.2020.3006872
   Zhu Y, 2019, PROC CVPR IEEE, V0, PP8848, DOI 10.1109/CVPR.2019.00906
NR 75
TC 12
Z9 13
U1 10
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 951
EP 963
DI 10.1109/JSTARS.2020.3043442
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UR0EE
UT WOS:000696430600017
DA 2023-04-26
ER

PT J
AU Gao, H
   Guo, JH
   Guo, P
   Chen, XW
AF Gao, Han
   Guo, Jinhui
   Guo, Peng
   Chen, Xiuwan
TI Classification of Very-High-Spatial-Resolution Aerial Images Based on Multiscale Features with Limited Semantic Information
SO REMOTE SENSING
LA English
DT Article
DE deep learning; aerial imagery; convolutional neural network; object-based classification
ID convolutional neural-network; metaanalysis; systems
AB Recently, deep learning has become the most innovative trend for a variety of high-spatial-resolution remote sensing imaging applications. However, large-scale land cover classification via traditional convolutional neural networks (CNNs) with sliding windows is computationally expensive and produces coarse results. Additionally, although such supervised learning approaches have performed well, collecting and annotating datasets for every task are extremely laborious, especially for those fully supervised cases where the pixel-level ground-truth labels are dense. In this work, we propose a new object-oriented deep learning framework that leverages residual networks with different depths to learn adjacent feature representations by embedding a multibranch architecture in the deep learning pipeline. The idea is to exploit limited training data at different neighboring scales to make a tradeoff between weak semantics and strong feature representations for operational land cover mapping tasks. We draw from established geographic object-based image analysis (GEOBIA) as an auxiliary module to reduce the computational burden of spatial reasoning and optimize the classification boundaries. We evaluated the proposed approach on two subdecimeter-resolution datasets involving both urban and rural landscapes. It presented better classification accuracy (88.9%) compared to traditional object-based deep learning methods and achieves an excellent inference time (11.3 s/ha).
C1 [Gao, Han; Guo, Jinhui; Guo, Peng; Chen, Xiuwan] Peking Univ, Inst Remote Sensing & Geog Informat Syst, Beijing 100871, Peoples R China.
C3 Peking University
RP Guo, JH (corresponding author), Peking Univ, Inst Remote Sensing & Geog Informat Syst, Beijing 100871, Peoples R China.
EM hgao@pku.edu.cn; guojh_rs@pku.edu.cn; peng_guo@pku.edu.cn; xwchen@pku.edu.cn
FU National Key Research and Development Program of China [2018YFC0407702, 2017YFC1500900]
CR Abadi Martin, 2016, ARXIV, V0, P0
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arvor D, 2013, ISPRS J PHOTOGRAMM, V82, P125, DOI 10.1016/j.isprsjprs.2013.05.003
   Audebert N., 2016, 160906846 ARXIV, V0, P0
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Baatz M., 2018, J GEOSCI GEOMAT, V6, P103
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Ban YF, 2015, ISPRS J PHOTOGRAMM, V103, P1, DOI 10.1016/j.isprsjprs.2015.01.001
   Bejiga MB, 2018, INT GEOSCI REMOTE SE, V0, P1264
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Tianqi, 2016, P 22 ACM SIGKDD INT, V0, P0
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Colomina I, 2014, ISPRS J PHOTOGRAMM, V92, P79, DOI 10.1016/j.isprsjprs.2014.02.013
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gao H, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17102427
   Ghazouani F., 2018, ONTOLOGY INFORM SCI, V0, P0
   Hay G., 2008, OBJECT BASED IMAGE A, V0, PP75, DOI 10.1007/978-3-540-77058-9_4
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Huang BH, 2018, INT GEOSCI REMOTE SE, V0, P6947
   Ji SP, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111343
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Koltun V., 2012, 12105644 ARXIV, V0, P0
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leotta MJ, 2019, IEEE COMPUT SOC CONF, V0, PP1451, DOI 10.1109/CVPRW.2019.00186
   Li MC, 2016, INT J APPL EARTH OBS, V49, P87, DOI 10.1016/j.jag.2016.01.011
   Li M, 2014, EUR J REMOTE SENS, V47, P389, DOI 10.5721/EuJRS20144723
   Li P, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060871
   Li WJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040403
   Liu T, 2018, ISPRS J PHOTOGRAMM, V139, P154, DOI 10.1016/j.isprsjprs.2018.03.006
   Liu YS, 2017, IEEE COMPUT SOC CONF, V0, PP1561, DOI 10.1109/CVPRW.2017.200
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Martins VS, 2020, ISPRS J PHOTOGRAMM, V168, P56, DOI 10.1016/j.isprsjprs.2020.08.004
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Neubert P, 2014, INT C PATT RECOG, V0, PP996, DOI 10.1109/ICPR.2014.181
   Papadomanolaki M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060684
   Ronneberger O., 2015, U NET CONVOLUTIONAL, V9351, P241
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Tehrany MS, 2014, GEOCARTO INT, V29, P351, DOI 10.1080/10106049.2013.768300
   Tuia D, 2015, ISPRS J PHOTOGRAMM, V105, P272, DOI 10.1016/j.isprsjprs.2015.01.006
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Xu SH, 2018, REMOTE SENS LETT, V9, P617, DOI 10.1080/2150704X.2018.1453173
   Xu YY, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010144
   Yang ZS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090936
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang SM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060631
   Zhao WQ, 2019, IEEE T SYST MAN CY-S, V49, P1254, DOI 10.1109/TSMC.2017.2724440
   Zhao WZ, 2017, ISPRS J PHOTOGRAMM, V132, P48, DOI 10.1016/j.isprsjprs.2017.08.011
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
   Zhong YF, 2018, ISPRS J PHOTOGRAMM, V138, P281, DOI 10.1016/j.isprsjprs.2018.02.014
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 66
TC 6
Z9 6
U1 7
U2 20
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 15
PY 2021
VL 13
IS 3
BP 
EP 
DI 10.3390/rs13030364
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QD4ET
UT WOS:000615474300001
DA 2023-04-26
ER

PT J
AU Fu, H
   Fu, BH
   Shi, PL
AF Fu, Han
   Fu, Bihong
   Shi, Pilong
TI An Improved Segmentation Method for Automatic Mapping of Cone Karst from Remote Sensing Data Based on DeepLab V3+Model
SO REMOTE SENSING
LA English
DT Article
DE UNESCO natural heritage site; cone karst landscape; segmentation; deep learning; multi-source remote sensing data
ID gis
AB The South China Karst, a United Nations Educational, Scientific and Cultural Organization (UNESCO) natural heritage site, is one of the world's most spectacular examples of humid tropical to subtropical karst landscapes. The Libo cone karst in the southern Guizhou Province is considered as the world reference site for these types of karst, forming a distinctive and beautiful landscape. Geomorphic information and spatial distribution of cone karst is essential for conservation and management for Libo heritage site. In this study, a deep learning (DL) method based on DeepLab V3+ network was proposed to document the cone karst landscape in Libo by multi-source data, including optical remote sensing images and digital elevation model (DEM) data. The training samples were generated by using Landsat remote sensing images and their combination with satellite derived DEM data. Each group of training dataset contains 898 samples. The input module of DeepLab V3+ network was improved to accept four-channel input data, i.e., combination of Landsat RGB images and DEM data. Our results suggest that the mean intersection over union (MIoU) using the four-channel data as training samples by a new DL-based pixel-level image segmentation approach is the highest, which can reach 95.5%. The proposed method can accomplish automatic extraction of cone karst landscape by self-learning of deep neural network, and therefore it can also provide a powerful and automatic tool for documenting other type of geological landscapes worldwide.
C1 [Fu, Han; Fu, Bihong; Shi, Pilong] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Fu, Han] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Fu, BH (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
EM fuhan2017@radi.ac.cn; fubh@aircas.ac.cn; shipl@aircas.ac.cn
FU Second Tibetan Plateau Scientific Expedition and Research Program (STEP) [2019QZKK0901]; Strategic Priority Research Program of Chinese Academy of Sciences [XDA 20070202]
CR Chen L.C., 2014, COMPUT SCI, V4357, P361
   Chen L.-C., 2017, ARXIV170605587, V0, P0, DOI DOI 10.1109/ICC.2017.7997128
   Chen L.C., 2018, LECT NOTES COMPUT SC, V0, P0, DOI DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, V0, PP3640, DOI 10.1109/CVPR.2016.396
   Dai C G, 2013, GUIZHOU GEOLOGY, V30, P119
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu Y.H., 2012, J YUNCHENG U, V30, P4
   Huang W., 2014, THESIS U WISCONSIN M, V0, P0
   Kavzoglu T, 2009, INT J APPL EARTH OBS, V11, P352, DOI 10.1016/j.jag.2009.06.002
   Kokkinos I., 2016, ARXIV151107386, V0, P0
   Lan Z., 2020, THESIS U ELECT SCI T, V0, P0
   Li F., 2015, SURV SPAT GEOGR INF, V8, P73
   Li G.C., 2014, THESIS GUIZHOU NORMA, V0, P0
   Li S, 2015, REMOTE SENS LETT, V6, P657, DOI 10.1080/2150704X.2015.1070315
   Liang FY, 2014, GEOMORPHOLOGY, V204, P42, DOI 10.1016/j.geomorph.2013.07.026
   Litwin L, 2008, ENVIRON GEOL, V54, P979, DOI 10.1007/s00254-007-0893-5
   [刘文雅 Liu Wenya], 2020, 国土资源遥感 REMOTE SENSING FOR LAND & RESOURCES, V32, P120
   Luo W., 2013, J CTR CHINA NORM U, V47, P436
   Papandreou G, 2015, PROC CVPR IEEE, V0, PP390, DOI 10.1109/CVPR.2015.7298636
   Plath N., 2009, P 26 ANN INT C MACH, V0, PP817, DOI 10.1145/1553374.1553479
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sun Y., 2015, J GUILIN U TECHNOL, V35, P193
   Theilen-Willige B, 2014, GEOSCIENCES, V4, P50, DOI 10.3390/geosciences4020050
   Tian S.J., 2008, THESIS GUIZHOU NORMA, V0, P0
   Tong L.Q., 2003, REMOTE SENS LAND RES, V4, P35, DOI 10.3969/J.ISSN.1001-070X.2003.04.009
   Vapnik V N, 1963, AUTOMAT REM CONTR, V24, P774
   Waltham T., 2008, CAVE KARST SCI, V35, P77
   [王振华 Wang Zhenhua], 2020, 中国图象图形学报 JOURNAL OF IMAGE AND GRAPHICS, V25, P768
   Xiong K.N., 2008, P SEM DEV LEIS AGR T, V0, P0
   [薛显武 XUE Xian-wu], 2009, 中国岩溶 CARSOLOGICA SINICA, V28, P175
   Yi YN, 2020, IEEE J-STARS, V13, P6166, DOI 10.1109/JSTARS.2020.3028855
   Yu D.Q., 2002, REMOTE SENS LAND RES, V1, P34
   Yu Y., 2005, J SHENYANG U, V17, P42
   Yuan D.X., 2002, CHINA KARST POWER SY, V0, P3
   Zhang L.G., 2018, THESIS NE NORMAL U C, V0, P0
   Zhao F., 2008, GEOD GEODYN, V28, P46
   Zheng S, 2015, IEEE I CONF COMP VIS, V0, PP1529, DOI 10.1109/ICCV.2015.179
   Zhou Z.F., 2001, GUIZHOU GEOL, V18, P93
   Zhou Z.F., 2001, SOIL WATER CONSERV B, V21, P52
NR 43
TC 7
Z9 10
U1 9
U2 39
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 15
PY 2021
VL 13
IS 3
BP 
EP 
DI 10.3390/rs13030441
PG 16
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA QD4CJ
UT WOS:000615468100001
DA 2023-04-26
ER

PT J
AU Laguarta, J
   Subirana, B
AF Laguarta, Jordi
   Subirana, Brian
TI Longitudinal Speech Biomarkers for Automated Alzheimer's Detection
SO FRONTIERS IN COMPUTER SCIENCE
LA English
DT Article
DE multimodal deep learning; transfer learning; explainable speech recognition; brain model; graph neural-networks; AI diagnostics
ID cognitive impairment; substance-p; disease; dementia; cough; dysphagia; covid-19; scale
AB We introduce a novel audio processing architecture, the Open Voice Brain Model (OVBM), improving detection accuracy for Alzheimer's (AD) longitudinal discrimination from spontaneous speech. We also outline the OVBM design methodology leading us to such architecture, which in general can incorporate multimodal biomarkers and target simultaneously several diseases and other AI tasks. Key in our methodology is the use of multiple biomarkers complementing each other, and when two of them uniquely identify different subjects in a target disease we say they are orthogonal. We illustrate the OBVM design methodology by introducing sixteen biomarkers, three of which are orthogonal, demonstrating simultaneous above state-of-the-art discrimination for two apparently unrelated diseases such as AD and COVID-19. Depending on the context, throughout the paper we use OVBM indistinctly to refer to the specific architecture or to the broader design methodology. Inspired by research conducted at the MIT Center for Brain Minds and Machines (CBMM), OVBM combines biomarker implementations of the four modules of intelligence: The brain OS chunks and overlaps audio samples and aggregates biomarker features from the sensory stream and cognitive core creating a multi-modal graph neural network of symbolic compositional models for the target task. In this paper we apply the OVBM design methodology to the automated diagnostic of Alzheimer's Dementia (AD) patients, achieving above state-of-the-art accuracy of 93.8% using only raw audio, while extracting a personalized subject saliency map designed to longitudinally track relative disease progression using multiple biomarkers, 16 in the reported AD task. The ultimate aim is to help medical practice by detecting onset and treatment impact so that intervention options can be longitudinally tested. Using the OBVM design methodology, we introduce a novel lung and respiratory tract biomarker created using 200,000+ cough samples to pre-train a model discriminating cough cultural origin. Transfer Learning is subsequently used to incorporate features from this model into various other biomarker-based OVBM architectures. This biomarker yields consistent improvements in AD detection in all the starting OBVM biomarker architecture combinations we tried. This cough dataset sets a new benchmark as the largest audio health dataset with 30,000+ subjects participating in April 2020, demonstrating for the first time cough cultural bias.
C1 [Laguarta, Jordi; Subirana, Brian] MIT, AutoID Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Subirana, Brian] Harvard Univ, Fac Arts & Sci, Cambridge, MA 02138 USA.
C3 Massachusetts Institute of Technology (MIT); Harvard University
RP Subirana, B (corresponding author), MIT, AutoID Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.; Subirana, B (corresponding author), Harvard Univ, Fac Arts & Sci, Cambridge, MA 02138 USA.
EM subirana@mit.edu
CR Abeyratne UR, 2013, ANN BIOMED ENG, V41, P2448, DOI 10.1007/s10439-013-0836-0
   Alagiakrishnan K, 2013, ARCH GERONTOL GERIAT, V56, P1, DOI 10.1016/j.archger.2012.04.011
   Altinkaya Emre, 2020, J INSTIT ELECT COMPU, V1, P39, DOI 10.33969/JIEC.2019.11005
   [Anonymous], 2020, ALZHEIMERS DEMENT, V16, P391, DOI 10.1002/alz.12068
   Azarpazhooha MR, 2020, J NEUROL SCI, V416, P0, DOI 10.1016/j.jns.2020.117013
   Babulal GM, 2016, AM J GERIAT PSYCHIAT, V24, P1095, DOI 10.1016/j.jagp.2016.04.004
   Baldwin Sharelle, 2009, CURR PROTOC NEUROSCI, VChapter 10, P0, DOI 10.1002/0471142301.ns1003s49
   Pulido MLB, 2020, EXPERT SYST APPL, V150, P0, DOI 10.1016/j.eswa.2020.113213
   Barthelemy NR, 2020, J EXP MED, V217, P0, DOI 10.1084/jem.20200861
   Bennett WD, 2010, J AEROSOL MED PULM D, V23, P261, DOI 10.1089/jamp.2010.0823
   Bidzan M, 2014, PSYCHIATR POL, V48, P319
   Bowling A, 2015, AGING MENT HEALTH, V19, P13, DOI 10.1080/13607863.2014.915923
   Briggs R, 2016, CLIN MED, V16, P247, DOI 10.7861/clinmedicine.16-3-247
   Cano-Cordoba F., 2017, 71 MIT CBMM, V0, P0
   Cassani R, 2018, DIS MARKERS, V2018, P0, DOI 10.1155/2018/5174815
   Cera ML, 2013, INT PSYCHOGERIATR, V25, P1679, DOI 10.1017/S1041610213000781
   CHERTKOW H, 1990, BRAIN, V113, P397, DOI 10.1093/brain/113.2.397
   Clark CM, 1996, ALZ DIS ASSOC DIS, V10, P31, DOI 10.1097/00002093-199601010-00006
   Coffey CS, 2008, DRUGS R&D, V9, P229, DOI 10.2165/00126839-200809040-00003
   Costa A, 2017, ALZHEIMERS RES THER, V9, P0, DOI 10.1186/s13195-017-0254-x
   Cummings L, 2019, PRAGMAT SOC, V10, P153, DOI 10.1075/ps.17011.cum
   Ding Y, 2019, RADIOLOGY, V290, P456, DOI 10.1148/radiol.2018180958
   Dodd JW, 2015, ALZHEIMERS RES THER, V7, P0, DOI 10.1186/s13195-015-0116-3
   Ebihara T, 2020, ERJ OPEN RES, V6, P0, DOI 10.1183/23120541.00108-2019
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fuller SJ, 2019, NEURODEGENERATION AND ALZHEIMERS DISEASE: THE ROLE OF DIABETES, V0, P0
   Galvin J., 2020, SCREEN INTERVENE IMP, V0, P0
   Garcia SD, 2020, J ALZHEIMERS DIS, V78, P1547, DOI 10.3233/JAD-200888
   Gaugler J, 2019, ALZHEIMERS DEMENT, V15, P321, DOI 10.1016/j.jalz.2019.01.010
   Ghoniem RM, 2019, LECT NOTES COMPUT SC, V11608, P220, DOI 10.1007/978-3-030-23281-8_18
   Giannakopoulos P, 1998, ARCH NEUROL-CHICAGO, V55, P689, DOI 10.1001/archneur.55.5.689
   Goodglass H., 1983, COOKIE THEFT PICTURE, V0, P0
   Guinjoan S.M., 2021, PERS MED PSYCHIAT, V2021, P100071, DOI 10.1016/j.pmip.2021.100071
   Hariyanto TI, 2021, EUR ARCH PSY CLIN N, V271, P393, DOI 10.1007/s00406-020-01205-z
   Haulcy R, 2021, FRONT PSYCHOL, V11, P0, DOI 10.3389/fpsyg.2020.624137
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Heckman Pim R A, 2017, ADV NEUROBIOL, V17, P135, DOI 10.1007/978-3-319-58811-7_6
   Henriksen K, 2014, ALZHEIMERS DEMENT, V10, P115, DOI 10.1016/j.jalz.2013.01.013
   Holmes RJ, 2000, INT J LANG COMM DIS, V35, P407
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, P0, DOI 10.1002/widm.1312
   HUGHES CP, 1982, BRIT J PSYCHIAT, V140, P566, DOI 10.1192/bjp.140.6.566
   Isaia G, 2020, AM J GERIAT PSYCHIAT, V28, P790, DOI 10.1016/j.archger.2004.04.022
   James HJ, 2020, J ALZHEIMERS DIS, V74, P625, DOI 10.3233/JAD-190922
   Johnen A, 2019, FRONT NEUROL, V10, P0, DOI 10.3389/fneur.2019.00594
   Kalia M, 2003, METABOLISM, V52, P36, DOI 10.1053/S0026-0495(03)00300-6
   Karlekar S., 2018, PROC NAACL, V2, P701
   King DB, 2015, ACS SYM SER, V1214, P1
   Krijnders J., 2017, ENERGY, V400, P500
   Kuo CL, 2020, AGING-US, V12, P12222, DOI 10.18632/aging.103405
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), V0, P109
   Laguarta J, 2020, IEEE OPEN J ENG MED, V1, P275, DOI 10.1109/OJEMB.2020.3026928
   Livingstone SR, 2018, PLOS ONE, V13, P0, DOI 10.1371/journal.pone.0196391
   Luz S, 2020, INTERSPEECH, V0, PP2172, DOI 10.21437/Interspeech.2020-2571
   Lyons J., 2020, JAMESLYONS PYTHON SP, V0, P0
   Lyu G, 2018, 2018 11TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, V0, P0
   Maclin JMA, 2019, GEN PSYCHIAT, V32, P0, DOI 10.1136/gpsych-2019-100054
   Manabe T, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0213825
   Michel A, 2021, J GERIATR PSYCH NEUR, V34, P150, DOI 10.1177/0891988720915519
   MORRIS RG, 1986, Q J EXP PSYCHOL-A, V38, P575, DOI 10.1080/14640748608401615
   Morsy A, 2019, J ALZHEIMERS DIS, V72, PS145, DOI 10.3233/JAD-190744
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Orimaye S.O., 2014, P WORKSHOP COMPUTATI, V0, PP78, DOI 10.3115/V1/W14-3210
   Palmqvist S, 2020, JAMA-J AM MED ASSOC, V324, P772, DOI 10.1001/jama.2020.12134
   Panayotov V, 2015, INT CONF ACOUST SPEE, V0, PP5206, DOI 10.1109/ICASSP.2015.7178964
   Parisot S, 2018, MED IMAGE ANAL, V48, P117, DOI 10.1016/j.media.2018.06.001
   Pawlowski M, 2019, J NEUROL NEUROSUR PS, V90, P562, DOI 10.1136/jnnp-2018-318470
   Pearl Judea., 2018, THE BOOK OF WHY, V0, P0
   Petti U, 2020, J AM MED INFORM ASSN, V27, P1784, DOI 10.1093/jamia/ocaa174
   Pramono RXA, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0162128
   Ralph MAL, 2003, BRAIN, V126, P2350, DOI 10.1093/brain/awg236
   Reed WJ, 2002, PHYS REV E, V66, P0, DOI 10.1103/PhysRevE.66.067103
   Rikkert MGMO, 2011, AM J ALZHEIMERS DIS, V26, P357, DOI 10.1177/1533317511418954
   Sekizawa K, 1996, PULM PHARMACOL THER, V9, P323, DOI 10.1006/pulp.1996.0042
   Severini C, 2016, CURR ALZHEIMER RES, V13, P964, DOI 10.2174/1567205013666160401114039
   Shaw LM, 2009, ANN NEUROL, V65, P403, DOI 10.1002/ana.21610
   Small BJ, 2000, ARCH NEUROL-CHICAGO, V57, P839, DOI 10.1001/archneur.57.6.839
   Song XW, 2011, NEUROLOGY, V77, P227, DOI 10.1212/WNL.0b013e318225c6bc
   Subirana B., 2017, TIME TALK FUTURE BRA, V0, P0
   Subirana B., 2020, ALGORITHMS LAW, V0, P0, DOI DOI 10.1017/9781108347846.010
   Subirana B., 2020, HISIGMA HAVE CORONAV, V0, P0
   Subirana B., 2017, 68 MIT CBMM, V0, P0, DOI DOI 10.21125/edulearn.2017.0672
   Subirana B, 2020, COMMUN ACM, V63, P32, DOI 10.1145/3402193
   Syed MSS, 2020, INTERSPEECH, V0, PP2222, DOI 10.21437/Interspeech.2020-3158
   Wirths O, 2008, GENES BRAIN BEHAV, V7, P1, DOI 10.1111/j.1601-183X.2007.00373.x
   Wise J, 2016, BMJ-BRIT MED J, V353, P0, DOI 10.1136/bmj.i2022
   Won HK, 2018, RESP PHYSIOL NEUROBI, V257, P65, DOI 10.1016/j.resp.2018.01.009
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yu YZ, 2021, GERIATRICS-BASEL, V6, P0, DOI 10.3390/geriatrics6010010
   Yuan JH, 2020, INTERSPEECH, V0, PP2162, DOI 10.21437/Interspeech.2020-2516
   Zetterberg H, 2019, J NEUROSCI METH, V319, P2, DOI 10.1016/j.jneumeth.2018.10.025
   Zunic A, 2020, JMIR MED INF, V8, P34, DOI 10.2196/16023
NR 91
TC 8
Z9 8
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 
EI 2624-9898
J9 FRONT COMP SCI-SWITZ
JI Front. Comput. Sci.-Switz
PD APR 8
PY 2021
VL 3
IS 
BP 
EP 
DI 10.3389/fcomp.2021.624694
PG 12
WC Computer Science, Interdisciplinary Applications
SC Computer Science
GA WE9UP
UT WOS:000705962900001
DA 2023-04-26
ER

