
PT J
AU Manokar, V
   Balaji, R
   Nandhini, VM
   Shankar, S
   Patnaik, LM
AF Manokar, Vigneshwar
   Balaji, R.
   Nandhini, V. M.
   Shankar, S.
   Patnaik, L. M.
TI Wavelet Decomposition and Classification of Diseased fMRI Brain Images Using Self Organized Maps
SO 2020 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATION SYSTEMS (ICACCS)
LA English
DT Proceedings Paper
DE Alzheimers' Diseaase - AD; Pick's disease -PD; Self - Organized Maps - SOM; Artificial Neural Network - ANN; Self - Organized Feature Maps - SOFM; Discrete Wavelet Transform - DWT; Daubechies Wavelet - DW; functional Magnetic Resonance Image- fMRI
ID intracranial compartment volumes
AB There are many solutions for detection and classification and classification of dementia into its corresponding patterns using PET, SPECT, MRT, fMRT addressing to the classification based on the patterns. They are classified based on the corresponding diseased and Non-diseased Syndrome types. Here in this scope, solution anticipated to the inter-related disease with Picks Syndrome (PD) and Alzheimers Disease Syndrome (AD). The image data sets implied her are the functional Magnetic Resonance Images. The images become very contrasting based on many parameters - capturing intensity, noise content, geographical locations, Image acquisition based on the different corporate machines, capability of the Radiologist, the moment during the motion capturing, patient nature, etc., and hence many more features that comes into the account. Ultimately this effects the intensity and the noise level imposed during the motion capturing. A Daubechies Wavelet Transform is implied here. Its properties are: 1) Smoothening filters 2) extraction of frequency (feature) components 3) Median filter - removing the random noises better. A fourth level of extraction of features using the Wavelet Decomposition by Daubechies type was implied for formation of the feature vectors. From the sub-band regions of H-H level order with fourth level of decomposition level which will have high resolution was chosen for this act. Other have low-high combinatory, and fourth band has low - low combination which are very difficult to pick up the resolution points. This obtained features were implied for feature vector formation. The extraction of the features was obtained from the approximated co-efficients got from the Approximated sub-band levels thus chosen to form the input images and extracted co-efficients were fed to design, train and test the network for convergence, network framing and efficiency estimation respectively. A Self Organizing Map technique was chosen for designing up of the network using the Competitive Neural Network. This was used to classify the normal and Dementia based image types into its corresponding types. This enables a good proviso for designing up of the network and also provides efficiency in convergence of the network, classification of the two types of diseases and also in classification of the disease types into its individual inter dependent types such as Demential and Non-Demential types.
C1 [Manokar, Vigneshwar] IIPS India, Mumbai, Maharashtra, India.
   [Balaji, R.] SriKrishna Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Balaji, R.] Anna Univ, Chennai, Tamil Nadu, India.
   [Nandhini, V. M.] Bharath Corp, R&D Bharath Labs, Coimbatore, Tamil Nadu, India.
   [Shankar, S.; Patnaik, L. M.] Hindusthan Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   Natl Inst Adv Studies, Consciousness Studies Program, IISc Campus, Bangalore, Karnataka, India.
C3 International Institute for Population Sciences; Sri Krishna College of Engineering & Technology; Anna University; Anna University Chennai
RP Shankar, S (corresponding author), Hindusthan Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM shanx80@gmail.com
CR Balaji R., 2018, JOUR ADV RES DYNAMIC, V10, P0
   Dinesh E, 2013, 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2013), V0, PP405, DOI 10.1109/ISCO.2013.6481189
   Fan Y, 2002, IEEE T MED IMAGING, V21, P904, DOI 10.1109/TMI.2002.803126
   FRENOUX Emmanuelle, 2001, P 23 ANN C IEEE EMBS, V0, P0
   Gonzalez R.C., 2003, DIGITAL IMAGE PROCES, V0, P0
   Haykins Simon, 1999, COMPETITIVE LEARNING, V0, P0
   Jensen A, 2001, RIPPLES MATH DISCRET, V0, P0
   Kontos Despina, 2004, P SPIE, V5370, P0
   Kumar AD, 2014, ADV INTELL SYST, V248, P49, DOI 10.1007/978-3-319-03107-1_6
   Kumar AD, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), V0, PP549, DOI 10.1109/HIS.2012.6421393
   Li Y., 2005, INT J INFORM TECHNOL, V11, P0
   Manokar Vigneshwar, 2012, P 2012 2 IEEE INT C, V0, P0
   Matsumae M, 1996, J NEUROSURG, V84, P972, DOI 10.3171/jns.1996.84.6.0972
   Matsumae M, 1996, J NEUROSURG, V84, P982, DOI 10.3171/jns.1996.84.6.0982
   Pollikar Robi, 2001, FUNDAMENTAL CONCEPTS, V0, P0
   Unser M, 2003, IEEE T MED IMAGING, V22, P285, DOI 10.1109/TMI.2003.809638
   Walker James S., 2000, PRIMER WAVELETS THEI, V0, P0
   Warfield S, 1995, J IMAGE GUID SURG, V1, P326, DOI 10.1002/(SICI)1522-712X(1995)1:6<326::AID-IGS4>3.0.CO;2-C
   Zhang Jinxing, 2005, J COMMUNICATION COMP, V2, P0
NR 19
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2469-5556
EI 
J9 INT CONF ADVAN COMPU
PD JUN 15
PY 2020
VL 0
IS 
BP 1342
EP 1348
DI 
PG 7
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA BP9RJ
UT WOS:000570722600271
DA 2023-04-26
ER

PT J
AU Anwar, K
   Deshmukh, S
AF Anwar, Khalid
   Deshmukh, Sandip
TI Parametric study for the prediction of wind energy potential over the southern part of India using neural network and geographic information system approach
SO PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART A-JOURNAL OF POWER AND ENERGY
LA English
DT Article
DE Wind energy potential; artificial neural network; geographic information system approach; modeling; India
ID weibull
AB Wind energy potential in India has so far not been evaluated state wise. Moreover, the prediction and assessment of wind potential are difficult due to the complexity of its nature. Here, a parametric study is done for the better prediction of wind potential using generalized feed-forward with back-propagation neural networks. Effect of three meteorological parameters (pressure, relative humidity, and temperature) on the wind speed prediction is studied in southern states of India. The meteorological parameters taken here are monthly mean, measured at ground station. These data were obtained at 28 sites over a period of 20 years from the IMD, Pune. Three different architectures of artificial neural network model were designed, trained, and evaluated for the prediction of wind speed. All three models have been optimized for varying neurons in the hidden layer. To evaluate the developed artificial neural network model for test locations, mean absolute percentage error and mean squared error have been calculated. It was found that the model with relative humidity as input parameter and having six neurons in the hidden layer give better prediction of the wind speed. The correlation coefficients were higher than 0.96 and the mean absolute percentage error and mean squared error of all test locations is less than 2.5 and 0.0176, respectively, which show high reliability of the model for the prediction of the wind speed within the region of study. Predicted wind speed has been analyzed and used to create monthly mean maps using geographic information system technology.
C1 [Anwar, Khalid; Deshmukh, Sandip] BITS Pilani Hyderabad, Dept Mech Engn, Hyderabad Campus, Hyderabad, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Anwar, K (corresponding author), BITS Pilani Hyderabad, Dept Mech Engn, Birla Inst Technol & Sci, Hyderabad Campus, Hyderabad 500078, Telangana, India.
EM khalid@hyderabad.bits-pilani.ac.in
CR Akpinar EK, 2004, P I MECH ENG A-J POW, V218, P557, DOI 10.1243/0957650042584357
   Anwar K, 2018, INT J RENEW ENERGY R, V8, P974
   Bekele G, 2009, APPL ENERG, V86, P388, DOI 10.1016/j.apenergy.2008.05.012
   Celik AN, 2013, APPL ENERG, V101, P582, DOI 10.1016/j.apenergy.2012.06.040
   Chock GYK, 2005, J WIND ENG IND AEROD, V93, P623, DOI 10.1016/j.jweia.2005.06.002
   Elhadidy M, 2000, RENEW ENERG, V21, P129, DOI 10.1016/S0960-1481(00)00040-9
   Evans A, 2009, RENEW SUST ENERG REV, V13, P1082, DOI 10.1016/j.rser.2008.03.008
   Fadare DA, 2009, APPL ENERG, V86, P1410, DOI 10.1016/j.apenergy.2008.12.005
   Foley AM, 2012, RENEW ENERG, V37, P1, DOI 10.1016/j.renene.2011.05.033
   Gastli A, 2010, RENEW SUST ENERG REV, V14, P790, DOI 10.1016/j.rser.2009.08.018
   Genc A, 2005, ENERG SOURCE, V27, P809, DOI 10.1080/00908310490450647
   Janjai S, 2014, J WIND ENG IND AEROD, V129, P1, DOI 10.1016/j.jweia.2014.03.010
   Jimenez PA, 2012, J APPL METEOROL CLIM, V51, P300, DOI 10.1175/JAMC-D-11-084.1
   Kalogirou SA, 2001, RENEW SUST ENERG REV, V5, P373, DOI 10.1016/S1364-0321(01)00006-5
   Mabel MC, 2008, RENEW ENERG, V33, P986, DOI 10.1016/j.renene.2007.06.013
   Maharani YN, 2009, 7 ASIA PACIFIC C WIN, V0, P0
   Mathew S, 2002, RENEW ENERG, V25, P381, DOI 10.1016/S0960-1481(01)00063-5
   Mellit A, 2008, PROG ENERG COMBUST, V34, P574, DOI 10.1016/j.pecs.2008.01.001
   Ministry of Power India, 2012, ANN REPORT, V0, P0
   Ohunakin OS, 2012, ENERGY SUSTAIN DEV, V16, P78, DOI 10.1016/j.esd.2011.10.004
   Qahwaji R, 2007, SOL PHYS, V241, P195, DOI 10.1007/s11207-006-0272-5
   Ramachandra TV, 2005, ENERG CONVERS MANAGE, V46, P1561, DOI 10.1016/j.enconman.2004.07.009
   Ramirez-Rosado IJ, 2009, RENEW ENERG, V34, P1848, DOI 10.1016/j.renene.2008.11.014
   Riahy GH, 2008, RENEW ENERG, V33, P35, DOI 10.1016/j.renene.2007.01.014
   Sathyajith M, 2006, WIND ENERGY FUNDAMEN, V0, P0
   Sozen A, 2004, APPL ENERG, V77, P273, DOI 10.1016/S0306-2619(03)00137-5
   Thran D, 2010, ENERGY SUSTAIN DEV, V14, P200, DOI 10.1016/j.esd.2010.07.004
NR 27
TC 14
Z9 14
U1 0
U2 15
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0957-6509
EI 2041-2967
J9 P I MECH ENG A-J POW
JI Proc. Inst. Mech. Eng. Part A-J. Power Energy
PD FEB 15
PY 2020
VL 234
IS 1
BP 96
EP 109
DI 10.1177/0957650919848960
PG 14
WC Thermodynamics; Engineering, Mechanical
SC Thermodynamics; Engineering
GA JP2AO
UT WOS:000498072900008
DA 2023-04-26
ER

PT J
AU Wen, CC
   Yang, LN
   Li, X
   Peng, L
   Chi, TH
AF Wen, Congcong
   Yang, Lina
   Li, Xiang
   Peng, Ling
   Chi, Tianhe
TI Directionally constrained fully convolutional neural network for airborne LiDAR point cloud classification
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Airborne LiDAR; Point cloud classification; Directionlly constrained nearest neighbor; Fully convolution networks; ISPRS 3D labeling
ID contextual classification
AB Point cloud classification plays an important role in a wide range of airborne light detection and ranging (LiDAR) applications, such as topographic mapping, forest monitoring, power line detection, and road detection. However, due to the sensor noise, high redundancy, incompleteness, and complexity of airborne LiDAR systems, point cloud classification is challenging. Traditional point cloud classification methods mostly focus on the development of handcrafted point geometry features and employ machine learning-based classification models to conduct point classification. In recent years, the advances of deep learning models have caused researchers to shift their focus towards machine learning-based models, specifically deep neural networks, to classify airborne LiDAR point clouds. These learning-based methods start by transforming the unstructured 3D point sets to regular 2D representations, such as collections of feature images, and then employ a 2D CNN for point classification. Moreover, these methods usually need to calculate additional local geometry features, such as planarity, sphericity and roughness, to make use of the local structural information in the original 3D space. Nonetheless, the 3D to 2D conversion results in information loss. In this paper, we propose a directionally constrained fully convolutional neural network (D-FCN) that can take the original 3D coordinates and LiDAR intensity as input; thus, it can directly apply to unstructured 3D point clouds for semantic labeling. Specifically, we first introduce a novel directionally constrained point convolution (D-Conv) module to extract locally representative features of 3D point sets from the projected 2D receptive fields. To make full use of the orientation information of neighborhood points, the proposed D-Conv module performs convolution in an orientation-aware manner by using a directionally constrained nearest neighborhood search. Then, we design a multiscale fully convolutional neural network with downsampling and upsampling blocks to enable multiscale point feature learning. The proposed D-FCN model can therefore process input point cloud with arbitrary sizes and directly predict the semantic labels for all the input points in an end-to-end manner. Without involving additional geometry features as input, the proposed method demonstrates superior performance on the International Society for Photogrammetry and Remote Sensing (ISPRS) 3D labeling benchmark dataset. The results show that our model achieves a new stateof-the-art performance on powerline, car, and facade categories. Moreover, to demonstrate the generalization abilities of the proposed method, we conduct further experiments on the 2019 Data Fusion Contest Dataset. Our proposed method achieves superior performance than the comparing methods and accomplishes an overall accuracy of 95.6% and an average F1 score of 0.810.
C1 [Wen, Congcong; Yang, Lina; Li, Xiang; Peng, Ling; Chi, Tianhe] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
   [Wen, Congcong; Yang, Lina; Li, Xiang; Peng, Ling; Chi, Tianhe] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wen, Congcong; Li, Xiang] NYU, Tandon Sch Engn, New York, NY USA.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; New York University; New York University Tandon School of Engineering
RP Li, X (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
EM xl1845@nyu.edu
CR Andersen HE, 2005, REMOTE SENS ENVIRON, V94, P441, DOI 10.1016/j.rse.2004.10.013
   [Anonymous], 2006, INT ARCH PHOTOGRAMME, V0, P0, DOI DOI 10.1111/1750-3841.12802
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   [Anonymous], 2000, INT ARCH PHOTOGRAMME, V0, P0
   [Anonymous], 2009, ISPRS ARCH PHOTOGRAM, V0, P0
   Arief HA, 2019, ISPRS J PHOTOGRAMM, V155, P90, DOI 10.1016/j.isprsjprs.2019.07.002
   Babahajiani P, 2017, MACH VISION APPL, V28, P679, DOI 10.1007/s00138-017-0845-3
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Collobert R., 2008, P 25 INT C MACHINE L, V0, P0
   Cramer M, 2010, PHOTOGRAMM FERNERKUN, V0, PP73, DOI 10.1127/1432-8364/2010/0041
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Ene LT, 2017, REMOTE SENS ENVIRON, V188, P106, DOI 10.1016/j.rse.2016.10.046
   Hermosilla P, 2018, ACM T GRAPHIC, V37, P0, DOI 10.1145/3272127.3275110
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horvat D, 2016, ISPRS J PHOTOGRAMM, V116, P1, DOI 10.1016/j.isprsjprs.2016.02.011
   Hu Q., 2019, ARXIV191111236, V0, P0
   Jiang Mingyang, 2018, ABS180700652 CORR, V0, P0
   Kada M., 2009, INT ARCH PHOTOGRAMME, V38, P0
   Klokov R, 2017, IEEE I CONF COMP VIS, V0, PP863, DOI 10.1109/ICCV.2017.99
   Lalonde JF, 2006, J FIELD ROBOT, V23, P839, DOI 10.1002/rob.20134
   Lalonde JF, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, V0, P285, DOI 10.1109/3DIM.2005.71
   Li JX, 2018, PROC CVPR IEEE, V0, PP9397, DOI 10.1109/CVPR.2018.00979
   Li X, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON MANAGEMENT ENGINEERING, V0, P135, DOI 10.1145/3312662.3312694
   Li X, 2016, ENVIRON SCI POLLUT R, V23, P22408, DOI 10.1007/s11356-016-7812-9
   Li YY, 2018, ADV NEUR IN, V31, P0
   Lodha SK, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, V0, P435
   Masko D., 2015, IMPACT IMBALANCED TR, V0, P0
   Mongus D, 2014, IEEE J-STARS, V7, P340, DOI 10.1109/JSTARS.2013.2262996
   Munoz D, 2009, PROC CVPR IEEE, V0, PP975, DOI 10.1109/CVPRW.2009.5206590
   Niemeyer J, 2016, INT ARCH PHOTOGRAMM, V41, P655, DOI 10.5194/isprsarchives-XLI-B3-655-2016
   NIEMEYER J., 2012, 22 ISPRS C TECHN COM, VIII, P263, DOI 10.5194/isprsannals-I-3-263-2012
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Qi CR, 2017, ADV NEUR IN, V30, P0
   Qi CR, 2016, PROC CVPR IEEE, V0, PP5648, DOI 10.1109/CVPR.2016.609
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen YR, 2018, PROC CVPR IEEE, V0, PP4548, DOI 10.1109/CVPR.2018.00478
   Solberg S, 2009, REMOTE SENS ENVIRON, V113, P2317, DOI 10.1016/j.rse.2009.06.010
   Su H, 2015, IEEE I CONF COMP VIS, V0, PP945, DOI 10.1109/ICCV.2015.114
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Vosselman G, 2017, ISPRS J PHOTOGRAMM, V128, P354, DOI 10.1016/j.isprsjprs.2017.03.010
   Wang SL, 2018, PROC CVPR IEEE, V0, PP2589, DOI 10.1109/CVPR.2018.00274
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Weinmann M, 2015, ISPRS ANN PHOTO REM, V2-3, P271, DOI 10.5194/isprsannals-II-3-W4-271-2015
   Weinmann M, 2015, ISPRS J PHOTOGRAMM, V105, P286, DOI 10.1016/j.isprsjprs.2015.01.016
   Wen CC, 2019, SCI TOTAL ENVIRON, V654, P1091, DOI 10.1016/j.scitotenv.2018.11.086
   Yang BS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010014
   Yang B, 2018, BMC CARDIOVASC DISOR, V18, P0, DOI 10.1186/s12872-018-0743-2
   Yang ZS, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090936
   Yousefhussien M, 2018, ISPRS J PHOTOGRAMM, V143, P191, DOI 10.1016/j.isprsjprs.2018.03.018
   Zhang JX, 2013, REMOTE SENS-BASEL, V5, P3749, DOI 10.3390/rs5083749
   Zhang S, 2018, I S BIOMED IMAGING, V0, P1
   Zhao KG, 2009, REMOTE SENS ENVIRON, V113, P1628, DOI 10.1016/j.rse.2009.03.006
   Zhao RB, 2018, INT J GEOGR INF SCI, V32, P960, DOI 10.1080/13658816.2018.1431840
   Zhu Q, 2017, ISPRS J PHOTOGRAMM, V129, P86, DOI 10.1016/j.isprsjprs.2017.04.022
NR 56
TC 55
Z9 60
U1 10
U2 55
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2020
VL 162
IS 
BP 50
EP 62
DI 10.1016/j.isprsjprs.2020.02.004
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA LF9BW
UT WOS:000527709200005
DA 2023-04-26
ER

PT J
AU Wang, N
   Xue, J
   Peng, J
   Biswas, A
   He, Y
   Shi, Z
AF Wang, Nan
   Xue, Jie
   Peng, Jie
   Biswas, Asim
   He, Yong
   Shi, Zhou
TI Integrating Remote Sensing and Landscape Characteristics to Estimate Soil Salinity Using Machine Learning Methods: A Case Study from Southern Xinjiang, China
SO REMOTE SENSING
LA English
DT Article
DE soil salinity; remote sensing; machine learning; predictive mapping
ID agricultural soils; sentinel-2 msi; wet seasons; vegetation; model; mesopotamia; technology; prediction; parameters; regression
AB Soil salinization, one of the most severe global land degradation problems, leads to the loss of arable land and declines in crop yields. Monitoring the distribution of salinized soil and degree of salinization is critical for management, remediation, and utilization of salinized soil; however, there is a lack of thorough assessment of various data sources including remote sensing and landscape characteristics for estimating soil salinity in arid and semi-arid areas. The overall goal of this study was to develop a framework for estimating soil salinity in diverse landscapes by fusing information from satellite images, landscape characteristics, and appropriate machine learning models. To explore the spatial distribution of soil salinity in southern Xinjiang, China, as a case study, we obtained 151 soil samples in a field campaign, which were analyzed in laboratory for soil electrical conductivity. A total of 35 indices including remote sensing classifiers (11), terrain attributes (3), vegetation spectral indices (8), and salinity spectral indices (13) were calculated or derived and correlated with soil salinity. Nine were used to model and estimate soil salinity using four predictive modelling approaches: partial least squares regression (PLSR), convolutional neural network (CNN), support vector machine (SVM) learning, and random forest (RF). Testing datasets were divided into vegetation-covered and bare soil samples and were used for accuracy assessment. The RF model was the best regression model in this study, with R-2 = 0.75, and was most effective in revealing the spatial characteristics of salt distribution. Importance analysis and path modeling of independent variables indicated that environmental factors and soil salinity indices including digital elevation model (DEM), B10, and green atmospherically resistant vegetation index (GARI) showed the strongest contribution in soil salinity estimation. This showed a great promise in the measurement and monitoring of soil salinity in arid and semi-arid areas from the integration of remote sensing, landscape characteristics, and using machine learning model.
C1 [Wang, Nan; Xue, Jie; Shi, Zhou] Zhejiang Univ, Coll Environm & Resource Sci, Inst Agr Remote Sensing & Informat Technol Applic, Hangzhou 310058, Peoples R China.
   [Peng, Jie] Tarim Univ, Coll Plant Sci, Alar 843300, Peoples R China.
   [Biswas, Asim] Univ Guelph, Sch Environm Sci, Guelph, ON N1G 2W1, Canada.
   [He, Yong] Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310058, Peoples R China.
   [Shi, Zhou] Minist Agr, Key Lab Spect Sensing, Hangzhou 310058, Peoples R China.
C3 Zhejiang University; Tarim University; University of Guelph; Zhejiang University; Ministry of Agriculture & Rural Affairs
RP Shi, Z (corresponding author), Zhejiang Univ, Coll Environm & Resource Sci, Inst Agr Remote Sensing & Informat Technol Applic, Hangzhou 310058, Peoples R China.; Shi, Z (corresponding author), Minist Agr, Key Lab Spect Sensing, Hangzhou 310058, Peoples R China.
EM wangnanfree@zju.edu.cn; xj2019@zju.edu.cn; 11414049@zju.edu.cn; biswas@uoguelph.ca; yhe@zju.edu.cn; shizhou@zju.edu.cn
FU National Key Research and Development Program [2018YFE0107000]; Young and Middle-aged Innovative Talents Program of Xinjiang production and Construction Crops [2020CB032]
CR Abbas A, 2007, MODSIM 2007: INTERNATIONAL CONGRESS ON MODELLING AND SIMULATION, V0, P2632
   Alexakis DD, 2018, GEOCARTO INT, V33, P321, DOI 10.1080/10106049.2016.1250826
   Alifu H, 2020, GEOMORPHOLOGY, V369, P0, DOI 10.1016/j.geomorph.2020.107365
   Alonso-Monsalve S, 2020, EXPERT SYST APPL, V149, P0, DOI 10.1016/j.eswa.2020.113250
   Bai L, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18113855
   Bannari A, 2008, COMMUN SOIL SCI PLAN, V39, P2795, DOI 10.1080/00103620802432717
   Cheng JL, 2007, J ENVIRON SCI-CHINA, V19, P50, DOI 10.1016/S1001-0742(07)60008-4
   Chi Y, 2019, ECOL INDIC, V107, P0, DOI 10.1016/j.ecolind.2019.105517
   Dakak H, 2017, SOIL USE MANAGE, V33, P553, DOI 10.1111/sum.12370
   Danks NP, 2020, J BUS RES, V113, P13, DOI 10.1016/j.jbusres.2020.03.019
   Davis E, 2019, INT J REMOTE SENS, V40, P6134, DOI 10.1080/01431161.2019.1587205
   Ding JL, 2014, GEODERMA, V235, P316, DOI 10.1016/j.geoderma.2014.07.028
   Douaoui AEK, 2006, GEODERMA, V134, P217, DOI 10.1016/j.geoderma.2005.10.009
   El Hajj M, 2016, REMOTE SENS ENVIRON, V176, P202, DOI 10.1016/j.rse.2016.01.027
   Fathizad H, 2020, GEODERMA, V365, P0, DOI 10.1016/j.geoderma.2020.114233
   Fernandez-Buces N, 2006, J ARID ENVIRON, V65, P644, DOI 10.1016/j.jaridenv.2005.08.005
   Gitelson AA, 1996, REMOTE SENS ENVIRON, V58, P289, DOI 10.1016/S0034-4257(96)00072-7
   Goel N., 1994, REMOTE SENSING REV, V10, P309, DOI 10.1080/02757259409532252
   Gorji T, 2020, ECOL INDIC, V112, P0, DOI 10.1016/j.ecolind.2020.106173
   Gorji T, 2017, ECOL INDIC, V74, P384, DOI 10.1016/j.ecolind.2016.11.043
   Henseler J, 2016, IND MANAGE DATA SYST, V116, P2, DOI 10.1108/IMDS-09-2015-0382
   Hu J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070736
   Huang J, 2017, SCI TOTAL ENVIRON, V577, P395, DOI 10.1016/j.scitotenv.2016.10.224
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2
   Ivushkin K, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111260
   Jenny H., 1941, FACTORS SOIL FORMATI, V0, P0, DOI DOI 10.1097/00010694-194111000-00009
   Jiang QS, 2019, SCI TOTAL ENVIRON, V682, P190, DOI 10.1016/j.scitotenv.2019.05.037
   Kumar K, 2012, HYDROLOG SCI J, V57, P776, DOI 10.1080/02626667.2012.678583
   Liu Y, 2019, GEODERMA, V354, P0, DOI 10.1016/j.geoderma.2019.113887
   Ma LG, 2018, LAND DEGRAD DEV, V29, P551, DOI 10.1002/ldr.2890
   Ma LG, 2017, GEODERMA, V305, P1, DOI 10.1016/j.geoderma.2017.05.016
   Ma XL, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17040818
   Ma ZQ, 2018, IEEE GEOSCI REMOTE S, V15, P178, DOI 10.1109/LGRS.2017.2779127
   Masoud AA, 2019, INT J APPL EARTH OBS, V83, P0, DOI 10.1016/j.jag.2019.101944
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   Mulder VL, 2011, GEODERMA, V162, P1, DOI 10.1016/j.geoderma.2010.12.018
   Muller E, 2001, REMOTE SENS ENVIRON, V76, P173, DOI 10.1016/S0034-4257(00)00198-X
   Nouri H, 2018, SUSTAINABILITY-BASEL, V10, P0, DOI 10.3390/su10082826
   Nurmemet I, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040598
   Oliveira CF, 2019, SCI TOTAL ENVIRON, V697, P0, DOI 10.1016/j.scitotenv.2019.134081
   Pan L, 2016, J STAT PLAN INFER, V177, P1, DOI 10.1016/j.jspi.2014.10.003
   Patel NR, 2022, GEOCARTO INT, V37, P179, DOI 10.1080/10106049.2019.1704074
   Peng J, 2019, GEODERMA, V337, P1309, DOI 10.1016/j.geoderma.2018.08.006
   Peng J, 2016, BIOSYST ENG, V152, P94, DOI 10.1016/j.biosystemseng.2016.04.015
   Hoa PV, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020128
   Qiu S, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.05.024
   Racetin I, 2020, ECOL INDIC, V110, P0, DOI 10.1016/j.ecolind.2019.105924
   Ren DY, 2019, GEODERMA, V356, P0, DOI 10.1016/j.geoderma.2019.113935
   Sabri E, 2018, E3S WEB CONF, V37, P0, DOI 10.1051/e3sconf/20183704002
   Fernandes LFS, 2018, SCI TOTAL ENVIRON, V626, P1069, DOI 10.1016/j.scitotenv.2018.01.127
   Schuberth F, 2020, IND MANAGE DATA SYST, V120, P2211, DOI 10.1108/IMDS-12-2019-0642
   Scudiero E., 2014, GEODERMA REG, V2-3, P82, DOI 10.1016/j.geodrs.2014.10.004
   Scudiero E, 2015, REMOTE SENS ENVIRON, V169, P335, DOI 10.1016/j.rse.2015.08.026
   Shahabi M, 2017, ARCH AGRON SOIL SCI, V63, P151, DOI 10.1080/03650340.2016.1193162
   Shi Z, 2006, PEDOSPHERE, V16, P154, DOI 10.1016/S1002-0160(06)60038-6
   Sultanov M, 2018, PFG-J PHOTOGRAMM REM, V86, P221, DOI 10.1007/s41064-019-00062-3
   Sun N, 2018, J APPL REMOTE SENS, V12, P0, DOI 10.1117/1.JRS.12.036018
   Taghadosi MM, 2019, INT J REMOTE SENS, V40, P237, DOI 10.1080/01431161.2018.1512767
   Taghizadeh-Mehrjardi R, 2014, GEODERMA, V213, P15, DOI 10.1016/j.geoderma.2013.07.020
   Thiam S, 2019, LAND USE POLICY, V88, P0, DOI 10.1016/j.landusepol.2019.104191
   Vermeulen D, 2017, GEODERMA, V299, P1, DOI 10.1016/j.geoderma.2017.03.013
   Wang F, 2020, GEODERMA, V365, P0, DOI 10.1016/j.geoderma.2020.114211
   Wang JZ, 2020, SCI TOTAL ENVIRON, V707, P0, DOI 10.1016/j.scitotenv.2019.136092
   Wang JZ, 2019, GEODERMA, V353, P172, DOI 10.1016/j.geoderma.2019.06.040
   Wang JZ, 2018, PEERJ, V6, P0, DOI 10.7717/peerj.4703
   Wang XP, 2018, SCI TOTAL ENVIRON, V615, P918, DOI 10.1016/j.scitotenv.2017.10.025
   Wicke B, 2011, ENERG ENVIRON SCI, V4, P2669, DOI 10.1039/c1ee01029h
   Wu WC, 2019, ENVIRON RES COMMUN, V1, P0, DOI 10.1088/2515-7620/ab37f0
   Wu WC, 2018, LAND DEGRAD DEV, V29, P4005, DOI 10.1002/ldr.3148
   Wu WC, 2014, IEEE J-STARS, V7, P4442, DOI 10.1109/JSTARS.2014.2360411
   Xu HT, 2020, INT J REMOTE SENS, V41, P4470, DOI 10.1080/01431161.2020.1718239
   Yang RM, 2019, IEEE J-STARS, V12, P1482, DOI 10.1109/JSTARS.2019.2906064
   Yu H, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18041048
   Zhang LL, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18082675
   Zhang TT, 2015, ECOL INDIC, V52, P480, DOI 10.1016/j.ecolind.2015.01.004
   Zhang XG, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-41470-0
   Zhou Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12010085
   Zhu LJ, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111237
NR 78
TC 26
Z9 26
U1 21
U2 93
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 15
PY 2020
VL 12
IS 24
BP 
EP 
DI 10.3390/rs12244118
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PL5XY
UT WOS:000603195700001
DA 2023-04-26
ER

PT J
AU Persello, C
   Kuffer, M
AF Persello, Claudio
   Kuffer, Monika
TI TOWARDS UNCOVERING SOCIO-ECONOMIC INEQUALITIES USING VHR SATELLITE IMAGES AND DEEP LEARNING
SO IGARSS 2020 - 2020 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM
LA English
DT Proceedings Paper
DE urban deprivation; slums; deep learning; convolutional neural networks; remote sensing
AB In many cities of the Global South, informal and deprived neighborhoods, also commonly called slums, continue to proliferate, but their locations and dwellers' socio-economic status are often invisible in official statistics and maps. Very high resolution (VHR) satellite images coupled with deep learning allow us to efficiently map these areas and study their socio-economic and spatio-temporal variability to support interventions. This paper investigates a deep transfer learning approach based on convolutional neural networks (CNN) to identify the socio-economic variability of poor neighborhoods in Bangalore, India. Our deep network, pretrained on a slum classification data set, is tuned towards the prediction of a continuous-valued socio-economic index capturing multiple levels of deprivation. Experimental results show that the CNN-based regression model can explain the socio-economic variability with an R-2 of 0.75. The use of additional publicly available geographic information layers allow us to spatially extend the analysis beyond the surveyed deprived area data samples to uncover city-wide patterns of socio-economic inequalities.
C1 [Persello, Claudio; Kuffer, Monika] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
C3 University of Twente
RP Persello, C (corresponding author), Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
CR Ajami A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11111282
   Baud I., 2008, URBAN STUD, V45, P1385
   Ella L. P. A., 2008, INT GEOSC REM SENS S, V3, P0
   Kuffer M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060455
   Kuffer M, 2016, IEEE J-STARS, V9, P1830, DOI 10.1109/JSTARS.2016.2538563
   Lilford R, 2019, BMJ GLOB HEALTH, V4, P0, DOI 10.1136/bmjgh-2018-001267
   Liu RY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232844
   Mahabir R, 2020, INT J DIGIT EARTH, V13, P683, DOI 10.1080/17538947.2018.1554010
   Mboga N, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9111106
   Moser CON, 1998, WORLD DEV, V26, P1, DOI 10.1016/S0305-750X(97)10015-8
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Simonyan K, 2015, ARXIV, V0, P0
NR 12
TC 5
Z9 5
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2153-6996
EI 
J9 INT GEOSCI REMOTE SE
PD JUN 15
PY 2020
VL 0
IS 
BP 3747
EP 3750
DI 10.1109/IGARSS39084.2020.9324399
PG 4
WC Computer Science, Artificial Intelligence; Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Optics
SC Computer Science; Environmental Sciences & Ecology; Geology; Remote Sensing; Optics
GA BR6WH
UT WOS:000664335303181
DA 2023-04-26
ER
