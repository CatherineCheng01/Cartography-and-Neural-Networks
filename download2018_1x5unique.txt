
PT J
AU Khanal, S
   Fulton, J
   Klopfenstein, A
   Douridas, N
   Shearer, S
AF Khanal, Sami
   Fulton, John
   Klopfenstein, Andrew
   Douridas, Nathan
   Shearer, Scott
TI Integration of high resolution remotely sensed data and machine learning techniques for spatial prediction of soil properties and corn yield
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
LA English
DT Article
DE Remote sensing; Soil; DEM; Yield; Mapping
ID artificial neural-networks; organic-carbon; regression
AB Widespread adoption of precision agriculture requires timely acquisition of low-cost, high quality soil and crop yield maps. Integration of remotely sensed data and machine learning algorithms offers cost-and time-effective approach for spatial prediction of soil properties and crop yield compared to conventional approaches. The objectives of this study were to: (i) evaluate the role of remotely sensed images; (ii) compare the performance of various machine learning algorithms; and (iii) identify the importance of remotely sensed image-derived variables, in spatial prediction of soil properties and corn yield. This study integrated field based data on five soil properties (i.e., soil organic matter (SOM), cation exchange capacity (CEC), magnesium (Mg), potassium (K), and pH) and yield monitor based corn yield data with multispectral aerial images and topographic data, both collected in 2013, from seven fields at the Molly Caren Farm near London, Ohio. Digital elevation model data, at a resolution of 1 m, was used to derive topographic properties of the fields. Multispectral images collected at bare-soil conditions, at a resolution 0.30 m, were used to derive soil and vegetation indices. Models developed for prediction of soil properties and corn yield using linear regression (LM) and five machine learning algorithms (i.e., Random Forest (RF); Neural Network (NN); Support Vector Machine (SVM) with radial and linear kernel functions; Gradient Boosting Model (GBM); and Cubist (CU)) were evaluated in terms of coefficient of determination (R-2) and root mean square error (RMSE). Machine learning algorithms were found to outperform LM algorithm for most of the times with a higher R-2 and lower RMSE. Based on models for seven fields, on average, NN provided the highest accuracy for SOM (R-2 = 0.64, RMSE = 0.44) and CEC (R-2 = 0.67, RMSE = 2.35); SVM for K (R-2 = 0.21, RMSE = 0.49) and Mg (R-2 = 0.22, RMSE = 4.57); and GBM for pH (R-2 = 0.15, RMSE = 0.62). For corn yield, RF consistently outperformed other models and provided higher accuracy (R-2 = 0.53, RMSE = 0.97). Soil and vegetation indices based on bare-soil imagery played a more significant role in demonstrating in-field variability of corn yield and soil properties than topographic variables. The accuracy of the models developed for prediction of soil properties and corn yield observed in this study suggested that the approach of integrating remotely sensed data and machine learning algorithms are promising for mapping soil properties and corn yield at a local scale, which can be useful in locating areas of potential concerns and implementing site-specific farming practices.
C1 [Khanal, Sami] Ohio State Univ, Dept Food Agr & Biol Engn, Wooster, OH 44691 USA.
   [Fulton, John; Klopfenstein, Andrew; Shearer, Scott] Ohio State Univ, Dept Food Agr & Biol Engn, Columbus, OH 43210 USA.
   [Douridas, Nathan] Ohio State Univ, Farm Sci Review, London, OH 43140 USA.
C3 University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University
RP Khanal, S (corresponding author), Ohio State Univ, Dept Food Agr & Biol Engn, Wooster, OH 44691 USA.
EM Khanal.3@osu.edu
FU Ohio State University- the Field to Faucet program [F2F-000004]; Ohio Agricultural Research and Development Center (OARDC) (SEEDS: the OARDC Research Enhancement Competitive Grants Program)
CR Allen DE, 2013, SOIL RES, V51, P695, DOI 10.1071/SR13041
   Barnes EM, 2000, APPL ENG AGRIC, V16, P731
   Blasch G, 2015, REMOTE SENS-BASEL, V7, P11125, DOI 10.3390/rs70911125
   Chang YK, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0160478
   Davy MC, 2013, SOIL RES, V51, P631, DOI 10.1071/SR12353
   Dobos E., 2001, INT J APPL EARTH OBS, V3, P30, DOI 10.1016/S0303-2434(01)85019-4
   Escadafal R., 1993, INT ARCH PHOTOGRAMME, V29, P709
   Forkuor G, 2017, PLOS ONE, V12, P0, DOI 10.1371/journal.pone.0170478
   Geipel J, 2014, REMOTE SENS-BASEL, V6, P10335, DOI 10.3390/rs61110335
   Hahn C, 2008, NONLINEAR PROC GEOPH, V15, P115, DOI 10.5194/npg-15-115-2008
   Hively W. D., 2011, APPLIED AND ENVIRONMENTAL SOIL SCIENCE, V2011, P358193, DOI 10.1155/2011/358193
   HUETE AR, 1991, INT J REMOTE SENS, V12, P1223, DOI 10.1080/01431169108929723
   Kitchingman A., 2004, CTR RES REP, V0, P7
   Kuhn M, 2013, APPL PREDICTIVE MODE, V0, P0, DOI DOI 10.1007/978-1-4614-6849-3
   Kuhn M., 2017, CARET CLASSIFICATION, V0, P0
   Liess M, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0153673
   Lobell DB, 2015, REMOTE SENS ENVIRON, V164, P324, DOI 10.1016/j.rse.2015.04.021
   Lyle G, 2014, PRECIS AGRIC, V15, P377, DOI 10.1007/s11119-013-9336-3
   Minasny B, 2008, CHEMOMETR INTELL LAB, V94, P72, DOI 10.1016/j.chemolab.2008.06.003
   Morellos A, 2016, BIOSYST ENG, V152, P104, DOI 10.1016/j.biosystemseng.2016.04.018
   Mulder VL, 2011, GEODERMA, V162, P1, DOI 10.1016/j.geoderma.2010.12.018
   Peng Y, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0142295
   Ray S.S., 2004, INT ARCH PHOTOGRAMM, V35, P127
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   Riley SJ, 1999, INTERMT J SCI, VSci5, P23, DOI 10.1016/j.geomorph.2010.11.003
   Rossel RAV, 2010, GEODERMA, V158, P46, DOI 10.1016/j.geoderma.2009.12.025
   Scudiero E., 2014, GEODERMA REG, V2-3, P82, DOI 10.1016/j.geodrs.2014.10.004
   Shi YY, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0159781
   Souza EG, 2016, J PLANT NUTR, V39, P531, DOI 10.1080/01904167.2015.1124893
   Spectrum Analytic, 2017, AN SERV, V0, P0
   Stevens A, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0066409
   Sudduth KA, 2007, AGRON J, V99, P1471, DOI 10.2134/agronj2006.0326
   Thomasson JA, 2001, T ASAE, V44, P1445, DOI 10.13031/2013.7002
   Uno Y, 2005, COMPUT ELECTRON AGR, V47, P149, DOI 10.1016/j.compag.2004.11.014
   Were K, 2015, ECOL INDIC, V52, P394, DOI 10.1016/j.ecolind.2014.12.028
   Wilson MFJ, 2007, MAR GEOD, V30, P3, DOI 10.1080/01490410701295962
   Yang CH, 2014, REMOTE SENS-BASEL, V6, P5257, DOI 10.3390/rs6065257
   Yao RJ, 2016, AGRON J, V108, P2462, DOI 10.2134/agronj2016.01.0004
NR 38
TC 89
Z9 91
U1 11
U2 86
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0168-1699
EI 1872-7107
J9 COMPUT ELECTRON AGR
JI Comput. Electron. Agric.
PD OCT 15
PY 2018
VL 153
IS 
BP 213
EP 225
DI 10.1016/j.compag.2018.07.016
PG 13
WC Agriculture, Multidisciplinary; Computer Science, Interdisciplinary Applications
SC Agriculture; Computer Science
GA GV7EN
UT WOS:000446284900021
DA 2023-04-26
ER

PT J
AU Alghzawi, AZ
   Napoles, G
   Sammour, G
   Vanhoof, K
AF Alghzawi, Ahmad Zyad
   Napoles, Gonzalo
   Sammour, George
   Vanhoof, Koen
TI Forecasting Social Security Revenues in Jordan Using Fuzzy Cognitive Maps
SO INTELLIGENT DECISION TECHNOLOGIES 2017, KES-IDT 2017, PT I
LA English
DT Proceedings Paper
DE Fuzzy cognitive maps; Time series prediction; Economic modeling
ID time-series
AB In recent years, Fuzzy Cognitive Maps (FCMs) have become a convenient knowledge-based tool for economic modeling. Perhaps, the most attractive feature of these cognitive networks relies on their transparency when performing the reasoning process. For example, in the context of time series forecasting, an FCM-based model allows predicting the next outcomes while expressing the underlying behavior behind the investigated system. In this paper, we investigate the forecasting of social security revenues in Jordan using these neural networks. More specifically, we build an FCM forecasting model to predict the social security revenues in Jordan based on historical records comprising the last 120 months. It should be remarked that we include expert knowledge related to the sign of each weights, whereas the intensity in computed by a supervised learning procedure. This allows empirically exploring a sensitive issue in such models: the trade-off between interpretability and accuracy.
C1 [Alghzawi, Ahmad Zyad; Napoles, Gonzalo; Vanhoof, Koen] Hasselt Univ, Dept Business Informat, Hasselt, Belgium.
   [Sammour, George] Princess Sumaya Univ Technol, Dept Management Informat Syst, Amman, Jordan.
C3 Hasselt University; Princess Sumaya University for Technology
RP Alghzawi, AZ (corresponding author), Hasselt Univ, Dept Business Informat, Hasselt, Belgium.
EM ahmad.alghzawi@uhasselt.be
CR BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bueno S, 2009, EXPERT SYST APPL, V36, P5221, DOI 10.1016/j.eswa.2008.06.072
   Froelich W, 2017, KNOWL-BASED SYST, V115, P110, DOI 10.1016/j.knosys.2016.10.017
   Froelich W, 2014, INT J APPROX REASON, V55, P1319, DOI 10.1016/j.ijar.2014.02.006
   Herrera F, 1998, ARTIF INTELL REV, V12, P265, DOI 10.1023/A:1006504901164
   Homenda W, 2014, IEEE INT FUZZY SYST, V0, PP2055, DOI 10.1109/FUZZ-IEEE.2014.6891719
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Lu W, 2014, KNOWL-BASED SYST, V70, P242, DOI 10.1016/j.knosys.2014.07.004
   Napoles G., 2016, NEURAL PROCESS LETT, V0, P1
   Napoles G, 2016, INFORM SCIENCES, V349, P154, DOI 10.1016/j.ins.2016.02.040
   Napoles G, 2014, INTELL DATA ANAL, V18, PS77, DOI 10.3233/IDA-140710
   Papageorgiou EI, 2015, SMART INNOV SYST TEC, V39, P501, DOI 10.1007/978-3-319-19857-6_43
   Pedrycz W, 2016, IEEE T FUZZY SYST, V24, P120, DOI 10.1109/TFUZZ.2015.2428717
   Pedrycz W, 2010, EXPERT SYST APPL, V37, P7288, DOI 10.1016/j.eswa.2010.03.006
   Poczeta K, 2015, ADV INTELL SYST, V350, P197, DOI 10.1007/978-3-319-15796-2_20
   Salmeron JL, 2016, KNOWL-BASED SYST, V105, P29, DOI 10.1016/j.knosys.2016.04.023
   Scrucca L, 2013, J STAT SOFTW, V53, P1
   Tsadiras AK, 2008, INFORM SCIENCES, V178, P3880, DOI 10.1016/j.ins.2008.05.015
NR 18
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 2190-3018
EI 
J9 SMART INNOV SYST TEC
PD JUN 15
PY 2018
VL 72
IS 
BP 246
EP 254
DI 10.1007/978-3-319-59421-7_23
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications
SC Computer Science
GA BK2GJ
UT WOS:000432721700023
DA 2023-04-26
ER

PT J
AU Batsos, K
   Mordohai, P
AF Batsos, Konstantinos
   Mordohai, Philippos
TI RecResNet: A Recurrent Residual CNN Architecture for Disparity Map Enhancement
SO 2018 INTERNATIONAL CONFERENCE ON 3D VISION (3DV)
LA English
DT Proceedings Paper
AB We present a neural network architecture applied to the problem of refining a dense disparity map generated by a stereo algorithm to which we have no access. Our approach is able to learn which disparity values should be modified and how, from a training set of images, estimated disparity maps and the corresponding ground truth. Its only input at test time is a disparity map and the reference image. Two design characteristics are critical for the success of our network: (i) it is formulated as a recurrent neural network, and (ii) it estimates the output refined disparity map as a combination of residuals computed at multiple scales, that is at different up-sampling and down-sampling rates. The first property allows the network, which we named RecResNet, to progressively improve the disparity map, while the second property allows the corrections to come from different scales of analysis, addressing different types of errors in the current disparity map. We present competitive quantitative and qualitative results on the KITTI 2012 and 2015 benchmarks that surpass the accuracy of previous disparity refinement methods. Our code is available at https://github.com/kbatsos/RecResNet
C1 [Batsos, Konstantinos; Mordohai, Philippos] Stevens Inst Technol, Hoboken, NJ 07030 USA.
C3 Stevens Institute of Technology
RP Batsos, K (corresponding author), Stevens Inst Technol, Hoboken, NJ 07030 USA.
EM kbatsos@stevens.edu; mordohai@cs.stevens.edu
FU National Science Foundation [IIS-1527294, IIS-1637761]
CR Abadi M., 2016, TENSORFLOW LARGE SCA, V0, P0
   Alahari K, 2010, PROC CVPR IEEE, V0, PP895, DOI 10.1109/CVPR.2010.5540123
   [Anonymous], 2017, IEEE C COMPUTER VISI, V0, P0, DOI DOI 10.1109/CVPR.2017.243
   [Anonymous], 2017, ICCV WORKSH GEOM MEE, V0, P0
   [Anonymous], 2016, CVPR, V0, P0
   Barron J. T., 2016, ECCV, V0, P0
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Burget L., 2010, INTERSPEECH, V2, P3, DOI 10.1016/J.CSL.2010.08.008
   Chang J.-R., 2018, ARXIV180308669, V0, P0
   Chen ZY, 2015, IEEE I CONF COMP VIS, V0, PP972, DOI 10.1109/ICCV.2015.117
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, V0, PP2758, DOI 10.1109/ICCV.2015.316
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gidaris S., 2017, CVPR, V0, P0
   Goodfellow I., 2016, DEEP LEARNING, V0, P0
   Graves A, 2013, INT CONF ACOUST SPEE, V0, PP6645, DOI 10.1109/ICASSP.2013.6638947
   Guney F., 2015, CVPR, V0, P0
   Han XF, 2015, PROC CVPR IEEE, V0, PP3279, DOI 10.1109/CVPR.2015.7298948
   Jie Z., 2018, ARXIV180400796, V0, P0
   Kendall Alex, 2017, ICCV, V0, P0
   Kim KR, 2016, IEEE IMAGE PROC, V0, PP3429, DOI 10.1109/ICIP.2016.7532996
   Kingma DP, 2015, 3 INT C LEARN REPR I, V0, P0
   Knobelreiter P., 2017, CVPR, V0, P0
   Li Y., 2008, CVPR, V0, P0
   Luo Wenjie, 2016, CVPR, V0, P0
   Mayer N., 2016, CVPR, V0, P0
   Menze Moritz, 2015, C COMP VIS PATT REC, V0, P0
   Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355
   Park MG, 2015, PROC CVPR IEEE, V0, PP101, DOI 10.1109/CVPR.2015.7298605
   Poggi M., 2016, INT C 3D VIS 3DV, V0, P0
   Rumelhart D. E., 1985, PARALLEL DISTRIBUTED, V0, P0
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Seki A., 2017, COMPUTER VISION PATT, V0, P0
   Seki A., 2016, P BRIT MACH VIS C, V0, P0
   Shaked A., 2017, CVPR, V0, P0
   Slossberg R., 2017, ARXIV161201725V2, V0, P0
   Spyropoulos A, 2016, INT J COMPUT VISION, V118, P300, DOI 10.1007/s11263-015-0877-y
   Spyropoulos A, 2014, PROC CVPR IEEE, V0, PP1621, DOI 10.1109/CVPR.2014.210
   Taniai T., 2017, PAMI, V0, P0
   Tonioni A., 2017, ICCV, V0, P0
   Tulyakov S., 2017, ICCV, V0, P0
   Ummenhofer B., 2017, CVPR, V0, P0
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Ye XQ, 2017, IEEE ACCESS, V5, P18745, DOI 10.1109/ACCESS.2017.2754318
   Zagoruyko Sergey, 2015, CVPR, V0, P0
   Zbontar J., 2015, CVPR, V0, P0
   Zbontar J, 2016, J MACH LEARN RES, V17, P0
   Zhang C, 2015, IEEE I CONF COMP VIS, V0, PP2057, DOI 10.1109/ICCV.2015.238
   Zhang F., 2017, IEEE T IMAGE PROCESS, V0, P0
   Zhong Y., 2017, ARXIV170900930, V0, P0
NR 51
TC 15
Z9 16
U1 0
U2 6
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 
EI 
J9 INT CONF 3D VISION
PD JUN 15
PY 2018
VL 0
IS 
BP 238
EP 247
DI 10.1109/3DV.2018.00036
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA BL3JL
UT WOS:000449774200025
DA 2023-04-26
ER

PT J
AU Al-Marri, F
   Reza, F
   Begum, T
   Hitam, WHW
   Jin, GK
   Xiang, J
AF Al-Marri, Faraj
   Reza, Faruque
   Begum, Tahamina
   Hitam, Wan Hazabbah Wan
   Jin, Goh Khean
   Xiang, Jing
TI Neural activation patterns and connectivity in visual attention during number and non-number processing: An ERP study using Ishihara pseudoisochromatic plates
SO JOURNAL OF INTEGRATIVE NEUROSCIENCE
LA English
DT Article
DE Visual number recognition; event related potential; pseudoisochromatic plates; N100 and P300 event; attention; effective connectivity
ID event-related potentials; functional connectivity; selective attention; spatial vision; brain networks; p300 wave; color; pathways; object; time
AB Visual cognitive function is important in the construction of executive function in daily life. Perception of visual number form (e.g. Arabic digits) and numerosity (numeric magnitude) is of interest to cognitive neuroscientists. Neural correlates and the functional measurement of number representations are complex events when their semantic categories are assimilated together with concepts of shape and color. Color perception can be processed further to modulate visual cognition. The Ishihara pseudoisochromatic plates are one of the best and most common screening tools for basic red-green color vision testing. However, there has been little study of visual cognitive function assessment using such pseudoisochromatic plates. 25 healthy normal trichromat volunteers were recruited and studied using a 128-sensor net to record event-related electroencephalogram. Subjects were asked to respond by pressing numbered buttons when they saw the number and non-number plates of the Ishihara color vision test. Amplitudes and latencies of N100 and P300 event related potential components were analyzed from 19 electrode sites in the international 10-20 system. A brain topographic map, cortical activation patterns, and Granger causation (effective connectivity) were analyzed from 128 electrode sites. No significant differences between N100 event related potential components for either stimulus indicates early selective attention processing was similar for number and non-number plate stimuli, but non-number plate stimuli evoked significantly higher amplitudes, longer latencies of the P300 event related potential component with a slower reaction time compared to number plate stimuli imply the allocation of attentional load was more in non-number plate processing. A different pattern of the asymmetric scalp voltage map was noticed for P300 components with a higher intensity in the left hemisphere for number plate tasks and higher intensity in the right hemisphere for non-number plate tasks. Asymmetric cortical activation and connectivity patterns revealed that number recognition occurred in the occipital and left frontal areas where as the consequence was limited to the occipital area during the non-number plate processing. Finally, results demonstrated that the visual recognition of numbers dissociates from the recognition of non-numbers at the level of defined neural networks. Number recognition was not only a process of visual perception and attention, but was also related to a higher level of cognitive function, that of language.
C1 [Al-Marri, Faraj; Reza, Faruque; Begum, Tahamina] Univ Sains Malaysia, Sch Med Sci, Dept Neurosci, Kota Baharu 16150, Kelantan, Malaysia.
   [Al-Marri, Faraj] King Faisal Univ, Dept Neurosci, Coll Med, Al Hufuf 31982, Al Ahsa, Saudi Arabia.
   [Hitam, Wan Hazabbah Wan] Univ Sains Malaysia, Sch Med Sci, Dept Ophthalmol, Kota Baharu 16150, Kelantan, Malaysia.
   [Jin, Goh Khean] Univ Malaya, Fac Med, Div Neurol, Kuala Lumpur 50603, Malaysia.
   [Xiang, Jing] Cincinnati Childrens Hosp Med Ctr, MEG Ctr, Div Neurol, 3333 Burnet Ave, Cincinnati, OH 45220 USA.
C3 Universiti Sains Malaysia; King Faisal University; Universiti Sains Malaysia; Universiti Malaya; Cincinnati Children's Hospital Medical Center
RP Reza, F (corresponding author), Univ Sains Malaysia, Sch Med Sci, Dept Neurosci, Kota Baharu 16150, Kelantan, Malaysia.
EM faruque@usm.my
FU Universiti Sains Malaysia (USM) [304/PPSP/61311092]
CR Abboud S, 2015, NAT COMMUN, V6, P0, DOI 10.1038/ncomms7026
   AREND LE, 1991, J OPT SOC AM A, V8, P661, DOI 10.1364/JOSAA.8.000661
   Baayen RH, 2010, INT J PSYCHOL RES, V3, P12
   Barsalou Lawrence W., 2014, COGNITIVE PSYCHOL OV, V0, P0
   Bassett DS, 2011, P NATL ACAD SCI USA, V108, P7641, DOI 10.1073/pnas.1018985108
   BELCHER S J, 1958, BR J OPHTHALMOL, V42, P355, DOI 10.1136/bjo.42.6.355
   Brang D, 2010, NEUROIMAGE, V53, P268, DOI 10.1016/j.neuroimage.2010.06.008
   BROOKHUIS KA, 1983, BIOL PSYCHOL, V17, P277, DOI 10.1016/0301-0511(83)90004-2
   Cavina-Pratesi C, 2010, CEREB CORTEX, V20, P2319, DOI 10.1093/cercor/bhp298
   Chang S, 2017, CORTEX, V105, P83
   Chayer C, 2001, CURR NEUROL NEUROSCI REP, V1, P547, DOI 10.1007/s11910-001-0060-4
   Connaughton VM, 2017, J NEUROSCI METH, V283, P33, DOI 10.1016/j.jneumeth.2017.03.010
   Cosstick M, 2005, AM J OPHTHALMOL, V140, P154, DOI 10.1016/j.ajo.2005.01.002
   Dain Stephen J, 2004, CLIN EXP OPTOM, V87, P276
   de Raad B, 2006, PSYCHOLOGICAL CONCEPTS: AN INTERNATIONAL HISTORICAL PERSPECTIVE, V0, P299
   Dehaene S, 1998, P NATL ACAD SCI USA, V95, P14529, DOI 10.1073/pnas.95.24.14529
   DEHAENE S, 1992, COGNITION, V44, P1, DOI 10.1016/0010-0277(92)90049-N
   Delb W, 2008, APPL PSYCHOPHYS BIOF, V33, P211, DOI 10.1007/s10484-008-9065-y
   DEYOE EA, 1988, TRENDS NEUROSCI, V11, P219, DOI 10.1016/0166-2236(88)90130-0
   Dosenbach NUF, 2008, TRENDS COGN SCI, V12, P99, DOI 10.1016/j.tics.2008.01.001
   Du YC, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0090794
   Eimer M., 2014, OXFORD HDB ATTENTION, V1st, P289, DOI 10.1093/OXFORDHB/9780199675111.013.006
   Esposito F, 2006, BRAIN RES BULL, V70, P263, DOI 10.1016/j.brainresbull.2006.06.012
   Fairchild M. D., 2013, COLOR APPEARANCE MOD, V0, P0, DOI DOI 10.1002/9781118653128
   Fonteneau E, 2007, NEUROREPORT, V18, P1323, DOI 10.1097/WNR.0b013e3282c48c33
   Galton Francis, 1880, NATURE, V21, P252, DOI 10.1038/021252A0
   Gavkare A.M., 2013, INDIAN MED GAZETTE, V147, P214
   Ghuntla T. P., 2014, J MAHATMA GANDHI I M, V19, P119, DOI 10.4103/0971-9903.138431
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Gow DW, 2012, FRONT PSYCHOL, V3, P0, DOI 10.3389/fpsyg.2012.00506
   Grotheer M, 2016, J NEUROSCI, V36, P88, DOI 10.1523/JNEUROSCI.2129-15.2016
   Hansenne M, 2000, NEUROPHYSIOL CLIN, V30, P191, DOI 10.1016/S0987-7053(00)00223-9
   Hasan RA., 2016, J ADV MED PHARM SCI, V10, P1, DOI 10.9734/JAMPS/2016/29783
   Hopf JM, 2002, J NEUROPHYSIOL, V88, P2088, DOI 10.1152/jn.2002.88.4.2088
   Horovitz SG, 2008, HUM BRAIN MAPP, V29, P671, DOI 10.1002/hbm.20428
   Horowitz-Kraus T, 2015, NEUROIMAGE-CLIN, V8, P619, DOI 10.1016/j.nicl.2015.06.010
   Hutchison RM, 2013, NEUROIMAGE, V80, P360, DOI 10.1016/j.neuroimage.2013.05.079
   Jonkman LM, 2000, PSYCHOPHYSIOLOGY, V37, P334
   Kleih SC, 2010, CLIN NEUROPHYSIOL, V121, P1023, DOI 10.1016/j.clinph.2010.01.034
   Knops A, 2017, NEUROSCIENTIST, V23, P264, DOI 10.1177/1073858416650153
   KOHLER S, 1995, NEUROREPORT, V6, P1865, DOI 10.1097/00001756-199510020-00011
   Koyama MS, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0055454
   Laming D. R. J., 1968, INFORM THEORY CHOICE, V0, P0, DOI DOI 10.1002/BS.3830140408
   LIT A, 1971, PERCEPT PSYCHOPHYS, V10, P397, DOI 10.3758/BF03210320
   Liu J, 2017, NEUROIMAGE, V147, P432, DOI 10.1016/j.neuroimage.2016.12.035
   Luck S.J., 2005, EVENT RELATED POTENT, V0, P0
   Mattingley JB, 2006, CORTEX, V42, P213, DOI 10.1016/S0010-9452(08)70346-0
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   MISHKIN M, 1983, TRENDS NEUROSCI, V6, P414, DOI 10.1016/0166-2236(83)90190-X
   MISRA N, 1985, INDIAN JOURNAL OF PHYSIOLOGY AND PHARMACOLOGY, V29, P213
   Miyahara E, 2008, CLIN EXP OPTOM, V91, P161, DOI 10.1111/j.1444-0938.2007.00210.x
   Moore T, 2017, ANNU REV PSYCHOL, V68, P47, DOI 10.1146/annurev-psych-122414-033400
   MS M, 1997, AM J PSYCHOL, V90, P541
   Niso G, 2013, NEUROINFORMATICS, V11, P405, DOI 10.1007/s12021-013-9186-1
   Park J, 2012, J COGNITIVE NEUROSCI, V24, P39, DOI 10.1162/jocn_a_00085
   Patrick CJ, 2006, PSYCHOPHYSIOLOGY, V43, P84, DOI 10.1111/j.1469-8986.2006.00376.x
   Piazza M, 2016, NEUROPSYCHOLOGIA, V83, P257, DOI 10.1016/j.neuropsychologia.2015.09.025
   PICTON TW, 1992, J CLIN NEUROPHYSIOL, V9, P456, DOI 10.1097/00004691-199210000-00002
   POLICH J, 1995, BIOL PSYCHOL, V41, P103, DOI 10.1016/0301-0511(95)05130-9
   Polich J, 1999, ELECTROENCEPHALOGRAP, V0, P1073
   Posner M.I., 1978, MODES PERCEIVING PRO, V137, P0
   Ramachandran VS, 2001, P ROY SOC B-BIOL SCI, V268, P979, DOI 10.1098/rspb.2000.1576
   Roldan SM, 2017, FRONT PSYCHOL, V8, P0, DOI 10.3389/fpsyg.2017.00833
   Roux FE, 2008, NEUROLOGY, V70, P210, DOI 10.1212/01.wnl.0000297194.14452.a0
   Rugani R, 2017, FRONT PSYCHOL, V8, P0, DOI 10.3389/fpsyg.2017.01481
   RUGG MD, 1987, NEUROPSYCHOLOGIA, V25, P85, DOI 10.1016/0028-3932(87)90045-5
   Rumelhart D E, 1977, SCIENCE, V198, P816, DOI 10.1126/science.198.4319.816
   Russo PM, 2008, INT J PSYCHOPHYSIOL, V69, P112, DOI 10.1016/j.ijpsycho.2008.03.008
   Sharpe LT, 1999, COLOR VISION GENES P, V0, P3
   Shum J, 2013, J NEUROSCI, V33, P6709, DOI 10.1523/JNEUROSCI.4558-12.2013
   Smith VC, 1996, COLOR RES APPL, V21, P375, DOI 10.1002/(SICI)1520-6378(199610)21:5<375::AID-COL6>3.0.CO;2-V
   Spence C, 2010, CONSCIOUS COGN, V19, P364, DOI 10.1016/j.concog.2009.12.001
   SPIRDUSO WW, 1975, J GERONTOL, V30, P435, DOI 10.1093/geronj/30.4.435
   Sporns O, 2007, PLOS ONE, V2, P0, DOI 10.1371/journal.pone.0001049
   Sur Shravani, 2009, IND PSYCHIATRY J, V18, P70, DOI 10.4103/0972-6748.57865
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, P0, DOI 10.1155/2011/879716
   Van der Stelt O, 1998, PSYCHOPHYSIOLOGY, V35, P227, DOI 10.1017/S0048577298961303
   Van Overwalle F, 2009, SOC COGN AFFECT NEUR, V4, P177, DOI 10.1093/scan/nsp003
   Vogel AC, 2014, FRONT HUM NEUROSCI, V8, P0, DOI 10.3389/fnhum.2014.00088
   Welford A. T., 1980, REACTION TIMES, V0, P73
   Yeo DJ, 2017, NEUROSCI BIOBEHAV R, V78, P145, DOI 10.1016/j.neubiorev.2017.04.027
NR 81
TC 1
Z9 1
U1 1
U2 9
PU IMR PRESS
PI WAN CHAI
PA RM 19C, LOCKHART CTR, 301-307 LOCKHART RD, WAN CHAI, 00000, HONG KONG
SN 0219-6352
EI 1757-448X
J9 J INTEGR NEUROSCI
JI J. Integr. Neurosci.
PD JUN 15
PY 2018
VL 17
IS 3
BP 257
EP 269
DI 10.31083/JIN-170058
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA HA9HD
UT WOS:000450609200008
DA 2023-04-26
ER

PT J
AU Helber, P
   Bischke, B
   Dengel, A
   Borth, D
AF Helber, Patrick
   Bischke, Benjamin
   Dengel, Andreas
   Borth, Damian
TI INTRODUCING EUROSAT: A NOVEL DATASET AND DEEP LEARNING BENCHMARK FOR LAND USE AND LAND COVER CLASSIFICATION
SO IGARSS 2018 - 2018 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM
LA English
DT Proceedings Paper
DE Deep Learning; Machine Learning; Convolutional Neural Network; Land Use Classification; Land Cover Classification; Earth Observation; Dataset
AB In this paper, we address the challenge of land use and land cover classification using Sentinel-2 satellite images. The key contributions are as follows. We present a novel dataset based on Sentinel-2 satellite images covering 13 different spectral bands and consisting of 10 classes with in total 27,000 labeled images. We evaluate state-of-the-art deep Convolutional Neural Networks (CNNs) on this novel dataset with its different spectral bands. We also evaluate deep CNNs on existing remote sensing datasets and compare the obtained results. With the proposed novel dataset, we achieved an overall classification accuracy of 98.57%. The classification system resulting from the proposed research opens a gate towards various Earth observation applications. We demonstrate how the classification system can assist in improving geographical maps.
C1 [Helber, Patrick; Bischke, Benjamin; Dengel, Andreas] TU Kaiserslautern, Kaiserslautern, Germany.
   [Helber, Patrick; Bischke, Benjamin; Dengel, Andreas; Borth, Damian] German Res Ctr Artificial Intelligence DFKI, Kaiserslautern, Germany.
C3 University of Kaiserslautern; German Research Center for Artificial Intelligence (DFKI)
RP Helber, P (corresponding author), TU Kaiserslautern, Kaiserslautern, Germany.; Helber, P (corresponding author), German Res Ctr Artificial Intelligence DFKI, Kaiserslautern, Germany.
FU BMBF project DeFuseNN [01IW17002]
CR Basu S, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), V0, P0, DOI DOI 10.1145/2820783.2820816
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Helber P., 2017, ABS170900029, V0, P0
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sheng GF, 2012, INT J REMOTE SENS, V33, P2395, DOI 10.1080/01431161.2011.608740
   Verdoliva L., 2015, ARXIV PREPRINT ARXIV, V28, P627
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang Y, 2010, PROC 18 SIGSPATIAL I, V0, P0, DOI DOI 10.1145/1869790.1869829
NR 11
TC 55
Z9 56
U1 1
U2 7
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2153-6996
EI 
J9 INT GEOSCI REMOTE SE
PD JUN 15
PY 2018
VL 0
IS 
BP 204
EP 207
DI 
PG 4
WC Engineering, Electrical & Electronic; Geosciences, Multidisciplinary; Remote Sensing
SC Engineering; Geology; Remote Sensing
GA BL4XL
UT WOS:000451039800052
DA 2023-04-26
ER
