
PT J
AU Mansouri, T
   ZareRavasan, A
   Ashrafi, A
AF Mansouri, Taha
   ZareRavasan, Ahad
   Ashrafi, Amir
TI A LEARNING FUZZY COGNITIVE MAP (LFCM) APPROACH TO PREDICT STUDENT PERFORMANCE
SO JOURNAL OF INFORMATION TECHNOLOGY EDUCATION-RESEARCH
LA English
DT Article
DE e-learning; Learning Analytics (LA); Learning Fuzzy Cognitive Map (LFCM); Learning Management System (LMS); Student Engagement; Student Performance
ID structural equation model; higher-education; satisfaction; optimization; engagement; quality; determinants; antecedents; information; achievement
AB Aim/Purpose This research aims to present a brand-new approach for student performance prediction using the Learning Fuzzy Cognitive Map (LFCM) approach. Background Predicting student academic performance has long been an important research topic in many academic disciplines. Different mathematical models have been employed to predict student performance. Although the available sets of common prediction approaches, such as Artificial Neural Networks (ANN) and regression, work well with large datasets, they face challenges dealing with small sample sizes, limiting their practical applications in real practices. Methodology Six distinct categories of performance antecedents are adopted here as course characteristics, LMS characteristics, student characteristics, student engagement, student support, and institutional factors, along with measurement items within each category. Furthermore, we assessed the student's overall performance using three items of student satisfaction score, knowledge construction level, and student GPA. We have collected longitudinal data from 30 postgraduates in four subsequent semesters and analyzed data using the Learning Fuzzy Cognitive Map (LFCM) technique. Contribution This research proposes a brand new approach, Learning Fuzzy Cognitive Map (LFCM), to predict student performance. Using this approach, we identified the most influential determinants of student performance, such as student engagement. Besides, this research depicts a model of interrelations among the student performance determinants. Findings The results suggest that the model reasonably predicts the incoming sequence when there is a limited sample size. The results also reveal that students' total online time and the regularity of learning interval in LMS have the largest effect on overall performance. The student engagement category also has the highest direct effect on student's overall performance. Recommendations Academic institutions can use the results and approach developed in this paper for Practitioners to identify students' performance antecedents, predict the performance, and establish action plans to resolve the shortcomings in the long term. Instructors can adjust their learning methods based on the feedback from students in the short run on the operational level. Recommendations Researchers can use the proposed approach in this research to deal with the for Researchers problems in other domains, such as using LMS for organizational/institutional education. Besides, they can focus on specific dimensions of the proposed model, such as exploring ways to boost student engagement in the learning process. Impact on Society Our results revealed that students are at the center of the learning process. The degree to which they are dedicated to learning is the most crucial determinant of the learning outcome. Therefore, learners should consider this finding in order the gain value from the learning process. Future Research As a potential for future works, the proposed approach could be used in other contexts to test its applicability. Future studies could also improve the performance level of the proposed LFMC model by tuning the model's elements.
C1 [Mansouri, Taha] Univ Salford, Sch Sci Engn & Environm, Salford, Lancs, England.
   [ZareRavasan, Ahad] Masaryk Univ, Fac Econ & Adm, Dept Corp Econ, Brno, Czech Republic.
   [Ashrafi, Amir] Univ Manchester, Business & Management, Alliance Manchester Business Sch, Manchester, Lancs, England.
C3 University of Salford; Masaryk University Brno; University of Manchester; Alliance Manchester Business School
RP ZareRavasan, A (corresponding author), Masaryk Univ, Fac Econ & Adm, Dept Corp Econ, Brno, Czech Republic.
EM T.Mansouri@salford.ac.uk; Ahad.ZareRavasan@econ.muni.cz; Amir.Ashrafi@postgrad.manchester.ac.uk
CR Abdous M, 2012, EDUC TECHNOL SOC, V15, P77
   Abdulwahhab R. S., 2017, 6 INT C INF COMM TEC, V0, PP1, DOI 10.1109/ICTA.2017.8336060
   Al Breiki B., 2019, 2019 INT C EL COMP T, V0, P1
   Al-Azawei A, 2016, INT REV RES OPEN DIS, V17, P126
   [Anonymous], 2010, 2010 6 INT C WIRELES, V0, P0, DOI DOI 10.1016/J.NEULET.2010.03.079.PUBMED
   Anusha G., 2015, STUDY SYMPTOMS STRES, V0, P0
   Ashrafi A, 2022, INTERACT LEARN ENVIR, V30, P1475, DOI 10.1080/10494820.2020.1734028
   Baloyi G. P, 2014, MEDITERRANEAN J SOCI, V5, P1251
   Baloyi G.P., 2014, J COMMUN, V5, P127
   Baykasoglu A, 2015, INFORM SCIENCES, V301, P75, DOI 10.1016/j.ins.2014.12.048
   Baron HB, 2015, SOFT COMPUT, V19, P1037, DOI 10.1007/s00500-014-1313-x
   Bueno S, 2009, EXPERT SYST APPL, V36, P5221, DOI 10.1016/j.eswa.2008.06.072
   Castellano Emilio J., 2008, E LEARNING, V0, P38
   Chawinga WD, 2016, INT REV RES OPEN DIS, V17, P1
   Cheng G, 2016, BRIT J EDUC TECHNOL, V47, P257, DOI 10.1111/bjet.12243
   Chrysafiadi K, 2015, IEEE T FUZZY SYST, V23, P164, DOI 10.1109/TFUZZ.2014.2310242
   Chrysafiadi K, 2013, SPRINGERPLUS, V2, P0, DOI 10.1186/2193-1801-2-81
   Clow D, 2013, TEACH HIGH EDUC, V18, P683, DOI 10.1080/13562517.2013.827653
   Dias SB, 2015, EXPERT SYST APPL, V42, P7399, DOI 10.1016/j.eswa.2015.05.048
   Farasat A, 2010, APPL SOFT COMPUT, V10, P1284, DOI 10.1016/j.asoc.2010.05.011
   Fatahi S, 2016, COMPUT HUM BEHAV, V63, P272, DOI 10.1016/j.chb.2016.05.041
   Ferguson JM, 2010, INT REV RES OPEN DIS, V11, P73, DOI 10.19173/irrodl.v11i2.772
   Georgiou DA, 2008, IEEE INT CONF FUZZY, V0, P2204
   Georgopoulos VC, 2014, IEEE ENG MED BIO, V0, PP1813, DOI 10.1109/EMBC.2014.6943961
   Gowda S.M., 2013, PROC INT C LEARN ANA, V0, P117
   Grant-Vallone E., 2003, J COLL STUD RETENT-R, V5, P255, DOI 10.2190/C0T7-YX50-F71V-00CW
   Hadullo K., 2017, INT J ED DEV USING I, V13, P0
   Hobbs BF, 2002, ECOL APPL, V12, P1548, DOI 10.1890/1051-0761(2002)012[1548:FCMAAT]2.0.CO;2
   Holmes T, 2019, 2019 IEEE FRONT ED C, V0, PP1, DOI 10.1109/FIE43999.2019.9028350
   Hossain S, 2008, COMPUT EDUC, V51, P1569, DOI 10.1016/j.compedu.2008.03.002
   Hu PJH, 2012, DECIS SUPPORT SYST, V53, P782, DOI 10.1016/j.dss.2012.05.014
   Huang S, 2013, COMPUT EDUC, V61, P133, DOI 10.1016/j.compedu.2012.08.015
   Hughes JN, 2006, J SCHOOL PSYCHOL, V43, P465, DOI 10.1016/j.jsp.2005.10.001
   Hwang GJ, 2015, AUSTRALAS J EDUC TEC, V31, P400
   Kaba B, 2013, INT J INFORM MANAGE, V33, P441, DOI 10.1016/j.ijinfomgt.2013.01.010
   Kahvandi Z., 2018, LEAN CONSTRUCTION J, V2018, P63
   Kashorda M., 2014, E READINESS SURVEY K, V0, P0
   Kireev V. S., 2016, INT C DAT AN MAN DAT, V0, P0, DOI DOI 10.1007/978-3-319-57135-5_4
   Kisanga DH, 2016, INT REV RES OPEN DIS, V17, P109
   Knight S, 2020, INTERNET HIGH EDUC, V45, P0, DOI 10.1016/j.iheduc.2020.100729
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kumar A. N. V., 2009, EUR J SCI RES, V34, P526
   Lai MM, 2015, J MARK HIGH EDUC, V25, P45, DOI 10.1080/08841241.2015.1042097
   Lang C., 2017, HDB LEARNING ANAL, V0, P0, DOI DOI 10.18608/hla17
   Long Phil, 2011, EDUCAUSE REVIEW, V46, P31
   Lykourentzou I, 2009, J AM SOC INF SCI TEC, V60, P372, DOI 10.1002/asi.20970
   Macfadyen LP, 2010, COMPUT EDUC, V54, P588, DOI 10.1016/j.compedu.2009.09.008
   Makokha GL, 2016, INT REV RES OPEN DIS, V17, P341
   Mansouri T, 2011, EXPERT SYST APPL, V38, P4866, DOI 10.1016/j.eswa.2010.09.084
   Masood MF, 2019, INT CONF SOFT COMP, V0, PP12, DOI 10.1109/ISCMI47871.2019.9004299
   Mayoka K., 2012, INFORM TECHNOLOGY RE, V2, P1
   Meghji A. F., 2018, P 2018 5 INT MULT IC, V0, P1
   Misopoulos F., 2018, LINE, V0, PP235, DOI 10.1007/978-3-319-62776-2_18
   Mohammadi M, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), V0, PP124, DOI 10.1109/ICAIIC.2019.8669085
   Moridis CN, 2009, COMPUT EDUC, V53, P644, DOI 10.1016/j.compedu.2009.04.002
   Muntean CI, 2011, PROC INT C VIRTUAL L, V0, P323
   Muuro ME, 2014, INT REV RES OPEN DIS, V15, P132
   Mwalumbwe I, 2017, ELECTR J INF SYS DEV, V79, P0
   Ngandu M. R., 2015, C EM TECHN AUTH LEAR, V0, P0
   Nguyen Thai-Nghe, 2011, 2011 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES (ICALT 2011), V0, PP412, DOI 10.1109/ICALT.2011.130
   Nguyen TN, 2010, PROCEDIA COMPUT SCI, V1, P2811, DOI 10.1016/j.procs.2010.08.006
   Nownaisin P., 2012, P IEEE INT C TEACH A, V0, P0, DOI DOI 10.1109/TALE.2012.6360392
   PANDEY H, 2015, INT J COMPUTER APPL, V122, P18, DOI 10.5120/21793-5140
   Panigrahi R, 2018, INT J INFORM MANAGE, V43, P1, DOI 10.1016/j.ijinfomgt.2018.05.005
   Papageorgiou EI, 2012, APPL SOFT COMPUT, V12, P3798, DOI 10.1016/j.asoc.2012.03.064
   Papamitsiou Z, 2014, EDUC TECHNOL SOC, V17, P49
   Pappas C, 2015, SHORT ANSWER QUESTIO, V0, P0
   Pena A, 2007, LECT NOTES ARTIF INT, V4496, P328
   Pye G, 2016, AUSTRALAS J INF SYST, V20, P0, DOI 10.3127/ajis.v19i0.1251
   Queiros DR, 2016, INT REV RES OPEN DIS, V17, P165
   Raga RC, 2019, 2019 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET 2019), V0, PP39, DOI 10.1109/ISET.2019.00018
   Raspopovic M, 2014, INT REV RES OPEN DIS, V15, P1
   Ravasan AZ, 2016, PROD PLAN CONTROL, V27, P65, DOI 10.1080/09537287.2015.1064551
   Ravasan AZ, 2014, INT J ENTERP INF SYS, V10, P32, DOI 10.4018/ijeis.2014010103
   Romero-Zaldivar VA, 2012, COMPUT EDUC, V58, P1058, DOI 10.1016/j.compedu.2011.12.003
   Ros S, 2015, BRIT J EDUC TECHNOL, V46, P1250, DOI 10.1111/bjet.12199
   Roy R., 2004, DISTANCE ED TECHNOLO, V0, P129
   Salik E. D., 2019, 2019 IEEE 30 ANN INT, V0, P1
   Salmeron JL, 2019, KNOWL-BASED SYST, V163, P723, DOI 10.1016/j.knosys.2018.09.034
   Salmeron JL, 2016, KNOWL-BASED SYST, V105, P29, DOI 10.1016/j.knosys.2016.04.023
   Salmeron JL, 2009, KNOWL-BASED SYST, V22, P275, DOI 10.1016/j.knosys.2009.01.002
   Sharma SK, 2017, BEHAV INFORM TECHNOL, V36, P1053, DOI 10.1080/0144929X.2017.1340973
   Sheshadri A., 2018, P 11 INT C ED DATA M, V0, P411
   Siegle D, 2010, GIFTED CHILD QUART, V54, P92, DOI 10.1177/0016986209355975
   Ssekakubo Grace, 2011, P S AFR I COMP SCI I, V0, PP231, DOI 10.1145/2072221.2072248
   Sweta S., 2016, IOSR J COMPUTER ENG, V18, P18, DOI 10.9790/0661-1802041824
   Takacs M, 2014, INT CONF SYST SCI EN, V0, PP284, DOI 10.1109/ICSSE.2014.6887950
   Tarus JK, 2015, INT REV RES OPEN DIS, V16, P120
   Thai-Nghe N, 2009, INT CONF INTELL SYST, V0, PP878, DOI 10.1109/ISDA.2009.15
   TOSCHER A, 2010, P KDD CUP, V0, P0
   Tsadiras A., 2008, P 6 INT C NETW LEARN, V0, P376
   Turabieh H., 2019, 2019 2 INT C NEW TRE, V0, P0, DOI DOI 10.1109/ICTCS.2019.8923093
   Umer R, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, V0, P0
   van Vliet M, 2010, FUTURES, V42, P1, DOI 10.1016/j.futures.2009.08.005
   Vialardi C, 2011, USER MODEL USER-ADAP, V21, P217, DOI 10.1007/s11257-011-9098-4
   Yang F., 2011, ADV WEBBASED LEARNIN, V0, P0, DOI DOI 10.1007/978-3-642-25813-8_19
   Yesil E, 2013, INT CONF INFO TECH, V0, P0
   ZareRavasan A., 2018, IT MANAGEMENT STUDIE, V6, P87
   Zareravasan A, 2019, PROCEEDINGS OF 9TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2019), V0, PP165, DOI 10.1145/3357419.3357429
   Zhang WY, 2012, INT REV RES OPEN DIS, V13, P66, DOI 10.19173/irrodl.v13i3.1181
   Zhu C, 2012, EDUC TECHNOL SOC, V15, P127
NR 101
TC 4
Z9 4
U1 7
U2 17
PU INFORMING SCIENCE INST
PI SANTA ROSA
PA 131 BROOKHILL CT, SANTA ROSA, CA 95409 USA
SN 1547-9714
EI 1539-3585
J9 J INF TECHNOL EDUC-R
JI J. Inf. Technol. Educ.-Res.
PD JUN 15
PY 2021
VL 20
IS 
BP 
EP 
DI 10.28945/4760
PG 23
WC Education & Educational Research
SC Education & Educational Research
GA TD9CY
UT WOS:000669616700001
DA 2023-04-26
ER

PT J
AU Li, PL
   He, XH
   Qiao, MJ
   Miao, DS
   Cheng, XJ
   Song, DJ
   Chen, MY
   Li, JMA
   Zhou, T
   Guo, XY
   Yan, XY
   Tian, ZH
AF Li, Panle
   He, Xiaohui
   Qiao, Mengjia
   Miao, Disheng
   Cheng, Xijie
   Song, Dingjun
   Chen, Mingyang
   Li, Jiamian
   Zhou, Tao
   Guo, Xiaoyu
   Yan, Xinyu
   Tian, Zhihui
TI Exploring multiple crowdsourced data to learn deep convolutional neural networks for road extraction*
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Road extraction; Deep convolutional neural networks; Multiple crowdsourced data; Multi-map integration model; Refined labels
ID image classification; building extraction; segmentation; multiscale; labels; aware
AB Road extraction from high-resolution remote sensing images (HRSIs) is essential for applications in various areas. Although deep convolutional neural networks (DCNNs) have exhibited remarkable success in road extraction, the performance relies on a large amount of training samples which are hard to obtain. To address this issue, multiple crowdsourced data are used in this study, including OpenStreetMap (OSM), Zmap and GPS. And a multi-map integration model (MMIM) is developed to improve the noise robustness of DCNNs for road extraction tasks. Specifically, rich geographical road information are obtained from multiple crowdsourced data, including main roads, new construction roads, midsize and small roads, which can generate complete road training samples and reduce the label noise. Meanwhile, by exploring the true road label information hidden in different crowdsourced data, the MMIM is used to generate high-quality refined labels for learning DCNNs. In this case, the DCNN-based road extraction methods have more opportunities to learn true road distribution and avoid the overfitting problems of label noise. Experiments based on real road extraction dataset indicate that the proposed method shows great performance, and road extraction results are smoother and more complete.
C1 [Li, Panle; Qiao, Mengjia; Miao, Disheng; Cheng, Xijie; Song, Dingjun; Chen, Mingyang; Li, Jiamian; Zhou, Tao] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
   [He, Xiaohui; Guo, Xiaoyu; Yan, Xinyu; Tian, Zhihui] Zhengzhou Univ, Sch Geosci & Technol, Zhengzhou 450001, Peoples R China.
   [He, Xiaohui; Guo, Xiaoyu; Tian, Zhihui] Zhengzhou Univ, Ecometeorol Joint Lab, Zhengzhou 450001, Peoples R China.
   [He, Xiaohui; Guo, Xiaoyu; Tian, Zhihui] Chinese Acad Meteorol Sci, Zhengzhou 450001, Peoples R China.
C3 Zhengzhou University; Zhengzhou University; Zhengzhou University; Chinese Academy of Meteorological Sciences (CAMS)
RP He, XH (corresponding author), Zhengzhou Univ, Sch Geosci & Technol, Zhengzhou 450001, Peoples R China.
EM hexh@zzu.edu.cn
FU Science and Technology Major Project of Henan Province [201400210900]
CR Ali AL, 2017, ISPRS J PHOTOGRAMM, V127, P3, DOI 10.1016/j.isprsjprs.2016.06.003
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bottou L., 2012, NEURAL NETWORKS TRIC, V0, PP421, DOI 10.1007/978-3-642-35289-8_25
   Chen JY, 2019, IEEE T GEOSCI REMOTE, V57, P1713, DOI 10.1109/TGRS.2018.2868748
   Chen JY, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP771, DOI 10.1145/3041021.3054250
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Ding L., 2020, IEEE T MED IMAGING, V0, P1
   Dong R., 2021, IEEE T GEOSCI ELECT, V0, P1
   Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Gevaert CM, 2018, IEEE J-STARS, V11, P2731, DOI 10.1109/JSTARS.2017.2762905
   Grinias I, 2016, ISPRS J PHOTOGRAMM, V122, P145, DOI 10.1016/j.isprsjprs.2016.10.010
   Han B, 2019, IEEE T NEUR NET LEAR, V30, P3774, DOI 10.1109/TNNLS.2019.2899045
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Jiang JJ, 2019, IEEE T GEOSCI REMOTE, V57, P851, DOI 10.1109/TGRS.2018.2861992
   Jiang L., 2018, MENTORNET REGULARIZI, V0, P0
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Li PL, 2021, IEEE T GEOSCI REMOTE, V59, P6182, DOI 10.1109/TGRS.2020.3023112
   Li PL, 2019, IEEE ACCESS, V7, P122784, DOI 10.1109/ACCESS.2019.2938215
   Li YS, 2021, IEEE T CYBERNETICS, V51, P1756, DOI 10.1109/TCYB.2020.2989241
   Li Y, 2019, IEEE GEOSCI REMOTE S, V16, P613, DOI 10.1109/LGRS.2018.2878771
   Liu YH, 2019, IEEE T GEOSCI REMOTE, V57, P2043, DOI 10.1109/TGRS.2018.2870871
   Lu XY, 2019, IEEE T GEOSCI REMOTE, V57, P9362, DOI 10.1109/TGRS.2019.2926397
   Martins VS, 2020, ISPRS J PHOTOGRAMM, V168, P56, DOI 10.1016/j.isprsjprs.2020.08.004
   Mattyus G, 2017, IEEE I CONF COMP VIS, V0, PP3458, DOI 10.1109/ICCV.2017.372
   Menon AK, 2018, MACH LEARN, V107, P1561, DOI 10.1007/s10994-018-5715-3
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Qiu J, 2016, PHOTOGRAMM ENG REM S, V82, P593, DOI 10.14358/PERS.82.8.593
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rowland M., 2018, P MACHINE LEARNING R, V84, P29
   Sun T, 2019, PROC CVPR IEEE, V0, PP7501, DOI 10.1109/CVPR.2019.00769
   Tao C, 2019, ISPRS J PHOTOGRAMM, V158, P155, DOI 10.1016/j.isprsjprs.2019.10.001
   Tu B, 2019, IEEE T GEOSCI REMOTE, V57, P5085, DOI 10.1109/TGRS.2019.2896471
   Upadhyay D, 2021, IEEE T NETW SCI ENG, V8, P2559, DOI 10.1109/TNSE.2021.3099371
   Volodymyr Mnih, 2013, INT C MACH LEARN, V0, P0
   Wang EP, 2019, FOOD POLICY, V89, P0, DOI 10.1016/j.foodpol.2019.101791
   Wang WX, 2016, J TRAFFIC TRANSP ENG, V3, P271, DOI 10.1016/j.jtte.2016.05.005
   Wiedemann C., 1998, EMPIRICAL EVALUATION, V12, P172
   Yuan JY, 2018, IEEE T PATTERN ANAL, V40, P2793, DOI 10.1109/TPAMI.2017.2750680
   Zang Y, 2016, IEEE T GEOSCI REMOTE, V54, P3322, DOI 10.1109/TGRS.2016.2514602
   Zhang J, 2021, IEEE T KNOWL DATA EN, V33, P2083, DOI 10.1109/TKDE.2019.2951668
   Zhang JF, 2020, J CLEAN PROD, V271, P0, DOI 10.1016/j.jclepro.2020.122429
   Zhang J, 2021, IEEE T GEOSCI REMOTE, V59, P1836, DOI 10.1109/TGRS.2020.3003425
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou MT, 2020, ISPRS J PHOTOGRAMM, V168, P288, DOI 10.1016/j.isprsjprs.2020.08.019
   Zhu QQ, 2021, ISPRS J PHOTOGRAMM, V175, P353, DOI 10.1016/j.isprsjprs.2021.03.016
NR 45
TC 5
Z9 5
U1 7
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 15
PY 2021
VL 104
IS 
BP 
EP 
DI 10.1016/j.jag.2021.102544
PG 14
WC Remote Sensing
SC Remote Sensing
GA WD0OU
UT WOS:000704648000004
DA 2023-04-26
ER

PT J
AU Zou, SY
   Wang, L
AF Zou, Shengyuan
   Wang, Le
TI Detecting individual abandoned houses from google street view: A hierarchical deep learning approach
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Residential housing abandonment; Street view; Knowledge-guided deep learning; Patch-based classification
ID vacancy; addresses
AB Abandoned houses (AH) are focal points in urban communities by threatening local security, destroying housing markets, and burdening government finance in the U.S. legacy cities. In particular, individual-level AH detection provides essential information for fine-resolution urban studies, government decision-makers, and private sector practitioners. However, three primary conventional data sources (field data, utility data, and remote sensing data) cannot suffice to collect such fine-resolution data in the large spatial area via a cost-effective approach. To this end, Google Street View (GSV) imagery, which emerges as the mainstream open-access data source with global coverage, provides an opportunity to address this issue. Subsequently, a follow-up challenge confronting the detection of AH arises from the fact that it lacks an effective method that can discern authentic visual features from the redundant noise in GSV images. In this study, we aim to develop an effective method to detect individual-level AH from GSV imagery. Specifically, we developed a new hierarchical deep learning method to leverage both global and local visual features of AH in the detection. The method can be further divided into three steps: (1) Scene-based classification that can extract global visual features of AH was implemented through fine-tuning a pre-trained deep convolutional neural network (CNN) model. (2) We developed a patch-based classification method that can extract specific local features of AH. In this method, patches were generated from GSV images based on auto-detected local features, followed by being labeled as three categories: building patches, vegetation patches, and others. Two deep CNN models were employed to identify deteriorated building facade patches and overgrown vegetation patches, respectively. (3) Individual-level AH were detected by integrating scene classification results and patch classification results in a decision-tree model. Experimental results showed that the F-score of AH was 0.84 in a well-prepared dataset collected from five different Rust Belt cities. The proposed hierarchical deep learning approach effectively improved the accuracy comparing with the traditional scene-based method. In addition, the proposed method was applied to generate an AH map in a new site in Detroit, MI. Our study demonstrated the feasibility of GSV imagery in AH detection and showed great potential to detect AH in a large spatial extent.
C1 [Zou, Shengyuan; Wang, Le] Univ Buffalo State Univ New York, Dept Geog, Amherst, NY 14261 USA.
RP Wang, L (corresponding author), Univ Buffalo State Univ New York, Dept Geog, Amherst, NY 14261 USA.
EM szou2@buffalo.edu; lewang@buffalo.edu
CR Abbott G.R, 2007, BUILDING CONDITION A, V0, P0
   Accordino J, 2000, J URBAN AFF, V22, P301, DOI 10.1111/0735-2166.00058
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   Bentley GC, 2016, URBAN GEOGR, V37, P785, DOI 10.1080/02723638.2015.1112642
   Bosch A, 2007, IEEE I CONF COMP VIS, V0, P1863
   Chen ZQ, 2015, IEEE J-STARS, V8, P2188, DOI 10.1109/JSTARS.2015.2418201
   Deng CB, 2015, LANDSCAPE URBAN PLAN, V141, P88, DOI 10.1016/j.landurbplan.2015.05.002
   Deng CB, 2010, INT J REMOTE SENS, V31, P5673, DOI 10.1080/01431161.2010.496806
   Du MZ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10121920
   Elwood S, 2012, ANN ASSOC AM GEOGR, V102, P571, DOI 10.1080/00045608.2011.595657
   Frazier AE, 2013, APPL GEOGR, V41, P55, DOI 10.1016/j.apgeog.2013.02.014
   Griffin T.L, 2015, MAPPING AMERICAS LEG, V0, P0
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hillier AE, 2003, J URBAN AFF, V25, P91, DOI 10.1111/1467-9906.00007
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Kang J, 2018, ISPRS J PHOTOGRAMM, V145, P44, DOI 10.1016/j.isprsjprs.2018.02.006
   Koch D, 2018, RETECH18: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON MULTIMEDIA FOR REAL ESTATE TECH, V0, PP12, DOI 10.1145/3210499.3210526
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kumagai K, 2016, INT ARCH PHOTOGRAMM, V41, P709, DOI 10.5194/isprsarchives-XLI-B2-709-2016
   Kurth Joel, 2015, DETROIT NEWS, V0, P0
   Laumer D, 2020, ISPRS J PHOTOGRAMM, V162, P125, DOI 10.1016/j.isprsjprs.2020.02.001
   Law S, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3342240
   Li XJ, 2017, GISCI REMOTE SENS, V54, P819, DOI 10.1080/15481603.2017.1338389
   Li XJ, 2015, URBAN FOR URBAN GREE, V14, P675, DOI 10.1016/j.ufug.2015.06.006
   Li Z., 2019, SHRINKING CITIES CHI, V0, PP141, DOI 10.1007/978-981-13-2646-2_8
   Lin CY, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20102907
   Lynch A, 2017, CITIES, V60, P301, DOI 10.1016/j.cities.2016.09.011
   Mallach A., 2018, EMPTY HOUSE NEXT DOO, V0, P0
   Mallach A., 2012, DEPOPULATION MARKET, V0, P85
   Molloy R, 2016, REG SCI URBAN ECON, V59, P118, DOI 10.1016/j.regsciurbeco.2016.06.002
   Morckel V, 2014, COMMUNITY DEV, V45, P121, DOI 10.1080/15575330.2014.892019
   Morckel VC, 2014, APPL GEOGR, V48, P8, DOI 10.1016/j.apgeog.2014.01.001
   Morckel VC, 2013, HOUS POLICY DEBATE, V23, P469, DOI 10.1080/10511482.2013.788051
   Raleigh E, 2015, J URBAN AFF, V37, P367, DOI 10.1111/juaf.12102
   Raman A, 2019, CHEERS STREET VIEWS, V0, P0
   Scafidi BP, 1998, J HOUS ECON, V7, P287, DOI 10.1006/jhec.1998.0235
   Silverman RM, 2013, J URBAN AFF, V35, P131, DOI 10.1111/j.1467-9906.2012.00627.x
   Simonyan K, 2015, ARXIV, V0, P0
   U.S. Government Accountability Office, 1978, HOUS AB NAT PROBL NE, V0, P0
   U.S. Government Accountability Office (GAO), 2011, VAC PROP GROW NUMB I, V0, P0
   Wang L, 2019, IEEE INT CONF ADV LE, V0, PP1, DOI 10.1109/ICALT.2019.00007
   Weiss Karl, 2016, JOURNAL OF BIG DATA, V3, P0, DOI 10.1186/s40537-016-0043-6
   Wiechmann T, 2012, INT J URBAN REGIONAL, V36, P261, DOI 10.1111/j.1468-2427.2011.01095.x
   Yin L, 2015, ISPRS INT J GEO-INF, V4, P1184, DOI 10.3390/ijgi4031184
   Yongling Yao, 2011, PROCEEDINGS OF THE 2011 IEEE INTERNATIONAL CONFERENCE ON SPATIAL DATA MINING AND GEOGRAPHICAL KNOWLEDGE SERVICES (ICSDM 2011), V0, PP457, DOI 10.1109/ICSDM.2011.5969087
   Zeppelzauer M, 2018, ICMR 18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, V0, PP126, DOI 10.1145/3206025.3206060
   Zhang F, 2019, ISPRS J PHOTOGRAMM, V153, P48, DOI 10.1016/j.isprsjprs.2019.04.017
   Zhang WX, 2017, COMPUT ENVIRON URBAN, V64, P215, DOI 10.1016/j.compenvurbsys.2017.03.001
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zou SY, 2020, ANN AM ASSOC GEOGR, V110, P449, DOI 10.1080/24694452.2019.1665492
NR 50
TC 8
Z9 9
U1 8
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY 15
PY 2021
VL 175
IS 
BP 298
EP 310
DI 10.1016/j.isprsjprs.2021.03.020
EA APR 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RT8HA
UT WOS:000644695700021
DA 2023-04-26
ER

PT J
AU Cui, XD
   Yang, FL
   Wang, X
   Ai, B
   Luo, Y
   Ma, D
AF Cui, Xiaodong
   Yang, Fanlin
   Wang, Xin
   Ai, Bo
   Luo, Yu
   Ma, Dan
TI Deep learning model for seabed sediment classification based on fuzzy ranking feature optimization
SO MARINE GEOLOGY
LA English
DT Article
DE Seabed sediment classification; Multibeam echo-sounding system; Feature selection; Deep belief network; Supervised classification
ID multibeam acoustic data; scale; shelf; identification; backscatter; bathymetry; curves
AB Accurate acquisition of information on seabed sediment distributions plays an important role in the construction of basic marine geographic databases. Although a multibeam echo-sounding system (MBES) can satisfy large-scale seafloor mapping with high precision and high resolution, the development of a consistent, stable, repeatable and validated seabed sediment classification method based on swath acoustic data is still in its infancy. To achieve accurate prediction and mapping of geographic seabed sediment information, this paper developed a deep learning model based on feature optimization. First, faced with high-dimensional features extracted from multibeam bathymetry and backscatter intensity measurement data, a fuzzy ranking (FR) feature optimization method was proposed. By combining the physical properties of actual sediment samples, the multidimensional features derived from terrain and intensity data are ranked and optimally selected according to the mean square error to eliminate redundant and irrelevant features. Second, the deep belief network (DBN) deep learning method was used to build a supervised seabed sediment classification model. The optimized features and actual sediment samples participate in model training, which further enhances the prediction ability of acoustic data to seabed sediments. Finally, to evaluate the performance of the DBN model, this experiment used large-scale multibeam survey data and ground-truth data (acquired by grabbers, core samplers, dredges, etc.) in the southern Irish Sea to achieve accurate prediction of 10 sediment types (slightly gravelly muddy sand, slightly gravelly sand, gravelly mud, gravelly muddy sand, gravelly sand, muddy sand, muddy sandy gravel, sand, sandy gravel and sandy mud). The experiment results show that by using the optimal feature combination based on FR, the overall classification accuracy and Kappa coefficient reached 86.20% and 0.834, respectively, which are significantly improved compared to the evaluation metrics of other feature selection methods. In addition, compared with the current five typical supervised classification methods (i.e., the random forests, BP neural network, support vector machine, maximum likelihood and decision trees methods), the proposed DBN classification model achieves a better performance, highlighting its application potential in seabed sediment detection and mapping.
C1 [Cui, Xiaodong; Yang, Fanlin; Ai, Bo; Luo, Yu] Shandong Univ Sci & Technol, Coll Geodesy & Geomat, Qingdao 266590, Peoples R China.
   [Yang, Fanlin] Minist Nat Resources, Key Lab Surveying & Mapping Technol Isl & Reef, Qingdao 266590, Peoples R China.
   [Wang, Xin] Univ Calgary, Dept Geomat Engn, Calgary, AB T2N 1N4, Canada.
   [Ma, Dan] Natl Marine Data & Informat Serv, Tianjin 300171, Peoples R China.
C3 Shandong University of Science & Technology; Ministry of Natural Resources of the People's Republic of China; University of Calgary; National Marine Data & Information Service
RP Yang, FL (corresponding author), 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
EM flyang@126.com
FU National Natural Science Foundation of China [41930535, 41830540]; National Key R&D Program of China [2018YFF0212203, 2017YFC1405006, 2018YFC1405900, 2016YFC1401210]; SDUST Research Fund [2019TDJH103]
CR AITCHISON J, 1982, J ROY STAT SOC B, V44, P139
   [Anonymous], 1976, INT J NUMER METHODS, V0, P0
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Blondel P, 2009, APPL ACOUST, V70, P1288, DOI 10.1016/j.apacoust.2008.07.015
   Boswarva K, 2018, CONT SHELF RES, V168, P39, DOI 10.1016/j.csr.2018.09.005
   British Geological Survey, 2012, OPENGEOSCIENCE OFFSH, V0, P0
   Brown CJ, 2002, ESTUAR COAST SHELF S, V54, P263, DOI 10.1006/ecss.2001.0841
   Brown CJ, 2011, ESTUAR COAST SHELF S, V92, P502, DOI 10.1016/j.ecss.2011.02.007
   Brown CJ, 2009, APPL ACOUST, V70, P1242, DOI 10.1016/j.apacoust.2008.08.004
   Buhl-Mortensen P, 2009, ICES J MAR SCI, V66, P2026, DOI 10.1093/icesjms/fsp200
   CHE HR, 2012, REMOTE SENS, V4, P3427
   Clarke JEH, 1996, MAR GEOPHYS RES, V18, P607, DOI 10.1007/BF00313877
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cui XD, 2020, APPL ACOUST, V157, P0, DOI 10.1016/j.apacoust.2019.107029
   De Leo Fabio C, 2010, PROC BIOL SCI, V277, P2783, DOI 10.1098/rspb.2010.0462
   Demarchi L, 2014, ISPRS J PHOTOGRAMM, V87, P166, DOI 10.1016/j.isprsjprs.2013.10.012
   Diesing M, 2016, ICES J MAR SCI, V73, P2425, DOI 10.1093/icesjms/fsw118
   Diesing M, 2014, CONT SHELF RES, V84, P107, DOI 10.1016/j.csr.2014.05.004
   Elvenes S, 2014, ICES J MAR SCI, V71, P867, DOI 10.1093/icesjms/fst154
   Evans, 1995, TECHNICAL REPORT, V0, P0
   FOLK RL, 1970, NEW ZEAL J GEOL GEOP, V13, P937, DOI 10.1080/00288306.1970.10418211
   Glynn B, 2008, J GEOL SOC LONDON, V165, P597, DOI 10.1144/0016-76492006-186
   Guichard F, 1998, MAR ECOL PROG SER, V171, P59, DOI 10.3354/meps171059
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hosack GR, 2006, ESTUAR COAST, V29, P1150, DOI 10.1007/BF02781816
   Huang Z, 2012, INT J GEOGR INF SCI, V26, P283, DOI 10.1080/13658816.2011.590139
   Huang Z, 2011, CONT SHELF RES, V31, PS4, DOI 10.1016/j.csr.2010.03.012
   ICES, 2007, ICES COOP RES REP, V0, P1
   Ierodiaconou D, 2011, CONT SHELF RES, V31, PS28, DOI 10.1016/j.csr.2010.01.012
   Jensen H, 2005, TLS-TIMES LIT SUPPL, V0, P3
   Jianwei Qin, 2008, SENSING AND INSTRUMENTATION FOR FOOD QUALITY AND SAFETY, V2, P168, DOI 10.1007/s11694-008-9043-3
   Jordi A, 2005, PROG OCEANOGR, V66, P120, DOI 10.1016/j.pocean.2004.07.009
   Lanier A, 2007, MAR GEOD, V30, P51, DOI 10.1080/01490410701296143
   Lin YH, 1998, IEEE T SYST MAN CY A, V28, P678, DOI 10.1109/3468.709615
   Lin YH, 1996, FUZZY SET SYST, V82, P65, DOI 10.1016/0165-0114(95)00223-5
   Lucieer V, 2013, ESTUAR COAST SHELF S, V117, P94, DOI 10.1016/j.ecss.2012.11.001
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Marsh I, 2009, APPL ACOUST, V70, P1269, DOI 10.1016/j.apacoust.2008.07.012
   Max, 2013, R PACKAGE VERSION 5, V0, P0
   McGonigle C, 2014, ESTUAR COAST SHELF S, V147, P123, DOI 10.1016/j.ecss.2014.05.025
   McGonigle C, 2011, ESTUAR COAST SHELF S, V91, P87, DOI 10.1016/j.ecss.2010.10.016
   Michaels William, 2007, ACOUSTIC SEABED CLAS, V0, P0
   Robinson KA, 2012, ELSEV INSIGHT, V0, PP523, DOI 10.1016/B978-0-12-385140-6.00037-2
   Simons DG, 2009, APPL ACOUST, V70, P1258, DOI 10.1016/j.apacoust.2008.07.013
   SIMPSON JH, 1981, DEEP-SEA RES, V28, P727, DOI 10.1016/0198-0149(81)90132-1
   Stephens D, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0142502
   Su DP, 2019, IEEE T GEOSCI REMOTE, V57, P815, DOI 10.1109/TGRS.2018.2860931
   Wang BJ, 2013, COMPUT GEOSCI-UK, V57, P1, DOI 10.1016/j.cageo.2013.03.016
   Webb J., 2011, ENCY MACHINE LEARNIN, V0, PP267, DOI 10.1007/978-0-387-30164-8
   Wulsin DF, 2011, J NEURAL ENG, V8, P0, DOI 10.1088/1741-2560/8/3/036015
   Zajac RN, 2020, SEAFLOOR GEOMORPHOLOGY AS BENTHIC HABITAT: GEOHAB ATLAS OF SEAFLOOR GEOMORPHIC FEATURES AND BENTHIC HABITATS, V0, P199, DOI 10.1016/B978-0-12-814960-7.00010-5
   Zhi H, 2014, MAR GEOL, V357, P37, DOI 10.1016/j.margeo.2014.07.012
NR 52
TC 10
Z9 11
U1 4
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0025-3227
EI 1872-6151
J9 MAR GEOL
JI Mar. Geol.
PD FEB 15
PY 2021
VL 432
IS 
BP 
EP 
DI 10.1016/j.margeo.2020.106390
PG 14
WC Geosciences, Multidisciplinary; Oceanography
SC Geology; Oceanography
GA PS7YD
UT WOS:000608140700003
DA 2023-04-26
ER

PT J
AU Wong, PY
   Su, HJ
   Lee, HY
   Chen, YC
   Hsiao, YP
   Huang, JW
   Teo, TA
   Wu, CD
   Spengler, JD
   Klemes, JJ
AF Wong, Pei-Yi
   Su, Huey-Jen
   Lee, Hsiao-Yun
   Chen, Yu-Cheng
   Hsiao, Ya-Ping
   Huang, Jen-Wei
   Teo, Tee-Ann
   Wu, Chih-Da
   Spengler, John D.
   Klemes, Jiri Jaromir
TI Using land-use machine learning models to estimate daily NO2 concentration variations in Taiwan
SO JOURNAL OF CLEANER PRODUCTION
LA English
DT Article
DE NO < sub > 2 <; sub >; Land-use regression; Ordinary Kriging; Machine learning; Taiwan
ID use regression-model; nitrogen-dioxide concentrations; fine particulate matter; air-pollution exposure; neural-network; urban trees; pm2.5; incense; pollutants; resolution
AB It is likely that exposure surrogates from monitoring stations with various limitations are not sufficient for epidemiological studies covering large areas. Moreover, the spatiotemporal resolution of air pollution modelling approaches must be improved in order to achieve more accurate estimates. If not, the exposure assessments will not be applicable in future health risk assessments. To deal with this challenge, this study featured Land-Use Regression (LUR) models that use machine learning to assess the spatial-temporal variability of Nitrogen Dioxide (NO2). Daily average NO2 data was collected from 70 fixed air quality monitoring stations, belonging to the Taiwanese EPA, on the main island of Taiwan. Around 0.41 million observations from 2000 to 2016 were used for the analysis. Several datasets were employed to determine spatial predictor variables, including the EPA environmental resources dataset, the meteorological dataset, the land-use inventory, the landmark dataset, the digital road network map, the digital terrain model, MODIS Normalized Difference Vegetation Index database, and the power plant distribution dataset. Regarding analyses, conventional LUR and Hybrid Kriging-LUR were performed first to identify important predictor variables. A Deep Neural Network, Random Forest, and XGBoost algorithms were then used to fit the prediction model based on the variables selected by the LUR models. Lastly, data splitting, 10-fold cross validation, external data verification, and seasonal-based and county-based validation methods were applied to verify the robustness of the developed models. The results demonstrated that the proposed conventional LUR and Hybrid Kriging-LUR models captured 65% and 78%, respectively, of NO2 variation. When the XGBoost algorithm was further incorporated in LUR and hybrid-LUR, the explanatory power increased to 84% and 91%, respectively. The Hybrid Kriging-LUR with XGBoost algorithm outperformed all other integrated methods. This study demonstrates the value of combining Hybrid Kriging-LUR model and an XGBoost algorithm to estimate the spatial-temporal variability of NO2 exposure. For practical application, the associations of specific land-use/land cover types selected in the final model can be applied in land-use management and in planning emission reduction strategies.
C1 [Wong, Pei-Yi; Su, Huey-Jen] Natl Cheng Kung Univ, Dept Environm & Occupat Hlth, Tainan, Taiwan.
   [Lee, Hsiao-Yun] Natl Taipei Univ Nursing & Hlth Sci, Dept Leisure Ind & Hlth Promot, Taipei, Taiwan.
   [Chen, Yu-Cheng; Spengler, John D.] Natl Hlth Res Inst, Natl Inst Environm Hlth Sci, Miaoli, Taiwan.
   [Hsiao, Ya-Ping; Spengler, John D.] Natl Cheng Kung Univ, Dept Geomat, Tainan, Taiwan.
   [Huang, Jen-Wei] Natl Cheng Kung Univ, Dept Elect Engn, Tainan, Taiwan.
   [Teo, Tee-Ann] Natl Yang Ming Chiao Tung Univ, Dept Civil Engn, Hsinchu, Taiwan.
   [Klemes, Jiri Jaromir] Harvard TH Chan Sch Publ Hlth, Dept Environm Hlth, Boston, MA USA.
C3 National Cheng Kung University; National Taipei University of Nursing & Health Science (NTUNHS); National Health Research Institutes - Taiwan; National Cheng Kung University; National Cheng Kung University; National Yang Ming Chiao Tung University; Harvard University; Harvard T.H. Chan School of Public Health
RP Wu, CD (corresponding author), Natl Cheng Kung Univ, Dept Geomat, 1 Univ Rd, Tainan 701, Taiwan.
EM chidawu@mail.ncku.edu.tw
FU Ministry of Science and Technology, R.O. C. [MOST 108-2621-M-006-017-, MOST 108-2638-B-006-001-MY2]; National Health Research Institutes [NHRI-109A1-EMCO-02202312]
CR Achakulwisut P, 2019, LANCET PLANET HEALTH, V3, PE166, DOI 10.1016/S2542-5196(19)30046-4
   Adams MD, 2016, J ENVIRON MANAGE, V168, P133, DOI 10.1016/j.jenvman.2015.12.012
   Alexeeff SE, 2015, J EXPO SCI ENV EPID, V25, P138, DOI 10.1038/jes.2014.40
   Araki S, 2018, SCI TOTAL ENVIRON, V634, P1269, DOI 10.1016/j.scitotenv.2018.03.324
   Beelen R, 2013, ATMOS ENVIRON, V72, P10, DOI 10.1016/j.atmosenv.2013.02.037
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Briggs DJ, 1997, INT J GEOGR INF SCI, V11, P699, DOI 10.1080/136588197242158
   Brunekreef B, 2002, LANCET, V360, P1233, DOI 10.1016/S0140-6736(02)11274-8
   Chan TC, 2009, INT J HEALTH GEOGR, V8, P0, DOI 10.1186/1476-072X-8-26
   Chen J, 2019, ENVIRON INT, V130, P0, DOI 10.1016/j.envint.2019.104934
   Chen KS, 2004, J AIR WASTE MANAGE, V54, P36, DOI 10.1080/10473289.2004.10470880
   Chen TQ, 2016, KDD16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, V0, PP785, DOI 10.1145/2939672.2939785
   Chuang HC, 2013, J HAZARD MATER, V244, P142, DOI 10.1016/j.jhazmat.2012.11.034
   Di Q, 2020, ENVIRON SCI TECHNOL, V54, P1372, DOI 10.1021/acs.est.9b03358
   Eeftens M, 2012, ENVIRON SCI TECHNOL, V46, P11195, DOI 10.1021/es301948k
   Fantozzi F, 2015, URBAN CLIM, V12, P119, DOI 10.1016/j.uclim.2015.02.001
   Han H, 2016, INT CONF SOFTW ENG, V0, PP219, DOI 10.1109/ICSESS.2016.7883053
   Ierodiakonou D, 2016, J ALLERGY CLIN IMMUN, V137, P390, DOI 10.1016/j.jaci.2015.05.028
   Jerrett M, 2005, EPIDEMIOLOGY, V16, P727, DOI 10.1097/01.ede.0000181630.15826.7d
   Jiao C, 2020, ENVIRON POLLUT, V259, P0, DOI 10.1016/j.envpol.2019.113778
   Joharestani MZ, 2019, ATMOSPHERE-BASEL, V10, P0, DOI 10.3390/atmos10070373
   Jung CR, 2019, SCI TOTAL ENVIRON, V668, P342, DOI 10.1016/j.scitotenv.2019.03.018
   Kaminska JA, 2019, SCI TOTAL ENVIRON, V651, P475, DOI 10.1016/j.scitotenv.2018.09.196
   Kampa M, 2008, ENVIRON POLLUT, V151, P362, DOI 10.1016/j.envpol.2007.06.012
   Kenagy HS, 2016, AIR QUAL ATMOS HLTH, V9, P589, DOI 10.1007/s11869-015-0370-3
   Lee CS, 2018, ENVIRON SCI POLLUT R, V25, P22136, DOI 10.1007/s11356-018-2273-y
   Lee SC, 2004, ATMOS ENVIRON, V38, P941, DOI 10.1016/j.atmosenv.2003.11.002
   Lin Ta-Chang, 2008, CLIN MOL ALLERGY, V6, P3, DOI 10.1186/1476-7961-6-3
   Lui KH, 2016, ENVIRON POLLUT, V213, P524, DOI 10.1016/j.envpol.2016.02.053
   Lung SCC, 2003, J AIR WASTE MANAGE, V53, P130, DOI 10.1080/10473289.2003.10466140
   Michanowicz DR, 2016, TRANSPORT RES D-TR E, V43, P181, DOI 10.1016/j.trd.2015.12.007
   Moore DK, 2007, J ENVIRON MONITOR, V9, P246, DOI 10.1039/b615795e
   Motc, 2020, VEH STAT, V0, P0
   National Religion Information Network, 2020, OV REL AFF, V0, P0
   Qu Y, 2016, J ENVIRON SCI, V44, P13, DOI 10.1016/j.jes.2015.08.028
   Rao M, 2014, ENVIRON POLLUT, V194, P96, DOI 10.1016/j.envpol.2014.07.011
   Sbihi H, 2016, EUR RESPIR J, V47, P1062, DOI 10.1183/13993003.00746-2015
   Soh PW, 2018, IEEE ACCESS, V6, P38186, DOI 10.1109/ACCESS.2018.2849820
   Speiser JL, 2019, EXPERT SYST APPL, V134, P93, DOI 10.1016/j.eswa.2019.05.028
   Wong PY, 2021, ENVIRON MODELL SOFTW, V139, P0, DOI 10.1016/j.envsoft.2021.104996
   Wong PY, 2021, ENVIRON POLLUT, V277, P0, DOI 10.1016/j.envpol.2021.116846
   Wu CD, 2018, SCI TOTAL ENVIRON, V645, P1456, DOI 10.1016/j.scitotenv.2018.07.073
   Wu CD, 2017, ENVIRON POLLUT, V224, P148, DOI 10.1016/j.envpol.2017.01.074
   Wu SW, 2016, ENVIRON INT, V94, P76, DOI 10.1016/j.envint.2016.05.004
   Wu TJ, 2020, RESP MED, V172, P0, DOI 10.1016/j.rmed.2020.106133
   Xu H, 2019, SCI TOTAL ENVIRON, V655, P423, DOI 10.1016/j.scitotenv.2018.11.125
   Yin S, 2011, ENVIRON POLLUT, V159, P2155, DOI 10.1016/j.envpol.2011.03.009
   Young MT, 2016, ENVIRON SCI TECHNOL, V50, P3686, DOI 10.1021/acs.est.5b05099
   Yu KP, 2015, BUILD ENVIRON, V93, P258, DOI 10.1016/j.buildenv.2015.06.024
   Zhang ZY, 2018, ATMOS ENVIRON, V192, P48, DOI 10.1016/j.atmosenv.2018.08.046
   Zhou YL, 2019, J CLEAN PROD, V209, P134, DOI 10.1016/j.jclepro.2018.10.243
NR 51
TC 9
Z9 9
U1 9
U2 34
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0959-6526
EI 1879-1786
J9 J CLEAN PROD
JI J. Clean Prod.
PD OCT 1
PY 2021
VL 317
IS 
BP 
EP 
DI 10.1016/j.jclepro.2021.128411
EA JUL 2021
PG 9
WC Green & Sustainable Science & Technology; Engineering, Environmental; Environmental Sciences
SC Science & Technology - Other Topics; Engineering; Environmental Sciences & Ecology
GA XE1KL
UT WOS:000723154200006
DA 2023-04-26
ER
