
PT J
AU Liu, B
   Gao, L
   Li, B
   Marcos-Martinez, R
   Bryan, BA
AF Liu, Bao
   Gao, Lei
   Li, Baoan
   Marcos-Martinez, Raymundo
   Bryan, Brett A.
TI Nonparametric machine learning for mapping forest cover and exploring influential factors
SO LANDSCAPE ECOLOGY
LA English
DT Article
DE Machine learning; Support vector regression; Artificial neural network; Random forest; Gradient boosted regression tree; Forest cover
ID support vector machines; land-use; logistic-regression; deep uncertainty; dynamics; network; scale; classification; drivers; climate
AB Context The contribution of forest ecosystem services to human well-being varies over space following the dynamics in forest cover. Use of machine learning models is increasing in projecting forest cover changes and investigating the drivers, yet references are still lacking for selecting machine learning models for spatial projection of forest cover patterns. Objectives We assessed the ability of nonparametric machine learning techniques to project the spatial distribution of forest cover and identify its drivers using a case study of Tasmania, Australia. Methods We developed, evaluated, and compared the performance of four nonparametric machine learning models: support vector regression (SVR), artificial neural networks (ANN), random forest (RF), and gradient boosted regression trees (GBRT). Results The results demonstrated that RF far outperformed the other three models in both fitting and projection accuracy, and required less computional costs. GBRT outperformed SVR and ANN in projection accuracy. However, RF exhibited serious overfitting due to the full growth of its decision trees. The influence rankings of explanatory variables on spatial patterns of forest cover were different under the four models. Land tenure type and rainfall were identified among the top four most influential variables by all four models. The ranking produced by the RF model was significantly different with topographic factors associated with land clearing and production costs (elevation and distance to timber facilities) being the two most influential variables. Conclusions We encourage practitioners to consider nonparametric machine learning methods, especially RF, when facing problems of complex environmental data modelling.
C1 [Liu, Bao; Li, Baoan] China Univ Petr East China, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
   [Gao, Lei] CSIRO, Waite Campus, Urrbrae, SA 5064, Australia.
   [Gao, Lei] Shandong Normal Univ, Sch Business, Jinan 250014, Peoples R China.
   [Marcos-Martinez, Raymundo] CSIRO, Csiro, ACT 2601, Australia.
   [Bryan, Brett A.] Deakin Univ, Ctr Integrat Ecol, Melbourne Burwood Campus, Burwood, Vic 3125, Australia.
C3 China University of Petroleum; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Shandong Normal University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Deakin University
RP Gao, L (corresponding author), CSIRO, Waite Campus, Urrbrae, SA 5064, Australia.
EM lei.gao@csiro.au
FU Fundamental Research Funds for the Central Universities [20CX05006A]; CSIRO Julius award; CSIRO 2018/19 Land and Water Appropriation Project
CR ABARES, 2014, TEN AUSTR FOR 2013 V, V0, P0
   ACLEP, 2014, NAT SOIL DAT PROV AU, V0, P0
   Andam KS, 2008, P NATL ACAD SCI USA, V105, P16089, DOI 10.1073/pnas.0800437105
   Australia Bureau of Meteorology, 2015, CLIM DAT ONL, V0, P0
   Baskent EZ, 2007, LANDSCAPE URBAN PLAN, V81, P316, DOI 10.1016/j.landurbplan.2007.01.007
   Ben Taieb S, 2014, INT J FORECASTING, V30, P382, DOI 10.1016/j.ijforecast.2013.07.005
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 1984, CLASSIFICATION REGRE, V0, P0, DOI DOI 10.1002/widm.8
   Brereton RG, 2010, ANALYST, V135, P230, DOI 10.1039/b918972f
   Bryan BA, 2013, ENVIRON MODELL SOFTW, V39, P295, DOI 10.1016/j.envsoft.2012.02.006
   Caccetta P, 2012, GLOBAL EST MONITO, V0, PP243, DOI 10.1201/B13040-14
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, P0, DOI 10.1145/1961189.1961199
   Cohen WB, 2001, INT J REMOTE SENS, V22, P2279, DOI 10.1080/014311601300229827
   Cracknell MJ, 2014, COMPUT GEOSCI-UK, V63, P22, DOI 10.1016/j.cageo.2013.10.008
   Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1
   Department of Agriculture and Water Resources, 2013, ASUTR WAT RES, V0, P0
   Department of the Environment, 2014, COLL AUSTR PROT AR D, V0, P0
   Dong M, 2015, ECOSYST SERV, V15, P63, DOI 10.1016/j.ecoser.2015.07.006
   Dormann CF, 2013, ECOGRAPHY, V36, P27, DOI 10.1111/j.1600-0587.2012.07348.x
   Du GD, 2018, INT J GEOGR INF SCI, V32, P757, DOI 10.1080/13658816.2017.1410550
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Ferretti-Gallon K, 2014, METAANALYSIS SPATIAL, V0, P0
   Foley JA, 2005, SCIENCE, V309, P570, DOI 10.1126/science.1111772
   Forest Practices Authority, 2017, STAT FOR TASM 2017, V0, P0
   Freeman EA, 2016, CAN J FOREST RES, V46, P323, DOI 10.1139/cjfr-2014-0562
   Freitas SR, 2010, FOREST ECOL MANAG, V259, P410, DOI 10.1016/j.foreco.2009.10.036
   Freund Y., 1996, ICML, V0, PP148, DOI 10.5555/3091696.3091715
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Gallant J, 2011, SRTM DERIVED ONE SEC, V0, P0
   Gao L, 2004, INT J INTELL SYST, V19, P859, DOI 10.1002/int.20028
   Gao L, 2017, J CLEAN PROD, V162, P1009, DOI 10.1016/j.jclepro.2017.06.101
   Gao L, 2017, NATURE, V544, P217, DOI 10.1038/nature21694
   Gao L, 2016, ENVIRON MODELL SOFTW, V76, P154, DOI 10.1016/j.envsoft.2015.11.001
   Gao L, 2016, ECOL MODEL, V321, P1, DOI 10.1016/j.ecolmodel.2015.10.016
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Giriraj A, 2008, SENSORS-BASEL, V8, P6132, DOI 10.3390/s8106132
   GISCA, 2001, ACC REM IND AUSTR AR, V0, P0
   Gleason CJ, 2012, REMOTE SENS ENVIRON, V125, P80, DOI 10.1016/j.rse.2012.07.006
   Hansen MC, 2004, ECOSYSTEMS, V7, P695, DOI 10.1007/s10021-004-0243-3
   Hastie T., 2009, UNSUPERVISED LEARNIN, V0, PP485, DOI 10.1007/978-0-387-84858-7_14
   Hu XS, 2014, ECOL INDIC, V46, P121, DOI 10.1016/j.ecolind.2014.06.015
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Huang X, 2019, WATER-SUI, V11, P0, DOI 10.3390/w11091879
   Jain RK, 2014, APPL ENERG, V123, P168, DOI 10.1016/j.apenergy.2014.02.057
   Jiang ZJ, 2019, HYDROL EARTH SYST SC, V23, P2561, DOI 10.5194/hess-23-2561-2019
   Jones DA, 2009, AUST METEOROL OCEAN, V58, P233, DOI 10.22499/2.5804.003
   Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Kohavi R., 1995, P 14 INT JOINT C ART, V0, P1137
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar R, 2014, ECOL INDIC, V45, P444, DOI 10.1016/j.ecolind.2014.05.003
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lehmann EA, 2013, INT J APPL EARTH OBS, V21, P453, DOI 10.1016/j.jag.2012.06.005
   Leinenkugel P, 2014, INT J REMOTE SENS, V35, P2799, DOI 10.1080/01431161.2014.890302
   Lin SL, 2017, PEERJ, V5, P0, DOI 10.7717/peerj.3320
   Lin YP, 2011, INT J GEOGR INF SCI, V25, P65, DOI 10.1080/13658811003752332
   Ludwig M, 2019, REMOTE SENS ENVIRON, V222, P195, DOI 10.1016/j.rse.2018.12.019
   Makinano-Santillan MM, 2001, MERGING LANDSAT IMAG, V0, P0
   Marcos-Martinez R, 2019, ECOSYST SERV, V37, P0, DOI 10.1016/j.ecoser.2019.100935
   Marcos-Martinez R, 2018, FOREST POLICY ECON, V86, P67, DOI 10.1016/j.forpol.2017.10.021
   Marcos-Martinez R, 2017, LAND USE POLICY, V63, P53, DOI 10.1016/j.landusepol.2017.01.011
   Marinoni O, 2012, AGR SYST, V105, P33, DOI 10.1016/j.agsy.2011.09.002
   Mas JF, 2004, ENVIRON MODELL SOFTW, V19, P461, DOI 10.1016/S1364-8152(03)00161-0
   Mayfield H, 2017, ENVIRON MODELL SOFTW, V87, P17, DOI 10.1016/j.envsoft.2016.10.006
   McMichael A., 2005, MILLENIUM ECOSYSTEM, V0, P43
   Micheletti N, 2014, MATH GEOSCI, V46, P33, DOI 10.1007/s11004-013-9511-0
   Nahib I, 2017, IOP C SER EARTH ENV, V54, P0, DOI 10.1088/1755-1315/54/1/012044
   Norvig P., 2016, ARTIF INTELL, V0, P0
   Opitz D., 1999, J ARTIF INTELL RES, V11, P0, DOI 10.1613/JAIR.614
   Palmate SS, 2017, APPL WATER SCI, V7, P103, DOI 10.1007/s13201-014-0222-6
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peeters LJM, 2018, ENVIRON MODELL SOFTW, V109, P353, DOI 10.1016/j.envsoft.2018.08.020
   Pijanowski B. C., 2002, COMPUTERS, V0, P0
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, V0, P185
   Pressey RL, 2002, BIOL CONSERV, V106, P57, DOI 10.1016/S0006-3207(01)00229-4
   Schwieder M, 2014, REMOTE SENS-BASEL, V6, P3427, DOI 10.3390/rs6043427
   Simard M, 2011, J GEOPHYS RES-BIOGEO, V116, P0, DOI 10.1029/2011JG001708
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Sola J, 1997, IEEE T NUCL SCI, V44, P1464, DOI 10.1109/23.589532
   Sun H, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081248
   Wang X, 2016, ADV MECH ENG, V8, P0, DOI 10.1177/1687814016628395
   Wei B, 2021, IEEE T COGN DEV SYST, V13, P503, DOI 10.1109/TCDS.2020.2977974
   Were K, 2015, ECOL INDIC, V52, P394, DOI 10.1016/j.ecolind.2014.12.028
   Wheeler D, 2013, ECOL ECON, V85, P85, DOI 10.1016/j.ecolecon.2012.11.005
   Ye L, 2019, ENVIRON MODELL SOFTW, V119, P407, DOI 10.1016/j.envsoft.2019.07.013
   Zhou WQ, 2011, LANDSCAPE ECOL, V26, P645, DOI 10.1007/s10980-011-9589-z
NR 90
TC 4
Z9 4
U1 8
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0921-2973
EI 1572-9761
J9 LANDSCAPE ECOL
JI Landsc. Ecol.
PD JUL 15
PY 2020
VL 35
IS 7
BP 1683
EP 1699
DI 10.1007/s10980-020-01046-0
EA JUN 2020
PG 17
WC Ecology; Geography, Physical; Geosciences, Multidisciplinary
SC Environmental Sciences & Ecology; Physical Geography; Geology
GA MC7SA
UT WOS:000537990300001
DA 2023-04-26
ER

PT J
AU Zhao, S
   Liu, XN
   Ding, C
   Liu, SY
   Wu, CS
   Wu, L
AF Zhao, Shuang
   Liu, Xiangnan
   Ding, Chao
   Liu, Shuyuan
   Wu, Changshan
   Wu, Ling
TI Mapping Rice Paddies in Complex Landscapes with Convolutional Neural Networks and Phenological Metrics
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Rice mapping; Image classification; deep learning; CNNs; phenological metrics
ID time-series; crop classification; data set; area; images; intensification; agriculture; extraction; evolution; accuracy
AB Rice mapping with remote sensing imagery provides an alternative means for estimating crop-yield and performing land management due to the large geographical coverage and low cost of remotely sensed data. Rice mapping in Southern China, however, is very difficult as rice paddies are patchy and fragmented, reflecting the undulating and varied topography. In addition, abandoned lands widely exist in Southern China due to rapid urbanization. Abandoned lands are easily confused with paddy fields, thereby degrading the classification accuracy of rice paddies in such complex landscape regions. To address this problem, the present study proposes an innovative method for rice mapping through combining a convolutional neural network (CNN) model and a decision tree (DT) method with phenological metrics. First, a pre-trained LeNet-5 Model using the UC Merced Dataset was developed to classify the cropland class from other land cover types, i.e. built-up, rivers, forests. Then, paddy rice field was separated from abandoned land in the cropland class using a DT model with phenological metrics derived from the time-series data of the normalized difference vegetation index (NDVI). The accuracy of the proposed classification methods was compared with three other classification techniques, namely, back propagation neural network (BPNN), original CNN, pre-trained CNN applied to HJ-1 A/B charge-coupled device (CCD) images of Zhuzhou City, Hunan Province, China. Results suggest that the proposed method achieved an overall accuracy of 93.56%, much higher than those of other methods. This indicates that the proposed method can efficiently accommodate the challenges of rice mapping in regions with complex landscapes.
C1 [Zhao, Shuang; Wu, Changshan] Tianjin Chengjian Univ, Sch Geol & Geomet, Tianjin, Peoples R China.
   [Liu, Xiangnan; Wu, Ling] China Univ Geosci Beijing, Sch Informat Engn, Beijing, Peoples R China.
   [Ding, Chao] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Key Lab Digital Earth Sci, Beijing, Peoples R China.
   [Liu, Shuyuan] Esri China Informat Technol Co Ltd, Beijing, Peoples R China.
   [Wu, Changshan] Univ Wisconsin, Dept Geog, Milwaukee, WI 53201 USA.
C3 Tianjin Chengjian University; China University of Geosciences; Chinese Academy of Sciences; The Institute of Remote Sensing & Digital Earth, CAS; University of Wisconsin System; University of Wisconsin Milwaukee
RP Liu, XN (corresponding author), China Univ Geosci Beijing, Sch Informat Engn, Beijing, Peoples R China.
EM liuxn@cugb.edu.cn
FU National Natural Science Foundation of China Youth Science Foundation Project [41701387]
CR [Anonymous], 2010, 18 SIGSPATIAL INT C, V0, P0, DOI DOI 10.1145/1869790.1869829
   Avramovic A, 2016, SIGNAL IMAGE VIDEO P, V10, P75, DOI 10.1007/s11760-014-0704-x
   Bargiel D, 2017, REMOTE SENS ENVIRON, V198, P369, DOI 10.1016/j.rse.2017.06.022
   Boschetti M, 2013, EARS S, V0, P0, DOI DOI 10.5194/os-10-845-2014
   Bradley BA, 2007, REMOTE SENS ENVIRON, V106, P137, DOI 10.1016/j.rse.2006.08.002
   Chen J, 2004, REMOTE SENS ENVIRON, V91, P332, DOI 10.1016/j.rse.2004.03.014
   Chen JS, 2011, MATH COMPUT MODEL, V54, P1037, DOI 10.1016/j.mcm.2010.11.033
   Chockalingam J, 2017, IEEE J-STARS, V10, P5258, DOI 10.1109/JSTARS.2017.2748989
   Dong JW, 2016, ISPRS J PHOTOGRAMM, V119, P214, DOI 10.1016/j.isprsjprs.2016.05.010
   Du ZR, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070888
   Feng L, 2015, 2015 JOINT URBAN REMOTE SENSING EVENT (JURSE), V0, P0
   Gudex-Cross D, 2017, REMOTE SENS ENVIRON, V196, P193, DOI 10.1016/j.rse.2017.05.006
   Gumma MK, 2018, GISCI REMOTE SENS, V55, P926, DOI 10.1080/15481603.2018.1482855
   Gumma MK, 2011, J APPL REMOTE SENS, V5, P0, DOI 10.1117/1.3619838
   Hansen MC, 2012, REMOTE SENS ENVIRON, V122, P66, DOI 10.1016/j.rse.2011.08.024
   Bui HM, 2016, IEEE ACCESS, V4, P10059, DOI 10.1109/ACCESS.2016.2639543
   Kim HO, 2015, GISCI REMOTE SENS, V52, P1, DOI 10.1080/15481603.2014.1001666
   Kim M, 2017, GISCI REMOTE SENS, V54, P534, DOI 10.1080/15481603.2017.1291783
   Kontgis C, 2015, REMOTE SENS ENVIRON, V169, P255, DOI 10.1016/j.rse.2015.08.004
   Kovacs G, 2017, PATTERN RECOGN LETT, V100, P44, DOI 10.1016/j.patrec.2017.09.023
   Kumhalova J, 2017, INT AGROPHYS, V31, P195, DOI 10.1515/intag-2016-0046
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leutheuser H, 2013, PLOS ONE, V8, P0, DOI 10.1371/journal.pone.0075196
   Li DW, 2017, J INDIAN SOC REMOTE, V45, P229, DOI 10.1007/s12524-016-0597-y
   Liao ZB, 2017, PATTERN RECOGN, V71, P94, DOI 10.1016/j.patcog.2017.05.024
   Liu SY, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17061243
   Liu Y, 2013, COMPUT GEOSCI-UK, V59, P98, DOI 10.1016/j.cageo.2013.03.024
   MCCLOY KR, 1987, INT J REMOTE SENS, V8, P741, DOI 10.1080/01431168708948685
   Son NT, 2014, REMOTE SENS-BASEL, V6, P135, DOI 10.3390/rs6010135
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
   Onojeghuo AO, 2018, GISCI REMOTE SENS, V55, P659, DOI 10.1080/15481603.2018.1423725
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pena-Barragan JM, 2011, REMOTE SENS ENVIRON, V115, P1301, DOI 10.1016/j.rse.2011.01.009
   Phiri D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090967
   Qian PJ, 2017, KNOWL-BASED SYST, V130, P33, DOI 10.1016/j.knosys.2017.05.018
   Qin YW, 2015, ISPRS J PHOTOGRAMM, V105, P220, DOI 10.1016/j.isprsjprs.2015.04.008
   Qiu BW, 2017, SCI TOTAL ENVIRON, V598, P581, DOI 10.1016/j.scitotenv.2017.03.221
   Qiu BW, 2015, ECOL INDIC, V56, P79, DOI 10.1016/j.ecolind.2015.03.039
   Rottensteiner F., 2012, ISPRS ANN PHOTOGRAMM, V0, P293
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Su TF, 2017, GISCI REMOTE SENS, V54, P354, DOI 10.1080/15481603.2016.1273438
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Tong C, 2017, COMPUT ELECTR ENG, V60, P90, DOI 10.1016/j.compeleceng.2017.01.005
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Wang J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8110931
   Wang J, 2015, REMOTE SENS-BASEL, V7, P3467, DOI 10.3390/rs70403467
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xiao XM, 2006, REMOTE SENS ENVIRON, V100, P95, DOI 10.1016/j.rse.2005.10.004
   Xiao XM, 2005, REMOTE SENS ENVIRON, V95, P480, DOI 10.1016/j.rse.2004.12.009
   Xie YC, 2008, J PLANT ECOL, V1, P9, DOI 10.1093/jpe/rtm005
   Xu M, 2005, REMOTE SENS ENVIRON, V97, P322, DOI 10.1016/j.rse.2005.05.008
   Yang MD, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060583
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zhang CM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060619
   Zhang GL, 2015, ISPRS J PHOTOGRAMM, V106, P157, DOI 10.1016/j.isprsjprs.2015.05.011
   Zhang HX, 2017, GISCI REMOTE SENS, V54, P381, DOI 10.1080/15481603.2016.1276255
NR 60
TC 26
Z9 27
U1 4
U2 73
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD JAN 2
PY 2020
VL 57
IS 1
BP 37
EP 48
DI 10.1080/15481603.2019.1658960
EA SEP 2019
PG 12
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA KE9TM
UT WOS:000484769200001
DA 2023-04-26
ER

PT J
AU Ding, XG
   Zhao, ZY
   Yang, Q
   Chen, LN
   Tian, QY
   Li, XC
   Meng, FR
AF Ding, Xiaogang
   Zhao, Zhengyong
   Yang, Qi
   Chen, Lina
   Tian, Qiuyan
   Li, Xiaochuan
   Meng, Fan-Rui
TI Model prediction of depth-specific soil texture distributions with artificial neural network: A case study in Yunfu, a typical area of Udults Zone, South China
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
LA English
DT Article
DE Soil texture; Clay; Sand; Artificial neural network; Digital elevation model; Soil depth
ID spatial variability; random forest; part i; classification; information; fractions; carbon; water; drainage; france
AB The depth-specific soil texture map with high-resolution (i.e. <= 10 m) is essential for soil management and forest silviculture. The objective of this research was to develop a modelling method to generate high-resolution soil texture maps at five depths (D1: 0-20, D2: 20-40, D3: 40-60, D4: 60-80, and D5: 80-100 cm) in Yunfu, a typical area of Udults Zone, South China. Taking a coarse-resolution soil texture (CST) map with a 1: 2,800,000 scale and nine topo-hydrologic variables derived from a digital elevation model (DEM) with 10 m-resolution as input candidates, a series of artificial neural network (ANN) models for five depths were built and evaluated by a 10-fold cross-validation with 385 soil profiles from the Yunfu forest. The results indicated that the optimal model for five depths engaged five, five, five, four, and four DEM-generated variables as inputs, respectively, and model accuracies for estimating sand and clay contents varied with root mean squared error (RMSE) of 6.8-9.7%, R-2 of 0.56-0.72, and relative overall accuracy (ROA) +/- 5% of 54-81%, which were better than most of other researches. An extra independent validation with 64 soil profiles outside of the model-building area also indicated that the optimal models had adequate capabilities for generalization with RMSE of 9.2-12.2%, R-2 of 0.33-0.47, and ROA +/- 5% of 37-53%. The depth-specific sand and clay content maps with 10 m-resolution generated from the optimal models in Yunfu showed more detailed information than the CST map, and could reflected the influence of the DEM-derived topo-hydrologic variables. Based on the generated maps, horizontal characteristics of soil texture in the study area exhibited an obvious process of clay translocation from the topsoil (D1) to subsoil (D2-5), a maximum accumulation of clay in D4, and a dominant sandy soil in the topsoil (D1). Thus, the modelling method, i.e. developing ANNs with k-fold cross-validation, can be used to generate depth-specific soil texture maps in Udults Zone, South China. In addition, the generated high-resolution maps can clearly show the changes of soil texture in three-dimension.
C1 [Ding, Xiaogang; Chen, Lina; Li, Xiaochuan] Guangdong Acad Forestry, Guangzhou 510520, Guangdong, Peoples R China.
   [Zhao, Zhengyong; Yang, Qi; Tian, Qiuyan] Guangxi Univ, Coll Forestry, Guangxi Key Lab Forest Ecol & Conservat, Nanning 530004, Peoples R China.
   [Meng, Fan-Rui] Univ New Brunswick, Fac Forestry & Environm Management, Fredericton, NB E3B 5A3, Canada.
C3 Guangxi University; University of New Brunswick
RP Zhao, ZY (corresponding author), Guangxi Univ, Coll Forestry, Guangxi Key Lab Forest Ecol & Conservat, Nanning 530004, Peoples R China.
EM z.zhao@unb.ca
FU Guangdong Forestry Science and Technology Plan of China [2019-07]; National Natural Science Foundation of China [31500385]; Guangxi Natural Science Foundation of China [2016GXNSFCA380029, 2018GXNSFBA138035]
CR Adhikari K, 2013, SOIL SCI SOC AM J, V77, P860, DOI 10.2136/sssaj2012.0275
   Akhtar MK, 2009, HYDROL EARTH SYST SC, V13, P1607, DOI 10.5194/hess-13-1607-2009
   Akpa SIC, 2014, SOIL SCI SOC AM J, V78, P1953, DOI 10.2136/sssaj2014.05.0202
   Ambroise B, 1996, WATER RESOUR RES, V32, P2135, DOI 10.1029/95WR03716
   [Anonymous], 2006, P IUFRO PREC FOR S S, V0, P0
   [Anonymous], 2018, ACTA PEDOL SIN, V0, P0
   [Anonymous], 2005, SOILS PLANT GROWTH F, V0, P0
   [Anonymous], 2000, GEOGR RES, V0, P0
   [Anonymous], 2018, FOREST SOIL SURVEY Y, V0, P0
   [Anonymous], 1997, SPATIAL TEMPORAL VAR, V0, P0
   [Anonymous], 2000, NATURE PROPERTIES SO, V0, P0
   [Anonymous], 1990, NEURAL NETWORK PC TO, V0, P0
   Bashir MA, 2019, CATENA, V173, P141, DOI 10.1016/j.catena.2018.10.015
   Beven K., 1979, HYDROLOG SCI J, V24, P43, DOI 10.1080/02626667909491834
   Brungard CW, 2015, GEODERMA, V239, P68, DOI 10.1016/j.geoderma.2014.09.019
   Case BS, 2005, CAN J SOIL SCI, V85, P127, DOI 10.4141/S04-008
   Chagas CD, 2016, CATENA, V139, P232, DOI 10.1016/j.catena.2016.01.001
   Clemens G, 2010, CATENA, V81, P87, DOI 10.1016/j.catena.2010.01.006
   Deressa A, 2018, CATENA, V163, P184, DOI 10.1016/j.catena.2017.12.020
   Dexter AR, 2004, GEODERMA, V120, P201, DOI 10.1016/j.geoderma.2003.09.004
   Dobarco MR, 2017, GEODERMA, V298, P67, DOI 10.1016/j.geoderma.2017.03.015
   Duan L, 2002, GEODERMA, V110, P205, DOI 10.1016/S0016-7061(02)00231-8
   FERRO V, 1995, HYDROLOG SCI J, V40, P703, DOI 10.1080/02626669509491460
   Gawlik BM, 1999, SCI TOTAL ENVIRON, V229, P99, DOI 10.1016/S0048-9697(99)00076-5
   Gomes DS, 2018, FLORESTA AMBIENTE, V25, P0, DOI 10.1590/2179-8087.040017
   GREENLEE DD, 1987, PHOTOGRAMM ENG REM S, V53, P1383
   HASSINK J, 1992, BIOL FERT SOILS, V14, P126, DOI 10.1007/BF00336262
   Hengl T, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0125814
   Hengl T, 2014, PLOS ONE, V9, P0, DOI 10.1371/journal.pone.0105992
   HEUVELINK GBM, 1992, GEODERMA, V55, P1, DOI 10.1016/0016-7061(92)90002-O
   [黄国勤 Huang Guoqin], 2014, 生态学报 ACTA ECOLOGICA SINICA, V34, P5173
   Huang M, 2013, PROCEDIA ENVIRON SCI, V19, P148, DOI 10.1016/j.proenv.2013.06.017
   Huang MB, 2011, CAN J SOIL SCI, V91, P199, DOI 10.4141/CJSS10012
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   JENSON SK, 1988, PHOTOGRAMM ENG REM S, V54, P1593
   Jien SH, 2009, SOIL SCI, V174, P563, DOI 10.1097/SS.0b013e3181bccf35
   Katschinski NA, 1956, 6 C SCI SOL PAR B, V0, P321
   Lafon CW, 2000, OIKOS, V90, P431, DOI 10.1034/j.1600-0706.2000.900302.x
   Lamsal S, 2010, J ENVIRON MANAGE, V91, P1686, DOI 10.1016/j.jenvman.2010.03.015
   Li AD, 2017, ENVIRON MONIT ASSESS, V189, P0, DOI 10.1007/s10661-017-5997-0
   Li ZY, 1998, J INFRARED MILLIM W, V17, P153
   Liao KH, 2013, SOIL SCI PLANT NUTR, V59, P488, DOI 10.1080/00380768.2013.802643
   Liess M, 2012, GEODERMA, V170, P70, DOI 10.1016/j.geoderma.2011.10.010
   Liu Y, 2000, J INTERF CYTOK RES, V20, P21, DOI 10.1089/107999000312702
   Makabe S, 2009, SOIL SCI PLANT NUTR, V55, P300, DOI 10.1111/j.1747-0765.2008.00352.x
   MANRIQUE LA, 1991, SOIL SCI SOC AM J, V55, P787, DOI 10.2136/sssaj1991.03615995005500030026x
   MARTZ LW, 1992, COMPUT GEOSCI, V18, P747, DOI 10.1016/0098-3004(92)90007-E
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   McBratney AB, 2000, GEODERMA, V97, P293, DOI 10.1016/S0016-7061(00)00043-4
   Mulder VL, 2016, SCI TOTAL ENVIRON, V573, P1352, DOI 10.1016/j.scitotenv.2016.07.066
   Oberthur T, 1996, SOIL USE MANAGE, V12, P33, DOI 10.1111/j.1475-2743.1996.tb00527.x
   Pahlavan-Rad MR, 2018, CATENA, V160, P275, DOI 10.1016/j.catena.2017.10.002
   Peng DM, 2015, STOCH ENV RES RISK A, V29, P27, DOI 10.1007/s00477-014-0962-8
   Pongpattananurak N, 2012, SOIL SCI SOC AM J, V76, P199, DOI 10.2136/sssaj2011.0180
   RAWLS WJ, 1982, T ASAE, V25, P1316
   Renne RR, 2019, ECOLOGY, V100, P0, DOI 10.1002/ecy.2824
   Rossel RAV, 2015, SOIL RES, V53, P845, DOI 10.1071/SR14366
   Rousseva SS, 1997, EUR J SOIL SCI, V48, P749, DOI 10.1046/j.1365-2389.1997.00113.x
   Silver WL, 2000, ECOSYSTEMS, V3, P193, DOI 10.1007/s100210000019
   [孙佳佳 Sun Jiajia], 2015, 长江科学院院报 JOURNAL OF YANGTZE RIVER SCIENTIFIC RESEARCH INSTITUTE, V32, P54
   Tang ZH, 2019, ENVIRON MONIT ASSESS, V191, P0, DOI 10.1007/s10661-019-7523-z
   Thattai D, 2000, J HYDROL ENG, V5, P386, DOI 10.1061/(ASCE)1084-0699(2000)5:4(386)
   VANDERPAS JB, 1984, NEW ZEAL J FOR SCI, V14, P3
   VOLTZ M, 1990, J SOIL SCI, V41, P473, DOI 10.1111/j.1365-2389.1990.tb00080.x
   Voltz M, 1997, EUR J SOIL SCI, V48, P19, DOI 10.1111/j.1365-2389.1997.tb00181.x
   [王冬冬 Wang Dongdong], 2016, 土壤 SOILS, V48, P361
   Zhang L., 2010, EURASIP J ADV SIG PR, V2010, P1, DOI 10.1109/EC0C.2010.5622099
   Zhang ShiWen, 2011, SCIENTIA AGRICULTURA SINICA, V44, P1154
   [赵其国 ZHAO Qiguo], 2006, 水土保持通报 BULLETIN OF SOIL AND WATER CONSERVATION, V26, P1
   Zhao ZY, 2010, CAN J SOIL SCI, V90, P75, DOI 10.4141/CJSS08057
   Zhao ZY, 2006, INT GEOSCI REMOTE SE, V0, PP2655, DOI 10.1109/IGARSS.2006.685
   Zhao ZY, 2009, COMPUT ELECTRON AGR, V65, P36, DOI 10.1016/j.compag.2008.07.008
NR 85
TC 12
Z9 12
U1 3
U2 26
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0168-1699
EI 1872-7107
J9 COMPUT ELECTRON AGR
JI Comput. Electron. Agric.
PD FEB 15
PY 2020
VL 169
IS 
BP 
EP 
DI 10.1016/j.compag.2020.105217
PG 13
WC Agriculture, Multidisciplinary; Computer Science, Interdisciplinary Applications
SC Agriculture; Computer Science
GA KR5NR
UT WOS:000517665600046
DA 2023-04-26
ER

PT J
AU Zhang, Y
   Aslam, NS
   Lai, JT
   Cheng, T
AF Zhang, Yang
   Aslam, Nilufer Sari
   Lai, Juntao
   Cheng, Tao
TI You are how you travel: A multi-task learning framework for Geodemographic inference using transit smart card data
SO COMPUTERS ENVIRONMENT AND URBAN SYSTEMS
LA English
DT Article
DE Geodemographic inference; Smart card data; Multi-task CNN; Spatio-temporal activity pattern; Residential area detection
ID model
AB Geodemographics, providing the information of population's characteristics in the regions on a geographical basis, is of immense importance in urban studies, public policy-making, social research and business, among others. Such data, however, are difficult to collect from the public, which is usually done via census, with a low update frequency. In urban areas, with the increasing prevalence of public transit equipped with automated fare payment systems, researchers can collect massive transit smart card (SC) data from a large population. The SC data record human daily activities at an individual level with high spatial and temporal resolutions. It can reveal frequent activity areas (e.g., residential areas) and travel behaviours of passengers that are intimately intertwined with personal interests and characteristics. This provides new opportunities for geodemographic study. This paper seeks to develop a framework to infer travellers' demographics (such as age, income level and car ownership, et al.) and their residential areas for geodemographic mapping using SC data with a household survey. We first use a decision tree diagram to detect passengers' residential areas. We then represent each individual's spatio-temporal activity pattern derived from multi-week SC data as a 2D image. Leveraging this representation, a multi-task convolutional neural network (CNN) is employed to predict multiple demographics of individuals from the images. Combing the demographics and locations of their residence, geodemographic information is further obtained. The methodology is applied to a large-scale SC dataset provided by Transport for London. Results provide new insights in understanding the relationship between human activity patterns and demographics. To the best of our knowledge, this is the first attempt to infer geodemographics by using the SC data.
C1 [Zhang, Yang; Aslam, Nilufer Sari; Cheng, Tao] UCL, Dept Civil Environm & Geomat Engn, SpaceTimeLab Big Data Analyt, Gower St, London WC1E 6BT, England.
   [Lai, Juntao] ASTAR, Inst Infocomm Res, 1 Fusionopolis Way,10-25 Connexis North Tower, Singapore 138632, Singapore.
C3 University of London; University College London; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Zhang, Y (corresponding author), UCL, Dept Civil Environm & Geomat Engn, SpaceTimeLab Big Data Analyt, Gower St, London WC1E 6BT, England.
EM yang.zhang.16@ucl.ac.uk; n.aslam.11@ucl.ac.uk; Lai_Juntao@i2r.a-star.edu.sg; tao.cheng@ucl.ac.uk
FU UK Economic and Social Research Council [ES/L011840/1]; China Scholarship Council [201603170309]; University College London; EPSRC [EP/J004197/1, EP/G023212/1, EP/M023583/1] Funding Source: UKRI; ESRC [ES/L011840/1] Funding Source: UKRI
CR Abadi M., 2016, 12 S OP SYST DES IMP, V0, P265
   Aslam NS, 2019, GEO-SPAT INF SCI, V22, P1, DOI 10.1080/10095020.2018.1545884
   Bagchi M, 2005, TRANSP POLICY, V12, P464, DOI 10.1016/j.tranpol.2005.06.008
   Bantis T, 2017, TRANSPORT RES C-EMER, V80, P286, DOI 10.1016/j.trc.2017.05.003
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Carmel D, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW17), V0, PP1541, DOI 10.1145/3038912.3052658
   Chen T, 2015, XGBOOST EXTREME GRAD, V0, P1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CZ Mooney, 1993, BOOTSTRAPPING NONPAR, V0, P0
   Ding S., 2019, 2019 28 INT C COMPUT, V0, P1
   Dong YX, 2017, ACM T INFORM SYST, V35, P0, DOI 10.1145/3057278
   El Mahrsi MK, 2017, IEEE T INTELL TRANSP, V18, P712, DOI 10.1109/TITS.2016.2600515
   Evans J., 1996, STRAIGHTFORWARD STAT, V0, P0
   Gao J, 2019, PHYS REP, V817, P1, DOI 10.1016/j.physrep.2019.05.002
   Ghosh S, 2017, WWW17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP51, DOI 10.1145/3041021.3054150
   Gordon JB, 2013, TRANSPORT RES REC, V0, PP17, DOI 10.3141/2343-03
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Hu J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, P0
   Ilagcrstrand T., 1970, PAPERS REGIONAL SCI, V0, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Langlois GG, 2016, TRANSPORT RES C-EMER, V64, P1, DOI 10.1016/j.trc.2015.12.012
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li GX, 2015, IEEE INT C INTELL TR, V0, PP2788, DOI 10.1109/ITSC.2015.445
   Liu YJ, 2019, THEOR APPL CLIMATOL, V135, P1375, DOI 10.1007/s00704-018-2435-3
   Liu YZ, 2020, TRANSPORTMETRICA A, V16, P76, DOI 10.1080/23249935.2018.1493549
   Long Y, 2015, COMPUT ENVIRON URBAN, V53, P19, DOI 10.1016/j.compenvurbsys.2015.02.005
   Ma XL, 2013, TRANSPORT RES C-EMER, V36, P1, DOI 10.1016/j.trc.2013.07.010
   Martin D, 2018, COMPUT ENVIRON URBAN, V67, P68, DOI 10.1016/j.compenvurbsys.2017.09.002
   Perozzi B, 2015, WWW15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, V0, PP91, DOI 10.1145/2740908.2742765
   Riederer C., 2015, P 2015 ACM C ONLINE, V0, PP185, DOI 10.1145/2817946.2817968
   Ruder S, 2017, ARXIV170605098, V0, P0
   Sari Aslam N., 2019, 27 C GEOGR INF SCI R, V0, P97
   Shen JN, 2016, INT J GEOGR INF SCI, V30, P1785, DOI 10.1080/13658816.2016.1139119
   Singleton AD, 2014, PROF GEOGR, V66, P558, DOI 10.1080/00330124.2013.848764
   Siren A, 2004, TRANSPORT RES F-TRAF, V7, P107, DOI 10.1016/j.trf.2004.02.003
   TfL, 2013, 7 TFL, V0, P0
   van den Berg P, 2013, TRANSPORT RES C-EMER, V26, P256, DOI 10.1016/j.trc.2012.10.002
   Vijayaraghavan P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P478, DOI 10.18653/v1/P17-2076
   Volkova S, 2016, PROCEEDINGS 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2016), V0, PP36, DOI 10.1109/BigDataService.2016.28
   Wang P., 2016, ADV INFORM RETRIEVAL, V0, P0
   Wang YH, 2017, J TRANSP GEOGR, V63, P40, DOI 10.1016/j.jtrangeo.2017.06.010
   Wu L, 2019, COMPUT ENVIRON URBAN, V77, P0, DOI 10.1016/j.compenvurbsys.2019.101368
   Zhang J, 2019, ACTA MECH SOLIDA SIN, V32, P463, DOI 10.1007/s10338-019-00114-6
   Zhang Y., 2019, ISPRS INT ARCH PHOTO, V0, P1375
   Zhang Y, 2020, INT J GEOGR INF SCI, V34, P969, DOI 10.1080/13658816.2019.1697879
   Zhang Y, 2021, ENVIRON PLAN B-URBAN, V48, P151, DOI 10.1177/2399808319851517
   Zhang Y, 2019, COMPUT-AIDED CIV INF, V34, P877, DOI 10.1111/mice.12450
   Zhang Y, 2018, 2ND INTERNATIONAL CONFERENCE ON ADVANCED RESEARCH METHODS AND ANALYTICS (CARMA 2018), V0, PP55, DOI 10.4995/CARMA2018.2018.8310
   Zhang Y, 2020, IEEE T INTELL TRANSP, V21, P617, DOI 10.1109/TITS.2019.2896460
   Zhao S, 2017, IEEE SYST J, V11, P315, DOI 10.1109/JSYST.2015.2431323
   Zhong EH, 2013, PERVASIVE MOB COMPUT, V9, P823, DOI 10.1016/j.pmcj.2013.07.009
   Zhong Y, 2015, WSDM15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, V0, PP295, DOI 10.1145/2684822.2685287
   Zhu L, 2017, NANOMED NANOTOXICOL, V0, PP173, DOI 10.1007/978-981-10-5864-6_8
NR 53
TC 11
Z9 11
U1 4
U2 22
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0198-9715
EI 1873-7587
J9 COMPUT ENVIRON URBAN
JI Comput. Environ. Urban Syst.
PD SEP 15
PY 2020
VL 83
IS 
BP 
EP 
DI 10.1016/j.compenvurbsys.2020.101517
PG 15
WC Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research & Management Science; Regional & Urban Planning
SC Computer Science; Engineering; Environmental Sciences & Ecology; Geography; Operations Research & Management Science; Public Administration
GA MY5IY
UT WOS:000558452100007
DA 2023-04-26
ER

PT J
AU Kuo, BI
   Chang, WY
   Liao, TS
   Liu, FY
   Liu, HY
   Chu, HS
   Chen, WL
   Hu, FR
   Yen, JY
   Wang, IJ
AF Kuo, Bo-, I
   Chang, Wen-Yi
   Liao, Tai-Shan
   Liu, Fang-Yu
   Liu, Hsin-Yu
   Chu, Hsiao-Sang
   Chen, Wei-Li
   Hu, Fung-Rong
   Yen, Jia-Yush
   Wang, I-Jong
TI Keratoconus Screening Based on Deep Learning Approach of Corneal Topography
SO TRANSLATIONAL VISION SCIENCE & TECHNOLOGY
LA English
DT Article
DE keratoconus; deep learning; convolutional neuronal network; corneal topography
ID subclinical keratoconus; videokeratography; ectasia; classification; biomechanics; tomography; lasik; index
AB Purpose: To develop and compare deep learning (DL) algorithms to detect keratoconus on the basis of corneal topography and validate with visualization methods. Methods: We retrospectively collected corneal topographies of the study group with clinically manifested keratoconus and the control group with regular astigmatism. All images were divided into training and test datasets. We adopted three convolutional neural network (CNN) models for learning. The test dataset was applied to analyze the performance of the three models. In addition, for better discrimination and understanding, we displayed the pixel-wise discriminative features and class-discriminative heat map of diopter images for visualization. Results: Overall, 170 keratoconus, 28 subclinical keratoconus and 156 normal topographic pictures were collected. The convergence of accuracy and loss for the training and test datasets after training revealed no overfitting in all three CNN models. The sensitivity and specificity of all CNN models were over 0.90, and the area under the receiver operating characteristic curve reached 0.995 in the ResNet152 model. The pixel-wise discriminative features and the heat map of the prediction layer in the VGG16 model both revealed it focused on the largest gradient difference of topographic maps, which was corresponding to the diagnostic clues of ophthalmologists. The subclinical keratoconus was positively predicted with our model and also correlated with topographic indexes. Conclusions: The DL models had fair accuracy for keratoconus screening based on corneal topographic images. The visualization mentioned in the current study revealed that the model focused on the appropriate region for diagnosis and rendered clinical explainability of deep learning more acceptable. Translational Relevance: These high accuracy CNN models can aid ophthalmologists in keratoconus screening with color-coded corneal topography maps.
C1 [Kuo, Bo-, I; Liu, Fang-Yu; Liu, Hsin-Yu; Chu, Hsiao-Sang; Chen, Wei-Li; Hu, Fung-Rong; Wang, I-Jong] Natl Taiwan Univ Hosp, Dept Ophthalmol, 7 Chung Shan South Rd, Taipei, Taiwan.
   [Kuo, Bo-, I] Taipei City Hosp, Dept Ophthalmol, Renai Branch, Taipei, Taiwan.
   [Chang, Wen-Yi] Natl Ctr High Performance Comp, Natl Appl Res Labs, Hsinchu, Taiwan.
   [Liao, Tai-Shan] Taiwan Instrument Res Inst, Natl Appl Res Labs, Hsinchu, Taiwan.
   [Liu, Fang-Yu] Triserv Gen Hosp, Natl Def Med Ctr, Dept Ophthalmol, Taipei, Taiwan.
   [Chen, Wei-Li; Wang, I-Jong] Natl Taiwan Univ, Coll Med, Grad Inst Clin Med, Taipei, Taiwan.
   [Yen, Jia-Yush] Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
C3 National Taiwan University; National Taiwan University Hospital; Taipei City Hospital; National Applied Research Laboratories - Taiwan; National Applied Research Laboratories - Taiwan; National Defense Medical Center; Tri-Service General Hospital; National Taiwan University; National Taiwan University
RP Wang, IJ (corresponding author), Natl Taiwan Univ Hosp, Dept Ophthalmol, 7 Chung Shan South Rd, Taipei, Taiwan.
EM ijong@ms8.hinet.net
FU National Taiwan University [107L891002, 108L891002]
CR Accardo PA, 2002, J BIOMED INFORM, V35, P151, DOI 10.1016/S1532-0464(02)00513-0
   Ambrosio R, 2017, J REFRACT SURG, V33, P434, DOI 10.3928/1081597X-20170426-02
   Ambrosio R, 2010, J REFRACT SURG, V26, P906, DOI 10.3928/1081597X-20100428-02
   [Anonymous], 2015, ICLR, V0, P0
   Chatzis N, 2012, J REFRACT SURG, V28, P753, DOI 10.3928/1081597X-20121011-01
   Cheung CY, 2019, ASIA-PAC J OPHTHALMO, V8, P158, DOI 10.22608/APO.201976
   Christian S., 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   Dastjerdi MH, 1998, J REFRACT SURG, V14, P427
   de Sanctis U, 2008, OPHTHALMOLOGY, V115, P1534, DOI 10.1016/j.ophtha.2008.02.020
   Ferdi AC, 2019, OPHTHALMOLOGY, V126, P935, DOI 10.1016/j.ophtha.2019.02.029
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Henriquez MA, 2020, J REFRACT SURG, V36, P270, DOI 10.3928/1081597X-20200212-03
   Hinton G.E., 2012, ARXIV PREPRINT ARXIV, V0, P0
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Holladay JT, 2009, J REFRACT SURG, V25, PS958, DOI 10.3928/1081597X-20090915-11
   HUSTEAD JD, 1993, OPHTHALMOLOGY, V100, P975
   Hwang ES, 2018, OPHTHALMOLOGY, V125, P1862, DOI 10.1016/j.ophtha.2018.06.020
   JACOBS DS, 1993, INT OPHTHALMOL CLIN, V33, P249, DOI 10.1097/00004397-199303320-00023
   KRACHMER JH, 1984, SURV OPHTHALMOL, V28, P293, DOI 10.1016/0039-6257(84)90094-8
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XH, 2004, OPHTHALMOLOGY, V111, P440, DOI 10.1016/j.ophtha.2003.06.020
   Li XH, 2009, J CATARACT REFR SURG, V35, P1597, DOI 10.1016/j.jcrs.2009.03.050
   Lopes BT, 2018, AM J OPHTHALMOL, V195, P223, DOI 10.1016/j.ajo.2018.08.005
   Luz A, 2016, J REFRACT SURG, V32, P479, DOI 10.3928/1081597X-20160502-02
   MAEDA N, 1995, INVEST OPHTH VIS SCI, V36, P1327
   MAEDA N, 1995, ARCH OPHTHALMOL-CHIC, V113, P870, DOI 10.1001/archopht.1995.01100070044023
   MAEDA N, 1994, INVEST OPHTH VIS SCI, V35, P2749
   Moshirfar M, 2019, OPHTHALMOL THER, V8, P367, DOI 10.1007/s40123-019-0199-1
   Rabinowitz Y S, 1989, REFRACT CORNEAL SURG, V5, P400
   Rabinowitz YS, 1999, J CATARACT REFR SURG, V25, P1327, DOI 10.1016/S0886-3350(99)00195-9
   Rabinowitz YS, 1996, BRIT J OPHTHALMOL, V80, P610, DOI 10.1136/bjo.80.7.610
   Ramos IC, 2013, J REFRACT SURG, V29, P770, DOI 10.3928/1081597X-20130823-01
   Randleman JB, 2015, CORNEA, V34, Pe20, DOI 10.1097/ICO.0000000000000500
   Reid JE, 2019, CURR OPIN OPHTHALMOL, V30, P337, DOI 10.1097/ICU.0000000000000593
   Roberts CJ, 2014, J CATARACT REFR SURG, V40, P991, DOI 10.1016/j.jcrs.2014.04.013
   Rozema JJ, 2016, CORNEA, V35, P860, DOI 10.1097/ICO.0000000000000802
   Saad A, 2016, J REFRACT SURG, V32, P510, DOI 10.3928/1081597X-20160523-01
   Schmidt-Erfurth U, 2018, INVEST OPHTH VIS SCI, V59, P3199, DOI 10.1167/iovs.18-24106
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Sherwin T, 2004, CLIN EXP OPHTHALMOL, V32, P211, DOI 10.1111/j.1442-9071.2004.00805.x
   Smadja D, 2013, AM J OPHTHALMOL, V156, P237, DOI 10.1016/j.ajo.2013.03.034
   Smolek MK, 1997, INVEST OPHTH VIS SCI, V38, P2290
   Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P167, DOI 10.1136/bjophthalmol-2018-313173
   Tompson J., 2014, ADV NEURAL INFORM PR, V0, P1799
   Tur VM, 2017, SURV OPHTHALMOL, V62, P770, DOI 10.1016/j.survophthal.2017.06.009
   Ucakhan OO, 2011, J CATARACT REFR SURG, V37, P1116, DOI 10.1016/j.jcrs.2010.12.049
   Vinciguerra R, 2016, J REFRACT SURG, V32, P803, DOI 10.3928/1081597X-20160629-01
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zheng CJ, 2019, CURR OPIN OPHTHALMOL, V30, P97, DOI 10.1097/ICU.0000000000000552
NR 50
TC 24
Z9 24
U1 2
U2 9
PU ASSOC RESEARCH VISION OPHTHALMOLOGY INC
PI ROCKVILLE
PA 12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA
SN 2164-2591
EI 
J9 TRANSL VIS SCI TECHN
JI Transl. Vis. Sci. Technol.
PD JAN 15
PY 2020
VL 9
IS 2
BP 
EP 
DI 10.1167/tvst.9.2.53
PG 11
WC Ophthalmology
SC Ophthalmology
GA PG1FX
UT WOS:000599489500039
PM 33062398
DA 2023-04-26
ER
