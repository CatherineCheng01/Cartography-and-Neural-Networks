
PT J
AU Hsu, SY
   Jura, B
   Shih, MH
   Meyrand, P
   Tsai, FS
   Bem, T
AF Hsu, Sheng-Yi
   Jura, Bartosz
   Shih, Mau-Hsiang
   Meyrand, Pierre
   Tsai, Feng-Sheng
   Bem, Tiaza
TI Recognition of post-learning alteration of hippocampal ripples by convolutional neural network differs in the wild-type and AD mice
SO SCIENTIFIC REPORTS
LA English
DT Article
ID sharp-wave-ripple; reactivation; disruption; memory; replay; age
AB Evidence indicates that sharp-wave ripples (SWRs) are primary network events supporting memory processes. However, some studies demonstrate that even after disruption of awake SWRs the animal can still learn spatial task or that SWRs may be not necessary to establish a cognitive map of the environment. Moreover, we have found recently that despite a deficit of sleep SWRs the APP/PS1 mice, a model of Alzheimer's disease, show undisturbed spatial reference memory. Searching for a learning-related alteration of SWRs that could account for the efficiency of memory in these mice we use convolutional neural networks (CNN) to discriminate pre- and post-learning 256 ms samples of LFP signals, containing individual SWRs. We found that the fraction of samples that were correctly recognized by CNN in majority of discrimination sessions was equal to -50% in the wild-type (WT) and only 14% in APP/PS1 mice. Moreover, removing signals generated in a close vicinity of SWRs significantly diminished the number of such highly recognizable samples in the WT but not in APP/PS1 group. These results indicate that in WT animals a large subset of SWRs and signals generated in their proximity may contain learning-related information whereas such information seem to be limited in the AD mice.
C1 [Hsu, Sheng-Yi; Tsai, Feng-Sheng] China Med Univ, Dept Biomed Imaging & Radiol Sci, Taichung 40402, Taiwan.
   [Hsu, Sheng-Yi; Shih, Mau-Hsiang; Tsai, Feng-Sheng] China Med Univ Hosp, Res Ctr Interneural Comp, Taichung 40447, Taiwan.
   [Jura, Bartosz; Bem, Tiaza] Polish Acad Sci, Nalecz Inst Biocybernet & Biomed Engn, Ks Trojdena 4, PL-02109 Warsaw, Poland.
   [Meyrand, Pierre] Univ Bordeaux, INSERM, U1215, Neuroctr Magendie, Bordeaux, France.
   [Jura, Bartosz] Jagiellonian Univ, Inst Appl Psychol, Krakow, Poland.
C3 China Medical University Taiwan; China Medical University Taiwan; China Medical University Hospital - Taiwan; Polish Academy of Sciences; Nalecz Institute of Biocybernetics & Biomedical Engineering of the Polish Academy of Sciences; Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; Universite de Bordeaux; Jagiellonian University
RP Bem, T (corresponding author), Polish Acad Sci, Nalecz Inst Biocybernet & Biomed Engn, Ks Trojdena 4, PL-02109 Warsaw, Poland.
EM tiaza.bem@ibib.waw.pl
FU Ministry of Science and Technology, Taiwan; China Medical University [CMU105-N-19]; Ministry of Education and Science, Poland
CR Altimus Cara, 2015, MOL NEUROPSYCHIATRY, V1, P52
   Bragin A, 2002, J NEUROSCI, V22, P2012, DOI 10.1523/JNEUROSCI.22-05-02012.2002
   Buzsaki G, 2015, HIPPOCAMPUS, V25, P1073, DOI 10.1002/hipo.22488
   Cho K, 2014, P 2014 C EMP METH NA, V0, PP1724, DOI 10.3115/V1/D14-1179
   Colgin LL, 2016, NAT REV NEUROSCI, V17, P239, DOI 10.1038/nrn.2016.21
   Ego-Stengel V, 2010, HIPPOCAMPUS, V20, P1, DOI 10.1002/hipo.20707
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Eschenko O, 2008, LEARN MEMORY, V15, P222, DOI 10.1101/lm.726008
   Gerrard JL, 2008, J NEUROSCI, V28, P7883, DOI 10.1523/JNEUROSCI.1265-08.2008
   Gillespie AK, 2016, NEURON, V90, P740, DOI 10.1016/j.neuron.2016.04.009
   Girardeau G, 2009, NAT NEUROSCI, V12, P1222, DOI 10.1038/nn.2384
   Goodfellow I., 2018, DEEP LEARNING, V1373, P68009
   Gupta AS, 2010, NEURON, V65, P695, DOI 10.1016/j.neuron.2010.01.034
   Jadhav SP, 2012, SCIENCE, V336, P1454, DOI 10.1126/science.1217230
   Joo HR, 2018, NAT REV NEUROSCI, V19, P744, DOI 10.1038/s41583-018-0077-1
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Jura B, 2019, SCI REP-UK, V9, P0, DOI 10.1038/s41598-019-56582-w
   Karlsson MP, 2009, NAT NEUROSCI, V12, P913, DOI 10.1038/nn.2344
   Kay K, 2019, HIPPOCAMPUS, V29, P184, DOI 10.1002/hipo.22956
   Kovacs KA, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0164675
   Lagadec S, 2012, NEUROBIOL AGING, V33, P0, DOI 10.1016/j.neurobiolaging.2010.07.023
   Laredo D., 2020, INT J DYN CONTROL, V8, P1063, DOI 10.1007/S40435-020-00708-W
   Nicole O, 2016, SCI REP-UK, V6, P0, DOI 10.1038/srep22728
   Nokia MS, 2012, FRONT BEHAV NEUROSCI, V6, P0, DOI 10.3389/fnbeh.2012.00084
   Pfeiffer BE, 2013, NATURE, V497, P74, DOI 10.1038/nature12112
   Poo MM, 2016, BMC BIOL, V14, P0, DOI 10.1186/s12915-016-0261-6
   Rothschild G, 2019, NEUROBIOL LEARN MEM, V160, P58, DOI 10.1016/j.nlm.2018.03.019
   Rothschild G, 2017, NAT NEUROSCI, V20, P251, DOI 10.1038/nn.4457
   Skelin I, 2019, NEUROBIOL LEARN MEM, V160, P21, DOI 10.1016/j.nlm.2018.04.004
   Valero M, 2017, NEURON, V94, P1234, DOI 10.1016/j.neuron.2017.05.032
   Wiegand JPL, 2016, J NEUROSCI, V36, P5650, DOI 10.1523/JNEUROSCI.3069-15.2016
   Witton J, 2016, J PHYSIOL-LONDON, V594, P4615, DOI 10.1113/jphysiol.2014.282889
   Zhang YC, 2017, PR MACH LEARN RES, V54, P83
NR 33
TC 0
Z9 0
U1 1
U2 3
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
EI 
J9 SCI REP-UK
JI Sci Rep
PD OCT 28
PY 2021
VL 11
IS 1
BP 
EP 
DI 10.1038/s41598-021-00598-8
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA WO6LX
UT WOS:000712564800021
PM 34711860
DA 2023-04-26
ER

PT J
AU Aeberli, A
   Johansen, K
   Robson, A
   Lamb, DW
   Phinn, S
AF Aeberli, Aaron
   Johansen, Kasper
   Robson, Andrew
   Lamb, David W.
   Phinn, Stuart
TI Detection of Banana Plants Using Multi-Temporal Multispectral UAV Imagery
SO REMOTE SENSING
LA English
DT Article
DE unoccupied aerial vehicle; UAV; banana plant; geographic object-based image analysis; convolutional neural network; CNN; template matching; local maximum filter
ID tree crown detection; unmanned aircraft systems; vegetation index; canopy structure; delineation; classification; segmentation; reflectance; plantations; phenology
AB Unoccupied aerial vehicles (UAVs) have become increasingly commonplace in aiding planning and management decisions in agricultural and horticultural crop production. The ability of UAV-based sensing technologies to provide high spatial (<1 m) and temporal (on-demand) resolution data facilitates monitoring of individual plants over time and can provide essential information about health, yield, and growth in a timely and quantifiable manner. Such applications would be beneficial for cropped banana plants due to their distinctive growth characteristics. Limited studies have employed UAV data for mapping banana crops and to our knowledge only one other investigation features multi-temporal detection of banana crowns. The purpose of this study was to determine the suitability of multiple-date UAV-captured multi-spectral data for the automated detection of individual plants using convolutional neural network (CNN), template matching (TM), and local maximum filter (LMF) methods in a geographic object-based image analysis (GEOBIA) software framework coupled with basic classification refinement. The results indicate that CNN returns the highest plant detection accuracies, with the developed rule set and model providing greater transferability between dates (F-score ranging between 0.93 and 0.85) than TM (0.86-0.74) and LMF (0.86-0.73) approaches. The findings provide a foundation for UAV-based individual banana plant counting and crop monitoring, which may be used for precision agricultural applications to monitor health, estimate yield, and to inform on fertilizer, pesticide, and other input requirements for optimized farm management.
C1 [Aeberli, Aaron; Robson, Andrew] Univ New England, Sch Sci & Technol, Appl Agr Remote Sensing Ctr, Armidale, NSW 2351, Australia.
   [Aeberli, Aaron; Phinn, Stuart] Univ Queensland, Sch Earth & Environm Sci, Remote Sensing Res Ctr, St Lucia, Qld 4072, Australia.
   [Johansen, Kasper] King Abdullah Univ Sci & Technol, Water Desalinat & Reuse Ctr, Hydrol Agr & Land Observat, Thuwal 239556900, Saudi Arabia.
   [Lamb, David W.] Food Agil Cooperat Res Ctr Ltd, 81 Broadway, Ultimo, NSW 2007, Australia.
   [Lamb, David W.] Univ New England, Precis Agr Res Grp, Armidale, NSW 2351, Australia.
C3 University of New England; University of Queensland; King Abdullah University of Science & Technology; University of New England
RP Aeberli, A (corresponding author), Univ New England, Sch Sci & Technol, Appl Agr Remote Sensing Ctr, Armidale, NSW 2351, Australia.; Aeberli, A (corresponding author), Univ Queensland, Sch Earth & Environm Sci, Remote Sensing Res Ctr, St Lucia, Qld 4072, Australia.
EM aaeberli@myune.edu.au; kasper.johansen@kaust.edu.sa; andrew.robson@une.edu.au; dave.lamb@foodagility.com; s.phinn@uq.edu.au
FU Horticulture Innovation; Department of Agriculture and Water Resources, Australian Government,Rural R&D for Profit Program's subproject "Multi-Scale Monitoring Tools for Managing Australia Tree Crops-Industry Meets Innovation
CR BARKER WG, 1962, ANN BOT-LONDON, V26, P413, DOI 10.1093/oxfordjournals.aob.a083803
   Basso B, 2016, PRECIS AGRIC, V17, P168, DOI 10.1007/s11119-015-9414-9
   Blozan W., 2006, B E NATIV TREE SOC, V1, P3
   Bolton DK, 2013, AGR FOREST METEOROL, V173, P74, DOI 10.1016/j.agrformet.2013.01.007
   Bouwman AF, 2017, SCI REP-UK, V7, P0, DOI 10.1038/srep40366
   Bunting P, 2006, REMOTE SENS ENVIRON, V101, P230, DOI 10.1016/j.rse.2005.12.015
   Bureau of Meteorology, 2019, CLIM STAT AUSTR LOC, V0, P0
   Chlingaryan A, 2018, COMPUT ELECTRON AGR, V151, P61, DOI 10.1016/j.compag.2018.05.012
   Clark A, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10062017
   Csillik O, 2018, DRONES-BASEL, V2, P0, DOI 10.3390/drones2040039
   Erikson M, 2005, MACH VISION APPL, V16, P258, DOI 10.1007/s00138-005-0180-y
   Gitelson AA, 1996, J PLANT PHYSIOL, V148, P501, DOI 10.1016/S0176-1617(96)80285-9
   Good AG, 2011, PLOS BIOL, V9, P0, DOI 10.1371/journal.pbio.1001124
   Handique B.K., 2020, INT ARCH PHOTOGRAMME, VXLIII-B3-2020, P67, DOI 10.5194/isprs-archives-XLIII-B3-2020-67-2020
   Harto A. B., 2019, HAYATI JOURNAL OF BIOSCIENCES, V26, P7
   Jiang ZY, 2008, REMOTE SENS ENVIRON, V112, P3833, DOI 10.1016/j.rse.2008.06.006
   Johansen K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10060854
   Johansen K, 2014, REMOTE SENS-BASEL, V6, P8261, DOI 10.3390/rs6098261
   Johansen K, 2009, PHOTOGRAMM ENG REM S, V75, P1069, DOI 10.14358/PERS.75.9.1069
   Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436
   Ke YH, 2011, INT J REMOTE SENS, V32, P4725, DOI 10.1080/01431161.2010.494184
   Kestur R, 2018, J INDIAN SOC REMOTE, V46, P991, DOI 10.1007/s12524-018-0756-4
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   KNIPLING E B, 1970, REMOTE SENSING OF ENVIRONMENT, V1, P155
   Lamar WR, 2005, REMOTE SENS ENVIRON, V94, P133, DOI 10.1016/j.rse.2004.09.003
   Lamour J, 2021, PRECIS AGRIC, V22, P873, DOI 10.1007/s11119-020-09762-y
   Lamour J., 2019, PRECISION AGR 19, V0, P407
   Larsen M, 1998, PATTERN RECOGN LETT, V19, P1153, DOI 10.1016/S0167-8655(98)00092-0
   Larsen M, 2011, INT J REMOTE SENS, V32, P5827, DOI 10.1080/01431161.2010.507790
   Li WJ, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11010011
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Maes WH, 2019, TRENDS PLANT SCI, V24, P152, DOI 10.1016/j.tplants.2018.11.007
   Mahlein AK, 2016, PLANT DIS, V100, P241, DOI 10.1094/PDIS-03-15-0340-FE
   McCarthy, 2004, AGRILINK SERIES, VQI04011, P0
   Memon N., 2005, INTERNATIONAL JOURNAL OF AGRICULTURE AND BIOLOGY, V7, P824
   Neupane B, 2019, PLOS ONE, V14, P0, DOI 10.1371/journal.pone.0223906
   Norzaki N, 2019, INT J REMOTE SENS, V40, P7477, DOI 10.1080/01431161.2018.1524182
   Picq C., 1999, BANANAS FOOD SECURIT, V0, P0
   PINZ AJ, 1991, NASA CONF P, V3099, P111
   Pollock R. J., 1994, PROCEEDINGS OF THE SPIE - THE INTERNATIONAL SOCIETY FOR OPTICAL ENGINEERING, V2315, P526, DOI 10.1117/12.196753
   Pouliot DA, 2002, REMOTE SENS ENVIRON, V82, P322, DOI 10.1016/S0034-4257(02)00050-0
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scott GJ, 2021, INT J FOOD SCI TECH, V56, P1093, DOI 10.1111/ijfs.14778
   Selvaraj MG, 2020, ISPRS J PHOTOGRAMM, V169, P110, DOI 10.1016/j.isprsjprs.2020.08.025
   Sims DA, 2002, REMOTE SENS ENVIRON, V81, P337, DOI 10.1016/S0034-4257(02)00010-X
   Soares J. D. R., 2012, AFRICAN JOURNAL OF BIOTECHNOLOGY, V11, P10682
   Susic N, 2018, SENSOR ACTUAT B-CHEM, V273, P842, DOI 10.1016/j.snb.2018.06.121
   Swarupa V, 2014, PLANTA, V239, P735, DOI 10.1007/s00425-013-2024-8
   Tang YC, 2020, FRONT PLANT SCI, V11, P0, DOI 10.3389/fpls.2020.00510
   TAYLOR SE, 1972, ECOLOGY, V53, P143, DOI 10.2307/1935720
   Thomas DS, 2001, SCI HORTIC-AMSTERDAM, V90, P93, DOI 10.1016/S0304-4238(00)00260-0
   Torres-Sanchez J, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0130479
   Trimble, 2020, ECOGNITION DEV, V0, P0
   Tu YH, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030269
   Tu YH, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10111684
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Turner David W., 2007, BRAZ. J. PLANT PHYSIOL., V19, P463, DOI 10.1590/S1677-04202007000400013
   TURNER DW, 1983, AUST J PLANT PHYSIOL, V10, P43, DOI 10.1071/PP9830043
   TWYFORD IT, 1967, J SCI FOOD AGR, V18, P177, DOI 10.1002/jsfa.2740180501
   Vina A, 2004, AGRON J, V96, P1139, DOI 10.2134/agronj2004.1139
   Wang CY, 2015, IEEE J-STARS, V8, P1876, DOI 10.1109/JSTARS.2015.2422716
   Wang J, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17030538
   Watts AC, 2012, REMOTE SENS-BASEL, V4, P1671, DOI 10.3390/rs4061671
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, P0, DOI 10.1016/j.rse.2019.111402
   Wu D, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12101647
   Wu D, 2020, INT J APPL EARTH OBS, V89, P0, DOI 10.1016/j.jag.2020.102091
   Zenger-Landolt B., 2016, P GEOB 2016 SOL SYN, V0, P0
   Zou XC, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9100994
NR 73
TC 9
Z9 9
U1 5
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 15
PY 2021
VL 13
IS 11
BP 
EP 
DI 10.3390/rs13112123
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SQ8JG
UT WOS:000660595800001
DA 2023-04-26
ER

PT J
AU Zheng, ZX
   Zhang, XL
   Xiao, PF
   Li, ZS
AF Zheng, Zixian
   Zhang, Xueliang
   Xiao, Pengfeng
   Li, Zhenshi
TI Integrating Gate and Attention Modules for High-Resolution Image Semantic Segmentation
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Semantics; Image segmentation; Feature extraction; Decoding; Remote sensing; Spatial resolution; Logic gates; Attention module (AM); gate module (GM); high-resolution (HR) remote sensing imagery; semantic segmentation
ID fully convolutional networks; aerial; multiscale; fusion
AB Semantic segmentation of high-resolution (HR) remote sensing images achieved great progress by utilizing deep convolutional neural networks (DCNNs) in recent years. However, the decrease of resolution in the feature map of DCNNs brings about the loss of spatial information and thus leads to the blurring of object boundary and misclassification of small objects. In addition, the class imbalance and the high diversity of geographic objects in HR images exacerbate the performance. To deal with the above problems, we proposed an end-to-end DCNN network named GAMNet to balance the contradiction between global semantic information and local details. An integration of attention and gate module (GAM) is specially designed to simultaneously realize multiscale feature extraction and boundary recovery. The integration module can be inserted in an encoder-decoder network with skip connection. Meanwhile, a composite loss function is designed to achieve deep supervision of GAM by adding an auxiliary loss, which can help improve the effectiveness of the integration module. The performance of GAMNet is quantitatively evaluated on the ISPRS 2-D semantic labeling datasets and achieves state-of-the-art performance in comparison with other representative methods.
C1 [Zheng, Zixian; Zhang, Xueliang; Xiao, Pengfeng; Li, Zhenshi] Nanjing Univ, Sch Geog & Ocean Sci, Key Lab Land Satellite Remote Sensing Applicat, Minist Nat Resources,Jiangsu Prov Key Lab Geog In, Nanjing 210023, Peoples R China.
C3 Ministry of Natural Resources of the People's Republic of China; Nanjing University
RP Zhang, XL (corresponding author), Nanjing Univ, Sch Geog & Ocean Sci, Key Lab Land Satellite Remote Sensing Applicat, Minist Nat Resources,Jiangsu Prov Key Lab Geog In, Nanjing 210023, Peoples R China.
EM zhengzx95@gmail.com; zxl@nju.edu.cn; xiaopf@nju.edu.cn; lzhenshi@outlook.com
FU National Science and Technology Major Project of China [21-Y20A06-9001-17/18]; National Natural Science Foundation of China [42071297, 41871235, 41871326]; Fundamental Research Funds for the Central Universities [020914380080]; Highlevel Innovation and Entrepreneurship Talents Introduction Program of Jiangsu Province of China
CR [Anonymous], 2017, C COMP VIS PATT REC, V0, P0
   [Anonymous], 2015, ARXIV, V0, P0
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Audebert N, 2016, INT GEOSCI REMOTE SE, V0, PP5091, DOI 10.1109/IGARSS.2016.7730327
   Cao ZY, 2019, IEEE GEOSCI REMOTE S, V16, P1766, DOI 10.1109/LGRS.2019.2907009
   Chai DF, 2020, ISPRS J PHOTOGRAMM, V161, P309, DOI 10.1016/j.isprsjprs.2020.01.023
   Chai D, 2019, REMOTE SENS ENVIRON, V225, P307, DOI 10.1016/j.rse.2019.03.007
   Chen GZ, 2018, IEEE J-STARS, V11, P1633, DOI 10.1109/JSTARS.2018.2810320
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2016, PROC CVPR IEEE, V0, PP3640, DOI 10.1109/CVPR.2016.396
   Chen YT, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040625
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Cramer M, 2010, PHOTOGRAMM FERNERKUN, V0, PP73, DOI 10.1127/1432-8364/2010/0041
   Deng J., 2009, P CVPR, V0, P248
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Ding HH, 2019, IEEE I CONF COMP VIS, V0, PP6818, DOI 10.1109/ICCV.2019.00692
   Fu JL, 2017, PROC CVPR IEEE, V0, PP4476, DOI 10.1109/CVPR.2017.476
   Fu YY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030280
   Geng QC, 2016, I C VIRTUAL REALITY, V0, PP158, DOI 10.1109/ICVRV.2016.34
   Gerke M., 2014, USE STAIR VISION LIB, V0, P0, DOI DOI 10.13140/2.1.5015.9683
   He K., 2015, P IEEE C COMP VIS PA, V0, P0
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang ZL, 2019, IEEE I CONF COMP VIS, V0, PP603, DOI 10.1109/ICCV.2019.00069
   Islam M. A., 2018, GATED FEEDBACK REFIN, V0, P0
   Kang WC, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11232813
   Li XT, 2020, AAAI CONF ARTIF INTE, V34, P11418
   Lin HN, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050480
   Liu QH, 2020, IEEE T GEOSCI REMOTE, V58, P6309, DOI 10.1109/TGRS.2020.2976658
   Liu YC, 2018, ISPRS J PHOTOGRAMM, V145, P78, DOI 10.1016/j.isprsjprs.2017.12.007
   Liu Y, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060522
   Liu Z., 2019, P 8 INT C COMP PATT, V0, P117
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P7092, DOI 10.1109/TGRS.2017.2740362
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Milan A., 2016, REFINENET MULTIPATH, V0, P0
   Nogueira K, 2019, IEEE T GEOSCI REMOTE, V57, P7503, DOI 10.1109/TGRS.2019.2913861
   Paisitkriangkrai S, 2016, IEEE J-STARS, V9, P2868, DOI 10.1109/JSTARS.2016.2582921
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Ronneberger O., 2015, P MED IM COMP COMP A, V0, P234
   Rottensteiner F., 2012, ISPRS ANN PHOTOGRAMM, V0, P293
   Shi YL, 2020, ISPRS J PHOTOGRAMM, V159, P184, DOI 10.1016/j.isprsjprs.2019.11.004
   Trinh TH, 2018, PR MACH LEARN RES, V80, P0
   Vinyals O, 2015, PROC CVPR IEEE, V0, PP3156, DOI 10.1109/CVPR.2015.7298935
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang HZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050446
   Wang L, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11070884
   Wang MC, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121933
   Weng LG, 2020, ISPRS INT J GEO-INF, V9, P0, DOI 10.3390/ijgi9040256
   Wieland M, 2019, REMOTE SENS ENVIRON, V230, P0, DOI 10.1016/j.rse.2019.05.022
   Xi BB, 2021, IEEE T GEOSCI REMOTE, V59, P5114, DOI 10.1109/TGRS.2020.3022029
   Xin J, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212499
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang SQ, 2018, LECT NOTES COMPUT SC, V11165, P232, DOI 10.1007/978-3-030-00767-6_22
   Yao QL, 2019, INT GEOSCI REMOTE SE, V0, PP1450, DOI 10.1109/IGARSS.2019.8897851
   Yi YN, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151774
   Yu F., 2015, P 4 INT C LEARNING R, V0, P0
   Yue K, 2019, ISPRS J PHOTOGRAMM, V156, P1, DOI 10.1016/j.isprsjprs.2019.07.007
   Zhang J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12040701
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang M, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050500
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhao HS, 2017, PROC CVPR IEEE, V0, PP6230, DOI 10.1109/CVPR.2017.660
   Zheng XW, 2020, ISPRS J PHOTOGRAMM, V170, P15, DOI 10.1016/j.isprsjprs.2020.09.019
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 66
TC 8
Z9 8
U1 3
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 4530
EP 4546
DI 10.1109/JSTARS.2021.3071353
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA SC1VT
UT WOS:000650468700008
DA 2023-04-26
ER

PT J
AU Silva-Perez, C
   Marino, A
   Lopez-Sanchez, JM
   Cameron, I
AF Silva-Perez, Cristian
   Marino, Armando
   Lopez-Sanchez, Juan M.
   Cameron, Iain
TI Multitemporal Polarimetric SAR Change Detection for Crop Monitoring and Crop Type Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Crops; Covariance matrices; Scattering; Monitoring; Time series analysis; Synthetic aperture radar; Satellites; Agricultural fields; change detection; change matrix (CM); image classification; SAR polarimetry; target dynamics and evolution; time series encoding
ID time-series; rice fields; coherence; images
AB The interpretation of multidimensional synthetic aperture radar (SAR) data often requires expert knowledge. In fact, it requires to simultaneously consider several time series of polarimetric features to understand the physical changes of a target and its temporal evolution. In an effort to characterize the changes over time, multitemporal polarimetric SAR (MTPolSAR) change detection was introduced in the literature. However, existing methods either only exploit intensity of changes or the resulting changed scattering mechanisms are not guaranteed to represent physical changes of the target. This article presents a variation in a previously published change detector based on the difference of covariance matrices that characterize the polarimetric information, allowing for an intuitive representation and characterization of physical changes of a target and its dynamics. We show the results of this method for monitoring growth stages of rice crops and present a novel application of the method for crop type mapping from MT-PolSAR data. We compare its performance with a neural network based classifier that uses time series of PolSAR features derived from a target covariance matrix decomposition as input. Experimental results show that the classification performance of the proposed method and the baseline method are comparable with differences between the two methods in the overall balanced accuracy and the F1-macro metrics of around 2% and 3%, respectively. The method presented here achieves similar classification performances of a traditional PolSAR data classifier while providing additional advantages in terms of interpretability and insights about the physical changes of a target over time.
C1 [Silva-Perez, Cristian; Marino, Armando] Univ Stirling, Dept Nat Sci, Stirling FK9 4LA, Scotland.
   [Lopez-Sanchez, Juan M.] Univ Alicante, Inst Comp Res IUII, Alacant 03690, Spain.
   [Cameron, Iain] Environm Syst Ltd, Aberystwyth SY23 3AH, Dyfed, Wales.
C3 University of Stirling; Universitat d'Alacant
RP Silva-Perez, C (corresponding author), Univ Stirling, Dept Nat Sci, Stirling FK9 4LA, Scotland.
EM c.j.silva.perez@stir.ac.uk; armando.marino@stir.ac.uk; juanma.lopez@ua.es; iain.cameron@envsys.co.uk
FU Project EO4cultivar; U.K. Space Agency; Spanish Ministry of Science and Innovation (State Agency of Research, AEI); European Funds for Regional Development (EFRD) [TEC2017-85244-C2-1-P, PID2020-117303GB-C22]
CR Akbari V, 2016, IEEE T GEOSCI REMOTE, V54, P3953, DOI 10.1109/TGRS.2016.2532320
   Akbari V, 2014, IEEE T GEOSCI REMOTE, V52, P3729, DOI 10.1109/TGRS.2013.2275203
   Alonso A, 2016, METHODS MOL BIOL, V1447, P1, DOI 10.1007/978-1-4939-3746-2_1
   Alonso-Gonzalez A, 2020, IEEE T GEOSCI REMOTE, V58, P7317, DOI 10.1109/TGRS.2020.2981929
   Alonso-Gonzalez A, 2016, INT GEOSCI REMOTE SE, V0, PP325, DOI 10.1109/IGARSS.2016.7729077
   [Anonymous], 2004, UNDERSTANDING SYNTHE, V0, P0
   Antropov O, 2011, IEEE T GEOSCI REMOTE, V49, P3838, DOI 10.1109/TGRS.2011.2138146
   Bauer-Marschallingere B, 2019, IEEE T GEOSCI REMOTE, V57, P520, DOI 10.1109/TGRS.2018.2858004
   Cloude S.R., 2009, POLARISATION APPL RE, V0, P0
   Cloude SR, 1997, IEEE T GEOSCI REMOTE, V35, P68, DOI 10.1109/36.551935
   Cloude SR, 1996, IEEE T GEOSCI REMOTE, V34, P498, DOI 10.1109/36.485127
   Conradsen K, 2003, IEEE T GEOSCI REMOTE, V41, P4, DOI 10.1109/TGRS.2002.808066
   Conradsen K, 2016, IEEE T GEOSCI REMOTE, V54, P3007, DOI 10.1109/TGRS.2015.2510160
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jacob AW, 2020, IEEE J-STARS, V13, P535, DOI 10.1109/JSTARS.2019.2958847
   Jong-Sen Lee E.P., 2017, POLARIMETRIC RADAR I, V0, P0
   Kersten P., 2005, COMP CHANGE DETECTIO, V0, P0
   Liu M, 2014, IEEE T GEOSCI REMOTE, V52, P7483, DOI 10.1109/TGRS.2014.2310451
   Lopez-Sanchez JM, 2017, REMOTE SENS ENVIRON, V192, P30, DOI 10.1016/j.rse.2017.02.004
   Lopez-Sanchez JM, 2014, IEEE T GEOSCI REMOTE, V52, P2977, DOI 10.1109/TGRS.2013.2268319
   Marino A, 2022, IEEE T GEOSCI REMOTE, V60, P0, DOI 10.1109/TGRS.2021.3113182
   Marino A, 2017, INT GEOSCI REMOTE SE, V0, P5315
   Marino A, 2014, IEEE T GEOSCI REMOTE, V52, P4781, DOI 10.1109/TGRS.2013.2284510
   Marino A, 2012, IEEE T GEOSCI REMOTE, V50, P3787, DOI 10.1109/TGRS.2012.2185703
   McNairn H, 2016, REMOTE SENS DIGIT IM, V20, P317, DOI 10.1007/978-3-319-47037-5_15
   McNairn H, 2009, IEEE T GEOSCI REMOTE, V47, P3981, DOI 10.1109/TGRS.2009.2026052
   Mestre-Quereda A, 2020, IEEE J-STARS, V13, P4070, DOI 10.1109/JSTARS.2020.3008096
   Nascimento ADC, 2019, IEEE T GEOSCI REMOTE, V57, P1380, DOI 10.1109/TGRS.2018.2866367
   Nielsen AA, 2020, IEEE GEOSCI REMOTE S, V17, P242, DOI 10.1109/LGRS.2019.2918636
   Nielsen AA, 2017, CAN J REMOTE SENS, V43, P582, DOI 10.1080/07038992.2017.1394182
   Nielsen AA, 2020, IEEE GEOSCI REMOTE S, V17, P1727, DOI 10.1109/LGRS.2019.2952202
   NOVAK LM, 1989, IEEE T AERO ELEC SYS, V25, P150, DOI 10.1109/7.18677
   Santos MS, 2018, IEEE COMPUT INTELL M, V13, P59, DOI 10.1109/MCI.2018.2866730
   Silva C, 2018, INT GEOSCI REMOTE SE, V0, P6619
   Skriver H, 2011, IEEE J-STARS, V4, P423, DOI 10.1109/JSTARS.2011.2106198
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Le TT, 2015, ISPRS J PHOTOGRAMM, V107, P64, DOI 10.1016/j.isprsjprs.2015.02.008
   Le TT, 2014, IEEE GEOSCI REMOTE S, V11, P1826, DOI 10.1109/LGRS.2014.2311663
NR 38
TC 7
Z9 7
U1 4
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 12361
EP 12374
DI 10.1109/JSTARS.2021.3130186
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA XO8GN
UT WOS:000730417100007
DA 2023-04-26
ER

PT J
AU Polewski, P
   Shelton, J
   Yao, W
   Heurich, M
AF Polewski, Przemyslaw
   Shelton, Jacquelyn
   Yao, Wei
   Heurich, Marco
TI Instance segmentation of fallen trees in aerial color infrared imagery using active multi-contour evolution with fully convolutional network-based intensity priors
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE simulated annealing; U-net; sample consensus; precision forestry; energy minimization
ID optimization; minimization; algorithms; mortality
AB Over the last several years, semantic image segmentation based on deep neural networks has been greatly advanced. On the other hand, single-instance segmentation still remains a challenging problem. In this paper, we introduce a framework for segmenting instances of a common object class by multiple active contour evolution over semantic segmentation maps of images obtained through fully convolutional networks. The contour evolution is cast as an energy minimization problem, where the aggregate energy functional incorporates a data fit term, an explicit shape model, and accounts for object overlap. Efficient solution neighborhood operators are proposed, enabling optimization through metaheuristics such as simulated annealing. We instantiate the proposed framework in the context of segmenting individual fallen stems from high-resolution aerial multispectral imagery, providing problem-specific energy potentials. We validated our approach on 3 real-world scenes of varying complexity, using 730 manually labeled polygon outlines as ground truth. The test plots were situated in regions of the Bavarian Forest National Park, Germany, which sustained a heavy bark beetle infestation. Evaluations were performed on both the polygon and line segment level, showing that the multi-contour segmentation can achieve up to 0.93 precision and 0.82 recall. An improvement of up to 7 percentage points (pp) in recall and 6 in precision compared to an iterative sample consensus line segment detection baseline was achieved. Despite the simplicity of the applied shape parametrization, an explicit shape model incorporated into the energy function improved the results by up to 4 pp of recall. Finally, we show the importance of using a high-quality semantic segmentation method (e.g. U-net) as the basis for individual stem detection, as the quality of the results degraded dramatically in our baseline experiment utilizing a simpler method. Our method is a step towards increased accessibility of automatic fallen tree mapping in forests, due to higher cost efficiency of aerial imagery acquisition compared to laser scanning. The precise fallen tree maps could be further used as a basis for plant and animal habitat modeling, studies on carbon sequestration as well as soil quality in forest ecosystems.
C1 [Polewski, Przemyslaw; Shelton, Jacquelyn; Yao, Wei] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Kowloon, Hong Kong, Peoples R China.
   [Heurich, Marco] Bavarian Forest Natl Pk, Dept Visitor Management & Natl Pk Monitoring, D-94481 Grafenau, Germany.
C3 Hong Kong Polytechnic University
RP Yao, W (corresponding author), Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Kowloon, Hong Kong, Peoples R China.
EM wei.hn.yao@polyu.edu.hk; marco.heurich@npv-bw.bayern.de
FU Research Grants Council of the Hong Kong Special Administrative Region, China [PolyU 25211819]; Hong Kong Polytechnical University [1-ZE8E, G-YBZ9]
CR Akeret J, 2017, ASTRON COMPUT, V18, P35, DOI 10.1016/j.ascom.2017.01.002
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Arnab A., 2017, ABS170402386 CORR, V0, P0
   Cremers D, 2007, TOP BIOMED ENG, V0, PP447, DOI 10.1007/978-0-387-68343-0_13
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Douglas D. H., 1973, CARTOGRAPHICA INT J, V10, P112, DOI 10.3138/FM57-6770-U75U-7727
   Duan FZ, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040306
   Einzmann K, 2017, FORESTS, V8, P0, DOI 10.3390/f8010021
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Freeman MP, 2016, PHOTOGRAMM ENG REM S, V82, P571, DOI 10.14358/PERS.82.7.571
   Jensen J. R., 2006, REMOTE SENSING ENV E, V0, P0
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Latifi H, 2018, GISCI REMOTE SENS, V55, P839, DOI 10.1080/15481603.2018.1458463
   Lausch A, 2013, ECOL INDIC, V31, P73, DOI 10.1016/j.ecolind.2012.07.026
   Leica,, 2017, LEIC GEOS DMC 3 AIRB, V0, P0
   Li Y, 2017, PROC CVPR IEEE, V0, PP4438, DOI 10.1109/CVPR.2017.472
   LI ZQ, 1987, P NATL ACAD SCI USA, V84, P6611, DOI 10.1073/pnas.84.19.6611
   Long J., 1900, P610, V0, P0
   Lorensen W.E., 1987, P 14 ANN C COMPUTER, V0, PP163, DOI 10.1145/37402.37422
   Marchi N, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10091356
   Marcos D, 2018, PROC CVPR IEEE, V0, PP8877, DOI 10.1109/CVPR.2018.00925
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Muller J, 2010, EUR J FOREST RES, V129, P981, DOI 10.1007/s10342-010-0400-5
   NIEVERGELT J, 1982, COMMUN ACM, V25, P739, DOI 10.1145/358656.358681
   Ostovar A, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19071579
   Panagiotidis D, 2019, NEW ZEAL J FOR SCI, V49, P0, DOI 10.33494/nzjfs492019x26x
   Polewski P, 2015, ISPRS ANN PHOTO REM, V2-3, P181, DOI 10.5194/isprsannals-II-3-W4-181-2015
   Polewski P., 2020, ISPRS INT ARCH PHOTO, V0, P717
   Polewski P, 2017, ISPRS J PHOTOGRAMM, V129, P118, DOI 10.1016/j.isprsjprs.2017.04.023
   Polewski P, 2015, ISPRS J PHOTOGRAMM, V105, P252, DOI 10.1016/j.isprsjprs.2015.01.010
   Queiroz GL, 2019, FORESTS, V10, P0, DOI 10.3390/f10060471
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Safonova A, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11060643
   Seibold S, 2018, ZOOL MONOGR, V1, P607, DOI 10.1007/978-3-319-75937-1_18
   Seidl R, 2017, NAT CLIM CHANGE, V7, P395, DOI 10.1038/NCLIMATE3303
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siarry P, 1997, INT J NUMER METH ENG, V40, P2449, DOI 10.1002/(SICI)1097-0207(19970715)40:13<2449::AID-NME172>3.0.CO;2-O
   Thiel C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12203293
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   Wales DJ, 1997, J PHYS CHEM A, V101, P5111, DOI 10.1021/jp970984n
   WAND MP, 1994, COMPUTATION STAT, V9, P97
   Watson JEM, 2018, NAT ECOL EVOL, V2, P599, DOI 10.1038/s41559-018-0490-x
   Xu S, 2018, ABS180705511 CORR, V0, P0
   Zalik B, 2000, COMPUT GEOSCI, V26, P137, DOI 10.1016/S0098-3004(99)00071-0
NR 49
TC 5
Z9 5
U1 3
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG 15
PY 2021
VL 178
IS 
BP 297
EP 313
DI 10.1016/j.isprsjprs.2021.06.016
EA JUL 2021
PG 17
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA TE4AS
UT WOS:000669954900020
DA 2023-04-26
ER
