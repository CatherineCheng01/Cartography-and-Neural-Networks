
PT J
AU Shukla, G
   Garg, RD
   Srivastava, HS
   Garg, PK
AF Shukla, Gaurav
   Garg, Rahul Dev
   Srivastava, Hari Shanker
   Garg, Pradeep Kumar
TI An effective implementation and assessment of a random forest classifier as a soil spatial predictive model
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID artificial neural-network; decision tree; nitrogen mineralization; landscape patterns; moisture; maps; region; gis
AB Mapping the spatial distribution of soil classes is important for informing soil use and management decisions. This study aimed to effectively implement Random Forest (RF) model and to evaluate the behaviour and performance of the model for soil classification of Indian districts. Soil-forming factors, known as scorpan,' are selected as environmental covariates to tune RF model to classify 11 different soil categories. Thirty-five digital layers are prepared using different satellite data [ALOS (Advanced Land Observing Satellite) digital elevation model, Landsat-8, Moderate Resolution Imaging Spectroradiometer normalized difference vegetation index product, RISAT-1 (Radar Imaging Satellite-1), Sentinel-1A] and climatic data (precipitation and temperature) to represent scorpan environmental covariates in the study area. The RF parameters corresponding to highest Cohen's kappa coefficient () value and lowest number of random split variables are considered optimum values for RF model. Model behaviour evaluation is based on mapping accuracy, sensitivity to data set size, and noise. Two other machine-learning methods, CART (Classification and Regression Tree) decision tree (CDT) and CART ensemble bagger (CEB), are used to provide the comparative study. To access behaviour of models to the false data set, noise in training set is produced by assigning a false class to the training set in 5% increment. Comparative performance of RF model is based on quality assessment measures. To evaluate the performance of models, marginal rates, F-measure, and Jaccard's coefficient of the community, classification success index and agreement coefficients are selected under quality assessment measures. The score is calculated to rank the algorithm. RF model shows high stability against data set reduction in comparison to other methods. The results show that the abrupt change in accuracy is only observed after 60% training data reduction in RF model; however, significant decrease in accuracy can be noted after 45% and 25% data reduction in CEB and CDT, respectively. The RF model shows comparatively the greater resistance to noise. Overall, RF model has performed better than CDT and CEB to classify soil categories in the study area. The results of this research provide new insights into the performance of RF in the context of soil class mapping.
C1 [Shukla, Gaurav; Garg, Rahul Dev; Garg, Pradeep Kumar] Indian Inst Technol, Dept Civil Engn, Geomat Engn, Roorkee, Uttar Pradesh, India.
   [Srivastava, Hari Shanker] ISRO, IIRS, Dehra Dun, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Roorkee; Department of Space (DoS), Government of India; Indian Space Research Organisation (ISRO); Indian Institute of Remote Sensing (IIRS)
RP Shukla, G (corresponding author), Indian Inst Technol, Dept Civil Engn, Geomat Engn, Roorkee, Uttar Pradesh, India.
EM gaur.knit@gmail.com
CR Abdelfattah MA, 2012, J MAPS, V8, P392, DOI 10.1080/17445647.2012.746744
   Anderson K, 2009, PROG PHYS GEOG, V33, P457, DOI 10.1177/0309133309346644
   [Anonymous], 1993, SOIL SURV MAN, V0, P0
   [Anonymous], 2015, ENV DIS RISK SOC CLI, V0, P0
   Barthold FK, 2013, J ARID ENVIRON, V88, P194, DOI 10.1016/j.jaridenv.2012.08.004
   Behrens T, 2007, DEV SOIL SCI, V31, P353
   Behrens T, 2005, J PLANT NUTR SOIL SC, V168, P21, DOI 10.1002/jpln.200421414
   Bodily J. M., 2005, THESIS, V0, P0
   Boerner REJ, 2000, LANDSCAPE ECOL, V15, P425, DOI 10.1023/A:1008179702536
   Boruvka L, 2008, DIGITAL SOIL MAPPING WITH LIMITED DATA, V0, PP303, DOI 10.1007/978-1-4020-8592-5_26
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 1984, CLASSIFICATION REGRE, V0, P0, DOI DOI 10.1002/widm.8
   Bui EN, 2003, GEODERMA, V111, P21, DOI 10.1016/S0016-7061(02)00238-0
   Chavez PS, 1996, PHOTOGRAMM ENG REM S, V62, P1025
   Cole N. J., 2004, THESIS, V0, P0
   Connolly J., 2009, IRISH GEOGRAPHY, V42, P343, DOI 10.1080/00750770903407989
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Eichhorn M. P., 2016, NATURAL SYSTEMS ORG, V0, P0, DOI DOI 10.1002/9781118905982.ch21
   ELRAKAIBY ML, 1994, INT J REMOTE SENS, V15, P3785, DOI 10.1080/01431169408954358
   Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764
   FOODY GM, 1995, INT J GEOGR INF SYST, V9, P527, DOI 10.1080/02693799508902054
   Genuer R, 2010, PATTERN RECOGN LETT, V31, P2225, DOI 10.1016/j.patrec.2010.03.014
   GESSLER PE, 1995, INT J GEOGR INF SYST, V9, P421, DOI 10.1080/02693799508902047
   Gomez C, 2008, GEODERMA, V146, P403, DOI 10.1016/j.geoderma.2008.06.011
   Hengl T, 2007, GEODERMA, V140, P417, DOI 10.1016/j.geoderma.2007.04.022
   Hutchinson TF, 1999, PLANT ECOL, V144, P177, DOI 10.1023/A:1009804020976
   Iverson LR, 1997, LANDSCAPE ECOL, V12, P331, DOI 10.1023/A:1007989813501
   Jaccard P., 2010, NEW PHYTOL, V11, P37, DOI 10.1111/j.1469-8137.1912.tb05611.x
   Jafari A, 2013, GEOMORPHOLOGY, V201, P86, DOI 10.1016/j.geomorph.2013.06.010
   Jafari A, 2012, EUR J SOIL SCI, V63, P284, DOI 10.1111/j.1365-2389.2012.01425.x
   Jenny H., 1941, FACTORS SOIL FORMATI, V0, P0, DOI DOI 10.1097/00010694-194111000-00009
   Jensen J.R., 2005, INTRO DIGITAL IMAGE, V3rd, P0
   Justice C. O., 1981, TERRAIN ANAL REMOTE, V0, P38
   Kempen B, 2012, GEODERMA, V189, P540, DOI 10.1016/j.geoderma.2012.05.028
   Kim J, 2012, SOIL SCI SOC AM J, V76, P2327, DOI 10.2136/sssaj2012.0043
   Kornelsen KC, 2013, J HYDROL, V476, P460, DOI 10.1016/j.jhydrol.2012.10.044
   KOROLYUK TV, 1994, INT J REMOTE SENS, V15, P1379, DOI 10.1080/01431169408954173
   Kovacevic M, 2010, GEODERMA, V154, P340, DOI 10.1016/j.geoderma.2009.11.005
   Labatut V., 2011, 5 INT C INF TECHN AM, V0, P0
   Lookingbill T, 2004, LANDSCAPE ECOL, V19, P417, DOI 10.1023/B:LAND.0000030451.29571.8b
   Louppe G., 2014, UNDERSTANDING RANDOM, V0, P0
   Marchetti A, 2011, CATENA, V85, P267, DOI 10.1016/j.catena.2011.01.012
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   McCoy R., 2005, FIELD METHODS REMOTE, V0, P0
   Mellor A, 2013, REMOTE SENS-BASEL, V5, P2838, DOI 10.3390/rs5062838
   Mishra M., 2014, INT J ADV ENG RES SC, V1, P78
   Moonjun R, 2010, PROGR SOIL SCI, V2, P151, DOI 10.1007/978-90-481-8863-5_13
   Moore I. D., 1993, MODELLING CHANGE IN ENVIRONMENTAL SYSTEMS., V0, P189
   Moran CJ, 2002, INT J GEOGR INF SCI, V16, P533, DOI 10.1080/13658810210138715
   Morris SJ, 1998, LANDSCAPE ECOL, V13, P215, DOI 10.1023/A:1007967630020
   Neild SJ, 2007, SOIL SCI SOC AM J, V71, P245, DOI 10.2136/sssaj2006-0049
   Newhall F., 1996, CALCULATION SOIL MOI, V0, P0
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Pal M, 2003, REMOTE SENS ENVIRON, V86, P554, DOI 10.1016/S0034-4257(03)00132-9
   Panagos P, 2011, INT J DIGIT EARTH, V4, P434, DOI 10.1080/17538947.2011.596580
   Pasztor L, 2012, J MAPS, V8, P215, DOI 10.1080/17445647.2012.705517
   Poggio L, 2013, GEODERMA, V209, P1, DOI 10.1016/j.geoderma.2013.05.029
   Rad MRP, 2014, GEODERMA, V232, P97, DOI 10.1016/j.geoderma.2014.04.036
   Ranjan G, 2000, BASIC APPL SOIL MECH, V0, P0
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   ROUSE JW, 1974, MONITORING VERNAL AD, V0, P0
   Sarma V. A. K., 1987, SOIL RESOURCE MAPPIN, V0, P0
   Scull P, 2005, ECOL MODEL, V181, P1, DOI 10.1016/j.ecolmodel.2004.06.036
   Shcherbenko Ye. V., 1992, MAPPING SCIENCES AND REMOTE SENSING, V29, P248
   Shukla G, 2018, GEOCARTO INT, V33, P240, DOI 10.1080/10106049.2016.1240721
   Shukla G, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.026005
   Smith CAS, 2012, DIGITAL SOIL ASSESSMENTS AND BEYOND, V0, P215
   Srivastava H. S., 2002, ASIAN J GEOINFORMATI, V2, P33
   Srivastava HS, 2009, IEEE T GEOSCI REMOTE, V47, P2528, DOI 10.1109/TGRS.2009.2018448
   Stum AK, 2010, PROGR SOIL SCI, V2, P179, DOI 10.1007/978-90-481-8863-5_15
   Taghizadeh-Mehrjardi R, 2014, ARID LAND RES MANAG, V28, P147, DOI 10.1080/15324982.2013.828801
   Taghizadeh-Mehrjardi R, 2016, ARCH AGRON SOIL SCI, V62, P109, DOI 10.1080/03650340.2015.1038253
   Triantafilis J, 2012, DIGITAL SOIL ASSESSMENTS AND BEYOND, V0, P187
   USGS Landsat 8 product guide, 2016, PROD GUID US USGS LA, V0, P0
   van Zijl GM, 2012, DIGITAL SOIL ASSESSMENTS AND BEYOND, V0, P335
   Zhu AX, 2001, SOIL SCI SOC AM J, V65, P1463, DOI 10.2136/sssaj2001.6551463x
NR 77
TC 12
Z9 12
U1 0
U2 21
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD JUN 15
PY 2018
VL 39
IS 8
BP 2637
EP 2669
DI 10.1080/01431161.2018.1430399
PG 33
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA FV0HP
UT WOS:000424236900029
DA 2023-04-26
ER

PT J
AU Lin, HW
   Chiang, YY
AF Lin, Haowen
   Chiang, Yao-Yi
TI An Uncertainty Aware Method for Geographic Data Conflation
SO BIGSPATIAL 2018: PROCEEDINGS OF THE 7TH ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON ANALYTICS FOR BIG GEOSPATIAL DATA (BIGSPATIAL-2018)
LA English
DT Proceedings Paper
DE Historical maps; Vector data conflation; Uncertainty
AB With a significant amount of spatial data archives online, data conflation is becoming more and more critical in the domain of Geographical Information Science (GIScience) because of its broad applications such as detecting the development of road networks and the change of river course. Existing conflation approaches usually rely on the vector data of corresponding features in multiple sources to have an approximate location. However, they commonly overlook the uncertainty produced during the vector data generation process in the data sources. In previous work, we presented a Convolutional Neural Networks (CNN) recognition system that automatically recognizes areas of geographic features from maps and then generates a centerline representation of the area feature (e.g., from pixels of road areas to a road network). In this paper, we propose a method to systematically quantify the uncertainty generated by an image recognition model and the centerline extraction process. We provide an end-to-end evaluation method that exploits the distance map to calculate the uncertainty value for centerline extraction. Compared with methods that do not consider uncertainty value, our algorithm avoids using a fixed buffer size to identify corresponding features from multiple sources and generate accurate conflation results.
C1 [Lin, Haowen] Univ Southern Calif, Comp Sci Dept, Los Angeles, CA 90007 USA.
   [Chiang, Yao-Yi] Univ Southern Calif, Spatial Sci Inst, Los Angeles, CA USA.
C3 University of Southern California; University of Southern California
RP Lin, HW (corresponding author), Univ Southern Calif, Comp Sci Dept, Los Angeles, CA 90007 USA.
EM haowenli@usc.edu; yaoyic@usc.edu
FU National Endowment for the Humanities [NEH PR-253386-17]; USC Undergraduate Research Associates Program; National Science Foundation [IIS 1564164]; Microsoft Corporation; Azure for Research Award; NVIDIA Corporation
CR Aslan C, 2008, IEEE T PATTERN ANAL, V30, P2188, DOI 10.1109/TPAMI.2007.70842
   Attali D, 2009, MATH VIS, V0, PP109, DOI 10.1007/b106657_6
   Chatzis V, 2000, IEEE T IMAGE PROCESS, V9, P1798, DOI 10.1109/83.869190
   Chiang, 2004, P 12 ANN ACM INT WOR, V0, P0
   Chiang Y.-Y., 2016, INT C REC TRENDS IM, V0, P111
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Dey TK, 2004, ALGORITHMICA, V38, P179, DOI 10.1007/s00453-003-1049-y
   Duan W., 2018, P AUTOCARTO, V0, P0
   Farina A, 1999, PATTERN RECOGN, V32, P877, DOI 10.1016/S0031-3203(98)00107-1
   Giesen J, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG09), V0, PP106, DOI 10.1145/1542362.1542388
   GUO ZC, 1989, COMMUN ACM, V32, P359, DOI 10.1145/62065.62074
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Luscher Patrick, 2007, P 23 INT CART C, V0, P0
   PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2
   Ruiz JJ, 2011, INT J GEOGR INF SCI, V25, P1439, DOI 10.1080/13658816.2010.519707
   Steiniger S, 2009, INT J GEOGR INF SCI, V23, P1345, DOI 10.1080/13658810802634956
   Usery E. L., 2009, CARTOGRAPHIC PERSPEC, V62, P28
   Volz S., 2006, P ISPRS WORKSH MULT, VXXXVI, P101
   Wu X, 2007, P 15 ANN ACM INT S A, V0, P17
NR 20
TC 1
Z9 1
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
SN 
EI 
J9 
PD JUN 15
PY 2018
VL 0
IS 
BP 20
EP 27
DI 10.1145/3282834.3282842
PG 8
WC Computer Science, Information Systems; Computer Science, Theory & Methods; Geosciences, Multidisciplinary
SC Computer Science; Geology
GA BM9JU
UT WOS:000471043000004
DA 2023-04-26
ER

PT J
AU Zhang, CY
   Smith, M
   Fang, CY
AF Zhang, Caiyun
   Smith, Molly
   Fang, Chaoyang
TI Evaluation of Goddard's LiDAR, hyperspectral, and thermal data products for mapping urban land-cover types
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE G-LiHT; data fusion; urban land-cover mapping; ensemble analysis
ID segmentation parameter optimization; image classification; neural-network; point clouds; fusion; heterogeneity; integration; framework
AB Goddard's LiDAR (Light Detection And Ranging), hyperspectral and thermal (G-LiHT) airborne imager is a new system to advance concepts of data fusion for worldwide applications. A recent G-LiHT mission conducted in June 2016 over an urban area opens a new opportunity to assess the G-LiHT products for urban land-cover mapping. In this study, the G-LiHT hyperspectral and LiDAR-canopy height model (LiDAR-CHM) products were evaluated to map five broad land-cover types. A feature/decision-level fusion strategy was developed to integrate two products. Contemporary data processing techniques were applied, including object-based image analysis, machine-learning algorithms, and ensemble analysis. Evaluation focused on the capability of G-LiHT hyperspectral products compared with multispectral data with similar spatial resolution, the contribution of LiDAR-CHM, and the potential of ensemble analysis in land-cover mapping. The results showed that there was no significant difference between the application of the G-LiHT hyperspectral product and simulated Quickbird data in the classification. A synthesis of G-LiHT hyperspectral and LiDAR-CHM products achieved the best result with an overall accuracy of 96.3% and a Kappa value of 0.95 when ensemble analysis was applied. Ensemble analysis of the three classifiers not only increased the classification accuracy but also generated an uncertainty map to show regions with a robust classification as well as areas where classification errors were most likely to occur. Ensemble analysis is a promising tool for land-cover classification.
C1 [Zhang, Caiyun; Smith, Molly] Florida Atlantic Univ, Dept Geosci, 777 Glades Rd, Boca Raton, FL 33431 USA.
   [Fang, Chaoyang] Jiangxi Normal Univ, Key Lab Poyang Lake Wetland & Watershed Res, Nanchang 330022, Jiangxi, Peoples R China.
C3 State University System of Florida; Florida Atlantic University; Jiangxi Normal University
RP Zhang, CY (corresponding author), Florida Atlantic Univ, Dept Geosci, 777 Glades Rd, Boca Raton, FL 33431 USA.
EM czhang3@fau.edu
FU National Science and Technology Program of China [2015BAH50F03]; Collaborative Innovation Center for Major Ecological Security Issues of Jiangxi Province and Monitoring Implementation [JXS-EW-00]
CR Akbari D, 2016, INT J REMOTE SENS, V37, P440, DOI 10.1080/01431161.2015.1129561
   Anderson J. R., 1976, 964 US GEOL SERV, V0, P0
   [Anonymous], 1900, DOI 10.1016/J.MATCHAR.2009.07.002, V0, P0
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cadenasso ML, 2007, FRONT ECOL ENVIRON, V5, P80, DOI 10.1890/1540-9295(2007)5[80:SHIUER]2.0.CO;2
   Chen ZY, 2014, IEEE J-STARS, V7, P4243, DOI 10.1109/JSTARS.2014.2332337
   Cherkassky V, 1997, IEEE TRANS NEURAL NETW, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chirici G, 2016, REMOTE SENS ENVIRON, V176, P282, DOI 10.1016/j.rse.2016.02.001
   Chu HJ, 2016, GISCI REMOTE SENS, V53, P542, DOI 10.1080/15481603.2016.1177249
   Cook BD, 2013, REMOTE SENS-BASEL, V5, P4045, DOI 10.3390/rs5084045
   Demarchi L, 2014, ISPRS J PHOTOGRAMM, V87, P166, DOI 10.1016/j.isprsjprs.2013.10.012
   Dragut L, 2010, INT J GEOGR INF SCI, V24, P859, DOI 10.1080/13658810903174803
   Du PJ, 2012, SENSORS-BASEL, V12, P4764, DOI 10.3390/s120404764
   Foody GM, 2007, INT J REMOTE SENS, V28, P1733, DOI 10.1080/01431160600962566
   Foody GM, 2002, INT J REMOTE SENS, V23, P3853, DOI 10.1080/01431160110109570
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Forzieri G, 2013, INT J APPL EARTH OBS, V23, P313, DOI 10.1016/j.jag.2012.10.004
   Gerke M, 2014, ISPRS J PHOTOGRAMM, V87, P78, DOI 10.1016/j.isprsjprs.2013.10.011
   Ghamisi P, 2015, INT J IMAGE DATA FUS, V6, P189, DOI 10.1080/19479832.2015.1055833
   Gomez-Chova L, 2015, P IEEE, V103, P1560, DOI 10.1109/JPROC.2015.2449668
   Grybas H, 2017, GISCI REMOTE SENS, V54, P515, DOI 10.1080/15481603.2017.1287238
   Guan HY, 2013, INT J REMOTE SENS, V34, P5166, DOI 10.1080/01431161.2013.788261
   Hall M., 2009, ACM SIGKDD EXPLOR NE, V11, P10, DOI 10.1145/1656274.1656278
   Hamedianfar A, 2014, J APPL REMOTE SENS, V8, P0, DOI 10.1117/1.JRS.8.085091
   Hardin P, 2013, GEOGR COMPASS, V7, P7, DOI 10.1111/gec3.12017
   Herold M., 2006, URBAN REMOTE SENSING, V0, PP137, DOI 10.1201/B15917-10
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   Huang X, 2011, INT J REMOTE SENS, V32, P69, DOI 10.1080/01431160903439882
   Johnson B, 2011, ISPRS J PHOTOGRAMM, V66, P473, DOI 10.1016/j.isprsjprs.2011.02.006
   Johnson BA, 2015, ISPRS INT J GEO-INF, V4, P2292, DOI 10.3390/ijgi4042292
   Khodadadzadeh M, 2015, IEEE J-STARS, V8, P2971, DOI 10.1109/JSTARS.2015.2432037
   Kim Y, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8060521
   Lin ZL, 2016, GISCI REMOTE SENS, V53, P85, DOI 10.1080/15481603.2015.1114199
   Liu DS, 2010, REMOTE SENS LETT, V1, P187, DOI 10.1080/01431161003743173
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Luo SZ, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8010003
   Man QX, 2015, INT J REMOTE SENS, V36, P1618, DOI 10.1080/01431161.2015.1015657
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Priem F, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8100787
   Pullanagari R, 2017, J APPL REMOTE SENS, V11, P0, DOI 10.1117/1.JRS.11.026009
   Su TF, 2017, GISCI REMOTE SENS, V54, P354, DOI 10.1080/15481603.2016.1273438
   Tong XH, 2014, IEEE J-STARS, V7, P3998, DOI 10.1109/JSTARS.2013.2272212
   Torbick N, 2015, GISCI REMOTE SENS, V52, P746, DOI 10.1080/15481603.2015.1076561
   Trimble, 2014, ECOGNITION DEV 9 0 1, V0, P0
   Xun L, 2015, GISCI REMOTE SENS, V52, P257, DOI 10.1080/15481603.2015.1026049
   Yan WY, 2015, REMOTE SENS ENVIRON, V158, P295, DOI 10.1016/j.rse.2014.11.001
   Yang H, 2010, J APPL REMOTE SENS, V4, P0, DOI 10.1117/1.3491192
   Zhang CY, 2016, WETLANDS, V36, P201, DOI 10.1007/s13157-015-0730-7
   Zhang CY, 2016, INT J APPL EARTH OBS, V47, P153, DOI 10.1016/j.jag.2016.01.002
   Zhang CY, 2015, ISPRS J PHOTOGRAMM, V104, P213, DOI 10.1016/j.isprsjprs.2014.06.005
   Zhang CY, 2014, PHOTOGRAMM ENG REM S, V80, P733, DOI 10.14358/PERS.80.8.733
   Zhang CY, 2012, REMOTE SENS ENVIRON, V124, P310, DOI 10.1016/j.rse.2012.05.015
   Zhang JX, 2013, REMOTE SENS-BASEL, V5, P3749, DOI 10.3390/rs5083749
   Zhou WQ, 2013, IEEE GEOSCI REMOTE S, V10, P928, DOI 10.1109/LGRS.2013.2251453
NR 57
TC 21
Z9 22
U1 2
U2 33
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD JUN 15
PY 2018
VL 55
IS 1
BP 90
EP 109
DI 10.1080/15481603.2017.1364837
PG 20
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA FS8SD
UT WOS:000422682200005
DA 2023-04-26
ER

PT J
AU Qin, MJ
   Xie, FY
   Li, W
   Shi, ZW
   Zhang, HP
AF Qin, Manjun
   Xie, Fengying
   Li, Wei
   Shi, Zhenwei
   Zhang, Haopeng
TI Dehazing for Multispectral Remote Sensing Images Based on a Convolutional Neural Network With the Residual Architecture
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Convolutional neural network (CNN); haze removal; haze simulation; multispectral remote sensing images
ID haze removal; satellite data
AB Multispectral remote sensing images are often contaminated by haze, which causes low image quality. In this paper, a novel dehazing method based on a deep convolutional neural network (CNN) with the residual structure is proposed for multispectral remote sensing images. First, multiple CNN individuals with the residual structure are connected in parallel and each individual is used to learn a regression from the hazy image to the clear image. Then, the outputs of CNN individuals are fused with weight maps to produce the final dehazing result. In the designed network, the CNN individuals, mining multiscale haze features through multiscale convolutions, are trained using different levels of haze samples to achieve different dehazing abilities. In addition, the weight maps change with the haze distribution, and the fusion of the CNN individuals is adaptive. The designed network is end-to-end, and putting a hazy image into it, the clear scene can be restored. To train the network, a wavelength-dependent haze simulation method is proposed to generate labeled data, which can synthesize hazy multispectral images highly close to real conditions. Experimental results show that the proposed method can accurately remove the haze in each band of multispectral images under different scenes.
C1 [Qin, Manjun; Xie, Fengying; Shi, Zhenwei; Zhang, Haopeng] Beihang Univ, Sch Astronaut, Image Proc Ctr, Beijing 100191, Peoples R China.
   [Li, Wei] Shanghai Inst Satellite Engn, Shanghai 200240, Peoples R China.
C3 Beihang University
RP Xie, FY (corresponding author), Beihang Univ, Sch Astronaut, Image Proc Ctr, Beijing 100191, Peoples R China.
EM mnjune@163.com; xfy_73@buaa.edu.cn; liwei20rth@139.com; shizhenwei@buaa.edu.cn; zhanghaopeng@buaa.edu.cn
FU National Natural Science Foundation of China [61471016]; SAST innovation foundation [SAST201417]
CR Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   CHAVEZ PS, 1988, REMOTE SENS ENVIRON, V24, P459, DOI 10.1016/0034-4257(88)90019-3
   Dal Moro G, 2007, INT J REMOTE SENS, V28, P2187, DOI 10.1080/01431160600928559
   Du Y, 2002, IEEE T GEOSCI REMOTE, V40, P210, DOI 10.1109/36.981363
   Feng C, 2004, INT GEOSCI REMOTE SE, V0, P3387
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He XY, 2010, INT J REMOTE SENS, V31, P5331, DOI 10.1080/01431160903369600
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Kim J, 2016, PROC CVPR IEEE, V0, PP1637, DOI 10.1109/CVPR.2016.181
   Koschmieder H., 1924, BEITR PHYS FREIEN AT, V12, P33, DOI 10.1007/978-3-663-04661-5_2
   Lan X, 2013, EURASIP J ADV SIG PR, V0, P0, DOI DOI 10.1186/1687-6180-2013-86
   Li HF, 2012, PHOTOGRAMM ENG REM S, V78, P947, DOI 10.14358/PERS.78.9.947
   Liu CB, 2011, INT J REMOTE SENS, V32, P8685, DOI 10.1080/01431161.2010.547884
   Liu Q, 2017, SIGNAL PROCESS, V137, P33, DOI 10.1016/j.sigpro.2017.01.036
   Long J, 2014, IEEE GEOSCI REMOTE S, V11, P59, DOI 10.1109/LGRS.2013.2245857
   Makarau A, 2014, IEEE T GEOSCI REMOTE, V52, P5895, DOI 10.1109/TGRS.2013.2293662
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   McCartney EJ, 1976, OPTICS ATMOSPHERE SC, V0, P421
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Ni WP, 2016, NEUROCOMPUTING, V175, P25, DOI 10.1016/j.neucom.2015.10.010
   Pan XX, 2016, IEEE GEOSCI REMOTE S, V13, P1855, DOI 10.1109/LGRS.2016.2614890
   Pan XX, 2015, IEEE SIGNAL PROC LET, V22, P1806, DOI 10.1109/LSP.2015.2432466
   Richter R, 1996, COMPUT GEOSCI, V22, P675, DOI 10.1016/0098-3004(96)00010-6
   Shen HF, 2014, ISPRS J PHOTOGRAMM, V96, P224, DOI 10.1016/j.isprsjprs.2014.06.011
   Tang KT, 2014, PROC CVPR IEEE, V0, PP2995, DOI 10.1109/CVPR.2014.383
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
NR 30
TC 50
Z9 55
U1 7
U2 71
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD MAY 15
PY 2018
VL 11
IS 5
BP 1645
EP 1655
DI 10.1109/JSTARS.2018.2812726
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA GE7QH
UT WOS:000431427400023
DA 2023-04-26
ER

PT J
AU Chin, WH
   Loo, CK
AF Chin, Wei Hong
   Loo, Chu Kiong
TI Topological Gaussian ARAM for biologically inspired topological map building
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Adaptive resonance theory; SLAM; Place cell learning; Topological map; Unsupervised learning
ID simultaneous localization; exploration; oscillations; hippocampus
AB This paper presents a new neural network for online topological map building inspired by beta oscillations and hippocampal place cell learning. The memory layer represents the hippocampus, the input layer represents the entorhinal, and the is the orientation system. In this model, multiple-scale entorhinal grid cell activations form the input layer feature patterns, which are categorized by hippocampal place cells (nodes) and act as spatial categories in the memory layer. Top-down attentive matching and mismatch-mediated reset (beta oscillations), which are triggered by the orientation system, overcome the stability-plasticity dilemma and prevent the catastrophic forgetting of place cell maps. In our proposed method, nodes in the topological map represent place cells (robot location), while edges connect nodes and store robot action (i.e., orientation, direction). Our method is based upon a multi-channel Adaptive Resonance Associative Memory (ARAM) network architecture to obtain multiple sensory sources for topological map building. It comprises two layers: input and memory. The input layer collects sensory data and incrementally clusters the obtained information into a set of topological nodes. In the memory layer, the clustered information is used as a topological map where nodes are associated with actions. The advantages of the proposed method are: (1) it does not require high-level cognitive processes and prior knowledge to make it work in a natural environment; and (2) it can process multiple sensory sources simultaneously in continuous space, which is crucial for real-world robot navigation. Thus, we combine our Topological Gaussian ARAM method (TGARAM) with incremental principle component analysis to constitute a basis for topological map building. Lastly, the proposed method was validated using several standardized benchmark datasets.
C1 [Chin, Wei Hong; Loo, Chu Kiong] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
C3 Universiti Malaya
RP Chin, WH (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM weihong118118@gmail.com
FU University of Malaya (Fellowship Scheme); HIR from the University of Malaya [UM.C/625/1/HIR/MOHE/FCSIT/10]
CR Ball D, 2013, AUTON ROBOT, V34, P149, DOI 10.1007/s10514-012-9317-9
   Barrera A, 2008, AUTON ROBOT, V25, P147, DOI 10.1007/s10514-007-9074-3
   Berke JD, 2008, HIPPOCAMPUS, V18, P519, DOI 10.1002/hipo.20435
   Carpenter GA, 2003, IEEE IJCNN, V0, P1396
   CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2
   Ceriani S, 2009, AUTON ROBOT, V27, P353, DOI 10.1007/s10514-009-9156-5
   Chandrasekaran S, 1996, TECHNICAL REPORT, V0, P0
   Chang HJ, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1473
   Chatila R., 1985, IEEE INT C ROBOTICS, V0, PP138, DOI 10.1109/robot.1985.1087373
   Choi CH, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS
   Filliat D., 2003, COGN SYST RES, V4, P243, DOI 10.1016/S1389-0417(03)00008-1
   Fontana G., 2014, METHODS EXPT TECHNIQ, V0, PP55, DOI 10.1007/978-3-319-00272-9-4
   Ghahramani Z, 2000, NEURAL COMPUT, V12, P831, DOI 10.1162/089976600300015619
   Giovannangeli C, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, P0
   Grossberg S, 2008, BRAIN RES, V1218, P278, DOI 10.1016/j.brainres.2008.04.024
   Grossberg S, 2009, HIPPOCAMPUS, V19, P881, DOI 10.1002/hipo.20602
   HALL P, 1998, IEEE T PATTERN ANAL, V22, P2000
   Hall P. M., 1998, BMVC 98. PROCEEDINGS OF THE NINTH BRITISH MACHINE VISION CONFERENCE, V0, P286
   Jockusch J., 1999, IJCNN99. INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS. PROCEEDINGS (CAT. NO.99CH36339), V0, PP529, DOI 10.1109/IJCNN.1999.831553
   Kuipers B., 1991, ROBOTICS AND AUTONOMOUS SYSTEMS, V8, P47, DOI 10.1016/0921-8890(91)90014-C
   Kwon TB, 2008, ADV ROBOTICS, V22, P339, DOI 10.1163/156855308X292619
   Leivas G., 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI 2010), V0, PP139, DOI 10.1109/MFI.2010.5604482
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   McGlinchey S., 2006, P 5 WSEAS INT C SIGN, V0, P105
   Meyer JA, 2005, ROBOT AUTON SYST, V50, P211, DOI 10.1016/j.robot.2004.09.018
   Milford MJ, 2004, IEEE INT CONF ROBOT, V0, PP403, DOI 10.1109/ROBOT.2004.1307183
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1
   Shia CX, 2010, ROBOT AUTON SYST, V58, P488, DOI 10.1016/j.robot.2010.01.009
   TAN AH, 1995, NEURAL NETWORKS, V8, P437, DOI 10.1016/0893-6080(94)00092-Z
   Tarutoko Y., 2006, P 2006 SICE ICASE IN, V0, P492
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7
   Tomatis N, 2003, ROBOT AUTON SYST, V44, P3, DOI 10.1016/S0921-8890(03)00006-X
   Van Zwynsvoorde D, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS
   Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8
   Winkeler J, 1999, IEEE COMP SOC C COMP, V2, P516, DOI 10.1109/CVPR.1999.784729
NR 35
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD FEB 15
PY 2018
VL 29
IS 4
BP 1055
EP 1072
DI 10.1007/s00521-016-2505-3
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA FU6YW
UT WOS:000424000000012
DA 2023-04-26
ER
