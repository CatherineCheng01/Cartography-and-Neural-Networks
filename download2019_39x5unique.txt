
PT J
AU Zhang, YH
   Ge, TT
   Tian, W
   Liou, YA
AF Zhang, Yonghong
   Ge, Taotao
   Tian, Wei
   Liou, Yuei-An
TI Debris Flow Susceptibility Mapping Using Machine-Learning Techniques in Shigatse Area, China
SO REMOTE SENSING
LA English
DT Article
DE debris flow susceptibility; remote sensing; GIS; oversampling methods; back propagation neural network; one-dimensional convolutional neural network; decision tree; random forest; extreme gradient boosting
ID global land-cover; landslide susceptibility; logistic-regression; frequency ratio; decision tree; models; gis; applicability; region; volume
AB Debris flows have been always a serious problem in the mountain areas. Research on the assessment of debris flows susceptibility (DFS) is useful for preventing and mitigating debris flow risks. The main purpose of this work is to study the DFS in the Shigatse area of Tibet, by using machine learning methods, after assessing the main triggering factors of debris flows. Remote sensing and geographic information system (GIS) are used to obtain datasets of topography, vegetation, human activities and soil factors for local debris flows. The problem of debris flow susceptibility level imbalances in datasets is addressed by the Borderline-SMOTE method. Five machine learning methods, i.e., back propagation neural network (BPNN), one-dimensional convolutional neural network (1D-CNN), decision tree (DT), random forest (RF), and extreme gradient boosting (XGBoost) have been used to analyze and fit the relationship between debris flow triggering factors and occurrence, and to evaluate the weight of each triggering factor. The ANOVA and Tukey HSD tests have revealed that the XGBoost model exhibited the best mean accuracy (0.924) on ten-fold cross-validation and the performance was significantly better than that of the BPNN (0.871), DT (0.816), and RF (0.901). However, the performance of the XGBoost did not significantly differ from that of the 1D-CNN (0.914). This is also the first comparison experiment between XGBoost and 1D-CNN methods in the DFS study. The DFS maps have been verified by five evaluation methods: Precision, Recall, F1 score, Accuracy and area under the curve (AUC). Experiments show that the XGBoost has the best score, and the factors that have a greater impact on debris flows are aspect, annual average rainfall, profile curvature, and elevation.
C1 [Zhang, Yonghong; Ge, Taotao] Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
   [Tian, Wei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Liou, Yuei-An] Natl Cent Univ, Ctr Space & Remote Sensing Res, Taoyuan 32001, Taiwan.
C3 Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; National Central University
RP Tian, W (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.; Liou, YA (corresponding author), Natl Cent Univ, Ctr Space & Remote Sensing Res, Taoyuan 32001, Taiwan.
EM zyh@nuist.edu.cn; gtt347568@gmail.com; tw@nuist.edu.cn; yueian@csrsr.ncu.edu
FU National Natural Science Foundation of China [41661144039, 41875027, 41871238]
CR Abanco C, 2014, NAT HAZARDS, V71, P363, DOI 10.1007/s11069-013-0930-5
   Abdi H., 2010, ENCY RES DESIGN, V3, P1
   Achour Y, 2018, ARAB J GEOSCI, V11, P0, DOI 10.1007/s12517-018-3920-9
   Aditian A, 2018, GEOMORPHOLOGY, V318, P101, DOI 10.1016/j.geomorph.2018.06.006
   Ahmed B, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9040304
   Alharbi T, 2014, NAT HAZARD EARTH SYS, V14, P1553, DOI 10.5194/nhess-14-1553-2014
   Cavalli M, 2017, J MT SCI-ENGL, V14, P2498, DOI 10.1007/s11629-017-4573-y
   Chen XZ, 2016, ENVIRON EARTH SCI, V75, P0, DOI 10.1007/s12665-015-5033-z
   Di Cristo C, 2018, J HYDROL, V559, P585, DOI 10.1016/j.jhydrol.2018.02.016
   Djeddaoui F, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9101031
   Golovko D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090943
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Gregoretti C, 2019, J HYDROL, V568, P575, DOI 10.1016/j.jhydrol.2018.10.001
   [郭沉稳 Guo Chenwen], 2016, 西南交通大学学报 JOURNAL OF SOUTHWEST JIAOTONG UNIVERSITY, V51, P71
   Iverson RM, 2005, S-P BKS GEOPHYS SCI, V0, P105
   Jiang WG, 2017, J GEOGR SCI, V27, P439, DOI 10.1007/s11442-017-1386-4
   Kadavi PR, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081252
   Kang S, 2017, ENG GEOL, V230, P64, DOI 10.1016/j.enggeo.2017.09.017
   Kim HS, 2016, INT J DISAST RISK SC, V7, P293, DOI 10.1007/s13753-016-0096-3
   Kim H, 2014, J MT SCI-ENGL, V11, P578, DOI 10.1007/s11629-013-2829-8
   Li CB, 2018, WIREL COMMUN MOB COM, V0, P0, DOI DOI 10.1155/2018/5018053
   Li CC, 2017, SCI BULL, V62, P508, DOI 10.1016/j.scib.2017.03.011
   LI YY, 2017, WATER-SUI, V9, P0, DOI 10.3390/w9090669
   Liou YIA, 2017, ECOL INDIC, V80, P52, DOI 10.1016/j.ecolind.2017.04.055
   LV X., 2017, J INEQUAL APPL, V0, PP1, DOI 10.3969/j.issn.1671-8755.2017.01.005
   Mao YM, 2017, ENVIRON EARTH SCI, V76, P0, DOI 10.1007/s12665-017-7095-6
   Nikolopoulos EI, 2018, NAT HAZARD EARTH SYS, V18, P2331, DOI 10.5194/nhess-18-2331-2018
   Oh HJ, 2017, APPL SCI-BASEL, V7, P0, DOI 10.3390/app7101000
   Pan HH, 2018, STROJ VESTN-J MECH E, V64, P443, DOI 10.5545/sv-jme.2018.5249
   Prenner D, 2018, WATER RESOUR RES, V54, P6822, DOI 10.1029/2018WR022985
   Rajaraman S, 2018, PEERJ, V6, P0, DOI 10.7717/peerj.4568
   Shimoda A, 2018, COMPUT METH PROG BIO, V163, P39, DOI 10.1016/j.cmpb.2018.05.032
   Shirzadi A, 2017, CATENA, V157, P213, DOI 10.1016/j.catena.2017.05.016
   Stolz A, 2008, LANDSLIDES, V5, P311, DOI 10.1007/s10346-008-0125-4
   Sujatha ER, 2017, J EARTH SYST SCI, V126, P0, DOI 10.1007/s12040-017-0899-7
   [孙妍 Sun Yan], 2014, 自然灾害学报 JOURNAL OF NATURAL DISASTERS, V23, P111
   Tang Minggao, 2012, JOURNAL OF HIGHWAY AND TRANSPORTATION RESEARCH AND DEVELOPMENT, V29, P30, DOI 10.3969/j.issn.1002-0268.2012.05.006
   Tsangaratos P, 2016, LANDSLIDES, V13, P305, DOI 10.1007/s10346-015-0565-6
   Verbiest N, 2014, APPL SOFT COMPUT, V22, P511, DOI 10.1016/j.asoc.2014.05.023
   Wang LJ, 2016, GEOSCI J, V20, P117, DOI 10.1007/s12303-015-0026-1
   Wang SX, 2017, ENERGIES, V10, P0, DOI 10.3390/en10122067
   [王兆印 Wang Zhaoyin], 2011, 地球科学进展 ADVANCE IN EARTH SCIENCES, V26, P1208
   Wu YJ, 2016, PATTERN RECOGN, V60, P770, DOI 10.1016/j.patcog.2016.06.024
   Xu WB, 2013, NAT HAZARDS, V65, P1379, DOI 10.1007/s11069-012-0414-z
   Zhang L, 2017, SCI REP-UK, V7, P0, DOI 10.1038/s41598-017-02365-0
   Zhao JF, 2018, IET SIGNAL PROCESS, V12, P713, DOI 10.1049/iet-spr.2017.0320
   Zhao XJ, 2019, IEEE ACCESS, V7, P12630, DOI 10.1109/ACCESS.2019.2892754
NR 47
TC 58
Z9 59
U1 20
U2 92
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 1
PY 2019
VL 11
IS 23
BP 
EP 
DI 10.3390/rs11232801
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA KE2IO
UT WOS:000508382100082
DA 2023-04-26
ER

PT J
AU Kniaz, VV
AF Kniaz, Vladimir V.
TI Deep Learning for Dense Labeling of Hydrographic Regions in Very High Resolution Imagery
SO IMAGE AND SIGNAL PROCESSING FOR REMOTE SENSING XXV
LA English
DT Proceedings Paper
DE Generative Adversarial Networks; Semantic segmentation; Remote sensing; Multispectral satellite images; Convolutional Neural Networks
ID satellite images; classification; model
AB Automatic dense labeling of multispectral satellite images facilitates faster map update process. Water objects are essential elements of a geographic map. While modern dense labeling methods perform robust segmentation of such objects like roads, buildings, and vegetation, dense labeling of hydrographic regions remains a challenging problem. Water objects change their surface albedo, color, and reflection in different weather and different seasons. Moreover, rivers and lakes can change their boundaries after floods or d roughts. Robust documentation of such seasonal changes is an essential task in the field of analysis of satellite imagery. Due to the high variance in water object appearance, their segmentation is usually performed manually by a human operator. Recent advances in machine learning have made possible robust segmentation of static objects such as buildings and roads. To the best of our knowledge, there is little research in the modern literature regarding dense labeling of water regions. This paper is focused on the development of a deep-learning-based method for dense labeling of hydrographic in aerial and satellite imagery. We use the GeoGAN framework(1) and MobileNetV2(2) as the starting point for our research. The GeoGAN framework uses an aerial image as an input to generate pixel-level annotations of five object c lasses: building, low vegetation, high vegetation, road, and car. The GeoGAN framework leverages two deep learning approaches to ensure robust labeling: a generator with skip connections(3) and Generative Adversarial Networks.(4) A generator with skip connections performs image -> label translation using feed-forward connections between convolutional and deconvolutional layers of the same depth. A GAN framework consists of two competing networks: a generator and a discriminator. The adversarial loss improves the quality of the resulting dense labeling. We made the following contributions to the GeoGAN framework: (1) new MobileNetV2-based generator, (2) adversarial loss function. We term the resulting framework as HydroGAN. We evaluate our HydroGAN model using a new HydroViews dataset focused on dense labeling of areas that are subject to severe flooding during the spring season. The evaluation results are encouraging and demonstrate that our HydroGAN model competes with the state-of-the-art models for dense labeling of aerial and satellite imagery. The evaluation demonstrates that our model can generalize from the training data to previously unseen samples. The developed HydroGAN model is capable of performing dense labeling of water objects in different seasons. We made our model publicly available*.
C1 [Kniaz, Vladimir V.] State Res Inst Aviat Syst GosNIIAS, Moscow, Russia.
   [Kniaz, Vladimir V.] MIPT, Moscow, Russia.
C3 Moscow Institute of Physics & Technology
RP Kniaz, VV (corresponding author), State Res Inst Aviat Syst GosNIIAS, Moscow, Russia.; Kniaz, VV (corresponding author), MIPT, Moscow, Russia.
EM vl.kniaz@gosniias.ru
FU Russian Foundation for Basic Research (RFBR) [17-29-04410]; Russian Science Foundation (RSF) [19-11-110082]
CR Alonzo M, 2014, REMOTE SENS ENVIRON, V148, P70, DOI 10.1016/j.rse.2014.03.018
   Audebert N, 2017, IEEE COMPUT SOC CONF, V0, PP1552, DOI 10.1109/CVPRW.2017.199
   Audebert Nicolas, 2017, ISPRS J PHOTOGRAMM, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Delassus R, 2018, IEEE COMPUT SOC CONF, V0, PP237, DOI 10.1109/CVPRW.2018.00044
   Everingham M, 2012, PASCAL VISUAL OBJECT, V0, P0
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   He Kaiming, 2016, PROC CVPR IEEE, V0, P630
   Isola P., 2017, PROC IEEE C COMPUT V, V0, P1125
   Kniaz VV, 2019, LECT NOTES COMPUT SC, V11134, P606, DOI 10.1007/978-3-030-11024-6_46
   Kniaz VV, 2018, PROC SPIE, V10789, P0, DOI 10.1117/12.2325601
   Knyaz V, 2019, PROC SPIE, V11059, P0, DOI 10.1117/12.2526067
   Knyaz VA, 2019, LECT NOTES COMPUT SC, V11129, P601, DOI 10.1007/978-3-030-11009-3_37
   Ladicky L, 2014, IEEE T PATTERN ANAL, V36, P1056, DOI 10.1109/TPAMI.2013.165
   Li E, 2015, IEEE T GEOSCI REMOTE, V53, P4483, DOI 10.1109/TGRS.2015.2400462
   Li FM, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050494
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Ma L, 2017, ISPRS INT J GEO-INF, V6, P0, DOI 10.3390/ijgi6020051
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Miao ZM, 2018, IEEE GEOSCI REMOTE S, V15, P602, DOI 10.1109/LGRS.2018.2794545
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Moser G, 2013, P IEEE, V101, P631, DOI 10.1109/JPROC.2012.2211551
   Paszke A., 2017, NIPS 2017 WORKSH AUT, V0, P0
   Penatti Otavio A. B., 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP44, DOI 10.1109/CVPRW.2015.7301382
   Rao Y., 2018, IEEE T PATTERN ANAL, V0, PP1, DOI 10.1109/vcip.2018.8698718
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, V0, PP4510, DOI 10.1109/CVPR.2018.00474
   Sherrah J., 2016, ABS160602585 CORR, V0, P0
   Solberg AHS, 1996, IEEE T GEOSCI REMOTE, V34, P100, DOI 10.1109/36.481897
   Srivastava S, 2017, INT GEOSCI REMOTE SE, V0, P5173
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
   Zhou Bolei, 2017, IEEE C COMP VIS PATT, V5, P6, DOI 10.1109/CVPR.2017.544
   2008, 1900, P1, V0, P0
NR 35
TC 2
Z9 2
U1 2
U2 9
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
J9 PROC SPIE
PD JUN 15
PY 2019
VL 11155
IS 
BP 
EP 
DI 10.1117/12.2533161
PG 10
WC Remote Sensing; Optics; Imaging Science & Photographic Technology
SC Remote Sensing; Optics; Imaging Science & Photographic Technology
GA BO7ZA
UT WOS:000526177000028
DA 2023-04-26
ER

PT J
AU Cao, YP
   Guan, DY
   Wu, YL
   Yang, J
   Cao, Y
   Yang, MY
AF Cao, Yanpeng
   Guan, Dayan
   Wu, Yulun
   Yang, Jiangxin
   Cao, Yanlong
   Yang, Michael Ying
TI Box-level segmentation supervised deep neural networks for accurate and real-time multispectral pedestrian detection
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Multispectral data; Pedestrian detection; Deep neural networks; Box-level segmentation; Real-time application
ID tracking; fusion
AB Effective fusion of complementary information captured by multi-modal sensors (visible and infrared cameras) enables robust pedestrian detection under various surveillance situations (e.g., daytime and nighttime). In this paper, we present a novel box-level segmentation supervised learning framework for accurate and real-time multispectral pedestrian detection by incorporating features extracted in visible and infrared channels. Specifically, our method takes pairs of aligned visible and infrared images with easily obtained bounding box annotations as input and estimates accurate prediction maps to highlight the existence of pedestrians. It offers two major advantages over the existing anchor box based multispectral detection methods. Firstly, it overcomes the hyperparameter setting problem occurred during the training phase of anchor box based detectors and can obtain more accurate detection results, especially for small and occluded pedestrian instances. Secondly, it is capable of generating accurate detection results using small-size input images, leading to improvement of computational efficiency for real-time autonomous driving applications. Experimental results on KAIST multi spectral dataset show that our proposed method outperforms state-of-the-art approaches in terms of both accuracy and speed.
C1 [Cao, Yanpeng; Yang, Jiangxin; Cao, Yanlong] Zhejiang Univ, Sch Mech Engn, State Key Lab Fluid Power & Mechatron Syst, Hangzhou, Zhejiang, Peoples R China.
   [Cao, Yanpeng; Guan, Dayan; Wu, Yulun; Yang, Jiangxin; Cao, Yanlong] Zhejiang Univ, Sch Mech Engn, Key Lab Adv Mfg Technol Zhejiang Prov, Hangzhou, Zhejiang, Peoples R China.
   [Yang, Michael Ying] Univ Twente, Scene Understanding Grp, Hengelosestr 99, NL-7514 AE Enschede, Netherlands.
C3 Zhejiang University; Zhejiang University; University of Twente
RP Yang, J (corresponding author), Zhejiang Univ, Sch Mech Engn, State Key Lab Fluid Power & Mechatron Syst, Hangzhou, Zhejiang, Peoples R China.
EM caoyp@zju.edu.cn; 11725001@zju.edu.cn; 3160105381@zju.edu.cn; yangjx@zju.edu.cn; sdcaoyl@zju.edu.cn; michael.yang@utwente.nl
FU National Natural Science Foundation of China [51605428, 51575486, U1664264]
CR Angelova A, 2015, IEEE INT CONF ROBOT, V0, PP704, DOI 10.1109/ICRA.2015.7139256
   [Anonymous], 2010, J MACH LEARN RES, V0, P0
   [Anonymous], 2017, IEEE I CONF COMP VIS, V0, P0, DOI DOI 10.1109/ICCV.2017.322
   Balloch Jonathan C, 2018, ARXIV180903676, V0, P0
   Brazil G, 2017, IEEE I CONF COMP VIS, V0, PP4960, DOI 10.1109/ICCV.2017.530
   Bu FP, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, V0, P100
   Cordts M, 2016, PROC CVPR IEEE, V0, PP3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2015, IEEE I CONF COMP VIS, V0, PP1635, DOI 10.1109/ICCV.2015.191
   Dollar P., 2009, P BRIT MACH VIS C, V0, P91
   Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Geiger A, 2012, PROC CVPR IEEE, V0, PP3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, V0, PP1440, DOI 10.1109/ICCV.2015.169
   Gonzalez A, 2016, SENSORS-BASEL, V16, P0, DOI 10.3390/s16060820
   Guan D., 2018, INFORM FUSION, V0, P0
   Guan DY, 2018, APPL OPTICS, V57, PD108, DOI 10.1364/AO.57.00D108
   Ha Q, 2017, IEEE INT C INT ROBOT, V0, P5108
   Hou QB, 2017, PROC CVPR IEEE, V0, PP5300, DOI 10.1109/CVPR.2017.563
   Hwang S, 2015, PROC CVPR IEEE, V0, PP1037, DOI 10.1109/CVPR.2015.7298706
   Jafari OH, 2016, IEEE INT CONF ROBOT, V0, PP5520, DOI 10.1109/ICRA.2016.7487767
   Jegou S, 2017, IEEE COMPUT SOC CONF, V0, PP1175, DOI 10.1109/CVPRW.2017.156
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM14), V0, PP675, DOI 10.1145/2647868.2654889
   Jingling L., 2016, BRIT MACH VIS C, V0, P0
   Klinger T, 2017, ISPRS J PHOTOGRAMM, V127, P73, DOI 10.1016/j.isprsjprs.2016.11.006
   Koenig D, 2017, IEEE COMPUT SOC CONF, V0, PP243, DOI 10.1109/CVPRW.2017.36
   Krotosky SJ, 2008, IEEE T CIRC SYST VID, V18, P1096, DOI 10.1109/TCSVT.2008.928217
   Law H., 2018, ARXIV180801244, V0, P0
   LEYKIN A, 2007, 2007 IEEE C COMP VIS, V0, PP1, DOI 10.1109/CVPR.2007.383444
   Li C., 2018, ARXIV180804818, V0, P0
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li XF, 2017, IEEE T INTELL TRANSP, V18, P269, DOI 10.1109/TITS.2016.2567418
   Li XD, 2017, PATTERN RECOGN, V67, P73, DOI 10.1016/j.patcog.2017.01.030
   Lin T. Y, 2018, IEEE INT SYMP CIRC S, V0, P0, DOI DOI 10.1109/ISCAS.2018.8351436
   Lin TY, 2017, PROC CVPR IEEE, V0, PP936, DOI 10.1109/CVPR.2017.106
   Liu J., 2018, IMPROVED ANNOTATIONS, V0, P0
   Mao JY, 2017, PROC CVPR IEEE, V0, PP6034, DOI 10.1109/CVPR.2017.639
   Nam W, 2014, ADV NEUR IN, V27, P0
   Oliveira M, 2015, INFORM FUSION, V24, P108, DOI 10.1016/j.inffus.2014.09.003
   Oren M, 1997, PROC CVPR IEEE, V0, PP193, DOI 10.1109/CVPR.1997.609319
   Pascanu R., 2013, ARXIV12115063, V0, P1310
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Rajchl M, 2017, IEEE T MED IMAGING, V36, P674, DOI 10.1109/TMI.2016.2621185
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salton G, 1986, INTRO MODERN INFORM, V0, P0
   Schindler K, 2010, ISPRS J PHOTOGRAMM, V65, P523, DOI 10.1016/j.isprsjprs.2010.06.006
   Shirazi MS, 2017, IEEE T INTELL TRANSP, V18, P4, DOI 10.1109/TITS.2016.2568920
   Shu G, 2012, PROC CVPR IEEE, V0, PP1815, DOI 10.1109/CVPR.2012.6247879
   Simonyan K, 2015, ARXIV, V0, P0
   Torabi A, 2012, COMPUT VIS IMAGE UND, V116, P210, DOI 10.1016/j.cviu.2011.10.006
   Triggs, 2005, PROC CVPR IEEE, V1, P886, DOI 10.1109/CVPR.2005.177
   Wagner J., 2016, PROC EUR S ARTIF NEU, V587, P509
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124
   Wu B., 2016, ARXIV161201051, V0, P0
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang S., 2017, P 2017 IEEE C COMP V, V1, P3
   Zhang SS, 2015, PROC CVPR IEEE, V0, PP1751, DOI 10.1109/CVPR.2015.7298784
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zinkevich M., 2010, NEURAL INFORM PROCES, V0, P0
NR 60
TC 23
Z9 25
U1 2
U2 37
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2019
VL 150
IS 
BP 70
EP 79
DI 10.1016/j.isprsjprs.2019.02.005
PG 10
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA HS7ZS
UT WOS:000464088400006
DA 2023-04-26
ER

PT J
AU Shahabi, H
   Jarihani, B
   Piralilou, ST
   Chittleborough, D
   Avand, M
   Ghorbanzadeh, O
AF Shahabi, Hejar
   Jarihani, Ben
   Piralilou, Sepideh Tavakkoli
   Chittleborough, David
   Avand, Mohammadtaghi
   Ghorbanzadeh, Omid
TI A Semi-Automated Object-Based Gully Networks Detection Using Different Machine Learning Models: A Case Study of Bowen Catchment, Queensland, Australia
SO SENSORS
LA English
DT Article
DE geographic object-based image analysis (GEOBIA); gully erosion; optimal scale detection; stacking model; Bowen catchment
ID artificial neural-networks; image-analysis obia; logistic-regression; random forests; affected areas; erosion; susceptibility; gis; landslides; extraction
AB Gully erosion is a dominant source of sediment and particulates to the Great Barrier Reef (GBR) World Heritage area. We selected the Bowen catchment, a tributary of the Burdekin Basin, as our area of study; the region is associated with a high density of gully networks. We aimed to use a semi-automated object-based gully networks detection process using a combination of multi-source and multi-scale remote sensing and ground-based data. An advanced approach was employed by integrating geographic object-based image analysis (GEOBIA) with current machine learning (ML) models. These included artificial neural networks (ANN), support vector machines (SVM), and random forests (RF), and an ensemble ML model of stacking to deal with the spatial scaling problem in gully networks detection. Spectral indices such as the normalized difference vegetation index (NDVI) and topographic conditioning factors, such as elevation, slope, aspect, topographic wetness index (TWI), slope length (SL), and curvature, were generated from Sentinel 2A images and the ALOS 12-m digital elevation model (DEM), respectively. For image segmentation, the ESP2 tool was used to obtain three optimal scale factors. On using object pureness index (OPI), object matching index (OMI), and object fitness index (OFI), the accuracy of each scale in image segmentation was evaluated. The scale parameter of 45 with OFI of 0.94, which is a combination of OPI and OMI indices, proved to be the optimal scale parameter for image segmentation. Furthermore, segmented objects based on scale 45 were overlaid with 70% and 30% of a prepared gully inventory map to select the ML models' training and testing objects, respectively. The quantitative accuracy assessment methods of Precision, Recall, and an F1 measure were used to evaluate the model's performance. Integration of GEOBIA with the stacking model using a scale of 45 resulted in the highest accuracy in detection of gully networks with an F1 measure value of 0.89. Here, we conclude that the adoption of optimal scale object definition in the GEOBIA and application of the ensemble stacking of ML models resulted in higher accuracy in the detection of gully networks.
C1 [Shahabi, Hejar] Univ Tabriz, Dept Remote Sensing & GIS, Tabriz 5166616471, Iran.
   [Jarihani, Ben; Chittleborough, David] Univ Cent Asia, Mt Soc Res Inst, Khorog 736000, Tajikistan.
   [Jarihani, Ben] Univ Sunshine Coast, Sustainabil Res Ctr, Sunshine Coast, Qld 4556, Australia.
   [Piralilou, Sepideh Tavakkoli; Ghorbanzadeh, Omid] Univ Salzburg, Dept Geoinformat Z GIS, A-5020 Salzburg, Austria.
   [Chittleborough, David] Univ Adelaide, Sch Phys Sci, Adelaide, SA 5005, Australia.
   [Avand, Mohammadtaghi] Tarbiat Modares Univ, Fac Nat Resources & Marine Sci, Tehran 46414356, Iran.
C3 University of Tabriz; University of Central Asia; University of the Sunshine Coast; Salzburg University; University of Adelaide; Tarbiat Modares University
RP Ghorbanzadeh, O (corresponding author), Univ Salzburg, Dept Geoinformat Z GIS, A-5020 Salzburg, Austria.
EM h.shahabi94@ms.tabrizu.ac.ir; bjarihan@usc.edu.au; sepideh.tavakkoli-piralilou@stud.sbg.ac.at; david.chittleborough@adelaide.edu.au; mt.avand70@gmail.com; omid.ghorbanzadeh@stud.sbg.ac.at
FU Austrian Science Fund (FWF) through the GIScience Doctoral College [DKW1237-N23]
CR Abdi O, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19183965
   Aguilar MA, 2013, INT J REMOTE SENS, V34, P2583, DOI 10.1080/01431161.2012.747018
   Arabameri A, 2019, J ENVIRON MANAGE, V232, P928, DOI 10.1016/j.jenvman.2018.11.110
   Arabameri A, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8081369
   Bagheri V, 2017, GEOTECH GEOL ENG, V35, P2163, DOI 10.1007/s10706-017-0236-6
   Bainbridge Z.T., 2015, TRACING SOURCES TRAN, V0, P0
   Ballabio C, 2012, MATH GEOSCI, V44, P47, DOI 10.1007/s11004-011-9379-9
   Billi P, 2003, CATENA, V50, P353, DOI 10.1016/S0341-8162(02)00131-5
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Blaschke T., 2018, NEAR DECOMPOSABILITY, V0, P0
   Blaschke T, 2014, IEEE J-STARS, V7, P4806, DOI 10.1109/JSTARS.2014.2350036
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Brenning A, 2005, NAT HAZARD EARTH SYS, V5, P853, DOI 10.5194/nhess-5-853-2005
   Brodie J., 2013, REEF WATER QUALITY P, V0, P0
   Bunn MD, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11030303
   Chen W, 2018, GEOCARTO INT, V33, P1398, DOI 10.1080/10106049.2018.1425738
   Cherkassky V, 1997, IEEE TRANS NEURAL NETW, V8, P1564, DOI 10.1109/TNN.1997.641482
   Comert R, 2019, ENG GEOL, V260, P0, DOI 10.1016/j.enggeo.2019.105264
   Conoscenti C, 2014, GEOMORPHOLOGY, V204, P399, DOI 10.1016/j.geomorph.2013.08.021
   Conoscenti C, 2013, ENVIRON EARTH SCI, V70, P1179, DOI 10.1007/s12665-012-2205-y
   dOleire-Oltmanns S, 2014, REMOTE SENS-BASEL, V6, P8287, DOI 10.3390/rs6098287
   Death G, 2010, ECOL APPL, V20, P840, DOI 10.1890/08-2023.1
   Desta L, 2012, FIELD GUIDE GULLY PR, V0, P0
   Bui DT, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19112444
   Bui DT, 2016, LANDSLIDES, V13, P361, DOI 10.1007/s10346-015-0557-6
   Dou J, 2015, REMOTE SENS-BASEL, V7, P4318, DOI 10.3390/rs70404318
   Dragut L, 2014, ISPRS J PHOTOGRAMM, V88, P119, DOI 10.1016/j.isprsjprs.2013.11.018
   Dube F, 2014, PHYS CHEM EARTH, V67-69, P145, DOI 10.1016/j.pce.2014.02.002
   Fabricius KE, 2005, MAR POLLUT BULL, V50, P125, DOI 10.1016/j.marpolbul.2004.11.028
   Francipane A., 2017, P EGU GEN ASS C VIEN, V0, P17281
   GARRETT JH, 1994, J COMPUT CIVIL ENG, V8, P129, DOI 10.1061/(ASCE)0887-3801(1994)8:2(129)
   Geyik, 1986, FAO WATERSHED MANAGE, V0, P0
   Ghorbanzadeh Omid, 2020, JOURNAL OF SPATIAL SCIENCE, V65, P401, DOI 10.1080/14498596.2018.1505564
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11020196
   Ghorbanzadeh O, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11010009
   Ghorbanzadeh O, 2018, NAT HAZARDS, V94, P497, DOI 10.1007/s11069-018-3449-y
   Ghorbanzadeh O, 2018, GEOMAT NAT HAZ RISK, V9, P127, DOI 10.1080/19475705.2017.1413012
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   Gomez-Gutierrez A, 2015, NAT HAZARDS, V79, PS291, DOI 10.1007/s11069-015-1703-0
   Goncalves J, 2019, INT J APPL EARTH OBS, V76, P218, DOI 10.1016/j.jag.2018.11.011
   Ionita I., 2015, GULLY EROSION NATURA, V0, P0
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kalantar B, 2018, GEOMAT NAT HAZ RISK, V9, P49, DOI 10.1080/19475705.2017.1407368
   Kaplan G, 2017, EUR J REMOTE SENS, V50, P137, DOI 10.1080/22797254.2017.1297540
   Karami A, 2015, ENVIRON ENG GEOSCI, V21, P101, DOI 10.2113/gseegeosci.21.2.101
   Kavzoglu T, 2014, LANDSLIDES, V11, P425, DOI 10.1007/s10346-013-0391-7
   Kinsey-Henderson AE, 2005, MATH COMPUT SIMULAT, V69, P90, DOI 10.1016/j.matcom.2005.02.022
   Kornejady A., 2015, ENV RESOUR RES, V3, P85, DOI 10.22069/IJERR.2015.2563
   Kroon FJ, 2012, MAR POLLUT BULL, V65, P167, DOI 10.1016/j.marpolbul.2011.10.018
   Kuhnert PM, 2010, ENVIRONMETRICS, V21, P493, DOI 10.1002/env.999
   Labib SM, 2018, EUR J REMOTE SENS, V51, P231, DOI 10.1080/22797254.2017.1419441
   Lahousse T, 2011, NAT HAZARD EARTH SYS, V11, P2715, DOI 10.5194/nhess-11-2715-2011
   Lee S, 2003, EARTH SURF PROC LAND, V28, P1361, DOI 10.1002/esp.593
   Lee S., 2012, TERRIGENOUS MASS MOV, V0, PP193, DOI 10.1007/978-3-642-25495-6_7
   Li H, 2016, SOIL TILL RES, V155, P157, DOI 10.1016/j.still.2015.07.018
   Lisita A, 2013, INT J REMOTE SENS, V34, P5409, DOI 10.1080/01431161.2013.790574
   Liu K, 2018, GEOMORPHOLOGY, V314, P13, DOI 10.1016/j.geomorph.2018.04.011
   Mararakanye N, 2012, S AFR J GEOMAT, V1, P109
   Meena SR, 2019, ISPRS INT GEO-INF, V8, P0, DOI 10.3390/ijgi8020094
   Mekonnen M, 2017, LAND DEGRAD DEV, V28, P708, DOI 10.1002/ldr.2629
   Moosavi V, 2014, GEOMORPHOLOGY, V204, P646, DOI 10.1016/j.geomorph.2013.09.012
   Nyssen J, 2002, EARTH SURF PROC LAND, V27, P1267, DOI 10.1002/esp.404
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pirnazar M, 2017, J FLOOD ENG, V8, P203
   Poesen J, 2003, CATENA, V50, P91, DOI 10.1016/S0341-8162(02)00143-1
   Pourghasemi HR, 2017, SCI TOTAL ENVIRON, V609, P764, DOI 10.1016/j.scitotenv.2017.07.198
   Pradhan B, 2017, LASER SCANNING APPL, V69, P81
   Pradhan B, 2009, INT J PHYS SCI, V4, P1
   Rahmati O, 2017, GEOMORPHOLOGY, V298, P118, DOI 10.1016/j.geomorph.2017.09.006
   Rahmati O, 2016, NAT HAZARDS, V82, P1231, DOI 10.1007/s11069-016-2239-7
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Saxton NE, 2012, GEOMORPHOLOGY, V173, P80, DOI 10.1016/j.geomorph.2012.05.030
   Shruthi RBV, 2015, CATENA, V128, P262, DOI 10.1016/j.catena.2014.01.010
   Shruthi RBV, 2014, GEOMORPHOLOGY, V216, P283, DOI 10.1016/j.geomorph.2014.04.006
   Stumpf A, 2011, REMOTE SENS ENVIRON, V115, P2564, DOI 10.1016/j.rse.2011.05.013
   Takken I, 2008, CATENA, V75, P257, DOI 10.1016/j.catena.2008.07.001
   Tavakkoli Piralilou S, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11212575
   Valentin C, 2005, CATENA, V63, P132, DOI 10.1016/j.catena.2005.06.001
   van der Laan MJ, 2007, STAT APPL GENET MOL, V6, P0, DOI 10.2202/1544-6115.1309
   Veress M., 2013, GEOMORPHOLOGICAL IMP, V0, P301
   Vrieling A, 2007, INT J REMOTE SENS, V28, P2723, DOI 10.1080/01431160600857469
   Wang T., 2014, SCI WORLD J, V2014, P0, DOI 10.1155/2014/417325
   Wilkinson SN, 2013, AGR ECOSYST ENVIRON, V180, P90, DOI 10.1016/j.agee.2012.02.002
   Zabihi M, 2018, CATENA, V161, P1, DOI 10.1016/j.catena.2017.10.010
   Zare M, 2013, ARAB J GEOSCI, V6, P2873, DOI 10.1007/s12517-012-0610-x
   Zglobicki W, 2015, CATENA, V126, P28, DOI 10.1016/j.catena.2014.10.022
NR 87
TC 47
Z9 48
U1 0
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD NOV 15
PY 2019
VL 19
IS 22
BP 
EP 
DI 10.3390/s19224893
PG 21
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA JW9QY
UT WOS:000503381500072
PM 31717546
DA 2023-04-26
ER

PT J
AU Li, S
   Zhu, ZY
   Wang, HP
   Xu, F
AF Li, Suo
   Zhu, Zhanyu
   Wang, Haipeng
   Xu, Feng
TI 3D Virtual Urban Scene Reconstruction From a Signal Optical Remote Sensing Image
SO IEEE ACCESS
LA English
DT Article
DE Optical image; urban reconstruction; convolutional neural networks
ID land-cover database
AB This paper presents a low-cost and efficient method for 3D virtual urban scene reconstruction based on multi-source remote sensing big data and deep learning. By integrating maps, satellite optical images, and digital terrain model (DTM), the proposed method achieves a reasonable reconstructed 3D model for complex urban. The method consists of two independent convolutional neural networks (CNN) to process the land cover and the building height extraction. The proposed method is then tested on a 100 km(2) scene in San Diego, USA, including about 30 000 buildings. The land cover classification achieves an overall accuracy (OA) of 80.4% for eight types of land as defined in NLCD 2011 datasets. Building height estimation achieves an average error at 1.9 meters on NYC open data, the building footprint. Furthermore, the scene reconstruction including the estimation of both land cover and building height can be finished in 10 min on a single NVidia Titan X GPU.
C1 [Li, Suo; Zhu, Zhanyu; Wang, Haipeng; Xu, Feng] Fudan Univ, Key Lab Informat Sci Electromagnet Waves MoE, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Wang, HP (corresponding author), Fudan Univ, Key Lab Informat Sci Electromagnet Waves MoE, Shanghai 200433, Peoples R China.
EM hpwang@fudan.edu.cn
FU National Key Research and Developmen Program of China [2017YFB0502703]; NSFC [61571132, 61571134, 61822107]; SAST Research Fund [SAST2017-078]
CR Akbarzadeh A., 2006, 3 INT S 3D DAT PROC, V0, P0
   Bertan E, 2006, INT GEOSCI REMOTE SE, V0, PP1415, DOI 10.1109/IGARSS.2006.365
   Habbecke M., 2010, ECCV WORKSH REC MOD, V0, P253
   Homer C, 2015, PHOTOGRAMM ENG REM S, V81, P345, DOI 10.14358/PERS.81.5.345
   Javanmardi M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY (ICVES), V0, PP126, DOI 10.1109/ICVES.2015.7396906
   Jin Y.-Q., 2015, IEEE SPECTRUM, V9, P70
   Long J, 2015, PROC CVPR IEEE, V0, PP3431, DOI 10.1109/CVPR.2015.7298965
   Musialski P, 2013, COMPUT GRAPH FORUM, V32, P146, DOI 10.1111/cgf.12077
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Singh SP, 2013, INT ARCH PHOTOGRAMM, V40-2-W2, P73
   Sun XF, 2016, INT C PATT RECOG, V0, PP663, DOI 10.1109/ICPR.2016.7899710
   Wickham J, 2017, REMOTE SENS ENVIRON, V191, P328, DOI 10.1016/j.rse.2016.12.026
   Wojna Z., 2017, DEVIL IS DECODER CLA, V0, P0
   Xu F, 2017, CHINESE PHYS B, V26, P0, DOI 10.1088/1674-1056/26/1/017803
   Yuan J., 2016, AUTOMATIC BUILDING E, V0, P0
NR 15
TC 2
Z9 2
U1 5
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
EI 
J9 IEEE ACCESS
JI IEEE Access
PD JUN 15
PY 2019
VL 7
IS 
BP 68305
EP 68315
DI 10.1109/ACCESS.2019.2915932
PG 11
WC Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA IC8IF
UT WOS:000471221600001
DA 2023-04-26
ER
