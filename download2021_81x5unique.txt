
PT J
AU Salem, H
   Soria, D
   Lund, JN
   Awwad, A
AF Salem, Hesham
   Soria, Daniele
   Lund, Jonathan N.
   Awwad, Amir
TI A systematic review of the applications of Expert Systems (ES) and machine learning (ML) in clinical urology
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
LA English
DT Review
ID artificial neural-network; prostate-specific antigen; predicting pathological stage; decision-support-systems; bladder outlet obstruction; shock-wave lithotripsy; resonance-imaging variables; cancer detection rate; fuzzy cognitive map; radical prostatectomy
AB Background Testing a hypothesis for 'factors-outcome effect' is a common quest, but standard statistical regression analysis tools are rendered ineffective by data contaminated with too many noisy variables. Expert Systems (ES) can provide an alternative methodology in analysing data to identify variables with the highest correlation to the outcome. By applying their effective machine learning (ML) abilities, significant research time and costs can be saved. The study aims to systematically review the applications of ES in urological research and their methodological models for effective multi-variate analysis. Their domains, development and validity will be identified. Methods The PRISMA methodology was applied to formulate an effective method for data gathering and analysis. This study search included seven most relevant information sources: WEB OF SCIENCE, EMBASE, BIOSIS CITATION INDEX, SCOPUS, PUBMED, Google Scholar and MEDLINE. Eligible articles were included if they applied one of the known ML models for a clear urological research question involving multivariate analysis. Only articles with pertinent research methods in ES models were included. The analysed data included the system model, applications, input/output variables, target user, validation, and outcomes. Both ML models and the variable analysis were comparatively reported for each system. Results The search identified n = 1087 articles from all databases and n = 712 were eligible for examination against inclusion criteria. A total of 168 systems were finally included and systematically analysed demonstrating a recent increase in uptake of ES in academic urology in particular artificial neural networks with 31 systems. Most of the systems were applied in urological oncology (prostate cancer = 15, bladder cancer = 13) where diagnostic, prognostic and survival predictor markers were investigated. Due to the heterogeneity of models and their statistical tests, a meta-analysis was not feasible. Conclusion ES utility offers an effective ML potential and their applications in research have demonstrated a valid model for multi-variate analysis. The complexity of their development can challenge their uptake in urological clinics whilst the limitation of the statistical tools in this domain has created a gap for further research studies. Integration of computer scientists in academic units has promoted the use of ES in clinical urological research.
C1 [Salem, Hesham] Univ Nottingham, NIHR Nottingham Biomed Res Ctr, Sch Med, Urol Dept, Nottingham NG7 2UH, England.
   [Salem, Hesham; Lund, Jonathan N.] Univ Nottingham, Royal Derby Hosp, Univ Hosp Derby & Burton NHS Fdn Trust, Derby DE22 3DT, England.
   [Soria, Daniele] Univ Westminster, Sch Comp Sci & Engn, London W1W 6UW, England.
   [Awwad, Amir] Univ Nottingham, Sch Med, NIHR Nottingham Biomed Res Ctr, Sir Peter Mansfield Imaging Ctr, Nottingham NG7 2UH, England.
   [Awwad, Amir] Western Univ, Schulich Sch Med & Dent, London Hlth Sci Ctr, Dept Med Imaging,Univ Hosp, London, ON, Canada.
C3 University of Nottingham; University of Nottingham; University of Westminster; University of Nottingham; London Health Sciences Centre; Western University (University of Western Ontario)
RP Awwad, A (corresponding author), Univ Nottingham, Sch Med, NIHR Nottingham Biomed Res Ctr, Sir Peter Mansfield Imaging Ctr, Nottingham NG7 2UH, England.; Awwad, A (corresponding author), Western Univ, Schulich Sch Med & Dent, London Hlth Sci Ctr, Dept Med Imaging,Univ Hosp, London, ON, Canada.
EM amir.awwad@lhsc.on.ca
CR Abbod M. F., 2004, BIOMEDICAL ENGINEERING, V0, P0
   Abbod M F, 2006, 2006 3 INT IEEE C IN, V0, P0
   Altunay S, 2009, EXPERT SYST APPL, V36, P4891, DOI 10.1016/j.eswa.2008.05.051
   Ammenwerth E, 2013, ARTIF INTELL MED, V59, P1, DOI 10.1016/j.artmed.2013.05.001
   [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Arlen AM, 2016, J PEDIATR UROL, V12, P0, DOI 10.1016/j.jpurol.2016.03.005
   Babaian RJ, 2000, UROLOGY, V56, P1000, DOI 10.1016/S0090-4295(00)00830-X
   Lopes MHBD, 2013, INT J MED INFORM, V82, P201, DOI 10.1016/j.ijmedinf.2012.05.012
   Bagli DJ, 1998, J UROLOGY, V160, P980, DOI 10.1016/S0022-5347(01)62675-2
   Bassi P, 2007, BJU INT, V99, P1007, DOI 10.1111/j.1464-410X.2007.06755.x
   Batuello JT, 2001, UROLOGY, V57, P481, DOI 10.1016/S0090-4295(00)01039-6
   Beligiannis G, 2006, LECT NOTES ARTIF INT, V4251, P968
   Benbasat I., 1989, KNOWL ACQUIS, V1, P215, DOI 10.1016/S1042-8143(89)80020-2
   Benecchi L, 2006, UROLOGY, V68, P357, DOI 10.1016/j.urology.2006.03.003
   BINIK YM, 1988, J NERV MENT DIS, V176, P387, DOI 10.1097/00005053-198807000-00001
   Bologna G, 2017, J ARTIF INTELL SOFT, V7, P265, DOI 10.1515/jaiscr-2017-0019
   Borque A, 2001, J UROLOGY, V166, P1672, DOI 10.1016/S0022-5347(05)65651-0
   Botoca C, 2009, PROCEEDINGS OF THE 8TH WSEAS INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, V0, P108
   Boyington AR, 2004, NURS OUTLOOK, V52, P241, DOI 10.1016/j.outlook.2004.04.014
   Buchner A, 2013, EJSO-EUR J SURG ONC, V39, P372, DOI 10.1016/j.ejso.2013.02.009
   Buchner A, 2012, CLIN GENITOURIN CANC, V10, P37, DOI 10.1016/j.clgc.2011.10.001
   Cabitza F, 2020, ANN TRANSL MED, V8, P0, DOI 10.21037/atm.2020.03.63
   Cabitza F, 2019, ANN TRANSL MED, V7, P0, DOI 10.21037/atm.2019.04.07
   Cai T, 2007, ANN ONCOL, V18, P604, DOI 10.1093/annonc/mdl411
   Cai T, 2007, ONCOL REP, V18, P959
   Cai T, 2011, J SURG RES, V167, P267, DOI 10.1016/j.jss.2009.05.004
   Castanho MJP, 2013, EXPERT SYST APPL, V40, P466, DOI 10.1016/j.eswa.2012.07.046
   Catto JWF, 2010, EUR UROL, V57, P398, DOI 10.1016/j.eururo.2009.10.029
   Catto JWF, 2009, CLIN CANCER RES, V15, P3150, DOI 10.1158/1078-0432.CCR-08-1960
   Catto JWF, 2006, J UROLOGY, V175, P474, DOI 10.1016/S0022-5347(05)00246-6
   Catto JWF, 2003, CLIN CANCER RES, V9, P4172
   Chang PL, 1999, MED DECIS MAKING, V19, P419
   Chang TC, 2021, UROL CLIN N AM, V48, P151, DOI 10.1016/j.ucl.2020.09.004
   Chiu JS, 2009, J MED SYST, V33, P91, DOI 10.1007/s10916-008-9168-2
   Cinar M, 2009, EXPERT SYST APPL, V36, P6357, DOI 10.1016/j.eswa.2008.08.010
   Cosma G, 2016, PLOS ONE, V11, P0, DOI 10.1371/journal.pone.0155856
   Cummings JM, 2000, J UROLOGY, V164, P326, DOI 10.1016/S0022-5347(05)67351-X
   Dal Moro F, 2006, KIDNEY INT, V69, P157, DOI 10.1038/sj.ki.5000010
   Castanho MJD, 2008, APPL MATH COMPUT, V202, P78, DOI 10.1016/j.amc.2007.11.055
   Djavan B, 2004, UROLOGY, V64, P1144, DOI 10.1016/j.urology.2004.08.049
   Djavan B, 2002, J CLIN ONCOL, V20, P921, DOI 10.1200/JCO.20.4.921
   Ecke TH, 2012, UROL ONCOL-SEMIN ORI, V30, P139, DOI 10.1016/j.urolonc.2009.12.009
   El-Mekresh M, 2009, J UROLOGY, V182, P466, DOI 10.1016/j.juro.2009.04.018
   Eminaga O., 2021, ARTIF INTELL MED, V0, PP309, DOI 10.1016/B978-0-12-821259-2.00016-8
   Eminaga O, 2018, JCO CLIN CANCER INFO, V2, P0, DOI 10.1200/CCI.17.00126
   Filella X, 2014, CLIN CHIM ACTA, V436, P303, DOI 10.1016/j.cca.2014.06.019
   Finne P, 2000, UROLOGY, V56, P418, DOI 10.1016/S0090-4295(00)00672-5
   Fujikawa K, 2003, INT J UROL, V10, P149, DOI 10.1046/j.1442-2042.2003.00589.x
   Garg AX, 2005, JAMA-J AM MED ASSOC, V293, P1223, DOI 10.1001/jama.293.10.1223
   Gatidis S, 2015, NMR BIOMED, V28, P914, DOI 10.1002/nbm.3329
   Gil D, 2012, EXPERT SYST APPL, V39, P12564, DOI 10.1016/j.eswa.2012.05.028
   Gil D, 2010, EXPERT SYST APPL, V37, P4713, DOI 10.1016/j.eswa.2009.12.055
   Gil D, 2009, EXPERT SYST APPL, V36, P5754, DOI 10.1016/j.eswa.2008.06.065
   Girela JL, 2013, BIOL REPROD, V88, P0, DOI 10.1095/biolreprod.112.104653
   Gomha MA, 2004, J UROLOGY, V172, P175, DOI 10.1097/01.ju.0000128646.20349.27
   Gorman R, 1995, PROC ANNU SYMP COMPUT APPL MED CARE, V0, P527
   Goyal NK, 2007, INDIAN J UROL, V23, P14, DOI 10.4103/0970-1591.30258
   Green WJF, 2016, BRIT J CANCER, V115, P236, DOI 10.1038/bjc.2016.169
   Hamid A, 2003, BJU INT, V91, P821, DOI 10.1046/j.1464-410X.2003.04230.x
   Han M, 2001, CANCER, V91, P1661, DOI 10.1002/1097-0142(20010415)91:8+<1661::AID-CNCR1180>3.3.CO;2-X
   Han M, 2000, UROLOGY, V56, P994, DOI 10.1016/S0090-4295(00)00815-3
   Hao ATH, 2013, INT J MED INFORM, V82, P604, DOI 10.1016/j.ijmedinf.2013.02.006
   Hassanien AE, 2011, APPL SOFT COMPUT, V11, P2035, DOI 10.1016/j.asoc.2010.07.001
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, P0, DOI 10.1002/widm.1312
   Hu XH, 2014, ASIAN J ANDROL, V16, P897, DOI 10.4103/1008-682X.129940
   Hurst RE, 1997, CYTOMETRY, V27, P36, DOI 10.1002/(SICI)1097-0320(19970101)27:1<36::AID-CYTO5>3.3.CO;2-4
   JACKSON P, 1999, INTRO EXPERT SYSTEMS, V0, P0
   Kalra P, 2003, CANCER, V98, P1849, DOI 10.1002/cncr.11748
   Kattan MW, 1996, UROLOGY, V47, P14, DOI 10.1016/S0090-4295(99)80375-6
   Kawakami S, 2008, EUR UROL, V54, P601, DOI 10.1016/j.eururo.2008.01.017
   Kawamoto K, 2005, BMJ-BRIT MED J, V330, P765, DOI 10.1136/bmj.38398.500764.8F
   Keles A, 2007, COMPUT BIOL MED, V37, P1617, DOI 10.1016/j.compbiomed.2007.03.006
   Kim M, 2014, INT NEUROUROL J, V18, P198, DOI 10.5213/inj.2014.18.4.198
   Kim SY, 2011, KOREAN J RADIOL, V12, P588, DOI 10.3348/kjr.2011.12.5.588
   Kolasa M, 2009, ADV INTEL SOFT COMPU, V65, P113
   Koutsojannis C, 2004, LECT NOTES COMPUT SC, V3214, P1106
   Koutsojannis C, 2012, COMPUT METH PROG BIO, V107, P84, DOI 10.1016/j.cmpb.2012.02.012
   Koutsojannis C, 2009, INT CONF INTELL SYST, V0, PP341, DOI 10.1109/ISDA.2009.110
   Koutsojannis C, 2008, ELE COM ENG, V0, P254
   Krongrad A, 1997, J UROLOGY, V157, P534, DOI 10.1016/S0022-5347(01)65195-4
   Kshirsagar A, 2006, INT J IMPOT RES, V18, P47, DOI 10.1038/sj.ijir.3901369
   Kuo RJ, 2015, ARTIF INTELL MED, V63, P119, DOI 10.1016/j.artmed.2014.12.008
   Lakkaraju HKE, 2017, 170701154 ARXIV, V0, P0
   LAMB DJ, 1993, WORLD J UROL, V11, P129
   Lawrentschuk N, 2011, INT UROL NEPHROL, V43, P23, DOI 10.1007/s11255-010-9750-7
   Lee HJ, 2006, J ULTRAS MED, V25, P815, DOI 10.7863/jum.2006.25.7.815
   Lee HJ, 2010, EUR RADIOL, V20, P1476, DOI 10.1007/s00330-009-1686-x
   Liao SH, 2005, EXPERT SYST APPL, V28, P93, DOI 10.1016/j.eswa.2004.08.003
   Llobet R, 2007, INT J MED INFORM, V76, P547, DOI 10.1016/j.ijmedinf.2006.03.001
   Loch T, 1999, PROSTATE, V39, P198
   Logvinenko T, 2015, J PEDIATR UROL, V11, P0, DOI 10.1016/j.jpurol.2015.03.006
   Marszall MP, 2012, CENT EUR J MED, V7, P672, DOI 10.2478/s11536-012-0027-7
   Matsui Y, 2004, JPN J CLIN ONCOL, V34, P602, DOI 10.1093/jjco/hyh112
   Matsui Y, 2002, JPN J CLIN ONCOL, V32, P530, DOI 10.1093/jjco/hyf114
   Mattfeldt T, 1999, BJU INT, V84, P316
   Mattfeldt T, 2001, EUR UROL, V39, P530, DOI 10.1159/000052499
   Matulewicz L, 2014, J MAGN RESON IMAGING, V40, P1414, DOI 10.1002/jmri.24487
   McCarthy J, 2006, AI MAG, V27, P12
   Meijer RP, 2009, WORLD J UROL, V27, P593, DOI 10.1007/s00345-009-0444-7
   Michaels EK, 1998, UROLOGY, V51, P335, DOI 10.1016/S0090-4295(97)00611-0
   Moons KGM, 2019, ANN INTERN MED, V170, PW1, DOI 10.7326/M18-1377
   MOUL JW, 1995, J UROLOGY, V153, P1674, DOI 10.1016/S0022-5347(01)67502-5
   Nagendran M, 2020, BMJ-BRIT MED J, V368, P0, DOI 10.1136/bmj.m689
   Naguib RNG, 1997, P ANN INT IEEE EMBS, V19, P1007, DOI 10.1109/IEMBS.1997.756515
   Naguib RNG, 1998, BRIT J CANCER, V78, P246, DOI 10.1038/bjc.1998.472
   NICE, 2014, PROSTATE CANC DIAGNO, V0, P0
   NICE, 2008, PROSTATE CANC DIAGNO, V0, P0
   OKEEFE RM, 1993, ARTIF INTELL REV, V7, P3, DOI 10.1007/BF00849196
   Pandey B, 2009, COMPUT BIOL MED, V39, P215, DOI 10.1016/j.compbiomed.2008.12.008
   Pantazopoulos D, 1998, BRIT J UROL, V81, P574
   Pantazopoulos D, 1998, J UROLOGY, V159, P1619, DOI 10.1097/00005392-199805000-00057
   Papageorgiou EI, 2012, COMPUT METH PROG BIO, V105, P233, DOI 10.1016/j.cmpb.2011.09.006
   Parekattil SJ, 2005, J UROLOGY, V174, P1380, DOI 10.1097/01.ju.0000173921.67597.e8
   Parekattil SJ, 2003, J UROLOGY, V169, P917, DOI 10.1097/01.ju.0000051322.60266.06
   Pereira MA, 2004, P ANN INT IEEE EMBS, V26, P3412
   Petrovic S, 2011, EXPERT SYST APPL, V38, P10759, DOI 10.1016/j.eswa.2011.01.109
   Petrucci K, 1991, P ANN S COMP APPL ME, V0, P0
   Porter C, 2001, MOL UROL, V5, P159, DOI 10.1089/10915360152745830
   Porter CR, 2005, UROLOGY, V65, P937, DOI 10.1016/j.urology.2004.11.049
   Potter SR, 1999, UROLOGY, V54, P791, DOI 10.1016/S0090-4295(99)00328-3
   Poulakis V, 2004, UROLOGY, V64, P516, DOI 10.1016/j.urology.2004.04.027
   Poulakis V, 2004, J UROLOGY, V172, P1306, DOI 10.1097/01.ju.0000139881.04126.b6
   Poulakis V, 2002, UROLOGE A, V41, P583, DOI 10.1007/s00120-002-0194-2
   Powell CR, 2008, INT J IMPOT RES, V20, P79, DOI 10.1038/sj.ijir.3901593
   Qureshi KN, 2000, J UROLOGY, V163, P630, DOI 10.1016/S0022-5347(05)67948-7
   Ramasamy R, 2013, J UROLOGY, V189, P638, DOI 10.1016/j.juro.2012.09.038
   Regnier-Coudert O, 2012, ARTIF INTELL MED, V55, P25, DOI 10.1016/j.artmed.2011.11.003
   Remzi M, 2003, UROLOGY, V62, P456, DOI 10.1016/S0090-4295(03)00409-6
   Ronco AL, 1999, ULTRASOUND MED BIOL, V25, P729, DOI 10.1016/S0301-5629(99)00011-3
   Samli MM, 2004, J UROLOGY, V171, P2354, DOI 10.1097/01.ju.0000125272.03182.c3
   Saritas I, 1900, P345, V0, P0
   Saritas I, 2010, EXPERT SYST APPL, V37, P6646, DOI 10.1016/j.eswa.2010.03.056
   Seckiner Ilker, 2011, CAN UROL ASSOC J, V5, PE152, DOI 10.5489/cuaj.10043
   Seker H, 2003, IEEE T INF TECHNOL B, V7, P114, DOI 10.1109/TITB.2003.811876
   Serati M, 2011, EUR UROL, V60, P253, DOI 10.1016/j.eururo.2011.03.010
   Serrano-Durba A, 2004, BJU INT, V94, P120, DOI 10.1111/j.1464-410X.2004.04912.x
   SHORTLIFFE EH, 1975, CLIN RES, V23, P0
   Stephan C, 2005, BJU INT, V96, P521, DOI 10.1111/j.1464-410X.2005.05677.x
   Stephan C, 2002, CLIN CHEM, V48, P1279
   Stephan C, 2008, BJU INT, V102, P799, DOI 10.1111/j.1464-410X.2008.07765.x
   Stephan C, 2006, BIOL CHEM, V387, P801, DOI 10.1515/BC.2006.101
   Stephan C, 2006, EUR UROL, V50, P1014, DOI 10.1016/j.eururo.2006.04.011
   Stephan C, 2007, UROLOGY, V70, P596, DOI 10.1016/j.urology.2007.04.004
   Stephan C, 2013, CLIN CHEM, V59, P306, DOI 10.1373/clinchem.2012.195784
   Stephan C, 2010, INT J UROL, V17, P62, DOI 10.1111/j.1442-2042.2009.02417.x
   Stephan C, 2009, PROSTATE, V69, P198, DOI 10.1002/pros.20872
   SUCEVIC D, 1991, 6TH MEDITERRANEAN ELECTROTECHNICAL CONFERENCE, V0, P741, DOI 10.1109/MELCON.1991.161944
   Sun Chi-Cheng, 2006, AMIA ANNU SYMP PROC, V0, P1113
   Tanthanuch Monthira, 2004, JOURNAL OF THE MEDICAL ASSOCIATION OF THAILAND, V87, P515
   Tewari A, 1998, J UROLOGY, V160, P430, DOI 10.1016/S0022-5347(01)62916-1
   Tewari A, 2001, MOL UROL, V5, P163, DOI 10.1089/10915360152745849
   Torshizi AD, 2014, COMPUT METH PROG BIO, V113, P301, DOI 10.1016/j.cmpb.2013.09.021
   Tsao CW, 2014, J CHIN MED ASSOC, V77, P513, DOI 10.1016/j.jcma.2014.06.014
   Turing AM, 1950, MIND, V49, P433, DOI 10.1093/MIND/LIX.236.433
   Veltri RW, 2002, CLIN CHEM, V48, P1828
   VOLMER M, 1994, CLIN CHEM, V40, P1692
   von der Maase H, 2005, J CLIN ONCOL, V23, P4602, DOI 10.1200/JCO.2005.07.757
   Vukicevic AM, 2014, EXPERT SYST APPL, V41, P8092, DOI 10.1016/j.eswa.2014.07.006
   Herr HW, 2007, J UROLOGY, V177, P437, DOI 10.1016/j.juro.2006.09.027
   Wadie BS, 2006, UROLOGY, V68, P1211, DOI 10.1016/j.urology.2006.08.1079
   Wadie BS, 2001, J UROLOGY, V165, P35, DOI 10.1097/00005392-200101000-00009
   Wang GJ, 2015, COMPUT BIOL MED, V63, P124, DOI 10.1016/j.compbiomed.2015.05.015
   Wells DM, 1998, INT J RADIAT ONCOL, V41, P173, DOI 10.1016/S0360-3016(98)00035-2
   Xiao D, 2016, INT J COMPUT ASS RAD, V11, P89, DOI 10.1007/s11548-015-1234-x
   Yuksel S, 2013, J INEQUAL APPL, V0, P0, DOI DOI 10.1186/1029-242X-2013-229
   Zlotta AR, 2003, J UROLOGY, V169, P1724, DOI 10.1097/01.ju.0000062548.28015.f6
NR 167
TC 5
Z9 5
U1 1
U2 7
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 
EI 1472-6947
J9 BMC MED INFORM DECIS
JI BMC Med. Inform. Decis. Mak.
PD JUL 22
PY 2021
VL 21
IS 1
BP 
EP 
DI 10.1186/s12911-021-01585-9
PG 36
WC Medical Informatics
SC Medical Informatics
GA TR3HM
UT WOS:000678859800001
PM 34294092
DA 2023-04-26
ER

PT J
AU Park, SH
   Jung, HS
   Lee, S
   Kim, ES
AF Park, Sung-Hwan
   Jung, Hyung-Sup
   Lee, Sunmin
   Kim, Eun-Sook
TI Mapping Forest Vertical Structure in Sogwang-ri Forest from Full-Waveform Lidar Point Clouds Using Deep Neural Network
SO REMOTE SENSING
LA English
DT Article
DE forest vertical structure; full-waveform LiDAR; deep neural network; deep learning; forest genetic resource reserve
ID small-footprint discrete; airborne lidar; aboveground biomass; diversity; management; height; return; cover; urban
AB The role of forests is increasing because of rapid land use changes worldwide that have implications on ecosystems and the carbon cycle. Therefore, it is necessary to obtain accurate information about forests and build forest inventories. However, it is difficult to assess the internal structure of the forest through 2D remote sensing techniques and fieldwork. In this aspect, we proposed a method for estimating the vertical structure of forests based on full-waveform light detection and ranging (FW LiDAR) data in this study. Voxel-based tree point density maps were generated by estimating the number of canopy height points in each voxel grid from the raster digital terrain model (DTM) and canopy height points after pre-processing the LiDAR point clouds. We applied an unsupervised classification algorithm to the voxel-based tree point density maps and identified seven classes by profile pattern analysis for the forest vertical types. The classification accuracy was found to be 72.73% from the validation from 11 field investigation sites, which was additionally confirmed through comparative analysis with aerial images. Based on this pre-classification reference map, which is assumed to be ground truths, the deep neural network (DNN) model was finally applied to perform the final classification. As a result of accuracy assessment, it showed accuracy of 92.72% with a good performance. These results demonstrate the potential of vertical structure estimation for extensive forests using FW LiDAR data and that the distinction between one-storied and two-storied forests can be clearly represented. This technique is expected to contribute to efficient and effective management of forests based on accurate information derived from the proposed method.
C1 [Park, Sung-Hwan] Korea Inst Ocean Sci & Technol, Marine Disaster Res Ctr, Busan 49111, South Korea.
   [Park, Sung-Hwan; Jung, Hyung-Sup; Lee, Sunmin] Univ Seoul, Dept Geoinformat, Seoul 02504, South Korea.
   [Jung, Hyung-Sup] Univ Seoul, Dept Smart Cities, Seoul 02504, South Korea.
   [Lee, Sunmin] Korea Environm Inst KEI, Ctr Environm Assessment Monitoring, Sejong Si 30147, South Korea.
   [Kim, Eun-Sook] Natl Inst Forest Sci, Div Forest Ecol, Seoul 02455, South Korea.
C3 Korea Institute of Ocean Science & Technology (KIOST); University of Seoul; University of Seoul; Korea Environment Institute (KEI); Korea Forest Research Institute (KFRI); National Institute of Forest Science (NIFOS), Republic of South Korea
RP Lee, S (corresponding author), Univ Seoul, Dept Geoinformat, Seoul 02504, South Korea.; Lee, S (corresponding author), Korea Environm Inst KEI, Ctr Environm Assessment Monitoring, Sejong Si 30147, South Korea.
EM spark@kiost.ac.kr; hsjung@uos.ac.kr; smilee@kei.re.kr; drummer12@korea.kr
FU National Research Foundation of Korea - Korea government [NRF-2018M1A3A3A02066008]; National Research Foundation of Korea [2021-027(R), NRF-2018R1D1A1B07041203]; National Institute of Forest Science, Republic of Korea [FE0100-2019-05]
CR Anderson H.W., 1976, FORESTS WATER EFFECT, VVolume 18, P0
   [Anonymous], 2006, REMOTE SENSING DIGIT, V0, P0
   Bergen KM, 2009, J GEOPHYS RES-BIOGEO, V114, P0, DOI 10.1029/2008JG000883
   Bonan GB, 2008, SCIENCE, V320, P1444, DOI 10.1126/science.1155121
   Cao L, 2014, REMOTE SENS-BASEL, V6, P7110, DOI 10.3390/rs6087110
   DENNISON WC, 1993, BIOSCIENCE, V43, P86, DOI 10.2307/1311969
   Dieler J, 2017, EUR J FOREST RES, V136, P739, DOI 10.1007/s10342-017-1056-1
   Dubayah RO, 2000, J FOREST, V98, P44
   Garden JG, 2007, AUSTRAL ECOL, V32, P669, DOI 10.1111/j.1442-9993.2007.01750.x
   Gardner TA, 2009, ECOL LETT, V12, P561, DOI 10.1111/j.1461-0248.2009.01294.x
   Gaulton R, 2010, INT J REMOTE SENS, V31, P1193, DOI 10.1080/01431160903380565
   Gibbs HK, 2007, ENVIRON RES LETT, V2, P0, DOI 10.1088/1748-9326/2/4/045023
   Goodwin NR, 2006, REMOTE SENS ENVIRON, V103, P140, DOI 10.1016/j.rse.2006.03.003
   Hamdi ZM, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11171976
   Heinzel J, 2011, INT J APPL EARTH OBS, V13, P152, DOI 10.1016/j.jag.2010.09.010
   HOEN HF, 1994, FOREST SCI, V40, P429
   Kim HakYun, 2017, KOREAN JOURNAL OF ENVIRONMENT AND ECOLOGY, V31, P188, DOI 10.13047/kjee.2017.31.2.188
   Kim Jaebeom, 2017, KOREAN JOURNAL OF AGRICULTURAL AND FOREST METEOROLOGY 한국농림기상학회지, V19, P10, DOI 10.5532/KJAFM.2017.19.1.10
   Korea Forest Service, 2015, FOR BAS STAT, V0, P0
   Lee YS, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050797
   Lee YS, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10051666
   Leitold Veronika, 2015, CARBON BALANCE MANAG, V10, P3
   Liao WZ, 2018, IEEE ACCESS, V6, P68716, DOI 10.1109/ACCESS.2018.2880083
   Lillicrap TP, 2020, NAT REV NEUROSCI, V21, P335, DOI 10.1038/s41583-020-0277-3
   Lim K, 2003, PROG PHYS GEOG, V27, P88, DOI 10.1191/0309133303pp360ra
   Lu DS, 2016, INT J DIGIT EARTH, V9, P63, DOI 10.1080/17538947.2014.990526
   Lv Q, 2014, INT GEOSCI REMOTE SE, V0, P0, DOI DOI 10.1109/IGARSS.2014.6947537
   Narine LL, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121503
   Nie S, 2017, ECOL INDIC, V78, P221, DOI 10.1016/j.ecolind.2017.02.045
   Popescu SC, 2008, REMOTE SENS ENVIRON, V112, P767, DOI 10.1016/j.rse.2007.06.011
   Referowska-Chodak E, 2019, FORESTS, V10, P0, DOI 10.3390/f10090765
   Ruiz-Jaen MC, 2005, RESTOR ECOL, V13, P569, DOI 10.1111/j.1526-100X.2005.00072.x
   Saldana A, 2014, PLANT SPEC BIOL, V29, P253, DOI 10.1111/1442-1984.12020
   Segura M, 2005, BIOTROPICA, V37, P2, DOI 10.1111/j.1744-7429.2005.02027.x
   Seidel D, 2011, ANN FOREST SCI, V68, P225, DOI 10.1007/s13595-011-0040-z
   Sumnall MJ, 2016, REMOTE SENS ENVIRON, V173, P214, DOI 10.1016/j.rse.2015.07.027
   Sun JM, 2018, J HYDROL, V561, P187, DOI 10.1016/j.jhydrol.2018.04.003
   Terrasolid, 2004, TERRASCAN USERS GUID, V0, P0
   Tews J, 2004, J BIOGEOGR, V31, P79, DOI 10.1046/j.0305-0270.2003.00994.x
   Wagner FH, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142225
   Wang YS, 2008, SENSORS-BASEL, V8, P3938, DOI 10.3390/s8063938
   Wing BM, 2012, REMOTE SENS ENVIRON, V124, P730, DOI 10.1016/j.rse.2012.06.024
   Wulder MA, 2012, REMOTE SENS ENVIRON, V121, P196, DOI 10.1016/j.rse.2012.02.001
   Zimble DA, 2003, REMOTE SENS ENVIRON, V87, P171, DOI 10.1016/S0034-4257(03)00139-1
NR 44
TC 1
Z9 1
U1 2
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP 15
PY 2021
VL 13
IS 18
BP 
EP 
DI 10.3390/rs13183736
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA UY4ER
UT WOS:000701479400001
DA 2023-04-26
ER

PT J
AU Gupta, J
   Molnar, C
   Xie, YQ
   Knight, J
   Shekhar, S
AF Gupta, Jayant
   Molnar, Carl
   Xie, Yiqun
   Knight, Joe
   Shekhar, Shashi
TI Spatial Variability Aware Deep Neural Networks (SVANN): A General Approach
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE Neural networks; spatial variability
AB Spatial variability is a prominent feature of various geographic phenomena such as climatic zones, USDA plant hardiness zones, and terrestrial habitat types (e.g., forest, grasslands, wetlands, and deserts). However, current deep learning methods follow a spatial-one-size-fits-all (OSFA) approach to train single deep neural network models that do not account for spatial variability. Quantification of spatial variability can be challenging due to the influence of many geophysical factors. In preliminary work, we proposed a spatial variability aware neural network (SVANN-I, formerly called SVANN) approach where weights are a function of location but the neural network architecture is location independent. In this work, we explore a more flexible SVANNE approach where neural network architecture varies across geographic locations. In addition, we provide a taxonomy of SVANN types and a physics inspired interpretation model. Experiments with aerial imagery based wetland mapping show that SVANN-I outperforms OSFA and SVANN-E performs the best of all.
C1 [Gupta, Jayant; Molnar, Carl; Shekhar, Shashi] Univ Minnesota, Dept Comp Sci & Engn, 4-192 Keller Hall,200 Union St SE, Minneapolis, MN 55455 USA.
   [Xie, Yiqun] Univ Maryland, Ctr Geospatial Informat Sci, Dept Geog Sci, 1124 Lefrak Hall,7251 Preinkert Dr, College Pk, MD 20742 USA.
   [Knight, Joe] Univ Minnesota, Dept Forest Resources, 1530 Cleveland Ave N, St Paul, MN 55108 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities; University System of Maryland; University of Maryland College Park; University of Minnesota System; University of Minnesota Twin Cities
RP Gupta, J (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, 4-192 Keller Hall,200 Union St SE, Minneapolis, MN 55455 USA.
EM gupta423@umn.edu; molna018@umn.edu; xie@umd.edu; jknight@umn.edu; shekhar@umn.edu
FU National nce Foundation [1737633]
CR [Anonymous], 2015, ICLR, V0, P0
   [Anonymous], 2010, WETLAND ECOLOGY PRIN, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Conant RT, 2003, J ENVIRON QUAL, V32, P278, DOI 10.2134/jeq2003.0278
   Cowardin LM, 1979, CLASSIFICATION WETLA, V0, P0
   Cybenko G., 1989, MATHEMATICS OF CONTROL, V0, P0
   ENGLAND WL, 1988, MED DECIS MAKING, V8, P120, DOI 10.1177/0272989X8800800208
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Freund Y., 1996, MACHINE LEARNING. PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE (ICML 96), V0, P148
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Gupta Jayant, 2020, P WORKSH DEEP LEARN, V0, P0
   Heindl A, 2015, LAB INVEST, V95, P377, DOI 10.1038/labinvest.2014.155
   Iglovikov V., 2018, TERNAUSNET U NET VGG, V0, P0
   Jiang Z, 2019, ACM T INTEL SYST TEC, V10, P0, DOI 10.1145/3337798
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kloiber SM, 2015, WETLANDS, V35, P335, DOI 10.1007/s13157-014-0621-3
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V0, PP1097, DOI 10.2165/00129785-200404040-00005
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lee S., 2019, EARTH RESOUR ENV REM, V11156, P313
   Leitner M., 2018, OXFORD RES ENCY CRIM, V0, PP1, DOI 10.1093/acrefore/9780190264079.013.325
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Norvig P., 2016, ARTIF INTELL, V0, P0
   Nusser SM, 1997, ENVIRON ECOL STAT, V4, P181, DOI 10.1023/A:1018574412308
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Shekhar S., 2012, P 11 ACM INT WORKSH, V0, PP1, DOI 10.1145/2258056.2258058
   Silvertown J, 2009, TRENDS ECOL EVOL, V24, P467, DOI 10.1016/j.tree.2009.03.017
   Sitterson J, 2018, P IEMSS 2018 9 INT C, V0, P0
   Stewart Fotheringham A., 2003, GEOGRAPHICALLYWEIGHT, V0, P0
   Szegedy C, 2015, PROC CVPR IEEE, V0, PP1, DOI 10.1109/CVPR.2015.7298594
   TINER RW, 1990, FOREST ECOL MANAG, V33-4, P593, DOI 10.1016/0378-1127(90)90221-V
   Turner MG, 2005, ECOSYSTEM FUNCTION IN HETEROGENEOUS LANDSCAPES, V0, PP9, DOI 10.1007/0-387-24091-8_2
   U.S. Department of Agriculture, 2012, USDA PLANT HARD ZON, V0, P0
   U. S. Fish and Wildlife Service, 2020, NAT WETL INV SURF WA, V0, P0
   WAGNER CH, 1982, AM STAT, V36, P46, DOI 10.2307/2684093
   Xie YQ, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), V0, PP71, DOI 10.1145/3347146.3359066
   Xie YQ, 2020, INT J GEOGR INF SCI, V34, P777, DOI 10.1080/13658816.2019.1624761
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 42
TC 2
Z9 2
U1 1
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2157-6904
EI 2157-6912
J9 ACM T INTEL SYST TEC
JI ACM Trans. Intell. Syst. Technol.
PD NOV 15
PY 2021
VL 12
IS 6
BP 
EP 
DI 10.1145/3466688
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information Systems
SC Computer Science
GA YY1AN
UT WOS:000754524700009
DA 2023-04-26
ER

PT J
AU Zang, YF
   Meng, FC
   Lindenbergh, R
   Truong-Hong, L
   Li, BJ
AF Zang, Yufu
   Meng, Fancong
   Lindenbergh, Roderik
   Truong-Hong, Linh
   Li, Bijun
TI Deep Localization of Static Scans in Mobile Mapping Point Clouds
SO REMOTE SENSING
LA English
DT Article
DE point cloud localization; mobile laser scanning; terrestrial laser scanning; place recognition; pose refinement
ID terrestrial; registration; airborne
AB Mobile laser scanning (MLS) systems are often used to efficiently acquire reference data covering a large-scale scene. The terrestrial laser scanner (TLS) can easily collect high point density data of local scene. Localization of static TLS scans in mobile mapping point clouds can afford detailed geographic information for many specific tasks especially in autonomous driving and robotics. However, large-scale MLS reference data often have a huge amount of data and many similar scene data; significant differences may exist between MLS and TLS data. To overcome these challenges, this paper presents a novel deep neural network-based localization method in urban environment, divided by place recognition and pose refinement. Firstly, simple, reliable primitives, cylinder-like features were extracted to describe the global features of a local urban scene. Then, a probabilistic framework is applied to estimate a similarity between TLS and MLS data, under a stable decision-making strategy. Based on the results of a place recognition, we design a patch-based convolution neural network (CNN) (point-based CNN is used as kernel) for pose refinement. The input data unit is the batch consisting of several patches. One patch goes through three main blocks: feature extraction block (FEB), the patch correspondence search block and the pose estimation block. Finally, a global refinement was proposed to tune the predicted transformation parameters to realize localization. The research aim is to find the most similar scene of MLS reference data compared with the local TLS scan, and accurately estimate the transformation matrix between them. To evaluate the performance, comprehensive experiments were carried out. The experiments demonstrate that the proposed method has good performance in terms of efficiency, i.e., the runtime of processing a million points is 5 s, robustness, i.e., the success rate of place recognition is 100% in the experiments, accuracy, i.e., the mean rotation and translation error is (0.24 deg, 0.88 m) and (0.03 deg, 0.06 m) on TU Delft campus and Shanghai urban datasets, respectively, and outperformed some commonly used methods (e.g., iterative closest point (ICP), coherent point drift (CPD), random sample consensus (RANSAC)-based method).
C1 [Zang, Yufu] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
   [Zang, Yufu; Meng, Fancong; Lindenbergh, Roderik; Truong-Hong, Linh] Delft Univ Technol, Dept Geosci & Remote Sensing, Stevinweg 1, NL-2628 CN Delft, Netherlands.
   [Li, Bijun] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 Nanjing University of Information Science & Technology; Delft University of Technology; Wuhan University
RP Meng, FC (corresponding author), Delft Univ Technol, Dept Geosci & Remote Sensing, Stevinweg 1, NL-2628 CN Delft, Netherlands.
EM 3dmapzangyufu@nuist.edu.cn; Meng@student.tudelft.nl; R.C.Lindenbergh@tudelft.nl; L.Truong@tudelft.nl; lee@whu.edu.cn
FU National Science Foundation of China project [41701529]; OpenFund of State Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University [18S02]
CR Aissou B., 2020, PROC INT ARCHIV PHOT, V0, P191
   [Anonymous], 2008, REMOTE SENS SPATIAL, V0, P0
   Aoki Y, 2019, PROC CVPR IEEE, V0, PP7156, DOI 10.1109/CVPR.2019.00733
   Avidar D, 2017, IEEE I CONF COMP VIS, V0, PP891, DOI 10.1109/ICCV.2017.102
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cai ZP, 2019, ISPRS J PHOTOGRAMM, V147, P118, DOI 10.1016/j.isprsjprs.2018.11.016
   Che EZ, 2019, SENSORS-BASEL, V19, P0, DOI 10.3390/s19040810
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Cheng L, 2018, SENSORS-BASEL, V18, P0, DOI 10.3390/s18051641
   Cheng L, 2013, REMOTE SENS-BASEL, V5, P6260, DOI 10.3390/rs5126260
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Dong JM, 2014, NEUROCOMPUTING, V140, P67, DOI 10.1016/j.neucom.2014.03.035
   Drawil NM, 2013, IEEE T INTELL TRANSP, V14, P262, DOI 10.1109/TITS.2012.2213815
   Elbaz G, 2017, PROC CVPR IEEE, V0, PP2472, DOI 10.1109/CVPR.2017.265
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hauglin M, 2014, INT J REMOTE SENS, V35, P3135, DOI 10.1080/01431161.2014.903440
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Ji XG, 2021, MULTIMED TOOLS APPL, V80, P4553, DOI 10.1007/s11042-020-09910-6
   Kanai S., 2019, INT ARCH PHOTOGRAMM, V0, PP963, DOI 10.5194/isprs-archives-XLII-2-W13-963-2019
   Koguciuk D, 2017, FOUND COMPUT DECIS S, V42, P203, DOI 10.1515/fcds-2017-0010
   Koren M, 2017, INT J APPL EARTH OBS, V63, P122, DOI 10.1016/j.jag.2017.07.015
   Kurobe A, 2020, IEEE ROBOT AUTOM LET, V5, P3960, DOI 10.1109/LRA.2020.2970946
   Landsiedel C, 2017, INT J INTELL ROBOT, V1, P429, DOI 10.1007/s41315-017-0038-2
   Li XY, 2020, SENSORS-BASEL, V20, P0, DOI 10.3390/s20010237
   Liang FX, 2020, ISPRS J PHOTOGRAMM, V165, P120, DOI 10.1016/j.isprsjprs.2020.04.018
   Lu WX, 2019, IEEE I CONF COMP VIS, V0, PP12, DOI 10.1109/ICCV.2019.00010
   Makovetskii A, 2017, PROC SPIE, V10396, P0, DOI 10.1117/12.2273604
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nagy B., 2018, P EUROPEAN C COMPUTE, V0, P0
   Pais GD, 2020, PROC CVPR IEEE, V0, PP7191, DOI 10.1109/CVPR42600.2020.00722
   Poux F., 2020, INT ARCH PHOTOGRAMME, V43, P309, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2020-309-2020
   Qi C. R., 2017, ADV NEURAL INFORM PR, V0, P5099
   Sarode V, 2019, IEEE INT C COMP VIS, V0, P0
   Segal A., 2009, GENERALIZED ICP ROBO, V0, P435
   Sorkine-Hornung O, 2017, COMPUTING, V1, P1
   Uy MA, 2018, PROC CVPR IEEE, V0, PP4470, DOI 10.1109/CVPR.2018.00470
   Vivacqua R, 2017, SENSORS-BASEL, V17, P0, DOI 10.3390/s17102359
   Wong R., 2019, P IOP C SER MAT SCI, V705, P012004
   Wu HB, 2014, J APPL REMOTE SENS, V8, P0, DOI 10.1117/1.JRS.8.083587
   Yang BS, 2016, ISPRS J PHOTOGRAMM, V119, P373, DOI 10.1016/j.isprsjprs.2016.07.002
   Yang BS, 2015, ISPRS J PHOTOGRAMM, V109, P62, DOI 10.1016/j.isprsjprs.2015.08.006
   Yin H, 2018, IEEE INT VEH SYM, V0, P728
NR 42
TC 1
Z9 1
U1 1
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN 15
PY 2021
VL 13
IS 2
BP 
EP 
DI 10.3390/rs13020219
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA PX7QX
UT WOS:000611550100001
DA 2023-04-26
ER

PT J
AU Wen, CC
   Li, X
   Yao, XJ
   Peng, L
   Chi, TH
AF Wen, Congcong
   Li, Xiang
   Yao, Xiaojing
   Peng, Ling
   Chi, Tianhe
TI Airborne LiDAR point cloud classification with global-local graph attention convolution neural network
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Airborne LiDAR; Point cloud classification; Point cloud deep learning; Graph attention convolution; ISPRS 3D labeling
ID line
AB Airborne light detection and ranging (LiDAR) plays an increasingly significant role in urban planning, topographic mapping, environmental monitoring, power line detection and other fields thanks to its capability to quickly acquire large-scale and high-precision ground information. To achieve point cloud classification, previous studies proposed point cloud deep learning models that can directly process raw point clouds based on PointNet-like architectures. And some recent works proposed graph convolution neural network based on the inherent topology of point clouds. However, the above point cloud deep learning models only pay attention to exploring local geometric structures, yet ignore global contextual relationships among all points. In this paper, we present a global-local graph attention convolution neural network (GACNN) that can be directly applied to the classification of unstructured 3D point clouds obtained by airborne LiDAR. Specifically, we first introduce a graph attention convolution module that incorporates global contextual information and local structural features. The global attention module examines spatial relationships among all points, while the local attention module can dynamically learn convolution weights with regard to the spatial position of the local neighboring points and reweight the convolution weights by inspecting the density of each local region. Based on the proposed graph attention convolution module, we further design an end-to-end encoder-decoder network, named GACNN, to capture multiscale features of the point clouds and therefore enable more accurate airborne point cloud classification. Experiments on the ISPRS 3D labeling dataset show that the proposed model achieves a new state-of-the-art performance in terms of average F1 score (71.5%) and a satisfying overall accuracy (83.2%). Additionally, experiments further conducted on the 2019 Data Fusion Contest Dataset by comparing with other prevalent point cloud deep learning models demonstrate the favorable generalization capability of the proposed model.
C1 [Wen, Congcong; Yao, Xiaojing; Peng, Ling; Chi, Tianhe] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
   [Wen, Congcong] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wen, Congcong; Li, Xiang] NYU, Tandon Sch Engn, New York, NY USA.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; New York University; New York University Tandon School of Engineering
RP Peng, L (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
EM plqiqi@126.com
FU Beijing Municipal Science and Technology Project [Z191100001419002]; program of China Scholarship Council [201904910848]
CR [Anonymous], 2000, INT ARCH PHOTOGRAMME, V0, P0
   [Anonymous], 2009, ISPRS ARCH PHOTOGRAM, V0, P0
   Arief H.A., 2019, ARXIV PREPRINT ARXIV, V0, P0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Blomley R., 2016, 3D SEMANTIC LABELING, V0, P0
   Bradbury RB, 2005, IBIS, V147, P443, DOI 10.1111/j.1474-919x.2005.00438.x
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen Charles, 2019, ARXIV PREPRINT ARXIV, V0, P0
   Chen Q, 2007, PHOTOGRAMM ENG REM S, V73, P109
   Collobert R., 2008, P 25 INT C MACHINE L, V0, P0
   Cramer M, 2010, PHOTOGRAMM FERNERKUN, V0, PP73, DOI 10.1127/1432-8364/2010/0041
   Dai A, 2017, PROC CVPR IEEE, V0, PP6545, DOI 10.1109/CVPR.2017.693
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, V0, P1
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horvat D, 2016, ISPRS J PHOTOGRAMM, V116, P1, DOI 10.1016/j.isprsjprs.2016.02.011
   Huang CQ, 2014, REMOTE SENS ENVIRON, V141, P231, DOI 10.1016/j.rse.2013.10.020
   Jiang M, 2018, ARXIV PREPRINT ARXIV, V0, P0
   KRABILL WB, 1984, PHOTOGRAMM ENG REM S, V50, P685
   Li YY, 2018, ADV NEUR IN, V31, P0
   Liu XY, 2008, PROG PHYS GEOG, V32, P31, DOI 10.1177/0309133308089496
   Lodha SK, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, V0, P435
   Maturana D, 2015, IEEE INT C INT ROBOT, V0, PP922, DOI 10.1109/IROS.2015.7353481
   Munoz D, 2009, PROC CVPR IEEE, V0, PP975, DOI 10.1109/CVPRW.2009.5206590
   Niemeyer J, 2016, INT ARCH PHOTOGRAMM, V41, P655, DOI 10.5194/isprsarchives-XLI-B3-655-2016
   Niemeyer J, 2012, ISPRS ANN PHOTOGRAMM, V1, P263, DOI 10.5194/ISPRSANNALS-I-3-263-2012
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Niemeyer J, 2011, LECT NOTES COMPUT SC, V6952, P233, DOI 10.1007/978-3-642-24393-6_20
   Qi C.R., 2017, ADV NEUR IN, V0, P5099
   Shapovalov R., 2010, INT ARCH PHOTOGRAMME, VXXXVIII, P0
   Te GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM18), V0, PP746, DOI 10.1145/3240508.3240621
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang L, 2019, PROC CVPR IEEE, V0, PP10288, DOI 10.1109/CVPR.2019.01054
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Wang Z, 2018, IEEE T GEOSCI REMOTE, V56, P4594, DOI 10.1109/TGRS.2018.2829625
   Wen CC, 2020, ISPRS J PHOTOGRAMM, V162, P50, DOI 10.1016/j.isprsjprs.2020.02.004
   Wen CC, 2019, SCI TOTAL ENVIRON, V654, P1091, DOI 10.1016/j.scitotenv.2018.11.086
   Yang Z., 2017, REMOTE SENS-BASEL, V9, P0
   Yang Z., 2018, SENSORS-BASEL, V18, P0
   Yousefhussien M, 2017, ARXIV PREPRINT ARXIV, V0, P0
   Yousefhussien M, 2018, ISPRS J PHOTOGRAMM, V143, P191, DOI 10.1016/j.isprsjprs.2018.03.018
   Yu BL, 2010, LANDSCAPE URBAN PLAN, V98, P210, DOI 10.1016/j.landurbplan.2010.08.004
   Zhang JX, 2013, REMOTE SENS-BASEL, V5, P3749, DOI 10.3390/rs5083749
   Zhao RB, 2018, INT J GEOGR INF SCI, V32, P960, DOI 10.1080/13658816.2018.1431840
   Zhu LL, 2014, REMOTE SENS-BASEL, V6, P11267, DOI 10.3390/rs61111267
NR 45
TC 36
Z9 38
U1 12
U2 86
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAR 15
PY 2021
VL 173
IS 
BP 181
EP 194
DI 10.1016/j.isprsjprs.2021.01.007
EA JAN 2021
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO3ZZ
UT WOS:000640986100012
DA 2023-04-26
ER
