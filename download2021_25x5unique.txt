
PT J
AU Aroonsri, I
   Sangpradid, S
AF Aroonsri, Ilada
   Sangpradid, Satith
TI ARTIFICIAL NEURAL NETWORKS FOR THE CLASSIFICATION OF SHRIMP FARM FROM SATELLITE IMAGERY
SO GEOGRAPHIA TECHNICA
LA English
DT Article
DE Key- Sentinel-2 imagery; Supervise classification; Land use change detection; artificial neural networks (ANN)
ID sentinel-2
AB Shrimp production was the high demand for the popular in the global market in Thailand. The change of land use is important for the management and monitoring of land use changed. The objectives of this paper to (1) classification of shrimp farm using artificial neural networks (ANN) technique from the Sentinel-2 imagery. (2) change detection of land use changes map among 2015, 2018, and 2020. The land use classification based on ANN technique and the accuracy assessment by used the confusion matrices and kappa coefficient. The classify of land use classes divide into built-up, forest, water bodies, paddy field, shrimp farm, and field crop. The change detection methods used was the image differencing technique was performed to the land use changes map. The result of land use classification show that the field crop area was 80% cover the most area. The result of land use changed show that built-up, paddy field, and shrimp farm increased throughout between year 2015 to 2020. The shrimp farm between year 2015 to 2020 to increasing trend of related with the shrimp production was the high demand for the popular in the global market.
C1 [Aroonsri, Ilada] Valaya Alongkorn Rajabhat Univ Royal Patronage, Fac Management Sceinces, Dept Business Digital, 1,Moo 10,Klong 1, Klongluang 13180, Pathum Thani, Thailand.
   [Sangpradid, Satith] Mahasarakham Univ, Fac Informat, Res Unit Geoinformat Local Dev, Maha Sarakham 44150, Thailand.
   [Sangpradid, Satith] Mahasarakham Univ, Fac Informat, Dept Geoinformat, Maha Sarakham 44150, Thailand.
C3 Valaya Alongkorn Rajabhat University; Mahasarakham University; Mahasarakham University
RP Aroonsri, I (corresponding author), Valaya Alongkorn Rajabhat Univ Royal Patronage, Fac Management Sceinces, Dept Business Digital, 1,Moo 10,Klong 1, Klongluang 13180, Pathum Thani, Thailand.
EM ilada@vru.ac.th; satith.s@msu.ac.th
FU Faculty of Informatics, Mahasarakham University; Research unit of Geo-informatics for Local Development; Faculty of Management Sciences, Valaya Alongkorn Rajabhat University Under the Royal Patronage
CR Ahmad A, 2013, APPL MATH SCI, V7, P3681, DOI 10.12988/AMS.2013.34214
   Alonso-Perez F, 2003, OCEAN COAST MANAGE, V46, P583, DOI 10.1016/S0964-5691(03)00036-X
   Costantino D, 2020, GEOGR TECH, V15, P171, DOI 10.21163/GT_2020.152.17
   Dorber M, 2020, REMOTE SENS APPL, V20, P0, DOI 10.1016/j.rsase.2020.100416
   Erbek FS, 2004, INT J REMOTE SENS, V25, P1733, DOI 10.1080/0143116031000150077
   FOODY GM, 1995, PHOTOGRAMM ENG REM S, V61, P391
   Ge GBT, 2020, GLOB ECOL CONSERV, V22, P0, DOI 10.1016/j.gecco.2020.e00971
   Jomsrekrayom N, 2021, GEOGR TECH, V16, P70, DOI 10.21163/GT_2021.163.06
   Kovacs KD, 2019, GEOGR TECH, V14, P20, DOI 10.21163/GT_2019.142.03
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Mahmon NA, 2014, 2014 IEEE 5TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), V0, PP153, DOI 10.1109/ICSGRC.2014.6908713
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Maung WS, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13010052
   Migas-Mazur R, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13163314
   Ottinger M, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9050440
   Panuju DR, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111781
   Pradabmook P., 2021, ARPN J ENG APPL SCI, V16, P823
   Punalekar SM, 2021, AGRONOMY-BASEL, V11, P0, DOI 10.3390/agronomy11081661
   Rajitha K, 2007, AQUACULT ENG, V36, P1, DOI 10.1016/j.aquaeng.2006.05.003
   Sangpradid S., 2018, INT J GEOINFORMATICS, V14, P71
   Santaga FS, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13173379
   Shrestha S., 2012, 1 SENT 2 PREP S FRAS, V0, P0
   Stiller D, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11141707
   Thai Shrimp Association, 2019, SHRIMP SIT THAIL 202, V0, P0
   Toosi NB, 2019, GLOB ECOL CONSERV, V19, P0, DOI 10.1016/j.gecco.2019.e00662
   Toshniwal M., 2005, 3 INT C SCI EL TECHN, V0, P0
   Urban M, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13173342
   Vanderhoof M.K., 1900, V4, V0, P52
   Varghese D, 2021, REMOTE SENS-BASEL, V13, P0, DOI 10.3390/rs13173355
   Xiong Y., 2010, INT C COMP APPL SYST, V0, P52
   Yaday P., 2010, INT J REMOTE SENSING, V1, P90
NR 32
TC 0
Z9 0
U1 1
U2 2
PU CLUJ UNIV PRESS
PI CLUJ NAPOCA
PA STRADA B P HASDEU NR 51, CLUJ NAPOCA, 400371, ROMANIA
SN 1842-5135
EI 2065-4421
J9 GEOGR TECH
JI Geogr. Tech.
PD OCT 15
PY 2021
VL 16
IS 2
BP 149
EP 159
DI 10.21163/GT_2021.162.12
PG 11
WC Geography, Physical
SC Physical Geography
GA WL7WI
UT WOS:000710611000012
DA 2023-04-26
ER

PT J
AU Xiao, AR
   Yang, XF
   Lu, SJ
   Guan, DY
   Huang, JX
AF Xiao, Aoran
   Yang, Xiaofei
   Lu, Shijian
   Guan, Dayan
   Huang, Jiaxing
TI FPS-Net: A convolutional fusion network for large-scale LiDAR point cloud segmentation
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE LiDAR; Point cloud; Semantic segmentation; Spherical projection; Autonomous driving; Scene understanding
ID deep neural-networks; semantic segmentation; classification
AB Scene understanding based on LiDAR point cloud is an essential task for autonomous cars to drive safely, which often employs spherical projection to map 3D point cloud into multi-channel 2D images for semantic segmentation. Most existing methods simply stack different point attributes/modalities (e.g. coordinates, intensity, depth, etc.) as image channels to increase information capacity, but ignore distinct characteristics of point attributes in different image channels. We design FPS-Net, a convolutional fusion network that exploits the uniqueness and discrepancy among the projected image channels for optimal point cloud segmentation. FPS-Net adopts an encoder-decoder structure. Instead of simply stacking multiple channel images as a single input, we group them into different modalities to first learn modality-specific features separately and then map the learnt features into a common high-dimensional feature space for pixel-level fusion and learning. Specifically, we design a residual dense block with multiple receptive fields as a building block in encoder which preserves detailed information in each modality and learns hierarchical modality-specific and fused features effectively. In the FPS-Net decoder, we use a recurrent convolution block likewise to hierarchically decode fused features into output space for pixel-level classification. Extensive experiments conducted on two widely adopted point cloud datasets show that FPS-Net achieves superior semantic segmentation as compared with state-of-the-art projection-based methods. Specifically, FPS-Net outperforms the state-of-the-art in both accuracy (4.9% higher than RangeNet++ and 2.8% higher than PolarNet in mIoU) and computation speed (15.0 FPS faster than Squeeze-SegV3) for SemanticKITTI benchmark. For KITTI benchmark, FPS-Net achieves significant accuracy improvement (12.6% higher than RangeNet++ in mIoU) with comparable computation speed. In addition, the proposed modality fusion idea is compatible with typical projection-based methods and can be incorporated into them with consistent performance improvement.
C1 [Xiao, Aoran; Lu, Shijian; Guan, Dayan; Huang, Jiaxing] Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab Ente, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Yang, Xiaofei] Univ Macau, Ave Univ, Taipa 999078, Macau, Peoples R China.
C3 Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Macau
RP Lu, SJ (corresponding author), Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab Ente, 50 Nanyang Ave, Singapore 639798, Singapore.
EM aoran.xiao@ntu.edu.sg; yangxiaofei@um.edu.mo; Shijian.Lu@ntu.edu.sg; dayan.guan@ntu.edu.sg; jiaxing.huang@ntu.edu.sg
FU Singapore Government through the Industry Alignment Fund -Industry Collaboration Projects Grant
CR [Anonymous], 1900, DOI 10.1038/NATURE14539, V0, P0
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Behley J, 2019, IEEE I CONF COMP VIS, V0, PP9296, DOI 10.1109/ICCV.2019.00939
   Bendjebbour A, 2001, IEEE T GEOSCI REMOTE, V39, P1789, DOI 10.1109/36.942557
   Berman M, 2018, PROC CVPR IEEE, V0, PP4413, DOI 10.1109/CVPR.2018.00464
   Hua BS, 2018, PROC CVPR IEEE, V0, PP984, DOI 10.1109/CVPR.2018.00109
   Bugeau A, 2019, P IEEE INT C COMP VI, V0, P0
   Cao YP, 2019, ISPRS J PHOTOGRAMM, V150, P70, DOI 10.1016/j.isprsjprs.2019.02.005
   Cao YP, 2019, INFORM FUSION, V46, P206, DOI 10.1016/j.inffus.2018.06.005
   Choy C, 2019, PROC CVPR IEEE, V0, PP3070, DOI 10.1109/CVPR.2019.00319
   Dechesne C, 2017, ISPRS J PHOTOGRAMM, V126, P129, DOI 10.1016/j.isprsjprs.2017.02.011
   Geiger A, 2012, PROC CVPR IEEE, V0, PP3354, DOI 10.1109/CVPR.2012.6248074
   Ghamisi P, 2015, INT J IMAGE DATA FUS, V6, P189, DOI 10.1080/19479832.2015.1055833
   Guan DY, 2021, PATTERN RECOGN, V112, P0, DOI 10.1016/j.patcog.2020.107764
   Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017
   Gunes H, 2005, IEEE SYS MAN CYBERN, V0, P3437
   Guo B, 2015, ISPRS J PHOTOGRAMM, V100, P71, DOI 10.1016/j.isprsjprs.2014.04.015
   Guo L, 2011, ISPRS J PHOTOGRAMM, V66, P56, DOI 10.1016/j.isprsjprs.2010.08.007
   Hackel T, 2016, ISPRS ANN PHOTO REM, V3, P177, DOI 10.5194/isprsannals-III-3-177-2016
   Hu Q., 2020, P IEEECVF C COMPUTER, V0, PP11108, DOI 10.48550/ARXIV.1911.11236
   Huang J, 2016, INT C PATT RECOG, V0, PP2670, DOI 10.1109/ICPR.2016.7900038
   Iandola F.N., 2016, SQUEEZENET ALEXNET L, V0, P0
   Jiaxing Huang, 2020, COMPUTER VISION - ECCV 2020. 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12360), V0, PP705, DOI 10.1007/978-3-030-58555-6_42
   Kumar A., 1900, V4, V0, P0
   Landrieu L, 2018, PROC CVPR IEEE, V0, PP4558, DOI 10.1109/CVPR.2018.00479
   Landrieu L, 2017, ISPRS J PHOTOGRAMM, V132, P102, DOI 10.1016/j.isprsjprs.2017.08.010
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Lehtomaki M, 2016, IEEE T GEOSCI REMOTE, V54, P1226, DOI 10.1109/TGRS.2015.2476502
   Liao WZ, 2015, IEEE GEOSCI REMOTE S, V12, P552, DOI 10.1109/LGRS.2014.2350263
   Liu ZJ, 2019, ADV NEUR IN, V32, P0
   Meng HY, 2019, IEEE I CONF COMP VIS, V0, PP8499, DOI 10.1109/ICCV.2019.00859
   Milioto A, 2019, IEEE INT C INT ROBOT, V0, PP4213, DOI 10.1109/IROS40897.2019.8967762
   Ngiam J, 2011, ICML, V0, P0
   Niemeyer J, 2013, 2013 JOINT URBAN REMOTE SENSING EVENT (JURSE), V0, PP139, DOI 10.1109/JURSE#.2013.6550685
   Qi C.R., 2017, ADV NEUR IN, V0, P5099
   Qi CR, 2017, PROC CVPR IEEE, V0, PP77, DOI 10.1109/CVPR.2017.16
   Qi XJ, 2017, IEEE I CONF COMP VIS, V0, PP5209, DOI 10.1109/ICCV.2017.556
   Rasti B, 2017, IEEE T GEOSCI REMOTE, V55, P6354, DOI 10.1109/TGRS.2017.2726901
   Rasti B, 2017, IEEE T GEOSCI REMOTE, V55, P3997, DOI 10.1109/TGRS.2017.2686450
   Rethage D., 2018, ECCV, V0, P596
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi HY, 2020, PROC CVPR IEEE, V0, PP4573, DOI 10.1109/CVPR42600.2020.00463
   Simonovsky M, 2017, PROC CVPR IEEE, V0, PP29, DOI 10.1109/CVPR.2017.11
   Snoek C. G. M., 2005, 13TH ANNUAL ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, V0, PP399, DOI 10.1145/1101149.1101236
   Su H, 2018, PROC CVPR IEEE, V0, PP2530, DOI 10.1109/CVPR.2018.00268
   Sun RQ, 2019, PROC CVPR IEEE, V0, PP4355, DOI 10.1109/CVPR.2019.00449
   Sun Y, 2018, ISPRS J PHOTOGRAMM, V143, P3, DOI 10.1016/j.isprsjprs.2018.06.005
   Tatarchenko M, 2018, PROC CVPR IEEE, V0, PP3887, DOI 10.1109/CVPR.2018.00409
   Tchapmi LP, 2017, INT CONF 3D VISION, V0, PP537, DOI 10.1109/3DV.2017.00067
   Thomas H, 2019, IEEE I CONF COMP VIS, V0, PP6420, DOI 10.1109/ICCV.2019.00651
   Vaswani A, 2017, ADV NEUR IN, V30, P0
   Wang Y, 2019, ACM T GRAPHIC, V38, P0, DOI 10.1145/3326362
   Weinmann M., 2014, ISPRS ANN PHOTOGRAMM, VII-3, P181, DOI 10.5194/ISPRSANNALS-II-3-181-2014
   Wu BC, 2019, IEEE INT CONF ROBOT, V0, PP4376, DOI 10.1109/ICRA.2019.8793495
   Wu BC, 2018, IEEE INT CONF ROBOT, V0, P1887
   Xiang BB, 2019, IEEE T GEOSCI REMOTE, V57, P7799, DOI 10.1109/TGRS.2019.2916625
   Xu H, 2006, ACM T MULTIM COMPUT, V2, P44, DOI 10.1145/1126004.1126007
   Xu S, 2014, ISPRS J PHOTOGRAMM, V88, P1, DOI 10.1016/j.isprsjprs.2013.11.008
   Yang JC, 2019, PROC CVPR IEEE, V0, PP3318, DOI 10.1109/CVPR.2019.00344
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Zhang JX, 2013, REMOTE SENS-BASEL, V5, P3749, DOI 10.3390/rs5083749
   Zhang Y., 2020, P IEEE C COMP VIS PA, V0, P9601
   Zhang YL, 2018, PROC CVPR IEEE, V0, PP2472, DOI 10.1109/CVPR.2018.00262
   Zhang ZY, 2019, IEEE I CONF COMP VIS, V0, PP1607, DOI 10.1109/ICCV.2019.00169
   Zhao CX, 2019, IEEE IMAGE PROC, V0, PP1475, DOI 10.1109/ICIP.2019.8803048
   Zhao HS, 2019, PROC CVPR IEEE, V0, PP5550, DOI 10.1109/CVPR.2019.00571
   Zhou Y, 2012, INT J ADV ROBOT SYST, V9, P0, DOI 10.5772/54715
NR 77
TC 12
Z9 12
U1 12
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUN 15
PY 2021
VL 176
IS 
BP 237
EP 249
DI 10.1016/j.isprsjprs.2021.04.011
EA MAY 2021
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA SJ4AV
UT WOS:000655474600018
DA 2023-04-26
ER

PT J
AU Rodrigues, PM
   Bispo, BC
   Garrett, C
   Alves, D
   Teixeira, JP
   Freitas, D
AF Rodrigues, Pedro M.
   Bispo, Bruno C.
   Garrett, Carolina
   Alves, Dilio
   Teixeira, Joao P.
   Freitas, Diamantino
TI Lacsogram A New EEG Tool to Diagnose Alzheimer's Disease
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Alzheimer's disease; mild-cognitive impairment; diagnose; cepstrum; lacsogram; artificial neural networks
ID mild cognitive impairment; association workgroups; biomarker signature; national institute; dementia; guidelines; pet; recommendations; discrimination
AB This work proposes the application of a new electroencephalogram (EEG) signal processing tool - the lacsogram - to characterize the Alzheimer's disease (AD) activity and to assist on its diagnosis at different stages: Mild Cognitive Impairment (MCI), Mild and Moderate AD (ADM) and Advanced AD (ADA). Statistical analyzes are performed to lacstral distances between conventional EEG subbands to find measures capable of discriminating AD in all stages and characterizing the AD activity in each electrode. Cepstral distances are used for comparison. Comparing all AD stages and Controls (C), the most important significances are the lacstral distances between subbands theta and alpha (p = 0.0014 < 0.05). The topographic maps show significant differences in parietal, temporal and frontal regions as AD progresses. Machine learning models with a leave-one-out cross-validation process are applied to lacstral/cepstral distances to develop an automatic method for diagnosing AD. The following classification accuracies are obtained with an artificial neural network: 95.55% for All vs All, 98.06% for C vs MCI, 95.99% for C vs ADM, 93.85% for MCI vs ADM-ADA. In C vs MCI, C vs ADM and MCI vs ADM-ADA, the proposed method outperforms the state-of-art methods by 5%, 1%, and 2%, respectively. In All vs All, it outperforms the state-of-art EEG and non-EEG methods by 6% and 2%, respectively. These results indicate that the proposed method represents an improvement in diagnosing AD.
C1 [Rodrigues, Pedro M.] Catholic Univ Portugal, Fac Biotechnol, Associated Lab, Ctr Biotechnol & Fine Chem, Rua Diogo Botelho, Lisbon, Portugal.
   [Bispo, Bruno C.] Univ Fed Santa Catarina, Dept Elect & Elect Engn, BR-88040370 Florianopolis, SC, Brazil.
   [Garrett, Carolina] Univ Porto, Fac Med, P-4200319 Porto, Portugal.
   [Garrett, Carolina] Univ Hosp Ctr Sao Joao, Neurol Unity, P-4200319 Porto, Portugal.
   [Alves, Dilio] Univ Hosp Ctr Sao Joao, Neurol Unity, P-4200319 Porto, Portugal.
   [Teixeira, Joao P.] UNIAG Polytech Inst Braganca, CEDRI, P-5300253 Braganca, Portugal.
   [Freitas, Diamantino] Univ Porto, Fac Engn, P-4099002 Porto, Portugal.
C3 Universidade Catolica Portuguesa; Universidade Federal de Santa Catarina (UFSC); Universidade do Porto; Universidade do Porto
RP Rodrigues, PM (corresponding author), Catholic Univ Portugal, Fac Biotechnol, Associated Lab, Ctr Biotechnol & Fine Chem, Rua Diogo Botelho, Lisbon, Portugal.
EM prodrigues@porto.ucp.pt; bruno.bispo@ufsc.br; garrett.mc51@gmail.com; alvesdilio@gmail.com; joaopt@ipb.pt; dfreitas@fe.up.pt
FU National Funds from FCT -Fundacao para a Ciencia e a Tecnologia [UIDB/50016/2020, UIDB/05757/2020]; Faculty of Engineering of the University of Porto through the Doctoral Program of Biomedical Engineering; Fundação para a Ciência e a Tecnologia [UIDB/05757/2020, UIDB/50016/2020] Funding Source: FCT
CR Afshari S, 2017, IEEE J BIOMED HEALTH, V21, P949, DOI 10.1109/JBHI.2016.2578954
   Aghajani H, 2013, IEEE J BIOMED HEALTH, V17, P1039, DOI 10.1109/JBHI.2013.2253326
   AGNOLI A, 1983, CLIN NEUROPHARMACOL, V6, P311, DOI 10.1097/00002826-198312000-00005
   Akrofi K, 2010, INT CONF ACOUST SPEE, V0, PP606, DOI 10.1109/ICASSP.2010.5495193
   Ballard C, 2011, LANCET, V377, P1019, DOI 10.1016/S0140-6736(10)61349-9
   Barthel H, 2011, LANCET NEUROL, V10, P424, DOI 10.1016/S1474-4422(11)70077-1
   BESTHORN C, 1994, ELECTROEN CLIN NEURO, V90, P242, DOI 10.1016/0013-4694(94)90095-7
   BIRD TD, 2001, HARRISONS PRINCIPLES, V0, P2391
   Blennow K, 2010, EUR NEUROPSYCHOPHARM, V20, PS159, DOI 10.1016/S0924-977X(10)70115-2
   Bogert B. P., 1962, TIME SERIES ANAL, V0, P209
   Buscema M, 2007, ARTIF INTELL MED, V40, P127, DOI 10.1016/j.artmed.2007.02.006
   Cassani R., 2019, IEEE J BIOMED HLTH I, V24, P1
   Colliot O, 2008, RADIOLOGY, V248, P194, DOI 10.1148/radiol.2481070876
   Dauwels J, 2011, ADVANCES IN COGNITIVE NEURODYNAMICS (II), V0, PP709, DOI 10.1007/978-90-481-9695-1_106
   De Meyer G, 2010, ARCH NEUROL-CHICAGO, V67, P949, DOI 10.1001/archneurol.2010.179
   Ferrer I, 2012, PROG NEUROBIOL, V97, P38, DOI 10.1016/j.pneurobio.2012.03.005
   Forlenza Orestes V, 2015, ALZHEIMERS DEMENT (AMST), V1, P455, DOI 10.1016/j.dadm.2015.09.003
   Freitas S, 2011, J CLIN EXP NEUROPSYC, V33, P989, DOI 10.1080/13803395.2011.589374
   Gallego-Jutgla E, 2015, J NEURAL ENG, V12, P0, DOI 10.1088/1741-2560/12/1/016018
   GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849
   Hampel H, 2011, PROG NEUROBIOL, V95, P718, DOI 10.1016/j.pneurobio.2011.11.008
   Hampel H, 2010, NAT REV DRUG DISCOV, V9, P560, DOI 10.1038/nrd3115
   Haykin S., 2009, NEURAL NETWORKS LEAR, V3rd ed., P0
   Herholz K, 2003, ANN NUCL MED, V17, P79, DOI 10.1007/BF02988444
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hort J, 2010, EUR J NEUROL, V17, P1236, DOI 10.1111/j.1468-1331.2010.03040.x
   Huang C, 2000, CLIN NEUROPHYSIOL, V111, P1961, DOI 10.1016/S1388-2457(00)00454-5
   Jeong JS, 2004, CLIN NEUROPHYSIOL, V115, P1490, DOI 10.1016/j.clinph.2004.01.001
   Khatun S, 2019, IEEE T NEUR SYS REH, V27, P1063, DOI 10.1109/TNSRE.2019.2911970
   Knopman DS, 2001, NEUROLOGY, V56, P1143, DOI 10.1212/WNL.56.9.1143
   Knott V, 2001, J PSYCHIATR NEUROSCI, V26, P106
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Li W, 2019, IEEE J BIOMED HEALTH, V23, P1234, DOI 10.1109/JBHI.2018.2839771
   Malvar H. S, 1992, SIGNAL PROCESSINGWIT, V0, P0
   MCKHANN G, 1984, NEUROLOGY, V34, P939, DOI 10.1212/WNL.34.7.939
   McKhann GM, 2011, ALZHEIMERS DEMENT, V7, P263, DOI 10.1016/j.jalz.2011.03.005
   Melissant C, 2005, ARTIF INTELL MED, V33, P209, DOI 10.1016/j.artmed.2004.07.003
   Mesulam MM., 2000, PRINCIPLES BEHAV COG, V0, P432
   Nestor PJ, 2004, NAT MED, V10, PS34, DOI 10.1038/nrn1433
   OBryant SE, 2008, ARCH NEUROL-CHICAGO, V65, P963, DOI 10.1001/archneur.65.7.963
   Paliwal K. K., 1982, SPEECH COMMUNICATION, V1, P151, DOI 10.1016/0167-6393(82)90034-6
   Palmqvist S, 2015, NEUROLOGY, V85, P1240, DOI 10.1212/WNL.0000000000001991
   Patterson C., 2018, WORLD ALZHEIMER REPO, V0, P0, DOI DOI 10.1111/j.0033-0124.1950.24_14.x
   Petrosian AA, 2001, CLIN NEUROPHYSIOL, V112, P1378, DOI 10.1016/S1388-2457(01)00579-X
   Poil SS, 2013, FRONT AGING NEUROSCI, V5, P0, DOI 10.3389/fnagi.2013.00058
   Priddy K.L., 2005, SPIE, V0, P0
   Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217
   Rodrigues P.M., 2018, INT J RELIABLE QUALI, V7, P40, DOI 10.4018/IJRQEH.2018010104
   Rodrigues PM, 2018, PROCEDIA COMPUT SCI, V138, P209, DOI 10.1016/j.procs.2018.10.030
   Rodrigues PM, 2017, ADV HEALTHC INF SYST, V0, PP112, DOI 10.4018/978-1-5225-1724-5.ch007
   Sanei S., 2007, EEG SIGNAL PROCESSIN, V0, P0, DOI DOI 10.1002/9780470511923
   Shaw LM, 2009, ANN NEUROL, V65, P403, DOI 10.1002/ana.21610
   Smit S. K., 2010, EXPT METHODS ANAL OP, V0, PP287, DOI 10.1007/978-3-642-02538-9_12
   Sperling RA, 2011, ALZHEIMERS DEMENT, V7, P280, DOI 10.1016/j.jalz.2011.03.003
   Strang G., 1996, WAVELETS FILTER BANK, V0, P0
   TOHKURA Y, 1987, IEEE T ACOUST SPEECH, V35, P1414, DOI 10.1109/TASSP.1987.1165058
   Tolboom N, 2010, J NEUROL NEUROSUR PS, V81, P882, DOI 10.1136/jnnp.2009.194779
   Tong T, 2017, IEEE T BIO-MED ENG, V64, P155, DOI 10.1109/TBME.2016.2549363
   Trappenberg TP, 2019, FUNDAMENTALS MACHINE, V0, P0
   Vetterli M., 1995, WAVELETS SUBBAND COD, V0, P0
   Vialatte F, 2005, LECT NOTES COMPUT SC, V3696, P683, DOI 10.1007/11550822_106
   Williams CJ, 1999, APPL STOCH MODEL BUS, V15, P89, DOI 10.1002/(SICI)1526-4025(199904/06)15:2<89::AID-ASMB366>3.0.CO;2-K
NR 62
TC 10
Z9 10
U1 3
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD SEP 15
PY 2021
VL 25
IS 9
BP 3384
EP 3395
DI 10.1109/JBHI.2021.3069789
PG 12
WC Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics
SC Computer Science; Mathematical & Computational Biology; Medical Informatics
GA UL4AS
UT WOS:000692596400019
PM 33784628
DA 2023-04-26
ER

PT J
AU Chaudhuri, U
   Dey, S
   Datcu, M
   Banerjee, B
   Bhattacharya, A
AF Chaudhuri, Ushasi
   Dey, Subhadip
   Datcu, Mihai
   Banerjee, Biplab
   Bhattacharya, Avik
TI Interband Retrieval and Classification Using the Multilabeled Sentinel-2 BigEarthNet Archive
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Vegetation mapping; Spatial resolution; Feature extraction; Sensors; Satellites; Task analysis; Soil; Interband retrieval; multilabel classification; multilabel cross triplet loss; multimodal classification; Sentinel-2; land-cover classification
ID graph convolutional network; spatial-resolution; driven; net
AB Conventional remote sensing data analysistechniques have a significant bottleneck of operating on a selectively chosen small-scale dataset. Availability of an enormous volume of data demands handling large-scale, diverse data, which have been made possible with neural network-based architectures. This article exploits the contextual information capturing ability of deep neural networks, particularly investigating multispectral band properties from Sentinel-2 image patches. Besides, an increase in the spatial resolution often leads to nonlinear mixing of land-cover types within a target resolution cell. We recognize this fact and group the bands according to their spatial resolutions, and propose a classification and retrieval framework. We design a representation learning framework for classifying the multispectral data by first utilizing all the bands and then using the grouped bands according to their spatial resolutions. We also propose a novel triplet-loss function for multilabeled images and use it to design an interband group retrieval framework. We demonstrate its effectiveness over the conventional triplet-loss function. Finally, we present a comprehensive discussion of the obtained results. We thoroughly analyze the performance of the band groups on various land-cover and land-use areas from agro-forestry regions, water bodies, and human-made structures. Experimental results for the classification and retrieval framework on the benchmarked BigEarthNet dataset exhibit marked improvements over existing studies.
C1 [Chaudhuri, Ushasi; Dey, Subhadip; Banerjee, Biplab; Bhattacharya, Avik] Indian Inst Technol, Ctr Studies Resources Engn, Mumbai 400076, Maharashtra, India.
   [Datcu, Mihai] German Aerospace Ctr DLR, D-82234 Wessling, Germany.
C3 Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay; Helmholtz Association; German Aerospace Centre (DLR)
RP Chaudhuri, U (corresponding author), Indian Inst Technol, Ctr Studies Resources Engn, Mumbai 400076, Maharashtra, India.
EM ushasi2cool@gmail.com; subhadipdey23071994@gmail.com; mihai.datcu@dlr.de; getbiplab@.com; avikb@csre.iitb.ac.in
FU Conservatoire National des Arts et Metiers (CNAM), Paris, France
CR Aghdam Hamed Habibi, 2017, GUIDE CONVOLUTIONAL, V10, P978
   [Anonymous], 2017, ARXIV170707321, V0, P0
   Bahmanyar R, 2018, IEEE GEOSCI REMOTE S, V15, P459, DOI 10.1109/LGRS.2018.2794511
   Barandela R, 2003, LECT NOTES COMPUT SC, V2905, P424
   Berman EE, 2018, REMOTE SENS ENVIRON, V216, P635, DOI 10.1016/j.rse.2018.07.029
   Blondeau-Patissier D, 2014, PROG OCEANOGR, V123, P123, DOI 10.1016/j.pocean.2013.12.008
   Caballero I, 2019, ESTUAR COAST SHELF S, V226, P0, DOI 10.1016/j.ecss.2019.106277
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chaudhuri Ushasi, 2022, IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, V19, P0, DOI 10.1109/LGRS.2021.3056392
   Chaudhuri U., 2020, P IEEECVF C COMPUTER, V0, P182
   Chaudhuri U, 2022, IEEE GEOSCI REMOTE S, V19, P0, DOI 10.1109/LGRS.2021.3105448
   Chaudhuri U, 2021, INT C PATT RECOG, V0, PP7335, DOI 10.1109/ICPR48806.2021.9412344
   Chaudhuri U, 2020, IMAGE VISION COMPUT, V104, P0, DOI 10.1016/j.imavis.2020.104003
   Chaudhuri U, 2020, PATTERN RECOGN LETT, V131, P456, DOI 10.1016/j.patrec.2020.02.006
   Chaudhuri U, 2019, COMPUT VIS IMAGE UND, V184, P22, DOI 10.1016/j.cviu.2019.04.004
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen D, 2004, INT J REMOTE SENS, V25, P2177, DOI 10.1080/01431160310001618464
   Chen SW, 2018, IEEE GEOSCI REMOTE S, V15, P627, DOI 10.1109/LGRS.2018.2799877
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cui SY, 2015, IEEE J-STARS, V8, P5158, DOI 10.1109/JSTARS.2015.2495267
   Delegido J, 2011, SENSORS-BASEL, V11, P7063, DOI 10.3390/s110707063
   Demir B, 2016, IEEE T GEOSCI REMOTE, V54, P892, DOI 10.1109/TGRS.2015.2469138
   Duan PH, 2021, IEEE T GEOSCI REMOTE, V59, P7726, DOI 10.1109/TGRS.2020.3031928
   Dutta Titir, 2020, COMPUTER VISION - ECCV 2020 16TH EUROPEAN CONFERENCE. PROCEEDINGS. LECTURE NOTES IN COMPUTER SCIENCE (LNCS 12350), V0, PP349, DOI 10.1007/978-3-030-58558-7_21
   Fan RY, 2020, IEEE J-STARS, V13, P4973, DOI 10.1109/JSTARS.2020.3019410
   Ferecatu M., 2004, P 6 ACM SIGMM INT WO, V0, P23
   Green CA, 2019, PHARMACOEPIDEM DR S, V28, P1127, DOI 10.1002/pds.4772
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P2281, DOI 10.1109/TGRS.2020.3007921
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Huang ZL, 2020, ISPRS J PHOTOGRAMM, V161, P179, DOI 10.1016/j.isprsjprs.2020.01.016
   IRONS JR, 1985, INT J REMOTE SENS, V6, P1385, DOI 10.1080/01431168508948285
   Janhall S, 2015, ATMOS ENVIRON, V105, P130, DOI 10.1016/j.atmosenv.2015.01.052
   Jaremenko SA, 2017, IOP CONF SER-MAT SCI, V262, P0, DOI 10.1088/1757-899X/262/1/012189
   Ji SP, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010075
   Jiang JH, 2019, IEEE ACCESS, V7, P20607, DOI 10.1109/ACCESS.2019.2896128
   Kakogeorgiou I, 2021, INT J APPL EARTH OBS, V103, P0, DOI 10.1016/j.jag.2021.102520
   Khan N, 2019, NEUROCOMPUTING, V357, P36, DOI 10.1016/j.neucom.2019.05.024
   Klemas V, 2012, J COASTAL RES, V28, P34, DOI 10.2112/JCOASTRES-D-11-00051.1
   Lee J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071097
   Li N, 2018, IEEE J-STARS, V11, P1348, DOI 10.1109/JSTARS.2018.2814617
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P6521, DOI 10.1109/TGRS.2018.2839705
   Lin TY, 2017, IEEE I CONF COMP VIS, V0, PP2999, DOI 10.1109/ICCV.2017.324
   Pflugmacher D, 2019, REMOTE SENS ENVIRON, V221, P583, DOI 10.1016/j.rse.2018.12.001
   Robinson C., 2019, PROC CVPR IEEE, V0, PP12726, DOI 10.1109/CVPR.2019.01301
   Sahadevan AS, 2014, IEEE J-STARS, V7, P2490, DOI 10.1109/JSTARS.2013.2280894
   Schmitt M., 2019, ISPRS ANN PHOTOGRAMM, V0, P0, DOI DOI 10.5194/isprs-annals-IV-2-W7-153-2019(
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Sebastia-Frasquet MT, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11242926
   Simonyan K, 2015, ARXIV, V0, P0
   Sumbul G, 2021, ARXIV200106372, V0, P0
   Sumbul G, 2020, IEEE ACCESS, V8, P95934, DOI 10.1109/ACCESS.2020.2995805
   Sumbul G, 2019, INT GEOSCI REMOTE SE, V0, PP5901, DOI 10.1109/IGARSS.2019.8900532
   Sumbul G, 2019, INT GEOSCI REMOTE SE, V0, PP5726, DOI 10.1109/IGARSS.2019.8898188
   Szegedy C, 2016, PROC CVPR IEEE, V0, PP2818, DOI 10.1109/CVPR.2016.308
   Tanase R, 2017, IEEE GEOSCI REMOTE S, V14, P237, DOI 10.1109/LGRS.2016.2636663
   Ulmas P., 2020, ARXIV PREPRINT ARXIV, V0, P0
   van der Meer FD, 2014, REMOTE SENS ENVIRON, V148, P124, DOI 10.1016/j.rse.2014.03.022
   Vincenzi Stefano, 2020, 2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR), V0, PP3034, DOI 10.1109/ICPR48806.2021.9413112
   Wu J, 2017, INTRO CONVOLUTIONAL, V5, P978
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xian YQ, 2018, PROC CVPR IEEE, V0, PP5542, DOI 10.1109/CVPR.2018.00581
   Xu ZW, 2018, ISPRS J PHOTOGRAMM, V144, P423, DOI 10.1016/j.isprsjprs.2018.08.005
   Yang X., 2011, URBAN REMOTE SENSING, V0, P0
   Yessou H, 2020, INT GEOSCI REMOTE SE, V0, PP1349, DOI 10.1109/IGARSS39084.2020.9323583
   Zhang GC, 2019, IEEE T GEOSCI REMOTE, V57, P7623, DOI 10.1109/TGRS.2019.2914967
   Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19
   Zhang YZ, 2013, IEEE J-STARS, V6, P746, DOI 10.1109/JSTARS.2013.2245405
   Zhao JP, 2019, IEEE T GEOSCI REMOTE, V57, P10116, DOI 10.1109/TGRS.2019.2931620
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zotov Michael, 2019, ARXIV191014567, V0, P0
NR 73
TC 5
Z9 5
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 9884
EP 9898
DI 10.1109/JSTARS.2021.3112209
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA WJ5GX
UT WOS:000709074200001
DA 2023-04-26
ER

PT J
AU Pessiglione, M
   Daunizeau, J
AF Pessiglione, Mathias
   Daunizeau, Jean
TI Bridging Across Functional Models: The OFC as a Value-Making Neural Network
SO BEHAVIORAL NEUROSCIENCE
LA English
DT Article
DE orbitofrontal cortex; artificial neural network; subjective value; likeability rating; economic choice
ID orbitofrontal cortex; decision-making; valuation system; visual fixations; cognitive map; mechanisms; choice; representations; computations; metaanalysis
AB Many functions have been attributed to the orbitofrontal cortex (OFC)-some classical roles, such as signaling the value of action outcomes, being challenged by more recent ones, such as signaling the position of a trial within a task space. In this paper, we propose a unifying neural network architecture, whose function is to generate a value from a set of attributes attached to a particular object. Our model reverses the logic of perceptual choice models, by considering values as outputs of (and not inputs to) the neural network. In doing so, the model explains why univariate value signals have been observed in both likeability rating and economic choice tasks, while the features associated with a particular task trial can be decoded using multivariate analysis. Moreover, simulations show that a globally positive correlation with subjective value at the population level can coexist with a variety of correlation coefficients at the single-unit level, bridging typical observations made in human neuroimaging and monkey electrophysiology studies of OFC activity. To better explain binary choice, we equipped the neural network with recurrent feedback connections that enable simultaneous coding of values associated with currently attended and previously considered objects. Simulations of this augmented model show that virtual lesions produce systematically intransitive preferences, as observed in patients with damage to the OFC. Thus, our neural network model is sufficiently general and flexible to account for a core set of observations and make specific predictions about both OFC activity during value judgment and behavioral consequence of OFC damage.
C1 [Pessiglione, Mathias; Daunizeau, Jean] Sorbonne Univ, Motivat Brain & Behav MBB Lab, Paris Brain Inst ICM, INSERM,CNRS,Pitie Salpetriere Hosp, Paris, France.
C3 Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Pitie-Salpetriere - APHP; Centre National de la Recherche Scientifique (CNRS); Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; Sorbonne Universite
RP Pessiglione, M (corresponding author), Sorbonne Univ, Motivat Brain & Behav MBB Lab, Paris Brain Inst ICM, INSERM,CNRS,Pitie Salpetriere Hosp, Paris, France.
EM mathias.pessiglione@gmail.com
CR Abitbol R, 2015, J NEUROSCI, V35, P2308, DOI 10.1523/JNEUROSCI.1878-14.2015
   Aridan N, 2019, NEUROIMAGE, V185, P446, DOI 10.1016/j.neuroimage.2018.10.051
   Bao XJ, 2019, NEURON, V102, P1066, DOI 10.1016/j.neuron.2019.03.034
   Bartra O, 2013, NEUROIMAGE, V76, P412, DOI 10.1016/j.neuroimage.2013.02.063
   Bastin J, 2012, NEUROIMAGE, V63, P339, DOI 10.1016/j.neuroimage.2012.07.011
   Camille N, 2011, J NEUROSCI, V31, P7527, DOI 10.1523/JNEUROSCI.6527-10.2011
   Chib VS, 2009, J NEUROSCI, V29, P12315, DOI 10.1523/JNEUROSCI.2575-09.2009
   Cisek P, 2010, ANNU REV NEUROSCI, V33, P269, DOI 10.1146/annurev.neuro.051508.135409
   Clithero JA, 2014, SOC COGN AFFECT NEUR, V9, P1289, DOI 10.1093/scan/nst106
   Constantinescu AO, 2016, SCIENCE, V352, P1464, DOI 10.1126/science.aaf0941
   De Martino B, 2013, NAT NEUROSCI, V16, P105, DOI 10.1038/nn.3279
   Fleming SM, 2010, P NATL ACAD SCI USA, V107, P6005, DOI 10.1073/pnas.0910380107
   Fouragnan E, 2018, HUM BRAIN MAPP, V39, P2887, DOI 10.1002/hbm.24047
   Garrison J, 2013, NEUROSCI BIOBEHAV R, V37, P1297, DOI 10.1016/j.neubiorev.2013.03.023
   Gherman S, 2018, ELIFE, V7, P0, DOI 10.7554/eLife.38293
   Grueschow M, 2015, NEURON, V85, P874, DOI 10.1016/j.neuron.2014.12.054
   Hare TA, 2009, SCIENCE, V324, P646, DOI 10.1126/science.1168450
   Harvey AH, 2010, J NEUROSCI, V30, P9597, DOI 10.1523/JNEUROSCI.1086-10.2010
   Hayden BY, 2011, NAT NEUROSCI, V14, P933, DOI 10.1038/nn.2856
   Hebscher M, 2016, CEREB CORTEX, V26, P4590, DOI 10.1093/cercor/bhv220
   Hunt LT, 2012, NAT NEUROSCI, V15, P470, DOI 10.1038/nn.3017
   Ito A, 2020, HUM BRAIN MAPP, V41, P3045, DOI 10.1002/hbm.24996
   Juechems K, 2019, TRENDS COGN SCI, V23, P836, DOI 10.1016/j.tics.2019.07.012
   Kim H, 2007, P NATL ACAD SCI USA, V104, P18253, DOI 10.1073/pnas.0703101104
   Kolling N, 2012, SCIENCE, V336, P95, DOI 10.1126/science.1216930
   Krajbich I, 2011, P NATL ACAD SCI USA, V108, P13852, DOI 10.1073/pnas.1101328108
   Krajbich I, 2010, NAT NEUROSCI, V13, P1292, DOI 10.1038/nn.2635
   Lebreton M, 2015, NAT NEUROSCI, V18, P1159, DOI 10.1038/nn.4064
   Lebreton M, 2013, PLOS BIOL, V11, P0, DOI 10.1371/journal.pbio.1001684
   Lebreton M, 2009, NEURON, V64, P431, DOI 10.1016/j.neuron.2009.09.040
   Lench HC, 2014, COGNITION, V133, P429, DOI 10.1016/j.cognition.2014.08.001
   Levy DJ, 2012, CURR OPIN NEUROBIOL, V22, P1027, DOI 10.1016/j.conb.2012.06.001
   Levy I, 2011, J NEUROSCI, V31, P118, DOI 10.1523/JNEUROSCI.3214-10.2011
   Lim SL, 2011, J NEUROSCI, V31, P13214, DOI 10.1523/JNEUROSCI.1246-11.2011
   Logothetis NK, 2001, NATURE, V412, P150, DOI 10.1038/35084005
   Lopez-Gamundi P., 2021, NEUROSCIENCE, V0, P0
   Lopez-Persem A, 2020, NAT NEUROSCI, V23, P664, DOI 10.1038/s41593-020-0615-9
   Lopez-Persem A, 2016, ELIFE, V5, P0, DOI 10.7554/eLife.20317
   Morrison SE, 2009, J NEUROSCI, V29, P11471, DOI 10.1523/JNEUROSCI.1815-09.2009
   ODoherty JP, 2014, NEUROSCI BIOBEHAV R, V43, P259, DOI 10.1016/j.neubiorev.2014.03.027
   Padoa-Schioppa C, 2006, NATURE, V441, P223, DOI 10.1038/nature04676
   Padoa-Schioppa C, 2017, NEURON, V96, P736, DOI 10.1016/j.neuron.2017.09.031
   Padoa-Schioppa C, 2011, ANNU REV NEUROSCI, V34, P333, DOI 10.1146/annurev-neuro-061010-113648
   Palminteri S, 2012, NEURON, V76, P998, DOI 10.1016/j.neuron.2012.10.017
   Palminteri S, 2009, J NEUROSCI, V29, P13465, DOI 10.1523/JNEUROSCI.1500-09.2009
   Papageorgiou GK, 2017, NAT COMMUN, V8, P0, DOI 10.1038/s41467-017-01833-5
   Pauli WM, 2019, NAT COMMUN, V10, P0, DOI 10.1038/s41467-019-08922-7
   Pelletier G, 2019, J NEUROSCI, V39, P4124, DOI 10.1523/JNEUROSCI.2969-18.2019
   Peters J, 2010, BEHAV BRAIN RES, V213, P135, DOI 10.1016/j.bbr.2010.04.031
   Piguet O, 2011, LANCET NEUROL, V10, P162, DOI 10.1016/S1474-4422(10)70299-4
   Plassmann H, 2008, P NATL ACAD SCI USA, V105, P1050, DOI 10.1073/pnas.0706929105
   Pleskac T.J., 2015, INT ENCY SOCIAL BEHA, V13, P895, DOI 10.1016/B978-0-08-097086-8.43031-X
   Polania R, 2019, NAT NEUROSCI, V22, P134, DOI 10.1038/s41593-018-0292-0
   Pouget A, 2013, NAT NEUROSCI, V16, P1170, DOI 10.1038/nn.3495
   Ratcliff R, 2016, TRENDS COGN SCI, V20, P260, DOI 10.1016/j.tics.2016.01.007
   Ray S, 2008, J NEUROSCI, V28, P11526, DOI 10.1523/JNEUROSCI.2848-08.2008
   Rich EL, 2014, J COGNITIVE NEUROSCI, V26, P1347, DOI 10.1162/jocn_a_00573
   Rustichini A, 2015, J NEUROPHYSIOL, V114, P1382, DOI 10.1152/jn.00184.2015
   Saez I, 2018, CURR BIOL, V28, P2889, DOI 10.1016/j.cub.2018.07.045
   Scheeringa R, 2011, NEURON, V69, P572, DOI 10.1016/j.neuron.2010.11.044
   Schneider B, 2017, NEUROPSYCHOLOGIA, V107, P84, DOI 10.1016/j.neuropsychologia.2017.09.035
   Schuck NW, 2016, NEURON, V91, P1402, DOI 10.1016/j.neuron.2016.08.019
   Strait CE, 2014, NEURON, V82, P1357, DOI 10.1016/j.neuron.2014.04.032
   Sutton R., 1998, INTRO REINFORCEMENT, V0, P0, DOI DOI 10.1109/TNN.1998.712192
   Suzuki S, 2017, NAT NEUROSCI, V20, P1780, DOI 10.1038/s41593-017-0008-x
   Tajima S, 2019, NAT NEUROSCI, V22, P1503, DOI 10.1038/s41593-019-0453-9
   Tappin BM, 2017, J EXP PSYCHOL GEN, V146, P1143, DOI 10.1037/xge0000298
   Tom SM, 2007, SCIENCE, V315, P515, DOI 10.1126/science.1134239
   Tremblay L, 1999, NATURE, V398, P704, DOI 10.1038/19525
   Tsetsos K, 2014, ELIFE, V3, P0, DOI 10.7554/eLife.03701
   Vaidya AR, 2018, CEREB CORTEX, V28, P3857, DOI 10.1093/cercor/bhx246
   Vinckier F, 2018, NAT COMMUN, V9, P0, DOI 10.1038/s41467-018-03774-z
   Wang XJ, 2002, NEURON, V36, P955, DOI 10.1016/S0896-6273(02)01092-9
   Wilson RC, 2014, NEURON, V81, P267, DOI 10.1016/j.neuron.2013.11.005
   Wong KF, 2006, J NEUROSCI, V26, P1314, DOI 10.1523/JNEUROSCI.3733-05.2006
   Wunderlich K, 2009, P NATL ACAD SCI USA, V106, P17199, DOI 10.1073/pnas.0901077106
NR 76
TC 6
Z9 6
U1 1
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0735-7044
EI 1939-0084
J9 BEHAV NEUROSCI
JI Behav. Neurosci.
PD APR 15
PY 2021
VL 135
IS 2
BP 277
EP 290
DI 10.1037/bne0000464
PG 14
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA SM0IN
UT WOS:000657296600019
PM 34060880
DA 2023-04-26
ER
