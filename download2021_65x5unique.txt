
PT J
AU Liu, W
   Zhang, XD
   He, F
   Xiong, Q
   Zan, XL
   Liu, Z
   Sha, DX
   Yang, CW
   Li, SM
   Zhao, YY
AF Liu, Wei
   Zhang, Xiaodong
   He, Fei
   Xiong, Quan
   Zan, Xuli
   Liu, Zhe
   Sha, Dexuan
   Yang, Chaowei
   Li, Shaoming
   Zhao, Yuanyuan
TI Open-air grape classification and its application in parcel-level risk assessment of late frost in the eastern Helan Mountains
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Open-air grape parcel; Late frost; Google Earth Engine; Crop classification; Sentinel-2; OpenStreetMap; Eastern Helan Mountains
ID land-surface temperature; high-spatial-resolution; random forest; image classification; neural-network; crop classification; training samples; sentinel-2 data; seed maize; cover
AB The eastern Helan Mountains are one of the most important plantings and production bases for high-quality grapes in China. In winter, grape root is prone to freezing damage owing to natural phenomenon such as early and late frost, and methods to assess disaster risk at the grape parcel level is one of the current research hotspots. However, there are two problems at present; first is the lack of grape parcel maps and second is that scale of disaster risk assessment is limited to the level of administrative divisions and grid systems. Therefore, according to the perennial characteristics of the grapes and clear texture of the open-air grape parcels based on public data sets (Sentinel-2A/B) and high-quality winery address information, combined with Google Earth engine (GEE) platform, Google Earth, and Ovitalmap, this study designs a collection scheme of open-air grape parcel samples and non-grape parcel samples, analyzes the environmental characteristics of the distribution of high-quality wineries, constructs a classification feature database in three aspects (time, terrain, and vegetation), uses the random forest classification method to classify open-air grape parcels in the eastern Helan Mountains in 2019, and conducts a late frost disaster risk assessment of the open-air grape parcel. The results show that: (1) The high-quality wineries are mainly distributed in the elevation of 1106-1240 m, with the average slope of 0.82., the organic matter content of 10.79-14.27 g/kg, the P content of 24.87-37.58 mg/kg, the K content of 116-166 mg/kg, the pH 8.38-8.55, N content of 0.65-0.98 g/kg, annual average active accumulated temperature >= 10 degrees C of 3490-3590 degrees C, annual average rainfall of 189-201 mm, the annual average sunshine duration of 7.3-7.6 h, annual average air temperature of 8.8-9.4 degrees C, annual average temperature difference of 12.7-13.2 degrees C, annual average frost-free period at 263-270 d and annual average relative air Humidity of 50-54%. (2) The overall classification accuracy of open-air grape parcels reached 98.96% and the verification accuracy of ground truth parcel samples reached 87.89%. The open-air grape parcels in the eastern Helan Mountains are mainly distributed in Helan County, Xixia District, Yongning County, and Qingtongxia City. (3) The highest risk of late frost was found in Xixia District and the lowest risk in Yongning County. Helan County was higher than Qingtongxia City in the medium risk of late frost. The typical small area high risk includes Liangtian Town, the experimental field of Ningxia Academy of Agricultural and Forestry Sciences in Zhenbeibao Town, Yuhuang Winery in Ganchengzi Village, and the State-run Warm Spring Farm in Helan County. Thus, the sample collection and augmentation scheme are feasible, the open-air grape classification accuracy is high and its result is consistent with field investigation, which can provide accurate parcel-level disaster risk assessment and provide decision support for agricultural departments and farmers.Y
C1 [Liu, Wei; Zhang, Xiaodong; Xiong, Quan; Zan, Xuli; Liu, Zhe; Li, Shaoming; Zhao, Yuanyuan] China Agr Univ, Coll Land Sci & Technol, Beijing 100083, Peoples R China.
   [He, Fei] China Agr Univ, Coll Food Sci & Nutr Engn, Beijing 100083, Peoples R China.
   [Sha, Dexuan; Yang, Chaowei] George Mason Univ, NSF Spatiotemporal Innovat Ctr, Fairfax, VA 22030 USA.
C3 China Agricultural University; China Agricultural University; George Mason University
RP Zhang, XD (corresponding author), China Agr Univ, Coll Land Sci & Technol, Beijing 100083, Peoples R China.
EM zhangxd@cau.edu.cn
FU National Natural Science Foundation of China [41771104]
CR Arikan M., 2004, P ISPRS S IST INT AR, VVolume 34, P0
   Benali A, 2012, REMOTE SENS ENVIRON, V124, P108, DOI 10.1016/j.rse.2012.04.024
   Brinkhoff J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142245
   Coakley C, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11202397
   Cogato A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111896
   Cu Zhu-jun, 2008, YINGYONG SHENGTAI XUEBAO, V19, P1296
   Diaz BM, 2003, INT J REMOTE SENS, V24, P53, DOI 10.1080/01431160305012
   Duan X.F., 2014, J SHANXI AGR SCI, V42, P1148
   Duddu HSN, 2018, CAN J REMOTE SENS, V44, P169, DOI 10.1080/07038992.2018.1462660
   [樊晓春 Fan Xiaochun], 2013, 中国农学通报 CHINESE AGRICULTURAL SCIENCE BULLETIN, V29, P194
   Fayad I, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12121976
   Feng ZY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223708
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Fritz S, 2009, REMOTE SENS-BASEL, V1, P345, DOI 10.3390/rs1030345
   Fu X, 2014, BEIJING AGR, V18, P66
   Huang C, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071163
   Huang HB, 2020, ISPRS J PHOTOGRAMM, V161, P27, DOI 10.1016/j.isprsjprs.2020.01.010
   [李红英 Li Hongying], 2014, 自然灾害学报 JOURNAL OF NATURAL DISASTERS, V23, P167
   [李华 LI Hua], 2007, 科技导报 SCIENCE & TECHNOLOGY REVIEW, V25, P16
   Li X, 2012, SINO OVERSEAS GRAPEV, V0, PP39, DOI 10.13414/j.cnki.zwpp.2012.01.009
   Liu Y, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12111780
   Maghsoudi Y, 2013, IEEE J-STARS, V6, P1531, DOI 10.1109/JSTARS.2013.2259219
   Malambo L, 2020, ISPRS J PHOTOGRAMM, V160, P107, DOI 10.1016/j.isprsjprs.2019.11.026
   Meier M, 2018, INT J BIOMETEOROL, V62, P991, DOI 10.1007/s00484-018-1501-y
   Molitor D, 2014, AUST J GRAPE WINE R, V20, P160, DOI 10.1111/ajgw.12059
   Mosedale JR, 2015, PLOS ONE, V10, P0, DOI 10.1371/journal.pone.0141218
   Murmu S, 2015, AQUAT PR, V4, P1203, DOI 10.1016/j.aqpro.2015.02.153
   Murphy ME, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030477
   Nevavuori P, 2019, COMPUT ELECTRON AGR, V163, P0, DOI 10.1016/j.compag.2019.104859
   Ning C., 2017, J NINGXIA U, V38, P186
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Pena JM, 2014, REMOTE SENS-BASEL, V6, P5019, DOI 10.3390/rs6065019
   Pena MA, 2017, ISPRS J PHOTOGRAMM, V128, P158, DOI 10.1016/j.isprsjprs.2017.03.019
   Pena-Barragan JM, 2011, REMOTE SENS ENVIRON, V115, P1301, DOI 10.1016/j.rse.2011.01.009
   Phalke AR, 2020, ISPRS J PHOTOGRAMM, V167, P104, DOI 10.1016/j.isprsjprs.2020.06.022
   Pinheiro ACT, 2004, IEEE T GEOSCI REMOTE, V42, P1941, DOI 10.1109/TGRS.2004.831886
   Qin G., 2019, AGR TECHNOL, V39, P159, DOI 10.19754/j.nyyjs.20191115068
   Qin W., 2019, JIANGSU AGR SCI, V33, P0
   Rahman MM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12081313
   Ren TW, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12132140
   Semeraro T, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060907
   Song A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050799
   [宋晓倩 Song Xiaoqian], 2020, 江苏农业学报 JIANGSU JOURNAL OF AGRICULTURAL SCIENCES, V36, P689
   Song Y, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11040449
   Sozzi MM, 2020, OENO ONE, V54, P189, DOI 10.20870/oeno-one.2020.54.2.2557
   Sun M., 2012, CHIN HORTICULT ABSTR, V28, P155, DOI 10.3969/j.issn.1672-0873.2012.09.077
   Sun YQ, 2017, GEOSCI FRONT, V8, P1051, DOI 10.1016/j.gsf.2016.10.008
   Tang K, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020193
   Teluguntla P, 2018, ISPRS J PHOTOGRAMM, V144, P325, DOI 10.1016/j.isprsjprs.2018.07.017
   Thonfeld F, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12071057
   Tian YL, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091383
   Vivone G, 2020, INFORM FUSION, V61, P71, DOI 10.1016/j.inffus.2020.03.012
   WALD A, 1949, ANN MATH STAT, V20, P595, DOI 10.1214/aoms/1177729952
   Wang DZ, 2020, INT J APPL EARTH OBS, V85, P0, DOI 10.1016/j.jag.2019.101986
   Wang J., 2017, CHINESE J AGR RESOUR, V38, P122
   Wang KC, 2009, REMOTE SENS ENVIRON, V113, P1556, DOI 10.1016/j.rse.2009.03.009
   Wang S, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12182957
   [王素艳 Wang Suyan], 2017, 生态学报 ACTA ECOLOGICA SINICA, V37, P3776
   Wang X., 2017, JIANGXI AGR, V13, P15, DOI 10.19394/j.cnki.issn1674-4179.2017.13.013
   Weng QH, 2014, REMOTE SENS ENVIRON, V145, P55, DOI 10.1016/j.rse.2014.02.003
   Wulder MA, 2019, REMOTE SENS ENVIRON, V225, P127, DOI 10.1016/j.rse.2019.02.015
   Xu XJ, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10040546
   Xue JR, 2017, J SENSORS, V2017, P0, DOI 10.1155/2017/1353691
   Yan YL, 2021, ISPRS J PHOTOGRAMM, V171, P278, DOI 10.1016/j.isprsjprs.2020.11.022
   Yang MD, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9060583
   Yang N, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11121500
   Yang W., 2018, GUANGDONG AGR SCI, V0, PP127, DOI 10.16768/j.issn.1004-874X.2018.05.021
   [杨洋 Yang Yang], 2019, 甘肃农业大学学报 JOURNAL OF GANSU AGRICULTURAL UNIVERSITY, V54, P149
   [杨洋 Yang Yang], 2017, 自然灾害学报 JOURNAL OF NATURAL DISASTERS, V26, P84
   Yuan H, 2009, REMOTE SENS-BASEL, V1, P243, DOI 10.3390/rs1030243
   Yuan JF, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12060945
   Zhang DY, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222647
   Zhang L., 2018, J SHANXI AGR SCI, V46, P260, DOI 10.3969/j.issn.1002-2481.2018.02.25
   Zhang L, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030362
   Zhang L, 2019, SUSTAINABILITY-BASEL, V11, P0, DOI 10.3390/su11185052
   Zhang ZM, 2013, INT J REMOTE SENS, V34, P7369, DOI 10.1080/01431161.2013.820368
   Zhao XiNi, 2019, JOURNAL OF HENAN AGRICULTURAL SCIENCES, V48, P153
   Zhou FQ, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2019.111628
NR 79
TC 3
Z9 3
U1 9
U2 54
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2021
VL 174
IS 
BP 132
EP 150
DI 10.1016/j.isprsjprs.2021.02.004
EA FEB 2021
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO4AQ
UT WOS:000640987800010
DA 2023-04-26
ER

PT J
AU Liu, MX
   Liu, JH
   Atzberger, C
   Jiang, Y
   Ma, MF
   Wang, XM
AF Liu, Mingxing
   Liu, Jianhong
   Atzberger, Clement
   Jiang, Ya
   Ma, Minfei
   Wang, Xunmei
TI Zanthoxylum bungeanum Maxim mapping with multi-temporal Sentinel-2 images: The importance of different features and consistency of results
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Zanthoxylum bungeanum Maxim; Random forest classifier; Sentinel-2; Vegetation indices; Topographic variables; Importance analysis
ID support vector machines; random forest; time-series; neural-network; landsat 8; classification; cover; biomass; china; crops
AB Zanthoxylum bungeanum Maxim (ZBM) is an important woody species in large parts of Asia, which provides oils and medicinal materials. Timely and accurate mapping of its spatial distribution and planting area is of great significance to local economy and ecology. As a special tree species planted in the Grain for Green Program of China, Linxia Hui Autonomous Prefecture (Linxia) in Gansu Province of China has vigorously developed ZBM cultivation since the launch of the program. However, lacking the accurate ZBM planting information hinders the assessment of the benefits and losses of the program to local people. Therefore, this study investigated the potential of multi-temporal Sentinel-2 Multi-Spectral Instrument (MSI) to accurately map ZBM in the study area in 2019. We first investigated the classification accuracies of four alternative Random Forest (RF) classifications using either alone or in combination, spectral bands, vegetation indices (VIs), and topographical variables. The importance of the three categories of features was examined based on the mean decrease accuracy (MDA) metric. The classification results with the most important features were further assessed for their consistency by considering the voting rates of 800 trees based on testing samples. Results show that the sole use of the spectral bands (40 input features) already achieves a satisfactory classification accuracy of 95.43%. Adding extra VIs and topographical variables further improves the results, but only to a small extent. However, certain VIs and topographic variables are far more effective in classification compared with the original spectral bands, especially the Red Edge Normalized Difference Vegetation Index (NDVI705) and Normalized Difference Yellow Index (NDYI). The classification accuracy achieves nearly 95% when using only the top 15 most important features. The desirable periods for differencing of ZBM and other land cover types are fruit coloring and ripening periods. The final map shows that the ZBM planting in Linxia is mainly distributed along the Yellow River and around the Liujiaxia reservoir. The total mapped acreages of ZBM is 51,601 ha, covering 9.51% of the study area. 99% of ZBM tends to grow between 1500 and 2400 m altitude, and 67% of ZBM are planted in areas with slopes between 5 and 25.. Voting rates show that the percentages of classification results with strong and good consistency are generally over 70% for all land cover types, proving the derived land cover map's high credibility, including ZBM. Altogether, our results demonstrate the high potential of multi-temporal Sentinel-2 images in accurate mapping of ZBM, which can serve as a reference for other specialty crops or tree species.Y
C1 [Liu, Mingxing; Liu, Jianhong; Ma, Minfei] Northwest Univ, Shaanxi Key Lab Earth Surface Syst & Environm Car, Xian 710127, Peoples R China.
   [Liu, Mingxing; Liu, Jianhong; Jiang, Ya; Ma, Minfei; Wang, Xunmei] Northwest Univ, Coll Urban & Environm Sci, Xian 710127, Peoples R China.
   [Atzberger, Clement] Univ Nat Resources & Life Sci BOKU, Inst Geomat, Peter Jordan Str 82, A-1190 Vienna, Austria.
C3 Northwest University Xi'an; Northwest University Xi'an; University of Natural Resources & Life Sciences, Vienna
RP Liu, JH (corresponding author), Northwest Univ, Shaanxi Key Lab Earth Surface Syst & Environm Car, Xian 710127, Peoples R China.
EM mingxingliu@stumail.nwu.edu.cn; jhliu@nwu.edu.cn; clement.atzberger@boku.ac.at
FU National Natural Science Foundation of China [41401494]; Natural Science Foundation of Shaanxi Provincial Department of Education [14JK1745]
CR Ashourloo D, 2020, COMPUT ELECTRON AGR, V175, P0, DOI 10.1016/j.compag.2020.105583
   Ashourloo D, 2019, ISPRS J PHOTOGRAMM, V156, P63, DOI 10.1016/j.isprsjprs.2019.08.007
   Bazi Y, 2006, IEEE T GEOSCI REMOTE, V44, P3374, DOI 10.1109/TGRS.2006.880628
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Blackard JA, 1999, COMPUT ELECTRON AGR, V24, P131, DOI 10.1016/S0168-1699(99)00046-0
   Breiman L., 2001, MACHINE LEARNING, V45, P5, DOI 10.1023/A:1010933404324
   Chen BQ, 2017, ISPRS J PHOTOGRAMM, V131, P104, DOI 10.1016/j.isprsjprs.2017.07.011
   Chen Y, 2019, APPL SCI-BASEL, V9, P0, DOI 10.3390/app9142917
   Cho MA, 2006, REMOTE SENS ENVIRON, V101, P181, DOI 10.1016/j.rse.2005.12.011
   Chrysafis I, 2019, INT J APPL EARTH OBS, V77, P1, DOI 10.1016/j.jag.2018.12.004
   Clark ML, 2020, ISPRS J PHOTOGRAMM, V159, P26, DOI 10.1016/j.isprsjprs.2019.11.007
   Corbera E, 2011, ENVIRON SCI POLICY, V14, P89, DOI 10.1016/j.envsci.2010.11.002
   dAndrimont R, 2020, REMOTE SENS ENVIRON, V239, P0, DOI 10.1016/j.rse.2020.111660
   Dash JP, 2017, ISPRS J PHOTOGRAMM, V131, P1, DOI 10.1016/j.isprsjprs.2017.07.007
   Deng S, 2019, BIOMED PHARMACOTHER, V112, P0, DOI 10.1016/j.biopha.2019.108696
   Douik A, 2010, INT J COMPUT COMMUN, V5, P506, DOI 10.15837/ijccc.2010.4.2508
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Duriancik LF, 2008, J SOIL WATER CONSERV, V63, P185A, DOI 10.2489/jswc.63.6.185A
   Ebert AW, 2014, SUSTAINABILITY-BASEL, V6, P319, DOI 10.3390/su6010319
   Eva H, 2010, ISPRS J PHOTOGRAMM, V65, P191, DOI 10.1016/j.isprsjprs.2009.10.008
   Fang JY, 2001, SCIENCE, V292, P2320, DOI 10.1126/science.1058629
   Feng SJ, 2015, GENET RESOUR CROP EV, V62, P1193, DOI 10.1007/s10722-015-0222-x
   Ferreira MP, 2019, ISPRS J PHOTOGRAMM, V149, P119, DOI 10.1016/j.isprsjprs.2019.01.019
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   FOODY GM, 1992, PHOTOGRAMM ENG REM S, V58, P1335
   Gitelson AA, 2003, J PLANT PHYSIOL, V160, P271, DOI 10.1078/0176-1617-00887
   Goetz S, 2011, CARBON MANAG, V2, P231, DOI 10.4155/CMT.11.18
   Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hamrouni Y, 2021, ISPRS J PHOTOGRAMM, V171, P76, DOI 10.1016/j.isprsjprs.2020.10.018
   Hansen MC, 2013, SCIENCE, V342, P850, DOI 10.1126/science.1244693
   Hansen MC, 2008, REMOTE SENS ENVIRON, V112, P3784, DOI 10.1016/j.rse.2008.05.012
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Hunt ML, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111410
   Ifarraguerri A, 2004, IEEE GEOSCI REMOTE S, V1, P101, DOI 10.1109/LGRS.2003.822879
   Immitzer M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11222599
   Immitzer M, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8030166
   Inglada J, 2016, REMOTE SENS-BASEL, V8, P0, DOI 10.3390/rs8050362
   Ingram JC, 2005, REMOTE SENS ENVIRON, V94, P491, DOI 10.1016/j.rse.2004.12.001
   Ji Y, 2019, FOOD SCI HUM WELL, V8, P115, DOI 10.1016/j.fshw.2019.03.008
   Lakshmanaprabu SK, 2019, INT J MACH LEARN CYB, V10, P2609, DOI 10.1007/s13042-018-00916-z
   Lambert MJ, 2018, REMOTE SENS ENVIRON, V216, P647, DOI 10.1016/j.rse.2018.06.036
   Le Toan T, 2011, REMOTE SENS ENVIRON, V115, P2850, DOI 10.1016/j.rse.2011.03.020
   Li CC, 2014, REMOTE SENS-BASEL, V6, P964, DOI 10.3390/rs6020964
   Li JK, 2015, FOOD CONTROL, V56, P9, DOI 10.1016/j.foodcont.2015.03.001
   Li LW, 2019, REMOTE SENS ENVIRON, V231, P0, DOI 10.1016/j.rse.2019.111265
   Liang S., 2017, COMPREHENSIVE REMOTE, V0, P0
   Liu YA, 2019, ISPRS J PHOTOGRAMM, V151, P277, DOI 10.1016/j.isprsjprs.2019.03.016
   Liu YS, 2017, NATURE, V548, P275, DOI 10.1038/548275a
   Long HL, 2016, J RURAL STUD, V47, P392, DOI 10.1016/j.jrurstud.2016.03.011
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Maschler J, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10081218
   Mayes S, 2012, J EXP BOT, V63, P1075, DOI 10.1093/jxb/err396
   Mellor A, 2013, REMOTE SENS-BASEL, V5, P2838, DOI 10.3390/rs5062838
   NELSON R, 1988, REMOTE SENS ENVIRON, V24, P247, DOI 10.1016/0034-4257(88)90028-4
   Ng WT, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9010074
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   Omer G, 2015, IEEE J-STARS, V8, P4825, DOI 10.1109/JSTARS.2015.2461136
   Onojeghuo AO, 2018, INT J REMOTE SENS, V39, P1042, DOI 10.1080/01431161.2017.1395969
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Peng C., 1999, TRANSFER-LONDON, V1, P0
   Phiri D, 2017, REMOTE SENS-BASEL, V9, P0, DOI 10.3390/rs9090967
   Potter C, 2012, REMOTE SENS ENVIRON, V121, P61, DOI 10.1016/j.rse.2012.01.019
   Qian C, 2019, CATENA, V183, P0, DOI 10.1016/j.catena.2019.104182
   Raczko E, 2017, EUR J REMOTE SENS, V50, P144, DOI 10.1080/22797254.2017.1299557
   Ramoelo A, 2015, J APPL REMOTE SENS, V9, P0, DOI 10.1117/1.JRS.9.094096
   Reis BP, 2019, ECOL ENG, V127, P178, DOI 10.1016/j.ecoleng.2018.11.022
   Rocchini D, 2013, COMPUT GEOSCI-UK, V50, P128, DOI 10.1016/j.cageo.2012.05.022
   Romijn E, 2012, ENVIRON SCI POLICY, V19-20, P33, DOI 10.1016/j.envsci.2012.01.005
   Roy DP, 2014, REMOTE SENS ENVIRON, V145, P154, DOI 10.1016/j.rse.2014.02.001
   Schultz B, 2015, REMOTE SENS-BASEL, V7, P14482, DOI 10.3390/rs71114482
   Sedano F, 2020, INT J APPL EARTH OBS, V92, P0, DOI 10.1016/j.jag.2020.102184
   Segarra J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142278
   Sesnie SE, 2010, INT J REMOTE SENS, V31, P2885, DOI 10.1080/01431160903140803
   Silveira EMO, 2019, INT J APPL EARTH OBS, V78, P175, DOI 10.1016/j.jag.2019.02.004
   Sulik JJ, 2016, REMOTE SENS ENVIRON, V184, P161, DOI 10.1016/j.rse.2016.06.016
   Sylvain JD, 2019, ISPRS J PHOTOGRAMM, V156, P14, DOI 10.1016/j.isprsjprs.2019.07.010
   Talema T, 2020, REMOTE SENS APPL, V18, P0, DOI 10.1016/j.rsase.2020.100290
   Tomppo E., 2002, UNASYLVA (ENGLISH ED.), V53, P16
   Tong XD, 2016, INT GEOSCI REMOTE SE, V0, PP3738, DOI 10.1109/IGARSS.2016.7729969
   Tscharntke T, 2012, BIOL CONSERV, V151, P53, DOI 10.1016/j.biocon.2012.01.068
   TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0
   van Leeuwen WJD, 2008, SENSORS-BASEL, V8, P2017, DOI 10.3390/s8032017
   Vuolo F, 2018, INT J APPL EARTH OBS, V72, P122, DOI 10.1016/j.jag.2018.06.007
   Waldner F, 2019, REMOTE SENS ENVIRON, V233, P0, DOI 10.1016/j.rse.2019.111375
   Wang M, 2019, LAND USE POLICY, V88, P0, DOI 10.1016/j.landusepol.2019.104190
   Wang S, 2011, J LIQ CHROMATOGR R T, V34, P2640, DOI 10.1080/10826076.2011.593219
   Wardlow BD, 2007, REMOTE SENS ENVIRON, V108, P290, DOI 10.1016/j.rse.2006.11.021
   Wu FL, 2017, GLOBAL PLANET CHANGE, V158, P36, DOI 10.1016/j.gloplacha.2017.09.008
   Wu XT, 2019, SCI TOTAL ENVIRON, V678, P565, DOI 10.1016/j.scitotenv.2019.05.022
   Wulder MA, 2006, FOREST CHRON, V82, P187, DOI 10.5558/tfc82187-2
   Wulder MA, 2006, REMOTE SENS ENVIRON, V101, P150, DOI 10.1016/j.rse.2005.12.010
   Wyniawskyj NS, 2019, INT GEOSCI REMOTE SE, V0, PP6598, DOI 10.1109/IGARSS.2019.8899782
   Xiao XM, 2004, REMOTE SENS ENVIRON, V89, P519, DOI 10.1016/j.rse.2003.11.008
   Xiao XM, 2005, REMOTE SENS ENVIRON, V95, P480, DOI 10.1016/j.rse.2004.12.009
   Xu ZG, 2004, INT FOREST REV, V6, P317, DOI 10.1505/ifor.6.3.317.59976
   Ye Y, 2018, SHAANXI FOREST SCI T, V46, P74
   You NS, 2020, ISPRS J PHOTOGRAMM, V161, P109, DOI 10.1016/j.isprsjprs.2020.01.001
   Yuan C, 2015, CAN J FOREST RES, V45, P783, DOI 10.1139/cjfr-2014-0347
   Zeng MM, 2018, FOOD CHEM, V239, P111, DOI 10.1016/j.foodchem.2017.06.097
   Zhang MM, 2017, INT J MOL SCI, V18, P0, DOI 10.3390/ijms18102172
NR 104
TC 7
Z9 8
U1 5
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD APR 15
PY 2021
VL 174
IS 
BP 68
EP 86
DI 10.1016/j.isprsjprs.2021.02.003
EA FEB 2021
PG 19
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology
GA RO4AQ
UT WOS:000640987800006
DA 2023-04-26
ER

PT J
AU Manso-Callejo, MA
   Cira, CI
   Garrido, RPA
   Matesanz, FJG
AF Manso-Callejo, Miguel-Angel
   Cira, Calimanut-Ionut
   Garrido, Ramon Pablo Alcarria
   Matesanz, Francisco Javier Gonzalez
TI First Dataset of Wind Turbine Data Created at National Level With Deep Learning Techniques From Aerial Orthophotographs With a Spatial Resolution of 0.5 M/Pixel
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Wind turbines; Feature extraction; Image segmentation; Training; Semantics; Task analysis; Production; Feature extraction; feature recognition; image classification; semantic segmentation; wind turbines
ID convolutional neural-network; building detection; object detection; recognition
AB Deep learning applied to feature extraction and mapping from high-resolution images is demonstrating the potential of this branch of data-intensive Artificial Intelligence to improve terrain mapping processes. The documented experiences have been applied on a small scale and there is a great expectation about its applicability on a country scale. For example, when extracting wind turbines using semantic segmentation models from a region of 28 km x 19 km containing unseen data, we obtained a commission rate of 1.4% and an omission rate of 0.38%. In this article, we present a methodology generated on the basis of two iterations. In these iterations, processing and postprocessing time, energy consumption, and finally results have been optimized to map wind turbines for the first time throughout the Spanish peninsular territory. In addition to adding a binary classification neural network prior to the semantic segmentation that extracts the turbines, a third multiclass recognition network has been used to classify the turbines by their power capacity complementing the features extracted with attributes. The proposed methodology can be adapted in the vectorization phase and applied to other types of features with linear or polygon representation to achieve a large-scale efficient extraction of geospatial elements using automated procedures.
C1 [Manso-Callejo, Miguel-Angel; Cira, Calimanut-Ionut; Garrido, Ramon Pablo Alcarria] Univ Politecn Madrid, Dept Ingn Topog & Cartog, Madrid 28031, Spain.
   [Matesanz, Francisco Javier Gonzalez] Direcc Gen Inst Geog Nacl, Subdirecc Gen Geodesia & Cartog, Madrid 28003, Spain.
C3 Universidad Politecnica de Madrid
RP Cira, CI (corresponding author), Univ Politecn Madrid, Dept Ingn Topog & Cartog, Madrid 28031, Spain.
EM m.manso@upm.es; ionut.cira@upm.es; ramon.alcarria@upm.es; fjgmatesanz@mitma.es
CR Abadi M, 2015, TENSORFLOW LARGE SCA, V0, P0
   Alidoost F, 2018, PFG-J PHOTOGRAMM REM, V86, P235, DOI 10.1007/s41064-018-0060-5
   Anaconda Inc, 2020, AN DOC, V0, P0
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP), V0, P0
   Chen Q., 2018, ARXIV180709532, V0, P0
   Chen X., 2019, PROC 7 INT C LEARN R, V0, P1
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Chollet F., 2017, DEEP LEARNING PYTHON, V0, P0
   Cira CI, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10207272
   Cira CI, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12050765
   Castillo VD, 2020, APPL SCI-BASEL, V10, P0, DOI 10.3390/app10113953
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   GDAL/OGR contributors, 2020, GDAL OGR GEOSP DAT A, V0, P0
   Gill J., 2019, P IEEE C COMP VIS PA, V0, P1
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Instituto Geografico Nacional, 2020, CTR DESC CNIG IGN CT, V0, P0
   Instituto Geografico Nacional, 2019, PLAN NAC ORT AER, V0, P0
   King DB, 2015, ACS SYM SER, V1214, P1
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li Y, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10020243
   Ma JJ, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152350
   Manso-Callejo MA, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12223743
   Ronneberger O., 2015, INT C MED IM COMP CO, V0, PP234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shorter N, 2009, REMOTE SENS-BASEL, V1, P731, DOI 10.3390/rs1040731
   Simonyan K., 2015, INT C LEARN REPRESEN, V0, P0
   Sirotkovic J., 2014, P IEEE S COMP COMM F, V0, P1
   Tan MX, 2019, PR MACH LEARN RES, V97, P0
   Vali A, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12152495
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Van Rossum G., 2009, PYTHON 3 REFERENCE M, V0, P0
   Yakubovskiy P., 2019, SEGMENTATION MODELS, V0, P0
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yuan JY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), V0, PP2703, DOI 10.1109/BigData.2016.7840915
   Zuo JW, 2018, IEEE GEOSCI REMOTE S, V15, P282, DOI 10.1109/LGRS.2017.2786232
NR 38
TC 1
Z9 1
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 7968
EP 7980
DI 10.1109/JSTARS.2021.3101934
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA UK8JJ
UT WOS:000692210900001
DA 2023-04-26
ER

PT J
AU Li, YY
   Huang, Q
   Pei, X
   Chen, YQ
   Jiao, LC
   Shang, RH
AF Li, Yangyang
   Huang, Qin
   Pei, Xuan
   Chen, Yanqiao
   Jiao, Licheng
   Shang, Ronghua
TI Cross-Layer Attention Network for Small Object Detection in Remote Sensing Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Object detection; Detectors; Remote sensing; Neural networks; Task analysis; Proposals; Attention mechanism; feature pyramid; object detection; remote sensing; small object
ID multiscale
AB In recent years, despite the tremendous progresses of object detection, small object detection has always been a challenge in the field of remote sensing. The main reason is that small objects cover few features that are easily lost during down-sampling. In this article, we propose a cross-layer attention network aiming to obtain stronger features of small objects for better detection. Specifically, we designed an up-sampling and down-sampling feature pyramid to obtain richer context information by bidirectionally fusing deep and shallow features, as well as skipping connections. Moreover, a cross-layer attention module is designed to obtain the nonlocal association of small objects in each layer, and further strengthen its representation ability through cross-layer integration and balance. Extensive experiments on the publicly available datasets (DIOR dataset and NWPUVHR-10 dataset) and the self-assembled datasets (SDOTA dataset and SDD dataset) show the excellent performance of our method compared with other detectors. Moreover, our method achieved 74.3% mAP on the public DIOR dataset without any tricks.
C1 [Li, Yangyang; Huang, Qin; Pei, Xuan; Jiao, Licheng; Shang, Ronghua] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Sch Artificial Intelligence,Minist Educ,Key Lab I, Xian 710071, Peoples R China.
   [Chen, Yanqiao] China Elect Technol Grp Corp, Res Inst 54, Shijiazhuang 050081, Hebei, Peoples R China.
C3 Xidian University; China Electronics Technology Group
RP Li, YY (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Sch Artificial Intelligence,Minist Educ,Key Lab I, Xian 710071, Peoples R China.
EM yyli@xidian.edu.cn; qinhuang@stu.xidian.edu.cn; 18804601171@163.com; chenyanqiao2016@163.com; lchjiao@mail.xidian.edu.cn; rhshang@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61772399, U1701267, 61773304, 61672405, 61772400]; Key Research and Development Program in Shaanxi Province of China [2019ZDLGY09-05]; Program for Cheung Kong Scholars and Innovative Research Team in University [IRT_15R53]; Technology Foundation for Selected Overseas Chinese Scholar in Shaanxi [2017021, 2018021]; National Key Research and Development Program of China [2017YFC08219]
CR [Anonymous], 2017, P IEEE C COMP VIS PA, V0, P0, DOI DOI 10.1109/CVPR.2017.106
   Cao Y, 2019, IEEE INT CONF COMP V, V0, PP1971, DOI 10.1109/ICCVW.2019.00246
   Chang SZ, 2020, IEEE T GEOSCI REMOTE, V58, P4033, DOI 10.1109/TGRS.2019.2960391
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cui LS, 2020, SCI CHINA INFORM SCI, V63, P0, DOI 10.1007/s11432-019-2723-1
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), V0, PP1796, DOI 10.1109/ICIT.2016.7475036
   Deng C., 2020, P ICLR, V0, P0
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Du B, 2019, IEEE J-STARS, V12, P3043, DOI 10.1109/JSTARS.2019.2917703
   Duan KW, 2019, IEEE I CONF COMP VIS, V0, PP6568, DOI 10.1109/ICCV.2019.00667
   Han JW, 2014, ISPRS J PHOTOGRAMM, V89, P37, DOI 10.1016/j.isprsjprs.2013.12.011
   He KM, 2016, PROC CVPR IEEE, V0, PP770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, V0, PP7132, DOI 10.1109/CVPR.2018.00745
   Huang L., 2015, DENSEBOX UNIFYING LA, V0, P0
   Jiang YY, 2018, INT C PATT RECOG, V0, P3610
   Li CL, 2020, IEEE COMPUT SOC CONF, V0, PP737, DOI 10.1109/CVPRW50498.2020.00103
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li YY, 2020, IEEE ACCESS, V8, P63121, DOI 10.1109/ACCESS.2020.2984310
   Li YY, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12030389
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Li Z., 2017, FSSD FEATURE FUSION, V0, P0
   Lim J-S., 2019, ARXIV191206319, V0, P0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, V0, PP8759, DOI 10.1109/CVPR.2018.00913
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Mark Everingham, 2010, IJCV, V88, P303, DOI 10.1007/S11263-009-0275-4
   Newell A, 2017, ADV NEUR IN, V30, P0
   Pang JM, 2019, PROC CVPR IEEE, V0, PP821, DOI 10.1109/CVPR.2019.00091
   Pang JM, 2019, IEEE T GEOSCI REMOTE, V57, P5512, DOI 10.1109/TGRS.2019.2899955
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Rabbi J, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12091432
   Redmon J, 2018, ARXIV, V0, P0, DOI DOI 10.1109/CVPR.2017.690
   Redmon J, 2017, PROC CVPR IEEE, V0, PP6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, V0, PP779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, P0, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, APPL SCI-BASEL, V8, P0, DOI 10.3390/app8050813
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wang SL, 2018, PROC CVPR IEEE, V0, PP2589, DOI 10.1109/CVPR.2018.00274
   Wei Liu, 2016, COMPUTER VISION - ECCV 2016. 14TH EUROPEAN CONFERENCE. PROCEEDINGS: LNCS 9905, V0, PP21, DOI 10.1007/978-3-319-46448-0_2
   Yang F, 2019, IEEE I CONF COMP VIS, V0, PP8310, DOI 10.1109/ICCV.2019.00840
   Yang X, 2018, IEEE ACCESS, V6, P50839, DOI 10.1109/ACCESS.2018.2869884
   Yang X, 2018, REMOTE SENS-BASEL, V10, P0, DOI 10.3390/rs10010132
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang H, 2019, PR MACH LEARN RES, V97, P0
NR 48
TC 20
Z9 20
U1 21
U2 69
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 2148
EP 2161
DI 10.1109/JSTARS.2020.3046482
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA QE6HN
UT WOS:000616306700002
DA 2023-04-26
ER

PT J
AU Bianchi, FM
   Grahn, J
   Eckerstorfer, M
   Malnes, E
   Vickers, H
AF Bianchi, Filippo Maria
   Grahn, Jakob
   Eckerstorfer, Markus
   Malnes, Eirik
   Vickers, Hannah
TI Snow Avalanche Segmentation in SAR Images With Fully Convolutional Neural Networks
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
LA English
DT Article
DE Synthetic aperture radar; Image segmentation; Peak to average power ratio; Deep learning; Snow; Radar imaging; Backscatter; Convolutional neural networks (CNNs); deep learning; saliency segmentation; Sentinel-1 (S1); snow avalanches; synthetic aperture radar (SAR)
AB Knowledge about frequency and location of snow avalanche activity is essential for forecasting and mapping of snow avalanche hazard. Traditional field monitoring of avalanche activity has limitations, especially when surveying large and remote areas. In recent years, avalanche detection in Sentinel-1 radar satellite imagery has been developed to improve monitoring. However, the current state-of-the-art detection algorithms, based on radar signal processing techniques, are still much less accurate than human experts. To reduce this gap, we propose a deep learning architecture for detecting avalanches in Sentinel-1 radar images. We trained a neural network on 6345 manually labeled avalanches from 117 Sentinel-1 images, each one consisting of six channels that include backscatter and topographical information. Then, we tested our trained model on a new synthetic aperture radar image. Comparing to the manual labeling (the gold standard), we achieved an F1 score above 66%, whereas the state-of-the-art detection algorithm sits at an F1 score of only 38%. A visual inspection of the results generated by our deep learning model shows that only small avalanches are undetected, whereas some avalanches that were originally not labeled by the human expert are discovered.
C1 [Bianchi, Filippo Maria] UiT Arctic Univ Norway, Dept Math & Stat, N-9019 Tromso, Norway.
   [Bianchi, Filippo Maria; Grahn, Jakob; Eckerstorfer, Markus; Malnes, Eirik; Vickers, Hannah] NORCE Norwegian Res Ctr AS, N-5008 Bergen, Norway.
C3 UiT The Arctic University of Tromso; Norwegian Research Centre (NORCE)
RP Bianchi, FM (corresponding author), UiT Arctic Univ Norway, Dept Math & Stat, N-9019 Tromso, Norway.
EM filippo.m.bianchi@uit.no; jgra@norceresearch.no; maec@norceresearch.no; eima@norceresearch.no; havi@norceresearch.no
FU 'Satskred' Project - Norwegian Space Centre [NIT.01.20.5]; Norwegian Water and Energy Resource Directorate; Norwegian Public Road Administration
CR Bakkehoi S., 1983, ANNALS OF GLACIOLOGY, V4, P24
   Berman M, 2018, PROC CVPR IEEE, V0, PP4413, DOI 10.1109/CVPR.2018.00464
   Bianchi FM, 2020, REMOTE SENS-BASEL, V12, P0, DOI 10.3390/rs12142260
   Chen L.-C., 2018, P EUR C COMP VIS ECC, V0, PP801, DOI 10.1007/978-3-030-01234-2_49
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, V0, P0, DOI DOI 10.5244/C.27.32
   Delparte D, 2008, COLD REG SCI TECHNOL, V54, P183, DOI 10.1016/j.coldregions.2008.07.006
   Eckerstorfer M, 2017, COLD REG SCI TECHNOL, V144, P39, DOI 10.1016/j.coldregions.2017.08.004
   Ioffe S., 2015, ARXIV 1502 03167, V1, P448
   Jones, 2011, P 5 CAN C GEOT NAT, V49, P1309
   Kampffmeyer M, 2018, IEEE J-STARS, V11, P1758, DOI 10.1109/JSTARS.2018.2834961
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, V0, PP680, DOI 10.1109/CVPRW.2016.90
   Kingma DP, 2015, 14126980 ARXIV, V0, P1
   Krestenitis M, 2019, REMOTE SENS-BASEL, V11, P0, DOI 10.3390/rs11151762
   Kummervold Per Egil, 2018, P INT SNOW SCI WORKS, V0, P377
   Larsen, 2018, P 12 EUR C SYNTH AP, V0, P1
   Luppino LT, 2018, IEEE INT WORKS MACH, V0, P0
   Luppino LT, 2019, IEEE T GEOSCI REMOTE, V57, P9960, DOI 10.1109/TGRS.2019.2930348
   Penatti Otavio A. B., 2015, 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW), V0, PP44, DOI 10.1109/CVPRW.2015.7301382
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sinha, 2019, P CLIM INF PAR FRANC, V0, P0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vickers H, 2017, LECT NOTES COMPUT SC, V10270, P136, DOI 10.1007/978-3-319-59129-2_12
   Waldeland AU, 2018, INT GEOSCI REMOTE SE, V0, P2386
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 26
TC 13
Z9 13
U1 3
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN 15
PY 2021
VL 14
IS 
BP 75
EP 82
DI 10.1109/JSTARS.2020.3036914
PG 8
WC Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology
GA PR7LT
UT WOS:000607413900003
DA 2023-04-26
ER
